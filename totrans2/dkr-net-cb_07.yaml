- en: Chapter 7. Working with Weave Net
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Installing and configuring Weave
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running Weave-connected containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding Weave IPAM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with WeaveDNS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weave security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the Weave network plugin
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Weave Net (Weave for short) is a third-party network solution for Docker. Early
    on, it provided users additional network functionality outside of what Docker
    natively offered. For instance, Weave provided overlay networks and **WeaveDNS**
    before Docker began supporting user-defined overlay networks and embedded DNS.
    However, with the more recent releases, Docker has started to gain feature parity
    from a network perspective with Weave. That being said, Weave still has a lot
    to offer and is an interesting example of how a third-party tool can interact
    with Docker to provide container networking. In this chapter, we'll walk through
    the basics of installing and configuring Weave to work with Docker as well as
    describe some of Weaves functionality from a network perspective. While we'll
    spend some time demonstrating some of the features of Weave this is not intended
    to be a how-to guide for the entire Weave solution. There are many features of
    Weave that will not be covered in this chapter. I recommend you check out their
    website for the most up–to-date information on features and functionality ([https://www.weave.works/](https://www.weave.works/)).
  prefs: []
  type: TYPE_NORMAL
- en: Installing and configuring Weave
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we'll walk through the installation of Weave as well as how
    to provision Weave services on your Docker hosts. We'll also show how Weave handles
    connecting hosts that wish to participate in the Weave network.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this example, we''ll be using the same lab topology we used in [Chapter
    3](ch03.html "Chapter 3. User-Defined Networks"), *User-Defined Networks*, where
    we discussed user-defined overlay networks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](graphics/B05453_07_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: You'll need a couple of hosts, preferably with some of them being on different
    subnets. It is assumed that the Docker hosts used in this lab are in their default
    configuration. In some cases, the changes we make may require you to have root-level
    access to the system.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Weave is installed and managed through the Weave CLI tool. Once downloaded,
    it manages not only Weave-related configuration but also the provisioning of Weave
    services. On each host you wish to configure, you simply run the following three
    commands:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the Weave binary to your local system:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Make the file executable:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Run Weave:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'If all of these commands complete successfully, your Docker host is now ready
    to use Weave for Docker networking. To verify, you can check the Weave status
    using the `weave status` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This output provides you with information regarding all five of Weave''s network-related
    services. Those are `router`, `ipam`, `dns`, `proxy`, and `plugin`. At this point,
    you might be wondering where all these services are running. Keeping with the
    Docker theme, they''re all running inside containers on the host:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](graphics/B05453_07_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, there are three Weave-related containers running on the host.
    Running the `weave launch` command spawned all three containers. Each container
    provides unique services that Weave uses to network containers. The `weaveproxy`
    container serves as a shim layer allowing Weave to be leveraged directly from
    the Docker CLI. The `weaveplugin` container implements a custom network driver
    for Docker. The "`weave`" container is commonly called the Weave router and provides
    all the other services that are related to Weave networking.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each of these containers can be configured and run independently. Running Weave
    with the `weave launch` command assumes that you''d like to use all three containers
    and deploys them with a sane set of defaults. However, if you ever wish to change
    the settings related to a specific container, you''d need to launch the containers
    independently. This can be done in this manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'If at any time you wish to clean up the Weave configuration on a particular
    host, you can issue the `weave reset` command, which will clean up all the Weave-related
    service containers. To start our example, we''ll only be using the Weave router
    container. Let''s clear out the Weave configuration and then start just that container
    on our host `docker1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The Weave router (weave container) is the only container we need to provide
    the majority of the network functionality. Let''s take a look at the configuration
    options that are passed to the Weave router by default by inspecting the weave
    container configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: There are some items worth pointing out in the preceding output. The IP allocation
    range is given as `10.32.0.0/12`. This is significantly different than the `172.17.0.0/16`
    we're used to dealing with by default on the `docker0` bridge. Also, there's an
    IP address defined to be used as the DNS listen address. Recall that Weave also
    provides WeaveDNS, which can be used to resolve the names of other containers
    on the Weave network by name. Notice that this IP address is that of the `docker0`
    bridge interface on the host.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now configure another one of our hosts as part of the Weave network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that we installed Weave in the same manner as before, but when we launched
    the router container, we did so by specifying the IP address of the first Docker
    host. In Weave, this is how we peer multiple hosts together. Any host you wish
    to connect to the Weave network just needs to specify the IP address of any existing
    node on the Weave network. If we check the status of Weave on this newly attached
    node, we should see that it shows as connected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We can proceed to connect the other two remaining nodes in the same way after
    Weave is installed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'In each case, we specify the previously joined Weave node as the peer of the
    node we are attempting to join. In our case, our join pattern looks like what''s
    shown in the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](graphics/B05453_07_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'However, we could have had each node join any other existing node and achieved
    the same result. That is, joining nodes `docker2`, `docker3`, and `docker4` to
    `docker1` would have yielded the same end state. This is because Weave only needs
    to talk to an existing node to get information about the current state of the
    Weave network. Since all of the existing members have that information, it doesn''t
    matter which one they talk to in order to join a new node to the Weave network.
    If we check the status of any of the Weave nodes now, we should see that we have
    a total of four peers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that this node has three connections, one to each of the other joined
    nodes. This gives us a total of four peers with twelve connections, three per
    Weave node. So despite only configuring peering between three nodes, we end up
    with a full mesh for container connectivity between all the hosts:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](graphics/B05453_07_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now the configuration of Weave is complete, and we have a full mesh network
    between all of our Weave-enabled Docker hosts. You can verify the connections
    that each host has with the other peers using the `weave status connections` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: You'll note that this configuration did not require the configuration of a standalone
    key-value store.
  prefs: []
  type: TYPE_NORMAL
- en: It should also be noted that Weave peers can be managed manually using the Weave
    CLI `connect` and `forget` commands. If you fail to specify an existing member
    of the Weave network when you instantiate Weave, you can use Weave connect to
    manually connect to an existing member. Also, if you remove a member from the
    Weave network and don't expect it to return, you can tell the network to entirely
    forget the peer with the `forget` command.
  prefs: []
  type: TYPE_NORMAL
- en: Running Weave-connected containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Weave is an interesting example showcasing the different ways in which a third-party
    solution can interact with Docker. It offers several different approaches to interacting
    with Docker. The first is the Weave CLI from which you can not only configure
    Weave, but also spawn containers much like you would through the Docker CLI. The
    second is the network plugin, which ties directly into Docker and allows you to
    provision containers from Docker onto the Weave network. In this recipe, we'll
    walk through how to connect containers to the Weave network using the Weave CLI.
    The Weave network plugin will be covered in its own recipe later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Weave also offers an API proxy service that allows Weave to insert itself as
    a shim in between Docker and the Docker CLI transparently. That configuration
    will not be covered in this chapter, but they have extensive documentation about
    that functionality at this link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.weave.works/docs/net/latest/weave-docker-api/](https://www.weave.works/docs/net/latest/weave-docker-api/)'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is assumed that you're building off of the lab we created in the first recipe
    of this chapter. It is also assumed that the hosts have Docker and Weave installed.
    The Weave peering we defined in the previous chapter is also assumed to be in
    place.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When using the Weave CLI to manage container connectivity, there are two approaches
    you can take to connect a container to the Weave network.
  prefs: []
  type: TYPE_NORMAL
- en: The first is to use the `weave` command to run a container. Weave accomplishes
    this by passing anything you specify after `weave run` to `docker run`. The advantage
    to this approach is that Weave is made aware of the connection since it's the
    one actually telling Docker to run the container.
  prefs: []
  type: TYPE_NORMAL
- en: 'This puts Weave in a perfect position to ensure that the container is started
    with the proper configuration for it to work on the Weave network. For instance,
    we can start a container named `web1` on the host `docker1` using this syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Note that the syntax for the `run` command is identical to that of Docker.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Despite the similarities, there are a couple of differences worth noting. Weave
    can only start containers in the background or `-d` mode. Also, you can not specify
    the `--rm` flag to remove the container after it finishes execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the container is started in this manner, let''s look at the container''s
    interface configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the container now has an additional interface named `ethwe`, which
    has an IP address of `10.32.0.1/12`. This is the Weave network interface and is
    added in addition to the Docker network interface (`eth0`). If we check, we''ll
    note that since we passed the `-P` flag, Docker has published the containers-exposed
    port to several the `eth0` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This proves that all of the port publishing functionality we saw earlier is
    still done through Docker networking constructs. The Weave interface is just added
    in addition to the existing Docker native network interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second approach to connecting a container to the Weave network can be accomplished
    in two different ways but yields essentially the same result. Existing Docker
    containers can be added to the Weave network by either starting a currently stopped
    container using the Weave CLI, or by attaching a running container to Weave. Let''s
    look at each approach. First, let''s start a container on the host `docker2` in
    the same way we normally do using the Docker CLI and then restart it using Weave:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'So as you can see, Weave has taken care of adding the Weave interface to the
    container when it was restarted using the Weave CLI. Similarly, we can start a
    second instance of our `web1` container on the host `docker3` and then dynamically
    connect it to the Weave network with the `weave attach` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: As we can see in the preceding output, the container did not have an `ethwe`
    interface until we manually attached it to the Weave network. The attachment was
    done dynamically without the need to restart the container. In addition to adding
    containers to the Weave network, you may also dynamically remove them from Weave
    using the `weave detach` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, you should have connectivity between all of the containers that
    are now connected to the Weave network. In my case, they were allocated the following
    IP addresses:'
  prefs: []
  type: TYPE_NORMAL
- en: '`web1` on host `docker1`: `10.32.0.1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`web2` on host `docker2`: `10.44.0.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`web1` on host `docker3`: `10.36.0.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This proves that the Weave network is working as expected and the containers
    are on the correct network segment.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Weave IPAM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we saw multiple times in earlier chapters, IPAM is a critical component of
    any container networking solution. The criticality of IPAM becomes even clearer
    when you start using common networks across multiple Docker hosts. As the number
    of IP allocations begins to scale being able to resolve these containers by names
    also becomes vital. Much like Docker, Weave has its own integrated IPAM for their
    container network solution. In this chapter, we'll show how to configure and leverage
    Weave IPAM to manage IP allocations across the Weave network.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is assumed that you're building off of the lab we created in the first recipe
    of this chapter. It is also assumed that the hosts have Docker and Weave installed.
    Docker should be in its default configuration, and Weave should be installed but
    not yet peered. If you need to remove the peering defined in previous examples,
    issue the `weave reset` command on each host.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Weave's solution to IPAM relies on the Weave network as a whole using one large
    subnet, which is then carved into smaller pieces and allocated directly to each
    host. The host then allocates container IP addresses out of the IP address pool
    it was allocated. In order for this to work, the Weave cluster has to agree on
    what IP allocations to assign to each host. It does this by first reaching a consensus
    within the cluster. If you have a general idea of how large your cluster will
    be, you can provide specifics to Weave during initialization that help it make
    a better decision.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The goal of this recipe is not to get into specifics on optimizing the consensus
    algorithm that Weave uses with IPAM. For specifics on that, see the following
    link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.weave.works/docs/net/latest/ipam/](https://www.weave.works/docs/net/latest/ipam/)'
  prefs: []
  type: TYPE_NORMAL
- en: For the sake of this recipe, we'll assume that you don't know how big your cluster
    will be and we'll work off the premise that it will start with two hosts and expand
    from there.
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s important to understand that the IPAM in Weave sits idle until you provision
    your first container. For instance, let''s start by configuring Weave on the host
    `docker1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The first thing you should notice is the addition of the parameter `--ipalloc-range`.
    As we mentioned earlier, Weave works off the concept of one large subnet. By default,
    this subnet is `10.32.0.0/12`. This default setting can be overridden during Weave
    initialization by passing the `--ipalloc-range` flag to Weave. To make these examples
    a little easier to understand, I decided to change the default subnet to something
    more manageable; in this case, `172.16.16.0/24`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s also run the same command on the host `docker2` but pass it the IP address
    of the host `docker1`, so it can immediately peer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that I once again passed the same subnet to Weave. It is critical that
    the IP allocation range on each host running Weave is identical. Only hosts that
    agree on the same IP allocation range will be able to function properly. Let''s
    now check the status of the Weave services:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The output shows two peers indicating that our peering to `docker1` was successful.
    Note that the IPAM service shows a status of `idle`. The `idle` status means that
    Weave is waiting for more peers to join before it makes any decisions about what
    hosts will get what IP allocations. Let''s see what happens when we run a container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'If we check the Weave status again, we should see that IPAM has now changed
    from **idle** to **ready**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Running the first container connected to the Weave network has forced Weave
    to come to a consensus. At this point, Weave has decided that the cluster size
    is two and has made its best effort to allocate the available IP addressing between
    the hosts. Let''s run a container on the host `docker1` as well and then check
    the IP addresses that were allocated to each container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the **weave ps** command, we can see that the container we just spawned
    on the host `docker1` received an IP address of `172.16.16.1/24`. If we check
    the IP address of the container `web2` on the host `docker2`, we''ll see that
    it got an IP address of `172.16.16.128/24`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This makes perfect sense. Weave knew that it had two members in the network
    so it splits the allocation directly in half, essentially giving each host its
    own `/25` network allocation. `docker1` started allocating out of the first half
    of the `/24` and `docker2` started right at the beginning of the second half.
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite fully allocating the entire space, it does not mean that we are now
    out of IP space. These initial allocations are more like reservations and can
    be changed based on the size of the Weave network. For instance, we can now add
    the host `docker3` to the Weave network and start another instance of the `web1`
    container on it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Because the network now has more members, Weave just further splits the initial
    allocation into smaller chunks. Based on the IP addresses being allocated to the
    containers on each host, we can see that Weave tries to keep the allocations within
    valid subnets. The following image shows what would happen to the IP allocations
    as the third and fourth hosts joined the Weave network:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](graphics/B05453_07_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: It's important to keep in mind that while the allocations given to each server
    are flexible, they all use the same mask as the initial allocation when they assign
    the IP address to the container. This ensures that the containers all assume that
    they are on the same network and have direct connectivity to each other removing
    the need to have routes pointing to other hosts.
  prefs: []
  type: TYPE_NORMAL
- en: 'To prove that the initial IP allocation must be the same across all hosts,
    we can try joining the last host, `docker4`, using a different subnet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'If we check the Weave router''s container for logs, we''ll see that it''s unable
    to join the existing Weave network because of having the wrong IP allocation defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The only way to join the existing Weave network would be to use the same initial
    IP allocation as all of the existing nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, it''s important to call out that it''s not a requirement to use Weave
    IPAM in this fashion. You can allocate IP addressing manually by specifying an
    IP address during a `weave run` like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: When specifying individual IP addresses, you can choose any IP address you like.
    As you'll see in a later recipe, you can also specify a subnet for allocation
    and have Weave keep track of that subnet allocation in IPAM. When assigning an
    IP address from a subnet the subnet must be part of the initial Weave allocation.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you wish to manually allocate IP addresses to some containers, it may be
    wise to configure an additional Weave parameter during the initial Weave configuration
    to limit the scope of the dynamic allocations. You may pass the `--ipalloc-default-subnet`
    parameter to Weave during launch to limit the scope of which IP addresses are
    dynamically assigned to hosts. For instance, you might pass this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: This would configure the Weave subnet to be `172.16.16.0/25` leaving the rest
    of the larger network available for manual allocation. We'll see in a later recipe
    that this type of configuration plays a big role in how Weave handles network
    isolation across the Weave network.
  prefs: []
  type: TYPE_NORMAL
- en: Working with WeaveDNS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Naturally, the next thing to consider after IPAM is name resolution. Regardless
    of scale, having some way to locate and identify containers by something other
    than an IP address becomes a necessity. Much like newer versions of Docker, Weave
    offers its own DNS service for resolving container names that live on Weave networks.
    In this recipe, we'll review the default configuration for WeaveDNS as well as
    show how it's implemented and some relevant configuration settings to get you
    up and running.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is assumed that you're building off the lab we created in the first recipe
    of this chapter. It is also assumed that the hosts have Docker and Weave installed.
    Docker should be in its default configuration and Weave should be installed with
    all four hosts successfully peered together, as we did in the first recipe of
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you''ve been following along up until this point in the chapter, you''ve
    already provisioned WeaveDNS. WeaveDNS comes along with the Weave router container
    and is enabled by default. We can see this by looking at the Weave status:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'When Weave provisions the DNS service, it starts with some sane defaults. In
    this case, it''s detected that my hosts DNS server is `10.20.30.13`, and so it
    has configured that as an upstream resolver. It''s also selected `weave.local`
    as the domain name. If we start a container using the weave run syntax, Weave
    will make sure that the container is provisioned in a manner that allows it to
    consume this DNS service. For instance, let''s start a container on the host `docker1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'After starting the container, we can see that Weave has configured the container''s
    `resolv.conf` file differently than Docker would have. Recall that Docker, by
    default, in nonuser-defined networks, will give a container the same DNS configuration
    as the Docker hosts itself. In this case, Weave has given the container a name
    server of `172.17.0.1`, which is, by default, the IP address assigned to the `docker0`
    bridge. You might be wondering how Weave expects the container to resolve its
    own DNS system by talking to the `docker0` bridge. The solution is quite simple.
    The Weave router container is run in host mode and has a service bound to port
    `53`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'If we check the ports bound on the host, we can see that the weave router is
    exposing port `53`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This means that the WeaveDNS service in the Weave container will be listening
    on the `docker0` bridge interface for DNS requests. Let''s start another container
    on the host `docker2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'As long as both containers are on the Weave network and have the appropriate
    settings, Weave will automatically generate a DNS record with the containers name.
    We can view all the name records Weave is aware of using the `weave status dns`
    command from any Weave-enabled host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see the container name, the IP address, the container ID, and the
    MAC address of the destination host's Weave network interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'This works well but relies on the container being configured with the appropriate
    settings. This is another scenario where using the Weave CLI is rather helpful
    since it ensures that these settings are in place at container runtime. For instance,
    if we start another container on the host `docker3` with the Docker CLI and then
    attach it to Docker, it won''t get a DNS record:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'This doesn''t work for two reasons. First, the container doesn''t know where
    to look for Weave DNS, and it is trying to resolve it through the DNS server Docker
    provided. In this case, that''s the one configured on the Docker host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Second, Weave did not register a record in WeaveDNS when the container was
    attached. In order for Weave to generate a record for the container in WeaveDNS,
    the container must be in the same domain. To do this, when Weave runs a container
    through its CLI, it passes the hostname of the container along with a domain name.
    We can mimic this behavior by provisioning a hostname when we run the container
    in Docker. For instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Now when we attach the container to the Weave network, we should see a DNS
    record generated for it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you wanted to have this container also be able to resolve records in WeaveDNS,
    you'd also need to pass the `--dns=172.17.0.1` flag to the container to ensure
    that its DNS server is set to the IP address of the `docker0` bridge.
  prefs: []
  type: TYPE_NORMAL
- en: 'You might have noticed that we now have two entries in WeaveDNS for the same
    container name. This is how Weave provides for basic load balancing within the
    Weave network. For instance, if we head back to the `docker2` host, let''s try
    and ping the name `web1` a couple of different times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Note how the container is resolving to a different IP address during the second
    ping attempt. Since there are multiple records in WeaveDNS for the same name,
    we can provide basic load balancing functionality just using DNS. Weave will also
    track the state of the containers and pull dead containers out of WeaveDNS. For
    instance, if we kill the container on the host `docker3`, we should see one of
    the `web1` records fall out of DNS leaving only a single record for `web1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are many different configuration options available to you for customizing
    how WeaveDNS works. To see the entire guide, check out the documentation at [https://www.weave.works/docs/net/latest/weavedns/](http://
    https://www.weave.works/docs/net/latest/weavedns/).
  prefs: []
  type: TYPE_NORMAL
- en: Weave security
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Weave offers a couple of features that fall under the umbrella of security.
    Since Weave is an overlay-based network solution, it offers the ability to encrypt
    the overlay traffic as it traverses the physical or underlay network. This can
    be particularly useful when your containers may need to traverse a public network.
    In addition, Weave allows you to isolate containers within certain network segments.
    Weave relies on using different subnets for each isolated segment to achieve this.
    In this recipe, we'll walk through how to configure both overlay encryption as
    well as how to provide isolation for different containers across the Weave network.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is assumed that you're building off the lab we created in the first recipe
    of this chapter. It is also assumed that the hosts have Docker and Weave installed.
    Docker should be in its default configuration, and Weave should be installed but
    not yet peered. If you need to remove the peering defined in previous examples,
    issue the `weave reset` command on each host.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Configuring Weave to encrypt the overlay network is fairly straightforward
    to accomplish; however, it must be done during the initial configuration of Weave.
    Using the same lab topology from the previous recipes, let''s run the following
    commands to build the Weave network:'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the host `docker1`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'On the hosts `docker2`, `docker3`,and `docker4`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'You''ll note that the command we run on the hosts is largely the same with
    the exception of the last three hosts specifying `docker1` as a peer in order
    to build the Weave network. In either case, there are a few additional parameters
    we''ve passed to the router during Weave initialization:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--password`: This is what enables the encryption for the communication between
    Weave nodes. You should, unlike in my example, pick a very secure password to
    use. This needs to be the same on every node running weave.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--trusted-subnets`: This allows you to define subnets of hosts as trusted,
    which means they don''t require their communication to be encrypted. When Weave
    does encryption it falls back to a slower data path than what is normally used.
    Since using the `--password` parameter turns on encryption end to end, it might
    make sense to define some subnets as not needing encryption'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--ipalloc-range`: Here, we define the larger Weave network to be `172.16.16.0/24`.
    We saw this command used in earlier recipes:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--ipalloc-default-subnet`: This instructs Weave to, by default, allocate container
    IP addresses out of a smaller subnet of the larger Weave allocation. In this case,
    that''s `172.16.16.128/25`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let''s run the following containers on each host:'
  prefs: []
  type: TYPE_NORMAL
- en: '`docker1`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '`docker2`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '`docker3`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '`docker4`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'You''ll note that on the host `docker3` and `docker4`, I added the `net:172.16.16.0/25`
    parameter. Recall when we started the Weave network, we told Weave to by default
    allocate IP addresses out of `172.16.16.128/25`. We can override this at container
    runtime and provide a new subnet for Weave to use so long as it''s within the
    larger Weave network. In this case, the containers on `docker1` and `docker2`
    will get an IP address within `172.16.16.128/25` because that is the default.
    The containers on `docker3` and `docker4` will get an IP address within `172.16.16.0/25`
    since we overrode the default. We can confirm this once you''ve started all the
    containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'As I mentioned earlier, using distinct subnets is how Weave provides for container
    segmentation. In this case, the topology would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](graphics/B05453_07_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The dotted lines symbolize the isolation that Weave is providing for us in
    the overlay network. Since the `tenant1` containers live is a separate subnet
    from the `tenant2` containers, they will not have connectivity. In this manner,
    Weave is using basic networking to allow for container isolation. We can prove
    this works with a few tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: You'll notice that when the `web2tenant2` container attempts to access a service
    within its own tenant (subnet), it works as expected. Attempts to access a service
    in `tenant1` receive no response. However, since DNS is shared across the Weave
    network, the container can still resolve the IP address of the containers in `tenant1`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This also illustrates an example of encryption and how we can specify certain
    hosts as being trusted. Regardless of which subnetwork the containers live in,
    Weave still builds connectivity between all of the hosts. Since we enabled encryption
    during Weave initialization, all of those connections should now be encrypted.
    However, we also specified a trusted network. The trusted network defines nodes
    that do not require encryption between themselves. In our case, we specified `192.168.50.0/24`
    as being trusted. Since there are two nodes that have those IP addresses, `docker3`
    and `docker4`, we should see that the connectivity between them is unencrypted.
    We can validate that using the weave status connections command on the hosts.
    We should get the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '`docker1` (truncated output):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '`docker2` (truncated output):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '`docker3` (truncated output):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '`docker4` (truncated output):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: You can see that all the connections show as encrypted with the exception of
    the connections between the host `docker3` (`192.168.50.101`) and the host `docker4`
    (`192.168.50.102`). Since both hosts need to agree on what a trusted network is,
    the hosts `docker1` and `docker2` will never agree for their connections to be
    unencrypted.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Weave network plugin
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the things that sets Weave apart is that it can be operated in several
    different manners. As we've seen in the previous recipes of this chapter, Weave
    has its own CLI which we can use to provision containers directly onto the Weave
    network. While this is certainly a tight integration that works well, it requires
    that you leverage the Weave CLI or Weave API proxy to integrate with Docker. In
    addition to these options, Weave has also written a native Docker network plugin.
    This plugin allows you to work with Weave directly from Docker. That is, once
    the plugin is registered, you no longer need to use the Weave CLI to provision
    containers into Weave. In this recipe, we'll review how to install and work with
    the Weave network plugin.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is assumed that you're building off the lab we created in the first recipe
    of this chapter. It is also assumed that the hosts have Docker and Weave installed.
    Docker should be in its default configuration, Weave should be installed, with
    all four hosts successfully peered together, as we did in the first recipe of
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Like the other components of Weave, leveraging the Docker plugin couldn''t
    be easier. All you need to do is to tell Weave to launch it. For instance, if
    I decided to use the Docker plugin on the host `docker1`, I could launch the plugin
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Much like the other services, the plugin comes in the form of a container.
    After running the preceding command, you should see the plugin running as a container
    named `weaveplugin`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](graphics/B05453_07_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Once running, you should also see it registered as a network plugin:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also see it as a defined network type using the `docker network` subcommand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, connecting containers to the Weave network can be done directly
    through Docker. All you need to do is specify the network name of `weave` when
    you start a container. For instance, we can run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'If we look at the container interfaces we should see the two interfaces we''re
    accustomed to seeing with Weave connected containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: However, you might note that the IP address for `eth1` is not on the `docker0`
    bridge, but rather on `docker_gwbridge` we saw used in earlier chapters when we
    showed the Docker overlay driver. The benefit of using the gateway bridge rather
    than the `docker0` bridge is that the gateway bridge has ICC disabled by default.
    This prevents Weave connected containers that are supposed to be isolated from
    accidentally cross talking across the `docker0` bridge if you had ICC mode enabled.
  prefs: []
  type: TYPE_NORMAL
- en: 'A downside to the plugin approach is that Weave isn''t in the middle to tell
    Docker about the DNS-related configurations, which means that the containers aren''t
    registering their names. Even if they were, they also aren''t receiving the proper
    name resolution settings required to resolve WeaveDNS. There are two ways we can
    specify the proper settings to the container. In either case, we need to manually
    specify the parameters at container runtime. The first method involves manually
    specifying all the required parameters yourself. Manually, it''s done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to register with DNS, you need the four bolded settings shown in the
    preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--hostname=web1.weave.local`: If you don''t set the hostname of the container
    to a name within `weave.local`, the DNS server won''t register the name.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--net=weave`: It has to be on the Weave network for any of this to work.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--dns=172.17.0.1`: We need to tell it to use the Weave DNS server listening
    on the `docker0` bridge IP address. However, you might have noticed that this
    container doesn''t actually have an IP address on the `docker0` bridge. Rather,
    since we''re connected to the `docker-gwbridge`, we have an IP address in the
    `172.18.0.0/16` network. In either case, since both bridges have IP interfaces
    the container can route through the `docker_gwbridge` to get to the IP interface
    on the `docker0` bridge.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--dns-search=weave.local`: This allows the container to resolve names without
    specifying the **Fully Qualified Domain Name** (**FQDN**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once a container is started with these settings, you should see records registering
    in WeaveDNS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'The second solution is still manual but involves pulling the DNS information
    from Weave itself. Rather than specifying the DNS server and the search domain,
    you can inject it right from Weave. Weave has a command named `dns-args` that
    will return the relevant information for you. So rather than specifying it, we
    can simply inject that command as part of the container parameters like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Granted, this doesn''t prevent the need to specify the network or the FQDN
    of the container, but it does trim down some of the typing. At this point, you
    should see all of the records defined in WeaveDNS and be able to access services
    across the Weave network by name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'You might note that these container''s DNS configuration isn''t exactly as
    you expected. For instance, the `resolv.conf` file does not show the DNS server
    we specified at container runtime:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'However, if you inspect the container''s configuration, you''ll see that the
    correct DNS server is properly defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Recall that user-defined networks require the use of Docker's embedded DNS system.
    The IP address we saw in the containers `resolv.conf` file references Docker's
    embedded DNS server. In turn, when we specify a DNS server for a container, the
    embedded DNS server adds that server as a forwarder in embedded DNS. This means
    that, although the request is still hitting the embedded DNS server first, the
    request is being forwarded on to WeaveDNS for resolution.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Weave plugin also allows you to create additional user-defined networks
    using the Weave driver. However, since Docker sees those as global in scope, they
    require the use of an external key store. If you're interested in using Weave
    in that fashion, please refer to the Weave documentation at [https://www.weave.works/docs/net/latest/plugin/](https://www.weave.works/docs/net/latest/plugin/).
  prefs: []
  type: TYPE_NORMAL
