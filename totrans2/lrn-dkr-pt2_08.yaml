- en: Chapter 8. Orchestrating Containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the earlier chapters, we laid down a strong foundation for the need for container
    networking, how to run a service inside a Docker container, and how to expose
    this service to the outside world by opening up network ports and other prerequisites.
    However, recently, there are advanced mechanisms being made available and a few
    third-party orchestration platforms hitting the market for sagaciously establishing
    dynamic and decisive linkages between distributed and differently enabled containers
    in order to compose powerful containers for comprehensively, yet compactly containing
    process-centric, multi-tiered, and enterprise-class distributed applications.
    In this extremely diversified yet connected world, the concept of orchestration
    cannot be kept away from its deserved prominence for long. This chapter is precisely
    devoted for explaining the nitty-gritty of container orchestration, and its direct
    role in picking up discrete containers to systematically compose sophisticated
    containers that are more directly aligned to the varying business expectations
    and expediencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will discuss the details associated with the following
    topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Linking containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orchestrating containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container orchestration using the `docker-compose` tool
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As mission-critical applications are overwhelmingly being built through loosely
    coupled, yet highly cohesive components/services destined to run on geographically
    distributed IT infrastructures and platforms, the concept of composition is getting
    a lot of attention and attraction. For sustaining the well-begun containerization
    journey, the orchestration of containers is being prescribed as one of the most
    critical and crucial requirements in the ensuing instant-on, adaptive, and smart
    IT era. There are a few proven and promising methods and standards-compliant tools
    for enabling the enigmatic orchestration goals.
  prefs: []
  type: TYPE_NORMAL
- en: Linking containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the prominent features of the Docker technology is linking containers.
    That is, cooperating containers can be linked together to offer complex and business-aware
    services. The linked containers have a kind of source-recipient relationship,
    wherein the source container gets linked to the recipient container, and the recipient
    securely receives a variety of information from the source container. However,
    the source container would know nothing about the recipients to which it is linked
    to. Another noteworthy feature of linking containers, in a secured setup, is that
    the linked containers can communicate using secured tunnels without exposing the
    ports used for the setup, to the external world.
  prefs: []
  type: TYPE_NORMAL
- en: The Docker engine provides the `--link` option in the `docker run` subcommand
    to link a source container to a recipient container.
  prefs: []
  type: TYPE_NORMAL
- en: 'The format of the `--link` option is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Here, `<container>` is the name of the source container and `<alias>` is the
    name seen by the recipient container. The name of the container must be unique
    in a Docker host, whereas alias is very specific and local to the recipient container,
    and hence, the alias need not be unique to the Docker host. This gives a lot of
    flexibility towards implementing and incorporating functionalities with a fixed
    source alias name inside the recipient container.
  prefs: []
  type: TYPE_NORMAL
- en: 'When two containers are linked together, the Docker engine automatically exports
    a few environment variables to the recipient container. These environment variables
    have a well-defined naming convention, where the variables are always prefixed
    with capitalized form of the alias name. For instance, if `src` is the alias name
    given to the source container, then the exported environment variables would begin
    with `SRC_`. Docker exports three categories of environment variables, as enumerated
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '`NAME`: This is the first category of environment variables. This variable
    takes the form of `<ALIAS>_NAME`, and it carries the recipient container''s hierarchical
    name as its value. For instance, if the source container''s alias is `src` and
    the recipient container''s name is `rec`, then the environment variable and its
    value would be `SRC_NAME=/rec/src`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`ENV`: This is the second category of environment variables. These variables
    export the environment variables configured in the source container by the `-e`
    option of the `docker run` subcommand or the `ENV` instruction of `Dockerfile`.
    This type of an environment variable takes the form of `<ALIAS>_ENV_<VAR_NAME>`.
    For instance, if the source container''s alias is `src` and the variable name
    is `SAMPLE`, then the environment variable would be `SRC_ENV_SAMPLE`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`PORT`: This is the final and third category of environment variables that
    is used to export the connectivity details of the source container to the recipient.
    Docker creates a bunch of variables for each port exposed by the source container
    through the `-p` option of the `docker run` subcommand or the `EXPOSE` instruction
    of the `Dockerfile`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'These variables take the form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This form is used to share the source''s IP address, port, and protocol as
    an URL. For example, if the source container''s alias is `src`, the exposed port
    is `8080`, the protocol is `tcp`, and the IP address is `172.17.0.2`, then the
    environment variable and its value would be `SRC_PORT_8080_TCP=tcp://172.17.0.2:8080`.
    This URL further splits into the following three environment variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '`<ALIAS>_PORT_<port>_<protocol>_ADDR`: This form carries the IP address part
    of the URL (For example: `SRC_PORT_8080_TCP_ADDR= 172.17.0.2`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<ALIAS>_PORT_<port>_<protocol>_PORT`: This form carries the port part of the
    URL (For example: `SRC_PORT_8080_TCP_PORT=8080`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<ALIAS>_PORT_<port>_<protocol>_PROTO`: This form carries the protocol part
    of the URL (For example: `SRC_PORT_8080_TCP_PROTO=tcp`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition to the preceding environment variables, the Docker engine exports
    one more variable in this category, that is, of the form `<ALIAS>_PORT`, and its
    value would be the URL of the lowest number of all the exposed ports of the source
    container. For instance, if the source container's alias is `src`, the exposed
    port numbers are `7070`, `8080`, and `80`, the protocol is `tcp`, and the IP address
    is `172.17.0.2`, then the environment variable and its value would be `SRC_PORT=tcp://172.17.0.2:80`.
  prefs: []
  type: TYPE_NORMAL
- en: Docker exports these auto-generated environment variables in a well-structured
    format so that they can be easily discovered programmatically. Thus, it becomes
    very easy for the recipient container to discover the information about the source
    container. In addition, Docker automatically updates the source IP address and
    its alias as an entry in the recipient's `/etc/hosts` file.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will take you deep into the mentioned features provided
    by the Docker engine for container linkage through a bevy of pragmatic examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start with, let''s choose a simple container linking example. Here, we will
    show you how to establish a linkage between two containers, and transfer some
    basic information from the source container to the recipient container, as illustrated
    in the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin by launching an interactive container that can be used as a source
    container for linking, using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The container is named `example` using the `--name` option. In addition, the
    `--rm` option is used to clean up the container as soon as you exit from the container.
  prefs: []
  type: TYPE_NORMAL
- en: 'Display the `/etc/hosts` entry of the source container using the `cat` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Here, the first entry in the `/etc/hosts` file is the source container's IP
    address (`172.17.0.3`) and its hostname (`a02895551686`).
  prefs: []
  type: TYPE_NORMAL
- en: 'We will continue to display the environment variables of the source container
    using the `env` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Having launched the source container, from another terminal of the same Docker
    host, let''s launch an interactive recipient container by linking it to our source
    container using the `--link` option of the `docker run` subcommand, as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Here, the source container named `example` is linked to the recipient container
    with `ex` as its alias.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s display the content of the `/etc/hosts` file of the recipient container
    using the `cat` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Of course, as always, the first entry of the `/etc/hosts` file is the container's
    IP address and its hostname. However, the noteworthy entry in the `/etc/hosts`
    file is the last entry, where the source container's IP address (`172.17.0.3`)
    and its alias (`ex`) are added automatically.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will continue to display the recipient container''s environment variable
    using the `env` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Apparently, a new `EX_NAME` environment variable is added automatically to `/berserk_mcclintock/ex`,
    as its value. Here `EX` is the capitalized form of the alias `ex` and `berserk_mcclintock`
    is the auto-generated name of the recipient container.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a final step, ping the source container using the widely used `ping` command
    for two counts, and use the alias name as the ping address:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Evidently, the source container's alias `ex` is resolved to the IP address `172.17.0.3`,
    and the recipient container is able to successfully reach the source. In the case
    of secured container communication, pinging between containers is not allowed.
    We have given more details on the aspect of securing containers in [Chapter 11](ch11.html
    "Chapter 11. Securing Docker Containers"), *Securing Docker Containers*.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding example, we could link two containers together, and also, observe
    how elegantly, networking is enabled between the containers by updating the source
    container's IP address in the `/etc/hosts` file of the recipient container.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next example is to demonstrate how container-linking exports the source
    container''s environment variables, which are configured using the `-e` option
    of the `docker run` subcommand or the `ENV` instruction of `Dockerfile`, to the
    recipient container. For this purpose, we are going to craft a `Dockerfile` with
    the `ENV` instruction, build an image, launch a source container using this image,
    and then launch a recipient container by linking it to the source container:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin with composing a `Dockerfile` with the `ENV` instruction, as shown
    here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Here, we are setting up two environment variables `BOOK` and `CHAPTER`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Proceed with building a Docker image `envex` using the `docker build` subcommand
    from the preceding `Dockerfile`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s launch an interactive source container with the name `example`
    using the `envex` image, we just built:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'From the source container prompt, display all the environment variables by
    invoking the `env` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In all the preceding environment variables, both the `BOOK` and the `CHAPTER`
    variables are configured with the `ENV` instruction of the `Dockerfile`.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a final step, to illustrate the `ENV` category of environment variables,
    launch the recipient container with the `env` command, as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This example is also available on GitHub at [https://github.com/thedocker/learning-docker/blob/master/chap08/Dockerfile-Env](https://github.com/thedocker/learning-docker/blob/master/chap08/Dockerfile-Env).
  prefs: []
  type: TYPE_NORMAL
- en: Strikingly, in the preceding output, the variables that are prefixed with `EX_`
    are the outcomes of container-linking. The environment variables of interest are
    `EX_ENV_BOOK` and `EX_ENV_CHAPTER`, which were originally set through the `Dockerfile`
    as `BOOK` and `CHAPTER` but modified to `EX_ENV_BOOK` and `EX_ENV_CHAPTER`, as
    an effect of container-linking. Though the environment variable names get translated,
    the values stored in these environment variables are preserved as is. We already
    discussed the `EX_NAME` variable name in the previous example.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding example, we could experience how elegantly and effortlessly
    Docker exports the `ENV` category variables from the source container to the recipient
    container. These environment variables are completely decoupled from the source
    and the recipient, thus the change in the value of these environment variables
    in one container does not impact the other. To be even more precise, the values
    the recipient container receives are the values set during the launch time of
    the source container. Any changes made to the value of these environment variables
    in the source container after its launch has no effect on the recipient container.
    It does not matter when the recipient container is launched because the values
    are being read from the JSON file.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our final illustration of linking containers, we are going to show you how
    to take advantage of the Docker feature to share the connectivity details between
    two containers. In order to share the connectivity details between containers,
    Docker uses the `PORT` category of environment variables. The following are the
    steps used to craft two containers and share the connectivity details between
    them:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Craft a `Dockerfile` to expose port `80` and `8080` using the `EXPOSE` instruction,
    as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Proceed to build a Docker image `portex` using the `docker build` subcommand
    from the `Dockerfile`, we created just now, by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s launch an interactive source container with the name, `example`
    using the earlier built image `portex`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have launched the source container, let''s continue to create a
    recipient container on another terminal by linking it to the source container,
    and invoke the `env` command to display all the environment variables, as shown
    here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This example is also available on GitHub at [https://github.com/thedocker/learning-docker/blob/master/chap08/Dockerfile-Expose](https://github.com/thedocker/learning-docker/blob/master/chap08/Dockerfile-Expose).
  prefs: []
  type: TYPE_NORMAL
- en: From the preceding output of the `env` command, it is quite evident that, the
    Docker engine exported a bunch of four `PORT` category environment variables for
    each port that was exposed using the `EXPOSE` instruction in the `Dockerfile`.
    In addition, Docker also exported another `PORT` category variable `EX_PORT`.
  prefs: []
  type: TYPE_NORMAL
- en: Orchestration of containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The pioneering concept of orchestration in the IT domain has been there for
    a long time now. For instance, in the **service computing** (**SC**) arena, the
    idea of service orchestration has been thriving in an unprecedented manner in
    order to produce and sustain highly robust and resilient services. Discrete or
    atomic services do not serve any substantial purpose unless, they are composed
    together in a particular sequence to derive process-aware composite services.
    As orchestrated services are more strategically advantageous for businesses in
    expressing and exposing their unique capabilities in the form of identifiable/discoverable,
    interoperable, usable, and composable services to the outside world; corporates
    are showing exemplary interest in having an easily searchable repository of services
    (atomic as well as composite). This repository, in turn, enables businesses in
    realizing large-scale data as well as process-intensive applications. It is clear
    that the multiplicity of services is very pivotal for organizations to grow and
    glow. This increasingly mandated requirement gets solved using the proven and
    promising orchestration capabilities, cognitively.
  prefs: []
  type: TYPE_NORMAL
- en: Now, as we are fast heading toward containerized IT environments; application
    and data containers ought to be smartly composed to realize a host of new generation
    software services.
  prefs: []
  type: TYPE_NORMAL
- en: However, for producing highly competent orchestrated containers, both purpose-specific
    as well as agnostic containers need to be meticulously selected and launched in
    the right sequence in order to create orchestrated containers. The sequence can
    come from the process (control as well as data) flow diagrams. Doing this complicated
    and daunting activity manually evokes a series of cynicisms and criticisms. Fortunately,
    there are orchestration tools in the Docker space that come in handy to build,
    run, and manage multiple containers to build enterprise-class services. The Docker
    firm, which has been in charge of producing and promoting, the generation, and
    assembling of, Docker-inspired containers, has come out with a standardized and
    simplified orchestration tool (named as `docker-compose`) in order to reduce the
    workloads of developers as well as system administrators.
  prefs: []
  type: TYPE_NORMAL
- en: The proven composition technique of the service computing paradigm is being
    replicated here in the raging containerization paradigm in order to reap the originally
    envisaged benefits of containerization, especially in building powerful application-aware
    containers.
  prefs: []
  type: TYPE_NORMAL
- en: The **microservice architecture** is an architectural concept that aims to decouple
    a software solution by decomposing its functionality into a pool of discrete services.
    This is done by applying the standard principles at the architectural level. The
    microservice architecture is slowly emerging as a championed way to design and
    build large-scale IT and business systems. It not only facilitates loose and light
    coupling and software modularity, but it is also a boon to continuous integration
    and deployment for the agile world. Any changes being made to one part of the
    application mandate has meant, massive changes being made to the application.
    This has been a bane and barrier to the aspect of continuous deployment. Micro
    services aim to resolve this situation, and hence, the microservice architecture
    needs light-weight mechanisms, small, independently deployable services, and ensures
    scalability and portability. These requirements can be met using Docker-sponsored
    containers.
  prefs: []
  type: TYPE_NORMAL
- en: Micro services are being built around business capabilities and can be independently
    deployed by fully automated deployment machinery. Each micro service can be deployed
    without interrupting the other micro services, and containers provide an ideal
    deployment and execution environment for these services along with other noteworthy
    facilities, such as the reduced time of deployment, isolation management, and
    a simple life cycle. It is easy to quickly deploy new versions of services inside
    containers. All of these factors led to the explosion of micro services using
    the features that Docker had to offer.
  prefs: []
  type: TYPE_NORMAL
- en: As explained, Docker is being posited as the next-generation containerization
    technology, which provides a proven and potentially sound mechanism to distribute
    applications in a highly efficient and distributed fashion. The beauty is that
    developers can tweak the application pieces within the container, while maintaining
    the overall integrity of the container. This has a bigger impact as the brewing
    trend is that, instead of large monolithic applications hosted on a single physical
    or virtual server, companies are building smaller, self-defined, easily manageable,
    and discrete services to be contained inside standardized and automated containers.
    In short, the raging containerization technology from Docker has come as a boon
    for the ensuing era of micro services.
  prefs: []
  type: TYPE_NORMAL
- en: Docker was built and sustained to fulfill the elusive goal of *run it once and
    run it everywhere*. Docker containers are generally isolated at process level,
    portable across IT environments, and easily repeatable. A single physical host
    can host multiple containers, and hence, every IT environment is generally stuffed
    with a variety of Docker containers. The unprecedented growth of containers is
    to spell out troubles for effective container management. The multiplicity and
    the associated heterogeneity of containers are used to sharply increase the management
    complexities of containers. Hence, the technique of orchestration and the flourishing
    orchestration tools have come as a strategic solace for accelerating the containerization
    journey in safe waters.
  prefs: []
  type: TYPE_NORMAL
- en: Orchestrating applications that span multiple containers containing micro services
    has become a major part of the Docker world, via projects, such as Google's Kubernetes
    or Flocker. Decking is another option used to facilitate the orchestration of
    Docker containers. Docker's new offering in this area is a set of three orchestration
    services designed to cover all aspects of the dynamic life cycle of distributed
    applications from application development to deployment and maintenance. Helios
    is another Docker orchestration platform used to deploy and manage containers
    across an entire fleet. In the beginning, `fig` was the most preferred tool for
    container orchestration. However, in the recent past, the company at the forefront
    of elevating the Docker technology has come out with an advanced container orchestration
    tool (`docker-compose`) to make life easier for developers working with Docker
    containers, as they move through the container life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Having realized the significance of having the capability of container orchestration
    for next generation, business-critical, and containerized workloads, the Docker
    company purchased the company that originally conceived and concretized the `fig`
    tool. Then, the Docker company appropriately renamed the tool as `docker-compose`
    and brought in a good number of enhancements to make the tool more tuned to the
    varying expectations of container developers and operation teams.
  prefs: []
  type: TYPE_NORMAL
- en: Here is a gist of `docker-compose`, which is being positioned as a futuristic
    and flexible tool used for defining and running complex applications with Docker.
    With `docker-compose`, you define your application's components (their containers,
    configuration, links, volumes, and so on) in a single file, and then, you can
    spin everything up with a single command, which does everything to get it up and
    running.
  prefs: []
  type: TYPE_NORMAL
- en: This tool simplifies the container management by providing a set of built-in
    tools to do a number of jobs that are being performed manually at this point in
    time. In this section, we supply all the details for using `docker-compose` to
    perform orchestration of containers in order to have a stream of next-generation
    distributed applications.
  prefs: []
  type: TYPE_NORMAL
- en: Orchestrate containers using docker-compose
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will discuss the widely used container orchestration tool
    `docker-compose`. The `docker-compose` tool is a very simple, yet powerful tool
    and has been conceived and concretized to facilitate the running of a group of
    Docker containers. In other words, `docker-compose` is an orchestration framework
    that lets you define and control a multi-container service.
  prefs: []
  type: TYPE_NORMAL
- en: It enables you to create a fast and isolated development environment as well
    as the ability to orchestrate multiple Docker containers in production. The `docker-compose`
    tool internally leverages the Docker engine for pulling images, building the images,
    starting the containers in a correct sequence, and making the right connectivity/linking
    among the containers/services based on the definition given in the `docker-compose.yml`
    file.
  prefs: []
  type: TYPE_NORMAL
- en: Installing docker-compose
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At the time of writing this book, the latest release of `docker-compose` is
    1.2.0, and it is recommended that you use it with Docker release 1.3 or above.
    You can find the latest official release of `docker-compose` at the GitHub location
    ([https://github.com/docker/compose/releases/latest](https://github.com/docker/compose/releases/latest)).
  prefs: []
  type: TYPE_NORMAL
- en: 'The Linux x86-64 binary for `docker-compose` version 1.2.0 is available at
    [https://github.com/docker/compose/releases/download/1.2.0/docker-compose-Linux-x86_64](https://github.com/docker/compose/releases/download/1.2.0/docker-compose-Linux-x86_64),
    which you can directly install using either the `wget` tool or the `curl` tool,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `wget` tool:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the `curl` tool:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, `docker-compose` is also available as a Python package, which
    you can install using the `pip` installer, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that if `pip` is not installed on the system, please install the `pip`
    package before the `docker-compose` installation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having successfully installed `docker-compose`, you can check the `docker-compose`
    version, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The docker-compose.yml file
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `docker-compose` tool orchestrates containers using the `docker-compose.yml`
    file, in which you can define the services that need to be crafted, the relationships
    between these services, and their runtime properties. The `docker-compose.yml`
    file is a **YAML Ain''t Markup Language** (**YAML**) format file, which is a human-friendly
    data serialization format. The default `docker-compose` file is `docker-compose.yml`,
    which can be changed using the `-f` option of the `docker-compose` tool. The following
    is the format of the `docker-compose.yml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Here, `<service>` is the name of the service. You can have more than one service
    definition in a single `docker-compose.yml` file. The service name should be followed
    by one or more keys. However, all the services must either have an `image` or
    a `build` key, followed by any number of optional keys. Except the `image` and
    `build` keys, the rest of the keys can be directly mapped to the options in the
    `docker run` subcommand. The value can be either a single value or multiple values.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a list of keys supported in the `docker-compose` version 1.2.0:'
  prefs: []
  type: TYPE_NORMAL
- en: '`image`: This is the tag or image ID'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`build`: This is the path to a directory containing a `Dockerfile`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`command`: This key overrides the default command'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`links`: This key links to containers in another service'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`external_links`: This key links to containers started either by some other
    `docker-compose.yml` or by some other means (not by `docker-compose`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ports`: This key exposes ports and specifies both the ports `HOST_port:CONTAINER_port`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`expose`: This key exposes ports without publishing them to the host machine'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`volumes`: This key mounts paths as volumes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`volumes_from`: This key mounts all of the volumes from another container'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`environment`: This adds environment variables and uses either an array or
    a dictionary'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`env_file`: This adds environment variables to a file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`extends`: This extends another service defined in the same or different configuration
    file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`net`: This is the networking mode, which has the same values as the Docker
    client `--net` option'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pid`: This enables the PID space sharing between the host and the containers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dns`: This sets custom DNS servers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cap_add`: This adds a capability to the container'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cap_drop`: This drops a capability of the container'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dns_search`: This sets custom DNS search servers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`working_dir`: This changes the working directory inside the container'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`entrypoint`: This overrides the default entrypoint'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`user`: This sets the default user'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hostname`: This sets a container''s host name'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`domainname`: This sets the domain name'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mem_limit`: This limits the memory'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`privileged`: This gives extended privileges'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`restart`: This sets the restart policy of the container'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stdin_open`: This enables the standard input facility'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tty`: This enables text based control such as a terminal'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cpu_shares`: This sets the CPU shares (relative weight)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The docker-compose command
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `docker-compose` tool provides sophisticated orchestration functionality
    with a handful of commands. All the `docker-compose` commands use the `docker-compose.yml`
    file as the base to orchestrate one or more services. The following is the syntax
    of the `docker-compose` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The `docker-compose` tool supports the following options:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--verbose`: This shows more output'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--version`: This prints the version and exits'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-f, --file <file>`: This specifies an alternate file for `docker-compose`
    (default is the `docker-compose.yml` file)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-p`, `--project-name <name>`: This specifies an alternate project name (default
    is the directory name)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `docker-compose` tool supports the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '`build`: This builds or rebuilds services'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kill`: This kills containers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logs`: This displays the output from the containers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`port`: This prints the public port for a port binding'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ps`: This lists the containers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pull`: This pulls the service images'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rm`: This removes the stopped containers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`run`: This runs a one-off command'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scale`: This sets a number of containers for a service'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start`: This starts services'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stop`: This stops services'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`up`: This creates and starts containers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common usage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, with the help of an example, we are going to experience the
    power of the orchestration feature provided by the Docker-Compose framework. For
    this purpose, we are going to build a two-tiered web application that will receive
    your inputs through a URL and respond back with the associated response text.
    This application is built using the following two services, as enumerated here:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Redis`: This is a key-value database used to store a key and its associated
    value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Node.js`: This is a JavaScript runtime environment used to implement web server
    functionality as well as the application logic'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each of these services is packed inside two different containers that are stitched
    together using the `docker-compose` tool. The following is the architectural representation
    of the services:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Common usage](graphics/7937OT_08_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, in this example, we begin with implementing the `example.js` module, a
    `node.js` file to realize the web server and the key lookup functionality. Further
    on, we will craft the `Dockerfile` on the same directory as `example.js` to package
    the `node.js` runtime environment, and then, define the service orchestration
    using a `docker-compose.yml` file on the same directory as `example.js`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the `example.js` file, which is a `node.js` implementation
    of the simple Request/Response web application. For demonstration purposes, in
    this code, we restrict the `build` and `kill docker-compose` commands. For the
    code to be self-explanatory, we added the comments in between the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This example is also available at [https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose](https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following text is the content of `Dockerfile` that packs the `node.js`
    image, the `redis` driver for `node.js`, and the `example.js` file as defined
    earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This code is also available at [https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose](https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following text is from the `docker-compose.yml` file that the defines the
    service orchestration for `docker compose` tool to act upon:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This example is also available at [https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose](https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose).
  prefs: []
  type: TYPE_NORMAL
- en: 'We defined two services in this `docker-compose.yml` file, wherein these services
    serve the following purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: The service named `web` is built using the `Dockerfile` in the current directory.
    Also, it is instructed to launch the container by running the node (the `node.js`
    runtime) with `/myapp/example.js` (web application implementation), as its argument.
    The container is linked to the `redis` container, and the container port `80`
    is mapped to the Docker host's port `8080`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The service named `redis` is instructed to launch a container with the `redis:latest`
    image. If the image is not present in the Docker host, the Docker engine will
    pull it from the central repository or the private repository.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let''s continue with our example by building the Docker images using the
    `docker-compose build` command, launch the containers using the `docker-compose
    up` command, and connect with a browser to verify the request/response functionality,
    as explained step by step here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `docker-compose` commands must be executed from the directory in which
    the `docker-compose.yml` file is stored. The `docker-compose` tool considers each
    `docker-compose.yml` file as a project, and it assumes the project name from the
    `docker-compose.yml` file''s directory. Of course, this can be overridden using
    the `-p` option. So, as a first step, let''s change the directory, wherein the
    `docker-compose.yml` file is stored:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Build the services using the `docker-compose build` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Proceed to bring up the services as indicated in the `docker-compose.yml`,
    file using the `docker-compose up` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Since the directory name is `example`, the `docker-compose` tool has assumed
    that the project name is `example`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having successfully orchestrated the services using the `docker-compose` tool,
    let''s invoke the `docker-compose ps` command from a different terminal to list
    the containers associated with the example `docker-compose` project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Evidently, the two `example_redis_1` and `example_web_1` containers are up and
    running. The container name is prefixed with `example_`, which is the `docker-compose`
    project name.
  prefs: []
  type: TYPE_NORMAL
- en: 'Explore the functionality of our own request/response web application on a
    different terminal of the Docker host, as illustrated here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Here, we are directly connecting to the web service using `http://0.0.0.0:8080`
    because the web service is bound to the Docker host on port `8080`.
  prefs: []
  type: TYPE_NORMAL
- en: Cool, isn't it? With very minimal effort, and the help of the `docker-compose.yml`
    file, we are able to compose two different services together and offer a composite
    service.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has been incorporated in the book in order to provide all the probing
    and prescribing details on seamlessly orchestrating multiple containers. We extensively
    discussed the need for container orchestration and the tools that enable us to
    simplify and streamline the increasingly complicated process of container orchestration.
    In order to substantiate how orchestration is handy and helpful in crafting enterprise-class
    containers, and to illustrate the orchestration process, we took the widely followed
    route of explaining the whole gamut through a simple example. We developed a web
    application and contained it within a standard container. Similarly, we took a
    database container, which is a backend for the frontend web application and the
    database was executed inside another container. We saw how to make the web application
    container aware of the database, using different technologies through the container-linkage
    feature of the Docker engine. We used the open source tool (`docker-compose`)
    for this purpose.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss how Docker facilitates software testing,
    especially integration testing with a few pragmatic examples.
  prefs: []
  type: TYPE_NORMAL
