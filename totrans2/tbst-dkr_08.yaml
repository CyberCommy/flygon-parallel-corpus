- en: Chapter 8. Managing Docker Containers with Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we learned about Docker networking and how to troubleshoot
    networking issues. In this chapter, we will introduce Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes is a container-cluster management tool. Currently, it supports Docker
    and Rocket. It is an open-sourced project by Google and it was launched in June
    2014 at Google I/O. It supports deployment on various cloud providers, such as GCE,
    Azure, AWS, vSphere, and Bare Metal. The Kubernetes manager is lean, portable,
    extensible, and self-healing.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following:'
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying Kubernetes on Bare Metal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying Kubernetes on Minikube
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying Kubernetes on AWS and vSphere
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying a pod
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying Kubernetes in a production environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Debugging Kubernetes issues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kubernetes has various important components, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Node**: This is a physical or virtual machine that is part of a Kubernetes
    cluster, running the Kubernetes and Docker services, onto which pods can be scheduled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Master**: This maintains the runtime state of Kubernetes'' server runtime.
    It is the point of entry for all the client calls to configure and manage Kubernetes
    components.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Kubectl**: This is the command-line tool used to interact with the Kubernetes
    cluster to provide master access to Kubernetes APIs. Through it, the user can
    deploy, delete, and list pods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pod**: This is the smallest scheduling unit in Kubernetes. It is a collection
    of Docker containers that share volumes and don''t have port conflicts. It can
    be created by defining a simple JSON file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Replication controller**: This manages the lifecycle of the pod and ensures
    that the specified number of pods are running at any given time by creating or
    killing pods as required.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Label**: Labels are used to identify and organize pods and services based
    on key-value pairs:![Managing Docker Containers with Kubernetes](graphics/image_08_001.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes master/minion flow
  prefs: []
  type: TYPE_NORMAL
- en: Deploying Kubernetes on Bare Metal machine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes can be deployed on the Bare Metal Fedora or Ubuntu machines. Even
    the Fedora and Ubuntu virtual machine can be deployed in vSphere, workstation,
    or VirtualBox. For the following tutorial, we''ll be looking at Kubernetes deployment
    on a single Fedora 24 machine, which will be acting as master, as well as node
    to deploy `k8s` pods:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Enable the Kubernetes testing YUM repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Install `etcd` and `iptables-services`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In `/etcd/hosts`, set the Fedora master and Fedora node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Disable the firewall and `iptables-services`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Edit the `/etcd/kubernetes/config` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Edit the contents of the `/etc/kubernetes/apiserver` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The `/etc/etcd/etcd.conf` file should have the following line uncommented in
    order to listen on port `2379`, as Fedora 24 uses etcd 2.0:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '**The Kubernetes node setup can be done on separate hosts, but we will be setting
    them on the current machine in order to have the Kubernetes master and node configured
    on the same machine:**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Edit the file `/etcd/kubernetes/kubelet` as follows:**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a shell script to start all the Kubernetes master and node services
    on the same machine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `node.json` file to configure it on the Kubernetes machine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a node object using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'After some time, node should be ready to deploy pods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Troubleshooting the Kubernetes Fedora manual setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If the kube-apiserver fails to start, it might be due to service account admission
    control and require a service account and a token before allowing pods to be scheduled.
    It is generated automatically by the controller. By default, the API server uses
    a TLS serving key, but as we are not sending over HTTPS and don't have a TLS server
    key, we can provide the API server the same key file in order for the API server
    to validate generated service-account tokens.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the following to generate the key and add it to the `k8s` cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'To start the API server, add the following option to the end of the `/etc/kubernetes/apiserver`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '`/etc/kubernetes/kube-controller-manager` add the following option to the end
    of the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Restart the cluster using the `start_k8s.sh` shell script.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying Kubernetes using Minikube
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Minikube is still in development; it is a tool that makes it easy to run Kubernetes
    locally, optimized for the underlying OS (MAC/Linux). It runs a single-node Kubernetes
    cluster inside a VM. Minikube helps developers to learn Kubernetes and do day-to-day
    development and testing with ease.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following setup will cover Minikube setup on Mac OS X, as very few guides
    are present to deploy Kubernetes on Mac:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the Minikube binary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Grant execute permission to the binary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Move the Minikube binary to `/usr/local/bin` so that it gets added to the path
    and can be executed directly on the terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'After this, we''ll require the `kubectl` client binary to run commands against
    the single-node Kubernetes cluster, for Mac OS X:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The kubectl is now configured to be used with the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Set up Minikube to deploy a VM locally and configure the Kubernetes cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We can set up kubectl to use a Minikube context, and switch later if required:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll be able to list the node of the Kubernetes cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `hello-minikube` pod and expose it as a service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We can get the `hello-minikube` pod status using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'We can open the Kubernetes dashboard using the following command and view details
    of the deployed pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '![Deploying Kubernetes using Minikube](graphics/image_08_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Kubernetes UI showcasing hello-minikube pod
  prefs: []
  type: TYPE_NORMAL
- en: Deploying Kubernetes on AWS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's get started with Kubernetes cluster deployment on AWS, which can be done
    by using the configuration file already existing in the Kubernetes codebase.
  prefs: []
  type: TYPE_NORMAL
- en: Log in to AWS console ([http://aws.amazon.com/console/](http://aws.amazon.com/console/))
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the IAM console ([https://console.aws.amazon.com/iam/home?#home](https://console.aws.amazon.com/iam/home?))
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose the IAM username, select the **Security Credentials** tab, and click
    the **Create Access Key** option.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After the keys are created, download them and keep them in a secure place. The
    downloaded CSV file will contain the access key ID and the secret access key,
    which will be used to configure the AWS CLI.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Install and configure the AWS command-line interface. In this example, we have
    installed AWS CLI on Linux using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to configure the AWS-CLI, use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: After the configuration of the AWS CLI, we will create a profile and attach
    a role to it with full access to S3 and EC2.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The role can be attached above the profile, which will have complete EC2 and
    S3 access, as shown in the following screenshot. The role can be created separately
    using the console or AWS CLI with the JSON file, which will define the permissions
    the role can have:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '![Deploying Kubernetes on AWS](graphics/image_08_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Attach policy in AWS during Kubernetes deployment
  prefs: []
  type: TYPE_NORMAL
- en: 'After the role is created, it can be attached to the policy using the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The script uses the default profile; we can change it as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The Kubernetes cluster can be easily deployed using one command, as follows;
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command will call `kube-up.sh` and, in turn, the `utils.sh` using
    the `config-default.sh` script, which contains the basic configuration of the
    `k8s` cluster with four nodes, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The instances are `**t2.micro**` running on Ubuntu. The process takes five to
    ten minutes, after which the IP address of the master and minions gets listed
    and can be used to access the Kubernetes cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploying Kubernetes on vSphere
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes can be installed on vSphere with the help of `govc` (a vSphere CLI
    built on top of govmomi):'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before starting the setup, we''ll have to install golang, which can be done
    in the following way on a Linux machine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Set the go path:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Download the pre-built Debian VMDK, which will be used to create the Kubernetes
    cluster on vSphere:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Kubernetes setup troubleshooting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We need to set up the proper environment variables to connect remotely to the
    ESX server to deploy the Kubernetes cluster. The following environment variables
    should be set in order to progress with Kubernetes setup on vSphere:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Use ESX and vSphere version v5.5 for this tutorial.
  prefs: []
  type: TYPE_NORMAL
- en: 'Upload the `kube.vmdk` to the ESX datastore. The VMDK will be stored in the
    `kube` directory, which will get created by the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Set up the Kubernetes provider as vSphere, as well the Kubernetes cluster,
    which will get deployed on the ESX. This will contain one Kubernetes master and
    four Kubernetes minion derived from the expanded `kube.vmdk` uploaded in the datastore:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'This will display a list of IP addresses for the four VMs. If you are currently
    developing Kubernetes, you can use this cluster-deployment mechanism to test out
    the new code in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The cluster can be brought down using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '![Kubernetes setup troubleshooting](graphics/image_08_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Kubernetes master/node deployed on vSphere
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes pod deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, in the following example, we will be deploying two NGINX replication pods
    (rc-pod) and exposing them via a service. To understand Kubernetes networking,
    please refer to the following diagram for more details. Here, an application can
    be exposed via a virtual IP address, and the request to be proxied, to which replica
    of pod (load balancer), is taken care of by the service:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Kubernetes pod deployment](graphics/image_08_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Kubernetes networking with OVS bridge
  prefs: []
  type: TYPE_NORMAL
- en: 'In the Kubernetes master, create a new folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the YAML file in the editor of your choice, which will be used to deploy
    the NGINX pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Create the NGINX pod using `kubectl:`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding pod creation process, we have created two replicas of the
    NGINX pod, and its details can be listed as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The container on the deployed minion can be listed as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Deploy the NGINX service using a YAML file in order to expose the NGINX pod
    on host port `82`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Create the NGINX service using `kubectl:`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The NGINX service can be listed as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Now the NGINX server test page via service can be accessed on the following
    URL: `http://192.168.3.43:82`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploying Kubernetes in a production environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we'll be covering some of the important points and concepts
    that can be used to deploy Kubernetes in production.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exposing Kubernetes services**: Once we deploy the Kubernetes pods, we expose
    them using services. The Kubernetes service is an abstraction, which defines a
    set of pods and a policy to expose them as a microservice. The service gets its
    own IP address, but the catch is that this address only exists within the Kubernetes
    cluster, which means the service is not exposed to the Internet. It''s possible
    to expose the service directly on the host machine port, but once we expose the
    service on the host machine, we get into port conflicts. It also voids Kubernetes
    benefits and makes it harder to scale the deployed service:![Deploying Kubernetes
    in a production environment](graphics/image_08_006.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes service exposed through external load balancer
  prefs: []
  type: TYPE_NORMAL
- en: 'One solution is to add an external load balancer such as HAProxy or NGINX.
    This is configured with a backend for each Kubernetes service and proxies traffic
    to individual pods. Similar to AWS deployment, a Kubernetes cluster can be deployed
    inside a VPN and an AWS external load balancer can be used to expose each Kubernetes
    service:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Support upgrade scenarios in Kubernetes**: In the case of an upgrade scenario,
    we need to have zero downtime. Kubernetes'' external load balancer helps to achieve
    this functionality in cases of service deployment through Kubernetes. We can start
    a replica cluster running the new version of the service, and the older cluster
    version will serve the live requests. As and when the new service is ready, the
    load balancer can be configured to switch load to the new version. By using this
    approach, we can support a zero-runtime upgrade scenario for enterprise products:![Deploying
    Kubernetes in a production environment](graphics/image_08_007.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Upgrade scenarios supported in Kubernetes deployment
  prefs: []
  type: TYPE_NORMAL
- en: '**Make the Kubernetes-based application deployment automatic**: With the help
    of a deployer, we can automate the process of testing, as well as deploying the
    Docker containers in production. In order to do so, we need to have a build pipeline
    and deployer, which pushes the Docker image to a registry such as Docker Hub after
    successful build. Then, the deployer will take care of deploying the test environment
    and invoke the test scripts. After successful testing, the deployer can also take
    care of deploying the service in the Kubernetes production environment:![Deploying
    Kubernetes in a production environment](graphics/image_08_008.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes application deployment pipeline
  prefs: []
  type: TYPE_NORMAL
- en: '**Know the resource constraints**: Know the resource constraints while starting
    Kubernetes cluster, configure the resource requests and CPU/memory limits on each
    pod. Most containers crash in the production environment due to lack of resources
    or insufficient memory. The containers should be well tested, and the appropriate
    resource should be allotted to the pod in the production environment for successful
    deployment of the microservice.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitor the Kubernetes cluster**: The Kubernetes cluster should be continuously
    monitored with the help of logging. Logging tools such as Graylog, Logcheck, or
    Logwatch should be used with Apache Kafka, a messaging system to collect logs
    from the containers and direct them to the logging tools. With the help of Kafka,
    it is easy to index the logs, as well as handle huge streams. Kubernetes replica
    works flawlessly. If any pod crashes, the Kubernetes service restarts them and
    keeps the number of replicas always up and running as per the configuration. One
    aspect that users like to know about is the real reason behind the failure. Kubernetes
    metrics and application metrics can be published to a time-series store such as
    InfluxDB, which can be used to track application errors and measure load, throughput,
    and other stats to perform post-analysis of the failure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Persistent storage in Kubernetes**: Kubernetes has the concept of volumes
    to work with persistent data. We want persistence storage in a production deployment
    of Kubernetes because containers lose their data as they restart. A volume is
    backed by a variety of implementations, such as host machines, NFS, or using the
    cloud-provider volume service. Kubernetes also provides two APIs to handle persistent
    storage:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Persistent volume (PV)**: This is a resource, provisioned in a cluster, which
    behaves as though a node is a cluster resource. Pods request the resource (CPU
    and memory) as required from the persistent volumes. It is usually provisioned
    by an administrator.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Persistent volume claim (PVC)**: A PVC consumes PV resources. It is a request
    for storage by the user, similar to a pod. A pod can request levels of resources
    (CPU and memory) as required.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Debugging Kubernetes issues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we''ll be discussing some of the Kubernetes troubleshooting
    concerns:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step to debug the Kubernetes cluster is to list the number of nodes,
    using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Also, verify that all nodes are in the ready state.
  prefs: []
  type: TYPE_NORMAL
- en: Look at the logs in order to figure out issues in the deployed Kubernetes cluster
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'If the pod stays in the pending state, use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: This will list events and might describe the last thing that happened to the
    pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see all the cluster events, use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'If the `kubectl` command line is unable to reach the `apiserver` process, ensure
    `Kubernetes_master` or `Kube_Master_IP` is set. Ensure the `apiserver` process
    is running in the master and check its logs:'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are able to create the replication controller but not see the pods:
    If the replication controller didn''t create the pods, check if the controller
    is running and look at the logs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If `kubectl` hangs forever or a pod is in the waiting state:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check if the hosts are being assigned to the pod, if not then currently they
    are being scheduled for some task.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check if the kubelet is pointing at the right place in `etcd` for pods and the
    `apiserver` is using the same name or IP of the minion.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check if the Docker daemon is running if some issue occurs. Also, check the
    Docker logs and make sure the firewall is not blocking the image from being fetched
    from Docker Hub.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `apiserver` process reports:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Error synchronizing container: `Get http://:10250/podInfo?podID=foo: dial tcp
    :10250:`**connection refused**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This means the pod has not yet been scheduled
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check the scheduler logs to see if it is running properly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cannot connect to the container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Try to Telnet to the minion at the service port or the pod's IP address
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Check if the container is created in Docker using the following command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: If you don't see the container, the issue will be with the pod configuration,
    image, Docker, or the kubelet. If you see the container getting created every
    10 seconds, then the issues are with the container creation, or the container's
    process is failing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: X.509 certificate has expired or is not yet valid.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check if the current time matches on the client and server. Use `ntpdate` for
    one-time clock synchronization.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about managing Docker containers with help of Kubernetes.
    Kubernetes have a different perspective among Docker orchestration tools,where
    each pod will get a unique IP address and communication between pods can occur
    with the help of services. We have covered many deployment scenarios, as well
    as troubleshooting issues when deploying Kubernetes on a Bare Metal machine, AWS,
    vSphere, or using Minikube. We also looked at deploying Kubernetes pods effectively
    and debugging Kubernetes issues. The final section helps with deploying Kubernetes
    in a production environment with load balancers, Kubernetes services, monitoring
    tools, and persistent storage. In the next chapter, we will cover Docker volumes
    and how to use them efficiently in a production environment.
  prefs: []
  type: TYPE_NORMAL
