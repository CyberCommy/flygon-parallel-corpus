- en: Kubernetes on AWS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using Kubernetes on the public cloud is flexible and scalable for your application.
    AWS is one of the popular services in the public cloud industry. In this chapter,
    you will know what AWS is and how to set up Kubernetes on AWS along with the following
    topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the public cloud
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using and understanding AWS components
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes setup and management by kops
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes cloud provider
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to AWS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you run your application on the public network, you need an infrastructure
    such as networks, Virtual Machines, and storage. Obviously, companies borrow or
    build their own data center to prepare those infrastructures, and then hire data
    center engineers and operators to monitor and manage those resources.
  prefs: []
  type: TYPE_NORMAL
- en: However, purchasing and maintaining those assets need a large capital expense;
    you also need an operation expense for data center engineers/operators. You also
    need a read time to fully set up those infrastructures, such as buying a server,
    mounting to a data center rack, cabling a network, and then the initial configuration/installation
    of the OS, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, rapidly allocating an infrastructure with appropriate resource capacity
    is one of the important factors that dictates that success of your business.
  prefs: []
  type: TYPE_NORMAL
- en: To make infrastructure management easier and quicker, there is a lot of technology
    helps for data centers. Such as, for virtualization, **Software Defined Network**
    (**SDN**), **Storage Area Network** (**SAN**), and so on. But combining this technology
    has some sensitive compatibility issues and is difficult to stabilize; therefore
    it is required to hire experts in this industry, which makes operation costs higher
    eventually.
  prefs: []
  type: TYPE_NORMAL
- en: Public cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are some companies that have provided an online infrastructure service.
    AWS is a well known service that provides online infrastructure, which is called
    cloud or public cloud. Back in the year 2006, AWS officially launched the Virtual
    Machine service, which was called **Elastic Computing Cloud** (**EC2**), an online
    object store service, which was called **Simple Storage Service** (**S3**) and
    an online messaging queue service, which was called **Simple Queue Service** (**SQS**).
  prefs: []
  type: TYPE_NORMAL
- en: These services are simple enough, but from a data center management point of
    view, they relieve infrastructure pre-allocation and reduce read time, because
    of pay-as-you-go pricing models (paying hourly or yearly for usage to AWS). Therefore,
    AWS is getting so popular that many companies have switched from their own data
    centers to the public cloud.
  prefs: []
  type: TYPE_NORMAL
- en: An antonym of the public cloud, your own data center is called **on- premises**.
  prefs: []
  type: TYPE_NORMAL
- en: API and infrastructure as code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the unique benefits of using a public cloud instead of on-premises data
    centers that public cloud provides an API to control infrastructure. AWS provides
    command-line tools (**AWS CLI**) to control AWS infrastructure. For example, after
    signing up to AWS ([https://aws.amazon.com/free/](https://aws.amazon.com/free/)),
    then install AWS CLI ([http://docs.aws.amazon.com/cli/latest/userguide/installing.html](http://docs.aws.amazon.com/cli/latest/userguide/installing.html)),
    then if you want to launch one Virtual Machine (EC2 instance), use AWS CLI as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00118.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, it takes only just a few minutes to access your Virtual Machine
    after signing up to AWS. On the other hand, what if you set up your own on premise
    data center from scratch? The following diagram is a high-level comparison on
    if you use on premise data centers or if you use the public cloud:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00119.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the public cloud is too simple and quick; this is why public
    cloud is flexible and convenient for not only emerging, but also permanent usage.
  prefs: []
  type: TYPE_NORMAL
- en: AWS components
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AWS has some components to configure network and storage. These are important
    to understand how the public cloud works and also important to know how to configure
    Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: VPC and subnet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: On AWS, first of all you need to create your own network; it is called **Virtual
    Private Cloud** (**VPC**) and uses a SDN technology. AWS allows you to create
    one or more VPC on AWS. Each VPC may connect with each other as required. When
    you create a VPC, just define one network CIDR block and AWS region. For example,
    CIDR `10.0.0.0/16` on `us-east-1`. No matter if you have access to a public network
    or not, you can define any network address range (between /16 to /28 netmask range).
    VPC creation is very quick, once done to create a VPC, and then you need to create
    one or more subnets within VPC.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, one VPC is created via the AWS command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Subnet is a logical network block. It must belong to one VPC and in addition,
    belong to one availability zone. For example, VPC `vpc-66eda61f` and `us-east-1b`.
    Then the network CIDR must be within VPC's CIDR. For example, if VPC CIDR is `10.0.0.0/16`
    (`10.0.0.0` - `10.0.255.255`) then one subnet CIDR could be `10.0.1.0/24` (`10.0.1.0`
    - `10.0.1.255`).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, two subnets are created (`us-east-1a` and `us-east-1b`)
    onto `vpc-66eda61f`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Let's make the first subnet a public facing subnet and the second subnet a private
    subnet. This means the public facing subnet can be accessible from the internet,
    which allows it to have a public IP address. On the other hand, a private subnet
    can't have a public IP address. To do that, you need to set up gateways and routing
    tables.
  prefs: []
  type: TYPE_NORMAL
- en: In order to make high availability for public networks and private networks,
    it is recommended to create at least four subnets (two public and two private
    on different availability zones).
  prefs: []
  type: TYPE_NORMAL
- en: But to simplify examples that are easy to understand, these examples create
    one public and one private subnet.
  prefs: []
  type: TYPE_NORMAL
- en: Internet gateway and NAT-GW
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In most cases, your VPC needs to have a connection with the public internet.
    In this case, you need to create an **IGW** (**internet gateway**) to attach to
    your VPC.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, an IGW is created and attached to `vpc-66eda61f`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Once the IGW is attached, then set a routing table (default gateway) for a subnet
    that points to the IGW. If a default gateway points to an IGW, this subnet is
    able to have a public IP address and access from/to the internet. Therefore, if
    the default gateway doesn't point to IGW, it is determined as a private subnet,
    which means no public access.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, a routing table is created that points to IGW and
    is set to the first subnet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: On the other hand, the second subnet, although a private subnet, does not need
    a public IP address, however, a private subnet sometimes needs to access the internet.
    For example, download some packages and access the AWS service access. In this
    case, we still have an option to connect to the internet. It is called **Network
    Address Translation Gateway** (**NAT-GW**).
  prefs: []
  type: TYPE_NORMAL
- en: NAT-GW allows private subnets to access the public internet through NAT-GW.
    Therefore, NAT-GW must be located at a public subnet, and the private subnet routing
    table points to NAT-GW as a default gateway. Note that in order to access NAT-GW
    on the public network, it needs **Elastic IP** (**EIP**) attached to the NAT-GW.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, a NAT-GW is created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Unlike an IGW, AWS charges you an additional hourly cost for Elastic IP and
    NAT-GW. Therefore, if you wish to save costs, launch an NAT-GW only while accessing
    the internet.
  prefs: []
  type: TYPE_NORMAL
- en: Creating NAT-GW takes a few minutes, then once NAT-GW is created, update a private
    subnet routing table that point to NAT-GW, and then any EC2 instances are able
    to access the internet, but again, due to no public IP address on the private
    subnet, there is no chance of access from the public internet to the private subnet
    EC2 instances.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, an update routing table for the second subnet points
    to NAT-GW as the default gateway:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Overall, there are two subnets that have been configured as public subnet and
    private subnet. Each subnet has a default route to use IGW and NAT-GW as follows.
    Note that ID varies because AWS assigns a unique identifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Types of subnet** | **CIDR block** | **Subnet ID** | **Route table ID**
    | **Default gateway** | **Assign Public IP while EC2 launches** |'
  prefs: []
  type: TYPE_TB
- en: '| Public | 10.0.1.0/24 | `subnet-d83a4b82` | `rtb-fb41a280` | `igw-c3a695a5`
    (IGW) | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| Private | 10.0.2.0/24 | `subnet-62758c06` | `rtb-cc4cafb7` | `nat-084ff8ba1edd54bf4`
    (NAT-GW) | No (default) |'
  prefs: []
  type: TYPE_TB
- en: Technically, you can still assign a public IP to private subnet EC2 instance,
    but there is no default gateway to the internet (IGW). Therefore, a public IP
    will just be wasted and absolutely not have connectivity from the internet.
  prefs: []
  type: TYPE_NORMAL
- en: Now if you launch an EC2 instance on the public subnet, it becomes public facing,
    so you can serve your application from this subnet.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if you launch an EC2 instance on the private subnet, it can
    still access to the internet through NAT-GW, but there will be no access from
    the internet. However, it can still access it from the public subnet's EC2 instances.
    So you can deploy internal services such as database, middleware, and monitoring
    tools.
  prefs: []
  type: TYPE_NORMAL
- en: Security group
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once VPC and subnets with related gateways/routes are ready, you can create
    EC2 instances. However, at least one access control needs to be created beforehand,
    which is called a **security group**. It can define a firewall rule that ingress
    (incoming network access) and egress (outgoing network access).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, a security group and a rule for public subnet hosts
    are created that allows ssh from your machine''s IP address, as well as open HTTP(80/tcp)
    world-wide:'
  prefs: []
  type: TYPE_NORMAL
- en: When you define a security group for public subnet, it is highly recommended
    it to be reviewed by a security expert. Because once you deploy an EC2 instance
    onto the public subnet, it has a public IP address and then everyone including
    crackers and bots are able to access your instances directly.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, create a security group for a private subnet host, that allows ssh from
    the public subnet host. In this case, specifing a public subnet security group
    ID (`sg-7d429f0d`) instead of a CIDR block is convenient:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Overall, there are two security groups that have been created as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Name** | **Security group ID** | **Allow ssh (22/TCP)** | **Allow HTTP
    (80/TCP)** |'
  prefs: []
  type: TYPE_TB
- en: '| Public | `sg-7d429f0d` | Your machine (`107.196.102.199`) | `0.0.0.0/0` |'
  prefs: []
  type: TYPE_TB
- en: '| Private | `sg-d173aea1` | public sg (`sg-7d429f0d`) | public sg (`sg-7d429f0d`)
    |'
  prefs: []
  type: TYPE_TB
- en: EC2 and EBS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: EC2 is one important service in AWS that you can launch a VM on your VPC. Based
    on hardware spec (CPU, memory, and network), there are several types of EC2 instances
    that are available on AWS. When you launch an EC2 instance, you need to specify
    VPC, subnet, security group, and ssh keypair. Therefore, all of these must be
    created beforehand.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because of previous examples, the only last step is ssh keypair. Let''s make
    an ssh keypair:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'After a few minutes, check the EC2 instances status on the AWS web console;
    it shows a public subnet host that has a public IP address. On the other hand,
    a private subnet host doesn''t have a public IP address:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00120.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you are in the public subnet host (`54.227.197.56`), but this host also
    has an internal (private) IP address, because this host is deployed in the 10.0.1.0/24
    subnet (`subnet-d83a4b82`), therefore the private address range must be `10.0.1.1`
    - `10.0.1.254`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s install nginx web server on the public host as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, go back to your machine and check the website for `54.227.197.56`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition, within the same VPC, there is reachability for other availability
    zones, therefore you can ssh from this host to the private subnet host (`10.0.2.98`).
    Note that we are using the `ssh -A` option that forwards a ssh-agent, so there
    is no need to create a `~/.ssh/id_rsa` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In addition to EC2, there is an important functionality, which is disk management.
    AWS provides a flexible disk management service called **Elastic Block Store**
    (**EBS**). You may create one or more persistent data storage that can attach
    to an EC2 instance. From an EC2 point of view, EBS is one of HDD/SSD. Once you
    terminate (delete) an EC2 instance, EBS and its contents may remain and then reattach
    to another EC2 instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, one volume that has 40 GB capacity is created; and
    then attached to a public subnet host (instance ID `i-0db344916c90fae61`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'After attaching the EBS volume to the EC2 instance, the Linux kernel recognizes
    `/dev/xvdh` as specified, and then you need to do partitioning in order to use
    this device, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00121.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'In this example, we made one partition as `/dev/xvdh1`, so you can create a
    filesystem as `ext4` format on `/dev/xvdh1` and then you can mount to use this
    device on an EC2 instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00122.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'After unmounting the volume, you can feel free to detach this volume and then
    re-attach it whenever needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Route 53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AWS also provides a hosted DNS service called **Route 53**. Route 53 allows
    you to manage your own domain name and associated FQDN to an IP address. For example,
    if you want to have a domain name `k8s-devops.net`, you can order through Route
    53 to register your DNS domain.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows ordering a domain name `k8s-devops.net`; it
    may take a few hours to complete registration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00123.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Once registration is completed, you may receive a notification email from AWS,
    and then you can control this domain name via the AWS command line or a web console.
    Let''s add one record (FQDN to IP address) that associate `public.k8s-devops.net`
    with the public facing EC2 host public IP address `54.227.197.56`. To do that,
    get a hosted zone ID as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you get a hosted zone id as `/hostedzone/Z1CTVYM9SLEAN8`, so let''s prepare
    a JSON file to update the DNS record as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Looks good, so now access the nginx through the DNS name `public.k8s-devops.net`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: ELB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AWS provides a powerful software based load balancer called **Elastic Load Balancer**
    (**ELB**). It allows you to load balance network traffic to one or multiple EC2
    instances. In addition, ELB can offload SSL/TLS encryption/decryption and also
    supports multi-availability zone.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, an ELB is created and associated with a public subnet
    host nginx (80/TCP). Because ELB also needs a security group, create a new security
    group for ELB first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s update the Route 53 DNS record `public.k8s-devops.net` that points to
    ELB. In this case, ELB already has an `A` record, therefore use a `CNAME` (alias)
    that points to ELB FQDN:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: S3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AWS provides a useful object data store service called **Simple Storage Service**
    (**S3**). It is not like EBS, no EC2 instance can mount as a file system. Instead,
    use AWS API to transfer a file to the S3\. Therefore, AWS can make availability
    (99.999999999%) and multiple instances can access it at the same time. It is good
    to store non-throughput and random access sensitive files such as configuration
    files, log files, and data files.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, a file is uploaded from your machine to AWS S3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Overall, we''ve discussed how to configure AWS components around VPC. The following
    diagram shows a major component and relationship:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00124.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Setup Kubernetes on AWS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've discussed some AWS components that are quite easy to set up networks,
    virtual machines, and storage. Therefore, there are a variety of ways to set up
    Kubernetes on AWS such as kubeadm ([https://github.com/kubernetes/kubeadm](https://github.com/kubernetes/kubeadm)),
    kops ([https://github.com/kubernetes/kops](https://github.com/kubernetes/kops)),
    and kubespray ([https://github.com/kubernetes-incubator/kubespray](https://github.com/kubernetes-incubator/kubespray)).
    One of the recommended ways to set up Kubernetes is using kops, which is a production
    grade setup tool and supports a lot of configuration. In this chapter, we will
    use kops to configure Kubernetes on AWS. Note that kops stands for Kubernetes
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: Install kops
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First of all, you need to install kops to your machine. Linux and macOS are
    supported. Kops is a single binary, so just copy the `kops` command to `/usr/local/bin`
    as recommended. After that, create an `IAM` user and role for kops that handles
    the kops operation. For details, follow the official documentation ([https://github.com/kubernetes/kops/blob/master/docs/aws.md](https://github.com/kubernetes/kops/blob/master/docs/aws.md)).
  prefs: []
  type: TYPE_NORMAL
- en: Run kops
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kops needs an S3 bucket that stores the configuration and status. In addition,
    use Route 53 to register the Kubernetes API server name, and etcd server name
    to the domain name system. Therefore, use S3 bucket and use the Route 53 that
    we've created in the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kops supports a variety of configurations, such as deploying to public subnets,
    private subnets, using different types and number of EC2 instances, high availability,
    and overlaying networks. Let''s configure Kubernetes with a similar configuration
    of network in the previous section as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Kops has an option to reuse existing VPC and subnets. However, it behaves tricky
    and may encounter some issues based on settings; it is recommended to create a
    new VPC by kops. For details, you may find a document at [https://github.com/kubernetes/kops/blob/master/docs/run_in_existing_vpc.md](https://github.com/kubernetes/kops/blob/master/docs/run_in_existing_vpc.md).
  prefs: []
  type: TYPE_NORMAL
- en: '| **Parameter** | **Value** | **Means** |'
  prefs: []
  type: TYPE_TB
- en: '| `--name` | `my-cluster.k8s-devops.net` | Set up `my-cluster` under `k8s-devops.net`
    domain |'
  prefs: []
  type: TYPE_TB
- en: '| `--state` | `s3://k8s-devops` | Use k8s-devops S3 bucket |'
  prefs: []
  type: TYPE_TB
- en: '| `--zones` | `us-east-1a` | Deploy on `us-east-1a` Availability Zone |'
  prefs: []
  type: TYPE_TB
- en: '| `--cloud` | `aws` | Use AWS as cloud provider |'
  prefs: []
  type: TYPE_TB
- en: '| `--network-cidr` | `10.0.0.0/16` | Create new VPC with CIDR 10.0.0.0/16 |'
  prefs: []
  type: TYPE_TB
- en: '| `--master-size` | `t2.large` | Use EC2 `t2.large` instance for master |'
  prefs: []
  type: TYPE_TB
- en: '| `--node-size` | `t2.medium` | Use EC2 `t2.medium` instance for nodes |'
  prefs: []
  type: TYPE_TB
- en: '| `--node-count` | `2` | Set up two nodes |'
  prefs: []
  type: TYPE_TB
- en: '| `--networking` | `calico` | Use Calico for overlay network |'
  prefs: []
  type: TYPE_TB
- en: '| `--topology` | `private` | Set up both public and private subnet, and deploy
    master and node to private |'
  prefs: []
  type: TYPE_TB
- en: '| `--ssh-puglic-key` | `/tmp/internal_rsa.pub` | Use `/tmp/internal_rsa.pub`
    for bastion host |'
  prefs: []
  type: TYPE_TB
- en: '| `--bastion` |  | Create ssh bastion server on public subnet |'
  prefs: []
  type: TYPE_TB
- en: '| `--yes` |  | Immediately to execute |'
  prefs: []
  type: TYPE_TB
- en: 'Therefore, run the following to run kops:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'It may take around 5 to 10 minutes to fully complete after seeing the preceding
    messages. This is because it requires us to create the VPC, subnet, and NAT-GW,
    launch EC2s, then install Kubernetes master and node, launch ELB, and then update
    Route 53 as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00125.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Once complete, `kops` updates `~/.kube/config` on your machine points to your
    Kubernetes API Server. Kops creates an ELB and sets the corresponding FQDN record
    on Route 53 as `https://api.<your-cluster-name>.<your-domain-name>/`, therefore,
    you may run the `kubectl` command from your machine directly to see the list of
    nodes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Hooray! It took just a few minutes to set up AWS Infrastructure and Kubernetes
    on the AWS from scratch. Now you can deploy pod through the `kubectl` command.
    But you may want to ssh to the master/node to see what is going on.
  prefs: []
  type: TYPE_NORMAL
- en: However, due to security reasons, if you specify `--topology private`, you can
    ssh to only the bastion host. Then ssh to master/node host using a private IP
    address. This is similar to the previous section that ssh to public subnet host,
    then ssh to the private subnet host using ssh-agent (`-A` option).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we ssh to the bastion host (kops creates Route 53
    entry as `bastion.my-cluster.k8s-devops.net`) and then ssh to master (`10.0.36.157`):'
  prefs: []
  type: TYPE_NORMAL
- en: '>![](../images/00126.jpeg)'
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes cloud provider
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While setting up Kubernetes by kops, it also configures Kubernetes cloud provider
    as AWS. Which means when you use the Kubernetes service with LoadBalancer, it
    will use ELB. It also uses **Elastic Block Store** (**EBS**) as its `StorageClass`.
  prefs: []
  type: TYPE_NORMAL
- en: L4 LoadBalancer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When you make the Kubernetes service public to the external world, using ELB
    makes much more sense. Setting service type as LoadBalancer will invoke ELB creation
    and associate it with nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, ELB has been created automatically and the DNS is `a5d97c8ef857511e7a6100edf846f38a-1490901085.us-east-1.elb.amazonaws.com`,
    so now you can access Grafana at `http://a5d97c8ef857511e7a6100edf846f38a-1490901085.us-east-1.elb.amazonaws.com`.
  prefs: []
  type: TYPE_NORMAL
- en: You may use `awscli` to update Route 53 to assign a `CNAME` such as `grafana.k8s-devops.net`.
    Alternatively, the Kubernetes incubator project `external-dns` ([https://github.com/kubernetes-incubator/external-dns)](https://github.com/kubernetes-incubator/external-dns))
    can automate to update Route 53 in this situation.![](../images/00127.jpeg)
  prefs: []
  type: TYPE_NORMAL
- en: L7 LoadBalancer (ingress)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As of kops version 1.7.0, it doesn't set up the ingress controller out of the
    box yet. However, kops provides some add-ons ([https://github.com/kubernetes/kops/tree/master/addons](https://github.com/kubernetes/kops/tree/master/addons))
    that expand the features of Kubernetes. One of the add-ons ingress-nginx ([https://github.com/kubernetes/kops/tree/master/addons/ingress-nginx](https://github.com/kubernetes/kops/tree/master/addons/ingress-nginx))
    uses a combination of AWS ELB and nginx to achieve the Kubernetes ingress controller.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to install the `ingress-nginx` add-on, type the following command
    to set up the ingress controller:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, deploy nginx and echoserver using the NodePort service as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'After a few minutes, the ingress controller associates the nginx service and
    echoserver service with the ELB. When you access the ELB server with URI "`/`"
    it shows the nginx screen as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00128.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'On the other hand, if you access the same ELB, but use the URI "`/echo`", it
    shows echoserver as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00129.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Compared to the standard Kubernetes LoadBalancer service, one LoadBalancer service
    consumes one ELB. On the other hand, using the nginx-ingress addon, it can consolidate
    multiple Kubernetes NodePort services onto the single ELB. This will help to build
    your RESTful service easier.
  prefs: []
  type: TYPE_NORMAL
- en: StorageClass
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we discussed in [Chapter 4](part0103.html#3279U0-6c8359cae3d4492eb9973d94ec3e4f1e),
    *Working with Storage and Resources*, there is a `StorageClass` that can dynamically
    allocate Persistent Volume. Kops sets up provisioner as `aws-ebs`, which uses
    EBS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This creates EBS volume automatically as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Overall, the Kubernetes cloud provider for AWS is utilized to map ELB to Kubernetes
    services and also EBS to Kubernetes Persistent Volume. It is a great benefit to
    use AWS for Kubernetes as there is no need to pre-allocate or buy either a physical
    LoadBalancer or storage, just pay as you go; it creates flexibility and scalability
    for your business.
  prefs: []
  type: TYPE_NORMAL
- en: Maintenance Kubernetes cluster by kops
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When you need to change the Kubernetes configuration, such as the number of
    nodes and even EC2 instance type, kops can support this kind of use case. For
    example, if you want to change Kubernetes node instance type from `t2.medium`
    to `t2.micro`, and also decrease number from 2 to 1 due to cost saving, you need
    to modify the kops node instance group (`ig`) setting as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'It launches vi editor and you can change the setting for kops node instance
    group as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, change `machineType` to `t2.small`, and `maxSize`/`minSize` to
    the `1` and then save it. After that, run the `kops update` command to apply settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'As you see in the preceding message, you need to run the `kops rolling-update
    cluster` command to reflect to the existing instances. It may take a few minutes
    to replace the existing instance to the new instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now the Kubernetes node instance has been decreased from `2` to `1` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have discussed public cloud. AWS is the most popular public
    cloud service and it gives the API to control AWS infrastructure programmatically.
    We can achieve automation and infrastructure as code easily. Especially, kops
    brings us to ultra-fast AWS and Kubernetes setup from scratch. Both Kubernetes
    and kops development are quite active. Please keep monitoring those projects,
    which will have more functionality and configuration in the near future.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will introduce **Google Cloud Platform** (**GCP**), which is
    another popular public cloud service. **Google Container Engine** (**GKE**) is
    the hosted Kubernetes service that makes using Kubernetes much easier.
  prefs: []
  type: TYPE_NORMAL
