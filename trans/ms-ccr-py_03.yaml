- en: Working with Threads in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 1](0159c46a-c66b-4ba3-87b5-81dbeb3bcf02.xhtml), *Advanced Introduction
    to Concurrent and Parallel Programming*, you saw an example of threads being used
    in concurrent and parallel programming. In this chapter, you will be introduced
    to the formal definition of a thread, as well as the `threading` module in Python.
    We will cover a number of ways to work with threads in a Python program, including
    activities such as creating new threads, synchronizing threads, and working with
    multithreaded priority queues, via specific examples. We will also discuss the
    concept of a lock in thread synchronization, and we will implement a lock-based
    multithreaded application, in order to better understand the benefits of thread
    synchronization.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The concept of a thread in the context of concurrent programming in computer
    science
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The basic API of the `threading` module in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to create a new thread via the `threading` module
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The concept of a lock and how to use different locking mechanisms to synchronize
    threads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The concept of a queue in the context of concurrent programming, and how to
    use the `Queue` module to work with queue objects in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following is a list of prerequisites for this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that you have Python 3 installed on your computer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Download the GitHub repository at [https://github.com/PacktPublishing/Mastering-Concurrency-in-Python](https://github.com/PacktPublishing/Mastering-Concurrency-in-Python)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: During this chapter, we will be working with the subfolder titled `Chapter03`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check out the following video to see the Code in Action: [http://bit.ly/2SeD2oz](http://bit.ly/2SeD2oz)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The concept of a thread
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the field of computer science, a **thread of execution** is the smallest
    unit of programming commands (code) that a scheduler (usually as part of an operating
    system) can process and manage. Depending on the operating system, the implementation
    of threads and processes (which we will cover in future chapters) varies, but
    a thread is typically an element (a component) of a process.
  prefs: []
  type: TYPE_NORMAL
- en: Threads versus processes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: More than one thread can be implemented within the same process, most often
    executing concurrently and accessing/sharing the same resources, such as memory;
    separate processes do not do this. Threads in the same process share the latter's
    instructions (its code) and context (the values that its variables reference at
    any given moment).
  prefs: []
  type: TYPE_NORMAL
- en: 'The key difference between the two concepts is that a thread is typically a
    component of a process. Therefore, one process can include multiple threads, which
    can be executing simultaneously. Threads also usually allow for shared resources,
    such as memory and data, while it is fairly rare for processes to do so. In short,
    a thread is an independent component of computation that is similar to a process,
    but the threads within a process can share the address space, and hence the data,
    of that process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/8ffb5a66-8985-4179-9c11-3abb0a3b0f28.png)'
  prefs: []
  type: TYPE_IMG
- en: A process with two threads of execution running on one processor
  prefs: []
  type: TYPE_NORMAL
- en: Threads were reportedly first used for a variable number of tasks in OS/360
    multiprogramming, which is a discontinued batch processing system that was developed
    by IBM in 1967\. At the time, threads were called tasks by the developers, while
    the term thread became popular later on and has been attributed to Victor A. Vyssotsky,
    a mathematician and computer scientist who was the founding director of Digital's
    Cambridge Research Lab.
  prefs: []
  type: TYPE_NORMAL
- en: Multithreading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In computer science, single-threading is similar to traditional sequential processing,
    executing a single command at any given time. On the other hand, **multithreading**
    implements more than one thread to exist and execute in a single process, simultaneously.
    By allowing multiple threads to access shared resources/contexts and be executed
    independently, this programming technique can help applications to gain speed
    in the execution of independent tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Multithreading can primarily be achieved in two ways. In single-processor systems,
    multithreading is typically implemented via **time slicing**, a technique that
    allows the CPU to switch between different software running on different threads.
    In time slicing, the CPU switches its execution so quickly and so often that users
    usually perceive that the software is running in parallel (for example, when you
    open two different software at the same time on a single-processor computer):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/8bad6da1-678c-48dd-a2ba-c4fc6320dad0.png)'
  prefs: []
  type: TYPE_IMG
- en: An example of a time slicing technique called round-robin scheduling
  prefs: []
  type: TYPE_NORMAL
- en: As opposed to single-processor systems, systems with multiple processors or
    cores can easily implement multithreading, by executing each thread in a separate
    process or core, simultaneously. Additionally, time slicing is an option, as these
    multiprocess or multicore systems can have only one processor/core to switch between
    tasks—although this is generally not a good practice.
  prefs: []
  type: TYPE_NORMAL
- en: 'Multithreaded applications have a number of advantages, as compared to traditional
    sequential applications; some of them are listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Faster execution time**: One of the main advantages of concurrency through
    multithreading is the speedup that is achieved. Separate threads in the same program
    can be executed concurrently or in parallel, if they are sufficiently independent
    of one another.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Responsiveness**: A single-threaded program can only process one piece of
    input at a time; therefore, if the main execution thread blocks on a long-running
    task (that is, a piece of input that requires heavy computation and processing),
    the whole program will not be able to continue with other input, and hence, it
    will appear to be frozen. By using separate threads to perform computation and
    remain running to take in different user input simultaneously, a multithreaded
    program can provide better responsiveness.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Efficiency in resource consumption**: As we mentioned previously, multiple
    threads within the same process can share and access the same resources. Consequently,
    multithreaded programs can serve and process many client requests for data concurrently,
    using significantly fewer resources than would be needed when using single-threaded
    or multiprocess programs. This also leads to quicker communication between threads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'That being said, multithreaded programs also have their disadvantages, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Crashes**: Even though a process can contain multiple threads, a single illegal
    operation within one thread can negatively affect the processing of all of the
    other threads in the process, and can crash the entire program as a result.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Synchronization**: Even though sharing the same resources can be an advantage
    over traditional sequential programming or multiprocessing programs, careful consideration
    is also needed for the shared resources. Usually, threads must be coordinated
    in a deliberate and systematic manner, so that shared data is computed and manipulated
    correctly. Unintuitive problems that can be caused by careless thread coordination
    include deadlocks, livelocks, and race conditions, all of which will be discussed
    in future chapters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An example in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To illustrate the concept of running multiple threads in the same process,
    let''s look at a quick example in Python. If you have already downloaded the code
    for this book from the GitHub page, go ahead and navigate to the `Chapter03` folder.
    Let''s take a look at the `Chapter03/my_thread.py` file, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In this file, we are using the `threading` module from Python as the foundation
    of the `MyThread` class. Each object of this class has a `name` and `delay` parameter.
    The function `run()`, which is called as soon as a new thread is initialized and
    started, prints out a starting message, and, in turn, calls the `thread_count_down()`
    function. This function counts down from the number `5` to the number `0`, while
    sleeping between iterations for a number of seconds, specified by the delay parameter.
  prefs: []
  type: TYPE_NORMAL
- en: The point of this example is to show the concurrent nature of running more than
    one thread in the same program (or process) by starting more than one object of
    the `MyThread` class at the same time. We know that, as soon as each thread is
    started, a time-based countdown for that thread will also start. In a traditional
    sequential program, separate countdowns will be executed separately, in order
    (that is, a new countdown will not start until the current one finishes). As you
    will see, the separate countdowns for separate threads are executed concurrently.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at the `Chapter3/example1.py` file, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are initializing and starting two threads together, each of which
    has `0.5` seconds as its `delay` parameter. Run the script using your Python interpreter.
    You should get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Just as we expected, the output tells us that the two countdowns for the threads
    were executed concurrently; instead of finishing the first thread's countdown
    and then starting the second thread's countdown, the program ran the two countdowns
    at almost the same time. Without including some overhead and miscellaneous declarations,
    this threading technique allows almost double improvement in speed for the preceding
    program.
  prefs: []
  type: TYPE_NORMAL
- en: There is one additional thing that should be taken note of in the preceding
    output. After the first countdown for number `5`, we can see that the countdown
    of thread B actually got ahead of thread A in execution, even though we know that
    thread A was initialized and started before thread B. This change actually allowed
    thread B to finish before thread A. This phenomenon is a direct result of concurrency
    via multithreading; since the two threads were initialized and started almost
    simultaneously, it was quite likely for one thread to get ahead of the other in
    execution.
  prefs: []
  type: TYPE_NORMAL
- en: If you were to execute this script many times, it would be quite likely for
    you to get varying output, in terms of the order of execution and the completion
    of the countdowns. The following are two pieces of output that I obtained by executing
    the script again and again. The first output shows a uniform and unchanging order
    of execution and completion, in which the two countdowns were executed hand in
    hand. The second shows a case in which thread A was executed significantly faster
    than thread B; it even finished before thread B counted to number `1`. This variation
    of output further illustrates the fact that the threads were treated and executed
    by Python equally.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows one possible output of the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is another possible output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: An overview of the threading module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a lot of choices when it comes to implementing multithreaded programs
    in Python. One of the most common ways to work with threads in Python is through
    the `threading` module. Before we dive into the module's usage and its syntax,
    first, let's explore the `thread` model, which was previously the main thread-based
    development module in Python.
  prefs: []
  type: TYPE_NORMAL
- en: The thread module in Python 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before the `threading` module became popular, the primary thread-based development
    module was `thread`. If you are using an older version of Python 2, it is possible
    to use the module as it is. However, according to the module documentation page,
    the `thread` module was, in fact, renamed `_thread` in Python 3.
  prefs: []
  type: TYPE_NORMAL
- en: For readers that have been working with the `thread` module to build multithreaded
    applications and are looking to port their code from Python 2 to Python 3, the
    2to3 tool might be a solution. The 2to3 tool handles most of the detectable incompatibilities
    between the different versions of Python, while parsing the source and traversing
    the source tree to convert Python 2.x code into Python 3.x code. Another trick
    to achieve the conversion is to change the import code from `import thread` to
    `import _thread as thread` in your Python programs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main feature of the `thread` module is its fast and sufficient method of
    creating new threads to execute functions: the `thread.start_new_thread()` function.
    Aside from this, the module only supports a number of low-level ways to work with
    multithreaded primitives and share their global data space. Additionally, simple
    lock objects (for example, mutexes and semaphores) are provided for synchronization
    purposes.'
  prefs: []
  type: TYPE_NORMAL
- en: The threading module in Python 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The old `thread` module has been considered deprecated by Python developers
    for a long time, mainly because of its rather low-level functions and limited
    usage. The `threading` module, on the other hand, is built on top of the `thread`
    module, providing easier ways to work with threads through powerful, higher-level
    APIs. Python users have actually been encouraged to utilize the new `threading`
    module over the `thread` module in their programs.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the `thread` module considers each thread a function; when the `thread.start_new_thread()`
    is called, it actually takes in a separate function as its main argument, in order
    to spawn a new thread. However, the `threading` module is designed to be user-friendly
    for those that come from the object-oriented software development paradigm, treating
    each thread that is created as an object.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to all of the functionality for working with threads that the `thread`
    module provides, the `threading` module supports a number of extra methods, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`threading.activeCount()`: This function returns the number of currently active
    thread objects in the program'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`threading.currentThread()`: This function returns the number of thread objects
    in the current thread control from the caller'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`threading.enumerate()`: This function returns a list of all of the currently
    active thread objects in the program'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Following the object-oriented software development paradigm, the `threading`
    module also provides a `Thread` class that supports the object-oriented implementation
    of threads. The following methods are supported in this class:'
  prefs: []
  type: TYPE_NORMAL
- en: '`run()`: This method is executed when a new thread is initialized and started'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start()`: This method starts the initialized calling thread object by calling
    the `run()` method'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`join()`: This method waits for the calling thread object to terminate before
    continuing to execute the rest of the program'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`isAlive()`: This method returns a Boolean value, indicating whether the calling
    thread object is currently executing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`getName()`: This method returns the name of the calling thread object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`setName()`: This method sets the name of the calling thread object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a new thread in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having provided an overview of the `threading` module and its differences from
    the old `thread` module, in this section, we will explore a number of examples
    of creating new threads by using these tools in Python. As mentioned previously,
    the `threading` module is most likely the most common way of working with threads
    in Python. Specific situations require use of the `thread` module and maybe other
    tools, as well, and it is important for us to be able to differentiate those situations.
  prefs: []
  type: TYPE_NORMAL
- en: Starting a thread with the thread module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the `thread` module, new threads are created to execute functions concurrently.
    As we have mentioned, the way to do this is by using the `thread.start_new_thread()`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: When this function is called, a new thread is spawned to execute the function
    specified by the parameters, and the identifier of the thread is returned when
    the function finishes its execution. The `function` parameter is the name of the
    function to be executed, and the `args` parameter list (which has to be a list
    or a tuple) includes the arguments to be passed to the specified function. The
    optional `kwargs` argument, on the other hand, includes a separate dictionary
    of additional keyword arguments. When the `thread.start_new_thread()` function
    returns, the thread also terminates silently.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at an example of using the `thread` module in a Python program. If
    you have already downloaded the code for this book from the GitHub page, go ahead
    and navigate to the `Chapter03` folder and the `Chapter03/example2.py` file. In
    this example, we will look at the `is_prime()` function that we have also used
    in previous chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: You may have noticed that there is quite a difference in the way this `is_prime(x)`
    function returns the result of its computation; instead of returning `true` or
    `false`, to indicate whether the `x` parameter is a prime number, this `is_prime()`
    function directly prints out that result. As you saw earlier, the `thread.start_new_thread()`
    function executes the parameter function through spawning a new thread, but it
    actually returns the thread's identifier. Printing out the result inside of the
    `is_prime()` function is a workaround for accessing the result of that function
    through the `thread` module.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the main part of our program, we will loop through a list of potential candidates
    for prime numbers, and we will call the `thread.start_new_thread()` function on
    the `is_prime()` function and each number in that list, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'You will notice that, in the `Chapter03/example2.py` file, there is a line
    of code to take in the user''s input at the end:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: For now, let's comment out this last line. Then, when we execute the whole Python
    program, it will be observed that the program terminates without printing out
    any output; in other words, the program terminates before the threads can finish
    executing. This is due to the fact that, when a new thread is spawned through
    the `thread.start_new_thread()` function to process a number in our input list,
    the program continues to loop through the next input number while the newly created
    thread executes.
  prefs: []
  type: TYPE_NORMAL
- en: So, by the time the Python interpreter reaches the end of the program, if any
    thread has not finished executing (in our case, it is all of the threads), that
    thread will be ignored and terminated, and no output will be printed out. However,
    once in a while, one of the output is `2 is a prime number.` which will be printed
    out before the program terminates, because the thread processing the number `2`
    is able to finish executing prior to that point.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last line of code is another workaround for the `thread` module—this time,
    to address the preceding problem. This line prevents the program from exiting
    until the user presses any key on their keyboard, at which time the program will
    quit. The strategy is to wait for the program to finish executing all of the threads
    (that is, to finish processing all of the numbers in our input list). Uncomment
    the last line and execute the file, and your output should be similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the `Type something to quit:` line, which corresponds to the
    last line of code in our program, was printed out before the output from the `is_prime()`
    function; this is consistent with the fact that that line is executed before any
    of the other threads finish executing, most of the time. I say most of the time
    because, when the thread that is processing the first input (the number `2`) finishes
    executing before the Python interpreter reaches the last line, the output of the
    program would be something similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Starting a thread with the threading module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You now know how to start a thread with the `thread` module, and you know about
    its limited and low-level use of threading and the need for considerably unintuitive
    workarounds when working with it. In this subsection, we will explore the preferred
    `threading` module and its advantages over the `thread` module, with regard to
    the implementation of multithreaded programs in Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create and customize a new thread using the `threading` module, there are
    specific steps that need to be followed:'
  prefs: []
  type: TYPE_NORMAL
- en: Define a subclass of the `threading.Thread` class in your program
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Override the default `__init__(self [,args])` method inside of the subclass,
    in order to add custom arguments for the class
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Override the default `run(self [,args])` method inside of the subclass, in order
    to customize the behavior of the thread class when a new thread is initialized
    and started
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You actually saw an example of this in the first example of this chapter. As
    a refresher, the following is what we have to use to customize a `threading.Thread`
    subclass, in order to perform a five-step countdown, with a customizable delay
    between each step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In our next example, we will look at the problem of determining whether a specific
    number is a prime number. This time, we will be implementing a multithreaded Python
    program through the `threading` module. Navigate to the `Chapter03` folder and
    the `example3.py` file. Let''s first focus on the `MyThread` class, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Each instance of the `MyThread` class will have a parameter called `x`, specifying
    the prime number candidate to be processed. As you can see, when an instance of
    the class is initialized and started (that is, in the `run(self)` function), the
    `is_prime()` function, which is the same prime-checking function that we used
    in the previous example, on the `x` parameter, before that a message is also printed
    out by the `run()` function to specify the beginning of the processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our main program, we still have the same list of input for prime-checking.
    We will be going through each number in that list, spawning and running a new
    instance of the `MyThread` class with that number, and appending that `MyThread`
    instance to a separate list. This list of created threads is necessary because,
    after that, we will have to call the `join()` method on all of those threads,
    which ensures that all of the threads have finished executing successfully:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Notice that, unlike when we used the `thread` module, this time, we do not have
    to invent a workaround to make sure that all of the threads have finished executing
    successfully. Again, this is done by the `join()` method provided by the `threading`
    module. This is only one example of the many advantages of using the more powerful,
    higher-level API of the `threading` module, rather than using the `thread` module.
  prefs: []
  type: TYPE_NORMAL
- en: Synchronizing threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you saw in the previous examples, the `threading` module has many advantages
    over its predecessor, the `thread` module, in terms of functionality and high-level
    API calls. Even though some recommend that experienced Python developers know
    how to implement multithreaded applications using both of these modules, you will
    most likely be using the `threading` module to work with threads in Python. In
    this section, we will look at using the `threading` module in thread synchronization.
  prefs: []
  type: TYPE_NORMAL
- en: The concept of thread synchronization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we jump into an actual Python example, let's explore the concept of synchronization
    in computer science. As you saw in previous chapters, sometimes, it is undesirable
    to have all portions of a program execute in a parallel manner. In fact, in most
    contemporary concurrent programs, there are sequential portions and concurrent
    portions of the code; furthermore, even inside of a concurrent portion, some form
    of coordination between different threads/processes is also required.
  prefs: []
  type: TYPE_NORMAL
- en: '**Thread/process synchronization** is a concept in computer science that specifies
    various mechanisms to ensure that no more than one concurrent thread/process can
    process and execute a particular program portion at a time; this portion is known
    as the **critical section**, and we will discuss it in further detail when we
    consider common problems in concurrent programming in [Chapter 12](e8b97a27-3966-4a32-aae6-b8d995f4c662.xhtml),
    *Starvation,* and [Chapter 13](d87c597d-2130-4847-9ca9-e12021bc7a0c.xhtml), *Race
    Conditions*.'
  prefs: []
  type: TYPE_NORMAL
- en: In a given program, when a thread is accessing/executing the critical section
    of the program, the other threads have to wait until that thread finishes executing.
    The typical goal of thread synchronization is to avoid any potential data discrepancies
    when multiple threads access their shared resources; allowing only one thread
    to execute the critical section of the program at a time guarantees that no data
    conflicts occur in multithreaded applications.
  prefs: []
  type: TYPE_NORMAL
- en: The threading.Lock class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the most common ways to apply thread synchronization is through the
    implementation of a locking mechanism. In our `threading` module, the `threading.Lock`
    class provides a simple and intuitive approach to creating and working with locks.
    Its main usage includes the following methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`threading.Lock()`: This method initializes and returns a new lock object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`acquire(blocking)`: When this method is called, all of the threads will run
    synchronously (that is, only one thread can execute the critical section at a
    time):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The optional argument `blocking` allows us to specify whether the current thread
    should wait to acquire the lock
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When `blocking = 0`, the current thread does not wait for the lock and simply
    returns `0` if the lock cannot be acquired by the thread, or `1` otherwise
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When `blocking = 1`, the current thread blocks and waits for the lock to be
    released and acquires it afterwards
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`release()`: When this method is called, the lock is released.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An example in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s consider a specific example. In this example, we will be looking at
    the `Chapter03/example4.py` file. We will go back to the thread example of counting
    down from five to one, which we looked at at the beginning of this chapter; take
    a moment to look back if you do not remember the problem. In this example, we
    will be tweaking the `MyThread` class, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: As opposed to the first example of this chapter, in this example, the `MyThread`
    class utilizes a lock object (whose variable is named `thread_lock`) inside of
    its `run()` function. Specifically, the lock object is acquired right before the
    `thread_count_down()` function is called (that is, when the countdown begins),
    and the lock object is released right after its ends. Theoretically, this specification
    will alter the behavior of the threads that we saw in the first example; instead
    of executing the countdown simultaneously, the program will now execute the threads
    separately, and the countdowns will take place one after the other.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we will initialize the `thread_lock` variable as well as run two separate
    instances of the `MyThread` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Multithreaded priority queue
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A computer science concept that is widely used in both non-concurrent and concurrent
    programming is queuing. A **queue** is an abstract data structure that is a collection
    of different elements maintained in a specific order; these elements can be the
    other objects in a program.
  prefs: []
  type: TYPE_NORMAL
- en: A connection between real-life and programmatic queues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Queues are an intuitive concept that can easily be related to our everyday
    life, such as when you stand in line to board a plane at the airport. In an actual
    line of people, you will see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: People typically enter at one end of the line and exit from the other end
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If person A enters the line before person B, person A will also leave the line
    before person B (unless person B has more priority)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once everyone has boarded the plane, there will be no one left in the line.
    In other words, the line will be empty
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In computer science, a queue works in a considerably similar way:'
  prefs: []
  type: TYPE_NORMAL
- en: Elements can be added to the end of the queue; this task is called **enqueue**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elements can also be removed from the beginning of the queue; this task is called
    **dequeue**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a **First In First Out** (**FIFO**) queue, the elements that are added first
    will be removed first (hence, the name FIFO). This is contrary to another common
    data structure in computer science, called **stack**, in which the last element
    that is added will be removed first. This is known as **L****ast In First Out**
    (**LIFO**).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If all of the elements inside of a queue have been removed, the queue will
    be empty and there will be no way to remove further elements from the queue. Similarly,
    if a queue is at the maximum capacity of the number of elements it can hold, there
    is no way to add any other elements to the queue:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](assets/3b3674f3-7f65-4736-83b2-66d87b5ce324.png)'
  prefs: []
  type: TYPE_IMG
- en: A visualization of the queue data structure
  prefs: []
  type: TYPE_NORMAL
- en: The queue module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `queue` module in Python provides a simple implementation of the queue
    data structure. Each queue in the `queue.Queue` class can hold a specific amount
    of element, and can have the following methods as its high-level API:'
  prefs: []
  type: TYPE_NORMAL
- en: '`get()`: This method returns the next element of the calling `queue` object
    and removes it from the `queue` object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`put()`: This method adds a new element to the calling `queue` object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`qsize()`: This method returns the number of current elements in the calling
    `queue` object (that is, its size)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`empty()`: This method returns a Boolean, indicating whether the calling `queue`
    object is empty'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`full()`: This method returns a Boolean, indicating whether the calling `queue`
    object is full'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Queuing in concurrent programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The concept of a queue is even more prevalent in the sub-field of concurrent
    programming, especially when we need to implement a fixed number of threads in
    our program to interact with a varying number of shared resources.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous examples, we have learned to assign a specific task to a new
    thread. This means that the number of tasks that need to be processed will dictate
    the number of threads our program should spawn. (For example, in our `Chapter03/example3.py`
    file, we had five numbers as our input and we therefore created five threads—each
    took one input number and processed it.)
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes it is undesirable to have as many threads as the tasks we have to
    process. Say we have a large number of tasks to be processed, then it will be
    quite inefficient to spawn the same large number of threads and have each thread
    execute only one task. It could be more beneficial to have a fixed number of threads
    (commonly known as a thread pool) that would work through the tasks in a cooperative
    manner.
  prefs: []
  type: TYPE_NORMAL
- en: Here is when the concept of a queue comes in. We can design a structure in which
    the pool of threads will not hold any information regarding the tasks they should
    each execute, instead the tasks are stored in a queue (in other words task queue),
    and the items in the queue will be fed to individual members of the thread pool.
    As a given task is completed by a member of the thread pool, if the task queue
    still contains elements to be processed, then the next element in the queue will
    be sent to the thread that just became available.
  prefs: []
  type: TYPE_NORMAL
- en: 'This diagram further illustrates this setup:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ff384e15-a7ed-4bf2-9342-bcad86b687c3.png)'
  prefs: []
  type: TYPE_IMG
- en: Queuing in threading
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider a quick example in Python, in order to illustrate this point. Navigate
    to the `Chapter03/example5.py` file. In this example, we will be considering the
    problem of printing out all of the positive factors of an element in a given list
    of positive integers. We are still looking at the previous `MyThread` class, but
    with some adjustments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'There is a lot going on, so let''s break the program down into smaller pieces.
    First, let''s look at our key function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This function takes in an argument, `x` then iterates through all positive numbers
    between `1` and itself, to check whether a number is a factor of `x`. It finally
    prints out a formatted message that contains all of the information that it cumulates
    through the loop.
  prefs: []
  type: TYPE_NORMAL
- en: In our new `MyThread` class, when a new instance is initialized and started,
    the `process_queue()` function will be called. This function will first attempt
    to obtain the next element of the queue object that the `my_queue` variable holds
    in a non-blocking manner by calling the `get(block=False)` method. If a `queue.Empty`
    exception occurs (which indicates that the queue currently holds no value), then
    we will end the execution of the function. Otherwise we simply pass that element
    we just obtained to the `print_factors()` function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The `my_queue` variable is defined in our main function as a `Queue` object
    from the `queue` module that contains the elements in the `input_` list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'For the rest of the main program, we simply initiate and run three separate
    threads until all of them finish their respective execution. Here we choose to
    create only three threads to simulate the design that we discussed earlier—a fixed
    number of threads processing a queue of input whose number of elements can change
    independently:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the program and you will see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, we have implemented the structure that we discussed earlier:
    a task queue that holds all the tasks to be executed and a thread pool (threads
    A, B, and C) that interacts with the queue to process its elements individually.'
  prefs: []
  type: TYPE_NORMAL
- en: Multithreaded priority queue
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The elements in a queue are processed in the order that they were added to the
    queue; in other words, the first element that is added leaves the queue first
    (FIFO). Even though this abstract data structure simulates real life in many situations,
    depending on the application and its purposes, sometimes, we need to redefine/change
    the order of the elements dynamically. This is where the concept of priority queuing
    comes in handy.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **priority queue** abstract data structure is similar to the queue (and
    even the aforementioned stack) data structure, but each of the elements in a priority
    queue, as the name suggests, has a priority associated with it; in other words,
    when an element is added to a priority queue, its priority needs to be specified.
    Unlike in regular queues, the dequeuing principle of a priority queue relies on
    the priority of the elements: the elements with higher priorities are processed
    before those with lower priorities.'
  prefs: []
  type: TYPE_NORMAL
- en: The concept of a priority queue is used in a variety of different applications—namely,
    bandwidth management, Dijkstra's algorithm, best-first search algorithms, and
    so on. Each of these applications typically uses a definite scoring system/function
    to determine the priority of its elements. For example, in bandwidth management,
    prioritized traffic, such as real-time streaming, is processed with the least
    delay and the least likelihood of being rejected. In best-search algorithms that
    are used to find the shortest path between two given nodes of a graph, a priority
    queue is implemented to keep track of unexplored routes; the routes with shorter
    estimated path lengths are given higher priorities in the queue.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A thread of execution is the smallest unit of programming commands. In computer
    science, multithreaded applications allow for multiple threads to exist within
    the same process simultaneously, in order to implement concurrency and parallelism.
    Multithreading provides a variety of advantages, in execution time, responsiveness,
    and the efficiency of resource consumption.
  prefs: []
  type: TYPE_NORMAL
- en: The `threading` module in Python 3, which is commonly considered superior to
    the old `thread` module, provides an efficient, powerful, and high-level API to
    work with threads while implementing multithreaded applications in Python, including
    options to spawn new threads dynamically and synchronize threads through different
    locking mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: Queuing and priority queuing are important data structures in the field of computer
    science, and they are essential concepts in concurrent and parallel programming.
    They allow for multithreaded applications to efficiently execute and complete
    their threads in an accurate manner, ensuring that the shared resources are processed
    in a specific and dynamic order.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss a more advanced function of Python, the
    `with` statement, and how it complements the use of multithreaded programming
    in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is a thread? What are the core differences between a thread and a process?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the API options provided by the `thread` module in Python?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the API options provided by the `threading` module in Python?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the processes of creating new threads via the `thread` and `threading`
    modules?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the idea behind thread synchronization using locks?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the process of implementing thread synchronization using locks in Python?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the idea behind the queue data structure?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the main application of queuing in concurrent programming?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the core differences between a regular queue and a priority queue?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information you can refer to the following links:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Python Parallel Programming Cookbook*, Giancarlo Zaccone, Packt Publishing
    Ltd, 2015'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '"Learning Concurrency in Python: Build highly efficient, robust, and concurrent
    applications", Elliot Forbes (2017)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Real-time concepts for embedded systems*, Qing Li and Caroline Yao, CRC Press,
    2003'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
