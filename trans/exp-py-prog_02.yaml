- en: Chapter 2. Syntax Best Practices – below the Class Level
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The ability to write an efficient syntax comes naturally with time. If you take
    a look back at your first program, you will probably agree with this. The right
    syntax will appear to your eyes as a good-looking piece of code, and the wrong
    syntax as something disturbing.
  prefs: []
  type: TYPE_NORMAL
- en: Besides the algorithms that are implemented and the architectural design for
    your program, taking great care over how it is written weighs heavily on how it
    will evolve. Many programs are ditched and rewritten from scratch because of their
    obtuse syntax, unclear APIs, or unconventional standards.
  prefs: []
  type: TYPE_NORMAL
- en: But Python has evolved a lot in the last few years. So, if you were kidnapped
    for a while by your neighbor (a jealous guy from the local Ruby developers user
    group) and kept away from the news, you will probably be astonished by its new
    features. From the earliest version to the current one (3.5 at this time), a lot
    of enhancements have been made to make the language clearer, cleaner, and easier
    to write. Python basics have not changed drastically, but the tools to play with
    them are now a lot more ergonomic.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter presents the most important elements of modern syntax and tips
    on their usage:'
  prefs: []
  type: TYPE_NORMAL
- en: List comprehensions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Iterators and generators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Descriptors and properties
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decorators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`with` and `contextlib`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code performance tips for speed improvement or memory usage are covered
    in [Chapter 11](ch11.html "Chapter 11. Optimization – General Principles and Profiling
    Techniques"), *Optimization – General Principles and Profiling Techniques*, and
    [Chapter 12](ch12.html "Chapter 12. Optimization – Some Powerful Techniques"),
    *Optimization – Some Powerful Techniques*.
  prefs: []
  type: TYPE_NORMAL
- en: Python's built-in types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python provides a great set of datatypes. This is true for both numeric types
    and also collections. Regarding the numeric types, there is nothing special about
    their syntax. There are, of course, some differences for defining literals of
    every type and some (maybe) not well-known details regarding operators, but there
    aren't a lot of choices left for developers. Things change when it comes to collections
    and strings. Despite the "there should be only one way to do something" mantra,
    the Python developer is really left with plenty of choices. Some of the code patterns
    that seem intuitive and simple to beginners are often considered non-*Pythonic*
    by experienced programmers because they are either inefficient or simply too verbose.
  prefs: []
  type: TYPE_NORMAL
- en: Such *Pythonic* patterns for solving common problems (by many programmers called
    idioms) may often seem like only aesthetics. This cannot be more wrong. Most of
    the idioms are driven by the fact how Python is implemented internally and on
    how built-in structures and modules work. Knowing more of such details is essential
    for a good understanding of the language. Also, the community itself is not free
    from myths and stereotypes about how things in Python work. Only by digging deeper
    yourself, will you be able to tell which of the popular statements about Python
    are really true.
  prefs: []
  type: TYPE_NORMAL
- en: Strings and bytes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The topic of strings may provide some confusion for programmers that are used
    to programming only in Python 2\. In Python 3, there is only one datatype capable
    of storing textual information. It is `str` or, simply, string. It is an immutable
    sequence that stores Unicode code points. This is the major difference from Python
    2, where `str` represents byte strings—something that is now handled by the `bytes`
    objects (but not exactly in the same way).
  prefs: []
  type: TYPE_NORMAL
- en: Strings in Python are sequences. This single fact should be enough to include
    them in the section covering other container types, but they differ from other
    container types in one important detail. Strings have very specific limitations
    on what type of data they can store, and that is Unicode text.
  prefs: []
  type: TYPE_NORMAL
- en: '`bytes` and its mutable alternative (`bytearray`) differs from `str` by allowing
    only bytes as a sequence value—integers in the range `0 <= x < 256`. This may
    be confusing at the beginning, since when printed, they may look very similar
    to strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The true nature of `bytes` and `bytearray` is revealed when it is converted
    to another sequence type like `list` or `tuple`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'A lot of Python 3 controversy was about breaking the backwards compatibility
    for string literals and how Unicode is dealt with. Starting from Python 3.0, every
    un-prefixed string literal is Unicode. So, literals enclosed by single quotes
    (`''`), double quotes (`"`), or groups of three quotes (single or double) without
    any prefix represent the `str` datatype:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In Python 2, the Unicode literals required the `u` prefix (like `u"some string"`).
    This prefix is still allowed for backward compatibility (starting from Python
    3.3), but does not hold any syntactic meaning in Python 3.
  prefs: []
  type: TYPE_NORMAL
- en: 'Bytes literals were already presented in some of the previous examples, but
    let''s explicitly present its syntax for the sake of consistency. Bytes literals
    are also enclosed by single quotes, double quotes, or triple quotes, but must
    be preceded by a `b` or `B` prefix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Note that there is no `bytearray` literals in the Python syntax.
  prefs: []
  type: TYPE_NORMAL
- en: 'Last but not least, Unicode strings contain "abstract" text that is independent
    from the byte representation. This makes them unable to be saved on the disk or
    sent over the network without encoding to binary data. There are two ways to encode
    string objects into byte sequences:'
  prefs: []
  type: TYPE_NORMAL
- en: Using the `str.encode(encoding, errors)` method, which encodes the string using
    a registered codec for encoding. Codec is specified using the `encoding` argument,
    and, by default, it is `'utf-8'`. The second errors argument specifies the error
    handling scheme. It can be `'strict'` (default), `'ignore'`, `'replace'`, `'xmlcharrefreplace'`,
    or any other registered handler (refer to the built-in `codecs` module documentation).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the `bytes(source, encoding, errors)` constructor, which creates a new
    bytes sequence. When the source is of the `str` type, then the `encoding` argument
    is obligatory and it does not have a default value. The usage of the `encoding`
    and `errors` arguments is the same as for the `str.encode()` method.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Binary data represented by `bytes` can be converted to a string in the analogous
    ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Using the `bytes.decode(encoding, errors)` method, which decodes the bytes using
    the codec registered for encoding. The arguments of this method have the same
    meaning and defaults as the arguments of `str.encode()`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the `str(source, encoding, error)` constructor, which creates a new string
    instance. Similar to the `bytes()` constructor, the `encoding` argument in the
    `str()` call has no default value and must be provided if the bytes sequence is
    used as a source.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Naming – bytes versus byte string**'
  prefs: []
  type: TYPE_NORMAL
- en: Due to changes made in Python 3, some people tend to refer to the `bytes` instances
    as byte strings. This is mostly due to historic reasons—`bytes` in Python 3 is
    the sequence type that is the closest one to the `str` type from Python 2 (but
    not the same). Still, the `bytes` instance is a sequence of bytes and also does
    not need to represent textual data. So, in order to avoid any confusion, it is
    advisable to always refer to them as either `bytes` or a byte sequence despite
    their similarities to strings. The concept of strings is reserved for textual
    data in Python 3 and this is now always `str`.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation details
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Python strings are immutable. This is also true to byte sequences. This is an
    important fact because it has both advantages and disadvantages. It also affects
    the way strings should be handled in Python efficiently. Thanks to immutability,
    strings can be used as dictionary keys or `set` collection elements because once
    initialized, they will never change their value. On the other hand, whenever a
    modified string is required (even with only tiny modification), a completely new
    instance needs to be created. Fortunately, `bytearray` as a mutable version of
    `bytes` does not introduce such an issue. Byte arrays can be modified in-place
    (without the need of new object creation) through item assignments and can be
    dynamically resized exactly like lists—using appends, pops, inserts, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: String concatenation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Knowing the fact that Python strings are immutable imposes some problems when
    multiple string instances need to be joined together. As stated before, concatenating
    any immutable sequences result in the creation of a new sequence object. Consider
    that a new string is built by the repeated concatenation of multiple strings,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in a quadratic runtime cost in the total string length. In
    other words, it is highly inefficient. For handling such situations, there is
    the `str.join()` method available. It accepts iterable of strings as the argument
    and returns a joined string. Because it is the method, the actual idiom uses the
    empty string literal as a source of method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The string providing this method will be used as a separator between joined
    substrings; consider the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'It is worth remembering that just because it is faster (especially for large
    lists), it does not mean that the `join()` method should be used in every situation
    where two strings need to be concatenated. Despite being a widely recognized idiom,
    it does not improve code readability – and readability counts! There are also
    some situations where `join()` may not perform as well as ordinary concatenation
    through addition. Here some examples of them:'
  prefs: []
  type: TYPE_NORMAL
- en: If the number of substrings is small and they are not contained already by some
    iterable—in some cases, an overhead of creating a new sequence just to perform
    concatenation can overshadow the gain of using `join()`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When concatenating short literals, thanks to constant folding in CPython, some
    complex literals (not only strings) such as `'a' + 'b' + 'c'` to `'abc'` can be
    translated to a shorter form at compile time. Of course, this is enabled only
    for constants (literals) that are relatively short.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ultimately, the best readability of string concatenation if the number of strings
    is known beforehand is ensured by proper string formatting, by either using the
    `str.format()` method or the `%` operator. In code sections where the performance
    is not critical or gain from optimizing string concatenation is very little, string
    formatting is recommended as the best alternative.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Constant folding and peephole optimizer**'
  prefs: []
  type: TYPE_NORMAL
- en: CPython uses the peephole optimizer on compiled source code in order to improve
    performance. This optimizer implements a number of common optimizations directly
    on Python's byte code. As mentioned, constant folding is one such feature. The
    resulting constants are limited in length by a hardcoded value. In Python 3.5,
    it is still invariably equal to 20\. Anyway, this particular detail is rather
    a curiosity than a thing that can be relied on in day-to-day programming. Information
    of other interesting optimizations performed by peephole optimizer can be found
    in the `Python/peephole.c` file of Python's source code.
  prefs: []
  type: TYPE_NORMAL
- en: Collections
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Python provides a good selection of built-in data collections that allows you
    to efficiently solve many problems if you choose wisely. Types that you probably
    already know are those that have dedicated literals:'
  prefs: []
  type: TYPE_NORMAL
- en: Lists
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tuples
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dictionaries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python is of course not limited to these four and it extends the list of possible
    choices through its standard library. In many cases, the solution to a problem
    may be as simple as making a good choice for data structure. This part of the
    book aims to ease such a decision by providing deeper insight into the possible
    options.
  prefs: []
  type: TYPE_NORMAL
- en: Lists and tuples
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The two most basic collection types in Python are lists and tuples, and they
    both represent sequences of objects. The basic difference between them should
    be obvious for anyone who has spent more than a few hours with Python—lists are
    dynamic so can change their size, while tuples are immutable (they cannot be modified
    after they are created).
  prefs: []
  type: TYPE_NORMAL
- en: Tuples, despite having many various optimizations that makes allocation/deallocation
    of small objects fast, are the recommended datatype for structures where the position
    of the element is information by itself. For example, tuple may be a good choice
    for storing a pair of (x, y) coordinates. Anyway, details regarding tuples are
    rather uninteresting. The only important thing about them in the scope of this
    chapter is that `tuple` is **immutable** and thus **hashable**. What this means
    will be covered later in a *Dictionaries* section. More interesting than tuple
    is its dynamic counterpart, `list`, how it really works, and how to deal with
    it efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation details
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Many programmers easily confuse Python's `list` type with the concept of linked
    lists found often in standard libraries of other languages such as C, C++, or
    Java. In fact, CPython lists are not lists at all. In CPython, lists are implemented
    as variable length arrays. This should also be true for other implementations
    such as Jython and IronPython, although such implementation details are often
    not documented in these projects. The reasons for such confusion are clear. This
    datatype is named **list** and also has an interface that could be expected from
    any linked list implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Why is it important and what does it mean? Lists are one of the most popular
    data structures and the way they are used greatly affects every application's
    performance. Also, CPython is the most popular and used implementation, so knowing
    its internal implementation details is crucial.
  prefs: []
  type: TYPE_NORMAL
- en: 'In detail, lists in Python is a contiguous array of references to other objects.
    The pointer to this array and the length is stored in a lists head structure.
    This means that every time an item is added or removed, the array of references
    needs to be resized (reallocated). Fortunately, in Python, these arrays are created
    with exponential over-allocation, so not every operation requires a resize. This
    is how the amortized cost of appending and popping elements can be low in terms
    of complexity. Unfortunately, some other operations that are considered "cheap"
    in ordinary linked lists have relatively high computational complexity in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: Inserting an item at arbitrary place using the `list.insert` method—complexity
    O(n)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deleting an item using `list.delete` or using `del`—complexity O(n)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here, *n* is the length of a list. At least retrieving or setting an element
    using index is an operation that cost is independent of the list''s size. Here
    is a full table of average time complexities for most of the list operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Operation | Complexity |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Copy | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Append | O(1) |'
  prefs: []
  type: TYPE_TB
- en: '| Insert | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Get item | O(1) |'
  prefs: []
  type: TYPE_TB
- en: '| Delete item | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Iteration | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Get slice of length *k* | O(k) |'
  prefs: []
  type: TYPE_TB
- en: '| Del slice | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Set slice of length *k* | O(k+n) |'
  prefs: []
  type: TYPE_TB
- en: '| Extend | O(k) |'
  prefs: []
  type: TYPE_TB
- en: '| Multiply by *k* | O(nk) |'
  prefs: []
  type: TYPE_TB
- en: '| Test existence (`element in list`) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| `min()`/`max()` | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Get length | O(1) |'
  prefs: []
  type: TYPE_TB
- en: For situations where a real linked list is needed (or simply, a data structure
    that has `appends` and `pop` at each side at O(1) complexity), Python provides
    `deque` in `collections` built-in module. This is a generalization of stacks and
    queues and should work fine anywhere where a doubly linked list is required.
  prefs: []
  type: TYPE_NORMAL
- en: List comprehensions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As you probably know, writing a piece of code such as this is painful:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This may work for C, but it actually makes things slower for Python because:'
  prefs: []
  type: TYPE_NORMAL
- en: It makes the interpreter work on each loop to determine what part of the sequence
    has to be changed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It makes you keep a counter to track what element has to be treated
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It requires an additional function lookup to be performed at every iteration
    because `append()` is a list's method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A list comprehension is the correct answer to this pattern. It uses wired features
    that automate parts of the previous syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Besides the fact that this writing is more efficient, it is way shorter and
    involves fewer elements. In a bigger program, this means fewer bugs and code that
    is easier to read and understand.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**List comprehensions and internal array resize**'
  prefs: []
  type: TYPE_NORMAL
- en: There is a myth among some Python programmers that the list comprehensions can
    be a workaround for the fact that the internal array representing the list object
    must be resized with every few additions. Some say that the array will be allocated
    once in just the right size. Unfortunately, this isn't true.
  prefs: []
  type: TYPE_NORMAL
- en: The interpreter during evaluation of the comprehension can't know how big the
    resulting container will be and it can't preallocate the final size of the array
    for it. Due to this, the internal array is reallocated in the same pattern as
    it would be in the `for` loop. Still, in many cases, list creation using comprehensions
    is both cleaner and faster than using ordinary loops.
  prefs: []
  type: TYPE_NORMAL
- en: Other idioms
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Another typical example of a Python idiom is the usage of `enumerate`. This
    built-in function provides a convenient way to get an index when a sequence is
    used in a loop. Consider the following piece of code as an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This can be replaced by the following code, which is shorter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'When the elements of multiple lists (or any iterables) need to be aggregated
    in a one-by-one fashion, then the built-in `zip()` function may be used. This
    is a very common pattern for uniform iteration over two same-sized iterables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the results of `zip()` can be reversed by another `zip()` call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Another popular syntax element is sequence unpacking. It is not limited to
    lists and tuples and will work with any sequence type (even strings and byte sequences).
    It allows you to unpack a sequence of elements into another set of variables as
    long as there are as many variables on the left-hand side of the assignment operator
    as the number of elements in the sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Unpacking also allows you to capture multiple elements in a single variable
    using starred expressions as long as it can be interpreted unambiguously. Unpacking
    can also be performed on nested sequences. This can come in handy especially when
    iterating on some complex data structures built of sequences. Here are some examples
    of more complex unpacking:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Dictionaries
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Dictionaries are one of the most versatile data structures in Python. `dict`
    allows to map a set of unique keys to values as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Dictionary literals are a very basic thing and you should already know them.
    Anyway, Python allows programmers to also create a new dictionary using comprehensions
    similar to the list comprehensions mentioned earlier. Here is a very simple example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: What is important is that the same benefits of using list comprehensions apply
    to dictionary comprehensions. So, in many cases, they are more efficient, shorter,
    and cleaner. For more complex code, when many `if` statements or function calls
    are required to create a dictionary, the simple `for` loop may be a better choice,
    especially if it improves the readability.
  prefs: []
  type: TYPE_NORMAL
- en: 'For Python programmers new to Python 3, there is one important note about iterating
    over dictionary elements. The dictionary methods: `keys()`, `values()`, and `items()`
    no longer have lists as their return value types. Also, their counterparts `iterkeys()`,
    `itervalues()`, and `iteritems()` that returned iterators instead are missing
    in Python 3\. Instead, what `keys()`, `values()`, and `items()` return now are
    view objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '`keys()`: This returns the `dict_keys` object that provides a view on all the
    keys of a dictionary'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`values()`: This returns the `dict_values` object that provides views on all
    the values of a dictionary'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`items()`: This returns the `dict_items` object providing views on all `(key,
    value)` two tuples of a dictionary'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'View objects provide a view on the dictionary content in a dynamic way, so
    every time the dictionary changes, the views will reflect these changes, as shown
    in this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: View objects join the behavior of lists returned by implementation of old methods
    with iterators returned by their "iter" counterparts. Views do not need to redundantly
    store all values in memory (like lists do), but still allow getting their length
    (using `len`) and testing membership (using the `in` clause). Views are, of course,
    iterable.
  prefs: []
  type: TYPE_NORMAL
- en: The last important thing is that both views returned by the `keys()` and `values()`
    methods ensure the same order of keys and values. In Python 2, you could not modify
    the dictionary content between these two calls if you wanted to ensure the same
    order of retrieved keys and values. `dict_keys` and `dict_values` are now dynamic
    so even if the content of a dictionary will change between `keys()` and `values()`
    calls, the order of iteration is consistent between these two views.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation details
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: CPython uses hash tables with pseudo-random probing as an underlying data structure
    for dictionaries. It seems like a very deep implementation detail, but it is very
    unlikely to change in the near future, so it is also a very interesting fact for
    the programmer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Due to this implementation detail, only objects that are **hashable** can be
    used as a dictionary key. An object is hashable if it has a hash value that never
    changes during its lifetime and can be compared to different objects. Every Python''s
    built-in type that is immutable is also hashable. Mutable types such as list,
    dictionaries, and sets are not hashable and so they cannot be used as dictionary
    keys. Protocol that defines if a type is hashable consists of two methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`__hash__`: This provides the hash value (as an integer) that is needed by
    the internal `dict` implementation. For objects that are instances of user-defined
    classes, it is derived from their `id()`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`__eq__`: This compares if two objects that have the same value. All objects
    that are instances of user-defined classes compare unequal, by default, except
    for themselves.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Two objects that are compared equal must have the same hash value. The reverse
    does not need to be true. This means collisions of hashes are possible—two objects
    with the same hash may not be equal. It is allowed, and every Python implementation
    must be able to resolve hash collisions. CPython uses **open addressing** to resolve
    such collisions ([https://en.wikipedia.org/wiki/Open_addressing](https://en.wikipedia.org/wiki/Open_addressing)).
    Still, the probability of collisions greatly affects performance, and if it is
    high, the dictionary will not benefit from its internal optimizations.
  prefs: []
  type: TYPE_NORMAL
- en: 'While three basic operations: adding, getting, and deleting an item have an
    average time complexity equal to O(1), their amortized worst case complexities
    are a lot higher—O(n), where *n* is the current dictionary size. Additionally,
    if user-defined class objects are used as dictionary keys and they are hashed
    improperly (with a high risk of collisions), then this will have a huge negative
    impact on the dictionary performance. The full table of CPyhton''s time complexities
    for dictionaries is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Operation | Average complexity | Amortized worst case complexity |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Get item | O(1) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Set item | O(1) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Delete item | O(1) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Copy | O(n) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Iteration | O(n) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: It is also important to know that the *n* number in worst-case complexities
    for copying and iterating the dictionary is the maximum size that the dictionary
    ever achieved, rather than the current item count. In other words, iterating over
    the dictionary that once was huge but has greatly shrunk in time may take a surprisingly
    long time. So, in some cases, it may be better to create a new dictionary object
    if it has to be iterated often instead of just removing elements from the previous
    one.
  prefs: []
  type: TYPE_NORMAL
- en: Weaknesses and alternatives
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'One of the common pitfalls of using dictionaries is that they do not preserve
    the order of elements in which new keys were added. In some scenarios, when dictionary
    keys use consecutive keys whose hashes are also consecutive values (for example,
    using integers), the resulting order might be the same due to the internal implementation
    of dictionaries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Still, using other datatypes which hash differently shows that the order is
    not preserved. Here is an example in CPython:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: As shown in the preceding code, the resulting order is both dependent on the
    hashing of the object and also on the order in which the elements were added.
    This is not what can be relied on because it can vary with different Python implementations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Still, in some cases, the developer might need dictionaries that preserve the
    order of additions. Fortunately, the Python standard library provides an ordered
    dictionary called `OrderedDict` in the `collections` module. It optionally accepts
    an iterable as the initialization argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: It also has some additional features such as popping items from both ends using
    the `popitem()` method or moving the specified element to one of the ends using
    the `move_to_end()` method. A full reference on that collection is available in
    the Python documentation (refer to [https://docs.python.org/3/library/collections.html](https://docs.python.org/3/library/collections.html)).
  prefs: []
  type: TYPE_NORMAL
- en: The other important note is that in very old code bases, `dict` may be used
    as a primitive set implementation that ensures the uniqueness of elements. While
    this will give proper results, this should be omitted unless Python versions lower
    than 2.3 are targeted. Using dictionaries this way is wasteful in terms of resources.
    Python has a built-in `set` type that serves this purpose. In fact, it has a very
    similar internal implementation to dictionaries in CPython, but offers some additional
    features as well as specific set-related optimizations.
  prefs: []
  type: TYPE_NORMAL
- en: Sets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Sets are a very robust data structure that are useful mostly in situations
    where the order of elements is not as important as their uniqueness and efficiency
    of testing if an element is contained by a collection. They are very similar to
    analogous mathematic concepts. Sets are provided as built-in types in two flavors:'
  prefs: []
  type: TYPE_NORMAL
- en: '`set()`: This is a mutable, non-ordered, finite collection of unique, immutable
    (hashable) objects'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`frozenset()`: This is an immutable, hashable, non-ordered collection of unique,
    immutable (hashable) objects'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The immutability of `frozenset()` makes it possible to be used as dictionary
    keys and also other `set()` and `frozenset()` elements. A plain mutable `set()`
    cannot be used within another set or frozenset content as this will raise `TypeError`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The following set initializations are completely correct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Mutable sets can be created in three ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Using a `set()` call that accepts optional iterable as the initialization argument,
    such as `set([0, 1, 2])`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a set comprehension such as `{element for element in range(3)}`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using set literals such as `{1, 2, 3}`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that using literals and comprehensions for sets requires extra caution
    because they are very similar in form to dictionary literals and comprehensions.
    Also, there is no literal for empty set objects—empty curly brackets `{}` are
    reserved for empty dictionary literals.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation details
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Sets in CPython are very similar to dictionaries. As a matter of fact, they
    are implemented like dictionaries with dummy values, where only keys are actual
    collection elements. Also, sets exploit this lack of values in mapping for additional
    optimizations.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to this, sets allow very fast additions, deletions, and checking for
    element existence with the average time complexity equal to O(1). Still, since
    the implementation of sets in CPython relies on a similar hash table structure,
    the worst-case complexity for these operations is O(n), where *n* is the current
    size of a set.
  prefs: []
  type: TYPE_NORMAL
- en: Other implementation details also apply. The item to be included in a set must
    be hashable, and if instances of user-defined classes in a set are hashed poorly,
    this will have a negative impact on the performance.
  prefs: []
  type: TYPE_NORMAL
- en: Beyond basic collections – the collections module
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Every data structure has its shortcomings. There is no single collection that
    can suit every problem and four basic types of them (tuple, list, set, and dictionary)
    is still not a wide range of choices. These are the most basic and important collections
    that have a dedicated literal syntax. Fortunately, Python provides a lot more
    options in its standard library through the `collections` built-in module. One
    of them was already mentioned (`deque`). Here are the most important collections
    provided by this module:'
  prefs: []
  type: TYPE_NORMAL
- en: '`namedtuple()`: This is a factory function for creating tuple subclasses whose
    indexes can be accessed as named attributes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`deque`: This is a double-ended queue, list-like generalization of stacks and
    queues with fast appends and pops on both ends'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ChainMap`: This is a dictionary-like class to create a single view of multiple
    mappings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Counter`: This is a dictionary subclass for counting hashable objects'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OrderedDict`: This is a dictionary subclass that preserves the order the entries
    were added in'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`defaultdict`: This is a dictionary subclass that can supply missing values
    with a provided default'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: More details on selected collections from the collections module and some advice
    on where it is worth using them are provided in [Chapter 12](ch12.html "Chapter 12. Optimization
    – Some Powerful Techniques"), *Optimization – Some Powerful Techniques*.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced syntax
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is hard to objectively tell which element of language syntax is advanced.
    For the purpose of this chapter on advanced syntax elements, we will consider
    the elements that do not directly relate to any specific built-in datatypes and
    which are relatively hard to grasp at the beginning. The most common Python features
    that may be hard to understand are:'
  prefs: []
  type: TYPE_NORMAL
- en: Iterators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decorators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Context managers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Iterators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An **iterator** is nothing more than a container object that implements the
    iterator protocol. It is based on two methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`__next__`: This returns the next item of the container'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`__iter__`: This returns the iterator itself'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Iterators can be created from a sequence using the `iter` built-in function.
    Consider the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'When the sequence is exhausted, a `StopIteration` exception is raised. It makes
    iterators compatible with loops since they catch this exception to stop cycling.
    To create a custom iterator, a class with a `__next__` method can be written,
    as long as it provides the special method `__iter__` that returns an instance
    of the iterator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is example usage of such iterator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Iterators themselves are a low-level feature and concept, and a program can
    live without them. But they provide the base for a much more interesting feature,
    generators.
  prefs: []
  type: TYPE_NORMAL
- en: The yield statement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Generators provide an elegant way to write simple and efficient code for functions
    that return a sequence of elements. Based on the `yield` statement, they allow
    you to pause a function and return an intermediate result. The function saves
    its execution context and can be resumed later, if necessary.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, the Fibonacci series can be written with an iterator (this is
    the example provided in the PEP about iterators):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'You can retrieve new values from generators as if it were iterators, so using
    `next()` function or `for` loops:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: This function returns a `generator` object, a special iterator, which knows
    how to save the execution context. It can be called indefinitely, yielding the
    next element of the suite each time. The syntax is concise, and the infinite nature
    of the algorithm does not disturb the readability of the code anymore. It does
    not have to provide a way to make the function stoppable. In fact, it looks similar
    to how the series would be designed in pseudocode.
  prefs: []
  type: TYPE_NORMAL
- en: In the community, generators are not used so often because the developers are
    not used to thinking this way. The developers have been used to working with straight
    functions for years. Generators should be considered every time you deal with
    a function that returns a sequence or works in a loop. Returning the elements
    one at a time can improve the overall performance, when they are passed to another
    function for further work.
  prefs: []
  type: TYPE_NORMAL
- en: In that case, the resources used to work out one element are most of the time
    less important than the resources used for the whole process. Therefore, they
    can be kept low, making the program more efficient. For instance, the Fibonacci
    sequence is infinite, and yet the generator that generates it does not require
    an infinite amount of memory to provide the values one at a time. A common use
    case is to stream data buffers with generators. They can be paused, resumed, and
    stopped by third-party code that plays over the data, and all the data does not
    need to be loaded before starting the process.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `tokenize` module from the standard library, for instance, generates tokens
    out of a stream of text and returns an `iterator` for each treated line that can
    be passed along to some processing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see that `open` iterates over the lines of the file and `generate_tokens`
    iterates over them in a pipeline, doing additional work. Generators can also help
    in breaking the complexity and raising the efficiency of some data transformation
    algorithms that are based on several suites. Thinking of each suite as an `iterator`,
    and then combining them into a high-level function is a great way to avoid a big,
    ugly, and unreadable function. Moreover, this can provide a live feedback to the
    whole processing chain.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, each function defines a transformation over a sequence.
    They are then chained and applied. Each function call processes one element and
    returns its result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the possible result of using these generators together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Keep the code simple, not the data**'
  prefs: []
  type: TYPE_NORMAL
- en: It is better to have a lot of simple iterable functions that work over sequences
    of values than a complex function that computes the result for entire collection
    at once.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another important feature available in Python regarding `generators` is the
    ability to interact with the code called with the `next` function. `yield` becomes
    an expression, and a value can be passed along with a new method called `send`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is an example session with our `psychologist()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '`send` acts like `next`, but makes `yield` return the value passed to it inside
    of the function definition. The function can, therefore, change its behavior depending
    on the client code. Two other functions were added to complete this behavior—`throw`
    and `close`. They raise an error into the generator:'
  prefs: []
  type: TYPE_NORMAL
- en: '`throw`: This allows the client code to send any kind of exception to be raised.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`close`: This acts in the same way, but raises a specific exception, `GeneratorExit`.
    In that case, the generator function must raise `GeneratorExit` again, or `StopIteration`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Generators are the basis of other concepts available in Python—coroutines and
    asynchronous concurrency, which are covered in [Chapter 13](ch13.html "Chapter 13. Concurrency"),
    *Concurrency*.
  prefs: []
  type: TYPE_NORMAL
- en: Decorators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Decorators were added in Python to make function and method wrapping (a function
    that receives a function and returns an enhanced one) easier to read and understand.
    The original use case was to be able to define the methods as class methods or
    static methods on the head of their definition. Without the decorator syntax,
    it would require a rather sparse and repetitive definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'If the decorator syntax is used for the same purpose, the code is shorter and
    easier to understand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: General syntax and possible implementations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The decorator is generally a named object (`lambda` expressions are not allowed)
    that accepts a single argument when called (it will be the decorated function)
    and returns another callable object. "Callable" is used here instead of "function"
    with premeditation. While decorators are often discussed in the scope of methods
    and functions, they are not limited to them. In fact, anything that is callable
    (any object that implements the `__call__` method is considered callable), can
    be used as a decorator and often objects returned by them are not simple functions
    but more instances of more complex classes implementing their own `__call__` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'The decorator syntax is simply only a syntactic sugar. Consider the following
    decorator usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'This can always be replaced by an explicit decorator call and function reassignment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: However, the latter is less readable and also very hard to understand if multiple
    decorators are used on a single function.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Decorator does not even need to return a callable!**'
  prefs: []
  type: TYPE_NORMAL
- en: As a matter of fact, any function can be used as a decorator because Python
    does not enforce the return type of decorators. So, using some function as a decorator
    that accepts a single argument but does not return callable, let's say `str`,
    is completely valid in terms of syntax. This will eventually fail if the user
    tries to call an object decorated this way. Anyway, this part of decorator syntax
    creates a field for some interesting experimentation.
  prefs: []
  type: TYPE_NORMAL
- en: As a function
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There are many ways to write custom decorators, but the simplest way is to write
    a function that returns a subfunction that wraps the original function call.
  prefs: []
  type: TYPE_NORMAL
- en: 'The generic patterns is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: As a class
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: While decorators almost always can be implemented using functions, there are
    some situations when using user-defined classes is a better option. This is often
    true when the decorator needs complex parametrization or it depends on a specific
    state.
  prefs: []
  type: TYPE_NORMAL
- en: 'The generic pattern for a nonparametrized decorator as a class is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Parametrizing decorators
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In real code, there is often a need to use decorators that can be parametrized.
    When the function is used as a decorator, then the solution is simple—a second
    level of wrapping has to be used. Here is a simple example of the decorator that
    repeats the execution of a decorated function the specified number of times every
    time it is called:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The decorator defined this way can accept parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that even if the parametrized decorator has default values for its arguments,
    the parentheses after its name is required. The correct way to use the preceding
    decorator with default arguments is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Missing these parentheses will result in the following error when decorated
    function is called:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Introspection preserving decorators
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Common pitfalls of using decorators is not preserving function metadata (mostly
    docstring and original name) when using decorators. All the previous examples
    have this issue. They created a new function by composition and returned a new
    object without any respect to the identity of the original one. This makes the
    debugging of functions decorated that way harder and will also break most of the
    auto-documentation tools that may be used because the original docstrings and
    function signatures are no longer accessible.
  prefs: []
  type: TYPE_NORMAL
- en: 'But let''s see this in detail. Assume that we have some dummy decorator that
    does nothing more than decorating and some other functions decorated with it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'If we inspect `function_with_important_docstring()` in a Python interactive
    session, we can notice that it has lost its original name and docstring:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'A proper solution to this problem is to use the built-in `wraps()` decorator
    provided by the `functools` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'With the decorator defined in such a way, the important function metadata is
    preserved:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Usage and useful examples
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since decorators are loaded by the interpreter when the module is first read,
    their usage should be limited to wrappers that can be generically applied. If
    a decorator is tied to the method's class or to the function's signature it enhances,
    it should be refactored into a regular callable to avoid complexity. In any case,
    when the decorators are dealing with APIs, a good practice is to group them in
    a module that is easy to maintain.
  prefs: []
  type: TYPE_NORMAL
- en: 'The common patterns for decorators are:'
  prefs: []
  type: TYPE_NORMAL
- en: Argument checking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Caching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Proxy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Context provider
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Argument checking
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Checking the arguments that a function receives or returns can be useful when
    it is executed in a specific context. For example, if a function is to be called
    through XML-RPC, Python will not be able to directly provide its full signature
    as in the statically-typed languages. This feature is needed to provide introspection
    capabilities, when the XML-RPC client asks for the function signatures.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The XML-RPC protocol**'
  prefs: []
  type: TYPE_NORMAL
- en: The XML-RPC protocol is a lightweight **Remote Procedure Call** protocol that
    uses XML over HTTP to encode its calls. It is often used instead of SOAP for simple
    client-server exchanges. Unlike SOAP, which provides a page that lists all callable
    functions (WSDL), XML-RPC does not have a directory of available functions. An
    extension of the protocol that allows discovering the server API was proposed,
    and Python's `xmlrpc` module implements it (refer to [https://docs.python.org/3/library/xmlrpc.server.html](https://docs.python.org/3/library/xmlrpc.server.html)).
  prefs: []
  type: TYPE_NORMAL
- en: 'A custom decorator can provide this type of signature. It can also make sure
    that what goes in and comes out respects the defined signature parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: The decorator registers the function into a global dictionary and keeps a list
    of the types for its arguments and for the returned values. Note that the example
    was highly simplified to demonstrate argument-checking decorators.
  prefs: []
  type: TYPE_NORMAL
- en: 'A usage example is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'When it is read, this class definition populates the `rpc_infos` dictionary
    and can be used in a specific environment, where the argument types are checked:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Caching
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The caching decorator is quite similar to argument checking, but focuses on
    those functions whose internal state does not affect the output. Each set of arguments
    can be linked to a unique result. This style of programming is the characteristic
    of **functional programming** (refer to [http://en.wikipedia.org/wiki/Functional_programming](http://en.wikipedia.org/wiki/Functional_programming))
    and can be used when the set of input values is finite.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, a caching decorator can keep the output together with the arguments
    that were needed to compute it, and return it directly on subsequent calls. This
    behavior is called **memoizing** (refer to [http://en.wikipedia.org/wiki/Memoizing](http://en.wikipedia.org/wiki/Memoizing))
    and is quite simple to implement as a decorator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: A `SHA` hash key is built using the ordered argument values, and the result
    is stored in a global dictionary. The hash is made using a pickle, which is a
    bit of a shortcut to freeze the state of all objects passed as arguments, ensuring
    that all arguments are good candidates. If a thread or a socket is used as an
    argument, for instance, a `PicklingError` will occur. (Refer to [https://docs.python.org/3/library/pickle.html](https://docs.python.org/3/library/pickle.html).)
    The `duration` parameter is used to invalidate the cached value when too much
    time has passed since the last function call.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example of the usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Caching expensive functions can dramatically increase the overall performance
    of a program, but it has to be used with care. The cached value could also be
    tied to the function itself to manage its scope and life cycle, instead of a centralized
    dictionary. But in any case, a more efficient decorator would use a specialized
    cache library based on advanced caching algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Chapter 12](ch12.html "Chapter 12. Optimization – Some Powerful Techniques"),
    *Optimization – Some Powerful Techniques*, provides detailed information and techniques
    on caching.'
  prefs: []
  type: TYPE_NORMAL
- en: Proxy
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Proxy decorators are used to tag and register functions with a global mechanism.
    For instance, a security layer that protects the access of the code, depending
    on the current user, can be implemented using a centralized checker with an associated
    permission required by the callable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: This model is often used in Python web frameworks to define the security over
    publishable classes. For instance, Django provides decorators to secure function
    access.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example, where the current user is kept in a global variable. The
    decorator checks his or her roles when the method is accessed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Context provider
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A context decorator makes sure that the function can run in the correct context,
    or run some code before and after the function. In other words, it sets and unsets
    a specific execution environment. For example, when a data item has to be shared
    among several threads, a lock has to be used to ensure that it is protected from
    multiple access. This lock can be coded in a decorator as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Context decorators are more often being replaced by the usage of the context
    managers (the `with` statement) that are also described later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Context managers – the with statement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `try...finally` statement is useful to ensure some cleanup code is run
    even if an error is raised. There are many use cases for this, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Closing a file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Releasing a lock
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making a temporary code patch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running protected code in a special environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `with` statement factors out these use cases by providing a simple way
    to wrap a block of code. This allows you to call some code before and after block
    execution even if this block raises an exception. For example, working with a
    file is usually done like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This example is specific to Linux since it reads the host file located in `etc`,
    but any text file could have been used here in the same way.
  prefs: []
  type: TYPE_NORMAL
- en: 'By using the `with` statement, it can be rewritten like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, `open` used as a context manager ensures that the
    file will be closed after executing the `for` loop and even if some exception
    will occur.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some other items that are compatible with this statement are classes from the
    `threading` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '`threading.Lock`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`threading.RLock`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`threading.Condition`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`threading.Semaphore`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`threading.BoundedSemaphore`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: General syntax and possible implementations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The general syntax for the `with` statement in the simplest form is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Additionally, if the context manager provides a context variable, it can be
    stored locally using the `as` clause:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that multiple context managers can be used at once, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'This is equivalent to nesting them, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: As a class
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Any object that implements the **context manager protocol** can be used as
    a context manager. This protocol consists of two special methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`__enter__(self)`: More on this can be found at [https://docs.python.org/3.3/reference/datamodel.html#object.__enter__](https://docs.python.org/3.3/reference/datamodel.html#object.__enter__)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`__exit__(self, exc_type, exc_value, traceback)`: More on this can be found
    at [https://docs.python.org/3.3/reference/datamodel.html#object.__exit__](https://docs.python.org/3.3/reference/datamodel.html#object.__exit__)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In short, the execution of the `with` statement proceeds as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The `__enter__` method is invoked. Any return value is bound to target the specified
    as clause.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The inner block of code is executed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `__exit__` method is invoked.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`__exit__` receives three arguments that are filled when an error occurs within
    the code block. If no error occurs, all three arguments are set to `None`. When
    an error occurs, `__exit__` should not re-raise it, as this is the responsibility
    of the caller. It can prevent the exception being raised though, by returning
    `True`. This is provided to implement some specific use cases, such as the `contextmanager`
    decorator that we will see in the next section. But for most use cases, the right
    behavior for this method is to do some cleaning, like what would be done by the
    `finally` clause; no matter what happens in the block, it does not return anything.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of some context manager that implements this protocol
    to better illustrate how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'When run without exceptions raised, the output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'When the exception is raised, the output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: As a function – the contextlib module
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Using classes seems to be the most flexible way to implement any protocol provided
    in the Python language but may be too much boilerplate for many use cases. A `contextlib`
    module was added to the standard library to provide helpers to use with context
    managers. The most useful part of it is the `contextmanager` decorator. It allows
    you to provide both `__enter__` and `__exit__` parts in a single function, separated
    by a `yield` statement (note that this makes the function a generator). The previous
    example written with this decorator would look like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: If any exception occurs, the function needs to re-raise it in order to pass
    it along. Note that the `context_illustration` could have some arguments if needed,
    as long as they are provided in the call. This small helper simplifies the normal
    class-based context API exactly as generators do with the classed-based iterator
    API.
  prefs: []
  type: TYPE_NORMAL
- en: 'The three other helpers provided by this module are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`closing(element)`: This returns the context manager that calls the element''s
    close method on exit. This is useful for classes that deal with streams, for instance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`supress(*exceptions)`: This suppresses any of the specified exceptions if
    they occur in the body of the with statement.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`redirect_stdout(new_target)` and `redirect_stderr(new_target)`: This redirects
    the `sys.stdout` or `sys.stderr` output of any code within the block to another
    file of the file-like object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other syntax elements you may not know yet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are some elements of the Python syntax that are not popular and rarely
    used. It is because they either provide very little gain or their usage is simply
    hard to memorize. Due to this, many Python programmers (even with years of experience)
    simply do not know about their existence. The most notable examples of such features
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The `for … else` clause
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Function annotations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The for … else … statement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using the `else` clause after the `for` loop allows you to execute a code of
    block only if the loop ended "naturally" without terminating with the `break`
    statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: This comes in handy in some situations because it helps to remove some "sentinel"
    variables that may be required if the user wants to store information if a `break`
    occurred. This makes the code cleaner but can confuse programmers not familiar
    with such syntax. Some say that such meaning of the `else` clause is counterintuitive,
    but here is an easy tip that helps you to remember how it works—memorize that
    `else` clause after the `for` loop simply means "no break".
  prefs: []
  type: TYPE_NORMAL
- en: Function annotations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Function annotation is one of the most unique features of Python 3\. The official
    documentation states that *annotations are completely optional metadata information
    about the types used by user-defined functions*, but in fact, they are not restricted
    to type hinting, and also there is no single feature in Python and its standard
    library that leverages such annotations. This is why this feature is unique—it
    does not have any syntactic meaning. Annotations can simply be defined for a function
    and can be retrieved in runtime, but that is all. What to do with them is left
    to the developers.
  prefs: []
  type: TYPE_NORMAL
- en: The general syntax
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A slightly modified example from the Python documentation shows best how to
    define and retrieve function annotations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: As presented, parameter annotations are defined by the expression evaluating
    to the value of the annotation preceded by a colon. Return annotations are defined
    by the expression between the colon denoting the end of the `def` statement and
    literal `->` that follows the parameter list.
  prefs: []
  type: TYPE_NORMAL
- en: Once defined, annotations are available in the `__annotations__` attribute of
    the function object as a dictionary and can be retrieved during application runtime.
  prefs: []
  type: TYPE_NORMAL
- en: 'The fact that any expression can be used as the annotation and it is located
    just near the default arguments allows to create some confusing function definitions
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: However, such usage of annotations serves no other purpose than obfuscation
    and even without them it is relatively easy to write code that is hard to read
    and maintain.
  prefs: []
  type: TYPE_NORMAL
- en: The possible uses
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'While annotations have a great potential, they are not widely used. An article
    explaining new features added to Python 3 (refer to [https://docs.python.org/3/whatsnew/3.0.html](https://docs.python.org/3/whatsnew/3.0.html))
    says that the intent of this feature was "to encourage experimentation through
    metaclasses, decorators, or frameworks". On the other hand, **PEP 3107** that
    officially proposed function annotations lists the following set of possible use
    cases:'
  prefs: []
  type: TYPE_NORMAL
- en: Providing typing information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Type checking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let IDEs show what types a function expects and returns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Function overloading / generic functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Foreign-language bridges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adaptation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicate logic functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Database query mapping
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RPC parameter marshaling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Documentation for parameters and return values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although the function annotations are as old as Python 3, it is still very hard
    to find any popular and actively maintained package that uses them for something
    else than type checking. So function annotations are still mostly good only for
    experimentation and playing—the initial purpose why they were included in initial
    release of Python 3.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covered various best syntax practices that do not directly relate
    to Python classes and object-oriented programming. The first part of the chapter
    was dedicated to syntax features around Python sequences and collections, strings
    and byte-related sequences were also discussed. The rest of the chapter covered
    independent syntax elements of two groups—those that are relatively hard to understand
    for beginners (such as iterators, generators, and decorators) and those that are
    simply less known (the `for…else` clause and function annotations).
  prefs: []
  type: TYPE_NORMAL
