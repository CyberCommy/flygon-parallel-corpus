- en: Persisting Data to a Database
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the file system-backed data persistence of the Artisan Application under
    our belt, it's time to turn our attention to their equivalents on the Central
    Office side of the system. We'll be reusing the `BaseDataObject` ABC that was
    defined previously to ensure that all data object functionality can be called
    in the same way (for example, using the `get` method to read the data and `save`
    to write it, for example), but because the underlying data storage process is significantly
    different in its implementation, that is where most of the similarities will end.
    We'll still have to decide which of the database options we're going to use, as
    well.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing database options in depth and selecting a database engine for data
    object persistence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining a data access strategy for the code that's expected to run at the Central
    Office
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing and implementing some supporting classes for the data access and persistence
    that are required
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Implementing the concrete data objects required at the Central Office:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Artisan
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Product
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are also some data access considerations that will postpone at least some
    of the concrete implementations, and those will be discussed in detail.
  prefs: []
  type: TYPE_NORMAL
- en: The Artisan Gateway and Central Office application objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **Artisan Gateway** and **Central Office application** both need project
    structures, so that we will have a place to put the code that''s specific to each
    of them. This need is captured in two stories:'
  prefs: []
  type: TYPE_NORMAL
- en: As a developer, I need a project for the Central Office application, so that
    I have a place to put the relevant code and build the application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a developer, I need a project for the Artisan Gateway, so that I have a place
    to put the relevant code and build the service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The aforementioned structures can start with nothing more than the basic project
    template, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/c423830f-96ad-4197-9e12-42c93ee49dba.png)'
  prefs: []
  type: TYPE_IMG
- en: As functionality is built out for the data persistence of business objects in
    the Artisan Gateway and Central Office application, more modules can be added,
    as they were in the Artisan Application's project structure. Whether that will
    be required can be impacted substantially by the selection of the data store engine,
    but for the time being, this should suffice.
  prefs: []
  type: TYPE_NORMAL
- en: Picking out a backend datastore engine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The story that drives the selection of the backend data store engine for the
    Artisan Gateway and Central Office application doesn''t really mandate any particular
    engine, just what that engine needs to provide:'
  prefs: []
  type: TYPE_NORMAL
- en: As a consumer of business object data at the HMS Central Office, I need business
    object data to be stored in a shared data store, so that data will be accessible
    by multiple consumers simultaneously, with transactional support/protection, and
    to the ends that they need access to it for.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a real-world scenario, there might well be specific database engines that
    are allowed, are encouraged, or are not allowed, based on any number of factors—what
    system administrators are willing to install and support; what options are available,
    based on the operating systems in use in the business; and possibly other external
    factors. There can also be developmental constraints; perhaps the preferred database
    doesn't have a reliable driver/library in the language being used, or data structure
    requirements are having a direct impact on the viable options.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another consideration, and one that does have some representation in the preceding
    scenario, is how data is accessed (locally versus over a network). In this case,
    since multiple users can access the system''s data at the same time, having a
    central database (of whatever flavor) that is accessible over the internal network
    is the easiest solution, in a number of respects:'
  prefs: []
  type: TYPE_NORMAL
- en: It would rely on database engines that are independently installable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Those engines, as prepackaged installations, do not require developer effort
    to create or maintain.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Their functionality can be tested externally, and thus, it can be trusted to
    behave as expected; therefore, development doesn't have to test the engine, but
    only interact with it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Taken together, these factors would allow for one of several options; a standard,
    SQL-based RDBMS would work, as would many of the available NoSQL database engines.
  prefs: []
  type: TYPE_NORMAL
- en: Another factor to consider is how the object data structure would be represented
    in the various database options. Simple objects, such as the `Address` in `hms_core`,
    can be represented quite easily in any RDBMS with a single table. More complicated
    objects, such as an `Artisan` with its embedded `Address`, or a `Product` with
    variably sized and variable content property data (`metadata`), require either
    discrete tables for related properties (with relationships defined so that the
    objects' related properties can be retrieved) or support for dynamic, structured
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'As they''d be built in a typical RDBMS implementation, the relationships are
    very simple; each `Artisan` has one address, and each `Product` has zero-to-many `metadata` items,
    which would look something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/6163148e-104a-4b39-ab6e-507a9c208c0d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Complications start to arise when we consider how to implement different data
    retrieval processes, using the possible permutations from the `BaseDataObject.get` class
    method and assuming that the real work happens at the database engine side of
    things:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Getting one `Artisan` and its `address`, or one `Product` and its `metadata`, isn''t
    too complicated; assuming an `oid` value, it boils down to variations of the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting the artisan or product record that matches the `oid`, then converting
    it to a `dict` so that we can use the `from_data_dict` class method to create
    an instance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For an `Artisan`: Getting the related `address` record, converting it to a `dict`,
    and inserting it into the first `dict`, created as `address`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For a `Product`: Getting the related `metadata` records, converting the records
    returned to a key/value `dict`, and inserting it into the first `dict`, created
    as ``metadata``'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating the instance by calling the appropriate `from_data_dict` class method.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting multiple instances based on only a list of `oid` values isn't much different;
    it simply starts with retrieving all of the records with matching `oid` values,
    then sorting out the data and creating and returning a list of instances. Realistically,
    if this process and the single-`oid` process used the same code, returning one
    (or zero) objects for a single `oid` (and no results if there was no matching `oid`),
    it wouldn't be horrible to work with.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Getting zero-to-many instances based on one local `criteria` value alone—finding
    an `Artisan` or `Product` by `company_name` or `name`, respectively, is also not
    difficult by itself. The actual process at the database side of the operation
    is significantly different from the pure `oid`-based retrievals, as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You find all of the matches based on the `criteria` passed, and keep track of
    the `oid` values for each match
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, you return the items identified by those `oid` values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding items by `address` or `metadata` values is similar, but it gets the
    initial list of `oid` values identifying results from the child table.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting multiple `criteria` values from a single table, parent, or child is
    yet another permutation that has to be handled.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another permutation is getting `criteria` values from parent and child tables
    in the same criteria set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The preceding list shows six different variations that have to be accounted
    for, assuming that the intentions of `BaseDataObject.get` are honored. These don't
    address how updates to (or deletions of) data are handled across related tables,
    either, which adds more complexity.
  prefs: []
  type: TYPE_NORMAL
- en: While it may be possible to implement all of them in SQL on the database side,
    such an implementation is going to be complicated. If the developers aren't pretty
    experienced database administrators, it may not be feasible at all; and, even
    if it is, it will still be a complex solution, with all of the potential risks
    that follow.
  prefs: []
  type: TYPE_NORMAL
- en: 'A trade-off approach that could be easily implemented, but would incur more
    processing time and/or memory usage, would be similar to the approach taken in
    the Artisan Application: loading all of the objects for any call made to `BaseDataObject.get`,
    then sorting out the results in the code. As the dataset involved grows, the data
    being retrieved and sent back will grow, and the time required to usefully retrieve
    the data that isn''t just a simple "get me objects with any of these `oid` values" request
    will take longer to find in the database and transmit to the application. Given
    enough time, or enough data, it will start to suffer from scalability issues.
    This approach is probably feasible, and it will probably work (if for a limited
    time), provided that multi-table updates and the deletion of child records can
    be managed in some fashion. The updating side of things would probably be managed
    purely in the application code, and related record deletion could be managed on
    the database side or in the application code.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another option that''s still in the realm of an RDBMS-based solution is to
    use an engine that has support for structured but schema-less data; MySQL and
    MariaDB, for example, have JSON field types that would allow entire Artisan and
    Product records to be represented with a very simple table structure, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/9ec76904-a53e-40de-886e-14cccfe3641d.png)'
  prefs: []
  type: TYPE_IMG
- en: Provided that those JSON fields allow for queries to execute against the data
    structure within them, all of the options that `BaseDataObject.get` needs to provide
    are supported, and without the concern of having to manage child tables. For all
    practical purposes, this specific approach would pretty much involve using MySQL
    as a replacement for a document store NoSQL database such as MongoDB, but without
    some of the functionality that a document store database likely already has.
  prefs: []
  type: TYPE_NORMAL
- en: All things considered, that's a lot of complexity that could be considered disadvantageous
    for an RDBMS-based data store. However, there are some advantages, too, even if
    they may not seem like significant ones at first glance. An RDBMS data store will
    generally allow for multiple queries to be executed in one pass. So, the multiple
    queries that are involved with the retrieval of data from multiple tables can
    be written as multiple query statements that are executed as a single call to
    the engine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most SQL-based databases also allow for some sort of precompiled/prepared functionality
    to be written: stored procedures or user functions; views; and, perhaps, other
    constructs that can move substantial chunks of functionality out of the application
    code and into the database. Those are usually quicker to execute, and, although
    SQL may not support extensive functionality (even in procedures and functions),
    there might be enough available to make their use worthwhile. Finally, and perhaps
    most significantly, the enforced data structure of tables, combined with the relational capabilities
    of pretty much any RDBMS worthy of the name, allows for pretty much any data in
    the system to be queried as needed, while enforcing solid data integrity across
    all system data if the databases are reasonably well designed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If an SQL-based RDBMS were to be selected as the engine for object state data
    persistence, the classes that used that engine to persist their state data would
    need some (or all) of the following properties to be specified:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A `host` specification: The hostname (FQDN, machine network name, or IP address)
    where the database resides'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A `database` name: The name of the database on the specified host that state
    data will be read from and written to'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A `user`: This will be used to connect to the database on the host'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A `password`: This will be used to connect to the database on the host'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instances would also need to be able to make connections to the database, which
    could be implemented with a method (`get_connection`, perhaps) or a property (`connection`,
    which could be lazily instantiated, and written so that an active `connection` could
    be deleted and recreated, when needed). It would also need a method to execute queries
    against the database once the connection had been established (`query`, perhaps).
    If this seems familiar, it's because this is the exact structure that was mentioned
    earlier, when discussing the idea of a `BaseDatabaseConnector` class.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the NoSQL side, all of the standard NoSQL advantages apply, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Since there aren't any hard and fast table structures involved in the database,
    there's no significant development time required to make changes to the data structure
    being stored. Once the data structure at the application side has been changed,
    any new or updated records will be adjusted when they are saved.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most of the NoSQL options already have the functionality to deal with the sort
    of data retrieval that `BaseDataObject.get` is promising to provide, and that
    has so much potential complexity in a more traditional RDBMS solution. That will
    probably translate to less development time and simpler code to maintain, both
    of which are good things.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The data writing (creation and update) processes will be simpler to implement,
    as well, since the relationships that require separate tables or unusual data
    structures in an RDBMS-based approach just go away, really—data-writes can store
    an entire data structure all at once, and don't have to worry about making sure
    that failures in a child table prevent the parent table from being written to.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of the two options, the NoSQL option feels like it will be easier to manage,
    while still fulfilling all of the requirements of the data persistence stories.
    Of the various NoSQL options, MongoDB feels like it will require the fewest changes
    to data structures, as object data is read from and written to the database; so,
    MongoDB will be the backend data store engine that we'll use.
  prefs: []
  type: TYPE_NORMAL
- en: The data access strategy for the Central Office projects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having selected the database engine, another decision that needs to be made
    is where that engine will ultimately live, in relation to the Artisan Gateway
    and Central Office application. Both of those will need to be able to read and
    write the same data from the same location. Since MongoDB can be used across a
    network, the data store could live pretty much anywhere that's accessible over
    that network (even on the same machine as one of the two components).
  prefs: []
  type: TYPE_NORMAL
- en: 'The logical architecture perspective of the relationships between the Artisan
    Gateway, several instances of the Central Office application, and the `hms_sys` database,
    then, would look something like the following diagram (allowing for any number
    of application instances, but showing only three):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/c09ce12c-5347-4028-9c00-0886ac403358.png)'
  prefs: []
  type: TYPE_IMG
- en: The physical architecture is less significant from a development perspective,
    provided that each logical component has a readily identifiable physical location.
    During development, all of those physical locations can be on a developer's local
    computer. Once deployed, the Artisan Gateway service and the `hms_sys` database might
    be installed to different machines, or they might reside on the same machine.
    This arrangement would allow all of the application instances and the service
    to share common data, reading from and writing to the `hms_sys`database from wherever
    they might live.
  prefs: []
  type: TYPE_NORMAL
- en: Supporting objects for data persistence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It''s almost unheard of for a database installation to not require some credentials
    for access in a production system, and there are other parameters that need to
    be kept track of across the various object types whose data will be saved in the
    data store. Since those parameters will be common for all of the different object
    types in use (for the most part), creating a mechanism that can be used to gather
    them all up seems like a logical first step. The common parameters that will most
    likely be needed were noted in the RDBMS exploration earlier, and are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`host`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`port`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`database`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`user`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`password`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'By the time `hms_sys` is deployed to a production environment, these will almost
    certainly be saved in some sort of configuration file, and it doesn''t hurt to
    get that logic in place now, rather than waiting to do so later. All of the data
    store configuration and connection parameters can be captured in a single object
    instance—a `DatastoreConfig`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'With the exception of the `port` property, which only allows `int` values from `0` through `65535` (the
    normal range of valid ports in a TCP/IP connection), there''s nothing substantially
    new in the property getter-, setter-, and deleter-methods. The `_set_port` method''s
    value checking is very straightforward, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The `__init__` method is also very straightforward, though it has no required
    arguments, because not all database engines will need all of the parameters, and
    the class is intended to be very generic. Connection issues that occur as a result
    of incomplete or invalid configuration will have to be handled at the relevant
    object level:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Since there will eventually be a need to read configuration data from a file,
    a class method (`from_config`) is defined to facilitate that, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The local MongoDB connections for development can then be created as instances
    of `DatastoreConfig`, with the minimum parameters needed to connect to a local
    database, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Reading and writing data against a Mongo database, using the `pymongo` library,
    requires a few steps, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A connection to the Mongo engine has to be established (using a `pymongo.MongoClient` object).
    This is where the actual credentials (the username and password) will apply, if
    the Mongo engine requires them. The connection (or client) allows the specification of…
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The database where the data is being stored has to be specified. The `database` value
    in the configuration takes care of specifying the name of the database, and the
    database itself, a `pymongo.database.Database` object, once returned by the client/connection
    allows the creation of…
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The collection where the actual documents (records) reside (a `pymongo.collection.Collection` object),
    and where all of the data access processes actually occur.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A very simple, functional example of the connection/database/collection setup for `hms_sys` development
    might include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: At this point, the `objects` object, as a Mongo `Collection`, provides methods
    for reading, writing, and deleting documents/records in the `Objects` collection/table.
  prefs: []
  type: TYPE_NORMAL
- en: The organization of documents in a collection can be very arbitrary. That `objects` collection
    could be used to store `Artisan`, `Product`, and `Order` state data documents
    all in the same collection. There's no functional reason that prevents it. Over
    a long enough period of time, though, reading data from that collection would
    slow down more than reads from collections that, for example, grouped those same `Artisan`, `Product`, and `Order` state
    data documents into separate collections—one collection for each object type.
    There might be other considerations that will make such a grouping beneficial,
    as well. Keeping objects of the same type would probably make managing them through
    a GUI tool easier, and might be similarly beneficial for command-line management
    tools.
  prefs: []
  type: TYPE_NORMAL
- en: 'Taking all of the preceding factors together, a fairly optimal integration
    of data storage and parameters across the objects in the `hms_sys` data store
    would include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: One or more client connections to a common MongoDB instance, whose credentials
    and parameters are all configurable and are eventually controlled by a configuration
    file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One database specification that is common to all of the objects in the Central
    Office code bases, from the same configuration that the client setup uses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One collection specification per object type, which could be as simple as using
    the name of the class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having made all of these decisions, we can create an ABC that central-office
    application and service objects can derive from in much the same way that Artisan
    Application data objects derived from `JSONFileDataObject`, as we saw in [Chapter
    12](c68ea186-809d-4c66-aa38-737f4cb070d5.xhtml), *Persisting Object Data to Files,*—call
    it `HMSMongoDataObject`. Since it will need to be available to both the Artisan
    Gateway service and the Central Office application, it needs to live in a package
    that is available to both. Without creating another package project solely for
    this purpose, the logical place for it to live would be in a new module in `hms_core`;
    and, if the naming convention established in the Artisan code base is followed,
    that module would be named `data_storage.py`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Diagrammed, the relationship between `HMSMongoDataObject` and the final central-office
    data objects looks much like the Artisan Application''s counterparts, although `hms_co` .. `Order` is
    not included, because it may need some special consideration that we haven''t
    explored:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/3078d392-c757-4609-8df1-ee6480f254fe.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The implementation of `HMSMongoDataObject` starts by inheriting from `BaseDataObject`,
    and then it includes the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we''ll be using a `DatastoreConfig` object to keep track of a common
    configuration for all derived classes, that becomes a class attribute (`_configuration`),
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'MongoDB documents, when they are created, have an `_id` value that, if passed
    to a normal `from_data_dict` to create an instance of the class, will throw an
    error. There hasn''t been an `_id` argument in any of our implementations so far,
    and there''s no reason to expect one to surface anywhere down the line, because
    we''re using our own `oid` property as the unique identifier for object records.
    In order to prevent that from happening, `from_data_dict` will need to either
    explicitly remove that `_id` value from its object creation process, or keep track
    of all of the valid arguments that can exist, and filter things accordingly. Of
    those two options, the latter, while slightly more complicated, also feels more
    stable. In the (unlikely) event that more fine-grained filtering of data is needed
    during object creation in `from_data_dict`, tracking the valid arguments will
    be easier to maintain than having to modify a long list of key removals:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we have decided that all objects of any given type should live in a collection
    with a meaningful and related name, the approach that needs the least effort is
    simply using the class name as the name of the MongoDB collection that state data
    for instances of the class live in. We can''t rule out a potential need to change
    that, though, so another class attribute that allows that default behavior to
    be overridden feels like a sensible precaution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The properties of `HMSMongoDataObject` look relatively normal at first glance,
    but there is a significant difference that may not be obvious at first. Since
    data access for any given class is focused on instances of that class, and creation
    of database connections and collections could be computationally expensive, having
    a single connection for all data object classes is a tempting idea—that implementation
    would have the instance-level connection and database properties' underlying storage
    attributes be members of `HMSMongoDataObject`, not of the derived classes themselves,
    or instances of those classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'That would, in effect, require that all data objects for `hms_sys` live in
    the same database and be accessed through the same MongoDB instance at all times.
    While that''s not an unreasonable requirement, it could make moving live system
    data problematic. The entire system might need to be shut down for such a data
    move. As a compromise, the `connection` and `database` properties of each class
    will be members of that class, instead – which would, for example, allow `Artisan` object
    data to be moved independently of `Product` data. This may not be a likely consideration
    in the near future of the system, but it doesn''t feel like a bad compromise to
    make if it has the potential of reducing effort somewhere down the line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The `collection`, `connection`, and `database` properties are also handled
    differently, for the purposes of deletion. The actual objects that are retrieved
    by the getter methods are lazily instantiated (created when they are needed, in
    order to reduce system load when they aren''t going to be used), and, because
    they don''t exist until they are first created (by a reference to them), it''s
    just easier to truly delete them, rather than set them to some default value,
    such as `None`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The property definitions are slightly different than what we''ve used in the
    past, because those properties can be retrieved or deleted, but not set. This
    corresponds to the idea that the database and collection can only be retrieved
    (opened) or closed (deleted). Accordingly, they have no setter methods defined
    or attached to the properties themselves, and the configuration property takes
    that a step further – it is read-only:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The `__init__` method looks very much like the `__init__` method of `JSONFileDataObject`,
    with the same arguments (and for the same reasons). Since we have no properties
    that require default values to be set, however, the only thing that it needs to
    do is call its own parent constructor, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Like `JSONFileDataObject`, the `_create` and `_update` methods for `HMSMongoDataObject` aren''t
    necessary. MongoDB, like the JSON file approach that was used earlier, doesn''t
    distinguish between creating and updating a document. Both processes will simply
    write all of the object data to the document, creating it if necessary. Since
    they are required by `BaseDataObject` but aren''t of use in this context, the
    same implementation, simply raising an error with developer-useful information,
    will suffice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The implementation of `save`, supported by the class-level `collection` and
    its `database` and `connection` ancestors, is very simple. We need to acquire
    the `data_dict` for the instance and tell the MongoDB connection to `insert` that
    data. The one complicating factor in this process is the standard MongoDB `_id` value
    that was mentioned earlier. If we did nothing more than calling `insert`, there
    would be no `_id` value for the MongoDB engine to use to identify that a document
    that already exists does, in fact, exist. The inevitable result of that would
    be the creation of new document records for existing items on every update (instead
    of replacing existing documents), polluting the data with out-of-date instances
    on every update.
  prefs: []
  type: TYPE_NORMAL
- en: Under normal circumstances, the easiest solution for this would be to either
    change the `oid` property to `_id` during data writing processes and from `_id` back
    to `oid` during data reads, or to simply change the `oid` properties that have
    been established thus far to `_id` in the classes defined thus far. The first
    option would require only a bit of effort in each `to_data_dict` and `from_data_dict` method,
    including the ones already defined in the `Artisan` data objects, but it would tend
    to be more error-prone, as well, and it would require additional testing. It's
    a viable option, but it may not be the best one. Changing the names of the `oid` properties
    to `_id` across the board would be simpler (little more than a wide-scale search-and-replace
    operation, really), but it would leave the classes with what would look like a
    protected property name that would actually be a public property. Functionally,
    that's not such a big deal, but it flies in the face of Python code standards,
    and it is not a preferred option.
  prefs: []
  type: TYPE_NORMAL
- en: Another option is to simply assure that the `hms_sys oid` properties and the `_id` values
    that MongoDB generates are identical. While that does mean that individual document
    record sizes will increase, that change is trivial – on the order of 12 bytes
    per document record. Since that could be handled by the `save` method's process,
    as a simple addition to the `data_dict` value being saved (and would need to be
    ignored, or otherwise dealt with, during `from_data_dict` retrievals, as a part
    of that process), there would only be two places where it would have to be written
    or maintained.
  prefs: []
  type: TYPE_NORMAL
- en: 'That feels like a much cleaner option, even with the additional data being
    stored. The final implementation of `save`, then, would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The corresponding change in `from_data_dict` uses the `_data_dict_keys` class
    attribute that was defined earlier. Since `_data_dict_keys` may not have been
    defined, but needs to be, checking that it''s been defined and raising a more
    detailed error message will make debugging those (hopefully rare) occasions easier.
    Once that''s been verified, the incoming `data_dict` will simply be filtered down
    to only those keys that match an argument in the `__init__` method of the class,
    and will be passed to `__init__` to create the relevant instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to allow all `HMSMongoDataObject`-derived classes to be configured
    at once, we need to provide a class method to that end. The one caveat to the
    implementation of this method is that all of the derived classes will also have
    the method available, but  the method changes the `_configuration` attribute of
    the `HMSMongoDataObject` class, even if it''s called from a derived class. It
    can be reasonably expected that calling, say, `Artisan.configure`, would configure
    data access for only `Artisan` objects – but that is not what should happen, so
    we''ll raise an error to make sure that it doesn''t go unnoticed if it''s attempted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Since all of the class methods that interact with the data store will need
    the relevant connection, and it may not have been created by an instance before
    the call was made, having a helper class method to acquire the connection will
    be useful. It is also possible to force the acquisition of all of the relevant
    data store objects by creating an instance, but that feels cumbersome and counter-intuitive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The implementation of the `delete` class method is very simple; it boils down
    to iterating over the provided `oids`, and deleting each one in the iteration.
    Since `delete` is interacting with the data store, and it''s a class method, it
    calls the `get_mongo_collection` class method that we defined first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The result of a failed check of `_data_dict_keys` is an `AttributeError` that
    includes a list of the arguments of the `__init__` method of the class, using
    the `getfullargspec` function of the `inspect` module. Python's `inspect` module
    provides a very thorough set of functions for examining code within the code that's
    running. We'll take a more in-depth look at the module when we start to look at
    metaprogramming concepts.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `get` method of `HMSMongoDataObject` also starts by assuring that the relevant `collection` is
    available. Structurally, it looks a lot like its counterpart in `JSONFileDataObject`,
    which should come as no great surprise, since it''s performing the same sort of
    actions, and uses the same method signature that was defined in `BaseDataObject`.
    Because MongoDB has more capabilities available than the file system, there are
    some noteworthy differences:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Rather than try to work out a (probably complex) mechanism for dynamically generating
    arguments for the `find` functionality of `pymongo` that include both `oids` and `criteria`,
    we'll handle requests based on the combination of `oids` and `criteria` that are
    present. Each branch in the code will result in a list of `data_dict` items that
    can be converted to a list of object instances later on.
  prefs: []
  type: TYPE_NORMAL
- en: 'If `oids` are provided, then the initial request will only concern itself with
    those. At present, the expectation is that `get` calls with `oids` will usually
    have only a few `oids` involved (usually just one, in fact), so using very basic
    functionality to get each document that corresponds to a single `oid` in the list
    should suffice, at least for now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'If, somewhere down the line, there is a need to handle longer collections of `oids`, `pymongo` supports
    that, as well; so, we''ll leave a comment about that in place, just in case we
    need it later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'If `oids` and `criteria` are both provided, the eventual list of objects will
    need to be filtered with the `matches` method, so the presence of `criteria` will
    have to be monitored and tracked. If `oids` and `criteria` are both supplied,
    then we''ll need to know that later, in order to filter the initial results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'If only `criteria` is passed, then the entire set of `data_dicts` can be retrieved
    with a single call, using a list comprehension to gather the found items from
    the cursor that `find` returns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'If neither `oids` nor `criteria` is passed, then we will want to return everything
    available, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the initial `data_dict` has been generated, it will be used to create
    the initial list of object instances, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'And, if we still need to filter those results down even more (if we set `post_filter` to `True` earlier),
    then the same filter process that was used in `JSONFileDataObject` can be used
    now, calling the `matches` method of each object in the initial results and only
    adding it to the final results list if it returns `True`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'All of the basic CRUD operations that are needed for Artisan Gateway and Central
    Office data objects should be easy to implement at this point, by simply deriving
    them from the corresponding `Base` class in `hms_core` and `HMSMongoDataObject`:'
  prefs: []
  type: TYPE_NORMAL
- en: Create and update operations still happen simply by calling the `save` method
    of any instance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Read operations are handled by the `get` class method, which also allows for
    a fair bit of functionality for finding objects, though there might be the need
    for additional functionality that supports more complex capabilities later on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Delete operations are handled by the `delete` class method; again, there may
    be the need for deletion capabilities that aren't based on the `oid`, but for
    now, this will suffice.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: RDBMS implementations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, both of the data object implementations that we've created have overridden
    the `_create` and `_update` methods that were required in `BaseDataObject`. It
    would be fair, under the circumstances, to question why those were put in place
    at all. The short answer to that question is that both of the implementations
    that have come together so far use the same process at the data store level for
    creating and updating records and documents. As a result, they simply haven't
    been needed. If it was expected that `hms_sys` would never need any other database
    backend, we'd be justified in removing them from the entire code base.
  prefs: []
  type: TYPE_NORMAL
- en: However, what would've happened if the decision to use MongoDB had gone a different
    way, and the preferred (or mandated) backend data store engine was an RDBMS such
    as Microsoft SQL Server? Or, worse, what if that sort of change was mandated after the
    system was operational?
  prefs: []
  type: TYPE_NORMAL
- en: 'Setting aside the data migration planning that would have to happen and focusing
    on only the application and service code, what would that kind of change require? Not
    much, when it comes right down to it. A generic SQL/RDBMS engine ABC (`HMSSQLDataObject`)
    might look something like the following, for a given RDBMS API/library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The `HMSSQLDataObject` class that is shown here is by no means complete, but
    should serve as a reasonable starting point for building a full implementation
    of such a class, which connects to and uses data from any of several RDBM systems.
    The complete code, such as it is, can be found in the `hms_core/ch-10-snippets` directory
    of the project code.
  prefs: []
  type: TYPE_NORMAL
- en: 'The same `_configuration` class property would probably be in use, serving
    the same purpose. It''s possible that the `_data_dict_keys` class attribute would
    also be of use in reducing record fields to a valid argument dictionary in `from_data_dict`.
    Since SQL, for the various CRUD operations, or at least for specific starting
    points for those CRUD operations, would need to be stored and accessible to the
    classes, a viable option for doing so would be to attach them as class-attributes,
    as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the SQL for the various CRUD operations would include the tables that
    the data is stored in, and the process of connecting to the database in most RDBMS''
    handles the equivalents to the `connection` and `database` in our MongoDB approach,
    only the `connection` itself needs to be tracked and available as a property:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Like its equivalent in the Mongo-based implementation, a `connection` is lazily
    instantiated and performs an actual deletion, rather than resetting to default
    values, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The related property declaration is identical, and is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Object initialization is also identical, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The significant, substantial differences are mostly in the methods that handle
    the CRUD operations. The original `save` method, as implemented in `BaseDataObject`,
    is left in place, and will call the `_create` or `_update` methods, as determined
    by the `is_dirty` or `is_new` property values for the instance. Each of these
    methods is responsible for acquiring the SQL template from the appropriate class
    attribute, populating it, as needed, with current state data values, sanitizing
    the resultant SQL, and executing it against the connection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Sanitizing SQL is a very important security precaution, reducing the risk of
    a system being vulnerable to an SQL injection attack. These attacks can compromise
    data confidentiality and integrity, at a minimum, and can also raise the risk
    of authentication and authorization compromises, perhaps even across multiple
    systems, depending on password policies and the enforcement of them. Most RDBMS
    APIs will have some mechanism for sanitizing SQL before executing it, and some
    will also support query parameterization that can also reduce the risk of vulnerabilities.
    As a basic rule of thumb, if data supplied by a user is being passed into a query,
    or even into a stored procedure, it should be sanitized wherever/whenever possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `delete` class method is simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Most of the pattern and approach behind the `get` method should look familiar;
    again, it''s got the same signature (and is intended to perform the same activities)
    as the methods that have been created so far, which implement the required functionality
    of the `BaseDataObject`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The branch that handles `oid` requests is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The `criteria` branch is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The default branch that simply gets everything else is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: All of the branches generate a list of `data_dict` values that can be used to
    create object instances, though they may not be returned from the backend data
    store as dictionary values.
  prefs: []
  type: TYPE_NORMAL
- en: 'The lowest common denominator results of a query are, as noted in the preceding
    code comments, a tuple of tuples of tuples, which might look something like the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'If the engine, or the Python API to the engine, provides a built-in mechanism
    for converting rows returned into dictionary instances, that''s probably the preferred
    approach to use to make the conversion. If there isn''t anything built in to handle
    that, converting the nested tuples to a series of dictionaries isn''t difficult
    to do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'From this point on, the process is pretty much the same as in the previous
    implementations, in `JSONFileDataObject` and `HMSMongoDataObject`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Another (potentially major) difference concerns how child objects, such as
    the `products` in an `Artisan` object, will have to be handled. If there is a
    need to fetch those child objects as objects and populate the parent object with
    them, assuming that they use the same `BaseDataObject`-derived interface, each
    child type will have a class associated with it, each of those classes will have
    a `get` method, and that `get` method will allow the `oid` of the parent object
    to be specified as criteria. That will allow for a process that looks like the
    following, used to retrieve and attach any child objects, as needed (using `Artisan` and `Product` classes
    as an example):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The other members of a final business/data object class that derives from `HMSSQLDataObject` should,
    for the most part, be expected by now, since they are also required for the implementation
    of final data objects derived from the other two `DataObject` ABCs. They would
    include the concrete implementations of `to_data_dict` and `matches` instance
    methods and the `from_data_dict` class method, and the various class-specific
    variables (mostly the `_sql` class attributes).
  prefs: []
  type: TYPE_NORMAL
- en: The concrete business objects of the Central Office projects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Up to this point, there''s been a lot of effort concerning the foundations,
    but it''s about to pay off, as the creation of the initial Central Office classes
    gets under way. At present, since the assumption is that the Central Office application
    and the Artisan Gateway service will be using the same business object classes,
    and that they need to reside in a common package that''s not a part of the package
    set for either of those code bases, the best option for where they should live
    appears to be in the `hms_core` component project:'
  prefs: []
  type: TYPE_NORMAL
- en: It was already in the design plan for `hms_core` to be included as a part of
    the build or deployment of all the other packages, anyway
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although it would certainly be possible to create yet another component project/package
    specifically for the data access that these concrete classes will provide, that's
    a fair amount of overhead for what will probably be a single module, with only
    three classes (so far)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If, at some point in the future, there is a need or desire to move them to a
    different package/project—say, if it's decided to change the Central Office application's
    data access to a web service call to the Artisan Gateway—it won't be difficult to
    move the code accordingly, although it will be somewhat tedious.
  prefs: []
  type: TYPE_NORMAL
- en: It will probably be easier to understand how the work regarding the foundations
    is going to pay off by diving right in to one of the concrete classes, so we'll
    do that now, starting with `hms_core.co_objects.Artisan`.
  prefs: []
  type: TYPE_NORMAL
- en: hms_core.co_objects.Artisan
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Story that''s driving the concrete, state data persisting `Artisan` class
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: As an Artisan manager, I need to be able to manage (create, modify, and delete)
    artisans in the system, so that their statuses and information can be kept current.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As with the `hms_artisan` equivalent, this is about being able to manage the
    data, not the UI around that data management process. The various moving parts
    of any of the data objects in `co_objects` will involve the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The properties of the object type, which will originate with the corresponding `Base` class
    in `hms_core.business_objects`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The data persistence-related properties of all data objects in the system, provided
    or required by `HMSMongoDataObject` or its parent `BaseDataObject`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concrete implementations of any abstract members inherited by the concrete class,
    from any of the classes it derives from
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using the concrete `Artisan` class as an example, the relationships involved
    are shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/70640dc2-a8ac-4d72-a723-f0708907ca20.png)'
  prefs: []
  type: TYPE_IMG
- en: In this particular case, there is only one property (the `_data_dict_keys` class
    attribute that needs to be overridden from `HMSMongoDataObject`) that needs to
    be created. Three of the four instance methods (`add_product` and `remove_product`,
    and `matches`) have concrete implementations in the abstract methods that require
    their implementation, and can be implemented as nothing more than a call to the
    original methods in the classes that they originate in.
  prefs: []
  type: TYPE_NORMAL
- en: The `to_data_dict` method for any class deriving from `BaseDataObject` will
    have to be implemented locally (that's just the nature of the structure that's
    been developed), but that implementation is not going to be much more than creating
    and returning a `dict` value.
  prefs: []
  type: TYPE_NORMAL
- en: That leaves `from_data_dict`, the class method that data objects use to create
    instances from dictionaries; those dictionaries are, in turn, being supplied by
    data retrievals from the backend data store. In cases where the data object doesn't
    have any child objects, the baseline method that `BaseDataObject` provides and
    requires should simply work as an inherited class method. Object types (such as `Artisan`)
    that do have child object properties will have to accommodate those, and that
    will happen as a local override of the original class method from `BaseDataObject`.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, all told, implementing most of these data objects will only involve the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating the `_data_dict_keys` class attribute, which can (more or less) be
    copied and pasted from the argument list of the class' `__init__` method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the `matches` method with a call to the method defined in `BaseDataObject` that
    carries through to `HMSMongoDataObject`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing `to_data_dict` from scratch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing a `from_data_dict` class method from scratch, if a customized method
    is needed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating an `__init__` method that shouldn't need to do anything more than call
    the relevant parent class `__init__` methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For most classes, then, the worst-case scenario, to get from nothing to a full,
    concrete implementation, is two detailed methods to develop, and a few copy-and-paste
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Those two methods play out in `hms_core.co_objects.Artisan`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The `_data_dict_keys` object is a fairly trivial effort, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The `__init__` method still has a fairly complicated argument list, but they
    can be copied from their source classes whole-cloth, unless those source classes'' `__init__` methods
    have an argument list (`*products`, in this case) or a keyword argument list (which
    has been avoided, in order to keep `__init__` signatures as simple as possible):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The instance methods that can call the parent classes'' methods are all one-liners,
    returning the results of calling the parent class'' method with the appropriate
    arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The `to_data_dict` method could be daunting, but, since the sequence of the
    keys in the resultant dictionary is irrelevant, grouping them by the classes they
    originate from allows several of them (the data store-related ones) to be copied
    around as needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: In retrospect, it might have been a better design to provide a method or property
    of each of the classes that would be responsible for generating their part of
    a final `data_dict`. That would've kept the code for generating those dictionary
    items in a single place, at a minimum, and would've allowed the final `data_dict` values
    to be assembled from all of the parent class values for each instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `from_data_dict` for the Artisan class uses the same logic and process
    as the original class method in `HMSMongoDataObject`, but has to account for the `address` property,
    which is either `None` or contains an `Address` instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: With a total of seven items to implement concretely, and only two of them that
    aren't manageable by calling a parent class' equivalent or writing very simple
    code, the implementation is pretty painless.
  prefs: []
  type: TYPE_NORMAL
- en: hms_core.co_objects.Product
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The corresponding Story for concrete `Product` object data persistence is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: As a product manager, I need to be able to manage products in the system, so
    that their statuses and information can be kept current.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code that fulfills this scenario is even simpler than the code for `Artisan` objects;
    it doesn''t need any special handling of object properties, so `from_data_dict` can
    simply fall back to the default, defined in `HMSMongoDataObject`. It doesn''t
    have any extraneous methods that are required, either, so a full, functional implementation
    really just boils down to the `_data_dict_keys` class attribute and the `__init__`, `matches`, and `to_data_dict` methods,
    with `matches` being implemented as a call to `HMSMongoDataObject.matches`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The `__init__` method has a long argument set, which should come as no surprise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'The implementations of `matches` and `to_data_dict` are very straightforward,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: The `matches` method may need to be reexamined later on, either during the creation
    of the Artisan Gateway service or when the various application UIs are being built,
    because while it works for most cases, it will not currently allow a `get` with
    any metadata criteria to return results unless `criteria` is the only value being
    searched for (no `oids` are passed). It's worth a more detailed look here and
    now, though, because it shows some aspects of how the data object code interacts
    with MongoDB.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s create some example `Product` objects and save them, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Finding products that have `metadata` indicating that they are made of silver
    and have sapphire gemstones is fairly straightforward, although it requires criteria
    specifications that look a little odd:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Creating the criteria as a `dict` allows them to be passed to `Product.get` as
    a single keyword argument set, and allows the criteria specification to be as
    detailed as we need. We could, for example, add other metadata, specify a product
    name, or add any other object properties that appear in the `data-dict` representation
    of a `Product` (as returned by `to_data_dict`). The results will come back as
    a list of objects, and, by printing the `data-dict` representations of them, we
    can see the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Executing the preceding code yields the dataset for the one matching the `Product`,
    our silver and sapphire necklace, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/6fc418fa-cac8-4245-a48a-50bb76a6b124.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It''s worth mentioning that passing `criteria` doesn''t have to be a multi-level `dict`,
    even for `metadata` values. Using `criteria` in this format is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: This criteria structure works just as well. The underlying `find()` method provided
    by a `pymongo connection` object treats **dot-notation** specifications of this
    sort as references to a nested object structure that looks much like the `dict` value
    shown previously, and will process the request accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: Other hms_core.co_objects classes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There could have been Stories and tasks in this iteration to deal with the
    data persistence of `Customer` and `Order` objects, as well. Those would have
    probably taken the same basic shape as the stories for the `Artisan` and `Product` objects,
    looking something like the following `Order` example:'
  prefs: []
  type: TYPE_NORMAL
- en: As an order manager, I need to be able to manage orders in the system, so that
    their statuses and information can be kept current.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To do so, I would do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Design and implement an `Order` class for the Central Office data store that
    allows object data to be persisted.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unit test the `Order` class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normally, in an Agile, iterative process, a story would have to be accepted
    before being included in an iteration, and the process of it being accepted would
    involved enough review and analysis that a full understanding of the tasks involved
    would be reached, and the stories and tasks written and planned accordingly. In
    this case, though, since there is a significant dependency on an external system
    (the Web Store Application) and on an order acceptance and processing workflow
    that hasn't been detailed yet, there's not a lot that can be done, beyond a bare-bones
    implementation of the `Customer` and `Order` classes. The workflow, in particular,
    was going to be somewhat dependent on the data structure that artisans need, which
    wasn't defined until this iteration.
  prefs: []
  type: TYPE_NORMAL
- en: For all of the preceding reasons, there are no stories to deal with these objects
    and their data persistence in this iteration. The data persistence aspects of
    the final classes created for the Artisan Gateway and/or Central Office application
    will be handled as parts of stories to implement the order processing workflow.
    In the meantime, though, we can at least stub out the bare minimum structure for
    those classes in a separate file (in `future/co_objects.py`, in the code for this
    chapter) while the data object definition process is fresh in our minds, to save
    some effort later.
  prefs: []
  type: TYPE_NORMAL
- en: Accounting for the other CRUD operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Up to this point, we''ve only accounted for two of the CRUD operations that
    all of our data objects need: `create` and `read`. The `delete` operations, across
    the board, are accounted for, but not yet proven; however, since that process
    is very simple, it can wait until we unit test everything, to prove that everything
    works. The missing item, then, is the `update` operation, at least in part. The
    various object documents that have been written to the database with every `save()` call
    have shown that the process of writing object data is working, but we haven''t
    actually tried to update anything yet; and, if we were to try now, it would fail
    (and fail silently). The reason behind that failure is very simple, and can be
    seen in the code from `HMSMongoDataObject.save`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: In a nutshell, it's because we're checking for the status of `_is_new` and `_is_dirty`,
    and only calling the database write if one of them is `True`. By default, when
    a data object is created, its `_is_dirty` flag value is set to `False`. If that
    value doesn't get changed somewhere along the line, when an object's property
    values are altered, the `save` method will never actually write the changed dataset
    to the database.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are at least two different ways to resolve this. The more complex solution
    would be to redefine each of the setter and deleter methods for each property
    of each concrete data object class, and the property declarations for each of
    them, so that the methods call their parent methods and the instance''s `_set_is_dirty` methods
    in the process. This is the approach that was taken for the corresponding objects
    in the Artisan project. See the following code snippet, which uses the `Product.name` property
    as an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Taking this approach would not be difficult (or even terribly time-consuming),
    but it would add some additional unit testing requirements, since each of those
    method and property overrides would register as new, local class members that
    need to be tested. That's not a bad thing, though, since those tests would ultimately
    only be concerned with verifying that the `is_dirty` state change happened when
    it was supposed to.
  prefs: []
  type: TYPE_NORMAL
- en: 'The other approach would be to simply remove the `is_new` and `is_dirty` check
    condition from `HMSMongoDataObject.save`. That is a much simpler solution, in
    many respects, but it comes with at least one caveat: it puts the responsibility
    of making sure that the `save` of any changed object is called in the code that''s
    making those changes. Without some careful monitoring of how and when the code
    is making and saving changes, there is a good possibility that many `save` calls
    will be made, incrementally updating the data document for any given object. That
    may or may not be a significant concern (it''s unlikely to have a significant
    impact on performance for small sets of data changes, for example), but it could
    get out of control quickly, if not closely monitored. If the data store had a
    cost per query associated with it, as unlikely as that might seem, that inefficiency
    would also cost more `money` on a long-term basis.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the actual use cases involving updating the data haven''t yet been developed
    (or even had stories presented that could guide the decision), for now, in order
    to close these stories, the latter solution will be taken. This keeps things simple
    for the time being, and we know what will be involved for a more complex solution,
    should the need for it arise. That, then, revises `HMSMongoDataObject.save` as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As with the Artisan Application's data persistence, we've accounted for (if
    not proven) all of the CRUD operation requirements for data objects living in
    the Central Office code bases. Because the interface requirements are also defined
    by the same `BaseDataObject` inheritance, even though there is additional functionality
    provided between that ABC and the concrete data objects, the processes for reading
    and writing data across all of the data objects look the same across the entire
    system – at least so far.
  prefs: []
  type: TYPE_NORMAL
- en: None of the data access has been unit tested yet, however, and that's a critical
    item for the system; at the end of the day, the data is, if not the most important
    part of the system, certainly one of the most import aspects of it. It's time,
    then, to change the context and write those unit tests, which we'll do in the
    next chapter.
  prefs: []
  type: TYPE_NORMAL
