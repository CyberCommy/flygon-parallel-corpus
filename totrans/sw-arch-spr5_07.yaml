- en: Pipe-and-Filter Architectures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will review a useful paradigm architecture named Pipe-and-Filter,
    and you will learn how to implement an application using the Spring Framework.
  prefs: []
  type: TYPE_NORMAL
- en: We will also explain how to build a pipeline that encapsulates an independent
    chain of tasks aimed at filtering and processing large amounts of data, focusing
    on the use of Spring Batch.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to Pipe-and-Filter concepts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boarding Pipe-and-Filter architectures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use cases for Pipe-and-Filter architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spring Batch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing pipes with Spring Batch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll start by providing an introduction to Pipe-and-Filter architecture and
    the concepts associated with it.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Pipe-and-Filter concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pipe-and-Filter architecture refers to a style of architecture that was introduced
    in the early 1970s. In this section, we will introduce Pipe-and-Filter architecture,
    along with concepts such as filters and pipes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Doug McIlroy introduced Pipe-and-Filter architecture in Unix in 1972\. The
    implementations are also known as pipelines, and they consist of a chain of processing
    elements, arranged so that the output of each element is the input of the next
    one, as illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/72e9d906-04fa-4277-863c-d16d09d749f1.png)'
  prefs: []
  type: TYPE_IMG
- en: As shown in the preceding diagram, Pipe-and-Filter architecture consists of
    several components, named filters, that can transform (or filter) data across
    the process. The data is then passed to other components (filters) via pipes that
    are connected to each component.
  prefs: []
  type: TYPE_NORMAL
- en: Filters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Filters are components that serve to transform (or filter) data that is received
    as an input from a previous component via pipes (connectors). Each filter has
    an input pipe and an output pipe, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b6f677e9-e5e4-4cc9-be84-8213f26ccacb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Another characteristic of this concept is that the filter can have several
    input pipes and several output pipes, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6d11a37d-2672-4163-9080-39e43a9c171c.png)'
  prefs: []
  type: TYPE_IMG
- en: Pipes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Pipes are the connectors for filters. The role of a pipe is to pass messages,
    or information, between filters and components. What we must keep in mind is that
    the flow is unidirectional, and the data should be stored until the filter can
    process it. This is shown in the following image, where the connector can be seen
    between the filters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/935a5bdf-989f-416b-88c6-15c36e458657.png)'
  prefs: []
  type: TYPE_IMG
- en: The Pipe-and-Filter architectural style is used to divide a larger process,
    task, or data into a sequence of small and independent steps (or filters) that
    are connected by pipes.
  prefs: []
  type: TYPE_NORMAL
- en: Boarding Pipe-and-Filter architectures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Based on the concepts that we recently introduced about Pipe-and-Filter in the
    field of enterprise applications, we use this kind of architecture in several
    scenarios in order to process a large amount of data (or large files) that trigger
    several steps (or tasks) that need to be processed. This architecture is highly
    beneficial when we need to perform a lot of transformations in the data.
  prefs: []
  type: TYPE_NORMAL
- en: To understand how Pipe-and-Filter works, we are going to review a classic example
    of processing payroll records. In this example, a message is being sent through
    a sequence of filters, where each filter processes the message in different transactions.
  prefs: []
  type: TYPE_NORMAL
- en: When we apply a Pipe-and-Filter approach, we decompose the whole process into
    a series of separate tasks that can be reused. Using these tasks, we can change
    the format of the received message, and then we can split it to execute separate
    transactions. As a benefit of doing this, we improve the performance, scalability,
    and reusability of the process.
  prefs: []
  type: TYPE_NORMAL
- en: 'This architectural style makes it possible to create a recursive process. In
    this case, a filter can be contained by itself. Inside of the process, we can
    include another Pipe-and-Filter sequence, as illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6e4ab34b-f85e-43cd-87fa-82e0320aa32b.png)'
  prefs: []
  type: TYPE_IMG
- en: In this case, every filter receives an input message via a pipe. The filter
    then processes the message and publishes the result to the next pipe. This repeatable
    process continues as many times as we need it to. We can add filters, accept or
    omit the received input, and reorder or rearrange the tasks into a new sequence,
    based on our business requirements. In the following section, we will detail the
    most common use cases for applying a Pipe-and-Filter architectural style.
  prefs: []
  type: TYPE_NORMAL
- en: Use cases for Pipe-and-Filter architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The most common use cases for Pipe-and-Filter architecture are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: To break a large process into several small and independent steps (filters)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To scale systems with processes that can be scaled independently with parallel
    processing, via several filters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To transform input or messages received
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To apply filtering in **Enterprise Service Bus** (**ESB**) components as an
    integration pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spring Batch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Spring Batch is a complete framework for creating a robust batch application
    ([https://projects.spring.io/spring-batch/](https://projects.spring.io/spring-batch/)).
    We can create reusable functions to process large volumes of data or tasks, commonly
    known as bulk processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Spring Batch provides many useful features, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Logging and tracing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transaction management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Job statistics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing the process; for example, through restarting jobs, skipping steps,
    and resource management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Administration Web Console
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This framework is designed to manage a high volume of data and achieve high-performance
    batch processes by using partition features. We will start with a simple project,
    to explain each principal component of Spring Batch.
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned in the Spring Batch documentation ([https://docs.spring.io/spring-batch/trunk/reference/html/spring-batch-intro.html](https://docs.spring.io/spring-batch/trunk/reference/html/spring-batch-intro.html)),
    the most common scenarios for using the framework are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Committing batch processes periodically
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concurrent batch processing for parallel processing a job
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Staged, enterprise message-driven processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Large parallel batch processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manual or scheduled restart after failures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sequential processing of dependent steps (with extensions to workflow-driven
    batches)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Partial processing: Skip records (for example, on rollback)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Whole-batch transaction: For cases with a small batch size or existing stored
    procedures/scripts'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In enterprise applications, the need to process millions of records (data) or
    read from a source is very common. This source may contain large files with several
    records (such as CSV or TXT files) or database tables. On each of these records,
    it is common to apply some business logic, execute validations or transformations,
    and finish the task, writing the result to another output format (for example,
    the database or file).
  prefs: []
  type: TYPE_NORMAL
- en: Spring Batch provides a complete framework to implement this kind of requirement,
    minimizing human interaction.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to review the basic concepts of Spring batch, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A job encapsulates the batch process, and must consist of one or more steps.
    Each step can run in sequence, run in parallel, or be partitioned.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A step is the sequential phase of a job.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: JobLauncher is in charge of taking a JobExecution of a job that is running.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: JobRepository is the metadata repository of the JobExecution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s create a simple example of a job using Spring Batch, in order to understand
    how it works. First, we will create a simple Java project and include the `spring-batch`
    dependency. For this, we will create a Spring Boot application using its initializer
    ([https://start.spring.io](https://start.spring.io)), as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/635128b7-d76c-44ac-abbf-4d58edf657c7.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that we added the dependency for Spring Batch. You can do this by typing
    `Spring Batch` into the search bar within the dependencies box, and clicking *Enter*.
    A green box with the word Batch in it will appear on the selected dependencies
    section. When this has been done, we will click on the Generate Project button.
  prefs: []
  type: TYPE_NORMAL
- en: 'The structure of the project will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ed6c7e59-d80d-4fc7-9cd5-5c241f5f6e0e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If we look at the dependencies section that was added by the initializer, we
    will see the `spring-batch` starter on the `pom.xml` file, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'If we are not using Spring Boot, we can add `spring-batch-core` explicitly,
    as a project dependency. The following shows how it looks using Maven:'
  prefs: []
  type: TYPE_NORMAL
- en: '`<dependencies>`'
  prefs: []
  type: TYPE_NORMAL
- en: '`  <dependency>`'
  prefs: []
  type: TYPE_NORMAL
- en: '`    <groupId>org.springframework.batch</groupId>`'
  prefs: []
  type: TYPE_NORMAL
- en: '`    <artifactId>spring-batch-core</artifactId>`'
  prefs: []
  type: TYPE_NORMAL
- en: '`    <version>4.0.1.RELEASE</version>`'
  prefs: []
  type: TYPE_NORMAL
- en: '`  </dependency>`'
  prefs: []
  type: TYPE_NORMAL
- en: '`</dependencies>`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, we can do this using Gradle, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`dependencies`'
  prefs: []
  type: TYPE_NORMAL
- en: '`{`'
  prefs: []
  type: TYPE_NORMAL
- en: '`  compile ''org.springframework.batch:spring-batch-core:4.0.1.RELEASE''`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: 'The project will need a data source; if we try to run the application without
    one, we will get a message in the console showing an error, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0bf0640b-3a2e-4f50-92a7-78ba3922defe.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To fix this issue, we are going to add a dependency as a part of the `pom.xml`
    file, to configure an embedded data source. For testing purposes, we are going
    to use HSQL ([http://hsqldb.org/](http://hsqldb.org/)), as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we need to add the `@EnabledBatchProcessing` and `@Configuration` annotations
    to the application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will set up our first job by using the `JobBuildFactory` class with
    one task process, based on Spring Batch, using the `StepBuilderFactory` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Job` method will then show that it is starting, which will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the `Job` has been created, we will add a new task (`Step`) to the `Job`,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code shows what the application class looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to check that everything is okay, we will run the application. To
    do this, we will execute the following on the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, we could build the application by running maven, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will run our recently built jar on the Terminal, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Don't forget that you will need to have installed Maven or Gradle before building
    or running the application and JDK 8.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we will see the following output in the console:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5ff94ceb-126a-4103-927b-bf3cee72df11.png)'
  prefs: []
  type: TYPE_IMG
- en: Pay attention to the console output. To do this, we run the job named `jobPackPub1`
    and execute the bean as `stepPackPub1`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will look at the components behind the following steps in more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: ItemReader represents the retrieval of the input for a step
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ItemProcessor represents the business processing of an item
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ItemWriter represents the output of a step
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram shows the big picture of Spring Batch''s main elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e1644f90-82c2-47be-b282-d8f417628856.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, we will complete our example by using an ItemReader, ItemProcessor, and
    an ItemWriter. By using and explaining these components, we will show you how Pipe-and-Filter
    architectures can be implemented using Spring Batch.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing pipes with Spring Batch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have illustrated what Spring Batch is, we are going to implement
    the payroll file processing use case (as defined in the previous section) through
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Coding a process that imports payroll data from a CSV spreadsheet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transforming the file tuples with a business class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storing the results in a database
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram illustrates our implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8ab5bee2-11ea-4098-9146-9eae1634813c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'First, we are going to create a new, clean project, using the Spring initializer
    ([https://start.spring.io](https://start.spring.io)), as we did in the previous
    section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ceeb8140-bd2f-4f36-ac75-ffcf3cd01e0c.png)'
  prefs: []
  type: TYPE_IMG
- en: Remember to add the `Batch` reference to our project, like we did in the previous
    example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Don''t forget to add a database driver as a dependency in the `pom.xml` file.
    For testing purposes, we are going to use HSQL ([http://hsqldb.org/](http://hsqldb.org/)),
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: If you want to use another database, you can refer to the detailed explanation
    available in the Spring Boot documentation ([https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-sql.html](https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-sql.html)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will create input data as a file and the output structure as a database
    table, as you can see in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/261d7e09-3198-4318-978e-f4422763d4bc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We are going to add a CSV file to our resource folder (`src/main/resources/payroll-data.csv`),
    with the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The structure of our project will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5b84cab7-de91-4058-b591-a7dbda6390ee.png)'
  prefs: []
  type: TYPE_IMG
- en: This spreadsheet contains the identification, currency, account number, account
    type, description of the transaction, beneficiary telephone, and beneficiary name.
    These are displayed on each row, separated by commas. This is a common pattern,
    which Spring handles out of the box.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now create the database structure where we will store the results processed
    by the payroll. We will add this to our resource folder (`src/main/resources/schema-all.sql`)
    with the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The file that we will create will follow this pattern name: `schema-@@platform@@.sql`.
    Spring Boot will run the SQL script during startup; this is the default behavior
    for all platforms.'
  prefs: []
  type: TYPE_NORMAL
- en: Up until this point, we have created the input data as a `.csv` file, as well
    as the output repository where it is going to store our complete payroll process.
    Consequently, we are now going to create the filters and use the default pipes
    that bring us Spring Batch.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we are going to create a class that represents our business data, with
    all of the fields that we are going to receive. We will name this `PayRollTo.java`
    (**Payroll Transfer Object**):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will create our filters, which are represented as processors in Spring
    Batch. Similar to how the framework gives us out-of-the-box behavior, we are first
    going to concentrate on translating our business classes that are intended to
    transform the input data, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/46caf14e-96c6-4720-b172-9d69f42c60cb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After including a representation of our file as a `PayrollTo` class on each
    row, we are going to need a filter that will transform each of our data files
    into uppercase. Using Spring Batch, we will create a processor that will transform
    the data files and then send the data to the following step. So, let''s create
    a `PayRollItemProcessor.java` object that implements the `org.springframework.batch.item.ItemProcessor<InputObject,
    OutputObjet>`interface, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: According to the API interface, we will receive an incoming `PayrollTo` object,
    after which we will transform it to an uppercase `PayrollTo` for the `firstLastName`
    and description properties.
  prefs: []
  type: TYPE_NORMAL
- en: It does not matter if the input object and the output object are different types.
    In many cases, a filter will receive one kind of message or data that needs a
    different kind of message or data for the next filter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we are going to create our Batch job and use some Spring Batch out-of-the-box features.
    For example, the **ItemReader** has a useful API to process files, and the **ItemWriter**
    can be used to specify how to store the produced data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a205ec9d-6a82-406d-952d-02dbeb251edb.png)'
  prefs: []
  type: TYPE_IMG
- en: Finally, we are going to connect all of our flow data using a job.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using Spring Batch, we need to concentrate on our business (like we did in
    the `PayRollItemProcessor.java` class), and then connect all of the pieces together,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: For a detailed explanation of what you can do with Spring Batch ItemReaders
    and ItemWriters, go to [https://docs.spring.io/spring-batch/trunk/reference/html/readersAndWriters.html](https://docs.spring.io/spring-batch/trunk/reference/html/readersAndWriters.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s review how the `Step` bean works, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: First, it configures the step to read the data in chunks of **10 records**,
    and after that, the step is configured with the corresponding `reader`, `processor`,
    and `writer` objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have now implemented all of the pipes and filters that we planned, as shown
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5c35ddfa-d6de-47dc-9200-e654e36f7119.png)'
  prefs: []
  type: TYPE_IMG
- en: Finally, we are going to add a listener, in order to check our processed payroll
    data. To do this, we will create a `JobCompletionPayRollListener.java` class that
    extends the class `JobExecutionListenerSupport` and implement the `afterJob(JobExecution
    jobExecution)`method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will review how many `insert` operations we process from our processed data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to check that everything is okay, we are going to execute the application,
    using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, we could build the application using maven, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will run the recently built `jar` on the Terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will see the following output on our console. This output represents
    the filter that has been implemented as an ItemProcessor that transforms the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/36450a60-601e-423c-8e43-3271e7dcd895.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can also see the verification of our process via the listener, implemented
    as a `JobExecutionListenerSupport`, which prints the results stored in the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/73968333-28d8-4d8c-b1cd-f91618785939.png)'
  prefs: []
  type: TYPE_IMG
- en: We can package the Spring Batch application in a WAR file, and then run a servlet
    container (like Tomcat) or any JEE application server (like Glassfish or JBoss).
    To package the `.jar` file into a WAR file, use `spring-boot-gradle-plugin` or `spring-boot-maven-plugin`.
    For Maven, you can refer to the Spring Boot documentation ([https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#build-tool-plugins-maven-packaging](https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#build-tool-plugins-maven-packaging)).
    For Gradle, you can refer to [https://docs.spring.io/spring-boot/docs/current/gradle-plugin/reference/html/#packaging-executable-wars](https://docs.spring.io/spring-boot/docs/current/gradle-plugin/reference/html/#packaging-executable-wars).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed the concept of Pipe-and-Filter architecture, the
    principal use cases of its implementation, and how to use it with enterprise applications.
    In addition, you learned how to implement the architecture using Spring Batch,
    along with how to manage different amounts of data and split the process into
    smaller tasks.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will review the importance of containerizing your applications.
  prefs: []
  type: TYPE_NORMAL
