- en: Designing Your Cloud-Native Application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we pause application development and take a step back to look
    at the bigger picture of designing cloud applications. As seen in the first chapter,
    applications in the cloud have more unique challenges than the traditional enterprise
    applications that we have been developing so far. Also, the business requirement
    of agility has to be met by not compromising on performance, stability, and resiliency.
    Hence, a look at the first principles becomes important.
  prefs: []
  type: TYPE_NORMAL
- en: In the first chapter, we had a look at the differences between cloud environments
    and traditional enterprises, and how the concepts of DevOps, 12-factor app, microservices,
    and ecosystems are important. Here, we will look at the various principles and
    techniques that enable us to design robust, scalable, and agile applications.
  prefs: []
  type: TYPE_NORMAL
- en: Some of the areas we will cover include the dominance of the REST, HTTP, and
    JSON for building APIs, the role of the API gateways, how to decouple applications,
    how to identify microservices, various microservice design guidelines, the role
    of the data architecture, and the role of security in designing the APIs.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Popularity of REST, HTTP, and JSON
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rise and popularity of the APIs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Role of API gateways
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decoupling—the need for smaller application boundaries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservice identifications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservice design guidelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservice patterns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Role of security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The trio – REST, HTTP, and JSON
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The web has made HTTP tremendously popular and is the de facto integration mechanism
    for accessing content on the internet. Interestingly, this technology was not
    hugely popular within applications that relied on native and binary protocols,
    such as RMI and CORBA for inter-application access.
  prefs: []
  type: TYPE_NORMAL
- en: When social consumer companies, such as Google, Amazon, Facebook, and Twitter,
    started publishing APIs to connect/integrate with their products, the de facto
    standard for integration across the web became HTTP/REST. Social consumer companies
    started investing in platforms for onboard developers to develop various applications
    leading to the proliferation of applications that relied on HTTP as the protocol.
  prefs: []
  type: TYPE_NORMAL
- en: The applications on the browser side are a mix of HTML and JavaScript. Information
    returned from the server or across other applications needs to be in a simple
    and usable format. JavaScript supports data manipulation, and the data format
    that it suited most is **JavaScript Object Notation** (**JSON**).
  prefs: []
  type: TYPE_NORMAL
- en: 'REST is a state representational style that provides a way to deal with interchange
    over HTTP. REST has a lot factors in its favor:'
  prefs: []
  type: TYPE_NORMAL
- en: Utilizes the HTTP protocol standard, giving it an immense leg up for anything
    and everything on WWW
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mechanism to isolate the access to entities (`GET`/`PUT`/`POST`/`DELETE`) while
    still utilizing the same HTTP request model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supports JSON as the data format
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'REST with JSON has become the dominant model over the SOAP/XML model. According
    to one statistic from ProgrammableWeb:'
  prefs: []
  type: TYPE_NORMAL
- en: 73% of the APIs on Programmable Web use REST. SOAP is far behind but is still
    represented in 17% of the APIs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s cover some high-level reasons why the REST/JSON model is favored over
    the SOAP/XML model of service development:'
  prefs: []
  type: TYPE_NORMAL
- en: SOAP model of contract first approach makes crafting web services difficult.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SOAP is complex compared to REST, giving a steeper learning curve as compared
    to REST.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: REST is lightweight compared to SOAP and does not tax the bandwidth as much
    as SOAP.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support for SOAP outside of the Java world is limited, relegating SOAP primarily
    to the enterprise world.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: XML parsing on the client side is memory and compute intensive, which does not
    lend well to the mobile world.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: XML Schema/markup provides structure definitions and validation models but at
    the expense of additional parsing. JSON has a loose syntax allowing rapid iterations
    on the data model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Today, the reality is REST/JSON has been adopted as the standard for integration
    across programming languages providing an easy and simple way to integrate APIs
    over the internet.
  prefs: []
  type: TYPE_NORMAL
- en: Rise and popularity of the APIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An **Application Programming Interface** (**API**) provides a standard interface
    or contract to consume its services over the internet. The API defines the structure
    of the input and output and remains constant over the life of an API version.
  prefs: []
  type: TYPE_NORMAL
- en: APIs are the contract between the client layer and the enterprise. They are
    consumer-oriented, that is, designed by the client, and they abstract the service
    implementation details from the client.
  prefs: []
  type: TYPE_NORMAL
- en: Coming back to the advent of social consumer companies, creating new applications
    meant not starting from scratch. For example, if my application needs to use geographical
    maps, I can make use of the Google Map APIs and build my application on top of
    that. Similarly, instead of building my own authentication model, I can make use
    of OAuth and use Google, Facebook, or Twitter as some of the OAuth providers.
  prefs: []
  type: TYPE_NORMAL
- en: This entire model of making a repeatable but often complex functionality available
    as a reusable service led to a model where the developer started building the
    applications using these pre-existing APIs, which in turn led to increased developer
    productivity and evolution of the modern day applications or mobile applications
    economy.
  prefs: []
  type: TYPE_NORMAL
- en: Companies started to look to see if they could monetize the APIs, which meant
    multiple companies were writing/publishing APIs that provided similar functionalities.
    This led to the democratization of the APIs allowing anyone and everyone access
    to features/functions.
  prefs: []
  type: TYPE_NORMAL
- en: This whole democratization of the API meant, suddenly, every process or functionality
    could be provided as a set of APIs that could be orchestrated or choreographed
    to build new features or functions. What took months or years earlier, now only
    takes weeks or days. All this productivity means shorter development cycles, allowing
    rapid iteration to provide new and innovative features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Today, all kinds of APIs are available: from social companies such as Facebook,
    Google, and Twitter to enterprises such as Salesforce, NetSuite, and PaaS/IaaS
    providers, such as AWS, Azure, **Google Cloud Engine** (**GCE**), and so on, that
    all provide functionality from provisioning a VM to a database instance, to AI
    providers such as Watson, AWS AI, and Azure ML.'
  prefs: []
  type: TYPE_NORMAL
- en: Role of API gateways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An API gateway is a singular interface that handles all the incoming requests
    before redirecting to the internal servers. An API gateway typically provides
    the following functions:'
  prefs: []
  type: TYPE_NORMAL
- en: Routes the incoming traffic to the appropriate service hosted with the provider's
    data center/cloud. Provides a reverse proxy model to limit the exposure of various
    APIs and services hosted within the provider's data center/cloud.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filters all the incoming traffic from all kind of channels—web, mobile, and
    so on.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implements security mechanisms (such as OAuth) to authenticate and log the service
    usage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provides ability to throttle and limit traffic to certain services.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transforms data between the service consumer and provider.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Provides one or more APIs that map to an underlying service provider. For example,
    for different kind of consumers—mobile, web, paid service, or a free service,
    the same underlying service can be split into multiple custom APIs that are exposed
    to a different set of consumers, so that the consumer sees only the features it
    needs:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/5215f408-cc6f-4926-ad6a-70890fc44f04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Benefits of an API gateway
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Use of API gateways provides the following benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Separation of concerns**: Insulates the microservice providers from the service
    consumers on the application side. This allows the separation of the application
    tier from the service requesting clients.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consumer oriented**: API gateways provide a unified hub for a large number
    of APIs and microservices. This allows the consumer to focus on API utility instead
    of locating where a service is hosted, managing service request limits, security,
    and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**API oriented**: Provides an optimum API based on the type of the client and
    required protocols.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Orchestration**: Provides the ability to orchestrate multiple services calls
    into one API call, which in turn simplifies the logic for a client. Now, instead
    of calling multiple services, it can invoke one API. Fewer requests means less
    invocation overhead and improve the consumer experience overall. An API gateway
    is essential for mobile applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitor**: An API gateway also provides the ability to monitor API invocations,
    which in turn allows enterprises to evaluate the success of APIs and their usage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Besides the overall benefits, API gateways add more pieces to the overall puzzle.
    Meaning more infrastructure to manage, more configurations to manage, more points
    of failure, and additional hops to the requests. So, unless the benefits outweigh
    the drawbacks, use of API gateways needs be carefully scrutinized for the business
    requirements and benefits.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will see the process of breaking down the application functionalities
    as a set of APIs or microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Application decoupling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The traditional model of application development, where all the features and
    functionalities were bundled in a large package called a monolithic application,
    is becoming less popular for multiple reasons. Monolith applications take on too
    many responsibilities in the form of function and logic. It is this characteristic
    which leaves them with high coupling and low cohesion. The reuse factor in monoliths
    tends to be low since one part of the functionality cannot be separated from the
    rest of the function and logic.
  prefs: []
  type: TYPE_NORMAL
- en: As we start breaking down the monolith functionality or even designing a new
    application, the focus needs to be on defining the service boundaries. Defining
    the right set of service boundaries and their related interactions is what leads
    to high cohesion and low coupling models.
  prefs: []
  type: TYPE_NORMAL
- en: The question becomes, what is the basis on which the application should be decoupled
    into services and defined service boundaries?
  prefs: []
  type: TYPE_NORMAL
- en: Bounded context/domain-driven design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As part of the application design, the business domain needs to be broken down
    into smaller subdomains or business capabilities. We need to carefully examine
    the business entities and their attributes to define service boundaries. For example,
    in the case of customer ID entity, the address of the customer might be integral
    to the customer. Within the context of the application, address maintenance might
    be a separate activity and might need to be handled separately. Similarly, customer
    preferences or shopping habits might be required for personalization. In this
    case, the personalization engine is more interested in this set of attributes.
  prefs: []
  type: TYPE_NORMAL
- en: Should we be slapping together one big customer service having all kind of attributes
    or can it be divided based on the perspectives derived from the business? These
    different perspectives are what led to the definition of bounded context as part
    of the domain-driven design.
  prefs: []
  type: TYPE_NORMAL
- en: 'The bounded context is a domain-driven design paradigm that helps to add a
    seam and create service groups. Bounded contexts work in solution-space to indicate
    that the services are related and belong to a common functional domain. It is
    built by one team that works with one business unit as per Inverse Conway''s law.
    A bounded context may communicate with the other services/business capabilities
    through:'
  prefs: []
  type: TYPE_NORMAL
- en: Exposing internal APIs or services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Emitting events on the Event Bus
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A bounded context may have its own data store common to services or adopt a
    data store per service paradigm.
  prefs: []
  type: TYPE_NORMAL
- en: Each bounded context has a life of its own and forms a product. Teams are organized
    around these bounded contexts and they take the full responsibility of the full
    stack implementation of the services. The teams are cross-functional and bring
    skills from development, testing, user experience, database, deployment, and project
    management. Each product might be split into smaller sets of services that communicate
    asynchronously with each other. Remember, the focus is not on a set of functionalities
    but rather on business capability.
  prefs: []
  type: TYPE_NORMAL
- en: We start building our services around business capabilities. The service owns
    its business data and functionality. The service is the master of such data, and
    other services cannot own any of this service data.
  prefs: []
  type: TYPE_NORMAL
- en: Classification into up/downstream services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another way to break down the application systems is to categorize them by upstream
    and downstream data flow models. Core entities in the system comprise the upstream
    services. These upstream services than raise events that are subscribed by the
    downstream services to augment their functionality. This is aimed at decoupling
    the systems and help improve the overall business agility. This works well with
    Reactive, also known as event-driven, architecture concepts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a simplified view of an e-commerce application, where the core
    entities are **CUSTOMER** and **PRODUCT**. The **ORDER** service depends on information
    about customers and products from the core entities. Next, we are building services
    that provide **RECOMMENDATION** and **PERSONALIZATION** services to the customer.
    The **RECOMMENDATION** and **PERSONALIZATION** services depend upon data from
    the core entities—**CUSTOMER**, **PRODUCT**, and **ORDER**. When there is a change
    to any of the core entities, changes are published. These changes are picked up
    by the **RECOMMENDATION** and **PERSONALIZATION** services, where they augment
    this data with additional attributes to provide relevant services. The **RECOMMENDATION**
    and **PERSONALIZATION** services downstream these services:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6188e3d5-a83d-41a7-a81e-9ae52fde7529.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This model of classifying the business capabilities into **UPSTREAM** and **DOWNSTREAM**
    help define the dependency relationships between services and change the impact
    of any upstream services on the downstream services.
  prefs: []
  type: TYPE_NORMAL
- en: Business events
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As the system evolves, the services will start aggregating into natural allies.
    This means finding out whether the services are depending on a similar set of
    data elements or providing overlapping/side-kick functionality, and can potentially
    be part of the same bounded context.
  prefs: []
  type: TYPE_NORMAL
- en: Services within the bounded context working within the same domain might need
    to rely on the master for accurate functioning. This might mean, some of the master
    service data attributes need to be made available to the associated bounded context
    services. For example, in our previous example, we talked of customer preferences.
    Now, these preferences might need to be mapped to the location (address) of the
    customer. In this case, should the customer preference call the customer address
    service every time to build the preferences or can it copy the relevant attributes
    to its own domain? Without duplication of data, the two services start getting
    coupled tightly, leading to a two-way communication model. To break this tight
    coupling, we allow the customer preferences service to cache or duplicate the
    relevant customer attributes using the events. This asynchronous model breaks
    the temporal tight coupling between the services. Whenever there is a change of
    customer address, the service publishes a business event for the requisite change.
    The change is subscribed by the customer preferences, which picks up the change
    to update its preferences model.
  prefs: []
  type: TYPE_NORMAL
- en: 'This asynchronous model allows us to make sure:'
  prefs: []
  type: TYPE_NORMAL
- en: Ownership of data is still clear. Any change to data is declared to the dependent
    services. The dependent services are allowed to hold or duplicate data, but not
    change the local copy unless the master copy is updated (golden source principle).
    The dependent services store only the subset of data that is required and functionally
    relevant (need-to-know principle).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asynchronous business events lead to low coupling between services. Core service
    changes result in an event. Events travel downstream to interested dependent services.
    The only dependency is the format of the business event published.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Downstream services follow the eventual consistency principle; all business
    events are stored in a sequential manner to construct/state a later time (event
    sourcing/CQRS). Query models can be different from the system of record.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asynchronous models of business events also promote choreography over orchestration,
    leading to loosely coupled systems/services.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At times, when teams start on a new product, an upfront definition of bounded
    context or services decomposition might not be possible. So, teams start building
    the application as a monolithic application by exposing its functionality as a
    set of services. As the team implements more stories, they can identify pieces
    of functionality that are changing at a fast pace (typically experience or channel
    services) versus slow changing pieces (typically core services or entity services).
  prefs: []
  type: TYPE_NORMAL
- en: The team can start putting the services into two categories—experience and system
    services. System services can further be grouped together around entities and
    interrelations. Experience services are mapped to the customer journeys. Teams
    will typically have sprints just to clean/refactor the code to clear the technical
    debt that accumulates with every cycle.
  prefs: []
  type: TYPE_NORMAL
- en: So, the next question is, what identifies a service as a microservice?
  prefs: []
  type: TYPE_NORMAL
- en: Microservice identification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The name microservice does not necessarily mean that the service has to be
    small in size. But it has the following characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Single responsibility principle**: This is the core design principle of microservices.
    They should do one business unit of a task and do it completely. If there is low
    coupling, the services will be easier to modify and deploy or even replace altogether.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Granular**: Microservice granularity is contained within the intersection
    of a single functional domain, a single data domain and its immediate dependencies,
    a self-sufficient packaging, and a technology domain.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bounded**: A service should have access to resources within its bounded context,
    which is managed by the same team. However, it should not access resources of
    other modules, such as cache and databases, directly. If a service needs to access
    other modules it should do so through an internal API or service layer. This helps
    reduce coupling and promotes agility.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Independent**: Each microservice is developed, tested, and deployed independently,
    in its own source. It can use third-party or shared libraries.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Differences between microservices and service-oriented architecture (SOA)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are the differences between microservices and **service-oriented architecture**
    (**SOA**):'
  prefs: []
  type: TYPE_NORMAL
- en: A service executes the entire business unit of work. For example, if a service
    requires customer or product data, it is preferable to store it within the service
    data stores. Typically, there is no need to go to a customer service for getting
    a customer record through ESB.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A service has its own private database or a database that is shared only in
    its bounded context and can store the information required to service the business
    unit of work.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A service is a smart endpoint and typically exposes a REST interface with a
    contract definition in Swagger or similar repository. Some of the services that
    are consumed by other divisions or clients are exposed through an API platform.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service granularity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are the types of services:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Atomic or system services**: These are the services that do a unit level
    of work and are enough to service the request by either referring to a database
    or a downstream source.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Composite or process services**: These services depend on the coordination
    between two or more atomic services. Typically, composite microservices are discouraged
    unless the business case already involves using existing atomic services. An example
    is a credit card payment from a savings account that calls two services, one to
    debit the savings account, and an other to credit the card account. Composite
    microservices also introduce inherent complexity such as state management and
    transactions that are difficult in a distributed scenario.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Experience services**: These services are tied to the customer journey and
    are deployed at the edge of the infrastructure. These services handle requests
    from the mobile and web applications. These services are exposed through a reverse
    proxy using tools such as API gateways.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservice design guidelines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The whole notion of microservices is about the separation of concerns. This
    requires a logical and architectural separation between the services with different
    responsibilities. Here are a few guidelines to design the microservices.
  prefs: []
  type: TYPE_NORMAL
- en: 'These guidelines are in line with the 12-factor applications guidelines given
    by Heroku engineers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Lightweight**: Microservices have to be lightweight in order to facilitate
    smaller memory footprints and faster startup times. This facilitates faster MTTR,
    and allows for services to be deployed on smaller runtime instances, hence horizontally
    scaling better. Compared to heavy runtime times, such as application servers,
    smaller runtimes such as Tomcat, Netty, Node.js, and Undertow are more suited.
    Also, the services should exchange data in lightweight text formats, such as JSON,
    or binary formats, such as Avro, Thrift, or Protocol Buffers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reactive**: This is applicable to services with highly concurrent loads or
    slightly longer response times. Typical server implementations block threads to
    execute imperative programming styles. As microservices could depend on other
    microservices or I/O resources such as a database, blocking threads could increase
    operating system overheads. The Reactive style operates on non-blocking I/O, uses
    call back handlers, and reacts to events. This does not block threads and as a
    result, increases the scalability and load handling characteristics of the microservices
    much better. Database drivers have started supporting reactive paradigms, for
    example, MongoDB Reactive Streams Java Driver.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stateless**: Stateless services scale better and start faster as there is
    no state to be stored on disk on shutdown or activated on start-up. They are also
    more resilient, as termination of a service will not result in a loss of data.
    Being stateless is also a step towards being lightweight. If a state is required,
    a service can delegate state storage to a high speed persistent (key value) store,
    or hold it in distributed caches.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Atomic**: This is the core design principle of microservices. They should
    be easy to change, test, and deploy. All these can be achieved if the services
    are reasonably small and do the smallest business unit of work that can be done
    independently. If there is low coupling, the services will be easier to modify
    and independently deploy. Composite microservices may be required on a need basis
    but should be limited in design.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Externalized configuration**: Typical application properties and configurations
    were traditionally managed as configuration files. Given the multiple and large
    deployments of microservices, this practice will start getting cumbersome, as
    the scale of the services increase. Hence, it is better to externalize the configurations
    in the configuration server, so that it can be maintained in a hierarchical structure
    per environment. Features such as hot changes can also be easier to reflect many
    services at once.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consistent**: Services should be written in a consistent style as per the
    coding standards and naming convention guidelines. Common concerns such as serialization,
    REST, exception handling, logging, configuration, property access, metering, monitoring,
    provisioning, validations, and data access should be consistently done through
    reusable assets, annotations, and so on. It should be easier for another developer
    from the same team to understand the intent and operation of the service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resilient**: Services should handle exceptions arising from technical reasons
    (connectivity, runtime), and business reasons (invalid inputs) and not crash.
    They should use patterns such as timeouts and circuit breakers to ensure that
    the failures are handled carefully.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Good citizens**: Report their usage statistics, number of times accessed,
    average response times, and so on through JMX API, and/or publish it through libraries
    to central monitoring infrastructures, log audit, error, and business events in
    the standards prescribed. Expose their condition through health check interfaces,
    for example, as done by Spring Actuator.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Versioned**: Microservices may need to support multiple versions for different
    clients, till all clients migrate to higher versions. Hence the deployments and
    URL should support semantic versioning, that is, X.X.X.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In addition, microservices will need to leverage additional capabilities that
    are typically built at an enterprise level such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dynamic service registry**: Microservice registers itself with a service
    registry when up.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Log aggregation**: The logs generated by a microservice can be aggregated
    for central analysis and troubleshooting. The log aggregation is a separate infrastructure
    and typically built as an async model. Products such as Splunk and ELK Stack in
    conjunction with event streams such as Kafka are used to build/deploy the log
    aggregation systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**External configuration**: The microservice can get the parameters and properties
    from an external configuration such as Consul and Zookeeper to initialize and
    run.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Provisioning and auto-scaling**: The service is automatically started by
    a PaaS environment if it detects a need to start an additional instance based
    on incoming load, some services failing, or not responding in time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**API gateway**: A microservice interface can be exposed to the clients or
    other divisions through an API gateway that provides abstraction, security, throttling,
    and service aggregation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We cover all the service design guidelines in subsequent chapters as we start
    building and deploying the services.
  prefs: []
  type: TYPE_NORMAL
- en: Design and deployment patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you start designing the applications, you need to be aware of the various
    service design and integration patterns.
  prefs: []
  type: TYPE_NORMAL
- en: Design patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The microservice design patterns can be categorized into multiple categories
    depending upon the problem being solved. The most common categories and the relevant
    patterns are discussed in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Content aggregation patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With microservices and bounded context, there is an additional responsibility
    of content aggregation. A client may need information that spans multiple domains
    or business areas (or in solution terms, the bounded contexts). The content required
    may not be available with one service. These patterns help identify and model
    the experience services category mostly. Hence there are various patterns for
    aggregation that can be applied.
  prefs: []
  type: TYPE_NORMAL
- en: Aggregation by client
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Aggregation at the last mile. This applies to web browsers or a reasonable
    *processing capable* user interface, which is showing content from various domains.
    This pattern is typically used in the home page that aggregates various subject
    areas. Also, it''s the pattern popularly used by Amazon:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b012f926-e78e-4ed4-852f-7da40ffff847.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**Benefits**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The benefits of using the aggregation by the client pattern are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Decoupled approach at the services layer. Easier for agility and maintainability
    at each individual service.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Faster perceived performance at the UI layer, since the requests, can run in
    parallel to populate the various areas on the screen. More enhanced when there
    is a higher bandwidth available to fetch data in parallel.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Trade-offs**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The trade-offs associated with the aggregation by the client pattern are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Sophisticated user interface processing capabilities, such as Ajax and single-page
    application required
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The knowledge of aggregation is exposed at the UI layer, hence if the similar
    output was given as a dataset to a third-party, aggregation would be required
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: API aggregation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Aggregation at the gates. This applies to mobile or third-party use cases that
    do not want to know the details of the aggregation and instead would want to expect
    one data structure over a single request. The API gateways are designed to do
    this aggregation and then expose a unified service to the client. The API gateways
    can also select to eliminate any data sections in the aggregate service if it
    is not required to be shown during content aggregation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6350e60c-8796-421c-854a-487e27090da7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**Benefits**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The benefits of using the API aggregation pattern are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The individual service details are abstracted from the client by the API gateway.
    Hence it gives the flexibility to change the services internally without affecting
    the client tier.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Better in bandwidth constrained scenarios where running parallel HTTP requests
    may not be a good idea.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Better in UI processing constrained scenarios where processing power might not
    be enough for concurrent page generation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Trade-offs**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The trade-offs associated with the API aggregation pattern are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Where there is sufficient bandwidth, the latency of this option is higher than
    the aggregation by the client. This is because the API gateway waits for all the
    content to be aggregated before sending the data out to the client.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservice aggregation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Aggregation at the business tier. In this approach, a microservice aggregates
    the responses from the various constituent microservices. This pattern is useful
    if there is any real-time business logic to be applied while aggregating data.
    For example, showing the total value of customer holdings across various businesses:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a298f28-adc3-4fa9-890d-e21915cb946c.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**Benefits**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The benefits of using the microservice aggregation pattern are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Finer control on the aggregation. Also, there is a possibility of incorporating
    the business logic based on aggregated data. Thus, offering richer content aggregation
    capabilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lower dependency on API gateway capabilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Trade-offs**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The trade-offs associated with the microservice aggregation pattern are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Lower latency and more code, as there is an additional hop introduced due to
    an additional step.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More chances of failure or making mistakes. Parallel aggregation from microservices
    will need sophisticated code such as reactive or call back mechanisms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Database aggregation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Aggregation at the data tier. In this approach, data is pre-aggregated into
    an **operational data store** (**ODS**) typically a document database. This approach
    is useful for scenarios where there is additional business inference on the aggregated
    data that is difficult to compute in real time through a microservice, and hence
    can be pre-computed by an analytical engine:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bf820d8a-153c-4fe8-b19b-349ca501f6e3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**Benefits**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The benefits of using the database aggregation pattern are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Additional enrichment of data by analytical jobs is possible. For example, in
    a customer 360° view, based on the customer portfolio aggregated in the ODS, additional
    analytics can be applied for **next-best-action** (**NBA**) scenarios.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More flexible and capable as compared to the earlier approaches, and finer control
    on the data model can be exercised.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Trade-offs**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The trade-offs associated with the database aggregation pattern are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Higher complexity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data duplication and more data storage requirements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additional ETL or **change data capture** (**CDC**) tools required to send the
    data from the system of a record to a central ODS store
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Coordination patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ideally, microservices should be capable of doing a business unit of work. However,
    in some business scenarios, microservices have to leverage other services as a
    dependency, or as a composition. For example, consider a credit card payment that
    first debits a savings account and then credits a card account. In this case,
    the two underlying services, such as debit and credit, could be exposed by the
    respective savings account and credit card domains and coordination is required
    between them.
  prefs: []
  type: TYPE_NORMAL
- en: Business process management (BPM)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Complex coordination that involves long-running processes are better done by
    BPM. An enterprise might already have a BPM product. However, BPM might be overkill
    for simple two- or three-step coordination.
  prefs: []
  type: TYPE_NORMAL
- en: Composite services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The guideline is to use composite services for low complexity (or simple) coordination
    that is high in volume. Such coordination can be referred to as microflows for
    the rest of the discussion.
  prefs: []
  type: TYPE_NORMAL
- en: Why composite services?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In microservices architecture, the implementation of the service definition
    is done by smaller deployable units instead of large monolith applications that
    run in application servers. This makes the services easier to write, faster to
    change and test, and quicker to deploy. But this also creates a challenge for
    microflows that span two or more microservices, perhaps across multiple bounded
    contexts. In a monolith application, such microflows could be coordinated as a
    single transaction across two modules deployed in a single deployable unit. In
    microservices architecture, distributed transactions are discouraged and hence,
    microflows have to be solved using a composition approach.
  prefs: []
  type: TYPE_NORMAL
- en: Capabilities for microservices coordination
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section lists the capabilities that the composite services require:'
  prefs: []
  type: TYPE_NORMAL
- en: '**State management**: Often the state manager component is required to manage
    the output state of the services that it is coordinating. This state will need
    to be held in a persistent store that is immune to **server-side state management**
    (**SSM**) failure. Another SSM instance should be able to retrieve the state and
    start where it left off.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transaction control**: Transaction boundaries are affected by microservices.
    Two separate function calls to two methods in a single transaction now become
    two separate service calls through a composite service. There are two approaches
    to handle this scenario.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distributed transactions**: These support the two-phase commit protocol.
    They are not scalable, increase latency and deadlocking scenarios, and need expensive
    products and infrastructure to support them. They may not be supported over selected
    protocols, such as REST or messaging. The benefit of this style is that the system
    is always in a consistent state.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compensating transactions**: Where the transaction control is functionally
    enforced by running functionally reverse transactions instead of trying to roll
    back to an earlier transaction. This is a more decoupled, and hence scalable,
    approach.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We would recommend compensating transactions over distributed transactions due
    to simplification in the technical product requirements.
  prefs: []
  type: TYPE_NORMAL
- en: '**Post service call coordination**: Atomic service calls can result in success,
    that is, when the constituent services have finished their work successfully;
    or a failure, when either of the coordination services has either not responded
    or failed in processing due to a technical or functional error. The composite
    service will need to get the response of the completed services and decide on
    the next step of action.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Timeout handling**: Initiate a timer when starting a microflow. If the services
    do not respond in a particular time from starting the microflow, then raise an
    event to send to the event bus.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Configurability**: Multiple instances of the SSM component will run to cater
    for various microflows. In each of the microflows, the service coordination, timer,
    and actions will differ. Hence, it is important to provide a framework that can
    have parameterized configuration of the timers, compensation transactions, and
    post-processing actions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Coordination models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will discuss the following coordination styles of composite service micro
    flows.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous parallel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A composite service initiates the service calls asynchronously to the constituent
    atomic services and then listens to the service response. If either services fails,
    it sends a compensating transaction to the other service.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is similar to the Scatter-Gather or Composed Message Processor patterns
    of the EIP:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e0536935-ad8e-4c6e-81b2-f071cd6a3f31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Asynchronous sequential
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In pipeline processing, composite services send messages to atomic services
    sequentially. It waits for the previous service to return success before calling
    the next service. If anyone service fails, then the composite service sends the
    compensating transaction to previously successful services. This is similar to
    the Process Manager pattern in the EIP:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/70b88b81-c1d8-4343-9436-a0291742dc0c.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Orchestration using request/response
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Similar to the preceding section, but in request/response and sync fashion instead
    of async messaging.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3730ee35-9058-4174-931c-36a88e596599.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Collapsing the microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An option for when there seems to be a coupling between composite and its constituent
    microservice collapsing the services, and run as a single component. For example,
    transferring funds can be implemented by an account service, with an additional
    method `transferFunds` accepting `fromAcc`, `toAcc`, and the fund amount. It can
    then issue the `debit` and `credit` method calls as part of a single transaction.
    However, this approach needs to be decided after due consideration. The drawbacks
    include coupling deploying of debit and credit services of the credit card and
    savings domain:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eb3a11c8-fbb0-4660-b108-c5e79c1cbfcc.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Deployment patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices attempt to solve monolith problems such as dependencies, and achieve
    agility by having separate deployable units. We can deploy the microservices on
    the target runtime in various styles. The options are described in the order of
    increasing isolation (good) and cost (bad).
  prefs: []
  type: TYPE_NORMAL
- en: Multiple services per WAR file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Although development might be in a microservice style (separate code base for
    services, different teams working on different services), the deployment essentially
    follows the monolith style:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f48fa51a-45b9-43f8-8dd5-9ce28884b1af.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Benefits and trade-offs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The only benefit compared to a complete monolith style is that due to separate
    code bases and lesser dependencies, there is lower dependency on common code elements.
    However, it does not offer any runtime isolation between service behavior, and
    hence does not have the true benefits of a microservice architecture model such
    as independent releases, scaling individual services, or limiting the impact of
    one service problem on the other services.
  prefs: []
  type: TYPE_NORMAL
- en: Suitability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are not many scenarios in which this is useful as it does not offer runtime
    isolation. However, it might be an intermediary step toward releasing the full
    separation.
  prefs: []
  type: TYPE_NORMAL
- en: Service per WAR/EAR
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This model separates the build process for the services to create separate
    `.war`/`.ear` files per service. However, they end up being deployed to the same
    web container or application server:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c52a556c-117e-49b5-9ab9-f38453782e33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Benefits and trade-offs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This style takes the isolation a step further, by separating the build process
    for each service to create a deployable unit. However, since they are deployed
    on the same web container or application server, they share the same process.
    Hence, there is no runtime isolation between the services.
  prefs: []
  type: TYPE_NORMAL
- en: Suitability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Some teams might experience constraints on target deployment to use the same
    software or hardware that they were using in monolith style development. In this
    case, this deployment style is suitable, as the teams can still do independent
    development without getting under each other's feet, but will have to coordinate
    the releases with other teams during deployment to their traditional production
    infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Service per process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This style uses the concept of the fat JAR discussed earlier to include the
    application server or web container as part of the deployment unit. Thus, the
    target runtime environment only needs a JVM to run the service. Dropwizard and
    Spring Boot frameworks encourage this type of deployment build. We have also seen
    an example of creating such a deployment unit in [Chapter 2](8a0a7cae-4aaa-460d-a760-59d0ffde9b48.xhtml),
    *Writing Your First Cloud-Native Application*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c8fe032a-2988-45d1-a845-256cfb2f8eba.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Benefits and trade-offs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The benefits and trade-offs associated with the service per process style are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: This approach helps in separating the runtime processes on which the services
    run. Thus, it creates an isolation between the services, so that a memory leak
    or fat exception in one process does not affect the other services to some extent.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This allows for selective scaling of service, by allowing more deployments of
    a service compared to other services on the existing hardware.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It also gives the freedom to teams of using a different application server/web
    container based on specific use cases or the needs of the team.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, it cannot prevent any one service from hogging system resources (such
    as CPU, I/O, and memory) that can affect the performance of the other services.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It also reduces the control over the runtime of the operations team, as there
    is no central web container or application server present in this model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This style requires good governance to limit variability in the deployment estate
    and having substantial use cases to support the divergence.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suitability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This style offers the best compromise for teams that are constrained to using
    their existing production infrastructure and do not have Docker containers or
    small VM configurations in place yet.
  prefs: []
  type: TYPE_NORMAL
- en: Service per Docker container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this style, a service deploys as a fat JAR in a Docker container, which
    has the necessary prerequisites, such as JVM. It takes the isolation a step higher
    than that provided by the Linux container technology:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7f1a6c81-2592-44fa-8dc1-e9c7150e9978.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Benefits and trade-offs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The benefits and trade-offs associated with the service per Docker container
    style are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The Linux container technology limits the CPU and memory consumption of the
    service in addition to providing networking and file access isolation. This level
    of isolation is sufficient for many services.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Containers are fast to start up from an image. Hence, new containers based on
    an application or service image can be spawned very quickly to address the fluctuating
    demands of the application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Containers can be orchestrated through various orchestration mechanisms, such
    as Kubernetes, Swarm, and DC/OS so that the entire application configuration can
    be created automatically based on a well-defined application blueprint.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As in the previous style, it is possible to run a variety of service technologies
    within a container. For example, running Node.js services in addition to Java
    services is possible as the container image would be at OS level and hence can
    be started seamlessly by the orchestration framework.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Containers have much lower overheads compared to the virtual machines in terms
    of resource requirements, as they are more lightweight. Hence, they are cheaper
    compared to running each service in its own virtual machine.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, containers reuse the kernel of the host system. Hence, it is not possible
    to run workloads demanding different operating systems, for example, Windows or
    Solaris on container technology.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suitability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This style of deployment is a good balance of isolation and cost. It is the
    recommended style and suitable for most service deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Service per VM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this style, the fat JAR is deployed directly on the VM, as in the *Service
    per process* section. However, here there is only one service deployed per VM.
    This ensures a complete isolation of the service from the other services.
  prefs: []
  type: TYPE_NORMAL
- en: 'The deployment is automated through tools such as Chef and Puppet, that can
    take a base image (such as having Java installed) and then run through a series
    of steps to install the application JAR and other utilities on the VM:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/297b14b8-8750-453a-9710-d2145cab55a1.png)'
  prefs: []
  type: TYPE_IMG
- en: Benefits and trade-offs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The benefits and trade-offs associated with the service per VM style are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: If there are any use cases that require a complete OS level isolation, then
    this style is suitable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This style also allows us to mix completely different workloads, such as Linux,
    Windows and Solaris, together on the VMs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, this style is more resource-intensive and slower to start up as compared
    to the previous style, as VMs include a complete guest OS start-up
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a result, it is less cost efficient as compared to earlier options
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suitability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This style of deployment is tilting toward the increased cost. It is the recommended
    style, and suitable for cloud image based deployments such as creating **Amazon
    Machine Images** (**AMI**).
  prefs: []
  type: TYPE_NORMAL
- en: Service per host
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This takes the isolation from the hypervisor (for VMs) to the hardware level
    by deploying the services on different physical hosts. The concept of microservers
    or specialized appliances can be used for this purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Benefits and trade-offs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The benefits and trade-offs associated with the service per host style are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The hardware (such as processors, memory, and I/O) can be exactly tuned to the
    use case of the service. Intel offers a range of microservers that are tuned for
    specific tasks such as graphics processing, web content serving, and so on.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A very high density of components can be achieved in this solution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This style of deployment is for very few use cases that would benefit from hardware-level
    isolation or specialized hardware needs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is a maturing technology and hence not many data center cloud providers
    offer it yet. However, it will have matured by the time this book gets published.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suitability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This style of deployment is extremely rare, as very few use cases require this
    high level of isolation or specialized hardware requirements. Appliances for web
    content or graphics processing are a few, specialized use cases that will benefit
    from this deployment style.
  prefs: []
  type: TYPE_NORMAL
- en: Release patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Following are the different release patterns used in services:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Fat JAR**: As discussed in [Chapter 2](8a0a7cae-4aaa-460d-a760-59d0ffde9b48.xhtml),
    *Writing Your First Cloud-Native Application* the fat JAR helps to bundle the
    web container with the deployable. This ensures that there is no inconsistency
    between the versions of the deployment in the development, test, and production
    environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Blue-green deployment**: This pattern suggests maintaining two production
    environments that are identical. A new release goes to one of the unused environments,
    say green. The switch is done from a router to send traffic to the green deployment.
    If successful, the green environment becomes the new production environment and
    the blue environment can be made inactive. If there is an issue, rollback is easier.
    The next cycle happens in reverse, with deployment to the blue environment, thus
    alternating between the two environments. There are a few challenges such as databases
    upgrades. For async microservices, this technique can be used to release one microservice
    or a set of microservices with different input queues. The configuration loaded
    from connection parameters decides to drop the request message in one queue versus
    the other.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Semantic versioning**: Semantic versioning is about releasing software with
    version numbers, the way they change the meaning of the underlying code, and what
    has been modified from one version to the next. Refer to [http://semver.org/](http://semver.org/)
    for more details. In async microservices, a similar strategy of using an input
    queue per microservice applies. However, in this case, both services are active,
    one for the legacy and one with the new changes. Based on the request, content-based
    routing pattern can be used to switch the queue to send the request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Canary release**: This pattern is used to introduce a change to a small set
    of users using a routing logic that selects a group of customers for a new service.
    In terms of asynchronous services, this can be handled by two sets of input queues,
    and the redirection logic now decides the queue to drop the request message to.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Immutable server / immutable delivery**: Immutable Server and Immutable Delivery
    are related. The intent is to automatically build the server, (VM or container)
    and its software and applications from the configuration management repository.
    Once built, it is not changed, not even when moving from one environment to other.
    Only the configuration parameters are injected via the environment, JNDI, or separate
    config servers, such as Consul or using Git. This ensures that there are no ad-hoc
    changes made to the production deployment that are not recorded in the version
    control system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feature toggle**: This allows features released in production to be toggled
    on or off from some configuration settings. This toggle is typically implemented
    at the frontend or API gates so that it can be made visible or not visible to
    the end users of the service/feature. This pattern is very useful for a dark launch
    capability, which is discussed in the following sections.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dark launch**: Popularized by Facebook. Dark launch means releasing the service/capability
    into the production well before its scheduled release. This gives the opportunity
    to test out the integration points and complex services in production environments.
    Only frontend or API changes are done using a Canary release and feature toggle
    as discussed earlier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data architecture for microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the key design philosophies of microservices is the bounded context and
    the service(s) managing the data store. Within a bounded context, multiple services
    might have access to a common data store, or adopt a per service data store paradigm.
  prefs: []
  type: TYPE_NORMAL
- en: Since there are potentially multiple instances of a service running, how do
    we make sure the data read/update operations do not lead to a deadlock in resources?
  prefs: []
  type: TYPE_NORMAL
- en: Command Query Responsibility Segregation (CQRS)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CQRS introduces an interesting paradigm challenging the conventional thought
    of using the same data store to create/update and also query the systems. The
    idea is to separate the commands that change the state of the system from the
    queries that are idempotent. The materialized view is an example of this pattern.
    The separation also gives the flexibility to use a different data model for updates
    and queries. For example, the relational model could be used for updates, but
    the events generated from the updates can be used to update caches or document
    databases that are more read-friendly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The user requests can be broadly classified into two parts, such as commands
    that change the state of the system, and queries that get the state of the system
    for user consumption. For the command processing, the system of engagement collects
    enough business data so that it can call the respective service on a system of
    record to execute the commands. For queries, the system of engagement can choose
    to either call the system of record, or get the information from a local store
    that is designed for read workloads. This separation of strategy can yield immense
    benefits, such as reducing the load on the system of record and reducing the latency:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c93f51b6-b83a-48e0-82f8-bc87cf924514.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The CQRS pattern helps to leverage legacy systems of records in conjunction
    with the newer document databases, and caches as well. We will cover how to implement
    CQRS in your service in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Duplicating data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Within the bounded context, the services are the custodians of the data. But
    what if another service requires a subset of your data? Some of the questions/solutions
    that arise are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Should I invoke the service to get that data?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increased chattiness among the services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tight coupling of two services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can I access the data store directly from another bounded context?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Breaks the bounded context model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, how does another service (residing in another bounded context) get access
    to the subset of the data? (For example, requiring address attributes for a customer
    (from customer service) in the personalization services.)
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the best way is to duplicate data from the master domain. The
    required changes are published as events by the master domain, which are subscribed
    to by any domain interested in those changes. The events are picked up from the
    event bus, and data from the event is used to update the changes in the duplicate
    data store:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6bcb5d57-6147-4089-91aa-1730ea807be3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Benefits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The benefits of duplicating data are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Helps decouple the service boundaries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A business event containing the data is the only relationship between the services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Helps avoid expensive distributed transaction models across boundaries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Allows us to make changes to our service boundaries without impeding progress
    of other parts of the system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can decide how quickly or slowly we want to see the rest of the outside world
    and eventually become consistent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ability to store the data in our own databases using the technology appropriate
    for our service model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flexibility to make changes to our schema/databases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Allows us to become much more scalable, fault tolerant, and flexible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cons
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The cons associated with duplicating data are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Large volume of data changes might mean a more robust infrastructure at both
    ends and the ability to handle lost events requires event durability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leads to an eventual consistency model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Complicated system and very difficult to debug
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fit for purpose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The bounded context model means the data encompassed can be modified only through
    the defined service interfaces or APIs. This means the actual schema or the storage
    technology used to store the data has no bearing on the API functionality. This
    opens us up to the possibility of using a fit for purpose data store. If we are
    building a search functionality and an in-memory data store is a better fit for
    the given business requirement, we can go ahead with it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since, access to the data is governed by the service APIs, the choice and structure
    of the data store is immaterial to the actual service consumers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4d5744e3-2db6-470b-9e66-1f0c55d6aef7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The service APIs model also provides the flexibility to move from one data store
    to another, without an impact on the other consuming services, as long as the
    service contracts are maintained. Martin Fowler has termed it, polyglot persistence.
  prefs: []
  type: TYPE_NORMAL
- en: The role of security
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the proliferation of microservices, the challenges of managing security
    for these services becomes a challenge. Some of the questions that need to be
    answered, besides the **Open Web Application Security Project** (**OWASP**) top
    ten web vulnerabilities, are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Does the service require the client to authenticate before service invocation
    (such as OAuth)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can a client call any service or only the service for which it is authorized?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the service know the identity of the client from where the request originated
    and does it get passed down to the downstream services? Do the downstream services
    have a mechanism to verify the authorization of their invocation?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the traffic between service to service invocation secured (HTTPS)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we verify that a request received from an authenticated user hasn't been
    tampered with?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we detect and reject a replay of a request?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the distributed microservice model, we need to control and limit the privileges
    the calling party has, and how much data is accessible (least privilege) on each
    call in case of a security breach. A large number of microservices and supporting
    databases means there is a large attack surface that need to be protected. Server
    hardening across the services becomes an important and key activity to secure
    the network. It is very important to monitor the service access and model the
    threats to break down the processes where we are most vulnerable and focus our
    effort there. We will see the role of API gateways in addressing some of the security
    concerns.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This brings us to the conclusion of the design principles for your cloud applications.
    In this chapter, you learned about the reasons for the popularity of the APIs,
    how to decouple your monolith application, and various categories of microservice
    patterns and data architecture principles for microservices design. We also saw
    the role of security in microservices and the role of API gateways.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will take our example from [Chapter 2](8a0a7cae-4aaa-460d-a760-59d0ffde9b48.xhtml),
    *Writing Your First Cloud-Native Application*, and start adding more meat to it
    to make it more production grade. We will add data access, options to do caching
    and their considerations, applying CQRS, and error handling.
  prefs: []
  type: TYPE_NORMAL
