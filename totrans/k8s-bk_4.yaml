- en: '4: Working with Pods'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll split this chapter in to two main parts:'
  prefs: []
  type: TYPE_NORMAL
- en: Theory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hands-on
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s crack on with the theory.
  prefs: []
  type: TYPE_NORMAL
- en: Pod theory
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the virtualization world, the atomic unit of scheduling is the Virtual Machine
    (VM). This means that **deploying applications** in the virtualization world means
    scheduling them on VMs.
  prefs: []
  type: TYPE_NORMAL
- en: In the Docker world, the atomic unit is the container. This means that **deploying
    applications** on Docker means deploying them inside of containers.
  prefs: []
  type: TYPE_NORMAL
- en: In the Kubernetes world, the atomic unit is the *Pod* . Ergo, **deploying applications**
    on Kubernetes means stamping them out as Pods.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1](Image00022.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1
  prefs: []
  type: TYPE_NORMAL
- en: Be sure to take this and tag it in your brain as important - Virtualization
    does VM’s, Docker does containers, and **Kubernetes does Pods!**
  prefs: []
  type: TYPE_NORMAL
- en: As Pods are the fundamental unit of deployment on a Kubernetes cluster, it’s
    vital that we understand how they work.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** We’re going to talk a lot about Pods in this chapter. However, it’s
    important to remember that Pods are just a vehicle for **deploying applications**
    .'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Pods vs containers
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: At a high-level, Pods sit somewhere in between a containers and VMs. They’re
    bigger than a container, but a lot smaller than a VM.
  prefs: []
  type: TYPE_NORMAL
- en: Digging a bit deeper, a Pod is a shared execution environment for one or more
    containers. More often than not, a Pod only has one container. But multi-container
    Pods are definitely a thing, and they’re great for co-scheduling tightly-coupled
    workloads. For example, two containers that share resources and wouldn’t work
    well if they were scheduled on different nodes in the cluster. Another increasingly
    common use-case for multi-container Pods is logging and service meshes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pods: the canonical example'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The example we usually use when comparing single-container and multi-container
    Pods is a web server that has a file synchronizer.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example we have two clear *concerns* :'
  prefs: []
  type: TYPE_NORMAL
- en: Serving the web page
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Making sure the content is up-to-date
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Note:** Think of a *concern* as a requirement/task. In microservices architectures
    we often refer to concerns as *services* . In the previous list we might call
    the *web page concern* the *web page service* . Each *service* deals with one
    *concern* .'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Generally speaking, microservices design patterns dictate that we should separate
    concerns. This means one *concern* per container. Assuming the previous example,
    that would be one container for the web service, another container for the file-sync
    service.
  prefs: []
  type: TYPE_NORMAL
- en: This approach has a lot of advantages.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of building a monolith, where a single Pod runs the web service *and*
    file-sync service, we’re building two microservices - each with its own distinct
    concern. This means we can have different teams responsible for each of the two
    services. We can scale each service independently. We can also update them independently.
    And if the Pod running the file-sync service fails, the web service can stay up
    (though it may end up serving stale content).
  prefs: []
  type: TYPE_NORMAL
- en: However, sometimes it makes sense to co-schedule multiple containers in a single
    Pod. Use-cases include; two containers that need to share memory or share a volume.
    See Figure 4.2.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2](Image00023.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.2
  prefs: []
  type: TYPE_NORMAL
- en: In this scenario, we are not separating concerns - a single Pod is doing two
    jobs. However, the simplest way to implement a shared volume is to schedule the
    containers that will be sharing the volume on the same node. By running the web
    service container and the file-sync container in the same Pod, we ensure they
    are deployed to the same node. We also give them a shared operating environment
    where both can access the same shared memory and shared volumes etc. More on all
    of this later.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, the general rule is separate concerns by designing Pods and containers
    do a single job, and then scheduling a single container per Pod. However, there
    are use-cases where breaking this rule has advantages.
  prefs: []
  type: TYPE_NORMAL
- en: How do we deploy Pods
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To deploy a Pod to a Kubernetes cluster we define it in a *manifest file* and
    `POST` that manifest file to the API server. The control plane examines it, records
    it in the cluster store, and the scheduler deploys it to a healthy node with enough
    available resources. This process is identical no matter how many containers a
    Pod is running.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3](Image00024.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.3
  prefs: []
  type: TYPE_NORMAL
- en: Let’s dig a bit deeper…
  prefs: []
  type: TYPE_NORMAL
- en: The anatomy of a Pod
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: At the highest level, a Pod is a shared execution environment for one or more
    containers. “Shared execution environment” means that the Pod has a set of resources
    that are shared by every container inside the Pod. These resources include; IP
    addresses, ports, hostname, sockets, memory, volumes, and more…
  prefs: []
  type: TYPE_NORMAL
- en: If you’re using Docker as the container runtime for Kubernetes, a Pod is actually
    a special type of container called the **pause container** . That’s right, a Pod
    is just a fancy name for a special container!
  prefs: []
  type: TYPE_NORMAL
- en: This means the containers that run inside of Pods are really containers running
    inside of containers! For more information, watch “Inception” by Christopher Nolan,
    starring Leonardo DiCaprio :-D
  prefs: []
  type: TYPE_NORMAL
- en: 'Seriously though, the Pod (pause container) is just a collection of system
    resources that containers running inside of it will inherit and share. These `system
    resources` are `kernel namespaces` and include:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Network namespace:** IP address, port range, routing table…'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**UTS namespace:** Hostname'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**IPC namespace:** Unix domain sockets…'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we just mentioned, this means that all containers in a Pod share a hostname,
    IP address, memory address space, and volumes.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look a bit closer at how this affects networking.
  prefs: []
  type: TYPE_NORMAL
- en: Each Pod creates its own network namespace - a single IP address, a single range
    of ports, and a single routing table. This is true even if the Pod is a multi-container
    Pod - each container in a Pod shares the Pod’s; IP, range of ports, and routing
    table.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.4 shows two Pods, each with its own IP. Even though one of the Pods
    is hosting two containers, it still only gets a single IP.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.4](Image00025.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.4
  prefs: []
  type: TYPE_NORMAL
- en: In the example in Figure 4.4, we can access the individual containers in Pod
    1 using a combination of the Pod IP, coupled with the containers individual port
    number (80 and 5000).
  prefs: []
  type: TYPE_NORMAL
- en: One last time (apologies if it feels like I’m over-repeating myself)… Each container
    in a Pod shares the **Pod’s** entire network namespace - IP, `localhost` adapter,
    port range, routing table, and more.
  prefs: []
  type: TYPE_NORMAL
- en: But as we’ve said, it’s more than just networking. All containers in a Pod have
    access to the same volumes, the same memory, the same IPC sockets, and more. Technically
    speaking, the Pod (pause container) holds all the namespaces, any containers in
    the Pod inherit them and share them.
  prefs: []
  type: TYPE_NORMAL
- en: This networking model makes *inter-Pod* communication really simple. Every Pod
    in the cluster has its own IP addresses that’s fully routable on the *Pod network*
    . If you read the chapter on installing Kubernetes, you’ll have seen how we created
    a Pod network at the end of the *Play with Kubernetes* , and *kubeadm* sections.
    Because every Pod gets its own routable IP, every Pod can talk directly to every
    other Pod. No need to mess around with things like nasty port mappings!
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5 Inter-Pod communication](Image00026.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.5 Inter-Pod communication
  prefs: []
  type: TYPE_NORMAL
- en: '*Intra-Pod* communication - where two containers in the same Pod need to communicate
    - can happen via the Pod’s `localhost` interface.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6 Intra-Pod communication](Image00027.gif)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.6 Intra-Pod communication
  prefs: []
  type: TYPE_NORMAL
- en: If you need to make multiple containers in the same Pod available to the outside
    world, you can expose them on individual ports. Each container needs its own port,
    and two containers in the same Pod cannot use the same port.
  prefs: []
  type: TYPE_NORMAL
- en: In summary. It’s all about the **Pod!** The **Pod** gets deployed, the **Pod**
    gets the IP, the **Pod** owns all of the namespaces… The **Pod** is at the center
    of the Kuberverse!
  prefs: []
  type: TYPE_NORMAL
- en: Pods and cgroups
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: At a high level, Control Groups (cgroups) are what stop individual containers
    from consuming all of the available CPU, RAM and IOPS on a node. We could say
    that cgroups “police” resource usage.
  prefs: []
  type: TYPE_NORMAL
- en: Individual containers have their own cgroup limits.
  prefs: []
  type: TYPE_NORMAL
- en: This means it’s possible for two containers in a single Pod to have their own
    set of cgroup limits. This is a powerful and flexible model. If we assume the
    canonical multi-container Pod example from earlier in the chapter, we could set
    a cgroup limit on the file sync container so that it has access to less resources
    than the web service container. This would reduce the risk of it starving the
    web service container of CPU and memory.
  prefs: []
  type: TYPE_NORMAL
- en: Atomic deployment of Pods
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Deploying a Pod is an *atomic operation* . This means it’s an all-or-nothing
    operation - there’s no such thing as a partially deployed Pod that can service
    requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, either: everything inside of a Pod comes up and the Pod becomes
    available, **OR** , everything doesn’t come up and the Pod fails. This means you
    can never have a situation where you have a multi-container Pod with one of its
    containers up and accessible but the other container in a failed state! That’s
    not how it works. Nothing in the Pod is made available until the entire Pod is
    up. Once all Pod resources are ready, the Pod is made available.'
  prefs: []
  type: TYPE_NORMAL
- en: It’s also important to stress that any given Pod can only be running on a single
    node. This is the same as containers and VMs - you can’t have part of a Pod on
    one node and another part of it on another node. One Pod gets scheduled to one
    node!
  prefs: []
  type: TYPE_NORMAL
- en: Pod lifecycle
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The lifecycle of typical Pod goes something like this. You define it in a YAML
    manifest file. Then you throw the manifest at the API server, and the Pod it defines
    gets scheduled to a healthy node. Once it’s scheduled to a node, it goes into
    the *pending* state while the node downloads images and fires up any containers.
    The Pod remains in this *pending* state until **all of its resources** are up
    and ready. Once everything’s up and ready, the Pod enters the *running* state.
    Once it’s completed everything it needs to do, it gets terminated and enters the
    *succeeded* state.
  prefs: []
  type: TYPE_NORMAL
- en: If you deploy a Pod independently (not via a higher-level object), and that
    Pod fails, it is not rescheduled! For this reason, we rarely deploy them directly.
    It’s far more common to deploy them via higher-level objects like *Deployments*
    and *DaemonSets* , as these reschedule Pods when they fail.
  prefs: []
  type: TYPE_NORMAL
- en: When a Pod can’t start, it can remain in the *pending* state or go to the *failed*
    state. This is all shown in Figure 4.7.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.7 Pod lifecycle](Image00028.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.7 Pod lifecycle
  prefs: []
  type: TYPE_NORMAL
- en: It’s also important to think of Pods as *mortal* . When they die, they die!
    There’s no bringing them back from the dead. This follows the *pets vs cattle*
    analogy - Pods should be treated as *cattle* . When they die, you replace them
    with another. There’s no tears and no funeral. The old one is gone, and a shiny
    new one – with the same config, but a different ID and IP - magically appears
    and takes its place.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** No offense is intended to any person or any animal when referring
    to the *pets vs cattle* analogy.'
  prefs: []
  type: TYPE_NORMAL
- en: This is one of the main reasons you should code your applications so that they
    don’t store *state* in Pods. It’s also why we shouldn’t rely on individual Pod
    IPs etc.
  prefs: []
  type: TYPE_NORMAL
- en: Pod theory summary
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Pods are the atomic unit of scheduling in Kubernetes
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can have more than one container in a Pod. Single-container Pods are the
    simplest, but multi-container Pods are ideal for containers that need to be tightly
    coupled - maybe they need to share memory or volumes. They’re also great for logging
    and service meshes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pods get scheduled on nodes – you can’t schedule a single Pod instance to span
    multiple nodes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pods get defined declaratively in a manifest file that is POSTed to the API
    server and assigned to nodes by the scheduler.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hands-on with Pods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It’s time to see Pods in action!
  prefs: []
  type: TYPE_NORMAL
- en: For the examples in the rest of this chapter we’ll use the 3-node cluster shown
    in Figure 4.8.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.8](Image00029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.8
  prefs: []
  type: TYPE_NORMAL
- en: It doesn’t matter where this cluster is, or how it was deployed. All that matters
    is that you have three Linux hosts configured into a Kubernetes cluster with at
    least one master and two nodes. You’ll also need `kubectl` installed and configured
    to talk to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: If you do not have a cluster and would like to follow along, go to http://play-with-k8s.com
    and build a quick cluster - it’s free and easy.
  prefs: []
  type: TYPE_NORMAL
- en: Following the Kubernetes mantra of *composable infrastructure* , we define Pods
    in manifest files, POST the manifest to the API server, and let the scheduler
    take care of instantiating the Pods on the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Pod manifest files
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'For the examples in this chapter we’re going to use the following Pod manifest.
    It’s available in the books GitHub repo under the `pods` folder called pod.yml:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Let’s step through what the YAML file is describing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Straight away we can see four top-level resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '`.apiVersion`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.kind`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.metadata`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.spec`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `.apiVersion` field tells us two things - the *API group* and the *API version*
    that will be used to create the object. Normally the format is `<api-group>/<version>`
    . However, Pods are defined in a special API group called the *core* group which
    omits the *api-group* part. For example, StorageClass objects are defined in `v1`
    of the `storage.k8s.io` API group and are described in YAML files as `storage.k8s.io/v1`
    . However, Pods are in the *core* API group which is special, as it omits the
    API group name.
  prefs: []
  type: TYPE_NORMAL
- en: It’s possible for an object to be defined in multiple versions of an API group.
    For example, `some-api-group/v1` and `some-api-group/v2` . In this case, the definition
    in the newer group would probably include additional fields that extend the capabilities
    of the object. Think of the *version* field as defining the object schema - newer
    is usually better.
  prefs: []
  type: TYPE_NORMAL
- en: Anyway, Pods are currently in the `v1` API group.
  prefs: []
  type: TYPE_NORMAL
- en: The `.kind` field tells us the type of object being deployed. It has two obvious
    functions. Firstly, it makes reading YAML files easier. Secondly, it explicitly
    tells the control plane what type of object is being defined, and therefore which
    controller to pass it on to.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we know we’re deploying a Pod object as defined in `v1` of the *core
    API group* .
  prefs: []
  type: TYPE_NORMAL
- en: The `.metadata` section is where we attach a name and labels. These help us
    identify the object in the cluster. We also define the `namespace` that an object
    should be deployed in. Keeping things brief, namespaces allow us to logically
    divide clusters for management purposes. In the real world, it’s highly recommended
    to use namespaces. However, they should not be considered strong security boundaries.
  prefs: []
  type: TYPE_NORMAL
- en: The `.metadata` section of this Pod manifest is naming the Pod “hello-pod” and
    assigning it two labels. Labels are simple key-value pairs, but they’re insanely
    powerful! We’ll talk more about labels later as we build our knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: The `.spec` section is where we define any containers that will run in the Pod.
    Our example is deploying a Pod with a single container based on the `nigelpoulton/k8sbook:latest`
    image. It’s calling it hello-ctr and exposing it on port `8080` .
  prefs: []
  type: TYPE_NORMAL
- en: If this was a multi-container Pod, we’d define additional containers in the
    `.spec` section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Manifest files: Empathy as Code'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Quick side-step.
  prefs: []
  type: TYPE_NORMAL
- en: 'Configuration files, such as Kubernetes manifest files, are excellent sources
    of documentation. As such, they have some secondary benefits. Two of these include:'
  prefs: []
  type: TYPE_NORMAL
- en: Helping speed-up the on-boarding process for new team members
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Helping bridge the gap between developers and operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, if you need a new team member to understand the basic functions
    and requirements of an application, get them to read the Kubernetes manifest files
    used to deploy it.
  prefs: []
  type: TYPE_NORMAL
- en: Also, if you have a problem with developers not clearly articulating their application
    requirements, get them to use Kubernetes. As they describe their applications
    through Kubernetes manifests, these can then be used by operations staff to understand
    how the application works and what it requires from the environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'These kinds of benefits were described by Nirmal Mehta as a form of *empathy
    as code* in his 2017 DockerCon talk entitled “A Strong Belief, Loosely Held: Bringing
    Empathy to IT”.'
  prefs: []
  type: TYPE_NORMAL
- en: I understand that describing YAML files like these as *“empathy as code”* sounds
    a bit extreme. However, there is merit to the concept - they definitely help.
  prefs: []
  type: TYPE_NORMAL
- en: Back to business…
  prefs: []
  type: TYPE_NORMAL
- en: Deploying Pods from a manifest file
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If you’re following along with the examples, save the following manifest file
    as `pod.yml` in your current directory.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Use the following `kubectl` command to POST the manifest to the API server and
    deploy a Pod from it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Although the Pod is showing as created, it might not be fully deployed on the
    cluster yet. This is because it can take time to pull the image.
  prefs: []
  type: TYPE_NORMAL
- en: Run a `kubectl get pods` command to check the status.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the container is still being created - no doubt waiting for
    the image to be pulled from Docker Hub.
  prefs: []
  type: TYPE_NORMAL
- en: You can use the `kubectl describe pods hello-pod` command to drill into more
    detail.
  prefs: []
  type: TYPE_NORMAL
- en: You can add the `--watch` flag to the `kubectl get pods` command so that you
    can monitor it and see when the status changes to running.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! Your Pod has been scheduled to a healthy node in the cluster
    and is being monitored by the local `kubelet` process on the node. The `kubelet`
    process is the Kubernetes agent running on the node.
  prefs: []
  type: TYPE_NORMAL
- en: In future chapters we’ll see how to connect to the web server running in the
    Pod.
  prefs: []
  type: TYPE_NORMAL
- en: Introspecting running Pods
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As good as the `kubectl get pods` command is, it’s a bit light on detail. Not
    to worry though, there’s plenty of options for deeper introspection.
  prefs: []
  type: TYPE_NORMAL
- en: 'First up, `kubectl get` offers a couple of really simple flags that give you
    more information:'
  prefs: []
  type: TYPE_NORMAL
- en: The `-o wide` flag gives a couple more columns, but is still a single line of
    output.
  prefs: []
  type: TYPE_NORMAL
- en: The `-o yaml` flag takes things to the next level! It returns a full copy of
    the Pod manifest from the cluster store. This output includes desired state (`.spec`
    ) and current observed status (`.status` ).
  prefs: []
  type: TYPE_NORMAL
- en: The following command shows a snipped version of a `kubectl get pods -o yaml`
    command.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Notice how the output contains more values than we initially set in our 13-line
    YAML file. Where does this extra information come from?
  prefs: []
  type: TYPE_NORMAL
- en: 'Two main sources:'
  prefs: []
  type: TYPE_NORMAL
- en: The Kubernetes Pod object contains a lot of properties - far more than we defined
    in the manifest. Those that we don’t specify are automatically expanded with default
    values by Kubernetes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you run a `kubectl get pods` with `-o yaml` you get the Pods *current observed
    state* as well as its *desired state* . This observed state is listed in the `.status`
    section.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another great Kubernetes introspection command is `kubectl describe` . This
    provides a nicely formatted, multi-line overview of an object. It even includes
    some important object lifecycle events. The following command describes the state
    of the hello-pod Pod and shows a snipped output.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The output has been snipped to help it fit the page.
  prefs: []
  type: TYPE_NORMAL
- en: Another way to introspect a running Pod is to log into it or execute commands
    in it. We do this with the `kubectl exec` command. The following example shows
    how to execute a `ps aux` command in the first container in the `hello-pod` Pod.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: You can log-in to the first container in the Pod with the following command.
    Once inside the container you can execute normal commands (as long as the command
    binaries are installed in the container).
  prefs: []
  type: TYPE_NORMAL
- en: The `kubectl exec` command will log-in to the first container in the Pod and
    create a new shell session. Once inside the container, the `curl` command transfers
    data from the process listening on port `8080` .
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `-it` flags make the `exec` session interactive and connects STDIN and STDOUT
    on your terminal windows to STDIN and STDOUT inside the first container in the
    Pod. When the command completes, your shell prompt will change, indicating that
    your shell is now connected to the container.
  prefs: []
  type: TYPE_NORMAL
- en: If you are running multi-container Pods, you will need to pass the `kubectl
    exec` command the `--container` flag and give it the name of the container in
    the Pod that you want to create the exec session with. If you do not specify this
    flag, the command will execute against the first container in the Pod. You can
    see the ordering and names of containers in a Pod with the `kubectl describe pods
    <pod>` command.
  prefs: []
  type: TYPE_NORMAL
- en: One other command for introspecting Pods is the `kubectl logs` command. Like
    other Pod-related commands, if you don’t specify a container by name, it will
    execute against the first container in the Pod. The format of the command is `kubectl
    logs <pod>` .
  prefs: []
  type: TYPE_NORMAL
- en: There’s obviously a lot more to Pods than what we’ve covered. However, we’ve
    learned enough to get started.
  prefs: []
  type: TYPE_NORMAL
- en: Clean-up your lab with the following command.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Chapter Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter, we learned that the atomic unit of deployment in the Kubernetes
    world is the *Pod* . Each Pod consists of one or more containers and gets deployed
    to a single node in the cluster. The deployment operation is an all-or-nothing
    *atomic transaction* .
  prefs: []
  type: TYPE_NORMAL
- en: The best way to deploy a Pod is declaratively using a YAML manifest file. We
    use the `kubectl` command to `POST` the manifest to the API server, it gets stored
    in the cluster store and converted into a PodSpec that gets scheduled onto a healthy
    cluster node with enough available resources.
  prefs: []
  type: TYPE_NORMAL
- en: The process on the worker node that accepts the PodSpec is the `kubelet` . This
    is the main Kubernetes agent running on every node in the cluster. It takes the
    PodSpec and is responsible for pulling all images and starting all containers
    in the Pod.
  prefs: []
  type: TYPE_NORMAL
- en: If a Pod fails, it is not automatically rescheduled. Because of this, we usually
    deploy them via higher-level objects such as Deployments and DaemonSets. These
    add things like self-healing and roll-backs, and are at the heart of what makes
    Kubernetes so powerful.
  prefs: []
  type: TYPE_NORMAL
