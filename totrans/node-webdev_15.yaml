- en: Deploying a Docker Swarm to AWS EC2 with Terraform
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Terraform将Docker Swarm部署到AWS EC2
- en: So far in this book, we've created a Node.js-based application stack comprising
    two Node.js microservices, a pair of MySQL databases, and a Redis instance. In
    the previous chapter, we learned how to use Docker to easily launch those services,
    intending to do so on a cloud hosting platform. Docker is widely used for deploying
    services such as ours, and there are lots of options available to us for deploying
    Docker on the public internet.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本书中，我们已经创建了一个基于Node.js的应用程序堆栈，包括两个Node.js微服务、一对MySQL数据库和一个Redis实例。在上一章中，我们学习了如何使用Docker轻松启动这些服务，打算在云托管平台上这样做。Docker被广泛用于部署我们这样的服务，对于在公共互联网上部署Docker，我们有很多可用的选项。
- en: Because **Amazon Web Services** (**AWS**) is a mature feature-filled cloud hosting
    platform, we've chosen to deploy there. There are many options available for hosting
    Notes on AWS. The most direct path from our work in [Chapter 11](b3de2a00-b4df-4552-9cf6-b3f356ef05b9.xhtml), *Deploying
    Node.js Microservices with Docker*, is to create a Docker Swarm cluster on AWS.
    That enables us to directly reuse the Docker compose file we created.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Amazon Web Services（AWS）是一个成熟且功能丰富的云托管平台，我们选择在那里部署。在AWS上有许多可用于托管Notes的选项。我们在第11章《使用Docker部署Node.js微服务》中的工作中，最直接的路径是在AWS上创建一个Docker
    Swarm集群。这使我们能够直接重用我们创建的Docker compose文件。
- en: Docker Swarm is one of the available Docker orchestration systems. These systems
    manage a set of Docker containers on one or more Docker host systems. In other
    words, building a swarm requires provisioning one or more server systems, installing
    Docker Engine on each, and enabling swarm mode. Docker Swarm is built into Docker
    Engine, and it's a matter of a few commands to join those servers together in
    a swarm. We can then deploy Docker-based services to the swarm, and the swarm
    distributes the containers among the server systems, monitoring each container,
    restarting any that crash, and so on.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm是可用的Docker编排系统之一。这些系统管理一个或多个Docker主机系统上的一组Docker容器。换句话说，构建一个Swarm需要为一个或多个服务器系统进行配置，安装Docker
    Engine，并启用Swarm模式。Docker Swarm内置于Docker Engine中，只需几个命令即可将这些服务器加入到Swarm中。然后，我们可以将基于Docker的服务部署到Swarm中，Swarm会在服务器系统之间分发容器，监视每个容器，重新启动任何崩溃的容器等。
- en: Docker Swarm can be used in any situation with multiple Docker host systems.
    It is not tied to AWS because we can rent suitable servers from any of hundreds
    of web hosting providers around the world. It's sufficiently lightweight that
    you can even experiment with Docker Swarm using **virtual machine** (**VM**) instances
    (Multipass, VirtualBox, and so on) on a laptop.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm可以在具有多个Docker主机系统的任何情况下使用。它不受AWS的限制，因为我们可以从世界各地的数百家Web托管提供商那里租用合适的服务器。它足够轻量级，以至于您甚至可以在笔记本电脑上使用虚拟机实例（Multipass、VirtualBox等）来尝试Docker
    Swarm。
- en: In this chapter, we will use a set of AWS **Elastic Compute Cloud** (**EC2**)
    instances. EC2 is the AWS equivalent of a **virtual private server** (**VPS**)
    that we would rent from a web hosting provider. The EC2 instances will be deployed
    within an AWS **virtual private cloud** (**VPC**), along with a network infrastructure
    on which we'll implement the deployment architecture we outlined earlier.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用一组AWS Elastic Compute Cloud（EC2）实例。EC2是AWS的虚拟专用服务器（VPS）的等价物，我们可以从Web托管提供商那里租用。EC2实例将部署在AWS虚拟私有云（VPC）中，以及我们将在其上实施之前概述的部署架构的网络基础设施。
- en: Let's talk a little about the cost since AWS can be costly. AWS offers what's
    called the Free Tier, where, for certain services, the cost is zero as long as
    you stay below a certain threshold. In this chapter, we'll strive to stay within
    the free tier, except that we will have three EC2 instances deployed for a while,
    which is beyond the free tier for EC2 usage. If you are sensitive to the cost,
    it is possible to minimize it by destroying the EC2 instances when not needed.
    We'll discuss how to do this later.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们谈谈成本，因为AWS可能成本高昂。AWS提供了所谓的免费层，对于某些服务，只要保持在一定阈值以下，成本就为零。在本章中，我们将努力保持在免费层内，除了我们将有三个EC2实例部署一段时间，这超出了EC2使用的免费层。如果您对成本敏感，可以通过在不需要时销毁EC2实例来将其最小化。我们将在稍后讨论如何做到这一点。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Signing up with AWS and configuring the AWS **command-line interface** (**CLI**)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注册AWS并配置AWS命令行界面（CLI）
- en: An overview of the AWS infrastructure to be deployed
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要部署的AWS基础设施概述
- en: Using Terraform to create an AWS infrastructure
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Terraform创建AWS基础设施
- en: Setting up a Docker Swarm cluster on AWS EC2
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在AWS EC2上设置Docker Swarm集群
- en: Setting up **Elastic Container Registry** (**ECR**) repositories for Notes Docker
    images
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为Notes Docker镜像设置Elastic Container Registry（ECR）存储库
- en: Creating a Docker stack file for deployment to Docker Swarm
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为部署到Docker Swarm创建Docker堆栈文件
- en: Provisioning EC2 instances for a full Docker Swarm
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为完整的Docker Swarm配置EC2实例
- en: Deploying the Notes stack file to the swarm
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Notes堆栈文件部署到Swarm
- en: You will be learning a lot in this chapter, starting with how to get started
    with the AWS Management Console, setting up **Identity and Access Management**
    (**IAM**) users on AWS, and how to set up the AWS command-line tools. Since the
    AWS platform is so vast, it is important to get an overview of what it entails
    and the facilities we will use in this chapter. Then, we will learn about Terraform,
    a leading tool for configuring services on all kinds of cloud platforms. We will
    learn how to use it to configure AWS resources such as the VPC, the associated
    networking infrastructure, and how to configure EC2 instances. We'll next learn
    about Docker Swarm, the orchestration system built into Docker, how to set up
    a swarm, and how to deploy applications in a swarm.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将学到很多东西，从如何开始使用AWS管理控制台，设置AWS上的身份和访问管理（IAM）用户，到如何设置AWS命令行工具。由于AWS平台如此庞大，重要的是要对其内容和我们在本章中将使用的功能有一个概述。然后，我们将学习Terraform，这是一种在各种云平台上配置服务的主要工具。我们将学习如何使用它来配置AWS资源，如VPC、相关的网络基础设施，以及如何配置EC2实例。接下来，我们将学习Docker
    Swarm，这是内置在Docker中的编排系统，以及如何设置一个Swarm，以及如何在Swarm中部署应用程序。
- en: For that purpose, we'll learn about Docker image registries, the AWS **Elastic
    Container Registry** (**ECR**), how to push images to a Docker registry, and how
    to use images from a private registry in a Docker application stack. Finally,
    we'll learn about creating a Docker stack file, which lets you describe Docker
    services to deploy in a swarm.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们将学习Docker镜像注册表、AWS弹性容器注册表（ECR）、如何将镜像推送到Docker注册表，以及如何在Docker应用程序堆栈中使用来自私有注册表的镜像。最后，我们将学习创建Docker堆栈文件，该文件允许您描述要在群集中部署的Docker服务。
- en: Let's get started.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: Signing up with AWS and configuring the AWS CLI
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 注册AWS并配置AWS CLI
- en: To use AWS services you must, of course, have an AWS account. The AWS account
    is how we authenticate ourselves to AWS and is how AWS charges us for services.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用AWS服务，当然必须拥有AWS账户。AWS账户是我们向AWS进行身份验证的方式，也是AWS向我们收费的方式。
- en: As a first step, go to [https://aws.amazon.com](https://aws.amazon.com) and
    sign up for an account.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，访问[https://aws.amazon.com](https://aws.amazon.com)并注册一个账户。
- en: The Amazon Free Tier is a way to experience AWS services at zero cost: [https://aws.amazon.com/free/](https://aws.amazon.com/free/).
    [](https://aws.amazon.com/free/) Documentation is available at[ ](https://aws.amazon.com/free/)[https://docs.aws.amazon.com](https://docs.aws.amazon.com).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon免费套餐是一种零成本体验AWS服务的方式：[https://aws.amazon.com/free/](https://aws.amazon.com/free/)。文档可在[https://docs.aws.amazon.com](https://docs.aws.amazon.com)找到。
- en: 'AWS has two kinds of accounts that we can use, as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: AWS有两种我们可以使用的账户，如下：
- en: The** root account** is what's created when we sign up for an AWS account. The
    root account has full access to AWS services.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**根账户**是我们注册AWS账户时创建的账户。根账户对AWS服务拥有完全访问权限。'
- en: An **IAM user account** is a less privileged account you can create within your
    root account. The owner of a root account creates IAM accounts, assigning the
    scope of permissions to each IAM account.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IAM用户账户是您可以在根账户中创建的权限较低的账户。根账户的所有者创建IAM账户，并为每个IAM账户分配权限范围。
- en: It is bad form to use the root account directly since the root account has complete
    access to AWS resources. If the account credentials for your root account were
    to be leaked to the public, significant damage could be done to your business.
    If the credentials for an IAM user account were leaked, the damage is limited
    to the resources controlled by that user account as well as by the privileges
    assigned to that account. Furthermore, IAM user credentials can be revoked at
    any time, and then new credentials generated, preventing anyone who is holding
    the leaked credentials from doing any further damage. Another security measure
    is to enable **multi-factor authentication** (**MFA**) for all accounts.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 直接使用根账户是不好的行为，因为根账户对AWS资源拥有完全访问权限。如果根账户的凭据泄露给公众，可能会对您的业务造成重大损害。如果IAM用户账户的凭据泄露，损害仅限于该用户账户控制的资源以及该账户被分配的权限。此外，IAM用户凭据可以随时被撤销，然后生成新的凭据，防止持有泄霩凭据的任何人进一步造成损害。另一个安全措施是为所有账户启用多因素身份验证（MFA）。
- en: If you have not already done so, proceed to the AWS website at one of the preceding
    links and sign up for an account. Remember that the account created that way is
    your AWS root account.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还没有这样做，请前往上述链接之一的AWS网站并注册一个账户。请记住，以这种方式创建的账户是您的AWS根账户。
- en: Our first step is to familiarize ourselves with the AWS Management Console.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一步是熟悉AWS管理控制台。
- en: Finding your way around the AWS account
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 找到AWS账户的方法
- en: Because there are so many services on the AWS platform, it can seem like a maze
    of twisty little passages, all alike. However, with a little orientation, we can
    find our way around.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 由于AWS平台上有如此多的服务，看起来就像是一个迷宫。但是，稍微了解一下，我们就能找到自己的路。
- en: First, look at the navigation bar at the top of the window. On the right, there
    are three dropdowns. The first has your account name and has account-related choices.
    The second lets you select which AWS region is your default. AWS has divided its
    infrastructure into *regions*, which essentially means the area of the world where
    AWS data centers are located. The third connects you with AWS Support.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，看一下窗口顶部的导航栏。右侧有三个下拉菜单。第一个是您的账户名称，并有与账户相关的选项。第二个可以让您选择AWS区域的默认设置。AWS将其基础设施划分为*区域*，基本上意味着AWS数据中心所在的世界地区。第三个可以让您联系AWS支持。
- en: On the left is a dropdown marked **Services**. This shows you the list of all
    AWS services. Since the Services list is unwieldy, AWS gives you a search box.
    Simply type in the name of the service, and it will show up. The AWS Management
    Console home page also has this search box.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧是一个标有“服务”的下拉菜单。这会显示所有AWS服务的列表。由于服务列表很长，AWS为您提供了一个搜索框。只需输入服务的名称，它就会显示出来。AWS管理控制台首页也有这个搜索框。
- en: While we are finding our way around, let's record the account number for the
    root account. We'll need this information later. In the Account dropdown, select My
    Account. The account ID is there, along with your account name.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们找到自己的路的同时，让我们记录根帐户的帐户号。我们以后会需要这些信息。在帐户下拉菜单中，选择“我的帐户”。帐户ID在那里，以及您的帐户名称。
- en: It is recommended to set up MFA on your AWS root account. MFA simply means to
    authenticate a person in multiple ways. For example, a service might use a code
    number sent via a text message as a second authentication method, alongside asking
    for a password. The theory is that the service is more certain of who we are if
    it verifies both that we've entered a correct password and that we're carrying
    the same cell phone we had carried on other days.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 建议在AWS根帐户上设置MFA。MFA简单地意味着以多种方式对人进行身份验证。例如，服务可能使用通过短信发送的代码号作为第二种身份验证方法，同时要求输入密码。理论上，如果服务验证了我们输入了正确的密码并且我们携带了其他日子携带的同一部手机，那么服务对我们的身份更加确定。
- en: To set up MFA on your root account, go to the My Security Credentials dashboard.
    A link to that dashboard can be found in the AWS Management Console menu bar. This
    brings you to a page controlling all forms of authentication with AWS. From there,
    you follow the directions on the AWS website. There are several possible tools
    for implementing MFA. The simplest tool is to use the Google Authenticator application
    on your smartphone. Once you set up MFA, every login to the root account will
    require a code to be entered from the authenticator app.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 要在根帐户上设置MFA，请转到“我的安全凭据”仪表板。在AWS管理控制台菜单栏中可以找到指向该仪表板的链接。这将带您到一个页面，控制与AWS的所有形式的身份验证。从那里，您可以按照AWS网站上的说明进行操作。有几种可能的工具可用于实施MFA。最简单的工具是在智能手机上使用Google
    Authenticator应用程序。设置MFA后，每次登录到根帐户都需要从验证器应用程序输入代码。
- en: So far, we have dealt with the online AWS Management Console. Our real goal
    is to use command-line tools, and to do that, we need the AWS CLI installed and
    configured on our laptop. Let's take care of that next.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经处理了在线AWS管理控制台。我们真正的目标是使用命令行工具，为此，我们需要在笔记本电脑上安装和配置AWS CLI。让我们接下来处理这个问题。
- en: Setting up the AWS CLI using AWS authentication credentials
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用AWS身份验证凭据设置AWS CLI
- en: The AWS CLI tool is a download available through the AWS website. Under the
    covers, it uses the AWS **application programming interface** (**API**), and it
    also requires that we download and install authentication tokens.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: AWS CLI工具是通过AWS网站提供的下载。在幕后，它使用AWS应用程序编程接口（API），并且还要求我们下载和安装身份验证令牌。
- en: Once you have an account, we can prepare the AWS CLI tool.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您有了帐户，我们就可以准备AWS CLI工具。
- en: The AWS CLI enables you to interact with AWS services from the command line
    of your laptop. It has an extensive set of sub-commands related to every AWS service.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: AWS CLI使您能够从笔记本电脑的命令行与AWS服务进行交互。它具有与每个AWS服务相关的广泛的子命令集。
- en: Instructions to install the AWS CLI can be found here: [https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 安装AWS CLI的说明可以在此处找到：[https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html)。
- en: Instructions to configure the AWS CLI can be found here: [https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 配置AWS CLI的说明可以在此处找到：[https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html)。
- en: Once you have installed the AWS CLI tool on your laptop, we must configure what
    is known as a *profile*.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦在笔记本电脑上安装了AWS CLI工具，我们必须配置所谓的*配置文件*。
- en: AWS supplies an AWS API that supports a broad range of tools for manipulating
    the AWS infrastructure. The AWS CLI tools use that API, as do third-party tools
    such as Terraform. Using the API requires access tokens, so of course, both the
    AWS CLI and Terraform require those same tokens.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: AWS提供了支持广泛的工具来操作AWS基础架构的AWS API。AWS CLI工具使用该API，第三方工具如Terraform也使用该API。使用API需要访问令牌，因此AWS
    CLI和Terraform都需要相同的令牌。
- en: To get the AWS API access tokens, go to the My Security Credentials dashboard
    and click on the Access Keys tab.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取AWS API访问令牌，请转到“我的安全凭据”仪表板，然后单击“访问密钥”选项卡。
- en: 'There will be a button marked Create New Access Key. Click on this and you
    will be shown two security tokens, the Access Key ID and the Secret Access Key.
    You will be given a chance to download a **comma-separated values** (**CSV**)
    file containing these keys. The CSV file looks like this:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 单击此按钮，将显示两个安全令牌，即访问密钥ID和秘密访问密钥。您将有机会下载包含这些密钥的逗号分隔值（CSV）文件。CSV文件如下所示：
- en: '[PRE0]js\1'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE0]js\1'
- en: For the first two prompts, paste in the keys you downloaded. The Region name prompt
    selects the default Amazon AWS data center in which your service will be provisioned.
    AWS has facilities all around the world, and each locale has a code name such
    as `us-west-2` (located in Oregon). The last prompt asks how you wish the AWS
    CLI to present information to you.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对于前两个提示，粘贴您下载的密钥。区域名称提示选择您的服务将在其中提供服务的默认Amazon AWS数据中心。AWS在世界各地都有设施，每个地点都有一个代码名称，例如`us-west-2`（位于俄勒冈州）。最后一个提示询问您希望AWS
    CLI如何向您呈现信息。
- en: For the region code, in the AWS console, take a look at the Region dropdown.
    This shows you the available regions, describing locales, and the region code
    for each. For the purpose of this project, it is good to use an AWS region located
    near you. For production deployment, it is best to use the region closest to your
    audience. It is possible to configure a deployment that works across multiple
    regions so that you can serve clients in multiple areas, but that implementation
    is way beyond what we'll cover in this book.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于区域代码，在AWS控制台中，查看区域下拉菜单。这会显示可用的区域，描述区域和每个区域的区域代码。对于这个项目，最好使用靠近您的AWS区域。对于生产部署，最好使用最接近您的受众的区域。可以配置跨多个区域工作的部署，以便您可以为多个地区的客户提供服务，但这种实现远远超出了我们在本书中涵盖的范围。
- en: By using the `--profile` option, we ensured that this created a named profile.
    If we had left off that option, we would have instead created a profile named `default`.
    For any of the `aws` commands, the `--profile` option selects which profile to
    use. As the name suggests, the default profile is the one used if we leave off
    the `--profile` option.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用`--profile`选项，我们确保创建了一个命名的配置文件。如果我们省略该选项，我们将创建一个名为`default`的配置文件。对于任何`aws`命令，`--profile`选项选择要使用的配置文件。顾名思义，默认配置文件是如果我们省略`--profile`选项时使用的配置文件。
- en: A better choice is to be explicit at all times in which an AWS identity is being
    used. Some guides suggest to not create a default AWS profile at all, but instead
    to always use the `--profile` option to be certain of always using the correct
    AWS profile.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用AWS身份时，最好始终明确。一些指南建议根本不创建默认的AWS配置文件，而是始终使用`--profile`选项以确保始终使用正确的AWS配置文件。
- en: 'An easy way to verify that AWS is configured is to run the following commands:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 验证AWS配置的一种简单方法是运行以下命令：
- en: '[PRE1]js\1'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE1]js\1'
- en: This describes the policy created for the Administrators group. It gives that
    group the rights we specified in the admin role earlier. The Resource tag is where
    we enter the ARN for the admin group that was created earlier. Make sure to put
    the entire ARN into this field.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这描述了为管理员组创建的策略。它为该组提供了我们之前在管理员角色中指定的权限。资源标签是我们输入之前创建的管理员组的ARN的地方。确保将整个ARN放入此字段。
- en: 'Navigate back to the Groups area, and click on Create Group again. We''ll create
    a group, `NotesDeveloper`, for use by developers assigned to the Notes project.
    It will give those user accounts some additional privileges. Perform the following
    steps:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 导航回到组区域，然后再次点击创建组。我们将创建一个名为`NotesDeveloper`的组，供分配给Notes项目的开发人员使用。它将为这些用户帐户提供一些额外的特权。执行以下步骤：
- en: Enter `NotesDeveloper` as the group name. Then, click Next.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`NotesDeveloper`作为组名。然后，点击下一步。
- en: For the Attach Policy page, there is a long list of policies to consider; for
    example, `AmazonRDSFullAccess`, `AmazonEC2FullAccess`, `IAMFullAccess`, `AmazonEC2ContainerRegistryFullAccess`, `AmazonS3FullAccess`, `AdministratorAccess`, and `AmazonElasticFileSystemFullAccess`.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于“附加策略”页面，有一个要考虑的策略长列表；例如，`AmazonRDSFullAccess`，`AmazonEC2FullAccess`，`IAMFullAccess`，`AmazonEC2ContainerRegistryFullAccess`，`AmazonS3FullAccess`，`AdministratorAccess`和`AmazonElasticFileSystemFullAccess`。
- en: Then, click Next, and if everything looks right on the Review page, click **Create
    Group**.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，点击下一步，如果在审阅页面上一切看起来都正确，请点击**创建组**。
- en: These policies cover the services required to finish this chapter. AWS error
    messages that stipulate that the user is not privileged enough to access that
    feature do a good job of telling you the required privilege. If it is a privilege
    the user needs, then come back to this group and add the privilege.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这些策略涵盖了完成本章所需的服务。AWS错误消息指出用户没有足够的特权访问该功能时，很好地告诉您所需的特权。如果这是用户需要的特权，那么回到这个组并添加特权。
- en: 'In the left-hand navigation, click on Users and then on Create User. This starts
    the steps involved in creating an IAM user, described as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在左侧导航中，点击用户，然后点击创建用户。这开始了创建IAM用户所涉及的步骤，如下所述：
- en: For the username, enter `notes-app`, since this user will manage all resources
    related to the Notes application. For Access type, click on both Programmatic
    access and AWS management console access since we will be using both. The first
    grants the ability to use the AWS CLI tools, while the second covers the AWS console.
    Then, click on Next.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于用户名，输入`notes-app`，因为此用户将管理与Notes应用程序相关的所有资源。对于访问类型，点击程序访问和AWS管理控制台访问，因为我们将同时使用两者。第一个授予使用AWS
    CLI工具的能力，而第二个涵盖了AWS控制台。然后，点击下一步。
- en: For permissions, select Add User to Group and then select both the Administrators
    and NotesDeveloper groups. This adds the user to the groups you select. Then,
    click on Next.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于权限，选择将用户添加到组，并选择管理员和NotesDeveloper两个组。这将用户添加到您选择的组。然后，点击下一步。
- en: There is nothing more to do, so keep clicking Next until you get to the Review
    page. If you're satisfied, click on Create user.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 没有其他事情要做，所以继续点击下一步，直到您到达审阅页面。如果您满意，请点击创建用户。
- en: You'll be taken to a page that declares Success. On this page, AWS makes available
    access tokens (a.k.a. security credentials) that can be used with this account.
    Download these credentials before you do anything else. You can always revoke
    the credentials and generate new access tokens at any time.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 您将被带到一个宣布成功的页面。在这个页面上，AWS提供了可以与此帐户一起使用的访问令牌（也称为安全凭证）。在您做任何其他操作之前，请下载这些凭证。您随时可以撤销这些凭证并生成新的访问令牌。
- en: Your newly created user is now listed in the Users section. Click on that entry,
    because we have a couple of data items to record. The first is obviously the ARN
    for the user account. The second is a **Uniform Resource Locator** (**URL**) you
    can use to sign in to AWS as this user. For that URL, click on the Security Credentials
    tab and the sign-in link will be there.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 您新创建的用户现在列在用户部分。点击该条目，因为我们有一些数据项要记录。第一个显然是用户帐户的ARN。第二个是一个**统一资源定位符**（**URL**），您可以使用它以此用户身份登录到AWS。对于该URL，请点击安全凭证选项卡，登录链接将在那里。
- en: It is recommended to also set up MFA for the IAM account. The My Security Credentials
    choice in the AWS taskbar gets you to the screen containing the button to set
    up MFA. Refer back a few pages to our discussion of setting up MFA for the root
    account.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: To test the new user account, sign out and then go to the sign-in URL. Enter
    the username and password for the account, and then sign in.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'Before finishing this section, return to the command line and run the following
    command:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]js\1'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: This is another way to verify that the AWS CLI is correctly installed. This
    command queries the user information from AWS, and if it executes without error
    then you've configured the CLI correctly.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: AWS CLI commands follow a similar structure, where there is a series of sub-commands
    followed by options. In this case, the sub-commands are `aws`, `iam`, and `list-users`.
    The AWS website has extensive online documentation for the AWS CLI tool.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Creating an EC2 key pair
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Since we''ll be using EC2 instances in this exercise, we need an EC2 key pair.
    This is an encrypted certificate that serves the same purpose as the normal **Secure
    Shell** (**SSH**) key we use for passwordless login to a server. In fact, the
    key-pair file serves the same purpose, allowing passwordless login with SSH to
    EC2 instances. Perform the following steps:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Log in to the AWS Management Console and then select the region you're using.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, navigate to the EC2 dashboard—for example, by entering `EC2` in the search
    box.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the navigation sidebar, there is a section labeled Network & Security, containing
    a link for Key pair.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on that link. In the upper-right corner is a button marked Create key
    pair. Click on this button, and you will be taken to the following screen:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/dfe865a3-6172-4b2b-ad97-760498cd6af6.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
- en: Enter the desired name for the key pair. Depending on the SSH client you're
    using, use either a pem (used for the `ssh` command) or a ppk (used for PuTTY)
    formatted key-pair file.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Create key pair and you'll be returned to the dashboard, and the key-pair
    file will download in your browser.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After the key-pair file is downloaded, it is required to make it read-only,
    which you can do by using the following command:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]js\1'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Terraform files have a `.tf` extension and use a fairly simple, easy-to-understand
    declarative syntax. Terraform doesn't care which filenames you use or the order
    in which you create the files. It simply reads all the files with a `.tf` extension
    and looks for resources to deploy. These files do not contain executable code,
    but declarations. Terraform reads these files, constructs a graph of dependencies,
    and works out how to implement the declarations on the cloud infrastructure being
    used.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: 'An example declaration is as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]js\1'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: The block types include resource, which declares something related to the cloud
    infrastructure, variable, which declares a named value, output, which declares
    a result from a module, and a few others.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: The structure of the block labels varies depending on the block type. For resource
    blocks, the first block label refers to the kind of resource, while the second
    is a name for the specific instance of that resource.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: The type of arguments also varies depending on the block type. The Terraform
    documentation has an extensive reference to every variant.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: A Terraform module is a directory containing Terraform scripts. When the `terraform` command
    is run in a directory, it reads every script in that directory to build a tree
    of objects.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: 'Within modules, we are dealing with a variety of values. We''ve already discussed
    resources, variables, and outputs. A resource is essentially a value that is an
    object related to something on the cloud hosting platform being used. A variable
    can be thought of as an input to a module because there are multiple ways to provide
    a value for a variable. The output values are, as the name implies, the output
    from a module. Outputs can be printed on the console when a module is executed,
    or saved to a file and then used by other modules. The code relating to this can
    be seen in the following snippet:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在模块内，我们处理各种值。我们已经讨论了资源、变量和输出。资源本质上是与云托管平台上的某些东西相关的对象值。变量可以被视为模块的输入，因为有多种方法可以为变量提供值。输出值如其名称所示，是模块的输出。当执行模块时，输出可以打印在控制台上，或保存到文件中，然后被其他模块使用。与此相关的代码可以在以下片段中看到：
- en: '[PRE5]js\1'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE5]js\1'
- en: In this case, we've defined several locals related to the CIDR of subnets to
    be created within a VPC. The `cidrsubnet` function is used to calculate subnet
    masks such as `10.1.1.0/24`.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们定义了与要在VPC中创建的子网的CIDR相关的几个本地变量。`cidrsubnet`函数用于计算子网掩码，例如`10.1.1.0/24`。
- en: Another important feature of Terraform is the provider plugin. Each cloud system supported
    by Terraform requires a plugin module that defines the specifics of using Terraform
    with that platform.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Terraform的另一个重要特性是提供者插件。Terraform支持的每个云系统都需要一个定义如何使用Terraform与该平台的具体细节的插件模块。
- en: One effect of the provider plugins is that Terraform makes no attempt to be
    platform-independent. Instead, all declarable resources for a given platform are
    unique to that platform. You cannot directly reuse Terraform scripts for AWS on
    another system such as Azure because the resource objects are all different. What
    you can reuse is the knowledge of how Terraform approaches the declaration of
    cloud resources.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '提供者插件的一个效果是Terraform不会尝试成为平台无关的。相反，给定平台的所有可声明资源都是唯一的。您不能直接在另一个系统（如Azure）上重用AWS的Terraform脚本，因为资源对象都是不同的。您可以重用的是Terraform如何处理云资源声明的知识。 '
- en: Another task is to look for a Terraform extension for your programming editor.
    Some of them have support for Terraform, with syntax coloring, checking for simple
    errors, and even code completion.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个任务是在你的编程编辑器中寻找一个Terraform扩展。其中一些支持Terraform，包括语法着色、检查简单错误，甚至代码补全。
- en: That's enough theory, though. To really learn this, we need to start using Terraform.
    In the next section, we'll begin by implementing the VPC structure within which
    we'll deploy the Notes application stack.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，这已经足够的理论了。要真正学会这个，我们需要开始使用Terraform。在下一节中，我们将从实现VPC结构开始，然后在其中部署Notes应用程序堆栈。
- en: Configuring an AWS VPC with Terraform
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Terraform配置AWS VPC
- en: An AWS VPC is what it sounds like—namely, a service within AWS to hold cloud
    services that you've defined. The AWS team designed the VPC service to look something
    like what you would construct in your own data center, but implemented on the
    AWS infrastructure.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: AWS VPC就像它的名字一样，是AWS内的一个服务，用来容纳您定义的云服务。AWS团队设计了VPC服务，看起来有点像您在自己的数据中心构建的东西，但是在AWS基础设施上实现。
- en: In this section, we will construct a VPC consisting of a public subnet and a
    private subnet, an internet gateway, and security group definitions.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将构建一个包含公共子网和私有子网、互联网网关和安全组定义的VPC。
- en: In the project work area, create a directory, `terraform-swarm`, that is a sibling
    to the `notes` and `users` directories.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在项目工作区中，创建一个名为`terraform-swarm`的目录，它是`notes`和`users`目录的同级目录。
- en: 'In that directory, create a file named `main.tf` containing the following:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在该目录中，创建一个名为`main.tf`的文件，其中包含以下内容：
- en: '[PRE6]js\1'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE6]js\1'
- en: The `default` attribute sets a default value for the variable. As we saw earlier,
    the declaration can also specify the data type for a variable, and a description.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`default`属性为变量设置了默认值。正如我们之前看到的，声明也可以指定变量的数据类型和描述。'
- en: 'With this, we can now run our first Terraform command, as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，我们现在可以运行我们的第一个Terraform命令，如下所示：
- en: '[PRE7]js\1'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE7]js\1'
- en: This declares the VPC. This will be the container for the infrastructure we're
    creating.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这声明了VPC。这将是我们正在创建的基础设施的容器。
- en: The `cidr_block` attribute determines the IPv4 address space that will be used
    for this VPC. The CIDR notation is an internet standard, and an example would
    be `10.0.0.0/16`. That CIDR would cover any IP address starting with the `10.0` octets.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '`cidr_block`属性确定将用于此VPC的IPv4地址空间。CIDR表示法是一个互联网标准，例如`10.0.0.0/16`。该CIDR将覆盖以`10.0`开头的任何IP地址。'
- en: The `enable_dns_support` and `enable_dns_hostnames` attributes determine whether
    **Domain Name System** (**DNS**) names will be generated for certain resources
    attached to the VPC. DNS names can assist with one resource finding other resources
    at runtime.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`enable_dns_support`和`enable_dns_hostnames`属性确定是否为连接到VPC的某些资源生成**域名系统**（**DNS**）名称。DNS名称可以帮助一个资源在运行时找到其他资源。'
- en: The `tags` attribute is used for attaching name/value pairs to resources. The
    name tag is used by AWS to have a display name for the resource. Every AWS resource
    has a computer-generated, user-unfriendly name with a long coded string and, of
    course, we humans need user-friendly names for things. The name tag is useful
    in that regard, and the AWS Management Console will respond by using this name
    in the dashboards.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '`tags`属性用于将名称/值对附加到资源上。名称标签被AWS用来为资源设置显示名称。每个AWS资源都有一个计算生成的、用户不友好的名称，带有一个长编码的字符串，当然，我们人类需要友好的名称。名称标签在这方面很有用，AWS管理控制台将通过在仪表板中使用这个名称来做出响应。'
- en: 'In `variables.tf`, add this to support these resource declarations:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在`variables.tf`中，添加以下内容以支持这些资源声明：
- en: '[PRE8]js\1'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE8]js\1'
- en: Where `resource` blocks declare something on the hosting platform (in this case,
    AWS), `data` blocks retrieve data from the hosting platform. In this case, we
    are retrieving a list of AZs for the currently selected region. We'll use this
    later when declaring certain resources.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '`resource`块声明了托管平台上的某些内容（在本例中是 AWS），`data`块从托管平台检索数据。在这种情况下，我们正在检索当前选择区域的 AZ
    列表。以后在声明某些资源时会用到这个数据。'
- en: Configuring the AWS gateway and subnet resources
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置 AWS 网关和子网资源
- en: Remember that a public subnet is associated with an internet gateway, and a
    private subnet is associated with a NAT gateway. The difference determines what
    type of internet access devices attached to each subnet have.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，公共子网与互联网网关相关联，私有子网与 NAT 网关相关联。这种区别决定了附加到每个子网的互联网访问设备的类型。
- en: 'Create a file named `gw.tf` containing the following:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个名为`gw.tf`的文件，其中包含以下内容：
- en: '[PRE9]js\1'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE9]js\1'
- en: This declares the public and private subnets. Notice that these subnets are
    assigned to a specific AZ. It would be easy to expand this to support more subnets
    by adding subnets named `public2`, `public3`, `private2`, `private3`, and so on.
    If you do so, it would be helpful to spread these subnets across AZs. Deployment
    is recommended in multiple AZs so that if one AZ goes down, the application is
    still running in the AZ that's still up and running.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这声明了公共和私有子网。请注意，这些子网分配给了特定的 AZ。通过添加名为`public2`、`public3`、`private2`、`private3`等子网，很容易扩展以支持更多子网。如果这样做，最好将这些子网分布在不同的
    AZ 中。建议在多个 AZ 中部署，这样如果一个 AZ 崩溃，应用程序仍在仍在运行的 AZ 中运行。
- en: This notation with `[0]` is what it looks like—an array. The value, `data.aws_availability_zones.available.names`,
    is an array, and adding `[0]` does access the first element of that array, just
    as you'd expect. Arrays are just one of the data structures offered by Terraform.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 带有`[0]`的这种表示是什么样子的——一个数组。值`data.aws_availability_zones.available.names`是一个数组，添加`[0]`确实访问了该数组的第一个元素，就像你期望的那样。数组只是
    Terraform 提供的数据结构之一。
- en: 'Each subnet has its own CIDR (IP address range), and to support this, we need
    these CIDR assignments listed in `variables.tf`, as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 每个子网都有自己的 CIDR（IP 地址范围），为了支持这一点，我们需要在`variables.tf`中列出这些 CIDR 分配，如下所示：
- en: '[PRE10]js\1'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE10]js\1'
- en: To configure the routing table for the public subnets, we modify the routing
    table connected to the main routing table for the VPC. What we're doing here is
    adding a rule to that table, saying that public internet traffic is to be sent
    to the internet gateway. We also have a route table association declaring that
    the public subnet uses this route table.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 要为公共子网配置路由表，我们修改连接到 VPC 的主路由表的路由表。我们在这里做的是向该表添加一条规则，指定公共互联网流量要发送到互联网网关。我们还有一个路由表关联声明，公共子网使用这个路由表。
- en: For `aws_route_table.private`, the routing table for private subnets, the declaration
    says to send public internet traffic to the NAT gateway. In the route table associations,
    this table is used for the private subnet.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`aws_route_table.private`，私有子网的路由表，声明指定将公共互联网流量发送到 NAT 网关。在路由表关联中，此表用于私有子网。
- en: Earlier, we said the difference between a public and private subnet is whether
    public internet traffic is sent to the internet gateway or the NAT gateway. These
    declarations are how that's implemented.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们说公共子网和私有子网的区别在于公共互联网流量是发送到互联网网关还是 NAT 网关。这些声明就是实现这一点的方式。
- en: In this section, we've declared the VPC, subnets, gateways, and routing tables—in
    other words, the infrastructure within which we'll deploy our Docker Swarm.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分中，我们声明了 VPC、子网、网关和路由表，换句话说，我们将部署 Docker Swarm 的基础架构。
- en: Before attaching the EC2 instances in which the swarm will live, let's deploy
    this to AWS and explore what gets set up.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在连接容纳 Swarm 的 EC2 实例之前，让我们将其部署到 AWS 并探索设置的内容。
- en: Deploying the infrastructure to AWS using Terraform
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Terraform 将基础架构部署到 AWS
- en: We have now declared the bones of the AWS infrastructure we'll need. This is
    the VPC, the subnets, and routing tables. Let's deploy this to AWS and use the
    AWS console to explore what was created.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经声明了我们需要的 AWS 基础架构的基本结构。这是 VPC、子网和路由表。让我们将其部署到 AWS，并使用 AWS 控制台来探索创建了什么。
- en: 'Earlier, we ran `terraform init` to initialize Terraform in our working directory.
    When we did so, it suggested that we run the following command:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们运行了`terraform init`来初始化我们的工作目录中的 Terraform。这样做时，它建议我们运行以下命令：
- en: '[PRE11]js\1'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE11]js\1'
- en: Terraform's error messages are usually self-explanatory. In this case, the cause
    was a decision to use only one public and one private subnet. This code was left
    over from there being two of each. Therefore, this error referred to stale code
    that was easy to remove.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Terraform 的错误消息通常是不言自明的。在这种情况下，原因是决定只使用一个公共子网和一个私有子网。这段代码是从两个子网的情况遗留下来的。因此，这个错误指的是容易删除的陈旧代码。
- en: The other thing `terraform plan` does is construct a graph of all the declarations
    and print out a listing. This gives you an idea of what Terraform intends to deploy
    on to the chosen cloud platform. It is therefore your opportunity to examine the
    intended infrastructure and make sure it is what you want to use.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '`terraform plan`的另一个作用是构建所有声明的图表并打印出一个列表。这让你了解 Terraform 打算部署到所选云平台上的内容。因此，这是你检查预期基础架构并确保它是你想要使用的机会。'
- en: 'Once you''re satisfied, run the following command:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您满意了，请运行以下命令：
- en: '[PRE12]js\1'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE12]js\1'
- en: This lists the parameters for the VPC that was created.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这列出了创建的 VPC 的参数。
- en: Remember to either configure the `AWS_PROFILE` environment variable or use `--profile`
    on the command line.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 记得要么配置`AWS_PROFILE`环境变量，要么在命令行上使用`--profile`。
- en: 'To list data on the subnets, run the following command:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 要列出子网上的数据，请运行以下命令：
- en: '[PRE13]js\1'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE13]js\1'
- en: In the Terraform AWS provider, the resource name for EC2 instances is `aws_instance`.
    Since this instance is attached to our public subnet, we'll call it `aws_instance.public`.
    Because it is a public EC2 instance, the `associate_public_ip_address` attribute
    is set to `true`.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在Terraform AWS提供程序中，EC2实例的资源名称是`aws_instance`。由于此实例附加到我们的公共子网，我们将其称为`aws_instance.public`。因为它是一个公共的EC2实例，`associate_public_ip_address`属性设置为`true`。
- en: The attributes include the AMI ID, the instance type, the ID for the subnet,
    and more. The `key_name` attribute refers to the name of an SSH key we'll use
    to log in to the EC2 instance. We'll discuss these key pairs later. The `vpc_security_group_ids`
    attribute is a reference to a security group we'll apply to the EC2 instance.
    The `depends_on` attribute causes Terraform to wait for the creation of the resources
    named in the array. The `user_data` attribute is a shell script that is executed
    inside the instance once it is created.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 属性包括AMI ID、实例类型、子网ID等。`key_name`属性是指我们将用于登录EC2实例的SSH密钥的名称。我们稍后会讨论这些密钥对。`vpc_security_group_ids`属性是指我们将应用于EC2实例的安全组。`depends_on`属性导致Terraform等待数组中命名的资源的创建。`user_data`属性是一个shell脚本，一旦创建实例就在实例内执行。
- en: 'For the AMI, instance type, and key-pair data, add these entries to `variables.tf`,
    as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 对于AMI、实例类型和密钥对数据，请将这些条目添加到`variables.tf`，如下所示：
- en: '[PRE14]js\1'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE14]js\1'
- en: This script is derived from the official instructions for installing Docker
    Engine **Community Edition** (**CE**) on Ubuntu. The first portion is support
    for `apt-get` to download packages from HTTPS repositories. It then configures
    the Docker package repository into Ubuntu, after which it installs Docker and
    related tools. Finally, it ensures that the `docker` group is created and ensures
    that the `ubuntu` user ID is a member of that group. The Ubuntu AMI defaults to
    this user ID, `ubuntu`, to be the one used by the EC2 administrator.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本源自Ubuntu上安装Docker Engine **Community Edition** (**CE**)的官方说明。第一部分是支持`apt-get`从HTTPS存储库下载软件包。然后将Docker软件包存储库配置到Ubuntu中，之后安装Docker和相关工具。最后，确保`docker`组已创建并确保`ubuntu`用户ID是该组的成员。Ubuntu
    AMI默认使用此用户ID `ubuntu` 作为EC2管理员使用的用户ID。
- en: For this EC2 instance, we also run `docker swarm init` to initialize the Docker
    Swarm. For other EC2 instances, we do not run this command. The method used for
    initializing the `user_data` attribute lets us easily have a custom configuration
    script for each EC2 instance. For the other instances, we'll only run `docker_install.sh`,
    whereas for this instance, we'll also initialize the swarm.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此EC2实例，我们还运行`docker swarm init`来初始化Docker Swarm。对于其他EC2实例，我们不运行此命令。用于初始化`user_data`属性的方法让我们可以轻松地为每个EC2实例设置自定义配置脚本。对于其他实例，我们只运行`docker_install.sh`，而对于此实例，我们还将初始化swarm。
- en: 'Back in `ec2-public.tf`, we have two more things to do, and then we can launch
    the EC2 instance. Have a look at the following code block:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 回到`ec2-public.tf`，我们还有两件事要做，然后我们可以启动EC2实例。看一下以下代码块：
- en: '[PRE15]js\1'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE15]js\1'
- en: This will let us know the public IP address and public DNS name. If we're interested,
    the outputs also tell us the private IP address and DNS name.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这将让我们知道公共IP地址和公共DNS名称。如果我们感兴趣，输出还会告诉我们私有IP地址和DNS名称。
- en: Launching the EC2 instance on AWS
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在AWS上启动EC2实例
- en: We have added to the Terraform declarations for creating an EC2 instance.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经添加了用于创建EC2实例的Terraform声明。
- en: 'We''re now ready to deploy this to AWS and see what we can do with it. We already
    know what to do, so let''s run the following command:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好将其部署到AWS并查看我们可以做些什么。我们已经知道该怎么做了，所以让我们运行以下命令：
- en: '[PRE16]js\1'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE16]js\1'
- en: This built our EC2 instance, and we have the IP address and domain name. Because
    the initialization script will have required a couple of minutes to run, it is
    good to wait for a short time before proceeding to test the system.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这构建了我们的EC2实例，我们有了IP地址和域名。因为初始化脚本需要几分钟才能运行，所以最好等待一段时间再进行系统测试。
- en: The `ec2-public-ip` value is the public IP address for the EC2 instance. In
    the following examples, we will put the text `PUBLIC-IP-ADDRESS`, and you must
    of course substitute the IP address your EC2 instance is assigned.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '`ec2-public-ip`值是EC2实例的公共IP地址。在以下示例中，我们将放置文本`PUBLIC-IP-ADDRESS`，当然您必须替换为您的EC2实例分配的IP地址。'
- en: 'We can log in to the EC2 instance like so:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以这样登录到EC2实例：
- en: '[PRE17]js\1'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE17]js\1'
- en: 'It can be inconvenient to remember to add the `-i` flag every time we use SSH.
    To avoid having to use this option, run this command:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 每次使用SSH时记住添加`-i`标志可能会不方便。为了避免使用此选项，运行此命令：
- en: '[PRE18]js\1'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE18]js\1'
- en: 'The setup script was also supposed to have initialized this EC2 instance as
    a Docker Swarm node, and the following command verifies whether that happened:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 设置脚本也应该已经将此EC2实例初始化为Docker Swarm节点，以下命令验证了是否发生了这种情况：
- en: '[PRE19]js\1'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE19]js\1'
- en: The `docker node` command is for managing the nodes in a swarm. In this case,
    there is only one node—this one, and it is shown as not only a manager but as
    the swarm leader. It's easy to be the leader when you're the only node in the
    cluster, it seems.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker node`命令用于管理集群中的节点。在这种情况下，只有一个节点 - 这个节点，并且它被显示为不仅是一个管理者，而且是集群的领导者。当你是集群中唯一的节点时，成为领导者似乎很容易。'
- en: The `docker service` command is for managing the services deployed in the swarm.
    In this context, a service is roughly the same as an entry in the `services` section
    of a Docker compose file. In other words, a service is not the running container
    but is an object describing the configuration for launching one or more instances
    of a given container.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker service`命令用于管理集群中部署的服务。在这种情况下，服务大致相当于Docker compose文件中`services`部分的条目。换句话说，服务不是正在运行的容器，而是描述启动给定容器一个或多个实例的配置的对象。 '
- en: 'To see what this means, let''s start an `nginx` service, as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解这意味着什么，让我们启动一个`nginx`服务，如下所示：
- en: '[PRE20]js\1'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE20]js\1'
- en: Once a service is deployed, we can modify the deployment using the `docker service
    update` command. In this case, we told it to increase the number of instances
    using the `--replicas` option, and we now have three instances of the `nginx`
    container all running on the `notes-public` node.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also run the normal `docker ps` command to see the actual containers,
    as illustrated in the following code block:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]js\1'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Exit the shell on the EC2 instance so that you're at the command line on your
    laptop.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]js\1'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Normally with an EC2 instance, we would use the `-i` option, as shown earlier.
    But after running `ssh-add`, the `-i` option is no longer required.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: 'That enables us to create the following environment variable:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]js\1'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin by deleting the environment variable because we''ll replace it with
    something better, as follows:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]js\1'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: There are times when we must be cognizant of which is the current Docker context
    and when to use which context. This will be useful in the next section when we
    learn how to push the images to AWS ECR.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ve learned a lot in this section, so before heading to the next task, let''s
    clean up our AWS infrastructure. There''s no need to keep this EC2 instance running
    since we used it solely for a quick familiarization tour. We can easily delete
    this instance while leaving the rest of the infrastructure configured. The most
    effective way to so is by renaming `ec2-public.tf` to `ec2-public.tf-disable`,
    and to rerun `terraform apply`, as illustrated in the following code block:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]js\1'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: This command switches the Docker context to the local system.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: To hold the scripts and other files related to managing AWS ECR repositories,
    create a directory named `ecr` as a sibling to `notes`, `users`, and `terraform-swarm`.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: There are several commands required for a build process to create Docker images,
    tag them, and push them to a remote repository. To simplify things, let's create
    a few shell scripts, as well as PowerShell scripts, to record those commands.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: 'The first task is to connect with the AWS ECR service. To this end, create
    a file named `login.sh` containing the following:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]js\1'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: This relies on the AWS Tools for PowerShell package (see [https://aws.amazon.com/powershell/](https://aws.amazon.com/powershell/)),
    which appears to offer some powerful tools that are useful with AWS services.
    In testing, however, this command was not found to work very well.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, the following command was found to work much better, which you can
    put in a file named `login.ps1`:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]js\1'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: 'This script is, of course, following the syntax of the Bash shell. For other
    command environments, you must transliterate it appropriately. To set these variables
    in the Bash shell, run the following command:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]js\1'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: These should be the same values, just in a syntax recognized by Windows.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: We have defined the environment variables being used. Let's now get back to
    defining the process to build Docker images and push them to the ECR.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: Defining a process to build Docker images and push them to the AWS ECR
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We were exploring a build procedure for pushing Docker containers to ECR repositories
    until we started talking about environment variables. Let's return to the task
    at hand, which is to easily build Docker images, create ECR repositories, and
    push the images to the ECR.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned at the beginning of this section, make sure to switch to the *default* Docker
    context. We must do so because it is a policy with Docker Swarm to not use the
    swarm hosts for building Docker images.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: 'To build the images, let''s add a file named `build.sh` containing the following:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]js\1'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, create a companion file named `delete.sh` containing the following:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]js\1'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: The `aws ecr create-repository` command outputs these descriptors for the image
    repositories. The important piece of data to note is the `repositoryUri` value.
    This will be used later in the Docker stack file to name the image to be retrieved.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: The `create.sh` script only needs to be executed once.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: 'Beyond creating the repositories, the workflow is as follows:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Build the images, for which we've already created a script named `build.sh`.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tag the images with the ECR repository **Uniform Resource Identifier** (**URI**).
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Push the images to the ECR repository.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the latter two steps, we still have some scripts to create.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a file named `tag.sh` containing the following:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]js\1'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: The `docker push` command causes the target image to be sent to the ECR repository.
    And again, for Windows, create a file named `push.ps1` containing the same commands
    but with Windows-style environment variable references.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: In both the `tag` and `push` scripts, we are using the repository URI value,
    but have plugged in the two environment variables. This will make it generalized
    in case we deploy Notes to another AWS region.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: 'We have the workflow implemented as scripts, so let''s see now how it is run,
    as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]js\1'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: The `docker build` command automatically adds the tag, `latest`, if we do not
    specify a tag.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, to push the images to the ECR repositories, we execute these commands:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]js\1'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: Remember that swarm hosts are not to be used for building Docker images. At
    the beginning of this section, we switched to the default context so that builds
    would occur on our laptop.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we learned how to set up a build procedure to push our Docker
    images to repositories on the AWS ECR service. This included using some interesting
    tools that simplify building complex build procedures in `package.json` scripts.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: Our next step is learning how to use Docker compose files to describe deployment
    on Docker Swarm.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Docker stack file for deployment to Docker Swarm
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous sections, we learned how to set up an AWS infrastructure using
    Terraform. We've designed a VPC that will house the Notes application stack, we
    experimented with a single-node Docker Swarm cluster built on a single EC2 instance,
    and we set up a procedure to push the Docker images to the ECR.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Our next task is to prepare a Docker stack file for deployment to the swarm.
    A stack file is nearly identical to the Docker compose file we used in [Chapter
    11](b3de2a00-b4df-4552-9cf6-b3f356ef05b9.xhtml), *Deploying Node.js Microservices
    with Docker*. Compose files are used with normal Docker hosts, but stack files
    are used with swarms. To make it a stack file, we add some new tags and change
    a few things, including the networking implementation.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: Earlier, we kicked the tires of Docker Swarm with the `docker service create`
    command to launch a service on a swarm. While that was easy, it does not constitute
    code that can be committed to a source repository, nor is it an automated process.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: In swarm mode, a service is a definition of the tasks to execute on swarm nodes.
    Each service consists of a number of tasks, with this number depending on the replica
    settings. Each task is a container that has been deployed to a node in the swarm.
    There are, of course, other configuration parameters, such as network ports, volume
    connections, and environment variables.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: 'The Docker platform allows the use of the compose file for deploying services
    to a swarm. When used this way, the compose file is referred to as a stack file.
    There is a set of `docker stack` commands for handling the stack file, as follows:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: On a regular Docker host, the `docker-compose.yml` file is called a compose
    file. We use the `docker-compose` command on a compose file.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On a Docker swarm, the `docker-compose.yml` file is called a stack file. We
    use the `docker stack` command on a stack file.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remember that a compose file has a `services` tag, and each entry in that tag
    is a container configuration to deploy. When used as a stack file, each `services`
    tag entry is, of course, a service in the sense just described. This means that
    just as there was a lot of similarity between the `docker run` command and container
    definitions in the compose file, there is a degree of similarity between the `docker
    service create` command and the service entries in the stack file.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: 'One important consideration is a policy that builds must not happen on Swarm
    host machines. Instead, these machines must be used solely for deploying and executing
    containers. This means that any `build` tag in a service listed in a stack file
    is ignored. Instead, there is a `deploy` tag that has parameters for the deployment
    in the swarm, and the `deploy` tag is ignored when the file is used with Compose.
    Put more simply, we can have the same file serve both as a compose file (with
    the `docker compose` command) and as a stack file (with the `docker stack` command),
    with the following conditions:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: When used as a compose file, the `build` tag is used and the `deploy` tag is
    ignored.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When used as a stack file, the `build` tag is ignored and the `deploy` tag is
    used.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another consequence of this policy is the necessity of switching the Docker
    context as appropriate. We have already discussed this issue—that we use the *default* Docker
    context to build images on our laptop and we use the EC2 context when interacting
    with the swarm on the AWS EC2 instances.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: To get started, create a directory named `compose-stack` that's a sibling to
    `compose-local`, `notes`, `terraform-swarm`, and the other directories. Then,
    copy `compose-local/docker-compose.yml` into `compose-stack`. This way, we can
    start from something we know is working well.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: This means that we'll create a Docker stack file from our compose file. There
    are several steps involved, which we'll cover over the next several sections.
    This includes adding deploy tags, configuring networking for the swarm, controlling
    the placement of services in the swarm, storing secrets in the swarm, and other
    tasks.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Docker stack file from the Notes Docker compose file
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With that theory under our belts, let's now take a look at the existing Docker
    compose file and see how to make it useful for deployment to a swarm.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we will require some advanced `docker-compose.yml` features, update the
    version number to the following:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]js\1'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: This tells Docker that we want one instance of each service. Later, we will
    experiment with adding more service instances. We will add other parameters later,
    such as placement constraints. Later, we will want to experiment with multiple
    replicas for both `svc-notes` and `svc-userauth`. It is tempting to put CPU and
    memory limits on the service, but this isn't necessary.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: It is nice to learn that with swarm mode, we can simply change the `replicas`
    setting to change the number of instances.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: 'The next thing to take care of is the image name. While the `build` tag is
    present, remember that it is ignored. For the Redis and database containers, we
    are already using images from Docker Hub, but for `svc-notes` and `svc-userauth`,
    we are building our own containers. This is why, earlier in this chapter, we set
    up a procedure for pushing the images to ECR repositories. We can now reference
    those images from the stack file. This means that we must make the following change:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]js\1'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: To support switching between using this for a swarm, or for a single-host deployment,
    we can leave the `bridge` network setting available but commented out. We would
    then change whether `overlay` or `bridge` networking is active by changing which
    is commented, depending on the context.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: The `overlay` network driver sets up a virtual network across the swarm nodes.
    This network supports communication between the containers and also facilitates
    access to the externally published ports.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: The `overlay` network configures the containers in a swarm to have a domain
    name automatically assigned that matches the service name. As with the `bridge`
    network we used before, containers find each other via the domain name. For a
    service deployed with multiple instances, the `overlay` network ensures that requests
    to that container can be routed to any of its instances. If a connection is made
    to a container but there is no instance of that container on the same host, the `overlay`
    network routes the request to an instance on another host. This is a simple approach
    to service discovery, by using domain names, but extending it across multiple
    hosts in a swarm.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: That took care of the easy tasks for converting the compose file to a stack
    file. There are a few other tasks that will require more attention, however.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: Placing containers across the swarm
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We haven''t done it yet, but we will add multiple EC2 instances to the swarm.
    By default, swarm mode distributes tasks (containers) evenly across the swarm
    nodes. However, we have two considerations that should force some containers to
    be deployed on specific Docker hosts—namely, the following:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: We have two database containers and need to arrange persistent storage for the
    data files. This means that the databases must be deployed to the same instance
    every time so that it can use the same data directory.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The public EC2 instance, named `notes-public`, will be part of the swarm. To
    maintain the security model, most of the services should not be deployed on this
    instance but on the instances that will be attached to the private subnet. Therefore,
    we should strictly control which containers deploy to `notes-public`.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Swarm mode lets us declare the placement requirements for any service. There
    are several ways to implement this, such as matching against the hostname, or
    against labels that can be assigned to each node.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: For documentation on the stack file `placement` tag, refer to [https://docs.docker.com/compose/compose-file/#placement](https://docs.docker.com/compose/compose-file/#placement).
    [](https://docs.docker.com/compose/compose-file/#placement) The documentation
    for the `docker stack create` command includes a further explanation of deployment
    parameters:[ ](https://docs.docker.com/compose/compose-file/#placement)[https://docs.docker.com/engine/reference/commandline/service_create](https://docs.docker.com/engine/reference/commandline/service_create).
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: 'Add this `deploy` tag to the `db-userauth` service declaration:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]js\1'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: This command attaches a label named `type`, with the value `public`, to the
    node named `notes-public`. We use this to set labels, and, as you can see, the
    label can have any name and any value. The labels can then be used, along with
    other attributes, as influence over the placement of containers on swarm nodes.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: 'For the rest of the stack file, add the following placement constraints:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]js\1'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: This is how we store a secret in a Docker swarm. The `docker secret create`
    command first takes the name of the secret, and then a specifier for a file containing
    the text for the secret. This means we can either store the data for the secret
    in a file or—as in this case—we use `-` to specify that the data comes from the
    standard input. In this case, we are using the `printf` command, which is available
    for macOS and Linux, to send the value into the standard input.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: Docker Swarm securely records the secrets as encrypted data. Once you've given
    a secret to Docker, you cannot inspect the value of that secret.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: 'In `compose-stack/docker-compose.yml`, add this declaration at the end:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]js\1'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: This notifies the swarm that the Notes service requires the two secrets. In
    response, the swarm will make the data for the secrets available in the filesystem
    of the container as `/var/run/secrets/TWITTER_CONSUMER_KEY` and `/var/run/secrets/TWITTER_CONSUMER_SECRET`.
    They are stored as in-memory files and are relatively secure.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, the steps required are as follows:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: Use `docker secret create` to register the secret data with the swarm.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the stack file, declare `secrets` in a top-level secrets tag.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In services that require the secrets, declare a `secrets` tag that lists the
    secrets required by this service.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the environments tag for the service, create an environment variable pointing
    to the `secrets` file.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Docker team has a suggested convention for configuration of environment
    variables. You could supply the configuration setting directly in an environment
    variable, such as `TWITTER_CONSUMER_KEY`. However, if the configuration setting
    is in a file, then the filename should be given in a different environment variable
    whose name has `_FILE` appended. For example, we would use `TWITTER_CONSUMER_KEY`
    or `TWITTER_CONSUMER_KEY_FILE`, depending on whether the value is directly supplied
    or in a file.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: This then means that we must rewrite Notes to support reading these values from
    the files, in addition to the existing environment variables.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: 'To support reading from files, add this import to the top of `notes/routes/users.mjs`:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]js\1'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: This is similar to the code we've already used but organized a little differently.
    It first tries to read the Twitter tokens from the environment. Failing that,
    it tries to read them from the named files. Because this code is executing in
    the global context, we must read the files using `readFileSync`.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: If the tokens are available from either source, the `twitterLogin` variable
    is set, and then we enable the support for `TwitterStrategy`. Otherwise, Twitter
    support is disabled. We had already organized the views templates so that if `twitterLogin`
    is `false`, the Twitter login buttons do not appear.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: All of this is what we did in [Chapter 8](1ef2de06-5b7d-44c8-a132-55f822d113cf.xhtml), *Authenticating
    Users with a Microservice*, but with the addition of reading the tokens from a
    file.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: Persisting data in a Docker swarm
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The data persistence strategy we used in [Chapter 11](b3de2a00-b4df-4552-9cf6-b3f356ef05b9.xhtml), *Deploying
    Node.js Microservices with Docker*, required the database files to be stored in
    a volume. The directory for the volume lives outside the container and survives
    when we destroy and recreate the container.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: That strategy relied on there being a single Docker host for running containers.
    The volume data is stored in a directory in the host filesystem. But in swarm
    mode, volumes do not work in a compatible fashion.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: With Docker Swarm, unless we use placement criteria, containers can deploy to
    any swarm node. The default behavior for a named volume in Docker is that the
    data is stored on the current Docker host. If the container is redeployed, then
    the volume is destroyed on the one host and a new one is created on the new host.
    Clearly, that means that the data in that volume is not persistent.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: For documentation about using volumes in a Docker Swarm, refer to [https://docs.docker.com/compose/compose-file/#volumes-for-services-swarms-and-stack-files](https://docs.docker.com/compose/compose-file/#volumes-for-services-swarms-and-stack-files).
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: What's recommended in the documentation is to use placement criteria to force
    such containers to deploy to specific hosts. For example, the criteria we discussed
    earlier deploy the databases to a node with the `type` label equal to `db`.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next section, we will make sure that there is exactly one such node
    in the swarm. To ensure that the database data directories are at a known location,
    let''s change the declarations for the `db-userauth` and `db-notes` containers,
    as follows:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]js\1'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: This declares two EC2 instances that are attached to the private subnet. There's
    no difference between these instances other than the name. Because they're on
    the private subnet, they are not assigned a public IP address.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: Because we use the `private-db1` instance for databases, we have allocated 50
    **gigabytes** (**GB**) for the root device. The `root_block_device` block is for
    customizing the root disk of an EC2 instance. Among the available settings, `volume_size`
    sets its size, in GB.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: Another difference in `private-db1` is the `instance_type`, which we've hardcoded
    to `t2.medium`. The issue is about deploying two database containers to this server.
    A `t2.micro` instance has 1 GB of memory, and the two databases were observed
    to overwhelm this server. If you want the adventure of debugging that situation,
    change this value to be `var.instance_type`, which defaults to `t2.micro`, then
    read the section at the end of the chapter about debugging what happens.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: Notice that for the `user_data` script, we only send in the script to install
    Docker Support, and not the script to initialize a swarm. The swarm was initialized
    in the public EC2 instance. The other instances must instead join the swarm using
    the `docker swarm join` command. Later, we will go over initializing the swarm,
    and see how that's accomplished. For the `public-db1` instance, we also create
    the `/data/notes` and `/data/users` directories, which will hold the database
    data directories.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following code to `ec2-private.tf`:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]js\1'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: 'This is literally not a best practice since it allows any network traffic from
    any IP address to reach the public EC2 instance. However, it does give us the
    freedom to develop the code without worrying about protocols at this moment. We
    will address this later and implement the best security practice. Have a look
    at the following code snippet:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]js\1'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: This is largely the same as before, but with two changes. The first is to add
    references to the private EC2 instances to the `depends_on` attribute. This will
    delay the construction of the public EC2 instance until after the other two are
    running.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: The other change is to extend the shell script attached to the `user_data` attribute.
    The first addition to that script is to set the `type` label on the `notes-public`
    node. That label is used with service placement.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: 'The last change is a script with which we''ll set up the swarm. Instead of
    setting up the swarm in the `user_data` script directly, it will generate a script
    that we will use in creating the swarm. In the `sh` directory, create a file named
    `swarm-setup.sh` containing the following:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]js\1'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: The part between `<<EOF` and `EOF` is supplied as the standard input to the
    `cat` command. The result is, therefore, for `/home/ubuntu/swarm-setup.sh` to
    end up with the text between those markers. An additional detail is that a number
    of variable references are escaped, as in `PEM=\$1`. This is necessary so that
    those variables are not evaluated while setting up this script but are present
    in the generated script.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: This script is processed using the `templatefile` function so that we can use
    template commands. Primarily, that is the `%{for .. }` loop with which we generate
    the commands for configuring each EC2 instance. You'll notice that there is an
    array of data for each instance, which is passed through the `templatefile` invocation.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, the `swarm-setup.sh` script will contain a copy of the following
    pair of commands for each EC2 instance:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]js\1'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: The word `manager` here means that we are requesting a token to join as a manager
    node. To connect a node as a worker, simply replace `manager` with `worker`.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: Once the EC2 instances are deployed, we could log in to `notes-public`, and
    then run this command to get the join token and run that command on each of the
    EC2 instances. The `swarm-setup.sh` script, however, handles this for us. All
    we have to do, once the EC2 hosts are deployed, is to log in to `notes-public`
    and run this script.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: It runs the `docker swarm join-token manager` command, piping that user-friendly
    text through a couple of `sed` commands to extract out the important part. That
    leaves the `join` variable containing the text of the `docker swarm join` command,
    and then it uses SSH to execute that command on each of the instances.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we examined how to automate, as far as possible, the setup
    of the Docker swarm.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: Let's now do it.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the Docker Swarm before deploying the Notes stack
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you make an omelet, it's best to cut up all the veggies and sausage, prepare
    the butter, and whip the milk and eggs into a mix before you heat up the pan.
    In other words, we prepare the ingredients before undertaking the critical action
    of preparing the dish. What we've done so far is to prepare all the elements of
    successfully deploying the Notes stack to AWS using Docker Swarm. It's now time
    to turn on the pan and see how well it works.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: 'We have everything declared in the Terraform files, and we can deploy our complete
    system with the following command:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]js\1'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: We have already run `ssh-add` on our laptop, and therefore SSH and **secure
    copy** (**SCP**) commands can run without explicitly referencing the PEM file.
    However, the SSH on the `notes-public` EC2 instance does not have the PEM file.
    Therefore, to access the other EC2 instances, we need the PEM file to be available.
    Hence, we've used `scp` to copy it to the `notes-public` instance.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to verify the fact that the instances are running and have Docker
    active, type the following command:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]js\1'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see this using SSH to execute the `docker swarm join` command on each
    EC2 instance, causing these two systems to join the swarm, and to set the labels
    on the instances, as illustrated in the following code snippet:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]js\1'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ve already seen how this works and that, having done this, we will be able
    to run Docker commands on our laptop; for example, have a look at the following
    code snippet:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]js\1'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: Remember that a newly created swarm does not have any secrets. To install the
    secrets requires these commands to be rerun.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: 'If you wish to create a shell script to automate this process, consider the
    following:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]js\1'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: Our primary requirement is to adjust the `TWITTER_CALLBACK_HOST` variable. The
    domain name for the `notes-public` instance changes every time we deploy the AWS
    infrastructure. Therefore, `TWITTER_CALLBACK_HOST` must be updated to match.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, we must go to the Twitter developers' dashboard and update the URLs
    in the application settings. As we already know, this is required every time we
    have hosted Notes on a different IP address or domain name. To use the Twitter
    login, we must change the list of URLs recognized by Twitter.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: Updating `TWITTER_CALLBACK_HOST` and the Twitter application settings will let
    us log in to Notes using a Twitter account.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: While here, we should review the other variables and ensure that they're correct
    as well.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: 'The last preparatory step is to log in to the ECR repository. To do this, simply
    execute the following commands:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]js\1'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: This deploys the services, and the swarm responds by attempting to launch each
    service. The `--with-registry-auth` option sends the Docker Registry authentication
    to the swarm so that it can download container images from the ECR repositories.
    This is why we had to log in to the ECR first.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: Verifying the correct launch of the Notes application stack
  id: totrans-320
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It will be useful to monitor the startup process using these commands:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]js\1'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: The error, `no suitable node`, means that the swarm was not able to find a node
    that matches the placement criteria. In this case, the `type=public` label might
    not have been properly set.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: 'The following command is helpful:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]js\1'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: As soon as this is run, the swarm will place the `svc-notes` service on the
    `notes-public` node.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: 'If this happens, it may be useful to add the following command to the `user_data`
    script for `aws_instance.public` (in `ec2-public.tf`), just ahead of setting the
    `type=public` label:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]js\1'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: 'The output will tell you the current status, such as any error in deploying
    the service. However, to investigate connectivity with the EC2 instances, we must
    log in to the `notes-public` instance as follows:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]js\1'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: 'This should work, but the output from `docker node ls` may show the node as `Unreachable`.
    Ask yourself: what happens if a computer runs out of memory? Then, recognize that
    we''ve deployed two database instances to an EC2 instance that has only 1 GB of
    memory—the memory capacity of `t2.micro` EC2 instances as of the time of writing.
    Ask yourself whether it is possible that the services you''ve deployed to a given
    server have overwhelmed that server.'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: 'To test that theory, make the following change in `ec2-private.tf`:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]js\1'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: The `notes_svc-userauth` task has been deployed to `notes-private-svc1`, as
    expected.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: 'To run `cli.mjs`, we must get shell access inside the container. Since it is
    deployed on a private instance, this means that we must first SSH to the `notes-public`
    instance; from there, SSH to the `notes-private-svc1` instance; and from there,
    run the `docker exec` command to launch a shell in the running container, as illustrated
    in the following code block:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]js\1'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: 'This verifies that the user authentication server works and that it can communicate
    with the database. To verify this even further, we can access the database instance,
    as follows:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]js\1'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: This will print the full error, including the originating error that caused
    the failure. You may see the following message printed: `getaddrinfo EAI_AGAIN
    api.twitter.com`. That may be puzzling because that domain name is certainly available.
    However, it might not be available inside the `svc-notes` container due to the
    DNS configuration.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: 'From the `notes-public` instance, we will be able to ping that domain name,
    as follows:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]js\1'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, this will work from inside the container as well. If this fails inside
    the container, it means that the Notes service cannot reach Twitter to handle
    the OAuth dance required to log in with Twitter credentials.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem is that, in this case, Docker set up an incorrect DNS configuration,
    and the container was unable to make DNS queries for many domain names. In the
    Docker Compose documentation, it is suggested to use the following code in the service
    definition:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]js\1'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: 'This increases the number of replicas. Because of the existing placement constraints,
    both instances will deploy to the node with a `type` label of `public`. To update
    the services, it''s just a matter of rerunning the following command:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]js\1'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: And indeed, it shows two instances of the `svc-notes` service. The `2/2` notation
    says that two instances are currently running out of the two instances that were
    requested.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: 'To view the details, run the following command:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]js\1'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, each service deployed to a Docker swarm contains one or more running
    containers.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: 'You''ll notice that this shows `svc-notes` listening on port `3000`. In the
    environment setup, we did not set the `PORT` variable, and therefore `svc-notes`
    will default to listening to port `3000`. Refer back to the output for `docker
    service ls`, and you should see this: `*:80->3000/tcp`, meaning that there is
    mapping being handled in Docker from port `80` to port `3000`.'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: 'That is due to the following setting in `docker-swarm/docker-compose.yml`:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: '```js\1'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: This says to publish port `80` and to map it to port `3000` on the containers.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: In the Docker documentation ([https://docs.docker.com/network/overlay/#bypass-the-routing-mesh-for-a-swarm-service](https://docs.docker.com/network/overlay/#bypass-the-routing-mesh-for-a-swarm-service)),
    we learned that services deployed in a swarm are reachable by the so-called *routing
    mesh*. Connecting to a published port routes the connection to one of the containers
    handling that service. As a result, Docker acts as a load balancer, distributing
    traffic among the service instances you configure.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have—finally—deployed the Notes application stack to a cloud
    hosting environment we built on AWS EC2 instances. We created a Docker swarm,
    configured the swarm, created a stack file with which to deploy our services,
    and we deployed to that infrastructure. We then tested the deployed system and
    saw that it functioned well.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: With that, we can wrap up this chapter.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-358
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter is the culmination of a journey of learning Node.js application
    deployment. We developed an application existing solely on our laptop and added
    a number of useful features. With the goal of deploying that application on a
    public server to gain feedback, we worked on three types of deployment. In [Chapter
    10](176ce11c-dd6f-4ebf-ba14-529be6db28da.xhtml), *Deploying Node.js Applications
    to Linux Servers*, we learned how to launch persistent background tasks on Linux
    using PM2\. In [Chapter 11](b3de2a00-b4df-4552-9cf6-b3f356ef05b9.xhtml), *Deploying
    Node.js Microservices with Docker*, we learned how to dockerize the Notes application
    stack, and how to get it running with Docker.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we built on that and learned how to deploy our Docker containers
    on a Docker Swarm cluster. AWS is a powerful and comprehensive cloud hosting platform
    with a long list of possible services to use. We used EC2 instances in a VPC and
    the related infrastructure.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: To facilitate this, we used Terraform, a popular tool for describing cloud deployments
    not just on AWS but on many other cloud platforms. Both AWS and Terraform are
    widely used in projects both big and small.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: In the process, we learned a lot about AWS, and Terraform, and using Terraform
    to deploy infrastructure on AWS; how to set up a Docker Swarm cluster; and how
    to deploy a multi-container service on that infrastructure.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: We began by creating an AWS account, setting up the AWS CLI tool on our laptop,
    and setting up Terraform. We then used Terraform to define a VPC and the network
    infrastructure within which to deploy EC2 instances. We learned how to use Terraform
    to automate most of the EC2 configuration details so that we can quickly initialize
    a Docker swarm.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: We learned that a Docker compose file and a Docker stack file are very similar
    things. The latter is used with Docker Swarm and is a powerful tool for describing
    the deployment of Docker services.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about both unit testing and functional testing.
    While a core principle of test-driven development is to write the tests before
    writing the application, we've done it the other way around and put the chapter
    about unit testing at the end of the book. That's not to say unit testing is unimportant,
    because it certainly is important.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
