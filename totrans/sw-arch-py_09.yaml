- en: Chapter 9. Deploying Python Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pushing code to production is often the last step in taking an application from
    development to the customer. Though this is an important activity, it often gets
    overlooked in the scheme of importance in a software architect's checklist.
  prefs: []
  type: TYPE_NORMAL
- en: It is a pretty common and fatal mistake to assume that if a system works in
    the development environment, it will work dutifully in production also. For one
    thing, the configuration of a production system is often very different from that
    of a development environment. Many optimizations and debugging that are available
    and taken for granted in a developer's box, are often not available in the production
    setup.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment to production is an art rather than an exact science. The complexity
    of deployment of a system depends on a number of factors, such as the language
    the system is developed in, its runtime portability and performance, the number
    of configuration parameters, whether the system is deployed in a homogeneous or
    heterogeneous environment, binary dependencies, geographic distribution of the
    deployments, deployment automation tooling, and a host of other factors.
  prefs: []
  type: TYPE_NORMAL
- en: In recent years, Python, as an open-source language, has matured in the level
    of automation and support it provides for deploying packages to production systems.
    With its rich availability of built-in and third-party support tools, the pain
    and hassle for production deployments and maintaining deployment systems up to
    date has decreased.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will discuss, briefly, about deployable systems and the
    concept of deployability. We'll spend some time to understand the deployment of
    Python applications, and the tools and processes that the architect can add to
    his repertoire in order to ease the deploying and maintenance of his production
    systems' running applications, written using Python. We will also look at techniques
    and best practices that an architect can adopt to keep his production systems
    chugging along healthily and securely, without frequent downtimes.
  prefs: []
  type: TYPE_NORMAL
- en: Here are the list of topics we would be talking about in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Deployability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Factors affecting Deployability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tiers of software deployment architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Software Deployment in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Packaging Python Code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pip
  prefs: []
  type: TYPE_NORMAL
- en: Virtualenv
  prefs: []
  type: TYPE_NORMAL
- en: Virtualenv and Pip
  prefs: []
  type: TYPE_NORMAL
- en: PyPI – The Python Package Index
  prefs: []
  type: TYPE_NORMAL
- en: Packaging and submission of an application
  prefs: []
  type: TYPE_NORMAL
- en: PyPA
  prefs: []
  type: TYPE_NORMAL
- en: Remote deployments using Fabric
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remote deployments using Ansible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing remote daemons using Supervisor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment – Patterns & Best Practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The deployability of a software system is the ease with which it can be taken
    from development to production. It can be measured in terms of the effort–in terms
    of man-hours, or complexity–in terms of the number of disparate steps required
    for deploying code from a development to production environment.
  prefs: []
  type: TYPE_NORMAL
- en: It is a common mistake to assume that a code that runs well in a development
    or staging system would behave in a similar way in a production system. It is
    not often the case due to the vastly dissimilar requirements that a production
    system has when compared to a development one.
  prefs: []
  type: TYPE_NORMAL
- en: Factors affecting Deployability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here is a brief look at some of the factors that differentiate a production
    system from a development one, which can often give rise to unexpected issues
    in deployment leading to *Production Gotchas*:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Optimizations and debugging**: It is very common for development systems
    to turn off optimizations in code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your code is running in an interpreted runtime like Python, it is common
    to turn on debug configurations, which allows the programmer to generate generous
    tracebacks when an exception occurs. Also any Python interpreter optimizations
    are usually turned off.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, in production systems, the reverse is true – as optimizations
    are turned on and debugging is turned off. This usually requires additional configuration
    to be enabled for the code to work in a similar way. It is also possible (though
    rare) that the program gives a different behavior upon optimization under certain
    circumstances than it does when running unoptimized.
  prefs: []
  type: TYPE_NORMAL
- en: '**Dependencies and versions**: A development environment, usually, has a rich
    installation of development and support libraries for running multiple applications
    that a developer may be working on. Quite often, these may be dependencies which
    are themselves not stale, since developers often work on bleeding edge code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Production systems, on the other hand, need to be carefully prepared using a
    precompiled list of dependencies and their versions. It is quite common to specify
    only mature or stable versions for deployment on production systems. Hence if
    a developer had relied on a feature or bug-fix which was available on an unstable
    (alpha, beta or release-candidate) version of a downstream dependency, one may
    find – too late – that the feature doesn't work in production as intended.
  prefs: []
  type: TYPE_NORMAL
- en: Another common problem is undocumented dependencies or dependencies that need
    to be compiled from source code—this is often a problem with first-time deployments.
  prefs: []
  type: TYPE_NORMAL
- en: '**Resource configuration and access privileges**: Development systems and production
    systems often differ in level, privilege, and details of access of resources locally
    and in the network. A development system may have a local database, whereas, production
    systems tend to use separate hosting for application and database systems. A development
    system may use a standard configuration file, while in production, the configuration
    may have to be generated specifically for a host or an environment using specific
    scripts. Similarly, in production, the application may be required to run with
    lesser privileges as a specific user/group, whereas, in development, it may be
    common to run the program as the root or superuser. Such disparities in user privileges
    and configuration may affect resource access and might cause software to fail
    in production, when it runs fine on the development environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heterogeneous production environments**: Code is usually developed in development
    environments, which are usually homogeneous. But it may often be required to be
    deployed on heterogeneous systems in production. For example, software may be
    developed on Linux, but there may be a requirement for a customer deployment on
    Windows.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The complexity of deployments increases proportionally to heterogeneity in environments.
    Well-managed staging and testing environments are required before such code is
    taken to production. Also, heterogeneous systems make dependency management more
    complex, as a separate list of dependencies needs to be maintained for each target
    system architecture.
  prefs: []
  type: TYPE_NORMAL
- en: '**Security**: In development and testing environments, it is somewhat common
    to give a wide berth to security aspects to save time and to reduce the configuration
    complexity for testing. For example, in a web application, routes which need logins
    may be disabled by using special development environment flags to facilitate quick
    programming and testing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarly, systems used in development environments may often use easy-to-guess
    passwords, such as database systems, web application logins, and others, to make
    routine recall and usage easy. Also, role-based authorization may be ignored to
    facilitate testing.
  prefs: []
  type: TYPE_NORMAL
- en: However, security is critical in production, so these aspects require the opposite
    treatment. Routes which need logins should be enforced as such. Strong passwords
    should be used. Role-based authentication requires to be enforced. These can often
    cause subtle bugs in production where a feature which works in the development
    environment fails in production.
  prefs: []
  type: TYPE_NORMAL
- en: Since these and other similar problems are the bane of deploying code in production,
    standard practices have been defined to make the life of the devops practitioner
    a bit easy. Most companies follow the practice of using isolated environments
    to develop, test, and validate code and applications before pushing them to production.
    Let us take a look at this.
  prefs: []
  type: TYPE_NORMAL
- en: Tiers of software deployment architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To avoid complexities in taking the code from development to testing, and further
    to production, it is common to use a multitiered architecture for each stage of
    the life cycle of the application before deployment to production.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at some of the following common deployment tiers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Development/Test/Stage/Production**: This is the traditional four-tiered
    architecture.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The developers push their code to a development environment, where unit tests
    and developer tests are run. This environment will always be on the latest trunk
    or bleeding edge of the code. Many times this environment is skipped and replaced
    with the local setup on developer's laptops.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The software is then tested by QA or testing engineers on a test environment
    using black-box techniques. They may also run performance tests on this environment.
    This environment is always behind the development environment in terms of code
    updates. Usually, internal releases, tags, or **code dumps** are used to sync
    the QA environment from the development environment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The staging environment tries to mirror the production environment as closely
    as possible. It is the *pre-production* stage, where the software is tested on
    an environment as close as possible to the deployment one to find out issues that
    may occur in production in advance. This is the environment where usually stress
    or load tests are run. It also allows the devops engineer to test out his deployment
    automation scripts, cron jobs, and verify system configuration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Production is, of course, the final tier where software that is tested from
    staging is pushed and deployed. A number of deployments often use identical staging/production
    tiers, and simply switch from one to the other.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Development and Test/Stage/Production**: This is a variation of the previous
    tier, where the development environment also performs the double duty of a testing
    environment. This system is used in companies with agile software development
    practices, where code is pushed at least once a week to production, and there
    is no space or time to keep and manage a separate testing environment. When there
    is no separate development environment – that is when developers use their laptops
    for programming – the testing environment is also a local one.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Development and Test/ Stage and Production**: In this setup, staging and
    production environments are exactly the same with multiple servers used. Once
    a system is tested and verified in staging, it is *pushed* to production by simply
    switching the hosts—the current production system switches to staging, and staging
    switches to production.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apart from these, it is possible to have more elaborate architectures where
    a separate **Integration** environment is used for integration testing, a **Sandbox**
    environment for testing experimental features, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Using a staging system is important to ensure that software is well tested and
    orchestrated in a production-like environment, before pushing the code to production.
  prefs: []
  type: TYPE_NORMAL
- en: Software deployment in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned earlier, Python developers are richly blessed in the various tools
    offered by Python, and its third-party ecosystem in easing and automating the
    deployment of applications and code written using Python.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will briefly take a look at some of these tools.
  prefs: []
  type: TYPE_NORMAL
- en: Packaging Python code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Python comes with built in support for packaging applications for a variety
    of distributions—source, binary, and specific OS-level packaging.
  prefs: []
  type: TYPE_NORMAL
- en: The primary way of packaging source code in Python is to write a `setup.py`
    file. The source can then be packaged with the help of the in-built `distutils`
    library, or the more sophisticated and rich `setuptools` framework.
  prefs: []
  type: TYPE_NORMAL
- en: Before we get introduced to the guts of Python packaging, let us get familiar
    with a couple of closely related tools, namely, `pip` and `virtualenv`.
  prefs: []
  type: TYPE_NORMAL
- en: Pip
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Pip stands for the recursive acronym **Pip installs packages**. Pip is the standard
    and suggested tool to install packages in Python.
  prefs: []
  type: TYPE_NORMAL
- en: We've seen pip in action throughout this book, but so far, we've never seen
    pip itself getting installed, have we?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see this in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Pip](../Images/image00507.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Downloading and installing pip for Python3
  prefs: []
  type: TYPE_NORMAL
- en: The pip installation script is available at [https://bootstrap.pypa.io/get-pip.py](https://bootstrap.pypa.io/get-pip.py).
  prefs: []
  type: TYPE_NORMAL
- en: The steps should be self-explanatory.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this preceding example, there was already a pip version, so the action upgraded
    the existing version instead of doing a fresh install. We can see the version
    details by trying the program with the `–version` option, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Pip](../Images/image00508.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Printing the current version of pip (pip3)
  prefs: []
  type: TYPE_NORMAL
- en: See how pip clearly prints its version number along with the directory location
    of the installation, plus the Python version for which it is installed.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To distinguish between pip for the Python2 and Python3 versions, remember that
    the version installed for Python3 is always named `pip3`. The Python2 version
    is `pip2`, or just `pip`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install a package using pip, simply provide the package name via the command
    `install`. For example, the following screenshot shows installing the `numpy`
    package using `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Pip](../Images/image00509.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: We will not go into further details of using pip here. Instead, let's take a
    look at another tool that works closely with pip in installing the Python software.
  prefs: []
  type: TYPE_NORMAL
- en: Virtualenv
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Virtualenv is a tool that allows developers to create sand-boxed Python environments
    for local development. Let's say that you want to maintain two different versions
    of a particular library or framework for two different applications you are developing
    side by side.
  prefs: []
  type: TYPE_NORMAL
- en: If you are going to install everything to the system Python, then you can keep
    only one version at a given time. The other option is to create different system
    Python installations in different root folders—say, `/opt` instead of `/usr`.
    However, this creates additional overhead and management headaches of paths. Also,
    it wouldn't be possible to get write permission to these folders if you want the
    version dependency to be maintained on a shared host where you don't have superuser
    permissions.
  prefs: []
  type: TYPE_NORMAL
- en: Virtualenv solves the problems of permissions and versions in one go. It creates
    a local installation directory with its own Python executable standard library
    and installer (defaults to pip).
  prefs: []
  type: TYPE_NORMAL
- en: Once the developer has activated the virtual environment thus created, any further
    installations goes to this environment instead of the system Python environment.
  prefs: []
  type: TYPE_NORMAL
- en: Virtualenv can be installed using pip.
  prefs: []
  type: TYPE_NORMAL
- en: The following screenshot shows creating a virtualenv named `appvenv` using the
    `virtualenv` command, and activating the environment along with installing a package
    to the environment.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The installation also installs pip, setuptools, and other dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: '![Virtualenv](../Images/image00510.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: See how the `python` and `pip` commands point to the ones inside the virtual
    environment. The `pip –version` command clearly shows the path of `pip` inside
    the virtual environment folder.
  prefs: []
  type: TYPE_NORMAL
- en: From Python 3.3 onwards, support for virtual environments is built into the
    Python installation via the new `venv` library.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows installing a virtual environment in Python 3.5
    using this library, and installing some packages into it. As usual, take a look
    at Python and pip executable paths:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Virtualenv](../Images/image00511.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The preceding screenshot also shows how to upgrade pip itself via the `pip`
    command.
  prefs: []
  type: TYPE_NORMAL
- en: Virtualenv and pip
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once you''ve set up a virtual environment for your application(s) and installed
    the required packages, it is a good idea to generate the dependencies and their
    versions. This can be easily done via the following command using pip:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This command asks pip to output a list of all the installed Python packages
    along with their versions. This can be saved to a requirements file, and the setup
    duplicated on the server for mirroring deployments:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Virtualenv and pip](../Images/image00512.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following screenshot shows recreating the same setup in another virtual
    environment via the `-r` option of the pip install command, which accepts such
    a file as input:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Virtualenv and pip](../Images/image00513.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our source virtual environment was in Python2, and the target was in Python3\.
    However, pip was able to install the dependencies from the `requirements.txt`
    file without any issues whatsoever.
  prefs: []
  type: TYPE_NORMAL
- en: Relocatable virtual environments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The suggested way to copy package dependencies from one virtual environment
    to another is to perform a freeze, and install via pip as illustrated in the previous
    section. For example, this is the most common way to freeze Python package requirements
    from a development environment, and recreate it successfully on a production server.
  prefs: []
  type: TYPE_NORMAL
- en: One can also try and make a virtual environment relocatable so that it can be
    archived and moved to a compatible system.
  prefs: []
  type: TYPE_NORMAL
- en: '![Relocatable virtual environments](../Images/image00514.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Creating a relocatable virtual environment
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: First, the virtual environment is created as usual.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It is then made relocatable by running `virtualenv –relocatable lenv` on it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This changes some of the paths used by setuptools as relative paths, and sets
    up the system to be relocatable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Such a virtual environment is relocatable to another folder in the same machine,
    or to a folder in a *remote and similar machine*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A relocatable virtual environment doesn't guarantee that it will work if the
    remote environment differs from the machine environment. For example, if your
    remote machine is a different architecture, or even uses a different Linux distribution
    with another type of packaging, the relocation will fail to work. This is what
    is meant by the words *similar machine*.
  prefs: []
  type: TYPE_NORMAL
- en: PyPI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We learned that Pip is the standardized tool to do package installations in
    Python. It is able to pick up any package by name as long as it exists. It is
    also able to install packages by version, as we saw with the example of the requirements
    file.
  prefs: []
  type: TYPE_NORMAL
- en: But where does Pip fetch its packages from?
  prefs: []
  type: TYPE_NORMAL
- en: To answer this, we turn to the Python Package Index, more commonly known as
    PyPI.
  prefs: []
  type: TYPE_NORMAL
- en: '**Python Package Index (PyPI)** is the official repository for hosting metadata
    for third-party Python packages on the Web. As the name implies, it is an index
    to the Python packages on the Web whose metadata is published and indexed on a
    server. PyPI is hosted at the URL [http://pypi.python.org](http://pypi.python.org).'
  prefs: []
  type: TYPE_NORMAL
- en: PyPI hosts close to a million packages at present. The packages are submitted
    to PyPI using Python's packaging and distribution tools, distutils, and setuptools,
    which have hooks for publishing package metadata to PyPI. A number of packages
    also host the actual package data in PyPI, although PyPI can be used to point
    to package data sitting in a URL on another server.
  prefs: []
  type: TYPE_NORMAL
- en: When you install a package using pip, it actually performs the search for the
    package on PyPI, and downloads the metadata. It uses the metadata to find out
    the package's download URL and other information, such as further downstream dependencies,
    which it uses to fetch and install the package for you.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a screenshot of PyPI, which shows the actual count of the packages
    at the time of writing this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![PyPI](../Images/image00515.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'A developer can do quite a few things directly on the PyPI site:'
  prefs: []
  type: TYPE_NORMAL
- en: Register using e-mail address and log in to the site.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After logging in, submit your package directly on the site.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Search for packages via keywords.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Browse for packages via a number of top-level *trove* classifiers, such as Topics,
    Platforms/Operating Systems, Development Status, Licenses, and so on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we are familiar with the suite of all Python packaging and installation
    tools and their relationships, let us try out a small example of packaging a trivial
    Python module and submitting it to PyPI.
  prefs: []
  type: TYPE_NORMAL
- en: Packaging and submission of an application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Remember that we had developed a mandelbrot program, which uses pymp to scale,
    in [Chapter 5](part0040.xhtml#aid-164MG1 "Chapter 5. Writing Applications That
    Scale"), *Writing Applications that Scale*. We will use it as an example of a
    program to develop a package, and a setup.py file, which we will use to submit
    the application to PyPI.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will package the mandelbrot application in a main package consisting of
    two sub-packages as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`mandelbrot.simple`: The sub-package (sub-module) consisting of the basic implementation
    of mandelbrot'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mandelbrot`.mp: The sub package (sub-module) having the PyMP implementation
    of mandelbrot'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is our folder structure for the package:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Packaging and submission of an application](../Images/image00516.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Folder layout of the mandelbrot package
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us quickly analyze the folder structure of the application which we will
    be packaging:'
  prefs: []
  type: TYPE_NORMAL
- en: The top directory is named `mandelbrot`. It has an `__init__.py`, a `README`,
    and a `setup.py` file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This directory has two sub directories—`mp` and `simple`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of these subfolders consists of two files, namely, `__init__.py` and `mandelbrot.py`.
    These subfolders will form our sub-modules, each containing the respective implementation
    of the mandelbrot set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For the purpose of installing the mandelbrot modules as executable scripts,
    the code has been changed to add a `main` method to each of our `mandelbrot.py`
    modules.
  prefs: []
  type: TYPE_NORMAL
- en: The __init__.py files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `__init__.py` files allow to convert a folder inside a Python application
    as a package. Our folder structure has three of them: the first one is for the
    top-level package `mandelbrot`, and the rest two for each of the sub-packages,
    namely, `mandelbrot.simple` and `mandelbrot.mp`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The top-level `__init__.py` is empty. The other two have the following single
    line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The relative imports are to make sure that the sub-packages are importing the
    local `mandelbrot.py` module instead of the top-level `mandelbrot` package.
  prefs: []
  type: TYPE_NORMAL
- en: The setup.py file
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `setup.py` file is the central point of the entire package. Let us take
    a look at it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'A full discussion of the `setup.py` file is outside the scope of this chapter,
    but do note these few key points:'
  prefs: []
  type: TYPE_NORMAL
- en: The `setup.py` file allows the author to create a lot of package metadata such
    as name, author name, e-mail, package keywords, and others. These are useful in
    creating the package meta information, which helps people to search for the package
    in PyPI once it's submitted.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One of the main fields in this file is packages, which is the list of packages
    (and sub-packages) that is created by this `setup.py` file. We make use of the
    `find_packages` helper function provided by the setuptools module to do this.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We provide the installment requirements in the `install-requires` key, which
    lists the dependencies one by one in a PIP-like format.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `entry_points` key is used to configure the console scripts (executable
    programs) that this package installs. Let us look at one of them:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This tells the package resource loader to load the module named `mandelbrot.simple.mandelbrot`,
    and execute its function `main` when the script `mandelbrot` is invoked.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the package
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The package can be now installed using this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot of the installation shows a few of the initial steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Installing the package](../Images/image00517.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have installed this package to a virtual environment named `env3`.
  prefs: []
  type: TYPE_NORMAL
- en: Submitting the package to PyPI
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `setup.py` file plus setuptools/distutils ecosystem in Python is useful
    not just to install and package code, but also to submit code to the Python package
    index.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is very easy to register your package to PyPI. There are just the following
    two requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: A package with a proper setup.py file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An account on the PyPI website.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will now submit our new mandelbrot package to PyPI by performing the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: First, one needs to create a `.pypirc` file in one's home directory containing
    some details—mainly the authentication details for the PyPI account.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here is the author''s `.pypirc` file with the password obscured:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Submitting the package to PyPI](../Images/image00518.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Once this is done, registration is as simple as running `setup.py` with the
    `register` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The next screenshot shows the actual command in action on the console:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Submitting the package to PyPI](../Images/image00519.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: However, this last step has only registered the package by submitting its metadata.
    No package data, as in the source code data, has been submitted as part of this
    step.
  prefs: []
  type: TYPE_NORMAL
- en: 'To submit the source code also to PyPI, the following command should be run:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![Submitting the package to PyPI](../Images/image00520.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here''s a view of our new package on the PyPI server:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Submitting the package to PyPI](../Images/image00521.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now the package is installable via pip, completing the cycle of software development:
    that is first packaging, deployment and then installation.'
  prefs: []
  type: TYPE_NORMAL
- en: PyPA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Python Packaging Authority** (**PyPA**) is a working group of Python developers
    who maintain the standards and the relevant applications related to packaging
    in Python.yPA has their website at [https://www.pypa.io/](https://www.pypa.io/),
    and they maintain the application on GitHub at [https://github.com/pypa/](https://github.com/pypa/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table lists the projects that are maintained by PyPA. You''ve
    already seen some of these, such as pip, virtualenv, and setuptools; others may
    be new:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Project | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| setuptools | A collection of enhancements to Python distutils |'
  prefs: []
  type: TYPE_TB
- en: '| virtualenv | A tool for creating sandbox Python environments |'
  prefs: []
  type: TYPE_TB
- en: '| pip | A tool for installing Python packages |'
  prefs: []
  type: TYPE_TB
- en: '| packaging | Core Python utilities for packaging used by pip and setuptools
    |'
  prefs: []
  type: TYPE_TB
- en: '| wheel | An extension to setuptools for creating wheel distributions, which
    are an alternative to Python eggs (ZIP files) and specified in PEP 427 |'
  prefs: []
  type: TYPE_TB
- en: '| twine | A secure replacement for `setup.py` upload |'
  prefs: []
  type: TYPE_TB
- en: '| warehouse | The new PyPI application, which can be seen at [https://pypi.org](https://pypi.org)
    |'
  prefs: []
  type: TYPE_TB
- en: '| distlib | A low-level library implementing functions relating to packaging
    and distribution of Python code |'
  prefs: []
  type: TYPE_TB
- en: '| bandersnatch | A PyPI mirroring client to mirror the contents of PyPI |'
  prefs: []
  type: TYPE_TB
- en: Interested developers can go visit the PyPA site and sign up for one of the
    projects - and contribute to them in terms of testing, submitting patches and
    so on by visiting the github repository of PyPA.
  prefs: []
  type: TYPE_NORMAL
- en: Remote deployments using Fabric
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Fabric is a command-line tool and library written in Python, which helps to
    automate remote deployments on servers via a set of well-defined wrappers over
    the SSH protocol. It uses the `ssh-wrapper` library, `paramiko`, behind the scenes.
  prefs: []
  type: TYPE_NORMAL
- en: Fabric works with Python 2.x versions only. However, there is a fork Fabric3
    which works for both, the Python 2.x and 3.x versions.
  prefs: []
  type: TYPE_NORMAL
- en: When using fabric, a devops user usually deploys his remote system administrator
    commands as Python functions in a `fabfile` named as `fabfile.py`.
  prefs: []
  type: TYPE_NORMAL
- en: Fabric works best when the remote systems are already configured with the ssh
    public keys of the user's machine from where he performs deployments, so there
    is no need to supply a username and password.
  prefs: []
  type: TYPE_NORMAL
- en: Here is an example of remote deployment on a server. In this case, we are installing
    our mandelbrot application on a remote server.
  prefs: []
  type: TYPE_NORMAL
- en: 'The fabfile looks as follows. See that it is written for Python3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is an example of running this, installing it on a remote server:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Remote deployments using Fabric](../Images/image00522.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Devops engineers and system administrators can use a predefined set of fabfiles
    for automating different system and application deployment tasks across multiple
    servers.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Though it is written in Python, Fabric can be used to automate deployment of
    any kind of remote server administration and configuration tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Remote deployments using Ansible
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ansible is a configuration management and deployment tool written in Python.
    Ansible can be thought of as a wrapper over SSH with scripts with support for
    orchestration via tasks which can be assembled in easy to manage units called
    *playbooks* which map a group of hosts to a set of roles.
  prefs: []
  type: TYPE_NORMAL
- en: Ansible uses "facts" which are system and environment information it gathers
    before it runs tasks. It uses the facts to check if there is any need to change
    any state before running a task to get the desired outcome.
  prefs: []
  type: TYPE_NORMAL
- en: This makes it safe for Ansible tasks to be run on a server in a repeated fashion.
    Well written ansible tasks are *idempotent* in that they have zero to few side
    effects on the remote system.
  prefs: []
  type: TYPE_NORMAL
- en: Ansible is written in Python and can be installed using pip.
  prefs: []
  type: TYPE_NORMAL
- en: It uses its own hosts file namely `/etc/ansible/hosts` to keep the host information
    against which it runs its task.
  prefs: []
  type: TYPE_NORMAL
- en: A typical ansible host file may look like,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The following is a snippet from an Ansible playbook named `dependencies.yaml`
    which installs a few Python packages via pip on a remote host named *webkaffe.*
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Here is an image of running this playbook on the command line using ansible-playbook.
  prefs: []
  type: TYPE_NORMAL
- en: '![Remote deployments using Ansible](../Images/image00520.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Ansible is an easy and efficient way of managing remote dependencies and due
    to its idempotent playbooks, is much better than Fabric at the task.
  prefs: []
  type: TYPE_NORMAL
- en: Managing remote daemons using Supervisor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Supervisor is a client/server system, which is useful to control processes on
    Unix and Unix-like systems. It consists mainly of a server daemon process named
    **supervisord** and a command-line client, which interacts with the server named
    **supervisorctl**.
  prefs: []
  type: TYPE_NORMAL
- en: Supervisor also comes with a basic webserver, which can be accessed via port
    9001\. It is possible to view the state of running processes, and also to start/stop
    them via this interface. Supervisor doesn't run on any version of Windows.
  prefs: []
  type: TYPE_NORMAL
- en: Supervisor is an application written using Python, and hence, is installable
    via pip. It runs only on Python 2.x versions.
  prefs: []
  type: TYPE_NORMAL
- en: Applications to be managed via supervisor should be configured via the supervisor
    daemons configuration file. By default, such files sit in the `/etc/supervisor.d/conf`
    folder.
  prefs: []
  type: TYPE_NORMAL
- en: However, it is possible to run Supervisor locally by installing it to a virtual
    environment, and keeping the configuration local to the virtual environment. In
    fact, this is a common way to run multiple supervisor daemons, each managing processes
    specific to the virtual environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'We won''t go into details or examples of using Supervisor, but here are some
    benefits of using Supervisor vs a traditional approach like system `rc.d` scripts:'
  prefs: []
  type: TYPE_NORMAL
- en: Decoupling process creation/management and process control by using a client/server
    system. The `supervisor.d` file manages the processes via subprocesses. The user
    can get the process state information via supervisorctl, the client. Also, whereas
    most traditional rc.d processes require root or sudo access, supervisor processes
    can be controlled by normal users of the system via the client or through the
    Web UI.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since supervisord starts processes via subprocesses, they can be configured
    to automatically restart upon crash. It is also easier to get a more accurate
    status of the subprocesses rather than relying on PID files.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supervisor supports process groups allowing users to define processes in a priority
    order. Processes can be started and stopped in a specific order as a group. This
    allows to implement fine-grained process control when there is a temporal dependency
    between creation of processes in an application. (Process B requires A to be running,
    C requires B to be running, and the like.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will complete the discussion in this chapter with an overview of the common
    deployment patterns, which an architect can choose from to solve common issues
    with deployability.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment – patterns and best practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are different deployment approaches or patterns that can be used to address
    issues like down-times, reduce risks with deployment, and for a seamless development
    and deployment of software.
  prefs: []
  type: TYPE_NORMAL
- en: '**Continuous deployment**: Continuous deployment is a deployment model where
    software is ready to go live at any time. Continuous delivery is possible only
    if tiers, including development, testing, and staging, are integrated continuously.
    In a continuous deployment model, multiple production deployments can occur in
    a day, and automatically, via a deployment pipeline. Since one is constantly deploying
    incremental changes, the continuous deployment mode minimizes deployment risks.
    In agile software development houses, it also helps the customer to track progress
    directly by seeing live code in production almost as soon as it leaves development
    and testing. There is also the added advantage of getting user feedback faster
    allowing faster iterations to the code and features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**BlueGreen deployment**: We already discussed this in [Chapter 5](part0040.xhtml#aid-164MG1
    "Chapter 5. Writing Applications That Scale") ob scalability. Blue green deployments
    keep two production environments, closely identical to each other. At a given
    instance, one environment is live (Blue). You prepare your new deployment changes
    to the other environment (Green), and once tested and ready to go live, switch
    your systems—Green becomes active and Blue becomes the backup. BlueGreen deployments
    reduce deployment risks considerably, since for anything that goes wrong with
    the new deployment, you just need to switch your router or load-balancer to the
    new environment. Usually, in typical BlueGreen systems, one system is the production
    (live) and other the staging, and you switch the roles between them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Canary releases**: If you want to test the changes in your software on a
    subset of users before deploying it for the entire audience of your customers,
    you can use this approach. In canary release, the changes are rolled out to a
    small subset of users first. A simple approach is dogfooding, where the changes
    are rolled out internally to the employees first. Another approach is beta-testing,
    where a select group of audience is invited to test out your early features. Other
    involved approaches include selecting users based on their geographic location,
    demographics, and profiles. Canary releases, apart from insulating the company
    from sudden user reaction to badly managed features, also allows to manage load
    and capacity scaling in an incremental way. For example, if a particular feature
    becomes popular, and starts driving, say, 100X users to your servers than before,
    a traditional deployment may cause server failures and availability issues as
    opposed to a gradual deployment using a Canary release. Geographical routing is
    a technique that can be used to select a subset of users if you don''t want to
    do complex user profiling and analysis. This is where the load is sent more to
    nodes deployed in a particular geography or data center as opposed to other nodes.
    Canary release is also related to the concept of increment rollout or phased rollout.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bucket testing (A/B testing)**: This is the technique of deploying two dissimilar
    versions of an application or a webpage to production to test out which version
    is more popular and/or has more engagement. In production, a subset of your audience
    sees the A version of the app (or page)—the control or basic version—and the other
    subset sees the B version or the modified (variant) version. Usually, this is
    a 50-50 split, though as with Canary releases, user profiles, geo locations, or
    other complex models can be used. User experience and engagement is collected
    using an analytics dashboard, and then it is determined whether the change had
    a positive, negative, or neutral response.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Induced chaos**: This is a technique of purposely introducing errors or disabling
    part of a production deployment system to test its resilience to failures and/or
    level of availability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Production servers have the problem of drift—unless you use continuous deployment
    or similar approaches for sync, production servers, usually, tend to drift away
    from the standard configuration. One way to test your system is to go and intentionally
    disable part of the production system—this can be done, for example, by disabling
    a random 50% of the nodes in a load-balancer configuration, and see how the rest
    of the system performs.
  prefs: []
  type: TYPE_NORMAL
- en: A similar approach in finding out and weeding unused parts of code is to go
    and inject random secrets in parts of the configuration using, say, an API that
    you suspect is redundant and no longer required. You then observe how the application
    performs in production. Since a random secret will fail the API, if there is an
    active part of the application which still uses the dependent code, it will fail
    in production. Otherwise, it is an indication that the code can be safely removed.
  prefs: []
  type: TYPE_NORMAL
- en: Netflix has a tool called **Chaos Monkey**, which automatically injects failures
    in production systems, and then measures the impact.
  prefs: []
  type: TYPE_NORMAL
- en: Induced Chaos allows the devops engineer and architect to understand weak points
    in the system, learn about systems which are undergoing configuration drift, and
    find and weed out unnecessary or unused parts of an application.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter was about deploying your Python code to production. We looked at
    the different factors that affect the deployability of a system. We went on to
    discuss the tiers in deployment architecture, such as the traditional four-tiered
    and the three- and two- tiered architectures including combinations of development,
    testing, staging/QA, and production tiers.
  prefs: []
  type: TYPE_NORMAL
- en: We then went on to discuss the details of packaging Python code. We discussed
    the tools of pip and virtualenv in detail. We looked at how pip and virtualenv
    can work together, and how to install a set of requirements using pip, and set
    up similar virtual environments using it. We also took a quick look at relocatable
    virtual environments.
  prefs: []
  type: TYPE_NORMAL
- en: We then went to discuss PyPI—the Python Package Index which hosts Python third-party
    packages on the web. We then went through a detailed example of setting up a Python
    package using setuptools and the `setup.py` file. We used the mandelbrot application
    as an example in this case.
  prefs: []
  type: TYPE_NORMAL
- en: We ended that discussion by showing how to register the package to PyPI using
    its metadata, and also how to upload the package data including its code. We also
    took a brief look at PyPA, the Python Packaging Authority and their projects.
  prefs: []
  type: TYPE_NORMAL
- en: After that, two tools—both developed in Python—were discussed– Fabric for remote
    automated deployments, and Supervisor for remote management of processes on Unix
    systems. We finished the chapter with an overview of the common deployment patterns,
    which one can use to solve deployment problems.
  prefs: []
  type: TYPE_NORMAL
- en: In the final chapter of this book, we talk about a variety of techniques of
    Debugging your code to find out potential issues.
  prefs: []
  type: TYPE_NORMAL
