- en: Chapter 5. Friends of Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up until now, we have been busy learning all about Docker. One major factor
    influencing the lifetime of open source projects is the community around it. The
    creators of Docker, Docker Inc. (the offshoot of **dotCloud)**, take care of developing
    and maintaining Docker and its sister projects such as libcontainer, libchan,
    swarm, and so on (the complete list can be found at [github.com/docker](http://github.com/docker)).
    However, like any other open source project, the development is open (in GitHub),
    and they accept pull requests.
  prefs: []
  type: TYPE_NORMAL
- en: The industry has embraced Docker as well. Bigwigs such as Google, Amazon, Microsoft,
    eBay, and RedHat actively use and contribute to Docker. Most popular IaaS solutions
    such as Amazon Web Services, Google Compute Cloud, and so on support creating
    images preloaded with and optimized for Docker. Many start-ups are betting their
    fortunes on Docker as well. CoreOS, Drone.io, and Shippable are some of the start-ups
    that are modeled such that they provide services based around Docker. So you can
    rest assured that it's not going away any time soon.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will discuss some of the projects surrounding Docker and
    how to use them. We will also be looking at projects you may already be familiar
    with that can facilitate your Docker workflow (and make your life a lot easier).
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, we will talk about using Chef and Puppet recipes with Docker. Many
    of you might already be using these tools in your workflow. This section will
    help you integrate Docker with your current workflow, and ease you into the Docker
    ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will try to set up an **apt-cacher** so that our Docker builds won't
    spend a lot of time fetching frequently used packages all the way from Canonical
    server. This will considerably reduce the time it takes to build images from Dockerfiles.
  prefs: []
  type: TYPE_NORMAL
- en: One of the things that gave Docker so much hype in the early stages was how
    easy some things that have been known to be hard seemed so easy when implemented
    with Docker. One such project is **Dokku**, a 100-line bash script that sets up
    a **mini**-**Heroku** like PaaS. We will set up our own PaaS using Dokku in this
    chapter. The very last thing we will be covering in this book is deploying a highly
    available service using CoreOS and Fleet.
  prefs: []
  type: TYPE_NORMAL
- en: 'In short, in this final leg of our journey, we will be looking at the following
    topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Using Docker with Chef and Puppet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up an apt-cacher
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up your own mini-Heroku
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up a highly available service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Docker with Chef and Puppet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When businesses started moving into the cloud, scaling became a whole lot easier
    as one could go from a single machine to hundreds without breaking a sweat. But
    this also meant configuring and maintaining these machines. Configuration management
    tools such as Chef and Puppet arose from the need to automate deploying applications
    in public/private clouds. Today, Chef and Puppet are used every day by start-ups
    and corporates all over the world to manage their cloud environments.
  prefs: []
  type: TYPE_NORMAL
- en: Using Docker with Chef
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Chef''s website states the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Chef turns infrastructure into code. With Chef, you can automate how you
    build, deploy, and manage your infrastructure. Your infrastructure becomes as
    versionable, testable, and repeatable as application code."*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Now, assuming that you have already set up Chef and are familiar with the Chef
    workflow, let's see how to use Docker with Chef using the chef-docker cookbook.
  prefs: []
  type: TYPE_NORMAL
- en: You can install this cookbook with any of the cookbook dependency managers.
    The installation instructions for each of Berkshelf, Librarian, and Knife are
    available at the Chef community site for the cookbook ([https://supermarket.getchef.com/cookbooks/docker](https://supermarket.getchef.com/cookbooks/docker)).
  prefs: []
  type: TYPE_NORMAL
- en: Installing and configuring Docker
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Installing Docker is simple. Just add the `recipe[docker]` command to your run-list
    (the list of configuration settings). An example is worth a million words, so
    let's see how to write a Chef recipe to run the `code.it` file (our sample project)
    on Docker.
  prefs: []
  type: TYPE_NORMAL
- en: Writing a Chef recipe to run Code.it on Docker
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following Chef recipe starts a container based on `code.it`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The first non-comment statement includes the Chef-Docker recipe. The `docker_image
    'shrikrishna/code.it'` statement is equivalent to running the `$ docker pull shrikrishna/code.it`
    command in the console. The block of statements at the end of the recipe is equivalent
    to running the `$ docker run --d -p '8000:8000' -e 'NODE_PORT=8000' -v '/var/log/code.it:/var/log/code.it'
    shrikrishna/code.it` command.
  prefs: []
  type: TYPE_NORMAL
- en: Using Docker with Puppet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'PuppetLabs''s website states the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Puppet is a configuration management system that allows you to define the
    state of your IT infrastructure, then automatically enforces the correct state.
    Whether you''re managing just a few servers or thousands of physical and virtual
    machines, Puppet automates tasks that sysadmins often do manually, freeing up
    time and mental space so sysadmins can work on the projects that deliver greater
    business value."*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Puppet''s equivalent of Chef cookbooks are modules. There is a well-supported
    module available for Docker. Its installation is carried out by running this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Writing a Puppet manifest to run Code.it on Docker
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following Puppet manifest starts a `code.it` container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The first non-comment statement includes the `docker` module. The `docker::image
    {'shrikrishna/code.it':}` statement is equivalent to running the `$ docker pull
    shrikrishna/code.it` command in the console. The block of statements at the end
    of the recipe is equivalent to running the `$ docker run --d -p '8000:8000' -e
    'NODE_PORT=8000' -v '/var/log/code.it:/var/log/code.it' shrikrishna/code.it node
    /srv/app.js` command.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up an apt-cacher
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you have multiple Docker servers, or when you are building multiple unrelated
    Docker images, you might find that you have to download packages every time. This
    can be prevented by having a caching proxy in-between the servers and clients.
    It caches packages as you install them. If you attempt to install a package that
    is already cached, it is served from the proxy server itself, thus reducing the
    latency in fetching packages and greatly speeding up the build process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s write a Dockerfile that sets up an apt-caching server as a caching proxy
    server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This Dockerfile installs the `apt-cacher-ng` package in the image and exposes
    port `3142` (for the target containers to use).
  prefs: []
  type: TYPE_NORMAL
- en: 'Build the image using this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Then run it, binding the exposed port:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'To see the logs, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Using the apt-cacher while building your Dockerfiles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So we have set up an apt-cacher. We now have to use it in our Dockerfiles:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In the second instruction, replace the `<host's-docker0-ip-here>` command with
    your Docker host's IP address (at the `docker0` interface). While building this
    Dockerfile, if it encounters any `apt-get install` installation command for a
    package that has already been installed before (either for this image or for any
    other image), instead of using Docker's or Canonical package repositories, it
    will fetch the packages from the local proxy server, thus speeding up package
    installations in the build process. If the package being installed is not present
    in the cache, then it is fetched from Canonical repositories and saved in the
    cache.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An apt-cacher will only work for Debian-based containers (such as Ubuntu) that
    use the Apt package management tool.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up your own mini-Heroku
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now let's do something cool. For the uninitiated, Heroku is a cloud PaaS, which
    means that all you need to do upon building an application is to push it to Heroku
    and it will get deployed on [https://www.herokuapp.com](https://www.herokuapp.com).
    You don't need to worry how or where your application runs. As long as the PaaS
    supports your technology stack, you can just develop locally and push the application
    to the service to have it running live on the public Internet.
  prefs: []
  type: TYPE_NORMAL
- en: There are a lot of PaaS providers apart from Heroku. Some popular providers
    are Google App Engine, Red Hat Cloud, and Cloud Foundry. Docker was developed
    by one such PaaS provider—dotCloud. Almost every PaaS works by running the applications
    in predefined sandboxed environments, and this is something Docker excels at.
    Today, Docker has made setting up a PaaS easier, if not simple. The project that
    proved this was Dokku. Dokku shares the usage pattern and terminologies (such
    as `buildpacks`, `slug` `builder` scripts) with Heroku, which makes it easier
    to use. In this section, we will be setting up a mini-PaaS using Dokku and pushing
    our `code.it` application.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The next steps should be done on either a **Virtual** **Private** **Server**
    (**VPS**) or a virtual machine. The host you are working from should have git
    and SSH set up.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Dokku using a bootstrapper script
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There is a `bootstrapper` script that will set up Dokku. Run this command inside
    the VPS/virtual machine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Users on version 12.04 will need to run the `$ apt-get install -y python-software-properties`
    command before running the preceding `bootstrapper` script.
  prefs: []
  type: TYPE_NORMAL
- en: The `bootstrapper` script will download all the dependencies and set up Dokku.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Dokku using Vagrant
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Step 1: Clone Dokku:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 2: Set up SSH hosts in your `/etc/hosts` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 3: Set up SSH Config in `~/.ssh/config`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 4: Create a VM'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some optional ENV arguments to set up:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 5 : Copy your SSH key using this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Paste your SSH key in the dokku-installer at `http://dokku.app` (which points
    to `10.0.0.2` as assigned in the `/etc/hosts` file). Change the **Hostname** field
    on the **Dokku Setup** screen to your domain and then check the box that says
    **Use** **virtualhost** **naming**. Then, click on **Finish** **Setup** to install
    your key. You'll be directed to application deployment instructions from here.
  prefs: []
  type: TYPE_NORMAL
- en: You are now ready to deploy an app or install plugins.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring a hostname and adding the public key
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our PaaS will be routing subdomains to applications deployed with the same name.
    This means that the machine where Dokku has been set up must be visible to your
    local setup as well as to the machine where Dokku runs.
  prefs: []
  type: TYPE_NORMAL
- en: Set up a wildcard domain that points to the Dokku host. After running the `bootstrapper`
    script, check whether the `/home/dokku/VHOST` file in the Dokku host is set to
    this domain. It will only be created if the hostname can be resolved by the dig
    tool.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, I have set my Dokku hostname to `dokku.app` by adding the
    following configuration to my `/etc/hosts` file (of the local host):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'I have also set up an SSH port forwarding rule in the `~/.ssh/config` file
    (of the local host):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: According to Wikipedia, **Domain** **Information** **Groper** (**dig**) is a
    network administration command-line tool used to query DNS name servers. This
    means that given a URL, dig will return the IP address of the server that the
    URL points to.
  prefs: []
  type: TYPE_NORMAL
- en: If the `/home/dokku/VHOST` file hasn't been automatically created, you will
    have to manually create it and set it to your preferred domain name. If this file
    is missing when you deploy your application, Dokku will publish the application
    with a port name instead of the subdomain.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last thing to do is to upload your public `ssh` key to the Dokku host and
    associate it with a username. To do so, run this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding command, replace the `dokku.app` name with your domain name
    and `shrikrishna` with your name.
  prefs: []
  type: TYPE_NORMAL
- en: Great! Now that we're up and ready, it's time to deploy our application.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying an application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We now have a PaaS of our own where we can deploy our applications. Let''s
    deploy the `code.it` file there. You can also try deploying your own application
    there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: That's it! We now have a working application in our PaaS. For more details about
    Dokku, you can check out its GitHub repository page at [https://github.com/progrium/dokku](https://github.com/progrium/dokku).
  prefs: []
  type: TYPE_NORMAL
- en: If you want a production-ready PaaS, you must look up Deis at [http://deis.io/](http://deis.io/),
    which provides multi-host and multi-tenancy support.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a highly available service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While Dokku is great to deploy occasional side projects, it may not be suitable
    for larger projects. A large-scale deployment essentially has the following requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Horizontally** **scalable**: There is only so much that can be done with
    a single instance of a server. As the load increases, an organization on the hockey
    stick growth curve will find itself having to balance the load among a cluster
    of servers. In the earlier days, this meant having to design data centers. Today,
    this means adding more instances to the cloud.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fault** **tolerant**: Just as road accidents occur even when there are extensive
    traffic rules in place to avoid them, crashes might occur even after you take
    extensive measures to prevent them, but a crash in one of the instances must not
    create service downtime. A well-designed architecture will handle failure conditions
    and will make another server available to take the place of the server that crashed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Modular**: While this may not seem so, modularity is a defining feature of
    a large-scale deployment. A modular architecture makes it flexible and future-proof
    (because a modular architecture will accommodate newer components as the scope
    and the reach of the organization grow).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is by no means an exhaustive list, but it marks the amount of effort it
    takes to build and deploy a highly available service. However, as we have seen
    until now, Docker is used in a single host, and there are no tools available in
    it (until now) to manage a cluster of instances running Docker.
  prefs: []
  type: TYPE_NORMAL
- en: This is where CoreOS comes in. It is a minimal operating system built with the
    single intention of being the building block in large-scale deployments of services
    on Docker. It comes with a highly available key-value config store called `etcd`,
    which is used for configuration management and service discovery (discovering
    where each of the other components is located in the cluster). The `etcd` service
    was explored in [Chapter 4](ch04.html "Chapter 4. Automation and Best Practices"),
    *Automation and Best Practices*. It also comes with fleet, a tool that leverages
    `etcd` to provide a way to perform actions on the entire cluster as opposed to
    doing so on individual instances.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can think of fleet as an extension of the `systemd` suite that operates
    at the cluster level instead of the machine level. The `systemd` suite is a single-machine
    init system whereas fleet is a cluster init system. You can find out more about
    fleet at [https://coreos.com/using-coreos/clustering/](https://coreos.com/using-coreos/clustering/).
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will try to deploy our standard example, `code.it`, on a
    three-node CoreOS cluster in our local host. This is a representative example
    and an actual multi-host deployment will take a lot more work, but this serves
    as a good starting point. It also helps us appreciate the great work that has
    been done over the years, both in terms of hardware and software, to make it possible,
    even easy, to deploy a high-availability service, a task that had until only a
    few years ago been only possible in huge data centers.
  prefs: []
  type: TYPE_NORMAL
- en: Installing dependencies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Running the preceding example requires the following dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '**VirtualBox**: VirtualBox is a popular type of virtual machine management
    software. Installation executables for your platform can be downloaded from [https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Vagrant**: Vagrant is an open source tool that can be considered a virtual
    machine equivalent for Docker. It can be downloaded from [https://www.vagrantup.com/downloads.html](https://www.vagrantup.com/downloads.html).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Fleetctl**: Fleet is, in short, a distributed init system, which means that
    it will allow us to manage services in a cluster level. Fleetctl is a CLI client
    to interface to run the fleet commands. To install fleetctl, run the following
    commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Getting and configuring the Vagrantfile
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Vagrantfiles are the Vagrant equivalent of Dockerfiles. A Vagrantfile contains
    details such as the base virtual machine to get, the setup commands to run, the
    number of instances of the virtual machine image to start, and so on. CoreOS has
    a repository that contains the Vagrantfile that can be used to download and use
    CoreOS within virtual machines. This is the ideal way to try out CoreOS''s features
    in a development environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The preceding command clones the `coreos-vagrant` repository, which contains
    the Vagrantfile that downloads and starts CoreOS-based virtual machines.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Vagrant is a piece of free and open source software used to create and configure
    virtual development environments. It can be seen as a wrapper around virtualization
    software such as VirtualBox, KVM, or VMware, and around configuration management
    software such as Chef, Salt, or Puppet. You can download Vagrant from [https://www.vagrantup.com/downloads.html](https://www.vagrantup.com/downloads.html).
  prefs: []
  type: TYPE_NORMAL
- en: Before starting the virtual machines though, we have some configuring to do.
  prefs: []
  type: TYPE_NORMAL
- en: Getting discovery tokens
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Each CoreOS host runs an instance of the `etcd` service to coordinate the services
    running in that machine and to communicate with services running in other machines
    in the cluster. For this to happen, the `etcd` instances themselves need to discover
    each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'A discovery service ([https://discovery.etcd.io](https://discovery.etcd.io))
    has been built by the CoreOS team, which provides a free service to help the `etcd`
    instances communicate with each other by storing peer information. It works by
    providing a unique token that identifies the cluster. Each `etcd` instance in
    the cluster identifies every other `etcd` instance with this token using the discovery
    service. Generating a token is easy and is done by sending a `GET` request to
    [discovery.etcd.io/new](http://discovery.etcd.io/new):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Now open the file named `user-data.sample` in the `coreos-vagrant` directory
    and find the commented-out line that holds the `discovery` configuration option
    under the `etcd` service. Uncomment it and provide the token that is returned
    from the previously run `curl` command. Once this is done, rename the file to
    `user-data`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `user-data` file is used to set configuration parameters for the `cloud-config`
    program in CoreOS instances. Cloud-config is inspired by the `cloud-config` file
    from the `cloud-init` project, which defines itself as the DE-facto multi-distribution
    package that handles early initialization of a cloud instance (`cloud-init` docs).
    In short, it helps configure the various parameters such as ports to be opened,
    and in the case of CoreOS, the `etcd` configurations, and so on. You can find
    out more at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://coreos.com/docs/cluster-management/setup/cloudinit-cloud-config/](https://coreos.com/docs/cluster-management/setup/cloudinit-cloud-config/)
    and [http://cloudinit.readthedocs.org/en/latest/index.html](http://cloudinit.readthedocs.org/en/latest/index.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of the code of CoreOS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You will have to generate a new token each time you run the cluster. Simply
    reusing the token will not work.
  prefs: []
  type: TYPE_NORMAL
- en: Setting the number of instances
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the `coreos-vagrant` directory, there is another file called `config.rb.sample`.
    Find the commented line in this file that reads `$num_instances=1`. Uncomment
    it and set the value to `3`. This will make Vagrant spawn three instances of CoreOS.
    Now save the file as `config.rb`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `cnfig.rb` file holds the configurations for the Vagrant environment and
    the number of machines in the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the code example for Vagrant instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Spawning instances and verifying health
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now that we have the configurations ready, it''s time to see a cluster running
    in your local machine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'After the machines are created, you can SSH into them to try out the following
    commands, but you will need to add `ssh` keys to your SSH agent. Doing so will
    allow you to forward your SSH session to other nodes in the cluster. To add the
    keys, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s verify that the machines are up and ask fleet to list the machines
    running in the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Starting the service
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To run a service in your newly started cluster, you will have to write the `unit-files`
    files. Unit files are configuration files that list the services that must be
    run in each machine and some rules on how to manage these services.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create three files named `code.it.1.service`, `code.it.2.service`, and `code.it.3.service`.
    Populate them with the following configurations:'
  prefs: []
  type: TYPE_NORMAL
- en: '`code.it.1.service`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '`code.it.2.service`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '`code.it.3.service`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: You might have noticed a pattern in these files. The `ExecStart` parameter holds
    the command that must be executed in order to start the service. In our case,
    this means running the `code.it` container. `ExecStartPost` is the command that
    is executed once the `ExecStart` parameter succeeds. In our case, the service's
    availability is registered in the `etcd` service. Conversely, the `ExecStop` command
    will stop the service, and the `ExecStopPost` command executes once the `ExecStop`
    command succeeds, which in this case means removing the service's availability
    from the `etcd` service.
  prefs: []
  type: TYPE_NORMAL
- en: '`X-Fleet` is a CoreOS-specific syntax that tells fleet that two services cannot
    run on the same machine (as they would conflict while trying to bind to the same
    port). Now that all the blocks are in place, it''s time to submit the jobs to
    the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s verify that the services have been submitted to the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The machine column is empty and the active status is not set. This means our
    services haven''t started yet. Let''s start them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s verify that they are running by executing the `$ fleetctl list-units`
    file again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Congratulations! You have just set up your very own cluster! Now head over to
    `172.17.8.101`, `172.17.8.102`, or `172.17.8.103` in a web browser and see the
    `code.it` application running!
  prefs: []
  type: TYPE_NORMAL
- en: We have only set up a cluster of machines running a highly available service
    in this example. If we add a load balancer that maintains a connection with the
    `etcd` service to route requests to available machines, we will have a complete
    end-to-end production level service running in our systems. But doing so would
    veer off the topic, so is left as an exercise for you.
  prefs: []
  type: TYPE_NORMAL
- en: With this, we come to the end. Docker is still under active development, and
    so are the projects like CoreOS, Deis, Flynn, and so on. So, although we have
    seen great stuff coming out over the past few months, what is coming is going
    to be even better. We are living in exciting times. So, let's make the best of
    it and build stuff that makes this world a better place to live in. Happy shipping!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to use Docker with Chef and Puppet. Then we
    set up an apt-cacher to speed up package downloads. Next, we set up our own mini
    PaaS with Dokku. In the end, we set up a high-availability service using CoreOS
    and Fleet. Congratulations! Together, we have gained the necessary knowledge of
    Docker to build our containers, "dockerize" our applications and even run clusters.
    Our journey ends here. But for you, dear reader, a new journey has just begun.
    This book was meant to lay the groundwork to help you build the next big thing
    using Docker. I wish you all the success in the world. If you liked this book,
    give me a hoot at `@srikrishnaholla` on Twitter. If you didn't like it, let me
    know how I can make it better.
  prefs: []
  type: TYPE_NORMAL
