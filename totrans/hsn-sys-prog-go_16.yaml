- en: Synchronization with sync and atomic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter will continue the journey into Go concurrency, introducing the
    `sync` and `atomic` packages, which are a couple of other tools designed for orchestrating synchronization
    between goroutines. This will make it possible to write elegant and simple code
    that allows concurrent usage of resources and manages a goroutine's lifetime.
    `sync` contains high-level synchronization primitives, while `atomic` contains
    low-level ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Lockers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wait groups
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other sync components
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `atomic` package
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter requires Go to be installed and your favorite editor to be set
    up. For more information on this, refer to [Chapter 3](602a92d5-25f7-46b8-83d4-10c6af1c6750.xhtml),
    *An Overview of Go*.
  prefs: []
  type: TYPE_NORMAL
- en: Synchronization primitives
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We saw how channels are focused on communication between goroutines, and now
    we will focus on the tools offered by the `sync` package, which includes the basic
    primitives for synchronization between goroutines. The first thing we will see
    is how to implement concurrent access to the same resource with lockers.
  prefs: []
  type: TYPE_NORMAL
- en: Concurrent access and lockers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Go offers a generic interface for objects that can be locked and unlocked.
    Locking an object means taking control over it while unlocking releases it for
    others to use. This interface exposes a method for each operation. The following
    is an example of this in code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Mutex
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most simple implementation of locker is `sync.Mutex`. Since its method has
    a pointer receiver, it should not be copied or passed around by value. The `Lock()` method takes
    control of the mutex if possible, or blocks the goroutine until the mutex becomes
    available. The `Unlock()` method releases the mutex and it returns a runtime error
    if called on a non-locked one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a simple example in which we launch a bunch of goroutines using the
    lock to see which is executed first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The full example is available at: [https://play.golang.org/p/resVh7LImLf](https://play.golang.org/p/resVh7LImLf)
  prefs: []
  type: TYPE_NORMAL
- en: We are using a channel to signal the main goroutine when a job is done, and
    exit the application. Let's create an external counter and increment it concurrently
    using goroutines.
  prefs: []
  type: TYPE_NORMAL
- en: 'Operations executed on different goroutines are not thread-safe, as we can
    see from the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We would expect to have 5000 plus one, and 5000 minus one, with a `0` printed
    in the final instruction. However, what we get are different values each time
    we run the application. This happens because these kind of operations are not
    thread-safe, so two or more of them could happen at the same time, with the last
    one shadowing the others. This kind of phenomena is known as a **race condition**;
    that is, when more than one operation is trying to write the same result.
  prefs: []
  type: TYPE_NORMAL
- en: 'This means that without any synchronization, the result is not predictable;
    if we check the previous example and use a lock to avoid the race condition, we
    will have zero as the value for the integer—the result that we were expecting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'A very common practice is embedding a mutex in a data structure to symbolize
    that the container is the one you want to lock. The counter variable from before
    can be represented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The operations that the counter performs can be methods that already take care
    of locking before the main operation, along with unlocking it afterward, as shown
    in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This will simplify the goroutine loop, resulting in a much clearer code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: RWMutex
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The problem with race conditions is caused by concurred writing, not by reading
    the operation. The other data structure that implements the locker interface, `sync.RWMutex`,
    is made to support both these operations, having write locks that are unique and
    mutually exclusive with read locks. This means that the mutex can be locked either
    by a single write lock, or by one or more read locks. When a reader locks the
    mutex, other readers trying to lock it will not be blocked. They are often referred
    to as shared-exclusive locks. This allows read operations to happen all at the
    same time, without there being a waiting time.
  prefs: []
  type: TYPE_NORMAL
- en: The write lock operations are done using the `Lock` and `Unlock` methods of
    the locker interface. The reading operations are executed using two other methods: `RLock` and `RUnlock`.
    There is another method, `RLocker`, which returns a locker for reading operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can make a quick example of their usage by creating a concurrent list of
    strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We can iterate the slice to find the selected value and use a read lock to
    delay the writing while we are reading:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use the write lock when adding new elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we can try to use several goroutines to execute the same operation on
    the list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We are checking whether the name is contained in the lock first, then we try
    to add the element. This causes more than one routine to attempt to add a new
    element, but since writing locks are exclusive, only one will succeed.
  prefs: []
  type: TYPE_NORMAL
- en: Write starvation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When designing an application, this kind of mutex is not always the obvious
    choice, because in a scenario where there is a greater number of read locks and
    a few write ones, the mutex will be accepting incoming more read locks after the
    first, letting the write operation wait for a moment where there are no read locks
    active. This is a phenomenon referred to as **write starvation**.
  prefs: []
  type: TYPE_NORMAL
- en: 'To check this out, we can define a type that has both a write and a read operation,
    which take some time, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We can try to execute both write and read operations with the same cadence in
    separate goroutines, using a duration that is lower than the execution time of
    the methods (50 ms versus 100 ms). We will also check out how much time they spend
    in a locked state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: If we execute the application, we see that for each write operation, more than
    one read is executed, and each next call is spending more time than the previous,
    waiting for the lock. This is not true for the read operation, which can happen
    at the same time, so as soon as a reader manages to lock the resource, all the
    other waiting readers will do the same. Replacing `RWMutex` with `Mutex` will
    make both operations have the same priority, as in the previous example.
  prefs: []
  type: TYPE_NORMAL
- en: Locking gotchas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Some care must be taken when locking and unlocking mutexes in order to avoid
    unexpected behavior and deadlocks in the application. Take the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This code seems okay at first sight, but it will inevitably block the goroutine.
    This is because the `defer` statement is not executed at the end of each loop
    iteration, but when the function returns. So the first attempt will lock without
    releasing and the second attempt will remain stuck.
  prefs: []
  type: TYPE_NORMAL
- en: 'A little refactor can help fix this, as shown in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We can use a closure to be sure that the deferred `Unlock` gets executed, even
    if `action` panics.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the kind of operations that are executed on the mutex will not cause panic,
    it can be a good idea to ditch the defer and just use it after executing the action,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '`defer` has a cost, so it is better to avoid it when it is not necessary, such
    as when doing a simple variable read or assignment.'
  prefs: []
  type: TYPE_NORMAL
- en: Synchronizing goroutines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Until now, in order to wait for goroutines to finish, we used a channel of
    empty structures and sent a value through the channel as the last operation, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This strategy works, but it''s not the preferred way to accomplish the task.
    It''s not correct semantically, because we are using a channel, which is a tool
    for communication, to send empty data. This use case is about synchronization
    rather than communication. That''s why there is the `sync.WaitGroup` data structure,
    which covers such cases. It has a main status, called counter, which represents
    the number of elements waiting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The `noCopy` field prevents the structure from being copied by value with `panic`.
    The state is an array made by three `int32`, but only the first and last entries
    are used; the remaining one is used for compiler optimizations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `WaitGroup` offers three methods to accomplish the same result:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Add`: This changes the value of the counter using the given value, which could
    also be negative. If the counter goes under zero, the application panics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Done`: This is a shorthand for `Add` with `-1` as the argument. It is usually
    called when a goroutine finishes its job to decrement the counter by 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Wait`: This operation blocks the current goroutine until the counter reaches
    zero.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using the wait group results in a much cleaner and more readable code, as we
    can see in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'To the wait group, we are adding a delta equal to goroutines, which we will
    launch beforehand. In each single goroutine, we are using the `Done` method to
    reduce the count. If the number of goroutines is not known, the `Add` operation
    (with `1` as its argument) can be executed before starting each goroutine, as
    shown in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we have a 10% chance of finishing each iteration of
    the `for` loop, so we are adding one to the group before starting the goroutine.
  prefs: []
  type: TYPE_NORMAL
- en: 'A very common error is to add the value inside the goroutine, which usually
    results in a premature exit without any goroutines executed. This happens because
    the application creates the goroutines and executes the `Wait` function before
    the routines start and add their own delta, as in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This application will not print anything because it arrives at the `Wait` statement
    before any goroutine is started and the `Add` method is called.
  prefs: []
  type: TYPE_NORMAL
- en: Singleton in Go
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The singleton pattern is a commonly used strategy for software development.
    This involves  restricting the number of instances of a certain type to one, using
    the same instance across the whole application. A very simple implementation of
    the concept could be the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This is perfectly fine in a consecutive scenario but in a concurrent one, like
    in many Go applications, this is not thread-safe and could generate race conditions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The previous example could be made thread-safe by adding a lock that would
    avoid any race condition, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: This is safe, but slower, because `Mutex` will be synchronizing each time the
    instance is requested.
  prefs: []
  type: TYPE_NORMAL
- en: 'The best solution to implement this pattern, as shown in the following example,
    is to use the `sync.Once` struct that takes care of executing a function once
    using a combination of `Mutex` and `atomic` readings (which we will see in the
    second part of the chapter):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The resulting code is idiomatic and clear, and has better performance compared
    to the mutex solution. Since the operation will be executed just the once, we
    can also get rid of the `nil` check we were doing on the instance in the previous
    examples.
  prefs: []
  type: TYPE_NORMAL
- en: Once and Reset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `sync.Once` function is made for executing another function once and no
    more. There is a very useful third-party library, which allows us to reset the
    state of the singleton using the `Reset` method.
  prefs: []
  type: TYPE_NORMAL
- en: The package source code can be found at: [github.com/matryer/resync](https://github.com/matryer/resync).
  prefs: []
  type: TYPE_NORMAL
- en: Typical uses include some initialization that needs to be done again on a particular
    error, such as obtaining an API key or dialing again if the connection disrupts.
  prefs: []
  type: TYPE_NORMAL
- en: Resource recycling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have already seen how to implement resource recycling, with a buffered channel with
    a pool of workers, in the previous chapter. There will be two methods as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A `Get` method that tries to receive a message from the channel or return a
    new instance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A `Put` method that tries to return an instance back to a channel or discard it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This is a simple implementation of a pool with channels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We can improve this using the `sync.Pool` structure, which implements a thread-safe
    set of objects that can be saved or retrieved. The only thing that needs to be
    defined is the behavior of the pool when creating a new object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The pool offers two methods: `Get` and `Put`. These methods return an object
    from the pool (or create a new one) and place the object back in the pool. Since
    the `Get` method returns an `interface{}`, the value needs to be cast to the specific
    type in order to be used correctly. We talked extensively about buffer recycling
    and in the following example, we will try to implement one using `sync.Pool`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will need to define the pool and functions to obtain and release new buffers.
    Our buffers will have an initial capacity of 4 KB, and the `Put` function will
    ensure that the buffer is reset before putting it back in the pool, as shown in
    the following code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we will create a series of goroutines, which will use the `WaitGroup` to
    signal when they''re done, and will do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Wait a certain amount of time (1-5 seconds).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Acquire a buffer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Write information on the buffer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Copy the content to the standard output.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Release the buffer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will use a sleep time equal to `1` second, plus another second every `4`
    iterations of the loop, up to `5`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The information in print also contains the buffer memory address. This will
    help us to confirm that the buffers are always the same and no new ones are created.
  prefs: []
  type: TYPE_NORMAL
- en: Slices recycling issues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With data structure with an underlying byte slice, such as `bytes.Buffer`,
    we should be careful when using them combined with `sync.Pool` or a similar mechanism
    of recycling. Let''s change the previous example and collect the buffer''s bytes
    instead of printing them to standard output. The following is an example code
    for this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'So, what happens when we print the list of byte slices? We can see this in
    the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: We get an unexpected result as the buffers have been overwritten. That's because
    the buffers are reusing the same underlying slice and overriding the content with
    every new usage.
  prefs: []
  type: TYPE_NORMAL
- en: 'A solution to this problem is usually to execute a copy of the bytes, instead
    of just assigning them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Conditions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In concurrent programming, a condition variable is a synchronization mechanism
    that contains threads waiting for the same condition to verify. In Go, this means
    that there are some goroutines waiting for something to occur. We already did
    an implementation of this using channels with a single goroutine waiting, as shown
    in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'This approach is limited to a single goroutine, but it can be improved to support
    more listeners switching from message-sending to closing down the channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Closing the channel works for more than one listener, but it does not allow
    them to use the channel any further after it closes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `sync.Cond` type is a tool that makes it possible to handle all this behavior
    in a better way. It uses a locker in its implementation and exposes three methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Broadcast`: This wakes all goroutines waiting for the condition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Signal`: This wakes a single goroutine waiting for the condition, if there
    is at least one.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Wait`: This unlocks the locker, suspends execution of the goroutine, and later
    resumes the execution and locks it again, waiting for a `Broadcast` or `Signal`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is not required, but the `Broadcast` and `Signal` operations can be done
    while holding the locker, locking it before and releasing it after. The `Wait`
    method requires holding the locker before calling and unlocking it after the condition
    has been used.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a concurrent application which uses `sync.Cond` to orchestrate
    more goroutines. We will have a prompt from the command line, and each record
    will be written to a series of files. We will have a main structure that holds
    all the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The condition we will be monitoring is a change in the `buf` field. In the
    `Run` method, the `record` structure will start several goroutines, one for each
    writer. Each goroutine will be waiting for the condition to trigger and will write
    in its file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that we lock the condition before using `Wait`, and we unlock it
    after using the value that our condition refers to. The main function will create
    a record and a series of files, according to the command-line arguments provided:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'We will then use `bufio.Scanner` to read lines and broadcast the change of
    the `buf` field. We will also accept a special value, `\q`, as a quit command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the change of `buf` is done while holding the lock and this
    is followed by the call to `Broadcast`, which wakes up all the goroutines waiting
    for the condition.
  prefs: []
  type: TYPE_NORMAL
- en: Synchronized maps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Built-in maps in Go are not thread-safe, and, therefore, trying to write from
    different goroutines can cause a runtime error: `concurrent map writes`. We can
    verify this using a simple program that tries to make changes concurrently:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Reading while writing is also a runtime error, `concurrent map iteration and
    map write`, which we can see by running the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Sometimes, trying to iterate a map (as the `Print` statement does) can cause
    panic such as `index out of range`, because the internal slices may have been
    allocated somewhere else.
  prefs: []
  type: TYPE_NORMAL
- en: 'A very easy strategy to make a map concurrent is to couple it with `sync.Mutex` or `sync.RWMutex`.
    This makes it possible to lock the map when executing the operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'We use the map for getting or setting the value, such as the following, for
    instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also pass a function that takes a key-value pair and executes it for
    each tuple, while locking the map:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Go 1.9 introduced a structure called `sync.Map` that does exactly this. It
    is a very generic `map[interface{}]interface{}`, which makes it possible to execute
    thread-safe operations using the following methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Load`: Gets a value from the map for the given key.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Store`: Sets a value in the map for the given key.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Delete`: Removes the entry for the given key from the map.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LoadOrStore`: Returns the value for the key, if present, or the stored value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Range`: Calls a function that returns a Boolean for each key-value pair in
    the map. The iteration stops if `false` is returned.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can see how this works in the following snippet, in which we try to attempt
    several writes at the same time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: This application, unlike the version with a regular `Map`, does not crash and
    executes all the operations.
  prefs: []
  type: TYPE_NORMAL
- en: Semaphores
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we saw how it is possible to use channels to create
    weighted semaphores. There is a better implementation in the experimental `sync`
    package. This can be found at: [golang.org/x/sync/semaphore](https://godoc.org/golang.org/x/sync/semaphore).
  prefs: []
  type: TYPE_NORMAL
- en: This implementation makes it possible to create a new semaphore, specifying
    the weight with `semaphore.NewWeighted`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Quotas can be acquired using the `Acquire` method, specifying how many quotas
    you want to acquire. These can be released using the `Release` method, as shown
    in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Acquiring quotas requires another argument besides the number, which is `context.Context`.
    This is another concurrency tool available in Go and we are going to see how to
    use this in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Atomic operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `sync` package delivers synchronization primitives, and, under the hood,
    it is using thread-safe operations on integers and pointers. We can find these
    functionalities in another package called `sync/atomic`, which can be used to
    create tools specific to the user use case, with better performance and less memory
    usage.
  prefs: []
  type: TYPE_NORMAL
- en: Integer operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There is a series of functions for pointers to the different types of integers:'
  prefs: []
  type: TYPE_NORMAL
- en: '`int32   `'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`int64   `'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`uint32  `'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`uint64`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`uintptr `'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This includes a specific type of integer that represents a pointer, `uintptr`.
    The operation available for these types are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Load`: Retrieves the integer value from the pointer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Store`: Stores the integer value in the pointer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Add`: Adds the specified delta to the pointer value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Swap`: Stores a new value in the pointer and returns the old one'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CompareAndSwap`: Swaps the new value for the old one only if this is the same
    as the specified one'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: clicker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This function can be very helpful for defining thread-safe components really
    easily. A very obvious example could be a simple integer counter that uses `Add`
    to change the counter, `Load` to retrieve the current value, and `Store` to reset
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: We can see it in action in a simple program, which tries to read, write, and
    reset the counter concurrently.
  prefs: []
  type: TYPE_NORMAL
- en: 'We define the `clicker` and `WaitGroup` and add the correct number of elements
    to the wait group as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'We can launch a bunch of goroutines doing different actions, such as: 10 reads,
    10 adds, and a reset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: We will see the clicker acting as it is supposed to, executing concurrent sums
    without race conditions.
  prefs: []
  type: TYPE_NORMAL
- en: Thread-safe floats
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `atomic` package offers only primitives for integers, but since `float32`
    and `float64` are stored in the same data structure that `int32` and `int64` use,
    we use them to create an atomic float value.
  prefs: []
  type: TYPE_NORMAL
- en: 'The trick is to use the `math.Floatbits` functions to get the representation
    of a float as an unsigned integer and the `math.Floatfrombits` functions to transform
    an unsigned integer to a float. Let''s see how this works with a `float64`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Creating the `Add` function is a little bit more complicated. We need to get
    the value with `Load`, then compare and swap. Since this operation could fail
    because the load is an `atomic` operation and **compare and swap** (**CAS**) is
    another, we keep trying it until it succeeds in a loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Thread-safe Boolean
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can also use `int32` to represent a Boolean value. We can use the integer `0` as `false`, and `1` as `true`,
    creating a thread-safe Boolean condition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: This will allow us to use the `cond` type as a thread-safe Boolean value.
  prefs: []
  type: TYPE_NORMAL
- en: Pointer operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pointer variables in Go are stored in `intptr` variables, integers large enough
    to hold a memory address. The `atomic` package makes it possible to execute the
    same operations for other integers types. There is a package that allows unsafe
    pointer operations, which offers the `unsafe.Pointer` type that is used in atomic
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we define two integer variables and their relative
    integer pointers. Then we execute a swap of the first pointer with the second:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: After the swap, both pointers are now referring to the second variable; any
    change to the first value does not influence the pointers. Changing the second
    variable changes the value referred to by the pointers.
  prefs: []
  type: TYPE_NORMAL
- en: Value
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The simplest tool we can use is `atomic.Value`. This holds `interface{}` and
    makes it possible to read and write it with thread safety. It exposes two methods, `Store` and `Load`,
    which make it possible to set or retrieve the value. As it happens, for other
    thread-safe tools, `sync.Value` must not be copied after its first use.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can try to have many goroutines to set and read the same value. Each load
    operation gets the latest stored value and there are no errors being raised by
    concurrency:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: This is a very generic container; it can be used for any type of variable and
    the variable type should change from one to another. If the concrete type changes,
    it will make the method panic; the same thing applies to a `nil` empty interface.
  prefs: []
  type: TYPE_NORMAL
- en: Under the hood
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `sync.Value` type stores its data in a non-exported interface, as shown
    by the source code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'It uses a type of `unsafe` package to convert that structure into another one,
    which has the same data structure as an interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Two types with the same exact memory layout can be converted in this way, skipping
    the Go's type safety. This makes it possible to use `atomic` operations with the
    pointers and execute thread-safe `Store` and `Load` operations.
  prefs: []
  type: TYPE_NORMAL
- en: To get the lock for writing values, `atomic.Value` uses a compare and swap operation
    with the `unsafe.Pointer(^uintptr(0))` value (which is `0xffffffff`) in the type;
    it changes the value and replaces the type with the correct one.
  prefs: []
  type: TYPE_NORMAL
- en: In the same way, the load operation loops until the type is different to `0xffffffff`,
    before trying to read the value.
  prefs: []
  type: TYPE_NORMAL
- en: Using this expedient, `atomic.Value` is capable of storing and loading any value
    using other `atomic` operations.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we saw the tools that are available in the Go standard package
    for synchronization. They are located in two packages: `sync`, which provides
    high-level tools such as mutexes, and `sync/atomic`, which executes low-level
    operations.'
  prefs: []
  type: TYPE_NORMAL
- en: First, we saw how to synchronize data using lockers. We saw how to use `sync.Mutex` to
    lock a resource regardless of the operation type, and `sync.RWMutex` to allow
    for concurrent readings and blocking writes. We should be careful using the second
    one because writes could be delayed by consecutive readings.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we saw how to keep track of running operations in order to wait for the
    end of a series of goroutines, using `sync.WaitGroup`. This acts as a thread-safe
    counter for current goroutines and makes it possible to put the current goroutine
    to sleep until it reaches zero, using the `Wait` method.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, we checked the `sync.Once` structure used to execute a functionality
    once, which allows the implementation of a thread-safe singleton, for instance.
    Then we used `sync.Pool` to reuse instances instead of creating new ones when
    possible. The only thing that a pool needs is the function that returns the new
    instance.
  prefs: []
  type: TYPE_NORMAL
- en: The `sync.Condition` struct represents a specific condition and uses a locker
    to change it, allowing a goroutine to wait for the change. This can be delivered
    to a single goroutine using `Signal`, or to all goroutines using `Broadcast`.
    The package also offers a thread-safe version of `sync.Map`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we checked out the functionalities of `atomic`, which are mostly integer
    thread-safe operations: loading, saving, adding, swapping, and CAS. We saw also `atomic.Value`,
    which that makes it possible to change the value of an interface concurrently
    and does not allow it to change type after the first change.'
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will be about the latest element introduced in Go concurrency: `Context`,
    which is an interface that handles deadlines, cancellations, and much more.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What's a race condition?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What happens when you try to execute read and write operations concurrently
    with a map?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What's the difference between `Mutex` and `RWMutex`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why are wait groups useful?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What's the main use of `Once`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can you use a `Pool`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What's the advantage of using atomic operations?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
