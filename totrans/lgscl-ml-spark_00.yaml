- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: Machine learning, at its core, is concerned with algorithms that transform raw
    data into information into actionable intelligence. This fact makes machine learning
    well suited to the predictive analytics of Big Data. Without machine learning,
    therefore, it would be nearly impossible to keep up with these massive streams
    of information altogether. Spark, which is relatively a new and emerging technology,
    provides big data engineers and data scientists a powerful response and a unified
    engine that is both faster and easy to use.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的核心是关注将原始数据转化为可操作智能的算法。这一事实使得机器学习非常适合于大数据的预测分析。因此，如果没有机器学习，要跟上这些大规模信息流几乎是不可能的。相对较新且新兴的技术Spark为大数据工程师和数据科学家提供了一个强大的响应和统一的引擎，既更快速又易于使用。
- en: This allows learners from numerous areas to solve their machine learning problems
    interactively and at much greater scale. The book is designed to enable data scientists,
    engineers, and researchers to develop and deploy their machine learning applications
    at scale so that they can learn how to handle large data clusters in data intensive
    environments to build powerful machine learning models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得来自多个领域的学习者能够以更大规模地交互解决他们的机器学习问题。本书旨在使数据科学家、工程师和研究人员能够开发和部署规模化的机器学习应用程序，以便他们学会如何在数据密集型环境中处理大数据集群，构建强大的机器学习模型。
- en: The contents of the books have been written in a bottom-up approach from Spark
    and ML basics, exploring data with feature engineering, building scalable ML pipelines,
    tuning and adapting them through for the new data and problem types, and finally,
    model building to deployment. To clarify more, we have provided the chapters outline
    in such a way that a new reader with a minimum of knowledge of machine learning
    and programming with Spark will be able to follow the examples and move towards
    some real-life machine learning problems and their solutions.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的内容是从Spark和ML基础开始以自下而上的方式编写的，探索了特征工程中的数据，构建可扩展的ML管道，通过调整和适应新的数据和问题类型，最终进行模型构建和部署。为了更清晰，我们以这样一种方式提供了章节大纲，以便具有最基本的机器学习和Spark编程知识的新读者能够跟随示例，并朝着一些真实的机器学习问题及其解决方案迈进。
- en: What this book covers
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书内容包括以下内容
- en: '[Chapter 1](part0014_split_000.html#DB7S2-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 1. Introduction to Data Analytics with Spark"),* Introduction to Data
    Analytics with Spark*, this chapter covers Spark''s overview, its computing paradigm,
    installation, and help us get started with Spark. It will briefly describe the
    main components of Spark and focus on its new computing advancements with the
    Resilient Distributed Datasets (RDD) and Dataset. It will then focus on the Spark’s
    ecosystem of machine learning libraries. Installing, configuring, and packaging
    a simple machine learning application with Spark and Maven will be demonstrated
    before scaling up on Amazon EC2.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 第1章，*使用Spark进行数据分析简介*，本章介绍了Spark的概述、计算范式、安装，并帮助我们开始使用Spark。它将简要描述Spark的主要组件，并专注于其具有弹性分布式数据集（RDD）和数据集的新计算进展。然后，它将专注于Spark的机器学习库生态系统。在扩展到Amazon
    EC2之前，将演示使用Spark和Maven安装、配置和打包简单的机器学习应用程序。
- en: '[Chapter 2](part0023_split_000.html#LTSU2-5afe140a04e845e0842b44be7971e11a
    "Chapter 2. Machine Learning Best Practices"), *Machine Learning Best Practices*,
    provides a conceptual introduction to statistical machine learning (ML) techniques
    aiming to take a newcomer from a minimal knowledge of machine learning all the
    way to being a knowledgeable practitioner in a few steps. The second part of the
    chapter is focused on providing some recommendations for choosing the right machine
    learning algorithms depending on its application types and requirements. It will
    then go through some best practices when applying large-scale machine learning
    pipelines.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 第2章，*机器学习最佳实践*，提供了对统计机器学习（ML）技术的概念介绍，旨在带领新手从对机器学习的最基本知识到成为熟练的从业者。本章的第二部分侧重于为根据应用类型和要求选择合适的机器学习算法提供一些建议。然后，它将介绍应用大规模机器学习管道时的一些最佳实践。
- en: '[Chapter 3](part0031_split_000.html#TI1E2-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 3. Understanding the Problem by Understanding the Data"), *Understanding
    the Problem by Understanding the Data*, covers in detail the Dataset and Resilient
    Distributed Dataset (RDD) APIs for working with structured data, aiming to provide
    a basic understanding of machine learning problems with the available data. By
    the end, you will be able to deal with basic and complex data manipulation with
    ease. Some comparisons will be made available with basic abstractions in Spark
    using RDD and Dataset-based data manipulation to show gains both in terms of programming
    and performance. In addition, we will guide you on the right track so that you
    will be able to use Spark to persist an RDD or data object in memory, allowing
    it to be reused efficiently across the parallel operations in the later stage.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 第3章，*通过了解数据来理解问题*，详细介绍了用于处理结构化数据的数据集和弹性分布式数据集（RDD）API，旨在提供对可用数据进行基本理解的机器学习问题。最后，您将能够轻松处理基本和复杂的数据操作。将提供使用RDD和基于数据集的数据操作的基本抽象的一些比较，以展示在编程和性能方面的收益。此外，我们将指导您走上正确的道路，以便您能够使用Spark将RDD或数据对象持久化在内存中，从而在后期的并行操作中有效地重复使用。
- en: '[Chapter 4](part0038_split_000.html#147LC2-5afe140a04e845e0842b44be7971e11a
    "Chapter 4. Extracting Knowledge through Feature Engineering"), *Extracting Knowledge
    through Feature Engineering*, explains that knowing the features that should be
    used to create a predictive model is not only vital but also a difficult question
    that may require deep knowledge of the problem domain to be examined. It is possible
    to automatically select those features in data that are most useful or most relevant
    for the problem someone is working on. Considering these questions, this chapter
    covers feature engineering in detail, explaining the reasons to apply it along
    with some best practices in feature engineering.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: In addition to this, theoretical descriptions and examples of feature extraction,
    transformations, and selection applied to large-scale machine learning technique
    using both Spark MLlib and Spark ML APIs will be discussed.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 5](part0043_split_000.html#190862-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 5.  Supervised and Unsupervised Learning by Examples"), *Supervised and
    Unsupervised Learning by Examples*, will provide the practical knowledge surrounding how
    to apply supervised and unsupervised techniques on the available data to new problems
    quickly and powerfully through some widely used examples based on the previous
    chapters. These examples will be demonstrated from the Spark perspective.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 6](part0049_split_000.html#1ENBI2-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 6.  Building Scalable Machine Learning Pipelines"), *Building Scalable
    Machine Learning Pipelines*, explains that the ultimate goal of machine learning
    is to make a machine that can automatically build models from data without requiring
    tedious and time-consuming human involvement and interaction. Therefore, this
    chapter guides the readers through creating some practical and widely used machine
    learning pipelines and applications using Spark MLlib and Spark ML. Both APIs
    will be described in detail, and a baseline use case will also be covered for
    both. Then we will focus towards scaling up the ML application so that it can
    cope up with increasing data loads.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 7](part0059_split_000.html#1O8H62-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 7. Tuning Machine Learning Models"), *Tuning Machine Learning Models*,
    shows that tuning an algorithm or machine learning application can be simply thought
    of as a process by which one goes through and optimizes the parameters that impact
    the model in order to enable the algorithm to perform to its best. This chapter
    aims at guiding the reader through model tuning. It will cover the main techniques
    used to optimize an ML algorithm’s performance. Techniques will be explained both
    from the MLlib and Spark ML perspective. We will also show how to improve the
    performance of the ML models by tuning several parameters, such as hyperparameters,
    grid search parameters with MLlib and Spark ML, hypothesis testing, Random search
    parameter tuning, and Cross-validation.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 8](part0067_split_000.html#1VSLM1-5afe140a04e845e0842b44be7971e11a
    "Chapter 8.  Adapting Your Machine Learning Models"), *Adapting Your Machine Learning
    Models*, covers advanced machine learning techniques that will make algorithms
    adaptable to new data and problem types. It will mainly focus on batch/streaming
    architectures and on online learning algorithms using Spark streaming. The ultimate
    target is to bring dynamism to static machine learning models. Readers will also
    see how the machine learning algorithms learn incrementally from the data, that
    is, the models are updated each time the algorithm sees a new training instance.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 9](part0073_split_000.html#25JP22-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 9.  Advanced Machine Learning with Streaming and Graph Data"), *Advanced
    Machine Learning with Streaming and Graph Data*, explains reader how to apply
    machine learning techniques, with the help of Spark MLlib and Spark ML, on streaming
    and graph data, for example, in topic modeling. The readers will be able to use
    available APIs to build real-time and predictive applications from streaming data
    sources such as Twitter. Through the Twitter data analysis, we will show how to
    perform large-scale social sentiment analysis. We will also show how to develop
    a large-scale movie recommendation system using Spark MLlib, which is an implicit
    part of social network analysis.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 第9章《使用流式和图形数据进行高级机器学习》解释了如何利用Spark MLlib和Spark ML等工具在流式和图形数据上应用机器学习技术，例如在主题建模中。读者将能够利用现有的API从流数据源（如Twitter）构建实时和预测性应用程序。通过Twitter数据分析，我们将展示如何进行大规模社交情感分析。我们还将展示如何使用Spark
    MLlib开发大规模电影推荐系统，这是社交网络分析的一个隐含部分。
- en: '[Chapter 10](part0079_split_000.html#2BASE2-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 10.  Configuring and Working with External Libraries"), *Configuring
    and Working with External Libraries*, guides the reader on using external libraries
    to expand their data analysis. Examples will be given for deploying third-party
    packages or libraries for machine learning applications with Spark core and ML/MLlib.
    We will also discuss how to compile and use external libraries with the core libraries
    of Spark for time series. As promised, we will also discuss how to configure SparkR
    to improve exploratory data manipulation and operations.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 第10章《配置和使用外部库》指导读者如何使用外部库来扩展他们的数据分析。将给出使用第三方包或库在Spark核心和ML/MLlib上进行机器学习应用的示例。我们还将讨论如何编译和使用外部库与Spark的核心库进行时间序列分析。如约定的，我们还将讨论如何配置SparkR以改进探索性数据操作。
- en: What you need for this book
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书所需内容
- en: '**Software requirements:**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**软件要求：**'
- en: 'Following software is required for chapters 1-8 and 10: Spark 2.0.0 (or higher),
    Hadoop 2.7 (or higher), Java (JDK and JRE) 1.7+/1.8+, Scala 2.11.x (or higher),
    Python 2.6+/3.4+, R 3.1+, and RStudio 0.99.879 (or higher) installed. Eclipse
    Mars or Luna (latest) can be used. Moreover, Maven Eclipse plugin (2.9 or higher),
    Maven compiler plugin for Eclipse (2.3.2 or higher) and Maven assembly plugin
    for Eclipse (2.4.1 or higher) are required. Most importantly, re-use the provided
    `pom.xml` file with Packt''s supplements and change the previously-mentioned version
    and APIs accordingly and everything will be sorted out.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 第1-8章和第10章需要以下软件：Spark 2.0.0（或更高版本）、Hadoop 2.7（或更高版本）、Java（JDK和JRE）1.7+/1.8+、Scala
    2.11.x（或更高版本）、Python 2.6+/3.4+、R 3.1+和已安装的RStudio 0.99.879（或更高版本）。可以使用Eclipse
    Mars或Luna（最新版本）。此外，还需要Maven Eclipse插件（2.9或更高版本）、用于Eclipse的Maven编译器插件（2.3.2或更高版本）和用于Eclipse的Maven汇编插件（2.4.1或更高版本）。最重要的是，重复使用Packt提供的`pom.xml`文件，并相应地更改先前提到的版本和API，一切都会得到解决。
- en: For [Chapter 9](part0073_split_000.html#25JP22-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 9.  Advanced Machine Learning with Streaming and Graph Data"), *Advanced
    Machine Learning with Streaming and Graph Data,* almost all the software required,
    mentioned previously, except for the Twitter data collection example, which will
    be shown in Spark 1.6.1\. Therefore, Spark 1.6.1 or 1.6.2 is required, along with
    the Maven-friendly `pom.xml` file.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第9章《使用流式和图形数据进行高级机器学习》，几乎所有先前提到的所需软件都是必需的，除了Twitter数据收集示例，该示例将在Spark 1.6.1中展示。因此，需要Spark
    1.6.1或1.6.2，以及友好的Maven `pom.xml`文件。
- en: '**Operating system requirements:  **'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**操作系统要求：**'
- en: Spark can be run on a number of operating systems including Windows, Mac OS,
    and LINUX. However, Linux distributions are preferable (including Debian, Ubuntu,
    Fedora, RHEL, CentOS and so on). To be more specific, for example, for Ubuntu
    it is recommended to have a 14.04/15.04 (LTS) 64-bit complete installation or
    VMWare player 12 or Virtual Box.  For Windows, Windows (XP/7/8/10) and for Mac
    OS X (10.4.7+) is recommended.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Spark可以在多个操作系统上运行，包括Windows、Mac OS和LINUX。然而，Linux发行版更可取（包括Debian、Ubuntu、Fedora、RHEL、CentOS等）。更具体地说，例如对于Ubuntu，建议使用14.04/15.04（LTS）64位完整安装或VMWare
    player 12或Virtual Box。对于Windows，建议使用Windows（XP/7/8/10），对于Mac OS X（10.4.7+）也是如此。
- en: '**Hardware requirements:**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**硬件要求：**'
- en: To work with Spark smoothly, a machine with at least a core i3 or core i5 processor
    is recommended.  However, to get the best results, core i7 would achieve faster
    data processing and scalability with at least 8 GB RAM (recommended) for a standalone
    mode and at least 32 GB RAM for a single VM, or higher for a cluster. Besides,
    enough storage to run heavy jobs (depending upon the data size you will be handling),
    and preferably at least 50 GB of free disk storage (for stand-alone and for SQL
    warehouse).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了顺利使用Spark，建议使用至少核心i3或核心i5处理器的计算机。然而，为了获得最佳结果，核心i7将实现更快的数据处理和可伸缩性，至少需要8GB RAM（建议）用于独立模式，至少需要32GB
    RAM用于单个VM，或者用于集群的更高内存。此外，需要足够的存储空间来运行繁重的任务（取决于您将处理的数据大小），最好至少有50GB的免费磁盘存储空间（用于独立和SQL仓库）。
- en: Who this book is for
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书适合对象
- en: Python and R are two popular languages for data scientists due to the large
    number of modules or packages that are readily available to help them solve their
    data analytics problems. However, traditional uses of these tools are often limiting,
    as they process data on either a single machine or with main memory-based approaches
    where the movement of data becomes time-consuming, the analysis requires sampling,
    and moving from development to production environments requires extensive re-engineering. To
    address these issues, Spark provides data engineers and data scientists a powerful
    and unified engine that is both faster and easy to use. This allows you to solve
    their machine learning problems interactively and at much greater scale.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, if you are an academic, researcher, data science engineer, or even
    a big data engineer working with large and complex data sets. Furthermore, if
    you want to board your data processing pipelines and machine learning applications
    to scale up more quickly, this book would be a suitable companion to this journey.
    Moreover, Spark provides many language choices, including Scala, Java, and Python.
    This facility will definitely help you to lift your machine learning applications
    on top of Spark and reshape using any one of these programming languages with
    Spark.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: You should be familiar with the basics of machine learning concepts at least.
    Knowledge of open source tools and frameworks such as Apache Spark and Hadoop-based
    MapReduce would be good, but is not essential. A solid background in statistics
    and computational mathematics is expected. In addition, knowledge of Scala, Python,
    and Java is advisable. However, if you are experienced with intermediate programming
    languages, this will help you to understand the discussions and examples demonstrated
    in this book.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: Conventions
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this book, you will find a number of styles of text that distinguish between
    different kinds of information. Here are some examples of these styles, and an
    explanation of their meaning.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: 'Code words in text, database table names, folder names, filenames, file extensions,
    pathnames, dummy URLs, user input and Twitter handles are shown as follows: "We
    can include other contexts through the use of the `include` directive."'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code for creating the Spark session in a Windows environment is
    set as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Or creating simple RDD from the input dataset is set as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Any command-line input or output is written as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**New terms** and **important words** are shown in bold. Words that you see
    on the screen, in menus or dialogue boxes, for example, appear in the text like
    this: "Clicking the **Next** button moves you to the next screen".'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Warnings or important notes appear in a box like this.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Tips and tricks appear like this.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Reader feedback
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome. Let us know what you think about
    this book—what you liked or may have disliked. Reader feedback is important for
    us to develop titles that you really get the most out of.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: To send us general feedback, simply send an e-mail to feedback@packtpub.com,
    and mention the book title via the subject of your message.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: If there is a topic that you have expertise in and you are interested in either
    writing or contributing to a book, see our author guide on [https://www.packtpub.com/books/info/packt/authors](https://www.packtpub.com/books/info/packt/authors).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Customer support
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you are the proud owner of a Packt book, we have a number of things
    to help you to get the most from your purchase.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: Downloading the example code
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can download the example code files for all Packt books you have purchased
    from your account at [http://www.packtpub.com](http://www.packtpub.com). If you
    purchased this book elsewhere, you can visit [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files e-mailed directly to you.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: 'You can download the code files by following these steps:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Log in or register to our website using your e-mail address and password.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用您的电子邮件地址和密码登录或注册我们的网站。
- en: Hover the mouse pointer on the **SUPPORT** tab at the top.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将鼠标指针悬停在顶部的**支持**选项卡上。
- en: Click on **Code Downloads & Errata**.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**代码下载和勘误**。
- en: Enter the name of the book in the **Search** box.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**搜索**框中输入书名。
- en: Select the book for which you're looking to download the code files.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择您要下载代码文件的书籍。
- en: Choose from the drop-down menu where you purchased this book from.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从下拉菜单中选择您购买这本书的地方。
- en: Click on **Code Download**.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**代码下载**。
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 文件下载后，请确保使用最新版本的解压缩软件解压文件夹：
- en: WinRAR / 7-Zip for Windows
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WinRAR / 7-Zip for Windows
- en: Zipeg / iZip / UnRarX for Mac
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zipeg / iZip / UnRarX for Mac
- en: 7-Zip / PeaZip for Linux
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 7-Zip / PeaZip for Linux
- en: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/Large-Scale-Machine-Learning-with-Spark](https://github.com/PacktPublishing/Large-Scale-Machine-Learning-with-Spark).
    We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 该书的代码包也托管在GitHub上，网址为[https://github.com/PacktPublishing/Large-Scale-Machine-Learning-with-Spark](https://github.com/PacktPublishing/Large-Scale-Machine-Learning-with-Spark)。我们还有其他丰富书籍和视频代码包可供下载，网址为[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)。快去看看吧！
- en: Errata
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 勘误
- en: Although we have taken every care to ensure the accuracy of our content, mistakes
    do happen. If you find a mistake in one of our books—maybe a mistake in the text
    or the code—we would be grateful if you would report this to us. By doing so,
    you can save other readers from frustration and help us improve subsequent versions
    of this book. If you find any errata, please report them by visiting [http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    selecting your book, clicking on the errata submission form link, and entering
    the details of your errata. Once your errata are verified, your submission will
    be accepted and the errata will be uploaded on our website, or added to any list
    of existing errata, under the Errata section of that title. Any existing errata
    can be viewed by selecting your title from [http://www.packtpub.com/support](http://www.packtpub.com/support).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们已经尽一切努力确保内容的准确性，但错误还是会发生。如果您在我们的书中发现错误——可能是文本或代码中的错误——我们将不胜感激，如果您能向我们报告。通过这样做，您可以帮助其他读者避免挫败，并帮助我们改进本书的后续版本。如果您发现任何勘误，请访问[http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)报告，选择您的书，点击勘误提交表单链接，并输入您的勘误详情。一旦您的勘误经过验证，您的提交将被接受，并且勘误将被上传到我们的网站上，或者添加到该标题的勘误部分的任何现有勘误列表中。您可以通过从[http://www.packtpub.com/support](http://www.packtpub.com/support)选择您的标题来查看任何现有的勘误。
- en: Piracy
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 盗版
- en: Piracy of copyright material on the Internet is an ongoing problem across all
    media. At Packt, we take the protection of our copyright and licenses very seriously.
    If you come across any illegal copies of our works, in any form, on the Internet,
    please provide us with the location address or website name immediately so that
    we can pursue a remedy.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网上的版权盗版是所有媒体的持续问题。在Packt，我们非常重视保护我们的版权和许可。如果您在互联网上以任何形式发现我们作品的非法副本，请立即向我们提供位置地址或网站名称，以便我们采取补救措施。
- en: Please contact us at copyright@packtpub.com with a link to the suspected pirated
    material.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 请通过copyright@packtpub.com与我们联系，并提供涉嫌盗版材料的链接。
- en: We appreciate your help in protecting our authors, and our ability to bring
    you valuable content.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢您帮助保护我们的作者，以及我们提供有价值内容的能力。
- en: Questions
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You can contact us at questions@packtpub.com if you are having a problem with
    any aspect of the book, and we will do our best to address it.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在书的任何方面遇到问题，请通过questions@packtpub.com与我们联系，我们将尽力解决。
