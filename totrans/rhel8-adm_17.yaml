- en: '*Chapter 14*: Advanced Storage Management with Stratis and VDO'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will learn about **Stratis** and **Virtual Data Optimizer**
    (**VDO**).
  prefs: []
  type: TYPE_NORMAL
- en: Stratis is a storage management tool to simplify running the most typical daily
    tasks. It uses the underlying technologies explained in the previous chapters,
    such as LVM, partition schemas, and filesystems.
  prefs: []
  type: TYPE_NORMAL
- en: VDO is a storage layer that includes a driver that sits between our applications
    and the storage devices to provide deduplication and compression of the data stored,
    as well as tools to manage this functionality. This will allow us, for example,
    to maximize the ability of our system to hold virtual machine (VM) instances that
    will only consume disk space based on what makes them unique, but just storing
    once the data that is common to them.
  prefs: []
  type: TYPE_NORMAL
- en: We can also use VDO for storing different copies of our backups, knowing that
    disk usage will still be optimized.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, we will know how VDO works and what is required
    to set it up for our system.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will explore how to prepare, configure, and use our systems in the following
    sections:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Stratis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing and enabling Stratis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing storage pools and filesystems with Stratis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preparing systems to use VDO
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a VDO volume
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assigning a VDO volume to LVM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing a VDO volume and reviewing stats
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's jump into preparing our systems to use VDO.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is possible to continue the practice of using the VM created at the beginning
    of this book in [*Chapter 1*](B16799_01_Final_SK_ePub.xhtml#_idTextAnchor014),
    *Installing RHEL8*. Any additional packages required for this chapter will be
    indicated and can be downloaded from [https://github.com/PacktPublishing/Red-Hat-Enterprise-Linux-8-Administration](https://github.com/PacktPublishing/Red-Hat-Enterprise-Linux-8-Administration).
  prefs: []
  type: TYPE_NORMAL
- en: We will need, for the *Understanding Stratis* section, the same two disks added
    in [*Chapter 13*](B16799_13_Final_SK_ePub.xhtml#_idTextAnchor169), *Flexible Storage
    Management with LVM*, after all the LVM components have been cleaned up from them.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Stratis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As a new feature, to manage storage, **Stratis** was included in RHEL 8 as a
    technology preview (as of version 8.3 of RHEL). Stratis was created to manage
    local storage by combining a system service, **stratisd**, with the well-known
    tools in LVM (explained in [*Chapter 13*](B16799_13_Final_SK_ePub.xhtml#_idTextAnchor169),
    *Flexible Storage Management with LVM*) and the XFS filesystem (explained in [*Chapter
    12*](B16799_12_Final_SK_ePub.xhtml#_idTextAnchor160), *Managing Local Storage
    and Filesystems*), which makes it very solid and reliable.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The filesystems/pools created with Stratis should always be managed with it,
    and not with the LVM/XFS tools. In the same way, already-created LVM volumes should
    not be managed with Stratis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Stratis combines local disks into **pools** and then distributes the storage
    in **filesystems**, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.1 – Stratis simplified architecture diagram'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16799_14_001.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 14.1 – Stratis simplified architecture diagram
  prefs: []
  type: TYPE_NORMAL
- en: As can be seen, when compared to LVM, Stratis provides a much simpler and easy-to-understand
    interface to storage management. In the following sections, we will install and
    enable Stratis and then use the same disks created in [*Chapter 13*](B16799_13_Final_SK_ePub.xhtml#_idTextAnchor169),
    *Flexible Storage Management with LVM*, to create a pool and a couple of filesystems.
  prefs: []
  type: TYPE_NORMAL
- en: Installing and enabling Stratis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To be able to work with Stratis, we will start by installing it. The two packages
    required to work with it are these:'
  prefs: []
  type: TYPE_NORMAL
- en: '`stratis-cli`: A command-line tool to execute storage management tasks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stratisd`: A system service (also known as a daemon) that takes commands and
    executes the low-level tasks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To install them, we will use the `dnf` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can start the `stratisd` service with `systemctl`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we shall enable it to start at boot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: We can do both tasks with one command, which would be `systemctl enable --now
    stratisd`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s check with `stratis-cli` that the daemon (also known as system service)
    is running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We have it all ready, so it's time to start working on disks. Let's move on
    to the next sub-section.
  prefs: []
  type: TYPE_NORMAL
- en: Managing storage pools and filesystems with Stratis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to have some storage available for Stratis, we will use the `/dev/vdb`
    and `/dev/vdc` disks. We need to be sure that they do not have any logical volumes
    or partitions on them. Let''s review them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We are good: all the LVM-created objects are on disk `/dev/vda`. Let''s check
    the other two disks, `/dev/vdb` and `/dev/vdc`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Disk `/dev/vdc` has no partition table label. We are good with this one. However,
    disk `/dev/vdb` has a partition table. Let''s remove it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: The `dd` command, which stands for disk dump, is used to dump data from devices
    and to devices. The special device `/dev/zero` simply generates zeroes, which
    we use to overwrite the initial sectors of the disk, where the label lives. Please
    use `dd` with care; it may overwrite anything without warning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we are ready to create the first pool with the `stratis` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We currently have the pool created, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.2 – Stratis pool created'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16799_14_002.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 14.2 – Stratis pool created
  prefs: []
  type: TYPE_NORMAL
- en: 'We have the pool created; we can now create a filesystem on top of it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The status of the storage is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.3 – Stratis filesystem created'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16799_14_003.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 14.3 – Stratis filesystem created
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s prepare to mount the filesystem. We need to add the following line in
    `/etc/fstab`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: In order for a Stratis filesystem to be mounted correctly during boot, we shall
    add the `x-systemd.requires=stratisd.service` option so it is mounted after the
    `stratisd` service is started.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can mount it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now extend the pool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'As the underlying layer uses thin-pooling, we do not need to extend the filesystem.
    The storage is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.4 – Stratis pool extended'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16799_14_004.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 14.4 – Stratis pool extended
  prefs: []
  type: TYPE_NORMAL
- en: 'Time to use the `stratis snapshot` command to create a snapshot. Let''s create
    some data and then snapshot it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: 'To see the internal pieces of Stratis, you can run the `lsblk` command. With
    it, you will see the components used by Stratis in a tree: physical devices, allocations
    for metadata and data, pools, and filesystems. All of that is abstracted by Stratis.'
  prefs: []
  type: TYPE_NORMAL
- en: With this, we have seen an overview of Stratis in order to cover the basics
    of its management. Remember that Stratis is in preview and therefore it should
    not be used in production systems.
  prefs: []
  type: TYPE_NORMAL
- en: Let's move on now to other advanced topics in storage management by reviewing
    data deduplication with VDO.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing systems to use VDO
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As mentioned earlier, VDO is a driver, specifically a Linux device-mapper driver,
    that uses two kernel modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kvdo`: This does data compression.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`uds`: This is in charge of deduplication.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Regular storage devices such as local disks, **Redundant Array of Inexpensive
    Disks** (**RAID**), and so on are the final backend where data is stored; the
    VDO layer on top reduces disk usage via the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The removal of zeroed blocks, only storing them in the metadata.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deduplication: Duplicate data blocks are referenced in the metadata but stored
    only once.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Compression, using 4 KB data blocks with a lossless compression algorithm (LZ4:
    [https://lz4.github.io/lz4/](https://lz4.github.io/lz4/)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These techniques have been used in the past in other solutions, such as in thin-provisioned
    **VMs** that only kept the differences between VMs, but VDO makes this happen
    transparently.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to thin-provisioning, VDO can mean faster data throughput, as data can
    be cached by the system controller and several services or even VMs can use that
    data without there being a need for additional disk reads to access it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s install the required packages on our system in order to create VDO volumes
    by installing the `vdo` and `kmod-kvdo` packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Now, with the packages installed, we're ready to create our first volume in
    the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a VDO volume
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create a VDO device, we will make use of the loopback device we created
    in [*Chapter 12*](B16799_12_Final_SK_ePub.xhtml#_idTextAnchor160), *Managing Local
    Storage and Filesystems*, so we will check first whether it''s mounted or not
    by executing this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'If no output is shown, we''re set for creating our `vdo` volume on top of it
    with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.5 – vdo volume creation'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16799_14_005.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 14.5 – vdo volume creation
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the volume has been created, we can execute `vdo status` to get detailed
    information about the volume created, as seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.6 – Output of vdo status'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16799_14_006.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 14.6 – Output of vdo status
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, there's information about the `kvdo` version, the configuration
    file being used, and our volumes (size, compression status, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: The new volume can now be seen via `/dev/mapper/myvdo` (the name we assigned
    with `–n`) and it's ready to be used.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can execute `vdo status|egrep -i "compression|dedupli"` and get an output
    that looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.7 – Checking vdo status for compression and deduplication'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16799_14_007.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 14.7 – Checking vdo status for compression and deduplication
  prefs: []
  type: TYPE_NORMAL
- en: This means that both compression and deduplication are enabled on our volume,
    so we're ready to test the functionality by adding it to an LVM volume in the
    next section.
  prefs: []
  type: TYPE_NORMAL
- en: Assigning a VDO volume to an LVM volume
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we created a VDO volume, which will now become our
    **physical volume** (**PV**) when creating an LVM volume group and some logical
    volumes on top of it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create the PV by running the following sequence of commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '`pvcreate /dev/mapper/myvdo`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`vgcreate myvdo /dev/mapper/myvdo`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`lvcreate -L 15G –n myvol myvdo`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'At this point, our `/dev/myvdo/myvol` is ready to be formatted. Let''s use
    the XFS filesystem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the filesystem has been created, let''s put some data on it by mounting
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Now let's test the VDO volume in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Testing a VDO volume and reviewing the stats
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to test deduplication and compression, we will test with a big file,
    such as the RHEL 8 KVM guest image available at [https://access.redhat.com/downloads/content/479/ver=/rhel---8/8.3/x86_64/product-software](https://access.redhat.com/downloads/content/479/ver=/rhel---8/8.3/x86_64/product-software).
  prefs: []
  type: TYPE_NORMAL
- en: 'Once downloaded, save it as `rhel-8.3-x86_64-kvm.qcow2` and copy it four times
    to our VDO volume:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This would be the typical case for a server holding VMs that start of the same
    base disk image, but do we see any improvement?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s execute `vdostats --human-readable` to verify the data. Note that the
    image downloaded is 1.4 GB, as reported by `ls –si`. The output obtained from
    `vdostats --human-readable` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The original volume (the loopback file) was 20 GB, so that's the size we can
    see, but the LVM volume we created was 15 GB, judging from the output, and we
    see that approximately only 1.2 GB has been consumed, even if we've got four files
    of 1.4 GB each.
  prefs: []
  type: TYPE_NORMAL
- en: The percentage is also very clear. We've saved 75% of the space (three files
    out of four are exact copies). If we make an additional copy, we will see that
    the percentage goes to 80% (1 out of 5 copies).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s check out one of the other approaches, by creating an empty file (filled
    with zeros):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, we were able to write 9.4 GB before the disk completely filled,
    but let''s check the `vdo` stats again with `vdostats --human-readable` as seen
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.8 – Checking the vdostats output'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16799_14_008.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 14.8 – Checking the vdostats output
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, we still have 14.8 GB available and we've increased the disk
    space saved from 80% to 92%, because this big file is empty.
  prefs: []
  type: TYPE_NORMAL
- en: Wait – how, if we're using deduplication and compression, have we filled the
    volume if 92% of it has been saved?
  prefs: []
  type: TYPE_NORMAL
- en: As we did not indicate the logical size of the VDO volume, it set by default
    a 1:1 ratio with the underlying device. This is the safest approach, but we're
    not taking real advantage of the compression and deduplication beyond performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make the most of the optimizations, we can create a bigger logical drive
    on top of the volume we have. For example, if after a long period of time we''re
    pretty sure that the disk optimizations might be similar, we can grow the logical
    size with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This will, of course, not increase the available size, as we defined a PV with
    a volume group and a logical volume on top. So, we will also need to extend it
    by executing these commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '`pvresize /dev/mapper/myvdo`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`lvresize –L +14G /dev/myvdo/myvol`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`xfs_growfs /mnt`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With this, we have extended the physical volume, increased the size of the logical
    volume, and extended the filesystem, so the space is now available to be used.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we now execute `df|grep vdo`, we will see something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.9 – Disk space availability after resizing the volume'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16799_14_009.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 14.9 – Disk space availability after resizing the volume
  prefs: []
  type: TYPE_NORMAL
- en: From this point on, we must be extremely careful, as our real usage of disk
    space might not be as optimized in terms of possible compression as it was before,
    resulting in failures in writes. It is then required to monitor available disk
    space as well as VDO status to ensure that we're not attempting to use more space
    than is available, for example, if the files stored can't be compressed or deduplicated
    at the same ratio.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: It's tempting to set a really big logical volume out of our real physical disk
    space, but we should plan ahead and think about avoiding future problems, such
    as the likelihood of compression ratios not being as high as our optimism. Adequately
    profiling the actual data being stored and the typical compression ratios for
    it can give us a better idea of what is a safe approach to be used while we continue
    to actively monitor disk usage evolution, both for the logical volume and for
    the physical one.
  prefs: []
  type: TYPE_NORMAL
- en: Long ago, when disk space was really expensive (and hard drives were 80 MB in
    total), it became very popular to use tools that allowed an *increase* in disk
    space by using a transparent layer of compression that could make some estimations
    and report bigger space; but in reality, we know that content such as images and
    movies don't compress as well as other document formats such as text files. Some
    document formats, such as the ones used by LibreOffice, are already compressed
    files, so no extra compression benefits are gained.
  prefs: []
  type: TYPE_NORMAL
- en: But this changes when we speak about VMs, where the base for each one is more
    or less equal (based on company policies and standards) and are deployed via cloning
    disk images and later performing small customization, but in essence, sharing
    most of the disk contents.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: In general, bear in mind that optimizations really just mean trade-offs. In
    the case of tuned profiles, you're adjusting throughput for latency, and in our
    case, you're trading CPU and memory resources for disk availability. The only
    way to tell whether something's a worthwhile trade-off is to implement it and
    see how it performs, look at the benefits gained, and then continue to monitor
    performance over time.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned about VDO and Stratis. We've looked at simple
    ways to manage storage, how to save disk space transparently, and how to gain
    some throughput in the process.
  prefs: []
  type: TYPE_NORMAL
- en: With Stratis, we have created a pool with two disks and assigned it to a mountpoint.
    It takes fewer steps than doing so with LVM, but on the other hand, we have less
    control over what we are doing. In any case, we learned how to use this preview
    technology in RHEL 8.
  prefs: []
  type: TYPE_NORMAL
- en: With VDO, we used the volume we created to define an LVM PV and, on top of it,
    a volume group and a logical volume that we've formatted using the knowledge gained
    in previous chapters to store a VM disk image several times, to simulate a scenario
    where several VMs are started from the same base.
  prefs: []
  type: TYPE_NORMAL
- en: We also learned how to check the VDO optimizations and the amount of disk saved.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we're ready to use Stratis instead of LVM to group and distribute storage
    (though not for production). We can also implement VDO for our servers to start
    optimizing disk usage.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about the boot process.
  prefs: []
  type: TYPE_NORMAL
