- en: 'Chapter 4. Getting Fancier: Django Unit Test Extensions'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the last chapter, we started learning how to use unit tests to test Django
    applications. This included learning about some Django-specific support, such
    as how to get test data loaded from fixture files into the database for a particular
    test. So far, though, our testing focus has been on small building blocks that
    make up the application. We have not yet begun to write code to serve up web pages
    for our application, nor considered how we will test whether the pages are served
    properly and contain the correct content. The Django `TestCase` class provides
    support that is useful for this broader kind of testing, which will be the focus
    of this chapter. In this chapter, we will:'
  prefs: []
  type: TYPE_NORMAL
- en: First learn how to use a tests directory for our Django application tests instead
    of a single `tests.py` file. This will allow us to organize the tests logically
    instead of having all sorts of different tests mixed up in a single huge file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Develop some web pages for the survey application. For each, we will write unit
    tests to verify their correct operation, learning the specifics of the `TestCase`
    support for testing Django applications along the way.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Experiment with adding custom validation to the `Survey` model in the admin
    application, and see how to test such customization.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Briefly discuss some aspects of Django's test support that we don't run across
    in our example tests.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we will learn under what conditions it may be necessary to use an alternate
    unit test class, `TransactionTestCase`. This class does not perform as well as
    `TestCase`, but it supports testing some database transaction behavior that is
    not possible with `TestCase`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Organizing tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we set out to write code (and tests) for serving web pages from the
    survey application, let''s consider the tests we have so far. If we run `manage.py
    test survey -v2` and examine the tail end of the output, we can see that we''ve
    already accumulated over a dozen individual tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Two of those, namely the two doctests with labels that start with `survey.models.Survey`,
    are from the `survey/models.py` file. The remaining 13 tests are all in the `survey/tests.py`
    file, which has grown to around 150 lines. Those numbers are not that big, but
    if you consider that we have barely started writing this application, it is clear
    that continuing to simply add to `tests.py` will soon result in an unwieldy test
    file. Since we are about to start moving on from building and testing the survey
    models to building and testing the code that serves web pages, now would be a
    good time to come up with a better organization for tests than a single file.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, this is not hard to do. Nothing in Django requires that the tests
    all reside in a single file; they simply need to be in a Python module named `tests`.
    So, we can create a subdirectory within `survey` named `tests`, and move our existing
    `tests.py` file into it. Since the tests in this file focus on testing the application's
    models, let's also rename it `model_tests.py`. We should also delete the `tests.pyc`
    file from `marketr/survey` since leaving stray `.pyc` files around after Python
    code reorganization can often cause confusion. Finally we need to create an `__init__.py`
    file inside the `tests` directory, so that Python will recognize it as a module.
  prefs: []
  type: TYPE_NORMAL
- en: 'Is that all? Not quite. Django uses `unittest.TestLoader.LoadTestsFromModule`
    to find and automatically load all of the `TestCase` classes in the `tests` module.
    However, we have now moved all of the `TestCase` classes into a submodule of tests,
    named `model_tests`. In order for `LoadTestsFromModule` to find them, we need
    to make them visible in the parent `tests` module, which we can do by adding an
    import for `model_tests` to the `__init__.py` file in `survey/tests`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now are we set? Almost. If we run `manage.py test survey -v2` now, we will
    see that the output reports 14 tests run, whereas the run prior to the reorganization
    reported 15 tests run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Which test is missing? The very last test from the earlier run, that is the
    doctest in the `__test__` dictionary that had been in `tests.py`. Because `__test__`
    starts with an underscore (signaling it is a private attribute), it is not imported
    by `from model_tests import *`. The privacy implied by the naming is not enforced
    by Python, so we could add an explicit import for `__test__` as well to `survey/tests/__init__.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'If we did that and ran the tests again, we would see that we were back to having
    15 tests. However that is a poor solution, since it is not extensible to multiple
    files in the `tests` directory. If we add another file to our `tests` directory,
    say `view_tests.py`, and simply replicate the imports used for `model_tests.py`,
    we will have:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This will not cause any errors, but it also does not quite work. The second
    import of `__test__` completely replaces the first, so the doctests contained
    in `model_tests.py` are lost if we do this.
  prefs: []
  type: TYPE_NORMAL
- en: It would be easy enough to devise an approach that would be extensible to multiple
    files, perhaps by creating our own naming convention for doctests defined within
    individual test files. Then, code in `__init__.py` could create the `__test__`
    dictionary for the overall `tests` module by combining dictionaries from the individual
    test files that defined doctests. But for the purposes of the examples we are
    going to be studying here, that is unnecessarily complicated, since the additional
    tests we will be adding are all unit tests, not doctests.
  prefs: []
  type: TYPE_NORMAL
- en: In fact the doctests now in `model_tests.py` have also been re-implemented as
    unit tests, so they are redundant as tests and could safely be dropped. However,
    they do serve to point out an issue with doctests that will arise if you decide
    to move away from the single-file `tests.py` approach in your own projects. We
    can keep the doctests we already have by simply moving the `__test__` dictionary
    definition from the `model_tests.py` file to the `survey/tests/__init__.py` file.
    Then, if we decide additional doctests (beyond ones in `models.py`) would be useful,
    we can either simply add to this dictionary in `survey/tests/__init__.py` or come
    up with a more sophisticated approach to allow splitting out doctests as well
    as unit tests into different files.
  prefs: []
  type: TYPE_NORMAL
- en: Note that it is not necessary to limit the `tests` directory tree to a single
    level. We could create a subdirectory for model tests, and one for views, and
    further subdivide these tests into individual files. Using the approach we have
    started with here, all that needs to be done is to include the proper imports
    in the various `__init__.py` files so that the test cases are visible at the top
    level of the `tests` package. How deep to make the tree and how small to make
    the individual test files are matters of personal preference. We will stick to
    a single level for now.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, note that you can take full control of what tests make up your application's
    test suite by defining a `suite()` function in the `models` and/or `tests` module
    for the application. The Django test runner looks for such a function in each
    of these modules, and if `suite()` exists, it is called to create the test suite.
    If provided, the `suite()` function must return an object suitable for passing
    as an argument to `unittest.TestSuite.addTest` (for example, a `unittest.TestSuite`).
  prefs: []
  type: TYPE_NORMAL
- en: Creating the survey application home page
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is now time to turn our attention to building some web pages for the survey
    application. The first page to consider is the home page, which will be the starting
    point for general users doing anything with surveys. Ultimately, we would likely
    plan for this page to have many different elements, such as a standard header
    and footer, also maybe a sidebar or two for news and feedback. We'd plan to develop
    comprehensive stylesheets to give the application a pretty and consistent appearance.
    But all of that is beside the point of what we want to focus on right now, which
    is the main content of the home page.
  prefs: []
  type: TYPE_NORMAL
- en: 'The primary function of the home page will be to provide a snapshot overview
    of the current state of surveys, and to provide links, where appropriate, to allow
    users to see details on individual surveys. The home page will show surveys grouped
    into three categories:'
  prefs: []
  type: TYPE_NORMAL
- en: First, there will be a list of currently open surveys. Each survey in this list
    will have a link for users to follow if they want to participate in the survey.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second, there will be a list of recently completed surveys. Each of these will
    also have a link to follow, but this link will bring up a page that allows users
    to see the survey results.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Third, there will be a list of surveys that will be opening soon. Surveys in
    this list will not have links since users cannot participate yet, nor are there
    results to be seen.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In order to build and test this home page we need to do four things:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to define the URLs that will be used to access the home page
    and any pages it links to, and define in the `urls.py` file how these URLs should
    map to the view code that will serve the pages.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Second, we need to implement the view code for serving the pages identified
    in step 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Third, we need to define the Django templates that will be used to render the
    responses generated in step 2.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we need to write tests for each page.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The following sections will focus on each of these steps in turn.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the survey application URLs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'From the description of the survey home page, it sounds like we may have two
    or three different URLs to define. Certainly there is the home page itself, which
    is most naturally placed at the root of the survey application''s URL tree. We
    can define this by creating a `urls.py` file within the `survey` directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Here we have specified that a request for the empty (root) URL should be handled
    by the `home` function in the `survey.views` module. Further we have given this
    URL the name `survey_home`, which we can use to refer to this URL from other code.
    Always using named URLs is good practice, as it allows for changing the actual
    URLs by simply changing the `urls.py` file and no other code.
  prefs: []
  type: TYPE_NORMAL
- en: Besides the home page, there are also the pages linked from the home page to
    consider. First there are the pages linked from the list of active surveys, which
    allow users to participate in a survey. Second are the pages linked from the list
    of recently completed surveys, which allow users to see the results. You might
    ask, should these be covered by one or two URLs?
  prefs: []
  type: TYPE_NORMAL
- en: 'While it sounds like these may need different URLs, since the pages will show
    very different content, in a sense that they are both showing the same thing—the
    details for a particular survey. It is just that the current state of the survey
    will influence what its details page displays. Thus, we can choose to put the
    logic for deciding what exactly to display, based on survey state, into the view
    that handles displaying details for a survey. Then we can cover both of these
    types of pages with a single URL pattern. Taking this approach, the `survey/urls.py`
    file becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Here we have taken the approach of placing the primary key of the survey in
    the URL. Any URL which consists of a single path component containing one or more
    digits (the primary key) will be mapped to the `survey_detail` function in the
    `survey.views` module. This function will receive the primary key path component
    as an argument, `pk`, in addition to the standard request argument. Finally, this
    URL has been given the name `survey_detail`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Those two URL patterns are enough to define the survey application pages we
    have considered so far. However, we still need to hook them into our project''s
    overall URL configuration. To do this, edit the project''s root `urls.py` file
    and add a line for the survey URLs. The `urlpatterns` variable in `urls.py` will
    then be defined like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The last line we have added here specifies an empty URL pattern, `r''`. All
    matching URLs will be tested against the patterns found in the `urls.py` file
    contained in the `survey` module. The pattern `r''` will match every URL, and
    no part of the URL will be removed as already matched when it is tested against
    the URL patterns in `survey/urls.py`, so this essentially mounts the survey `urls.py`
    file at the root of the project's URL tree.
  prefs: []
  type: TYPE_NORMAL
- en: Developing views to serve pages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have defined our URLs and specified the view functions that should
    be called to serve them, it is time to start writing these functions. Or, perhaps
    we should start with the templates for these pages? Both need to be done and they
    are dependent on each other. The data returned by views is dependent on what the
    templates need, while the specifics of how the templates are written are dependent
    on the naming and structure of the data provided by the views. Thus, it can be
    hard to know which to start with, and it is sometimes necessary to alternate between
    them.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, we have to start somewhere, and we will start with the views. In fact,
    whenever you add a reference to a view in a `urls.py` file, it is a good idea
    to immediately write at least a minimal implementation of that view. For example,
    for the two views we just added to `survey/urls.py`, we might immediately place
    the following in `survey/views.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: These views both simply return an `HttpResponse` describing what the page is
    supposed to display. Creating placeholder views like this ensures that the overall
    URL pattern configuration for the project remains valid. Keeping this configuration
    valid is important because any attempt to perform a reverse URL mapping (from
    the name back to the actual URL) will result in an exception if there is any error
    (such as reference to a non-existent function) in any part of the URL pattern
    configuration. Thus, an invalid URL configuration can easily seem to break other
    perfectly innocent code.
  prefs: []
  type: TYPE_NORMAL
- en: The admin application, for example, needs to use reverse URL mapping to generate
    links on its pages. Thus an invalid URL pattern configuration can result in an
    exception being raised when a user attempts to access an admin page, even though
    there is no error in the admin code itself. This kind of exception can be very
    hard to debug since at first glance it seems that the problem is caused by code
    that is entirely separate from where the actual error is. Thus, even if you prefer
    to work on writing templates before view functions, it is best to always immediately
    provide at least a bare minimum implementation for any view you add to your URL
    pattern configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can go a step beyond the bare minimum, though, at least for the home page
    view. As previously described, the home page will display three different lists
    of surveys: active, recently completed, and opening soon. It is unlikely that
    the template will need that data to be structured in any way more complicated
    than a simple list (or `QuerySet`), so the view for the home page is straightforward
    to write:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This view sets three variables to be `QuerySets` containing the appropriate
    subsets of the `Surveys` in the database. The recently completed set is limited
    to surveys that have closed in the last two weeks, and the opening soon set is
    limited to those that will open in the next week. The view then calls the `render_to_response`
    shortcut to render the `survey/home.html` template passing along a context dictionary
    containing the three `Survey` subsets in the `active_surveys`, `completed_surveys`,
    and `upcoming_surveys` context variables.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we can either proceed to replace the placeholder `survey_detail`
    view implementation with some real code, or we could get started on some templates.
    Writing the second view does not get us any closer to testing out the first one
    we've written, though, so moving on to the templates is better. The placeholder
    content for the second view will do fine for now.
  prefs: []
  type: TYPE_NORMAL
- en: Creating templates for pages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To get started with writing templates for the survey application, first create
    a `templates` directory under `survey`, and then a `survey` directory under `templates`.
    Placing the templates under a `templates` directory in the application directory
    allows them to be automatically found by the `app_directories` template loader,
    which is enabled by default. Further, placing the templates in a `survey` directory
    under `templates` minimizes the chance of name conflicts with templates used by
    other applications.
  prefs: []
  type: TYPE_NORMAL
- en: Now, what templates do we need to create? The one named in the home view is
    `survey/home.html`. We could create just that one file and make it a full standalone
    HTTP document. But that would be unrealistic. Django provides a convenient template
    inheritance mechanism to allow for re-use of common page elements and selective
    override of defined blocks. At a minimum, we probably want to use a common base
    template that defines the overall document structure and block components, and
    then implements the individual page templates as child templates that extend the
    base template.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a minimal `base.html` template we can use to start with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This document provides the overall HTML structure tags and defines just two
    blocks: `title` and `content`. The `title` block has default content of `Survey
    Central` that may be overridden by child templates, or left as is. The `content`
    block is initially empty, so child templates are expected to always provide something
    to fill in the body of the page.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Given that base template, we can write our `home.html` template as a child
    template that extends `base.html` and provides the content for the block `content`.
    We know that the `home` view is supplying three context variables (`active_surveys`,
    `completed_surveys`, and `upcoming_surveys`) containing the data that should be
    displayed. An initial implementation of the `home.html` template might look like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: That may look a little intimidating, but it is straightforward. The template
    starts by specifying that it extends the `survey/base.html` template. It then
    proceeds to define what should be placed in the block `content` defined in `base.html`.
    The first element is a first-level heading `Welcome to Survey Central`. Then,
    if the `active_surveys` context variable is not empty, the heading is followed
    by a paragraph inviting people to take a survey, followed by a list of the active
    surveys. Each item in the list is specified as a link where the link target value
    is obtained by calling the Survey's `get_absolute_url` method (which we have not
    implemented yet). The visible text for each link is set to the `title` value of
    `Survey`.
  prefs: []
  type: TYPE_NORMAL
- en: A nearly identical paragraph and list is displayed for the `completed_surveys`,
    if there are any. Finally, the `upcoming_surveys` are handled similarly, except
    in their case no links are generated. Rather, the survey titles are listed along
    with the date when each survey will open.
  prefs: []
  type: TYPE_NORMAL
- en: Now, what is the `get_absolute_url` method used to generate the links to the
    active and completed surveys? This is a standard model method we can implement
    to provide the URL for a model instance on our site. In addition to using it in
    our own code, the admin application uses it, if it is implemented by a model,
    to provide a **View on site** link on the change page for model instances.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall that in our `urls.py` file we named the URL for survey details `survey_detail`
    and that this view takes one argument, `pk`, which is the primary key of the `Survey`
    instance to display details about. Knowing that, we can implement this `get_absolute_url`
    method in the `Survey` model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This method uses the `reverse` function provided by `django.core.urlresolvers`
    to construct the actual URL that will map to the URL named `survey_detail` with
    an argument value of the model instance's primary key value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, we could use the convenient `models.permalink` decorator and
    avoid having to remember where the `reverse` function needs to be imported from:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This is equivalent to the first way of implementing `get_absolute_url`. This
    way simply hides the details of calling the reverse function, as that is done
    by the `models.permalink` code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have created the home page view and the templates it uses, and
    implemented all of the model methods called from those templates, we can actually
    test the view. Ensure that the development server is running (or start it again
    with `manage.py runserver`), and then from a browser on the same machine, go to
    `http://localhost:8000/`. This should (assuming it has been less than a week since
    the `Winning Answers Test` from the last chapter was created) bring up a page
    that lists that survey as one that can be taken:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating templates for pages](img/7566_04_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: If it has been longer than a week since that survey was created, it should show
    up under a paragraph that invites you to **See how your opinions compared to those
    of others!** instead. If it has been more than three weeks, the survey should
    not show up at all, in which case you may want to go back to the admin application
    and change its `closes` date so that it appears on the home page.
  prefs: []
  type: TYPE_NORMAL
- en: 'That **Winning Answers Test** text is a link, which can be followed to verify
    that the `get_absolute_url` method for `Survey` is working, and further that the
    URL configuration we have set up is valid. Since we still have only the placeholder
    view implementation of the survey detail view, clicking the **Winning Answers
    Test** link will bring up a page that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating templates for pages](img/7566_04_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Not overly impressive, perhaps, but it does verify that the various pieces we
    have in place so far are working.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, since we've only got one Survey in the database, we've only verified
    one part of the view and template. For a full test, we should also verify that
    the surveys in all three categories appear properly. In addition, we should verify
    that surveys in the database that should not appear either because they are too
    old or too far in the future do not in fact appear on the home page.
  prefs: []
  type: TYPE_NORMAL
- en: We might do all that now by manually adding surveys in the admin application
    and manually checking the contents of the home page as we make changes. However,
    what we really want to learn is how to write a test to verify that what we have
    now is correct and, more importantly, to allow us to verify that it remains correct
    as we continue to develop the application. Therefore, writing such a test is what
    we will focus on next.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the survey home page
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we think about how to write the test itself, let's consider the data
    the test will need and the best way to get that data into the database for the
    test. This test is going to be much like the `SurveyManagerTest` from the previous
    chapter, since determining correct behavior will depend on the relationship of
    the current date to dates contained in the test data. Therefore, using a fixture
    file for this data is not a good idea; it will be better to dynamically add the
    data in the test's `setUp` method.
  prefs: []
  type: TYPE_NORMAL
- en: We will begin, then, by writing a `setUp` method to create an appropriate set
    of data for testing the home page. Since we have moved on to testing the application's
    views, let's put it in a new file, `survey/tests/view_tests.py`. When we create
    that file, we need to also remember to add an `import` line for the new file (`from
    view_tests import *`) to the `__init__.py` file in `survey/tests`, so that the
    tests in it will be found by the test runner.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a `setUp` method for our home page test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This method starts by stashing today''s date in a local variable `today`. It
    then deletes all existing `Surveys` in the database, just in case there are any
    loaded by initial data fixtures that could interfere with the proper execution
    of the test methods in this test case. It then creates eight `Surveys`: three
    completed, two active, and three upcoming.'
  prefs: []
  type: TYPE_NORMAL
- en: The closing dates for the completed surveys are specifically set so as to test
    the boundaries of the window for what should appear on the home page. The oldest
    closing date is set just one day too far in the past (15 days) to be listed on
    the home page. The other two are set to the extreme edges of the window for what
    should appear as completed on the home page. The opens date for upcoming surveys
    is set similarly to test the limits of that window. One upcoming survey opens
    just one day too far in the future to appear on the home page while the other
    two open at the limits of the window for what should be shown as upcoming on the
    home page. Finally, there are two active surveys, one that opened yesterday and
    one that opened today, each with a default closing date seven days later, so both
    still open.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a `setUp` routine to create test data, how do we write a test
    to check the contents of the home page? Django provides a class, `django.test.Client`,
    to help out here. An instance of this `Client` class acts like a web browser and
    can be used to request pages and examine the responses returned. Each `django.test.TestCase`
    class is automatically assigned a `Client` class instance that can be accessed
    using `self.client`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see how to use the test `Client`, let''s examine the beginnings of a test
    for the survey application home page:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Here we have defined a `testHome` method within the `SurveyHomeTest`. This method
    uses the `get` method of the test's `client` class instance to retrieve the survey
    home page (again using `reverse` to determine the correct URL so as to ensure
    all URL configuration information is isolated in `urls.py`). The return value
    of `get` is the `django.http.HttpResponse` object returned by the view called
    to serve the requested page, annotated with some additional information to facilitate
    testing. The last line of the test verifies that the request was served successfully
    by ensuring that the `status_code` attribute of the returned response is `200`
    (HTTP OK).
  prefs: []
  type: TYPE_NORMAL
- en: Note that the `get` method supplied by the test `Client` supports more than
    the single URL parameter we are passing here. In addition, it supports two keyword
    arguments, `data` and `follow`, which default to an empty dictionary and `False`
    respectively. Finally, any number of `extra` keyword arguments may also be supplied.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `data` dictionary, if non-empty, is used to construct a query string for
    the request. For example, consider a `get` method such as this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The URL created for processing this request would be `/survey/?pk=4&type=results`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note you can also include a query string in the URL path passed to `get`. So
    an equivalent call would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: If both a `data` dictionary and a query string in the URL path are provided,
    the `data` dictionary is used for processing the request and the query string
    in the URL path is ignored.
  prefs: []
  type: TYPE_NORMAL
- en: The `follow` argument to `get` can be set to `True` in order to instruct the
    test client to follow redirects in the response. If it does so, a `redirect_chain`
    attribute will be set on the returned response. This attribute will be a list
    describing the intermediate URLs visited before the end of the redirect chain.
    Each element in the list will be a tuple containing the intermediate URL path
    and the status code that prompted it to be retrieved.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, any `extra` keyword arguments can be used to set arbitrary HTTP header
    values in the request. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This call will set the `HTTP_USER_AGENT` header in the request to `Tester`.
  prefs: []
  type: TYPE_NORMAL
- en: Returning to our own test, which supplies only the URL path argument, we can
    run it now with `manage.py test survey.SurveyHomeTest` and verify that so far
    everything looks good. We can retrieve the home page and the response comes back
    with a successful status code. But what about testing the contents of the page?
    We'd like to make sure that the various surveys that should appear are appearing,
    and further that the two surveys in the database that should not appear on the
    page are not listed.
  prefs: []
  type: TYPE_NORMAL
- en: The actual page content returned is stored in the `content` attribute of the
    response. We can examine this directly, but the Django `TestCase` class also provides
    two methods to check whether or not certain text appears in the response. These
    methods are named `assertContains` and `assertNotContains`.
  prefs: []
  type: TYPE_NORMAL
- en: To use the `assertContains` method we pass in the `response` and the text we
    are looking for. We can also optionally specify a `count` of the number of times
    that text should appear. If we specify `count`, the text must appear exactly that
    many times in the response. If we do not specify `count`, `assertContains` simply
    checks that the text appears at least once. Finally, we may specify the `status_code`
    that the response should have. If we do not specify this, then `assertContains`
    verifies that the status code is 200.
  prefs: []
  type: TYPE_NORMAL
- en: The `assertNotContains` method takes the same arguments as `assertContains`
    with the exception of `count`. It verifies that the passed text does not appear
    in the response content.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use these two methods to verify that the home page contains two instances
    each of `Completed`, `Active`, and `Upcoming`, and that it does not contain either
    `Too Old` or `Too Far Out`. Furthermore, since these methods check the status
    code, we can remove that check from our own test code. Thus the test method becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: If we try running this version, we will see that it works. However, it is not
    as specific as we might like it to be. Namely, it does not verify that the listed
    surveys are appearing in the right places on the page. This test as it is right
    now would pass with all of the listed surveys appearing under the paragraph **Take
    a survey now!**, for example. How can we verify that each is appearing in the
    appropriate list?
  prefs: []
  type: TYPE_NORMAL
- en: One approach would be to manually examine `response.content`, find where each
    of the expected strings is located, and ensure that they all appear in the expected
    order. However, that would make the test very dependent on the exact layout of
    the page. We might in the future decide to reorder the presentation of the lists
    and this test could then break, even though each survey was still being listed
    in the correct category.
  prefs: []
  type: TYPE_NORMAL
- en: 'What we really want to do is verify that the surveys are contained in the appropriate
    context variables passed to the template. We can in fact test this, since the
    response returned by `client.get` is annotated with the context used to render
    the template. Thus, we can check the completed survey list, for example, like
    so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This code retrieves the `completed_surveys` context variable from the response
    context, verifies it has `2` items in it, and further verifies that each of the
    items has a `title` that starts with the string `Completed`. If we run that code,
    we''ll see it works for checking the completed surveys. We can then either duplicate
    that block two more times and tweak it appropriately to check the active and upcoming
    surveys, or we can get a little fancier and write something more like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Here we have avoided duplicating, essentially, the same block of code three
    times with just minor differences by constructing a list of things to check and
    then iterating through that list. Thus, we only have the code block appearing
    once, but it is looped through three times, once for each of the context variables
    we want to check. This is a common technique used to avoid duplicating code that
    is almost identical multiple times.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that when this sort of technique is used in tests, though, it is a good
    idea to take the effort to include specific messages in the assertion checks.
    In the original version of the code, which tested the completed list directly,
    if there was an error such as too many surveys in that list, a test failure would
    produce a reasonably descriptive error report:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'There the code that is failing includes the string **completed** so it is clear
    which list is having a problem. With a more generalized version of the code, this
    report becomes much less helpful:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The poor programmer encountering that failure report would have no way of knowing
    which of the three lists had too many items. By providing a specific error message
    with the assertion, however, this can be made clear. So a better version of the
    full test method with descriptive errors would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Now if there is a failure during the checks in the generalized code, the error
    message is specific enough to indicate where the problem is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: We now have a reasonably complete test for our survey home page, or at least
    as much of it as we have implemented so far. It is time to turn our attention
    to the survey detail pages, which we will cover next.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the survey detail pages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The second URL mapping we added to our project's URL configuration was for the
    survey detail pages. Implementing this view is a little more complicated than
    the home page view since quite different data will need to be presented depending
    on the state of the requested survey. If the survey is completed, we need to display
    the results. If the survey is active, we need to display a form allowing the user
    to participate in the survey. If the survey is upcoming, we don't want the survey
    to be visible at all.
  prefs: []
  type: TYPE_NORMAL
- en: To do all of that at once, without testing along the way to verify we are headed
    in the right direction, would be asking for trouble. It's best to break the task
    down into smaller pieces and test as we go. We'll take the first step in that
    direction in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Refining the survey detail view
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first thing to do is to replace the simple placeholder view for the survey
    detail page with a view that determines the requested survey''s state and routes
    the request appropriately. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: This `survey_detail` view uses the `get_object_or_404` shortcut to retrieve
    the requested `Survey` from the database. The shortcut will automatically raise
    an `Http404` exception if the requested survey does not exist, so the following
    code does not have to account for that case. The view then checks the `closes`
    date on the returned `Survey` instance. If it closed before today, the request
    is sent on to a function named `display_completed_survey`. Otherwise, if the survey
    has not yet opened, an `Http404` exception is raised. Finally, if neither of those
    conditions hold, the survey must be active so the request is routed to a function
    named `display_active_survey`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start out with, we will implement the two new functions very simply. They
    will not do any of the real work required for their case, but they will each use
    a different template when rendering their response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: With just that much code, we can proceed to test whether surveys in different
    states are being routed correctly. First though, we need to create the two new
    templates that the view code has introduced.
  prefs: []
  type: TYPE_NORMAL
- en: Templates for the survey detail pages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The two new templates are named `survey/completed_survey.html` and `survey/active_survey.html`.
    Create them under the `survey/templates` directory. To start out with, they can
    be very simple. For example, `completed_survey.html` may be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, `active_survey.html` could be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Each of these extends the `survey/base.html` template and provides minimal but
    descriptive content for the `content` block. In each case, all that will be displayed
    is a first-level header identifying the survey by title and whether the page is
    showing results or questions.
  prefs: []
  type: TYPE_NORMAL
- en: Basic testing of the survey detail pages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now consider how we can test whether the routing code in `survey_detail` is
    working correctly. Again, we are going to need test data containing at least one
    survey in each of the three states. We have that with the test data we created
    in the `setUp` method of `SurveyHomeTest`. However, adding methods to the home
    page test case that actually tests survey detail page views would be confusing.
    Duplicating very similar `setUp` code is also not very attractive.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, we do not need to do either. What we can do is move the existing
    `setUp` code into a more general test case, say `SurveyTest`, and then base both
    `SurveyHomeTest` and our new `SurveyDetailTest` on this new `SurveyTest`. In this
    way, both the home page test and the detail page test will have the same data
    created in the database by the base `SurveyTest setUp` method. Furthermore, any
    additional tests that need similar data could also inherit from `SurveyTest`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given we have the test data in place, what can we do to test what we have implemented
    so far of the detail view? The case of an upcoming survey is easy enough, since
    it should simply return an HTTP 404 (NOT FOUND) page. Thus, we can start by creating
    a method for that case in our `SurveyDetailTest`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The `testUpcoming` method retrieves one of the upcoming surveys from the database,
    and uses the test `client` to request the page containing details on that survey.
    Again we use `reverse` to construct the appropriate URL for the details page,
    passing in the primary key of the survey we are requesting as the single argument
    in the `args` tuple. Correct handling of this request is tested by ensuring that
    the `status_code` of the response is 404\. If we run this test now, we will see:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Oops. In order for the `survey_detail` view to successfully raise an `Http404`
    and have that result in a "page not found" response, a `404.html` template must
    exist in the project. We have not yet created one, so this test generates an error.
    To fix this, we can create a simple `survey/templates/404.html` file containing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: At the same time, we should also create a `survey/templates/500.html` file in
    order to avoid any similar unhelpful errors in cases where a server error is encountered.
    A simple `500.html` file to use for now would be much like this `404.html` file,
    with the text changed to indicate the problem is a server error, and not a page
    not found situation.
  prefs: []
  type: TYPE_NORMAL
- en: With the `404.html` template in place, we can attempt to run this test again
    and this time, it will pass.
  prefs: []
  type: TYPE_NORMAL
- en: 'What about testing the pages for completed and active surveys? We could write
    tests that check `response.content` for the header text we have placed in each
    of their respective templates. However, that text may not remain the same as we
    continue development—at this point that is just placeholder text. It would be
    better to verify that the correct templates were used to render each of these
    responses. The `TestCase` class has a method for that: `assertTemplateUsed`. Thus,
    we can write tests for these cases that are likely to continue to work properly
    in the long-run, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Each of these test methods retrieves a survey from the appropriate category
    and requests the detail page for that survey. So far, the only test done on the
    responses is to check that the expected template was used to render the response.
    Again, we can run these tests now and verify that they pass.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to `assertTemplateUsed`, there is an `assertTemplateNotUsed` method
    provided by `TestCase`. It takes the same arguments as `assertTempalteUsed`. As
    you might expect, it verifies that the specified template was not used to render
    the response.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we are going to take a break from implementing `survey` application
    pages. The next unit test topic to cover is how to test pages that accept user
    input. We don't have any of those in the survey application yet, but the Django
    admin application does. Thus, the task of testing an admin customization provides
    a quicker route to learning how to test such pages, since we'll need to write
    less custom code before developing the test. In addition to this, learning how
    to test admin customizations is useful in its own right.
  prefs: []
  type: TYPE_NORMAL
- en: Customizing the admin add and change survey pages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've already seen how the Django admin application provides a convenient way
    to examine and manipulate data in our database. In the previous chapter, we set
    up the admin with some simple customizations to allow editing `Questions` inline
    with `Surveys` and `Answers` inline with `Questions`. Besides those inline customizations,
    however, we made no changes to the admin defaults.
  prefs: []
  type: TYPE_NORMAL
- en: One additional change that would be good to make to the admin is to ensure that
    `Survey opens` and `closes` dates are valid. Clearly for this application, it
    makes no sense to have an `opens` date that is later than `closes`, but there
    is no way for the admin to know that. In this section, we will customize the admin
    to enforce our application requirement on the relationship between `opens` and
    `closes`. We will also develop a test for this customization.
  prefs: []
  type: TYPE_NORMAL
- en: Developing a custom survey form
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first step in implementing this admin customization is to implement a form
    for `Survey` that includes custom validation. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: This is a standard `ModelForm` for the `Survey` model. Since the validation
    we want to perform involves multiple fields on the form, the best place to put
    it is in the overall form `clean` method. The method here retrieves the `opens`
    and `closes` values from the form's `cleaned_data` dictionary. Then, if they have
    both been provided, it checks to see if `opens` is later than `closes`. If so,
    a `ValidationError` is raised, otherwise everything is OK, so the existing `cleaned_data`
    dictionary is returned unmodified from `clean`.
  prefs: []
  type: TYPE_NORMAL
- en: As we are going to be using this form for the admin and do not presently anticipate
    the need to use it anywhere else, we can put this form definition in the existing
    `survey/admin.py` file.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring admin to use the custom form
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The next step is to tell the admin to use this form instead of a default `ModelForm`
    for the `Survey` model. To do this, change the `SurveyAdmin` definition in `survey/admin.py`
    to be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'By specifying the `form` attribute, we tell the admin to use our custom form
    for both adding and editing `Survey` instances. We can quickly verify that this
    works by using the admin to edit our existing `Winning Answers Test` survey and
    attempting to change its `closes` date to something earlier than `opens`. If we
    do so, we will see the error reported like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Configuring admin to use the custom form](img/7566_04_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: It's good that we have been able to manually validate that our customization
    is working, but what we really want is an automated test. That will be covered
    next.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the admin customization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: How do we write a test for this admin customization? There are at least a couple
    of things different about testing the behavior of pressing one of the **Save**
    buttons on an admin page than what we've tested so far. First, we need to issue
    an HTTP POST method, not a GET, to make the request. The test `Client` provides
    a `post` method for this, similar to `get`. For `post`, though, we will need to
    specify the form data values to be included with the request. We provide these
    as a dictionary of key / value pairs where the keys are the names of the form
    fields. Since we know the `ModelForm` the admin is using, we know that the key
    values here are the names of the model's fields.
  prefs: []
  type: TYPE_NORMAL
- en: We'll start with writing a test for the admin add survey page, since for that
    case we do not need to have any pre-existing data in the database. Let's create
    a new file for testing admin views, named `admin_tests.py`, in the tests directory.
    Also, remember to add `from admin_tests import *` to the `tests/__init__.py` file
    so that these tests are found when we run `tests`.
  prefs: []
  type: TYPE_NORMAL
- en: 'An initial attempt to implement a test of the admin application''s use of our
    customized `Survey` form might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Here we have a test method, `testAddSurveyError`, which creates a `post_data`
    dictionary with `title`, `opens`, and `closes` values for the `Survey ModelForm`.
    We use the test `client` to `post` that dictionary to the admin `Survey` add page
    for the `survey` application (using `reverse` on the documented name for that
    admin view). We expect that the returned `response` should contain the error message
    from our custom `ModelForm`, since we have specified an `opens` date that is later
    than the `closes` date. We use `assertContains` to check that the expected error
    message is found in the response.
  prefs: []
  type: TYPE_NORMAL
- en: Note that as was the case with `get`, our first test that is using `post` is
    only using a subset of the arguments that could be supplied to that method. In
    addition to the URL `path` and the `data` dictionary, `post` accepts a `content_type`
    keyword argument. This argument defaults to a value that results in the client
    sending `mutlipart/form-data`. In addition to `content_type`, `post` also supports
    the same `follow` and `extra` keyword arguments, with the same defaults and processing
    behavior, as `get`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Does our first attempt at an admin customization test work? Unfortunately,
    no. If we run it with `manage.py test survey.AdminSurveyTest`, we will see this
    failure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: What might be wrong? It's hard to say without seeing what is actually contained
    in the returned response. Realizing that, we may be tempted to include the text
    of the response in the error message. However, responses tend to be quite long
    (as they are generally complete web pages) and including them in test failure
    output usually adds more noise than anything else. Thus it is usually better to
    make a temporary change to the test case to print the response, for example, in
    order to figure out what might be going on.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we do that in this case, we will see that the returned response begins (after
    some standard HTML boilerplate):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Oh, right, we forgot that the admin requires a logged-in user for access. We
    did not do anything in our test case to set up and log in a user, so when the
    test attempts to access an admin page, the admin code simply returns a login page.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our test, then, will first need to create a user, as the test database is initially
    empty. That user will need appropriate permissions to access the admin, and must
    be logged in before attempting to do anything with the admin application. This
    sort of thing is appropriate for a test `setUp` routine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Here the `setUp` routine uses the `create_user` method provided by the standard
    `django.contrib.auth User` model to create a user named `survey_admin`. After
    creating the user, `setUp` sets its `is_staff` and `is_superuser` attributes to
    `True` and saves the user again to the database. This will allow the newly created
    user to access all pages in the admin application.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, `setUp` attempts to log the new user in using the test `Client login`
    method. This method will return `True` if it is successful. Here, `setUp` asserts
    that `login` does return `True`. If it does not, the assertion will provide a
    specific indication of where things went wrong. This should be more helpful than
    simply continuing the test if the `login` call fails.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Client login` method has a companion method, `logout`. We should use it
    in a `tearDown` method after we have used `login` in `setUp`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Now does our test work? No, but it does get farther. This time the error report
    is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'That may be a little confusing at first, but searching the Django documentation
    for **ManagementForm** quickly shows that it is something required when formsets
    are being used. Since, as part of our admin customization, we specified that `Questions`
    appear inline on a `Survey` page, the admin page for `Survey` contains a formset
    for `Questions`. However, we did not provide the required `ManagementForm` values
    in our `post_data` dictionary. The two values required are `TOTAL_FORMS` and `INITIAL_FORMS`
    for the `question_set`. Since we do not want to test any of the admin handling
    of the inlines here, we can just set these values to `0` in our data dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Now does this test work? Yes, if we run `manage.py test survey.AdminSurveyTest.testAddSurveyError`
    we will see that the test runs successfully.
  prefs: []
  type: TYPE_NORMAL
- en: Note that `TestCase` provides a more specific assertion than `assertContains`
    to check for form errors, named `assertFormError`. The parameters to `assertFormError`
    are the response, the name of the form in the template context, the name of the
    field to check for errors (or `None` if the error is a non-field error), and the
    error string (or a list of error strings) to check for. However, it is not possible
    to use `assertFormError` when testing admin pages because the admin does not provide
    the form directly in the context. Instead, the context contains a wrapper object
    that contains the actual form. Thus, we cannot change this particular test to
    use the more specific `assertFormError` method.
  prefs: []
  type: TYPE_NORMAL
- en: Are we done testing our admin customization? Almost. Since the same form is
    used for both add and change actions in admin, it is not necessary to test the
    change page as well. However, it would be good to add a test that includes valid
    data and ensure that nothing has been broken for that case.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is easy enough to add a test method that builds a data dictionary containing
    valid data and posts that to the admin add view. But what should it test for in
    response? The admin code does not return a simple `200 OK` response after successfully
    completing some action requested by the POST. Rather, it redirects to a different
    page, so that an attempt to reload the page resulting from the POST request does
    not result in another attempt to POST the same data. In the case of adding an
    object, the admin will redirect to the change list page for the added model. `TestCase`
    provides an `assertRedirects` method to test this sort of behavior. We can use
    this method like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: This `testAddSurveyOK` method sets up a valid data dictionary for a `Survey`,
    specifying `opens` and `closes` dates that are the same. It then posts that data
    to the admin add survey page, and saves the response. Finally, it asserts that
    the response should redirect to the admin survey application change list page
    for the `Survey` model. Two additional, optional parameters to `assertRedirects`
    are `status_code` and `target_status_code`. These default to `302` and `200` respectively,
    so we did not need to specify them here since those are the codes we expect in
    this case.
  prefs: []
  type: TYPE_NORMAL
- en: Additional test support
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The tests that we have developed in this chapter provide a reasonably broad
    overview of how to use the test support provided by Django's `TestCase` and test
    `Client` class. However, the examples neither cover every detail of what these
    classes provide, nor every detail of the additional data available in the annotated
    `response` objects returned by the `Client`. In this section, we briefly mention
    some additional features of `TestCase`, `Client`, and the additional data available
    with `response` objects. We will not develop examples that use all of these features;
    they are mentioned here so that if you encounter a need for this type of support,
    you will know that it exists. The Django documentation provides full details on
    all of these topics.
  prefs: []
  type: TYPE_NORMAL
- en: Supporting additional HTTP methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our example tests only needed to use the HTTP GET and POST methods. The test
    `Client` class also provides methods to issue HTTP HEAD, OPTIONS, PUT, and DELETE
    requests. These methods are named `head`, `options`, `put`, and `delete` respectively.
    Each supports the same `follow` and `extra` arguments as `get` and `post`. In
    addition, `put` supports the same `content_type` argument as `post`.
  prefs: []
  type: TYPE_NORMAL
- en: Maintaining persistent state
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The test `Client` maintains two attributes that maintain persistent state across
    request / response cycles: `cookies` and `session`. The `cookies` attribute is
    a Python `SimpleCookie` object containing any cookies that have been received
    with responses. The `session` attribute is a dictionary-like object containing
    session data.'
  prefs: []
  type: TYPE_NORMAL
- en: E-mail services
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some views in a web application may create and send mail. When testing, we do
    not want such mail to actually be sent, but it is good to be able to verify that
    the code being tested generated and attempted to send the mail. The `TestCase`
    class supports this by replacing the standard Python `SMTPConnection` class (in
    the context of the running tests only) with a custom class that does not send
    the mail, but rather stores it in `django.core.mail.outbox`. Thus, test code can
    check the contents of this `outbox` in order to verify whether the code being
    tested attempted to send the expected mail.
  prefs: []
  type: TYPE_NORMAL
- en: Providing test-specific URL configuration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the examples developed in this chapter, we were careful to make the tests
    independent of the specifics of the URL configuration in use by always using named
    URLs and using `reverse` to map these symbolic names back to URL path values.
    This is a good technique, but it may not be sufficient in all circumstances.
  prefs: []
  type: TYPE_NORMAL
- en: Consider that you are developing a reusable application with optional views
    that a particular installation of the application may or may not choose to deploy.
    For testing such an application, you cannot rely on the optional views actually
    being contained in the project's URL configuration, but you would still like to
    be able to include tests for them. To support this, the `TestCase` class allows
    an instance to set a `urls` attribute. If this attribute is set, the `TestCase`
    will use the URL configuration contained in the specified module instead of the
    project's URL configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Response context and template information
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In testing the survey home page, we examined values in the response `context`
    attribute using simple dictionary-style access. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: While this works, it glosses over some complexity involved in considering the
    context used to render a response. Recall that we set up our project to have a
    two-level hierarchy of templates. The `base.html` template is extended by each
    of the individual page templates. Each template used to render a response has
    its own associated context, so the `context` attribute of a response is not a
    simple dictionary, but rather a list of the contexts used for rendering each of
    the templates. In fact, it is something called `django.test.utils.ContextList`,
    which contains a number of `django.template.context.Context` objects.
  prefs: []
  type: TYPE_NORMAL
- en: This `ContextList` object supports dictionary-style access for simplicity, and
    searches for the specified key in each of the contexts it contains. We made use
    of that simple style of access in the examples earlier in this chapter. However,
    if you ever have the need to get more specific about which template context you
    want to check something in, the response `context` attribute supports that as
    well, as you can also index by number into a `ContextList` and retrieve the full
    context associated with a particular template.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, the responses returned by the test `Client` have a `template` attribute
    that is a list of the templates used to render the response. We did not need to
    use this attribute directly because we used the `assertTemplateUsed` method provided
    by `TestCase`.
  prefs: []
  type: TYPE_NORMAL
- en: Testing transactional behavior
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The final topic to discuss in this chapter involves testing transactional behavior.
    If it is ever necessary to do this, there is an alternative test case class, `TransactionTestCase`,
    that should be used instead of `TestCase`.
  prefs: []
  type: TYPE_NORMAL
- en: What does **testing transactional behavior** mean? Suppose you have a view that
    makes a series of database updates, all within a single database transaction.
    Further, suppose you need to test a case where at least one of the updates works,
    but is followed by a failure that should result in the entire set of updates being
    rolled back instead of committed. To test this sort of behavior, you might try
    to verify in the test code that one of the updates that initially worked is not
    visible in the database when the response is received. To successfully run this
    sort of test code, you will need to use `TransactionTestCase` instead of `TestCase`.
  prefs: []
  type: TYPE_NORMAL
- en: The reason for this is that `TestCase` internally uses transaction rollback
    to reset the database to a clean state in between calling test methods. In order
    for this rollback approach of cleaning up between test methods to work, the code
    under test must not be allowed to issue any database commit or rollback operations
    itself. Thus, `TestCase` intercepts any such calls and simply returns without
    actually forwarding them on to the database. Your test code, then, will be unable
    to verify that updates which should have been rolled back were rolled back, since
    they will not have been when running under `TestCase`.
  prefs: []
  type: TYPE_NORMAL
- en: '`TransactionTestCase` does not use rollback between test methods to reset the
    database. Rather it truncates and re-creates all the tables. This is much slower
    than the rollback method, but it does allow test code to verify that any database
    transaction behavior expected from the code under test was performed successfully.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have now come to the end of discussing Django''s unit test extensions to
    support testing web applications. In this chapter, we:'
  prefs: []
  type: TYPE_NORMAL
- en: Learned how to organize unit tests into separate files instead of placing everything
    into a single tests.py file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Began to develop views for the survey application, and learned how to use Django's
    unit test extensions to test these views
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saw how to customize the admin interface by providing custom validation for
    one of our models, and learned how to test that admin customization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Briefly discussed some unit test extensions provided by Django that we did not
    encounter in any of our example tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learned when it might be necessary to use `TransactionTestCase` instead of `TestCase`
    for a test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While we have covered a lot of ground in learning how to test a Django application,
    there are many aspects to testing a web application that we have not even touched
    on yet. Some of these are more appropriately tested using tools other than Django
    itself. The next chapter will explore some of these additional web application
    testing requirements and show how external tools can be integrated with Django's
    testing support in order to meet these requirements.
  prefs: []
  type: TYPE_NORMAL
