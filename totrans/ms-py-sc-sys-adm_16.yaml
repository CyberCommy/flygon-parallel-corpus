- en: Web Scraping - Extracting Useful Data from Websites
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will learn about web scraping. You will also learn about
    the `beautifulsoup` library in Python, which is used for extracting information
    from websites.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is web scraping?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data extraction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting information from Wikipedia
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is web scraping?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Web scraping is the technique used to extract information from websites. This
    technique is used to transform unstructured data into structured data.
  prefs: []
  type: TYPE_NORMAL
- en: The use of web scraping is to extract the data from the websites. The extracted
    information is saved as a local file on your system, and you can store it to database
    in a table format as well. The web scraping software accesses the **World Wide
    Web** (**WWW**) directly using HTTP or a web browser. This is an automated process
    implemented using a web crawler or a bot.
  prefs: []
  type: TYPE_NORMAL
- en: Scraping a web page involves fetching the page and then extracting the data.
    A web crawler fetches a web page. A web crawler is a mandatory component in web
    scraping. After fetching, extraction takes place. You can search, parse, save
    the data into tables, and reformat the page.
  prefs: []
  type: TYPE_NORMAL
- en: Data extraction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to see the actual data extraction process. Python
    has the `beautifulsoup` library to perform the data extraction task. We are also
    going to use the requests library of Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we must install these two libraries. Run the following commands to install
    the `requests` and `beautifulsoup` libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The requests library
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The use of the `requests` library is to use HTTP within our Python script in
    human-readable format. We can download the pages using the `requests` library
    in Python. The `requests` library has different types of requests. Here, we are
    going to learn about the `GET` request. The `GET` request is used to retrieve
    information from a web server. The `GET` request downloads the HTML content of
    a specified web page. Every request has a status code. The status codes return
    with every request we made to the server. These status codes give us the information
    about what happened with the request we made. The types of status code are listed
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '`200`: Indicates everything went OK and returns the result, if any'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`301`: Indicates that the server is redirecting to a different endpoint if
    it has switched the domain name or the endpoint name must be changed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`400`: Indicates that you made a bad request'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`401`: Indicates when we are not authenticated'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`403`: Indicated that you are trying to access forbidden resources'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`404`: Indicates that the resource you are trying to access is not available
    on the server'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The beautifulsoup library
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`beautifulsoup` is a library in Python, used for web scraping. It has simple
    methods for searching, navigating, and modifying. It is simply a toolkit used
    for extracting the data you needed from a web page.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, to use the `requests` and `beautifulsoup` functionality in your scripts
    you must import these two libraries using the `import` statement. Now, we are
    going to see an example of parsing a web page. Here, we are going to parse a web
    page, which is a top news page from the IMDb website. For that purpose, create
    a `parse_web_page.py` script and write the following content in it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the script and you will get the output as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we collected a page and parsed it using `beautifulsoup`.
    First, we imported the `requests` and `beautifulsoup` modules. Then, we collected
    the URL using the `GET` request and assigned that URL to the `page_result` variable.
    Next, we created a `beautifulsoup` object `parse_obj`. This object will take `page_result`.content
    as its argument from requests and then the page parsed using `html.parser`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we are going to extract the content from a class and a tag. To perform
    this operation, go to your web browser and right-click on the content, that you
    want to extract and scroll down so you can see the **Inspect** option. Click on
    that and you will get the class name. Mention it in your program and run your
    script. For that, create a `extract_from_class.py` script and write the following
    content in it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the script and you will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we first imported the requests and `beautifulsoup`
    modules. Then, we created a request object and assigned an URL to it. Next, we
    created a `beautifulsoup` object `parse_obj`. This object takes `page_result.content`
    as its argument from requests and then the page was parsed using `html.parser`.
    Next, we used beautifulsoup's `find()` method to get the content from the `'news-article__content'`
    class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we are going to see an example of extracting content from a particular
    tag. In this example, we are going to extract the content from the `<a>` tag.
    Create an `extract_from_tag.py` script and write the following content in it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the script and you will get the output as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we are extracting contents from the `<a>` tag. We
    used the `find_all()` method to extract all `<a>` tag contents from the `'news-article__content'`
    class.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting information from Wikipedia
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we are going to see an example of a list of dance forms from
    Wikipedia. We are going to list all classical Indian dances. For that, create
    a `extract_from_wikipedia.py` script and write the following content in it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the script and you will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about what web scraping is. We learned about two
    libraries that are used in extracting the data from a web page. We also extracted
    information from Wikipedia.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn about statistics gathering and reporting.
    You will learn about the NumPy module, data visualization, and displaying data
    using plots, graphs, and charts.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is web scrapping?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the web crawlers?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Can you scrape data behind a login page?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Can you crawl Twitter?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is it possible to scrap the Java script pages? If yes, how?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Urllib documentation: [https://docs.python.org/3/library/urllib.html](https://docs.python.org/3/library/urllib.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mechanize: [https://mechanize.readthedocs.io/en/latest/](https://mechanize.readthedocs.io/en/latest/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scrapemark: [https://pypi.org/project/scrape/](https://pypi.org/project/scrape/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scrapy: [https://doc.scrapy.org/en/latest/index.html](https://doc.scrapy.org/en/latest/index.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
