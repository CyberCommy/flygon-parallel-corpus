- en: 'Chapter 9. When You Don''t Even Know What to Log: Using Debuggers'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For many problems encountered during development, a debugger is the most efficient
    tool to use to help figure out what is going on. A debugger lets you see exactly
    what the code is doing, step by step if necessary. It lets you see, and change,
    the values of variables along the way. With a debugger, you can even test out
    potential code fixes before making changes to the source code.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter focuses on using debuggers to help debug during development of
    Django applications. Specifically, in this chapter we will:'
  prefs: []
  type: TYPE_NORMAL
- en: Continue development of the survey application, seeing how the Python debugger,
    pdb, can be used to help figure out any problems that arise
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn how to use the debugger to verify correct operation of code that is subject
    to multi-process race conditions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Briefly discuss the use of graphical debuggers for debugging Django applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the Survey results display
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The survey application has one major piece that still remains to be implemented:
    display of the results for a completed survey. What form should this display take?
    A text-only tally of votes received for each answer for each question in the survey
    would be easy enough to write, but not very good at communicating results. A graphical
    representation of the results, such as a pie chart, would be far more effecting
    in conveying the breakdown of votes.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will explore a couple of different approaches to implementing
    a survey results view that incorporates pie charts to display vote distributions.
    Along the way we'll encounter some difficulties, and see how the Python debugger
    can be used to help figure out what is going wrong.
  prefs: []
  type: TYPE_NORMAL
- en: Before starting on the implementation of code to display survey results, let's
    set up some test data to use in testing out the results as we go along. We can
    use the existing **Television Trends** survey and simply adjust its data to reflect
    what we want to test. First, we need to change its `closes` date to be in the
    last two weeks, so that it will display as a completed survey instead of an active
    one.
  prefs: []
  type: TYPE_NORMAL
- en: Second, we need to set the `votes` counts for the question answers to ensure
    we test any special cases we want to cover. This `Survey` has two questions, thus
    we can use it to test both the case where there is a single clear winner among
    the answers and the case where there is a tie.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the admin application to set up a tie for the winner on the first
    question:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Implementing the Survey results display](img/7566_09_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here we have set **Comedy** and **Drama** to be in a two-way tie for the winning
    answer. The total number of votes (5) has been kept low for simplicity. It will
    be easy to verify that the pie charts look correct when the wedges are supposed
    to contain amounts such as one and two fifths of the total.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the second question, we can set up the data so that there is a single clear
    winner:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Implementing the Survey results display](img/7566_09_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'For this question, our results display should list only **Hardly any: I already
    watch too much TV!** as the single winning answer.'
  prefs: []
  type: TYPE_NORMAL
- en: Results display using pygooglechart
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once we''ve decided we want to create pie charts, the next question is: how
    do we do that? Chart creation is not built into the Python language. There are,
    however, several add-on libraries that provide this function. We''ll start by
    experimenting with one of the simplest alternatives, `pygooglechart`, which is
    a Python wrapper around the Google chart API.'
  prefs: []
  type: TYPE_NORMAL
- en: The `pygooglechart` package is available on the Python Package Index site, [http://pypi.python.org/pypi/pygooglechart](http://pypi.python.org/pypi/pygooglechart).
    Information on the underlying Google chart API can be found at [http://code.google.com/apis/chart/](http://code.google.com/apis/chart/).
    The version of `pygooglechart` used in this chapter is 0.2.0.
  prefs: []
  type: TYPE_NORMAL
- en: One reason using `pygooglechart` is very simple, for a web application, is that
    the result of constructing a chart is simply a URL that can be used to fetch the
    chart image. There is no need to generate or serve an image file from our application.
    Rather, all of the work can be pushed off to the Google chart API, and our application
    simply includes HTML `img` tags that refer to images served by Google.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start, then, with the template for displaying results of a survey. The
    current implementation of this template, `survey/completed_survey.html`, does
    nothing more than print a header noting the title of the survey:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We want to change this now, and add template code that loops through the questions
    in the survey and prints out the results for each. Recall that the `Question`
    model has a method (implemented in [Chapter 3](ch03.html "Chapter 3. Testing 1,
    2, 3: Basic Unit Testing"), *Testing 1, 2, 3: Basic Unit Testing*) that returns
    the winning answers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In the template, then, we can use this method to access the winning answer
    (or answers, in the case of a tie). For each `Question` in the `Survey`, we will
    print out the question text, a list of the winning answers, and a pie chart showing
    a breakdown of the votes for each `Answer`. Template code that does this is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we have added a `{% for %}` block which loops through the questions in
    the passed survey. For each, the list of winning answers is retrieved using the
    `winning_answers` method and cached in the `winners` template variable. Then,
    if there is anything in `winners`, the following items are displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: The question text, as a level two heading.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A heading paragraph for the winners list that is properly pluralized depending
    on the length of `winners`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A text list of the winning answers formatted as an unordered list.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An embedded image that will be the pie chart breakdown of answer votes. The
    URL for this image is retrieved using a routine that needs to be implemented on
    the `Question` model: `get_piechart_url`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that the display of this entire list of items is protected by an `{% if
    winners %}` block to guard against the edge case of attempting to display results
    for a `Question` that received no answers. That may be unlikely but it's best
    to never display likely odd-looking output for edge cases to users, so at the
    template level here we simply avoid showing anything at all in this case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we need to implement the `get_piechart_url` method for the `Question`
    model. After some reading up on the `pygooglechart` API, an initial implementation
    might be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This code retrieves the set of answers associated with the `Question` and caches
    it in the local variable `answer_set`. (This is done because the set is iterated
    through multiple times in the following code and caching it in a local variable
    ensures the data is fetched from the database only once.) Then, the `pygooglechart`
    API is called to create a three-dimensional pie chart, `chart`, which will be
    500 pixels wide and 230 pixels high. Then, data values are set for the pie chart
    wedges: these data values are the `votes` count for each answer in the set. Next,
    labels are set for each of the wedges to be the `answer` values. Finally, the
    method returns the URL for the constructed chart, using the `get_url` method.'
  prefs: []
  type: TYPE_NORMAL
- en: 'How well does that work? When we navigate to the survey application home page,
    the **Television Trends** survey should now (since its `closes` date has been
    set to have already passed) be listed under the heading that indicates we can
    see its results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Results display using pygooglechart](img/7566_09_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Clicking on the **Television Trends** link now brings up a completed survey
    results page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Results display using pygooglechart](img/7566_09_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: That's not quite right. While the text displays of winning answer lists look
    fine, the pie charts are not appearing. Rather, the browser is displaying the
    alternate text defined for the image, **Pie Chart**, which means something went
    wrong in retrieving the specified image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking at the HTML source for the page, we see that both paragraphs containing
    the image tags look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Somehow, the `get_piechart_url` method returned an empty string instead of
    a value. We might first add some logging to `get_piechart_url` to try to figure
    out why:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ve added a log statement on entry noting the primary key of the `Question`
    instance, and a log statement prior to exit logging what the method is about to
    return. However, reloading the page with the logging included produces confusing
    output on the server console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We can see that `survey_detail` called `display_completed_survey` and `get_piechart_url`
    was called twice, but there are no messages showing what it was returning either
    time. What happened? There's no branching in the code between the two `logging.debug`
    calls, so how could one get executed and the other skipped?
  prefs: []
  type: TYPE_NORMAL
- en: We could try adding more logging calls, interspersed between each line of code.
    However, while that may reveal how far execution proceeds in the method before
    unexpectedly leaving, it won't provide any clue as to why execution stops proceeding
    to the next line. It is also a nuisance to add logging after every line of code,
    even for methods as small as this one. For problems like this, a debugger is a
    much more efficient way to figure out what is going on.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with the debugger
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A debugger is a powerful development tool that allows us to see what code is
    doing as it runs. When a program is run under the control of a debugger, the user
    is able to pause execution, examine and change the value of variables, flexibly
    continue execution to the next line or other explicitly set "breakpoints", and
    more. Python has a built-in debugger named pdb which provides a user interface
    that is essentially an augmented Python shell. In addition to normal shell commands,
    pdb supports various debugger-specific commands, many of which we will experiment
    with in this chapter as we debug the survey results display code.
  prefs: []
  type: TYPE_NORMAL
- en: 'How, then, do we use pdb to help figure out what is going on here? We''d like
    to enter the debugger and step through the code to see what is happening. The
    first task, breaking into the debugger, can be accomplished by adding `import
    pdb; pdb.set_trace()` wherever we''d like the debugger to get control. The `set_trace()`
    call sets an explicit breakpoint in our program where execution will pause under
    debugger control so we can investigate what the current state is and control how
    the code proceeds. Thus, we can change the `get_piechart_url` method like so to
    invoke the debugger on entry:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, when we reload the survey results page, the browser will appear to hang
    while it tries to load the page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting started with the debugger](img/7566_09_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'When we switch to the window containing the `runserver` console, we see:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Here we see that another call to the `survey_detail` view has been made, which
    forwarded the request to the `display_completed_survey` function. Then, the debugger
    was entered, due to the `pdb.set_trace()` call placed in `get_piechart_url`. On
    entry, the debugger prints out two lines identifying the location of the next
    line of code that is to be executed, and the contents of that line. So we can
    see that we are on line 71 of the `survey/models.py` file, in the `get_piechart_url`
    method, about to issue the call to log entry to the method. After the two lines
    noting where execution stopped, the debugger prints its prompt, `(Pdb)`, and waits
    for user input.
  prefs: []
  type: TYPE_NORMAL
- en: Before proceeding to step through the code and see what's happening as the code
    runs, let's see what we can learn about where we are and the present state of
    things. Pdb supports many commands and not all will be covered here, rather just
    the ones that are most commonly useful will be demonstrated. We'll start with
    a few that are helpful in getting context for where the code is, how it got there,
    and what arguments were passed to the current function.
  prefs: []
  type: TYPE_NORMAL
- en: The list command
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For example, if the single line of context provided on entry to the debugger
    is not sufficient, more of the surrounding code can be seen by using the `list`
    command. This command, like most pdb commands, can be abbreviated to its initial
    letter. Using it here we see:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Here we see that the response to the `list` command first displayed five lines
    above the current line of execution, then the current line of execution (noted
    by a `->` prefix), then five lines following the current line. At the `(Pdb)`
    prompt, an empty line was then entered, which causes the last entered command
    to be repeated. In the case of `list`, repeating the command results in the display
    of 11 additional lines following the last ones that were displayed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Arguments can be passed to `list` to specify exactly what lines to display,
    for example `l 1,5` will display the first five lines in the current file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The `list` command is most useful, though, for seeing the lines of code right
    around where execution is currently stopped. If more context is needed, I find
    it easier to have the file open in an editor in a separate window than to try
    to get a more complete picture of the file using `list` with arguments.
  prefs: []
  type: TYPE_NORMAL
- en: The where command
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `w` `here` command, which can be shorted to `w`, prints the current stack
    trace. In this case, there is no particular mystery about how the code got to
    where it is, but it can still be instructive to examine the details.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `get_piechart_url` method is called during template rendering, which means
    it will have a long stack trace due to the recursive way in which template nodes
    are rendered. The length of the response and the density of what gets printed
    out may seem overwhelming at first, but by ignoring a lot of the details and just
    focusing on the names of the files and functions you can get a good idea of the
    overall code flow. For example, at the start of the response, the `where` command
    here is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We may not be entirely sure what all of this code is doing, but with names
    like `serve_forever()`, `handle_request()`, `process_request()`, `finish_request()`,
    and `get_response()`, it seems likely that this is all part of a standard server
    request-processing loop. In particular, `get_response()` sounds like the code
    is getting close to the point where the real work of producing a response for
    the request will be done. Next, we see:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Indeed, in the `get_response` function, at the point where it invokes `callback()`,
    the code transitions from Django code (files in `/usr/lib/python2.5/site-packages/django`)
    to our own code in `/dj_projects`. We then see that we have introduced our own
    noise into the tracebacks with the logging wrapper functions—the references to
    `__call__` in `logutils.py`.
  prefs: []
  type: TYPE_NORMAL
- en: 'These don''t convey much information other than that the function calls being
    made are being logged. But ignoring the noise, we can still see that `survey_detail`
    was called, which in turned called `display_completed_survey`, which ran to the
    point where it is about to return (the last displayed line is the end of the multi-line
    call to `render_to_response` in `display_completed_survey`). The call to `render_to_response`
    transitions back into Django code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'What we can glean from this, and from the following `render()` and `render_node()`
    calls, is that the Django code is processing through rendering the template. Eventually,
    a few calls that are a bit different start appearing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: During rendering, the code finally got to the point where it needed to render
    the value of the `{{ q.get_piechart_url }}` in the template. Ultimately that got
    routed to a call to the `Question` model's `get_piechart_url` method, where we
    had placed the call to enter the debugger, and that is where we are now.
  prefs: []
  type: TYPE_NORMAL
- en: The args command
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `args` command, abbreviated as `a`, can be used to see the values of the
    arguments passed to the currently executing function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The whatis command
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `whatis` command displays the type of its argument. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Recall pdb also behaves like a Python shell session, so the same result can
    be obtained by taking the `type` of `self`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also interrogate individual attributes of variables, which can be helpful.
    Here the value of `self` displayed for the `args` command includes all of the
    individual attributes for this model, excepting its primary key value. We can
    find out what it is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The print and pp commands
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `print` command, abbreviated as `p`, prints the representation of a variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'For large data structures, the output of `print` may be hard to read if it
    ends up spilling across line boundaries. The alternative `pp` command pretty-prints
    the output using the Python `pprint` module. This can result in output that is
    more easily read. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Contrast that `print` output to the `pp` output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Debugging the pygooglechart results display
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point we know the code is at the beginning of processing in the `get_piechart_url`
    method, and the current value of `self` indicates that the `Question` instance
    we have been called for is the question that asks **What is your favorite type
    of TV show?** That's good to know, but what we'd really like to understand is
    what happens as execution continues.
  prefs: []
  type: TYPE_NORMAL
- en: The step and next commands
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'What we''d like to do now is instruct the debugger to continue execution, but
    keep the debugger active. There are two commands typically used here: `step` (abbreviated
    as `s`) and `next` (abbreviated as `n`).'
  prefs: []
  type: TYPE_NORMAL
- en: The `step` command begins execution of the current line and returns to the debugger
    at the first available opportunity. The `next` command also begins execution of
    the current line, but it does not return to the debugger until the next line in
    the current function is about to be executed. Thus, if the current line contains
    a function or method call, `step` is used to step into that function and trace
    through it, while `next` is used to execute the called function in its entirety
    and only return to the debugger when it is complete.
  prefs: []
  type: TYPE_NORMAL
- en: 'For where we are now, `next` is the command we''d want to use, since we do
    not particularly want to step into the logging code and trace through what it
    does:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, `next` caused execution of the `logging.debug` call, resulting in the
    logged message getting printed to the console. Then the debugger stopped again,
    right before execution of the next line in the current function. Entering nothing
    causes the `next` command to be executed again, causing `answer_set` to be assigned
    the value of `self.answer_set.all()`. We can see the result using the `print`
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'So far everything looks fine, so we continue on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'There''s a problem: the call to `set_data` on `chart` raised an attribute error
    with a message indicating that the chart has no such attribute. We made a mistake
    in implementing this routine. While many of the `pygooglechart` methods start
    with `set_`, the call to set the data for the chart is actually named `add_data`.
    So the attempt to specify the data for the chart has failed. But why didn''t we
    see that error reflected as a debug page returned instead of just an empty string
    returned from `get_piechart_url`? We can get the answer to that question by continuing
    on tracing through the code as it runs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: This shows that the `get_piechart_url` method is returning `None` at the point
    in the code where the `AttributeError` was raised. Since we did not enclose the
    code in `get_piechart_url` in a `try/except` block, the error is being propagated
    up the call stack.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we see that the code which called `get_piechart_url` was enclosed in a
    `try/except` block, and the `except` clauses are being tested for a match against
    the actual exception raised. The first clause, `except TypeError`, did not match
    `AttributeError`. The second one, `except Exception`, does match, since `AttributeError`
    is derived from the base `Exception` class. Thus, the code should proceed to run
    whatever code is in this except clause. Remember we can use the `list` command
    to see what that is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'These `except` clauses appear to be testing for special cases where the raised
    exception will be suppressed and the result produced will be set to the value
    of `settings.TEMPLATE_STRING_IF_INVALID`. That gives a hint of how this exception
    is ultimately not reflected in a debug page, though it may not happen immediately
    in the `except` clause that is about to be executed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Indeed, at this point the code is proceeding to re-raise the exception, only
    to have it be immediately caught again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The `list` command at this point shows what this `except` clause will do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Here it helps to recall exactly how constructs such as `{{ q.get_piechart_url
    }}` are handled during template rendering. Django template processing attempts
    to resolve the value on the right-hand side of the dot using these four methods,
    in order:'
  prefs: []
  type: TYPE_NORMAL
- en: Dictionary lookup
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attribute lookup
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Method call
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: List-index lookup
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We entered the debugger right in the middle of the method call attempt, after
    the first two options failed. The code that attempted the method call does not
    distinguish between an `AttributeError` resulting from the method not existing
    and an `AttributeError` raised by a called method, so the next step is going to
    be to attempt a list-index lookup. This too is going to fail:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Specifically, the list-index lookup attempt raises a `ValueError`, which we
    can see from the previous code is going to be treated specially and turned into
    a `VariableDoesNotExist` exception. We could continue tracing through the code,
    but at this point it is pretty clear what is going to happen. Invalid variables
    are turned into whatever is assigned to the `TEMPLATE_STRING_IF_INVALID` setting.
    Since the survey project has this setting set to the default of the empty string,
    an empty string is the ultimate result of the rendering of `{{ q.get_piechart_url
    }}`.
  prefs: []
  type: TYPE_NORMAL
- en: The continue command
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'At this point, we know what the problem is, how the problem resulted in an
    empty string in the template instead of a debug page, and we are ready to go fix
    the code. We can use the `continue` command, abbreviated as `c`, to tell the debugger
    to exit and let program execution continue normally. When we do that here we see:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'What happened? We are right back where we started. The reason is because there
    are two questions in the survey, and the template loops over them. The `get_piechart_url`
    method is called once for each question. When we exited the debugger after figuring
    out what happened with the first question, template processing continued and soon
    enough it again called `get_piechart_url`, where again the `pdb.set_trace()` call
    resulted in entry to the debugger. We can confirm this by seeing that `self` now
    refers to the second question in the survey:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: We could just `continue` again and proceed to fix our Python source file, but
    this actually presents an opportunity to play with some additional debugger commands,
    so we will do that.
  prefs: []
  type: TYPE_NORMAL
- en: The jump command
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, use `next` to proceed to the line of code where the wrong method is
    about to be called on `chart`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, manually issue the call that should be there instead, `chart.add_data`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'That call returned `0`, which is much better than raising an attribute error.
    Now we want to jump over the erroneous line of code. We can see that `set_data`
    call is on line `74` of `models.py`; we want to skip line `74` and instead go
    straight to line `75`. We do this with the `jump` command, which can be shortened
    to `j`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'That seems to have worked. We can proceed through with `next` to confirm we''re
    moving along without error in the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Except we don''t seem to be moving along, we seem to be stuck on one line.
    We''re not though. Notice that line includes a list comprehension: `[a.answer
    for a in answer_set]`. The `next` command will avoid tracing through called functions,
    but it does not do the same for list comprehensions. The line containing the comprehension
    is going to appear to be executed once for every item added to the list by the
    comprehension. This can get tedious, especially for long lists. In this case,
    the list is only three elements long, since there are only three answers in the
    set, so we could easily just keep hitting enter to get past it. However, there
    is also a way to get around this, which we may as well learn next.'
  prefs: []
  type: TYPE_NORMAL
- en: The break command
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `break` command, which can be shortened to `b`, sets a breakpoint on the
    specified line. Since `next` isn''t getting us past line 75 as quickly as we would
    like, we can set a breakpoint on line 76 and use `continue` to get through the
    list comprehension on line 75 in one step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: This can come in handy for getting past other looping constructs besides list
    comprehensions, or for quickly moving forward in code when you get to a point
    where you don't need to trace through each line, but you do want to stop a bit
    further on and see the state of things.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `break` command issued without arguments prints out a list of the currently
    set breakpoints, and how many times they have been hit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Notice the breakpoint resulting from `pdb.set_trace()` isn't included here,
    this display just shows breakpoints set via the `break` command.
  prefs: []
  type: TYPE_NORMAL
- en: The `break` command also supports other arguments besides a simple line number.
    You can specify a function name or a line in another file. In addition, you can
    also specify a condition that must be met for the breakpoint to be triggered.
    None of these more advanced options are covered in detail here. The Python documentation,
    however, provides full details.
  prefs: []
  type: TYPE_NORMAL
- en: The clear command
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After setting a breakpoint, there may come a time when you want to clear it.
    This is done by the `clear` command, which can be shorted to `cl` (not `c`, since
    that is `continue`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Now the debugger will no longer stop on line 76 of `models.py`. At this point,
    we''ve probably seen enough of the various debugger commands, and can just enter
    `c` to let the code continue on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'There we see the code continued processing, logging the return value from `get_piechart_url`,
    and exit from `display_completed_survey` and `survey_detail`. Ultimately, a `2989`
    byte response was returned for this request. Switching back to the web browser
    window, we see the browser waited all that time for a response. Furthermore, our
    manual calling of the correct method and jumping over the wrong one did work.
    The browser shows it was able to successfully retrieve the pie chart for the second
    question:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The clear command](img/7566_09_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Unfortunately, although the figure was produced without error, there is a bit
    of a problem with the labels being too long to fit properly. To fix this, we can
    try using a legend instead of labels. We'll do that, and make the change of replacing
    `set_data` with `add_data`, next.
  prefs: []
  type: TYPE_NORMAL
- en: Fixing the pygooglechart results display
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We seem close to having a working implementation of pie charts for our results
    display. We can update the `get_piechart_url` method to look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: The changes from the previous version are first removal of the logging calls
    (since they weren't particularly helpful) and also removal of the import of logging.
    The import for `PieChart3D` has been moved to the top of the file, with the other
    imports. The erroneous call to `chart.set_data` has been replaced with the correct
    `chart.add_data`. Finally, the call to `chart.set_pie_labels` had been replaced
    by `chart.set_legend`, in hopes that when the answers are arranged as a legend,
    they will be able to fit on the chart without spilling off the edges.
  prefs: []
  type: TYPE_NORMAL
- en: How well does that work? If we reload the browser page, the browser again appears
    to hang, because the `get_piechart_url` method still has the `pdb.set_trace()`
    call that breaks into the debugger. We might have removed that along with the
    other changes, in hopeful belief that the new version of the code is surely going
    to work, but often such hopes are dashed and we find ourselves having to re-add
    the call to figure out what is going wrong next. In this case, there are also
    a few more debugger commands to experiment with, which we'll do next.
  prefs: []
  type: TYPE_NORMAL
- en: The up and down commands
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When we switch to the `runserver` console window, we again find the code sitting
    at the beginning of `get_piechart_url`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'We could just continue and see how the new code behaves, but there are a few
    debugger commands we have not experimented with, so let''s do that first. One
    is the `step` command, which was mentioned previously, but never used since we
    have exclusively used `next` for stepping through the code. If we try `step` a
    few times here, we see:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Here we have single-stepped six times and as a result are now nested a couple
    of call levels deep into the Django code. We did it intentionally, and it's often
    a useful way of learning more about how Django (or other support library) code
    works. But it is also quite common when debugging to mistakenly start single-stepping
    through support library code when we really only wanted to be single-stepping
    through our own code. We then find ourselves suddenly nested possibly a few levels
    deep in completely unfamiliar code, and we want to get back to stepping through
    the code we are developing.
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to accomplish this is with the `up` command, which can be shortened
    to `u`. The `up` command moves the current stack frame up one level in the call
    chain:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we have moved up three levels. The original current stack frame was the
    one for the call to `create_manager`. The first `up` command switched the current
    stack frame to the one for `__get__`, the next switched to `get_piechart_url`,
    and the third went all the way back to the caller of `get_piechart_url`, `_resolve_lookup`.
    Switching the current stack frame does not execute any code, it just changes the
    context for commands. For example, now with the current stack frame for `_resolve_lookup`
    being current, we can examine variables that exist in that frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, `list` now will show us the code associated with the current stack frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'If we have switched stack frames and wonder where the current stack frame is
    relative to where the current execution point is, the `where` command shows that.
    In this case, the end of the `where` command output looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: The last line listed is always the current execution point, while the current
    stack frame is indicated by the `>` in the first column. Here, it indicates that
    the current stack frame is the one for `_resolve_lookup`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case we moved up one stack frame further than we really wanted to.
    To get back to our own code, we need to move back down one level. This is done
    by using the `down` command (which can be shortened to `d`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, if we want to continue running up to the next line from here, we can use
    the `next` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Now we are back in familiar territory, and can continue with debugging our own
    code.
  prefs: []
  type: TYPE_NORMAL
- en: The return command
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A second way to accomplish the same thing is to use the `return` command, which
    can be shortened to `r`. This command continues execution until the current function
    returns, and then the debugger is entered again. To see it in action, let''s step
    into the `PieChart3D` call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ve taken a couple of steps into the method, but have made only one call,
    so a single `return` should get us back to our survey code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'This method apparently does not have an explicit return line, so the line of
    code displayed is the last line in the method. The `->None` in the output shows
    what the method is returning. If we step from here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'We are now back to the next line of code after the call to create the pie chart.
    From here, we can use return to see what the `get_piechart_url` method is going
    to return:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'That looks good; the function ran to completion and is returning a value. Also,
    it seems that pdb shortens the displayed return values if they are long, since
    the displayed value doesn''t look quite right. We can confirm this with either
    of the `print` commands, which show that the actual value is a good bit longer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, it looks like all is working fine, so we may as well use `continue`
    to let the program keep running, then `continue` again when the debugger is entered
    for the second pie chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'That all looks good. What does the browser show? Switching to its window, we
    see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The return command](img/7566_09_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: That's better than before. Switching from labels to a legend has solved the
    problem of the answer text spilling off the figure. However, it's a little disconcerting
    for the pie charts themselves to be so different in size, depending on the length
    of the answers. Also, it might be nice if the pie chart wedges could be labeled
    with the percentage of the total that each represents.
  prefs: []
  type: TYPE_NORMAL
- en: Researching more on the Google chart API doesn't reveal any way to control the
    legend placement to perhaps keep the pie sizes the same, nor how to annotate the
    wedges with information like the percentage of total. While reasonably simple
    and straightforward to use, this API does not offer a lot in terms of customizing
    the charts that are generated. Thus, we might want to investigate other alternatives
    for generating charts, which we'll do next.
  prefs: []
  type: TYPE_NORMAL
- en: We'll keep the current implementation of `get_piechart_url`, though, since at
    this point we don't know that we are going to really switch to an alternative.
    Before moving on to the next thing, it makes sense to remove the import `pdb;
    pdb.set_trace()` in that function. The routine is working now, and if we do return
    to using it at a later point, it will be better if it runs to completion without
    user intervention instead of breaking into the debugger.
  prefs: []
  type: TYPE_NORMAL
- en: Results display using matplotlib
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `matplotlib` library provides another alternative for generating charts
    from Python. It can be found on the Python Package Index site, [http://pypi.python.org/pypi/matplotlib](http://pypi.python.org/pypi/matplotlib).
    The version of `matplotlib` used in this chapter is 0.98.3.
  prefs: []
  type: TYPE_NORMAL
- en: 'With `matplotlib`, our application cannot simply construct a URL and push the
    task of generating and serving the image data off to another host. Instead, we
    need to write a view that will generate and serve the image data. After some investigation
    of the `matplotlib` APIs, an initial implementation (in `survey/views.py`) might
    be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'That is a bit more complicated than the `pygooglechart` version. First, we
    need two imports from `matplotlib`: the basic `Figure` class, and an appropriate
    backend that can be used to render figures. Here, we have chosen the `agg` (Anti-Grain
    Geometry) backend, since it supports rendering to PNG format.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Within the `answer_piechart` view, the first four lines are straightforward.
    The `Question` instance is retrieved from the primary key value passed to the
    view. The answer set for that question is cached in the local variable `answer_set`.
    Then two arrays of data are created from the answer set: `x` contains the vote
    count values for each answer and `labels` contains the answer text values.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, a basic `matplotlib Figure` is created. A `matplotlib Figure` supports
    having multiple subplots contained in it. For the simple case where the `Figure`
    holds a single plot, `add_sublot` still needs to be called to create the subplot
    and return an `Axes` instance that can be used to draw on the plot. The arguments
    to `add_subplot` are the number of rows and columns in the subplot grid, then
    the number of the plot being added to the `Figure`. The arguments `1, 1, 1` here
    indicate the single subplot in a 1 x 1 grid.
  prefs: []
  type: TYPE_NORMAL
- en: The `pie` method is then invoked on the returned subplot `axes` to generate
    a pie chart figure. The first argument `x` is the array of data values for the
    pie wedges. The `autopct` keyword argument is used to specify a format string
    for annotating each pie wedge with its percentage of the total. The value `%.0f%%`
    specifies that the float percentage values should be formatted with zero digits
    after the decimal point, followed by a percent sign.
  prefs: []
  type: TYPE_NORMAL
- en: The `pie` method returns three data sequences. The first of these, `patches`,
    describes the pie wedges and needs to be passed to the figure's `legend` method
    for creating a legend to match the wedges to their associated answer values. Here
    we have specified that the legend should be placed in the lower left corner of
    the figure.
  prefs: []
  type: TYPE_NORMAL
- en: The other two sequences returned by `pie` describe the text labels (which will
    be blank here since `labels` were not specified when `pie` was called) and `autopct`
    annotations for the wedges. The code here does not need to use these sequences
    for anything.
  prefs: []
  type: TYPE_NORMAL
- en: With the legend in place, the figure is complete. A `canvas` for it is created
    using the previously imported `agg` backend `FigureCanvas`. An `HttpResponse`
    with content type `image/png` is created, and the image is written in PNG format
    to the response using the `print_png` method. Finally, the `answer_piechart` view
    returns this response.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the view code done, we need to update the `survey/urls.py` file to include
    a mapping that will route requests to that view:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Here we have added the last pattern. This pattern matches URL paths that start
    with `piechart/`, followed by one or more digits (the primary key), ending with
    `.png`. These URLs are routed to the `survey.views.answer_piechart` view, passing
    the captured primary key value as a parameter. The pattern is named `survey_answer_piechart`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final piece needed to switch to using `matplotlib` instead of `pygooglechart`
    is to update the `survey/completed_survey.html` template to generate URLs using
    this pattern. The only change needed is to update the line containing the `img`
    tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Here we have replaced the call to the question's `get_piechart_url` method with
    a `url` template tag referencing the new pattern just added.
  prefs: []
  type: TYPE_NORMAL
- en: 'How does that work? Reasonably well. We did not specify a size for the figures,
    and the default size from `matplotlib` is a bit larger than what we had specified
    for `pygooglechart`, so we cannot see the whole page without scrolling. However,
    each individual figure looks pretty good. For example, the first one appears like
    so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Results display using matplotlib](img/7566_09_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'And the second looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Results display using matplotlib](img/7566_09_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The `matplotlib` API supports much more customization than we have used here.
    The size of the figure could be changed, as could placement of the pie, colors
    of the wedge pieces, and font's properties for the text. The pie wedge for the
    winning answer could be emphasized by exploding it out from the rest of the pie.
    However, all of those items are cosmetic and beyond the scope of what we will
    cover here. To get back to the subject of debugging, we will turn our attention
    in the next section to removing some wasteful duplicate processing that was just
    introduced as a result of switching to `matplotlib`.
  prefs: []
  type: TYPE_NORMAL
- en: Improving the matplotlib approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Consider what happens now when the page for a completed survey is requested
    by a browser. For each question in the survey, the returned completed survey page
    has an embedded image that, when fetched, will trigger a call to the `answer_piechart`
    view. That view dynamically generates an image and is computationally expensive.
    In fact, depending on your hardware, if you try stepping through that view you
    may be able to observe appreciable pauses when stepping over some of the `matplotlib`
    calls.
  prefs: []
  type: TYPE_NORMAL
- en: Now consider what happens when many different users request the same completed
    survey page. That will trigger many calls into the computationally expensive `answer_piechart`
    view. Ultimately, all of the users will be served the exact same data, since results
    are not displayed until the survey is closed, so the underlying vote counts used
    to create the pie chart will not be changing. Yet `answer_piechart` will be called
    over and over to re-do the same considerable amount of work to produce the exact
    same result. This is a wasteful use of our server capacity.
  prefs: []
  type: TYPE_NORMAL
- en: 'How can we eliminate this waste? There are (at least) three possible approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduce caching, and cache the results of the `answer_piechart` view.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set up some external process that pre-computes all of the pie charts for a survey
    when it closes and saves them on disk somewhere. Change the `img` tags in the
    completed survey response template to refer to these static files instead of a
    view that dynamically generates the images.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dynamically generate the pie charts for a completed survey when the first request
    for it comes in, and save them to disk somewhere. This is essentially the same
    as the second approach, in that the `img` tags in the completed survey response
    will now refer to static files, but the computation of the charts is moved from
    some external process into the web server.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of these approaches has pros and cons. The one we are going to pursue is
    the last, simply because it offers the most opportunity to learn a couple of new
    things. Specifically, in implementing this third approach we will see how to set
    up the development server to serve static files, and we will see how pdb can be
    used to ensure that code operates properly in the face of multi-process race conditions.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up static file serving
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far in the development of the survey application we have concentrated entirely
    on serving dynamic content. While dynamic content is certainly the focus of Django
    applications, in reality even the most dynamic of applications will have some
    data that needs to be served from files. Here with the survey application we have
    run into a case where we want to serve image files from disk. Most applications
    will also have CSS and possibly JavaScript files that are better served directly
    from disk rather than through Django view code.
  prefs: []
  type: TYPE_NORMAL
- en: Django is a framework for serving dynamic content. Although it does not directly
    support serving data from files, there are a couple of settings that facilitate
    incorporating some static files into a project. These are `MEDIA_ROOT` and `MEDIA_URL`.
  prefs: []
  type: TYPE_NORMAL
- en: '`MEDIA_ROOT` is a file system path—the path to the directory that holds the
    static files for the project. It is used by Django internally as the base path
    for saving files uploaded to a model containing a `FileField`. For the survey
    application, we will use it as the base path for saving dynamically-generated
    pie chart image files.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The default value for this setting is an empty string, so we need to set it
    to something else now that we want to use it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Here we have set `MEDIA_ROOT` to point to a `site_media` directory (which we
    must create) under our main `marketr` project directory.
  prefs: []
  type: TYPE_NORMAL
- en: '`MEDIA_URL`, which also defaults to an empty string, is the base URL path for
    referring to static files. It is used by Django internally to general the `url`
    attribute of a file referenced by a `FileField` model.'
  prefs: []
  type: TYPE_NORMAL
- en: In addition, the `django.core.context_processors.media` context processor makes
    the value of this setting available in templates by setting `MEDIA_URL` in the
    template context. This context processor is enabled by default, so any templates
    rendered with a `RequestContext` have access to `MEDIA_URL`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s set `MEDIA_URL` in `settings.py` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Note that one value that should not be used for `MEDIA_URL` is `'/media/'`.
    This is the default setting for `ADMIN_MEDIA_PREFIX`, which defines the root URL
    for static files used by the admin. Trying to place two different trees of static
    files in the same place in the URL hierarchy does not work, and is most easily
    avoided by setting `MEDIA_URL` to something other than `'/media/'`.
  prefs: []
  type: TYPE_NORMAL
- en: Note that though these settings are defined in terms that establish a mapping
    from URL paths to files on disk, nothing in Django will automatically serve files
    based on that mapping. During URL resolution, Django does not test to see if the
    requested URL starts with `MEDIA_URL` and if so, serve up the corresponding file
    found under `MEDIA_ROOT`. Rather, Django assumes that URLs referring to static
    files on disk will be served by the web server directly and not routed through
    Django code at all.
  prefs: []
  type: TYPE_NORMAL
- en: However, so far during development we have not been using any web server other
    than Django's own development server. If we want to continue using the development
    server, we need to somehow get it to serve the image files created by the survey
    application. How do we do that?
  prefs: []
  type: TYPE_NORMAL
- en: 'Django does provide a static file serving capability, specifically for use
    during development. To use it, we need to update the project''s `urls.py` file
    to route requests for URLs that start with `''site_media/''` to Django''s static
    file serving view. Thus, we need to change the `urls.py` file to contain:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'The first change here from the previous version is the addition of the `import`
    of `settings` from `django.conf`. Second is the addition of the pattern referring
    to URLs that start with `site_media/`. These URLs are routed to `django.views.static.serve`.
    Two parameters are passed to this view: `document_root` and `show_indexes`. For
    `document_root`, the `MEDIA_ROOT` setting is specified, which means that the static
    server will look for the requested files under `MEDIA_ROOT`. `True` is specified
    for `show_indexes`, which means that the static server will return a list of files
    when the requested URL refers to a directory instead of a file.'
  prefs: []
  type: TYPE_NORMAL
- en: Dynamically generating image files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have set everything up for serving image files from disk, we can
    start to make the code changes necessary for this approach. First, we should remove
    the `piechart` pattern from the `survey/urls.py` file, as it is no longer needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Second, we can update the `display_completed_survey` function in `views.py`
    to include code that ensures the pie chart image files for each question in the
    survey have been generated before returning the completed survey response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: Here we have added the `for` loop that loops through all of the questions in
    the survey. For each, it calls a new method on the question, `check_piechart`.
    This routine will be responsible for ensuring that the pie chart file exists,
    creating it if necessary.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can move on to the `survey/models.py` file and update the `Question`
    model to include an implementation of `check_piechart` and anything else that
    might be needed to support the new approach. What else might be needed? For referencing
    the pie chart URL from a template, it would be convenient if the `Question` model
    supported returning the path to the pie chart file relative to `MEDIA_URL`. Thus,
    we need two new methods in the `Question` model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Here we have opted not to include a lot of file checking and creation code directly
    in `survey/models.py`, but rather to factor that work out into a new independent
    module in `survey/pie_utils.py`. The two routines implemented here, then, can
    be kept very simple.
  prefs: []
  type: TYPE_NORMAL
- en: '`piechart_path`, which is implemented as a read-only property, returns the
    path for the pie chart. This value can be combined with the `MEDIA_URL` setting
    to create a URL path, or with the `MEDIA_ROOT` setting to create a file system
    path. Since in the long-term we would expect to have more files than just pie
    chart images in the tree, it''s not appropriate to put the pie charts in the root
    of this tree. Thus, the `pie_utils.PIE_PATH` value is used to carve out a subtree
    within the static file tree to hold the pie charts.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that this routine is implemented to raise an `AttributeError` if the model
    instance has not yet been saved to the database, or if it references a survey
    that has not yet closed. In these situations, the pie chart file should not exist,
    so any attempt to reference it should trigger an error.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `check_piechart` method is implemented to forward the call to the `pie_utils
    make_pie_if_necessary` function. This function takes two parameters: the path
    for the pie chart, and the set of answers for the question.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we move on to the implementation of the `pie_utils` module, we can make
    a simple update to the `survey/completed_survey.html` template. The line containing
    the `img` tag needs to be changed to use the `Question` model''s `piechart_path`
    when creating the URL that references the pie chart image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: Here, `piechart_path` is combined with `MEDIA_URL` (available in the template
    since `display_completed_survey` specifies a `RequestContext` when calling `render_to_response`)
    to build the full URL for the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we need to implement the `survey/pie_utils.py` code. This module must
    define a value for `PIE_PATH`, and implement the `make_pie_if_necessary` function.
    The first task is trivial and accomplished with something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: This code defines a value for `PIE_PATH` and ensures that the resulting subdirectory
    under the project's `MEDIA_ROOT` exists, creating it if necessary. With this code
    and the previously noted setting for `MEDIA_ROOT`, the pie chart image files for
    the survey application will be placed in `/dj_projects/marketr/site-media/piecharts/`.
  prefs: []
  type: TYPE_NORMAL
- en: The second piece needed to complete the `pie_utils` module, an implementation
    of the `make_pie_if_necessary` function, may also seem quite simple at first glance.
    If the file already exists, `make_pie_if_necessary` does not need to do anything,
    otherwise it needs to create the file. However, things get more complicated when
    you consider that the deployment environment for this code will eventually be
    a potentially multi-process multi-threaded web server. This introduces the opportunity
    for race conditions, which we'll discuss next.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with race conditions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A naïve implementation of the `make_pie_if_necessary` module might be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Here `make_pie_if_necessary` creates the full file path by combining the passed
    relative path with the settings `MEDIA_ROOT` value. Then, if that file does not
    exist, it calls `create_piechart`, passing along the filename and the answer set,
    to create the pie chart file. This routine could be implemented like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: This code is essentially what was in the original `matplotlib` implementation
    in the `answer_piechart` view, modified to account for the fact that the answer
    set has been passed directly, as has the file to which the image data should be
    written.
  prefs: []
  type: TYPE_NORMAL
- en: This implementation of `make_pie_if_necessary`, when tested with the development
    server, would work fine. It might even seem to work fine in a lightly loaded production
    environment. However, if you consider a heavily loaded production environment,
    with a multi-process web server where requests for the same page may be arriving
    nearly simultaneously, a potential problem emerges. There is nothing to prevent
    multiple nearly-simultaneous calls to `make_pie_if_necessary` from resulting in
    multiple nearly-simultaneous calls to `canvas.print_png` to create the same file.
  prefs: []
  type: TYPE_NORMAL
- en: It's clear how this could happen on a multi-processor machine, since it's easy
    to see how two simultaneous requests might get dispatched to different processors
    and result in the same code running simultaneously on each. Both processes check
    to see if the file exists, both find it does not, and both embark on creating
    it.
  prefs: []
  type: TYPE_NORMAL
- en: The same situation can also occur even on a single-processor machine, with preemptive
    scheduling by the operating system. One process may check to see if the file exists,
    find it does not, and start down the path of creating it. However, before this
    code actually gets to the point of creating the file, the operating system's preemptive
    scheduler suspends it and lets the process handling the second nearly-simultaneous
    request run. This process also fails to find the file when it checks, and also
    starts down the path of creating it.
  prefs: []
  type: TYPE_NORMAL
- en: 'What would be the end result if this were to happen? Would it be that bad?
    Perhaps not. Possibly one process would do its job of creating and writing the
    file, and then the second one would do its work, overwriting the results from
    the first. There would have been some duplicate work done, but the end result
    might be fine: a file on disk containing the PNG image of the pie chart.'
  prefs: []
  type: TYPE_NORMAL
- en: However, is there any guarantee that the work of the two nearly simultaneous
    calls would be serialized like that? No. The `matplotlib` API doesn't provide
    any such guarantee. Without digging into the implementation it's hard to be sure,
    but it seems likely that the task of writing out an image file may be split into
    several different individual write calls. This affords ample opportunity for random
    interleaving of calls from different processes that reference the same file to
    result in a corrupt image file ultimately written out to disk.
  prefs: []
  type: TYPE_NORMAL
- en: 'To prevent this, we need to change the `make_pie_if_necessary` function to
    use an atomic method of checking for the file''s existence and create it if necessary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: This code uses a combination of flags passed to the `os.open` routine to atomically
    create the file. `os.O_WRONLY` specifies that the file is open for writing only,
    `os.O_CREAT` specifies that the file should be created if it does not exist, and
    `os.O_EXCL`, in combination with `os.O_CREAT`, specifies that an error should
    be raised if the file exists. Even if multiple processes simultaneously issue
    this `os.open` call, the underlying implementation guarantees that only one will
    be successful, and an error will be raised for the others. Thus, only one process
    will proceed with the code that creates the pie chart.
  prefs: []
  type: TYPE_NORMAL
- en: Note that when running on Windows, `os.O_BINARY` also needs to be included in
    the set of flags passed into `os.open`. Without that flag, Python will treat the
    file data as text and automatically insert carriage return characters whenever
    a linefeed is encountered in the data written to the file. This behavior will
    result in corrupt PNG image files that cannot be displayed.
  prefs: []
  type: TYPE_NORMAL
- en: One wrinkle introduced by this change is that the file descriptor returned by
    `os.open` cannot be passed to `matplotlib` as a target file for the PNG data.
    The `matplotlib` library accepts filenames, or Python file-like objects, but it
    does not support a file descriptor as returned by `os.open`. Thus, the code here
    converts the file descriptor to a Python file object using `os.fdopen`, and passes
    the returned file to the `create_piechart` routine.
  prefs: []
  type: TYPE_NORMAL
- en: In the case where the `os.open` call raises an `OSError`, the exception's `errno`
    attribute is tested against `errno.EEXIST`. This is the specific error that will
    be raised when the file already exists, and should not be reflected up as an error
    but rather should be ignored. Any other errors are reflected to the caller of
    `make_pie_if_necessary`.
  prefs: []
  type: TYPE_NORMAL
- en: These changes ensure that the image file will be created only once, which is
    good. However, there's another potential problem. Consider what happens now with
    multiple simultaneous requests. Only one will proceed down the path of creating
    the file. All the others will see that the file already exists and simply proceed
    to send a response referencing it.
  prefs: []
  type: TYPE_NORMAL
- en: 'But note that the file existence does not guarantee that the image data has
    been written to it: there is a fair amount of processing to be done first to create
    the image, before it is written to the file. Is there any guarantee that this
    processing will complete before any requests for the file are received and processed?
    No. Depending on how fast clients are and how slow the image generation is, it''s
    possible for a request for the file to arrive and be processed before the image
    data is actually written to the file.'
  prefs: []
  type: TYPE_NORMAL
- en: Is this likely to happen? Probably not. What would be the effect if it did?
    Probably nothing terrible. Likely the browser would display a partial image or
    the **Pie Chart** alternate text for the image. The user might try re-loading
    the page to see if it worked better the second time, and by then the image file
    would probably be served correctly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given the seemingly slim chances of this situation arising, and its fairly
    minor effect, we might choose not to fix this particular problem. However, in
    some situations it may be necessary to ensure that the file not only exists but
    also contains data. It might be worthwhile to investigate fixing this potential
    problem. One approach is to modify `make_pie_if_necessary` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Here the first change is to obtain an exclusive lock on the file, using `fcntl.flock`,
    before calling `create_piechart`. (Note that `fcntl` is a Unix-only Python module.
    Thus, this code will not work on Windows. There are add-on packages to get file
    locking capabilities in Windows, but specifics of using any of them are beyond
    the scope of what will be covered here.) Second, this file lock is released before
    the file is closed after `create_piechart` returns. Third, in the case where the
    file is found to already exist, instead of immediately returning, a new `wait_for_data`
    function is called. The implementation of `wait_for_data` is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: This code, given a filename, first opens the file for reading. It then assumes
    the file is empty and enters a loop that will continue as long as the file remains
    empty. In the loop, the code obtains a shared lock on the file, and then calls
    `os.fstat` to determine the file's size. If the returned size is non-zero, then
    `emtpy` is set to `False`, which will terminate the loop at the end of this iteration.
    Before that, though, the file lock is released, and if the file is in fact empty,
    the code sleeps for half a second before proceeding with the next iteration of
    the loop. The sleep is intended to give the other process, presumably busy trying
    to create and write the data, time to finish its work. Before returning, the file
    is closed (if it was ever successfully opened).
  prefs: []
  type: TYPE_NORMAL
- en: That all looks OK, and seems to work well enough when we try it out, testing
    it in a browser. However, it is hard to be sure, just based on visual inspection
    of code like this, that it is completely correct. Using a debugger here to artificially
    create the kind of race conditions we are trying to guard against, can be helpful.
    We'll do this next.
  prefs: []
  type: TYPE_NORMAL
- en: Using the debugger to force race situations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It is not possible to force race conditions using the development server alone:
    it is single-threaded and single-process. However, we can use the development
    server in combination with a `manage.py shell` session, with debugger breakpoints
    and single-stepping, to force any combination of multi-process interleaved execution
    that we want to test out.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, we can insert a breakpoint near the top of the `make_pie_if_necessary`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we need to delete any already-generated image files from disk, so that
    when this function is first entered it will go down the path of trying to create
    a file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we ensure the development server is running, and from a browser, re-load
    the results page for the **Television Trends** survey. The browser will appear
    to hang, and in the development server console we will see the debugger entered:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'If we use `next` to step over this call, we will see:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'Execution proceeded to the next line of code, so the `os.open` call was successful.
    This thread is now frozen at the point where the file has been created, but no
    data has been written to it. We want to verify that another process calling the
    same function will correctly proceed to wait for the file data to be written before
    continuing. To test this, we can start a `manage.py shell` in a separate window,
    manually retrieve the appropriate question, and call its `check_piechart` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'The breakpoint in `make_pie_if_necessary` has again stopped execution right
    before the call to open the file. In this case when we use next to step over the
    call, we should see the code take a different path, since the file already exists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'That looks good. Stepping through the code we see that `os.open` raised an
    `OSError` with `errno` attribute `errno.EEXIST`, as expected. The shell thread,
    then, will proceed to wait for the file to have data. If we step into that routine,
    we can see if it runs as we expect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, we''ve done the preliminary processing in this routine. The
    file is now open and `empty` has been initialized to `True`. We''re ready to enter
    the first iteration of the loop. What should happen? Since the other thread of
    control is still blocked before it has even obtained the exclusive lock on the
    file, this thread should be able to obtain a shared lock on the file, test the
    file size, and end up sleeping for half a second since the file is empty. Stepping
    through, we see that is indeed what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'The `fcntl.flock` to lock the file returned immediately since the file is not
    yet locked by the other thread. This code found the file size to be zero, proceeded
    to sleep for half a second, and is now beginning a second iteration of the loop.
    Let''s step it forward to a point where it has again obtained a shared lock on
    the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now leave this thread frozen here, return to the development server
    thread, and attempt to move forward in it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: This code was not able to proceed very far. It did convert the file descriptor
    into a Python file object, but the next call is to get an exclusive lock on the
    file, and that call has been blocked—there is no `(Pdb)` prompt in response to
    the final `n` command, so execution has stopped somewhere inside the call. That's
    good, since a call to obtain an exclusive lock should not return until the other
    thread releases its lock.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can switch back to that thread and move it forward to the point where it
    releases the lock:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'Immediately when we stepped over the call to release the lock, the development
    server console returned to the `(Pdb)` prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'This thread now has an exclusive lock on the file, and if we keep it frozen
    at this point, we should see that the other thread will be blocked on its next
    attempt to obtain a shared lock:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'That looks good, this thread has been blocked. It should now not be able to
    obtain the lock until the development server thread releases it, at which point
    the file will have data. Let''s move the development server thread forward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we stepped over the call to create the pie chart, and the call to unlock
    the file. At that point, the shell thread stopped blocking:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'This thread should now see that the file has data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'That looks good; the code is setting `empty` to `False`, which should trigger
    the end of the loop once the task of releasing the shared lock is finished:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'Indeed, the code proceeded to exit the loop, close the file, and return. We
    can enter `c` to continue here, and get back the regular shell prompt. At this
    point we can also let the development server continue, and it will re-enter the
    debugger for processing of the second pie chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: Are we done or is there anything else we might want to test at this point? All
    seemed to look good, but one thing you might have noticed tracing through the
    code was that the second thread that was waiting on the file data was allowed
    to proceed before the first thread actually closed the file. Might that be a problem?
    In the absence of explicit calls to flush data to disk, it's possible that data
    is buffered in memory, and won't actually get written until the file is closed.
    Depending on how long that takes, the other thread that proceeded under the assumption
    that the file was now all set for reading might run into trouble, because in fact
    not all of the data is available on disk for reading by a separate thread.
  prefs: []
  type: TYPE_NORMAL
- en: 'Can we test that situation? Yes, we can use this second request by the development
    server to see if there might be a problem. In this case, we leave the development
    server blocked before the call to create the file, and from the shell session
    we proceed to retrieve the second question and call its `check_piechart` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we''ve moved along in the shell session all the way through locking the
    file, creating the pie chart, and unlocking the file. We''ve not yet closed the
    file. Now if we move forward in the development server, it will see that the file
    exists and has data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'That looks good; the code in this case took the right path. But if we continue
    from here, still without giving the shell thread a chance to close the file, will
    the browser''s subsequent request for this image file be served successfully?
    We can test it out by entering `c` here, and checking what the browser shows for
    the second pie chart. It seems we do have a problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using the debugger to force race situations](img/7566_09_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Either we''ve broken the code that generates the pie chart, or that''s the
    result of serving an image file that has not yet been completely written to the
    disk. The latter seems more likely. How do we fix this? We can change the `make_pie_if_necessary`
    function to flush the data to disk before releasing the exclusive lock:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: Consulting the Python documentation shows both a `flush` of the file and a call
    to `os.fsync`, for it is needed to ensure that all the file data is actually written
    to disk, so we have added both of those before the call to unlock the file.
  prefs: []
  type: TYPE_NORMAL
- en: Does that work? Testing it means again deleting the image files and again forcing
    the race condition we are looking to exercise. The detailed output isn't included
    here, but indeed if we force a new shell session to be the thread that creates
    the second image file, halt it before it closes the file, and let the development
    server thread proceed to send the completed survey response page and then serve
    the image files, we see a complete second image in the browser. So adding the
    calls to `flush` and `os.fsync` does appear to fix the problem.
  prefs: []
  type: TYPE_NORMAL
- en: This exercise has demonstrated how hard it can be to write code that correctly
    handles race conditions. Unfortunately, such race conditions often cannot be avoided
    in web applications, which will generally be deployed in multi-threaded, multi-process
    web servers. The debugger is a valuable tool for ensuring that code written to
    deal with these conditions works as intended.
  prefs: []
  type: TYPE_NORMAL
- en: Notes on using graphical debuggers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have focused exclusively on use of the Python command-line
    debugger, pdb. Graphical integrated development environments such as Eclipse,
    NetBeans, and Komodo also provide debuggers that can be used for Django application
    code (though some require installation of particular plugins to support development
    of Python code). The details of setting up and using any of these environments
    is beyond the scope of what is covered here, but some general notes on using graphical
    debuggers for Django applications will be included next.
  prefs: []
  type: TYPE_NORMAL
- en: First, there are some definite advantages to using a graphical debugger. Usually,
    a graphical debugger will provide individual window panes that show the currently
    executing source code, the program stack trace, local variables, and program output.
    This can make it easy to quickly get an overall sense of the state of the program.
    It tends to be harder to do this in pdb, where you must run individual commands
    to get the same information, and be able to keep the results in mind after they
    scroll off the screen.
  prefs: []
  type: TYPE_NORMAL
- en: A second advantage to graphical debuggers is that you can generally set breakpoints
    simply by selecting the line of code in the debugger and choosing a menu item.
    Thus, you can easily debug without changing the source to include explicit breaks
    into the debugger.
  prefs: []
  type: TYPE_NORMAL
- en: One requirement for breakpoints in graphical debuggers to work, though, is that
    the `runserver` command used to start the development server in the debugger must
    specify the `--noreload` option. Without this option, the development server reloads
    itself automatically when it detects that running code has changed on disk. This
    reload mechanism interferes with the method used by graphical debuggers to trigger
    breakpoints activating the debugger, so it must be disabled by specifying `--noreload`
    when running the server.
  prefs: []
  type: TYPE_NORMAL
- en: A downside of this of course, is that the development server running in the
    integrated development environment will not automatically reload when code changes
    are made. If you have gotten used to the automatic reload feature when running
    from a simple command line, it can be hard to remember the need to manually restart
    the server after making code changes.
  prefs: []
  type: TYPE_NORMAL
- en: Another thing to watch out for when using a graphical debugger is the debugger
    itself triggering unexpected behavior. In order to produce the display of local
    variables, for example, the debugger must interrogate their values. For local
    variables that are `QuerySets`, this may mean that the debugger causes database
    interactions that the application itself would never initiate. Thus the debugger,
    in attempting to display the value of local variables, can trigger evaluation
    of `QuerySets` at points where the application itself does not.
  prefs: []
  type: TYPE_NORMAL
- en: '`QuerySets` are just one example of how the debugger can inject unexpected
    behavior. Essentially the debugger may need to run a lot of code behind the scenes
    in order to do its work, and that behind the scenes work may have side-effects.
    These side-effects may or may not interfere with the task of debugging the application
    code. If they do (generally signaled by unexpected results that occur only when
    run under the debugger), it may be more productive to switch to a different debugging
    technique rather than trying to figure out what exactly is going on behind the
    scenes with the debugger.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This brings us to the end of discussing the use of debuggers when developing
    Django application code. In this chapter, we:'
  prefs: []
  type: TYPE_NORMAL
- en: Implemented the display of survey results using `pygooglechart` to create pie
    charts. When we ran into some trouble along the way, we saw how the Python debugger,
    pdb, could be used to help figure out what was going wrong. We experimented with
    many of the most useful pdb commands. We learned the commands used to see the
    context of the code that is running, examine and change the values of variables,
    and flexibly control the execution of the code as it proceeds in the debugger.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Re-implemented the display of survey results using the `matplotlib` library.
    For this alternative implementation, we ended up needing to write code that was
    vulnerable to multi-process race conditions. Here we saw how pdb can be used to
    help verify correct behavior of this type of code, since it allows us to force
    problematic race conditions to occur, and then verify that the code behaves properly
    for such cases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, some pros and cons of using graphical debuggers for Django application
    code were discussed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next chapter, we will learn what to do when we encounter problems during
    development that none of the debugging techniques discussed so far seem to help
    in fixing.
  prefs: []
  type: TYPE_NORMAL
