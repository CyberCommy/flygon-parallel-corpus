- en: Chapter 7. 360-Degree Gallery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 360-degree photos and videos are a different approach to virtual reality. Rather
    than rendering 3D geometry in real time with OpenGL, you're letting users look
    around a prerendered or photographed scene. 360-degree viewers are a great way
    to introduce consumers to VR because they give a very natural experience and are
    easy to produce. It is much easier to take a photo than to render a photorealistic
    scene of objects in real time. Images are easy to record with a new generation
    of 360-degree cameras, or the photosphere feature in the Google Camera app. Viewing
    prerecorded images requires much less computer power than rendering full 3D scenes,
    and this works well on mobile Cardboard viewers. Battery power should also be
    less of an issue.
  prefs: []
  type: TYPE_NORMAL
- en: Non-VR 360-degree media has become fairly common. For example, for many years
    real-estate listing sites have provided panoramic walkthroughs with a web-based
    player that lets you interactively view the space. Similarly, YouTube supports
    the uploading and playback of 360-degree videos and provides a player with interactive
    controls to look around during playback. Google Maps lets you upload 360-degree
    still photosphere images, much like their Street View tool, that you can create
    with an Android or iOS app (for more information, visit [https://www.google.com/maps/about/contribute/photosphere/](https://www.google.com/maps/about/contribute/photosphere/))
    or a consumer 360 camera. The Internet is teeming with 360-degree media!
  prefs: []
  type: TYPE_NORMAL
- en: Viewing 360-degree media in VR is surprisingly immersive, even for still photos
    (and even without a pair of stereoscopic images). You're standing at the center
    of a sphere with an image projected onto the inside surface, but you feel like
    you're really there in the captured scene. Simply turn your head to look around.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this project, we''ll build a photo gallery that lets you browse photos on
    your phone. Regular flat pictures and panoramas will appear projected on a large
    screen to your left. But 360-degree photospheres will fully immerse you inside
    the spherical projection. We will accomplish this project by performing the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the new project
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Viewing a 360-degree photosphere
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Viewing a regular photo on a large virtual projection screen
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding a frame border to the photos
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading and displaying a photo image from your device's camera folder
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adjusting a photo's orientation and aspect ratio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a user interface with a grid of thumbnail images for selecting the
    photo to be viewed with scrolling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensuring a good, responsive VR experience with thread-safe operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Launching an Android image view intent app
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The source code for this project can be found on the Packt Publishing website,
    and on GitHub at [https://github.com/cardbookvr/gallery360](https://github.com/cardbookvr/gallery360)
    (with each topic a separate commit).
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the new project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To build this project, we''re going to use our `RenderBox` library created
    in [Chapter 5](ch05.html "Chapter 5. RenderBox Engine"), *RenderBox Engine*. You
    can use yours, or grab a copy from the download files provided with this book
    or our GitHub repo (use the commit tagged `after-ch6`—[https://github.com/cardbookvr/renderboxlib/releases/tag/after-ch6](https://github.com/cardbookvr/renderboxlib/releases/tag/after-ch6)).
    For a more detailed description of how to import the `RenderBox` library, refer
    to the final section, *Using RenderBox in future projects*, in [Chapter 5](ch05.html
    "Chapter 5. RenderBox Engine"), *RenderBox Engine*. To do this, perform the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: With Android Studio opened, create a new project. Let's name it `Gallery360`
    and target **Android 4.4 KitKat (API 19)** with an **Empty Activity**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create new modules for the `renderbox`, `common`, and `core` packages, using
    **File** | **New Module** | **Import .JAR/.AAR Package**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the modules as dependencies for the app, using **File** | **Project Structure**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Edit the `build.gradle` file as explained in [Chapter 2](ch02.html "Chapter 2. The
    Skeleton Cardboard Project"), *The Skeleton Cardboard Project*, to compile against
    SDK 22.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update `/res/layout/activity_main.xml` and `AndroidManifest.xml`, as explained
    in the previous chapters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Edit `MainActivity` as `class MainActivity extends CardboardActivity implements
    IRenderBox`, and implement the interface method stubs (*Ctrl* + *I*).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can go ahead and define the `onCreate` method in `MainActivity`. The class
    now has the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'While we implement this project, we will be creating new classes that could
    be good extensions to `RenderBoxLib`. We''ll make them regular classes in this
    project at first. Then, at the end of the chapter, we''ll help you move them into
    the `RenderBoxLib` project and rebuild the library. Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Right-click on the `gallery360` folder (`com.cardbookvr.gallery360`) and go
    to **New** | **Package**, and name the package `RenderBoxExt`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Within `RenderBoxExt`, create package subfolders named `components` and `materials`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There's no real technical need to make it a separate package but this helps
    organize our files, because the ones in `RenderBoxExt` will be moved into our
    reusable library at the end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can add a cube to the scene, temporarily, to help ensure that everything
    is set up properly. Add it to the `setup` method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: If you remember, a cube is a component that's added to a transform. The cube
    defines its geometry (for example, vertices). The transform defines its position,
    rotation, and scale in 3D space.
  prefs: []
  type: TYPE_NORMAL
- en: You should be able to click on **Run 'app'** with no compile errors, and see
    the cube and Cardboard split screen view on your Android device.
  prefs: []
  type: TYPE_NORMAL
- en: Viewing a 360-degree photo
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ever since it was discovered that the Earth is round, cartographers and mariners
    have struggled with how to project the spherical globe onto a two-dimensional
    chart. The result is an inevitable distortion of some areas of the globe.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To learn more about map projections and spherical distortions, visit [http://en.wikipedia.org/wiki/Map_projection](http://en.wikipedia.org/wiki/Map_projection).
  prefs: []
  type: TYPE_NORMAL
- en: 'For 360-degree media, we typically use an equirectangular (or a meridian) projection
    where the sphere is unraveled into a cylindrical projection, stretching the texture
    as you progress toward the North and South poles while keeping the meridians as
    equidistant vertical straight lines. To illustrate this, consider Tissot''s Indicatrix
    (visit [http://en.wikipedia.org/wiki/Tissot%27s_indicatrix](http://en.wikipedia.org/wiki/Tissot%27s_indicatrix)
    for more information) that shows a globe with strategically arranged identical
    circles (an illustration by Stefan Kühn):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Viewing a 360-degree photo](img/B05144_07_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following image shows the globe unwrapped with an equirectangular projection
    ([https://en.wikipedia.org/wiki/Equirectangular_projection](https://en.wikipedia.org/wiki/Equirectangular_projection)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Viewing a 360-degree photo](img/B05144_07_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We will use an equirectangular mesh for our photospheres and an appropriately
    projected (warped) image for its texture map. To view, we place the camera viewpoint
    at the center of the sphere and render the image onto the inside surface.
  prefs: []
  type: TYPE_NORMAL
- en: You may have noticed that our Earth and other planet textures had the same sort
    of distortion on them. It's a pretty common way to map spherical images to flat
    ones, and in fact, we've been "doing the math" on this problem ever since we created
    the UVs for our sphere in [Chapter 6](ch06.html "Chapter 6. Solar System"), *Solar
    System*! You'll have to get clever with UV offsets to keep them from appearing
    stretched, but you should also be able to display panoramic photos on a sphere
    in the same way.
  prefs: []
  type: TYPE_NORMAL
- en: Viewing a sample photosphere
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You may choose any 360-degree equirectangular image for this topic. We''ve
    included the following beach photo with this book, named `sample360.jpg`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Viewing a sample photosphere](img/B05144_07_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Add it to your project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Copy the image you want to view into the project''s `res/drawable/` folder.
    Now add the following code to the `MainActivity.java` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Note that multiplying the scale by 0.99 avoids unwanted clipping of the background
    image due to floating point precision errors on some phones. Using a negative
    scale *y* axis compensates for inverted rendering by the texture shader (alternatively
    you could modify the shader code).
  prefs: []
  type: TYPE_NORMAL
- en: You can replace the drawable filename, `R.drawable.sample360`, with yours, as
    defined in the `DEFAULT_BACKGROUND` variable. This variable must be final, as
    required by the Android resource system.
  prefs: []
  type: TYPE_NORMAL
- en: In the `setup` method, we create a `Sphere` component as we have been doing
    all along. Start with a new transform, scale it, then add a new `Sphere` component
    with our resource ID to the transform. We're naming the object `background` because
    later on, this object will be the default background for the app.
  prefs: []
  type: TYPE_NORMAL
- en: Run the app, and insert your phone into a Cardboard viewer. Voila! You're in
    Margaritaville!! If that seemed really easy, you're right; it was! Really, the
    hard work was done for us by the photosphere app or whatever transformed the image
    into an equirectangular projection. The rest of it is the standard UV projection
    math we've been doing all along!
  prefs: []
  type: TYPE_NORMAL
- en: '![Viewing a sample photosphere](img/B05144_07_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Using the background image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We're going to make a gallery that lets the user pick from a number of images.
    It would be nice if the user saw something more neutral when they first started
    the app. A more appropriate background image is included with the downloadable
    files for this book. It is named `bg.png` and contains a regular grid. Copy it
    to your `res/drawable/` folder. Then, change `DEFAULT_BACKGROUND` to `R.drawable.bg`.
  prefs: []
  type: TYPE_NORMAL
- en: '![Using the background image](img/B05144_07_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Rerun the app, and it should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using the background image](img/B05144_07_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Viewing a regular photo
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we got that done, let's prepare our app to also be able to view regular
    flat photos. We'll do this by rendering them onto a plane. So first we need to
    define a `Plane` component.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the Plane component and allocating buffers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `Plane` component rightfully belongs to the `RenderBox` library, but for
    the time being, we'll add it directly to the app.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Java class file in the `RenderBoxExt/components/` folder, and
    name it `Plane`. Define it as `extends RenderObject`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'As with other geometry in the `RenderBox` library, we''ll define the plane
    with triangles. Simply two adjacent triangles are required, a total of six indices.
    The following data arrays define our default plane''s 3D coordinates, UV texture
    coordinates, vertex colors (middle gray), normal vectors, and corresponding indices.
    Add the following code at the top of the class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can define the `Plane` constructor that calls an `allocateBuffers`
    helper method that allocates buffers for vertices, normals, textures, and indexes.
    Let''s declare variables for these at the top of the class, and write the methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Again, we ensure that `allocateBuffers` is run only once by checking whether
    `vertexBuffer` is null. (Note that we've decided to declare the buffers `public`
    to afford future flexibility to create arbitrary texture materials for objects.)
  prefs: []
  type: TYPE_NORMAL
- en: Adding materials to the Plane component
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, we can add an appropriate material to the `Plane`, one that uses a texture
    image. Using a constructor API pattern that is consistent with the built-in `Sphere`
    component in [Chapter 6](ch06.html "Chapter 6. Solar System"), *Solar System*,
    we''ll add the ability to call a new `Plane` with an image texture ID and an optional
    lighting Boolean flag. Then, we''ll add helper methods to allocate the corresponding
    `Material` objects and set their buffers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Adding an image screen to the scene
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can now add an image to the scene in `MainActivity`. Soon we will take a
    look at the phone's photos folder for pictures, but at this point, you can just
    use the same (photosphere) one that we used earlier (or drop another in your `res/drawable`
    folder). Note that you might have issues displaying an image that is too large
    for a phone's GPU. We will take a look at this issue later, so try to keep it
    less than 4,096 pixels in either dimension.
  prefs: []
  type: TYPE_NORMAL
- en: Name the object `screen` because later on, we'll use it to project whichever
    photo the user selects from a gallery.
  prefs: []
  type: TYPE_NORMAL
- en: 'In `MainActivity.java`, update the `setup` function to add the image to the
    scene, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The screen is scaled to 4 units (in X and Y) and placed 5 units in front of
    the camera. That's like sitting 5 meters (15 feet) from an 8 meter wide movie
    screen!
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, note that we rotate the plane 180 degrees on the *z* axis; otherwise,
    the image will appear upside down. Our world coordinate system has the up-direction
    along the positive *y* axis. However, UV space (for rendering textures) typically
    has the origin in the upper-left corner and positive is downward. (If you remember,
    in the previous chapter, this is why we also had to flip the Earth). Later in
    this chapter, when we implement an `Image` class, we''ll read the actual orientation
    from the image file and set the rotation accordingly. Here''s our screen plane
    with the image (viewed from an angle):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Adding an image screen to the scene](img/B05144_07_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'It will be convenient to separate the screen plane (with its image texture)
    from the placement and size of the screen. We will see why this is important later,
    but it has to do with scaling and rotating based on image parameters. Let''s refactor
    the code so that the screen is parented by a `screenRoot` transform as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Putting a border frame on the image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pictures look best in a frame. Let's add one now. There are a number of ways
    to accomplish this, but we are going to use shaders. The frame will also be used
    for the thumbnail images and will enable us to change colors to highlight when
    the user selects an image. Furthermore, it helps define a region of contrast,
    which ensures that you can see the edge of any image on any background.
  prefs: []
  type: TYPE_NORMAL
- en: Border shaders
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can start by writing the shader programs which, among other things, define
    the variables they will need from the `Material` object that uses it.
  prefs: []
  type: TYPE_NORMAL
- en: If necessary, create a resource directory for the shaders, `res/raw/`. Then,
    create the `border_vertex.shader` and `border_fragment.shader` files. Define them
    as follows.
  prefs: []
  type: TYPE_NORMAL
- en: The `border_vertex` shader is identical to the `unlit_tex_vertex` shader that
    we were using.
  prefs: []
  type: TYPE_NORMAL
- en: 'File: `res/raw/border_vertex.shader`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'For the `border_fragement` shader, we add variables for a border color (`u_Color`)
    and width (`u_Width`). Then, add a bit of logic to decide whether the current
    coordinate being rendered is on the border or in the texture image:'
  prefs: []
  type: TYPE_NORMAL
- en: 'File: `res/raw/border_fragment.shader`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that this technique cuts off the edges of the image. We found this to
    be acceptable, but if you really want to see the entire image, you can offset
    the UV coordinates within the `texture2D` sampler call. It would look something
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Finally, observant readers might notice that when the plane is scaled non-uniformly
    (to make it a rectangle), the border will be scaled so that the vertical borders
    might be thicker or thinner than the horizontal borders. There are a number of
    ways to fix this, but this is left as an exercise for the (over-achieving) reader.
  prefs: []
  type: TYPE_NORMAL
- en: The border material
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, we define the material for the border shader. Create a new Java class
    in `RenderBoxExt/materials/` named `BorderMaterial` and define it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Add material variables for the texture ID, border width, and color. Then, add
    variables for the shader program references and buffers, as shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can add a constructor. As we''ve seen earlier, it calls a `setupProgram`
    helper method that creates the shader program and obtains references to its parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Likewise, we add a `setBuffers` method to be called by the `RenderObject` component
    (`Plane`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Provide a setter method for the texture ID:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the draw code, which will be called from the `Camera` component, to render
    the geometry prepared in the buffers (via `setBuffer`). The draw method looks
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'One more thing; let''s provide a method to destroy an existing material:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Using the border material
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To use the `BorderMaterial` class instead of the default `UnlitTexMaterial`
    class, we wrote in the `Plane` class previously, we can add it to the `Plane`
    Java class, as follows. We plan to create the material outside the `Plane` class
    (in `MainActivity`), so we just need to set it up. In `Plane.java`, add the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'In `MainActivity`, modify the `setupScreen` method to use this material instead
    of the default one, as follows. We first create the material and set the texture
    to our sample image. We don’t need to set the color, which will default to black.
    Then we create the screen plane and set its material. And then create the transform
    and add the screen component:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'When you run it now, it should look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using the border material](img/B05144_07_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Loading and displaying a photo image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we've used images in the project's `drawable` resource folder. The next
    step is to read photo images from the phone and display one on our virtual screen.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the image class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s make a placeholder `Image` class. Later on, we''ll build the attributes
    and methods. Define it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: We define a constructor that takes the image's full path. We also provide a
    validation method that checks whether the path is actually for an image, based
    on the filename extension. We don't want to load and bind the image data on construction
    because we don't want to load all the images at once; as you'll see, we will manage
    these intelligently using a worker thread.
  prefs: []
  type: TYPE_NORMAL
- en: Reading images into the app
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now in `MainActivity`, access the photos folder on the phone and build a list
    of images in our app. The following `getImageList` helper method looks in the
    given folder path and instantiates a new `Image` object for each file found:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Use this method in the `setup` method, passing in the name of the camera images
    folder path, as follows (your path may vary):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, ensure that the following line is included in your `AndroidManifest.xml`
    file, giving the app the permission to read the device''s external storage. Technically,
    you should already have this permission when using the Cardboard SDK:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: You can add a log message to the `getImageList` loop and run it to verify that
    it is finding files. If not, you may need to discover the actual path to your
    photos folder.
  prefs: []
  type: TYPE_NORMAL
- en: This is the first project where we need to be really careful about permissions.
    Up until this point, the Cardboard SDK itself was the only thing which needed
    access to the filesystem, but now we need it for the app itself to function. If
    you are using a device with Andriod 6.0, and you don't make sure to compile the
    app against SDK 22, you will not be able to load the image files, and the app
    will either do nothing, or crash.
  prefs: []
  type: TYPE_NORMAL
- en: If you are compiling against SDK 22 and you have the permission set up correctly
    in the manifest but you still get an empty file list, try looking for the correct
    path on your device with a file browser. It could very well be that the path we
    provided doesn't exist or is empty. And, of course, make sure that you have actually
    taken a picture with that device!
  prefs: []
  type: TYPE_NORMAL
- en: Image load texture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you remember, in [Chapter 6](ch06.html "Chapter 6. Solar System"), *Solar
    System,* we wrote a `loadTexture` method that reads a static image from the project's
    `res/drawable` folder into a memory bitmap and binds it to the texture in OpenGL.
    Here, we're going to do something similar but source the images from the phone's
    camera path and provide methods for additional processing, such as resizing and
    rotating its orientation.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the top of the `Image` class, add a variable to hold the current texture
    handle:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The image''s `loadTexture` method, given a path to an image file, will load
    an image file into a bitmap and then convert it to a texture. (This method will
    be called from `MainActivity` with the app''s `CardboardView` class.) Write it
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: We added a small (but important) optimization, checking whether the texture
    has already been loaded; don't do it again if not needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our implementation of `bitmapToTexture` is shown in the following code. Given
    a bitmap, it binds the bitmap to an OpenGL ES texture (with some error checking).
    Add the following code to `Image`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Showing an image on the screen
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's show one of our camera images in the app, say, the first one.
  prefs: []
  type: TYPE_NORMAL
- en: 'To show an image on the virtual screen, we can write a `show` method that takes
    the current `CardboardView` object and the `Plane` screen. It''ll load and bind
    the image texture and pass its handle to the material. In the `Image` class, implement
    the `show` method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s use this stuff! Go to `MainActivity` and write a separate `showImage`
    method to load the image texture. And, temporarily, call it from `setup` with
    the first image that we find (you will need at least one image in your camera
    folder):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: It now also makes sense to modify `setupScreen,` so it creates the screen but
    doesn't load an image texture onto it. Remove the call to `screenMaterial.setTexture`
    in there.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now run the app, and you will see your own image on the screen. Here''s mine:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Showing an image on the screen](img/B05144_07_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Rotating to the correct orientation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some image file types keep track of their image orientation, particularly JPG
    files (`.jpg` or `.jpeg`). We can get the orientation value from the EXIF metadata
    included with the file written by the camera app. (For example, refer to [http://sylvana.net/jpegcrop/exif_orientation.html](http://sylvana.net/jpegcrop/exif_orientation.html).
    Note that some devices may not be compliant or contain different results.)
  prefs: []
  type: TYPE_NORMAL
- en: If the image is not JPG, we'll skip this step.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the top of the `Image` class, declare a variable to hold the current image
    rotation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The `rotation` value is stored as a `Quaternion` instance, as defined in our
    RenderBox math library. If you remember [Chapter 5](ch05.html "Chapter 5. RenderBox
    Engine"), *RenderBox Engine*, a quaternion represents a rotational orientation
    in three-dimensional space in a way that is more precise and less ambiguous than
    Euler angles. But Euler angles are more human-friendly, specifying an angle for
    each *x*, *y*, and *z* axes. So, we''ll set the quaternion using Euler angles
    based on the image orientation. Ultimately, we use a `Quaternion` here because
    it is the underlying type of `Transform.rotation`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we set the screen''s rotation in the `show` method of the `Image` class,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Run your project again. The image should be correctly oriented. Note that it
    is possible that your original image was fine all along. It will become easier
    to check whether your rotation code works once we get the thumbnail grid going.
  prefs: []
  type: TYPE_NORMAL
- en: '![Rotating to the correct orientation](img/B05144_07_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Dimensions to correct the width and height
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Square images are easy. But usually, photos are rectangular. We can get the
    actual width and height of the image and scale the screen accordingly, so the
    display won't show up distorted.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the top of the `Image` class, declare variables to hold the current image
    width and height:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, set them in `loadTexture` using bitmap options in the `decodeFile` method,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The `decodeFile` call returns the image's width and height (among other information)
    in the options (refer to [http://developer.android.com/reference/android/graphics/BitmapFactory.Options.html](http://developer.android.com/reference/android/graphics/BitmapFactory.Options.html)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can set the screen size in the `show` method of the `Image` class. We''ll
    normalize the scale so that the longer side is of size 1.0 and the shorter one
    is calculated as the image aspect ratio:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run it now, the screen will have the correct aspect ratio for the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Dimensions to correct the width and height](img/B05144_07_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Sample image down to size
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The camera in your phone is probably awesome! It's probably really mega awesome!
    Many-megapixel images are important when printing or doing lots of cropping. But
    for viewing in our app, we don't need the full resolution image. In fact, you
    might already be having trouble running this project if the image size generates
    a texture that's too big for your device's hardware.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can accommodate this issue by constraining the maximum size and scaling
    our bitmaps to fit within these constraints when loading the texture. We will
    ask OpenGL ES to give us its current maximum texture size. We''ll do this in `MainActivity,`
    so it''s generally available (and/or move this into the `RenderBox` class in your
    `RenderBox` library project). Add the following to `MainActivity`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: We call it as the first line of the `setup` method of the `MainActivity` class.
  prefs: []
  type: TYPE_NORMAL
- en: As for scaling the image, unfortunately, Android's `BitmapFactory` does not
    let you directly request a new size of a sampled image. Instead, given an arbitrary
    image, you can specify the sampling rate, such as every other pixel (2), every
    fourth pixel (4), and so on. It must be a power of two.
  prefs: []
  type: TYPE_NORMAL
- en: 'Back to the `Image` class. First, we will add a `sampleSize` argument to `loadTexture`,
    which can be used as an argument to `decodeFile`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: To determine an appropriate sample size for images, we need to first find out
    its full dimensions and then figure out what sample size will get it closest but
    less than the maximum texture size we're going to use. The math isn't too difficult,
    but instead of going through that, we'll use a procedural method to search for
    the best size value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortunately, one of the input options of `decodeFile` is to only retrieve the
    image bounds, and not actually load the image. Write a new load texture method
    named `loadFullTexture`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: We keep bumping up the sample size until we find one that produces a bitmap
    within the `MAX_TEXTURE_SIZE` bounds, and then call `loadTexture`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use `loadFullTexture` in the `show` method instead of the other `loadTexture`
    one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Run the project. It should look the same as the earlier one. But if your camera
    is too good, maybe it's not crashing like it was before.
  prefs: []
  type: TYPE_NORMAL
- en: This sampling will also be useful to display thumbnail versions of the images
    in the user interface. There's no point in loading the full-sized bitmap for a
    thumbnail view.
  prefs: []
  type: TYPE_NORMAL
- en: Loading and displaying a photosphere image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we've been handling all the images in the same manner. But some of them
    may be 360-degree images. These should be displayed on the photosphere and not
    on the virtual screen.
  prefs: []
  type: TYPE_NORMAL
- en: If you do not have any 360-degree photos in your device's camera folder yet,
    you can create them using the Google Camera app.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If the default camera app on your phone does not include a **Photosphere** mode,
    you may need to download the Google Camera app from the Play Store. Third-party
    cameras might use a different name. For example, Samsung calls their photosphere
    feature **Surround Shot**.
  prefs: []
  type: TYPE_NORMAL
- en: Some images include the XMP metadata that will include information of whether
    the image is distorted for an equirectangular projection. This can be useful to
    distinguish spherical images from flat ones. However, the Android API doesn't
    include an XMP interface, so integrating XMP header parsing is beyond the scope
    of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, we''ll just check whether the filename is prefixed with `PANO_`. Add
    the following variable to the `Image` class and set it in the constructor method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: We can now build the `MainActivity` show method to handle regular photos (displayed
    on the virtual screen) versus photospheres (displayed on the background sphere).
    Furthermore, it should handle switching between a flat image displayed on the
    virtual screen and rendering the photosphere and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: 'We want to remember the texture handle ID of the background photosphere texture.
    Add a `bgTextureHandle` handle at the top of the `MainActivity` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, set it in `setupBackground` by calling `getTexture`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can update the `showImage` method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: When the image is a photosphere, we set the background photosphere texture to
    the image and hide the screen plane. When the image is a regular photo, we set
    the background texture back to the default one and show the image on the virtual
    screen.
  prefs: []
  type: TYPE_NORMAL
- en: 'Until we implement the user interface (next) to test this, you will need to
    know which image in the images list is a photosphere. If you make a new photosphere
    now, it''ll be the last one in the list, and you can change the `setup` method
    to call `showImage` on it. For example, run the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Run the project again and be happy!
  prefs: []
  type: TYPE_NORMAL
- en: The image gallery user interface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we go ahead and implement a user interface for this project, let's talk
    about how we want it to work.
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of this project is to allow the user to select a photo from their
    phone's storage and view it in VR. The phone's photo collection will be presented
    in a scrollable grid of thumbnail images. If a photo is a normal 2D one, it'll
    be displayed on the virtual screen plane we just made. If it's a photosphere,
    we'll view it as a fully immersive 360-degree spherical projection.
  prefs: []
  type: TYPE_NORMAL
- en: A sketch of our proposed scene layout is shown in the following diagram. The
    user camera is centered at the origin, and the photosphere is represented by the
    gray circle, which surrounds the user. In front of the user (determined by the
    calibration at launch), there will be a 5 x 3 grid of thumbnail images from the
    phone's photo gallery. This will be a scrollable list. To the left of the user,
    there is the image projection screen.
  prefs: []
  type: TYPE_NORMAL
- en: '![The image gallery user interface](img/B05144_07_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Specifically, the UI will implement the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: Displays up to 15 thumbnail images in a 5 x 3 grid.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Allows the user to select one of the thumbnail images by looking at it and then
    clicking on the Cardboard trigger. Thumbnails will be highlighted when in the
    sightline.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selecting a regular photo will display it on the virtual projection screen in
    the scene (and clear the photosphere to the background image).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selecting a photosphere will hide the virtual projection screen and load the
    image into the photosphere projection.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Allows the user to scroll through thumbnail images by selecting the up/down
    arrows.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some of our UI considerations are unique to virtual reality. Most importantly,
    all of the user interface elements and controls are in world coordinate space,
    That is, they're integrated into the scene as geometric objects with a position,
    rotation, and scale like any other component. This is in contrast with most mobile
    games where the UI is implemented as a screen space overlay.
  prefs: []
  type: TYPE_NORMAL
- en: Why? Because in VR, in order to create the stereoscopic effect, each eye has
    a separate viewpoint, offset by the interpupillary distance. This can be simulated
    in screen space by horizontally offsetting the position of screen space objects,
    so they appear to have a parallax (a technique we used in [Chapter 4](ch04.html
    "Chapter 4. Launcher Lobby"), *Launcher Lobby*). But when mixed with 3D geometry,
    camera, lighting, and rendering, that technique proves inadequate. A world space
    UI is required for an effective user experience and immersion.
  prefs: []
  type: TYPE_NORMAL
- en: Another feature that's unique to VR is gaze-based selection. In this case, where
    you look will highlight an image thumbnail, and then you click on the Cardboard
    trigger to open the image.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, as mentioned earlier, since we're working in world space and making
    selections based on where we're looking, the layout of our 3D space is an important
    consideration. Remember that we're in VR and not constrained by rectangular edges
    of a phone screen. Objects in the scene can be placed all around you. On the other
    hand, you don't want users twisting and turning all the time (unless that's an
    intended part of the experience). We'll pay attention to comfort zones to place
    our UI controls and image screen.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, Google and researchers elsewhere have begun to develop best practices
    for the user interface design, including the optimal distance for menus and UI
    controls from the camera, approximately 5 to 15 feet (1.5 to 5 meters). This distance
    is close enough to enjoy a 3D parallax effect but not so close to make you look
    cross-eyed to focus on the objects.
  prefs: []
  type: TYPE_NORMAL
- en: Okay, let's begin with the UI implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Positioning the photo screen on the left
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Firstly, let''s move the screen from in front to the side, that is, rotate
    it 90 degrees to the left. Our transform math does the position after the rotation,
    so we now offset it along the *x* axis. Modify the `setupScreen` method of the
    `MainActivity` class, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Displaying thumbnails in a grid
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A thumbnail is a mini version of the full image. Therefore, we don't need to
    load a full-sized texture bitmap. For the sake of simplicity, let's just always
    sample it down by 4 (to 1/16th the original size).
  prefs: []
  type: TYPE_NORMAL
- en: The thumbnail image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the `Image` class, the `show` method loads the full texture. Let''s write
    a similar `showThumbnail` method that uses a smaller sampling. In the `Image`
    class, add the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: The Thumbnail class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Create a new `Thumbnail` class for the project that will contain a small `Plane`
    object and an `Image` object to show on it. It also gets the current `cardboardView`
    instance, which `Image` will require:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a `setImage` method that loads the image texture and shows it as a thumbnail:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, make a quick toggle for the thumbnail visibility:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: The thumbnail grid
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The plan is to display the phone photos in a 5 x 3 grid of thumbnail images.
    At the top of the `MainActivity` class, declare a `thumbnails` variable to hold
    the list of thumbnails:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Build the list in a new method named `setupThumbnailGrid`. The first thumbnail
    is positioned in the upper-left corner of the page (-4, 3, -5) and each thumb
    spaced 2.1 units in *x* and 3 units in *y*, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we need to add image textures to the planes. We''ll write another method,
    `updateThumbnails`, as follows. It will show the first 15 images in the grid (or
    less if you don''t have that many):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Add these new methods to `setup`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'When you run the project, it should look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The thumbnail grid](img/B05144_07_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note that the thumbnails' sizes are adjusted to match the image aspect ratio,
    and are properly oriented, because we implemented those features in the `Image`
    class earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you don''t have more than 15 photos already in your phone, add a loop to
    `loadImageList` to load duplicates. For example, run the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Gaze to load
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We want to detect when the user looks at a thumbnail and highlight the image
    by changing its border color. If users move their gaze away from the thumbnail,
    it will unhighlight. When the user clicks on the Cardboard trigger, that image
    is loaded.
  prefs: []
  type: TYPE_NORMAL
- en: Gaze-based highlights
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Fortunately, we implemented the `isLooking` detection in the `RenderBox` library
    at the end of [Chapter 5](ch05.html "Chapter 5. RenderBox Engine"), *RenderBox
    Engine*. If you remember, the technique determines whether the user is looking
    at the plane by checking whether the vector between the camera and the plane position
    is the same as the camera's view direction, within a threshold of tolerance.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use this in `MainActivity`. We''ll write a `selectObject` helper method
    that checks whether any of the objects in the scene are selected and highlights
    them. First, let''s declare some variables at the top of the `MainActivity` class.
    The `selectedThumbnail` object holds the currently selected thumbnail index. We
    define border colors for normal and selected states:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Now the `selectObject` method goes through each thumbnail, checks whether it''s
    `isLooking`, and highlights (or unhighlights) it accordingly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '`RenderBox` provides hooks, including `postDraw` where we''ll check for selected
    objects. We want to use `postDraw` because we need to wait until `draw` is called
    on all of `RenderObjects` before we know which one the user is looking at. In
    `MainActivity`, add a call to the `selectObject` method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Run the project. As you gaze at a thumbnail image, it should get highlighted!
  prefs: []
  type: TYPE_NORMAL
- en: Selecting and showing photos
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Well, now that we can pick an image from the thumbnail grid, we need a way to
    click on it and show that image. That'll happen in `MainActivity` using the Cardboard
    SDK hook, `onCardboardTrigger`.
  prefs: []
  type: TYPE_NORMAL
- en: 'With all the work we''ve done so far, it''s not going to take much more to
    implement this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Try and run it. Now highlight an image and pull the trigger. If you're lucky,
    it'll work…mine crashes.
  prefs: []
  type: TYPE_NORMAL
- en: Queue events
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What's going on? We're running into thread-safe issues. So far, we've been executing
    all of our code from the render thread, which is started by the `GLSurfaceView`/`CardboardView`
    class via the Cardboard SDK. This thread owns the access to the GPU and to the
    particular surface we're rendering on. The call to `onCardboardTrigger` originates
    from a thread that is not the render thread. This means that we can't make any
    OpenGL calls from here. Luckily, `GLSurfaceView` provides a nifty way to execute
    arbitrary code on the render thread through a method called `queueEvent`. The
    `queueEvent` method takes a single `Runnable` argument, which is a Java class
    meant to create one-off procedures such as these (refer to [http://developer.android.com/reference/android/opengl/GLSurfaceView.html#queueEvent(java.lang.Runnable](http://developer.android.com/reference/android/opengl/GLSurfaceView.html#queueEvent(java.lang.Runnable)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Modify `showImage` to wrap it inside a `Runnable` argument, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Note that any data passed to the anonymous class, such as our image, must be
    declared `final` to be accessible from the new procedure.
  prefs: []
  type: TYPE_NORMAL
- en: Try to run the project again. It should work. You can gaze at a thumbnail, click
    on the trigger, and that image will be shown, either on the virtual screen or
    in the background photosphere.
  prefs: []
  type: TYPE_NORMAL
- en: Using a vibrator
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: No worries, we're keeping it clean. We want to provide some haptic feedback
    to the user when an image has been selected, using the phone's vibrator. And fortunately,
    in Android, that's straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, make sure that your `AndroidManifest.xml` file includes the following
    line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'At the top of the `MainActivity` class, declare a `vibrator` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, in `onCreate`, add the following code to initialize it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, use it in `onCardboardTrigger`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: Run it again. Click on it and you'll feel it. *Ahhh!* But don't get carried
    away, it's not that kind of vibrator.
  prefs: []
  type: TYPE_NORMAL
- en: Enable scrolling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our thumbnail grid has 15 images. If your phone has more than 15 photos, you'll
    need to scroll through the list. For this project, we'll implement a simple mechanic
    to scroll the list up and down, using triangular scroll buttons.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the Triangle component
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Like other `RenderObjects` in our `RenderBox`, the `Triangle` component defines
    coordinates, normals, indices, and other data that describes a triangle. We create
    a constructor method that allocates buffers. Like the `Plane` component, we want
    to use the `BorderMaterial` class so that it can be highlighted when selected.
    And like the `Plane` component, it will determine when the user is looking at
    it. Without further ado, here's the code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Java class file, `Triangle.java`, in the `RenderBoxExt/components`
    folder. We begin by declaring it `extends RenderObject` and by declaring the following
    variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: In case it's not clear as to why we need this 2-triangle triangle, it has to
    do with how the UVs work. You can't get a full border with just one triangle,
    at least not the way we've written the border shader.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a constructor, along with an `allocateBuffers` helper:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'We can create various materials, but we really only plan to use `BorderMaterial`,
    so let''s support this like we did with `Plane`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: Adding triangles to the UI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In `MainActivity`, we can add the `up` and `down` triangle buttons to scroll
    the thumbnails. At the top of the `MainActivity` class, declare variables for
    the triangles and their materials:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a `setupScrollButtons` helper as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, call it from the `setup` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'When you run the project, you will see the arrows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Adding triangles to the UI](img/B05144_07_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Interacting with the scroll buttons
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now we will detect when the user is looking at a triangle, by using `isLooking`
    in `selectObject` (which is called from the `postDraw` hook):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: Implementing the scrolling method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To implement scrolling the thumbnail images, we''ll keep the grid planes in
    place and just scroll the textures. Use an offset variable to hold the index of
    the first image in the grid:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, modify the `updateThumbnails` method to populate the plane textures using
    the thumb offset as the starting index of the image textures:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'We can perform scrolling when the up or down arrows are pressed in `onCardboardTrigger`
    by shifting the `thumbOffset` variable one row at a time (`GRID_X`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'As with `showImage`, the `updateThumbnails` method needs to run on the render
    thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: Run the project. You can now click on the up and down arrows to scroll through
    your photos.
  prefs: []
  type: TYPE_NORMAL
- en: Stay responsive and use threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a few problems with our loading and scrolling code, all related to
    the fact that loading images and converting bitmaps is compute-intensive. Attempting
    to do this for 15 images all at once causes the app to appear frozen. You may
    have also noticed that the app takes significantly longer to start up since we
    added the thumbnail grid.
  prefs: []
  type: TYPE_NORMAL
- en: In conventional apps, it might be annoying but somewhat acceptable for the app
    to lock up while waiting for data to load. But in VR, the app needs to stay alive.
    The app needs to continue responding to the head movement and update the display
    for each frame with a view corresponding to the current view direction. If the
    app is locked while loading files, it will feel stuck, that is, stuck to your
    face! In a fully immersive experience, and on a desktop HMD that is strapped on,
    visual lockup is the most severe cause of nausea, or *sim sickness*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution is a worker thread. The key to successful multithreaded support
    is providing the ability for the procedures to signal each other with semaphores
    (Boolean flags). We''ll use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Image.loadLock`: This is true when waiting for the GPU to generate a texture'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MainActivity.cancelUpdate`: This is true when the thread should stop due to
    a user event'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MainActivity gridUpdateLock`: This is true when the grid is updating; ignore
    other user events'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s declare these. At the top of the `Image` class, add the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'At the top of the `MainActivity` class, add the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: First, let's identify the compute-intensive part of our code. Feel free to do
    your own investigation, but let's assume that `BitmapFactory.decodeFile` is the
    culprit. Ideally, any code that wasn't directly related to rendering should be
    done on a worker thread, but beware of pre-optimization. We're doing this work
    because we've noticed an issue, so we should be able to identify the new code
    which is causing it. An educated guess points to this business of loading arbitrary
    images into textures.
  prefs: []
  type: TYPE_NORMAL
- en: Where do we do this operation? Well, the actual call to `BitmapFactory.decodeFile`
    comes from `Image.loadTexture`, but more generally, all of this is kicked off
    in `MainActivity.updateGridTextures` and `MainActivity.showImage`. Let's update
    these last two functions now.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lucky for us, `showImage` has already been wrapped in `Runnable` for the purpose
    of redirecting its execution to the render thread. Now we want to actually ensure
    that it always happens off the render thread. We''ll be using `queueEvent` in
    a different place to avoid the error that we encountered earlier. We replace the
    previous `Runnable` code with `Thread`. For example, `showImage` now looks like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Do the same to `updateThumbnails`. While we''re here, add the `gridUpdateLock`
    flag that remains set while it''s running, and handle the `cancelUpdate` flag,
    so the loops can be interrupted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'Focusing on the `Image` class''s `loadTexture` method, we need to redirect
    the GPU calls back to the render thread with `queueEvent`. If you try to run the
    app now, it will crash right out of the gate. This is because `showImage` is now
    always run in its own thread, and when we eventually make the OpenGL calls to
    generate the texture, we''ll get the invalid operation error that we got earlier
    when we added the trigger input. To fix this, modify `loadTexture` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: We changed it so that `bitmapToTexture` is now called on the GPU thread. We
    use the `loadLock` flag to indicate that the loading is busy. When it's done,
    the flag is reset. Meanwhile, `loadTexture` waits for it to finish before returning
    because we need this `textureHandle` value for later. But since we're always calling
    this from a worker thread, the app isn't hung waiting. This change will also improve
    the start-up time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, we do the same thing in the `Thumbnail` class; its `setImage` method
    also loads the image texture. Modify it so that it looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'You might have noticed a subtler issue in all of this. If we try to close the
    app in the middle of one of these worker thread operations, it will crash. The
    underlying issue is that the thread persists, but the graphics context has been
    destroyed, even if you are just switching apps. Trying to generate textures with
    an invalid graphics context results in a crash, and the user gets little notification.
    Bad news. What we want to do is stop the worker thread when the app closes. This
    is where `cancelUpdate` comes into play. In `MainActivity`, we''ll set its value
    in the `onCreate` method, and add the methods to the `onStart`, `onResume`, and
    `onPause` hook methods, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'If you try to click on something while the grid is updating, it shouldn''t
    let you to do so. Add the following code to the top of `onCardboardTrigger`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: This new `long[]{0,50,30,50}` business is a way of programming a sequence into
    the vibrator. In this case, two short (50 milliseconds) pulses in a row are used
    to indicate the nuh-uh reaction.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can even go one beautiful step further and highlight selectable objects
    in `selectObject` with a disabled color during `gridUpdateLock` like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: Your project should run as before. But now it's more responsive, better behaved,
    and doesn't get stuck waiting for images to load.
  prefs: []
  type: TYPE_NORMAL
- en: An explanation of threading and virtual reality
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenGL is not thread-safe. This sounds like a design flaw. In reality, it's
    more like a design requirement. You want your graphics API to draw frames as quickly
    and frequently as possible. As you may know, or will soon learn, waiting is something
    that threads end up doing a lot of the time. If you introduce multithreaded access
    to your graphics hardware, you introduce periods where the hardware might be waiting
    on the CPU simply to figure out its thread scheduling and who needs access at
    the time. It's much simpler and faster to say "only one thread may access the
    GPU." Technically speaking, as graphics APIs become more advanced (DirectX 12
    and Vulkan), this is not strictly true, but we will not be getting into multithreaded
    rendering in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Let's first take a step back and ask the question, "Why do we need to use threads?"
    To some of you who are more experienced application developers, the answer should
    be obvious. But not all programmers need to use threads, and, even worse, many
    programmers use threads inappropriately, or when they aren't needed in the first
    place. For those of you still in the dark, a thread is a fancy term for "a way
    to run two procedures at the same time." On a practical level, the operating system
    takes control of scheduling threads to run one after another, or on different
    CPU cores, but as programmers, we assume that all threads are running "simultaneously."
  prefs: []
  type: TYPE_NORMAL
- en: Incidentally, while we are only allowed one CPU thread to control the GPU, the
    whole point of a GPU is that it is massively multithreaded. Mobile GPUs are still
    getting there, but high-end Tegra chips have hundreds of cores (currently, the
    X1 is at 256 cores), lagging behind their desktop equivalents with thousands of
    cores (Titan Black @ 2880 cores). A GPU is set up to process each pixel (or other
    similar small datum) on a separate thread, and there is some hardware magic going
    on that schedules all of them automatically with zero overhead. Think of your
    render thread as a slow taskmaster instructing a tiny army of CPUs to do your
    bidding and report back with the results, or in most cases, just draw them right
    to the screen. This means that the CPU is already doing a fair amount of waiting
    on behalf of the GPU, freeing your other worker threads to do their tasks and
    then wait when there is more CPU render work to be done.
  prefs: []
  type: TYPE_NORMAL
- en: Threads are generally useful when you want to run a process which will take
    a while, and you want to avoid blocking the program's execution, or main, thread.
    The most common place where this comes up is starting a background process and
    allowing the UI to continue to update. If you're creating a media encoder program,
    you don't want it to be unresponsive for 30 minutes while it decodes a video.
    Instead, you'd like the program to run as normal, allowing the user to click on
    buttons and see progress updates from the background work. In this scenario, you
    have to let the UI and background threads take a break now and then to send and
    check messages passed between the two. Adjusting the length of the break, or sleep
    time, and thread priority values allows you to avoid one thread hogging too much
    CPU time.
  prefs: []
  type: TYPE_NORMAL
- en: Back to OpenGL and graphics programming. It is common in a game engine to split
    the work into a few, distinct threads (render, physics, audio, input, and so on).
    However, the render thread is always a kind of *orchestrator* because rendering
    still tends to be the most time-sensitive job and must happen at least 30 times
    per second. In VR, this constraint is even more important. We're not worried about
    physics and audio, perhaps, but we still need to make sure that our renderer can
    draw things as quickly as possible, or the feeling of presence is lost. Furthermore,
    we can never stop rendering, as long as the person is looking at the screen. We
    need threads to avoid "hiccups" or unacceptably long periods between render frames.
  prefs: []
  type: TYPE_NORMAL
- en: Head tracking is essential to a VR experience. A person who is moving their
    head, looking only at a fixed image, will start to experience nausea, or *simsickness*.
    Even some text on a black background, if it is not compensated by some sort of
    fixed horizon, will eventually cause discomfort. Sometimes, we do have to block
    the render thread for significant periods of time, and the best option is to first
    fade the image to a solid color, or void. This can be comfortable for a short
    period of time. The worst thing that can happen in VR is periodic hiccups or frame
    rate drops due to extensive work being done on the render thread. If you don't
    maintain a constant, smooth, frame rate, your VR experience is worthless.
  prefs: []
  type: TYPE_NORMAL
- en: In our case, we need to decode a series of rather large bitmaps and load them
    into GPU textures. Unfortunately, the decode step takes a few hundred milliseconds
    and causes those hiccups we were just talking about. However, since this isn't
    GPU work, it doesn't have to happen on the render thread! If we want to avoid
    any heavy lifting in our `setup()`, `preDraw()`, and `postDraw()` functions, we
    should create a thread any time that we want to decode a bitmap. In the case of
    updating our grid of previews, we should probably just create a single thread,
    which can run the whole update process, waiting in between each bitmap. In the
    CPU land, the OS needs to use some resources to schedule threads and allocate
    their resources. It's much more efficient to just create a single thread to run
    through the entire job, rather than spinning up and taking down a thread for each
    bitmap.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, we're going to need to make use of our old friend `queueEvent` in
    order to do any graphics work, in this case generating and loading the texture.
    As it turns out, updating the display of the image is not graphics work, since
    it just involves changing a value on our material. We do, however, need to wait
    on the graphics work in order to get this new value. As a result of these optimizations
    and constraints, we need a locking system in order to allow one thread to wait
    on the others to finish its work, and to prevent the user from interrupting or
    restarting this procedure before it has completed. This is what we just implemented
    in the previous topic.
  prefs: []
  type: TYPE_NORMAL
- en: Launch with an intent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Wouldn't it be cool if you could launch this app any time you go to view an
    image on your phone, especially 360-degree photospheres?
  prefs: []
  type: TYPE_NORMAL
- en: One of the more powerful features of the Android operating system is the ability
    to communicate between apps with intents. An **intent** is a message that any
    app can send to the Android system, which declares its intent to use another app
    for a certain purpose. The intent object contains a number of members to describe
    what type of action needs to be done, and, if any, the data on which it needs
    to be done. As a user, you may be familiar with the default action picker, which
    displays a number of app icons, and the choices, **Just Once**, or **Always**.
    What you're seeing is the result of the app you were just using broadcasting a
    new intent to the system. When you choose an app, and Android launches a new activity
    from that app, which has been registered to respond to intents of that type.
  prefs: []
  type: TYPE_NORMAL
- en: 'In your `AndroidManifest.xml` file, add an intent filter to the activity block.
    Let Android know that the app can be used as an image viewer. Add the following
    XML code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'We just need to handle the situation so an intent image is the default image
    loaded when the app starts. In `MainActivity`, we''ll write a new function that
    shows an image given its URI, as follows. The method gets the URI path and translates
    it into a file pathname, calls the new `Image` object on that path, and then the
    `showImage` method. (For reference, visit [http://developer.android.com/guide/topics/providers/content-provider-basics.html](http://developer.android.com/guide/topics/providers/content-provider-basics.html)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, add a call to `showUriImage` from `setup`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: We've also added a call to `BorderMaterial.destroy()` since the intent launches
    a second instance of the activity. If we don't destroy the materials, the new
    activity instance, which has its own graphics context, will throw errors when
    it tries to use shaders compiled on the first activity's graphics context.
  prefs: []
  type: TYPE_NORMAL
- en: Now with the project built and installed on the phone, when you choose an image
    file, for example, from a file folder browser app such as **My Files** (Samsung),
    you're given a choice of apps with an intent to view images. Your Gallery360 app
    (or whatever you have actually named it) will be one of the choices, as shown
    in the following screenshot. Pick it and it will launch with that image file view
    as the default.
  prefs: []
  type: TYPE_NORMAL
- en: '![Launch with an intent](img/B05144_07_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Showing/hiding the grid with tilt-up gestures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Back in the early days of Cardboard, you had one button. That was all. The one
    button and head tracking were the only ways for the user to interact with the
    app. And because the button was a nifty magnet thing, you couldn't even press
    and hold the one button. With Cardboard 2.0, the screen turned into the button,
    and we also realized that we could briefly take the box off of our face, tilt
    the phone up, put it back on, and interpret that as a gesture. Thus, a second
    input was born! At the time of writing, the sample Cardboard apps use this as
    a back gesture.
  prefs: []
  type: TYPE_NORMAL
- en: We will be using tilt-up to show and hide the grid and arrows so that you can
    fully immerse yourself in the selected photosphere. Since it's less work, we'll
    also let the user do this anytime, and not just while looking at photospheres.
    As with the vibration feedback, this is actually a pretty painless feature to
    add. Most of the hard work is done by an `OrientationEventListener` class.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the top of the `MainActivity` class, add a variable for the state of the
    grid, the orientation event listener, and ones for a tilt detection timer, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we can write a method that toggles the thumbnail grid menu on/off. Check
    whether there are less images than planes since empty ones are already disabled
    in `updateThumbnails`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, write a `setupOrientationListener` helper method, which provides a callback
    function when the device orientation changes. If the orientation gets close to
    vertical after being in landscape mode, we can call our toggle function, and once
    the device returns to landscape and goes vertical again, we toggle again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, add it to `onCreate`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'The `setupComplete` flag prevents the grid from being toggled while it is still
    being created. Let''s reset the complete flag after `updateThumbnails`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s prudent to destroy it in `onDestroy`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: The `onOrientationChanged` callback will fire whenever the phone changes orientation.
    We'll only be interested in the times when it changes from landscape to portrait,
    and we also want to make sure that it doesn't happen too often, hence the **tilt
    damper** feature. You might want to tweak the value (currently 250 milliseconds)
    to your liking. Too short, and you might falsely register two changes in a row.
    Too long, and the user might try to tiltup twice within the cutoff time.
  prefs: []
  type: TYPE_NORMAL
- en: Spherical thumbnails
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Spherical 360-degree images deserve better than a plain ol' paint-chip thumbnail
    images, don't you think? I suggest that we display them as small balls. Maybe
    we should call them thumb-tips or thumb-marbles. Anyway, let's do a little hacking
    to make this happen.
  prefs: []
  type: TYPE_NORMAL
- en: Add a sphere to the Thumbnail class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the `Thumbnail` class, add a `sphere` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'Modify `setImage` to recognize a photosphere image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'We must also change `setVisible` to handle both the `plane` and `sphere` variables,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, in the `MainActivity` class''s `setupThumbnailGrid`, initialize a `Sphere`
    object in addition to a `Plane` object (inside the `GRID_Y` and `GRID_X` loops):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: Now the thumbnails have both a plane and a sphere that we can populate depending
    on the image type.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we just need to modify the `selectObject` method to see how we highlight
    a sphere thumbnail. We highlight the rectangular ones by changing the border color.
    Our spheres don't have a border; in lieu of that we'll change their size.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the top of `MainActivity`, add variables to the normal and selected scales:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, change `selectObject` to behave differently when the image is a photosphere:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: Whoo hoo! We even have the sphere spinning, so you can see its 360-ness in all
    its glory! This is so much fun, it should be illegal.
  prefs: []
  type: TYPE_NORMAL
- en: '![Add a sphere to the Thumbnail class](img/B05144_07_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: There you have it! A beautiful photo viewer app that supports both regular camera
    images as well as 360-degree photospheres.
  prefs: []
  type: TYPE_NORMAL
- en: Updating the RenderBox library
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the Gallery360 project implemented and our code stabilized, you might realize
    that we've built some code that is not necessarily specific to this application
    that can be reused in other projects, and ought to make its way back to the `RenderBox`
    library.
  prefs: []
  type: TYPE_NORMAL
- en: 'We did this at the end of the previous project in [Chapter 6](ch06.html "Chapter 6. Solar
    System"), *Solar System*. You can refer to that topic for details. Follow these
    steps to update the `RenderBoxLib` project:'
  prefs: []
  type: TYPE_NORMAL
- en: Move the `Plane` and `Triangle` components from `RenderBoxExt/components`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Move the `BorderMaterial` component from `RenderBoxExt/materials`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Move the border shader files from `res/raw`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Refactor any invalid references to correct the package names.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rebuild the library by clicking **Build** | **Make Project**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further possible enhancements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Whew, that was a lot of work! This thing is certainly done, isn''t it? *Never!*
    Here are a few improvements just begging to be implemented:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Better detection of phone images:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Not everyone keeps all of their images in a specific path. In fact, some camera
    software uses completely different paths! Introduce a proper file browser.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Better detection of photosphere images:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There is a `Projection Type` attribute in the XMP header, another piece of
    metadata in some JPG files. Unfortunately, the Android API doesn''t have a specific
    class to read this data, and integrating a third-party library is beyond the scope
    of this project. Feel free to try the following links:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://github.com/dragon66/pixymeta-android](https://github.com/dragon66/pixymeta-android)'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/drewnoakes/metadata-extractor](https://github.com/drewnoakes/metadata-extractor)'
  prefs: []
  type: TYPE_NORMAL
- en: Don't use the pano technique because it picks up regular panoramas. Allow users
    to flag or fix photosphere or rotation metadata on images that are displayed incorrectly.
  prefs: []
  type: TYPE_NORMAL
- en: Animate UI actions—scale/translate on select, smooth grid scrolling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A nifty technique to keep grid tiles from showing up behind the up/down arrows
    is known as **depth masking**. You can also just introduce a maximum and minimum
    Y value in the world space beyond which tiles would not be able to draw. But depth
    masks are cooler.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Respond to the `GALLERY` intent to override the grid with a selection of images
    from another app.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accept image URLs from the web in `VIEW` intents.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You need to first download the image, and then load it from the download path.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I hope you're as excited as I am with what we accomplished here! We built a
    truly practical Cardboard VR app to view a gallery of regular photos and 360-degree
    photospheres. The project uses the `RenderBox` library, as discussed in [Chapter
    5](ch05.html "Chapter 5. RenderBox Engine"), *RenderBox Engine*.
  prefs: []
  type: TYPE_NORMAL
- en: To begin with, we illustrated how photospheres work and viewed one on Cardboard
    using the `RenderBox` library without any custom changes. Then, to view a regular
    photo, we created a `Plane` component to be used as a virtual projection screen.
    We wrote new materials and shaders to render images with a frame border.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we defined a new `Image` class and loaded images from the phone's camera
    folder into a list, and wrote a method to show the image on the screen `Plane`,
    correcting its orientation and aspect ratio. Then, we built a user interface that
    shows a grid of thumbnail images and lets you select one by gazing at it and clicking
    on the Cardboard trigger to display the image. The grid is scrollable, which required
    us to add threading, so the app would not appear to lock up when files are loading.
    Lastly, we added a couple of bells and whistles to launch the app with the image
    view intent, toggle the menu grid by tilting the phone vertically, and spherical
    thumbanils for photospheres.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll build another kind of viewer; this time to view full
    3D models in OBJ files.
  prefs: []
  type: TYPE_NORMAL
