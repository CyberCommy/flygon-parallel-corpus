- en: Breath Life in Your World
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the last chapter, with materials, we made objects look more real. We know
    that is not totally necessary for VR to work as we discussed in [Chapter 1](8459021f-a32d-42ac-9372-21576359d65e.xhtml),
    *What is Virtual Reality, Really*, but it certainly helps. Now, we will learn
    how to really make things seem real by making them move. This does two things:
    things that move look more alive, and it also helps parallax depth perception.'
  prefs: []
  type: TYPE_NORMAL
- en: React VR has a number of APIs that will make it very easy to include animations
    that are fluid and natural. In most traditional CGI, making animation fluid is
    not so easy; you've got to start a motion out slow, ramp up to speed, and slow
    it down gently as well, otherwise the movement looks fake.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover these topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The `Animated` API that is used to animate objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A one-shot animation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous animation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Life cycle events such as `componentDidMount()`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to inject sound into the world
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Movement and sound go a long way in making a world look alive. Let's do that!
  prefs: []
  type: TYPE_NORMAL
- en: The Animated API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: React and React VR make this easy as the animation API has a number of animation
    types that make this straightforward, without having to do math or have key frames,
    as you would with traditional animation. Instead of keyframing, you can ramp up things
    slowly, bounce, and pause declaratively. These props are spring, decay, and timing;
    more detail on these is in the online documentation at [http://bit.ly/ReactAnims](http://bit.ly/ReactAnims).
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s fine to animate, but we need to know where we are going. To do this,
    the Animation API has two value types: value for scalar (single values), and ValueXY
    for vectors. You might wonder why in this case a vector is only *X* and *Y—*ValueXY
    is intended for UI elements, that by their nature, are flat. If you need to animate
    an X, Y, and Z location, you would use three scalars.'
  prefs: []
  type: TYPE_NORMAL
- en: First, we'll create an animated teapot that spins. This will be especially helpful
    to see how our texture mapping works. If you've been following along the code,
    your `SpaceGallery` app should already have most of what we need to start writing
    this chapter. If not, you can download the source files to start with at: [http://bit.ly/VR_Chap7](http://bit.ly/VR_Chap7).
    If you really don't want to type all of this, I put the final files at: [http://bit.ly/VR_Chap8](http://bit.ly/VR_Chap8).
  prefs: []
  type: TYPE_NORMAL
- en: Assuming you either downloaded or finished the last chapter, take the `index.vr.js`,
    from [Chapter 7](55c8c8f8-c349-43ad-b690-2d6de861b8b9.xhtml), *Sitting Down with
    a (Virtual) Teapot,*  start and enter the following new class, `TurningPot()` at
    the top of the file but under the `import` statements (note that we are still
    in the `SpaceGallery` app).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This sets up our animated value/variable—`yRotation`. We've created it as a
    scalar, which is OK, as we'll be mapping that to `rotateY`.
  prefs: []
  type: TYPE_NORMAL
- en: Don't forget to `import` the animated keyword.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we'll use a life cycle override called `componentDidMount`. Life cycle
    overrides are events that are called at specific times during the loading and
    creation (rendering) of the VR world; in this case, the `componentDidMount` function
    is called after mounting (as per the "Did" fragment in the name of the event).
    Mounting means that the object is loaded, available, and created inside three.js;
    in other words, it's in the world. The function `componentWillMount` is called when
     that component is about to be mounted but doesn't exist yet; we don't use this
    one as we want the object to move when it's actually a visible object, although
    it's really useful for loading objects, initializing state, and the like.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that we haven''t finished the declaration yet, so the final closing `{`
    brace isn''t there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `componentDidMount()` is an important object life cycle API call that is
    used to do things like what we're doing; starting the animation.
  prefs: []
  type: TYPE_NORMAL
- en: This event will most likely happen before the browser finishes loading everything,
    so you may miss the actual start. If this is a concern, you can overload some
    other methods to ensure that it fires at the right time, or introduces a small
    delay.
  prefs: []
  type: TYPE_NORMAL
- en: Flying teapots
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now for the important thing, the rendering itself. Write the following method
    using the `Animated.View` keyword:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now, save this file. If you used `?hotreload` in the URL [http://localhost:8081/vr/?hotreload](http://localhost:8081/vr/?hotreload) 
    when bringing up your world, and typed everything correctly, you'll see the teapot
    spinning in front of you automatically. Otherwise, hit the 'refresh' button in
    your browser.
  prefs: []
  type: TYPE_NORMAL
- en: Wait, what? What just happened? Why is the pot flying!
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/3d7472ee-4acd-416d-a9f8-be46ea8c09c7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The teapot revolved around *us*, the center of the `<view>`, not about its
    own axis. Why was that? Remember that translation order is important. In this
    case, we had a separate translation and rotation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'What is happening here is that the view is rotating, and then the model is
    transforming. We want to do it in the opposite order. One solution is to leave
    the model where it is and change the `render()` loop to this (note the bold part):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Spinning once and forever
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When we save this file and view it again in our VR browser, we will see the
    pot turn once. Note that we may not see the startup, and also note that when the
    pot finishes turning, it does so gracefully instead of being a computer animated
    ''smash stop'':'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/73217953-051c-4706-a152-02c25c5e7148.png)'
  prefs: []
  type: TYPE_IMG
- en: This is fantastic, but the pot turns and then stops. We might want it to continue
    to turn. So let's do that!
  prefs: []
  type: TYPE_NORMAL
- en: 'Modify the component creation to do the following (yes, we sort of get rid
    of all the cool Animate keywords):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Okay, in this part, make note of a few things. The variable we are using is
    called `yRotation`; we also use the word `rotate`, which is actually a new function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We also need to change the object loading/unloading routines, to both start
    up the rotation as well as to end the timer callback:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `<View>` itself doesn't change; it's merely rotating the object as the driving
    function does; this time, we're driving it with a custom function called on every
    `render()` loop.
  prefs: []
  type: TYPE_NORMAL
- en: It's very important to check the time lapsed, as different platforms will have
    different frame rates, depending on hardware, GPU, and many other factors. To
    ensure that all types of computers and mobile devices see the pot spin at the
    same speed, we take the `now` variable and calculating the difference between
    `now` and `this.lastUpdate` giving us a delta time. We use the delta for the actual
    spin speed.
  prefs: []
  type: TYPE_NORMAL
- en: The final code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have all that fixed, we have a well rendered spinning teapot. While
    doing the coding, we also fixed a bad piece of programming; the pot speed was
    hard coded to be 20 or so. This is better if it''s a `const` from a programming
    maxim, "never embed constants in the body of your program":'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Sound
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sound in VR is actually pretty complicated. Our ears hear things differently
    to someone else's ear. Many VR systems do a simple "if it's on the right, it's
    louder to my right ear" stereo pan (stereo panning), but this isn't really the
    way that actual sound works. For VR, and the high frame rates that they require,
    just like our lighting effects skip doing full raytracing, this sound panning
    is okay.
  prefs: []
  type: TYPE_NORMAL
- en: More sophisticated VR systems would use something called a **Head Related Transfer
    Function **(**HRTF**). An HRTF is how sound changes when you tilt your head. In
    other words, how does sound "transfer" based on *your* head? Each person has their
    own HRTF; it takes into account the shape of their ears, the bone density in their
    heads, and the size and shape of their nose and mouth cavities. Our ears, coupled
    with the way we are raised, during which we train our brain, allows us to do amazing
    things with an HRTF. For example, humans can locate something in three dimensions
    by only hearing it from two points. That would be like being able to see in stereo
    with only one eye! HRTF gives us what vision doesn't; it gives us spatial awareness
    of what is happening all around us, even if we don't see it.
  prefs: []
  type: TYPE_NORMAL
- en: To use HRTFs for Virtual Reality will require every person hearing a sound in
    a virtual world to have their HRTF loaded into the VR world's sound system. Further,
    that HRTF has to be measured in an anechoic chamber (a chamber with foam lining
    on the walls to eliminate echo). This is obviously not very common.
  prefs: []
  type: TYPE_NORMAL
- en: Most VR sound, thus, just does a left/right panning.
  prefs: []
  type: TYPE_NORMAL
- en: This is an area where VR can have significant breakthroughs. Sound is very important,
    and allows us to perceive things in 3D space; it is an important aspect of immersion.
    Many people think Stereo Panning is 3D; this is where a sound is simply louder
    in one ear than the other. In an audio system, this is the *balance* knob. In
    headphones, it'll sound weird, but it's not actually localizing the sound. In
    the real world, your right ear will hear a sound just a split second before (or
    after) the left ear, and as you tilt your head, the curves in your ear change
    that delay and your brain says "Ah, the sound is right *there*."
  prefs: []
  type: TYPE_NORMAL
- en: Stereo panning is about all that can be done without the HRTF measuring, but
    an HRTF is significantly better. The good news is that audio hardware and computing
    power is so great now that with an HRTF or reasonable software to simulate an
    average HRTF, much more complicated sound processing is possible. Look to this
    area for future enhancements.
  prefs: []
  type: TYPE_NORMAL
- en: The power of React VR again comes to our rescue. We don't have to worry about
    all that; we just have to put the sound in our world.
  prefs: []
  type: TYPE_NORMAL
- en: Seriously, don't get too discouraged with all that talk, just be aware that
    sound is difficult (as important as graphics rendering), but at this point, all
    you really need to do is to get a good mono (not stereo) sound and describe it
    in the scene file.
  prefs: []
  type: TYPE_NORMAL
- en: That's the whole point of React VR. Describe what you want; you don't need to
    tell people how to do it. Still, you need to know what is going on behind the
    scenes.
  prefs: []
  type: TYPE_NORMAL
- en: Putting sound in our world
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s actually make some noise. [Freesound.com](http://Freesound.com)
    is a good place to go for free game sounds. Most of the sounds there require attribution.
    Giving credit to the people who help build your world is the right thing to do.
    Go to the site and download several sound files you like. A few of the ones I
    found at `freesound.com` are these:'
  prefs: []
  type: TYPE_NORMAL
- en: Boiling pot water by Geodylabs ([http://bit.ly/BoilingPot1](http://bit.ly/BoilingPot1))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boiling water by dobroide ([http://bit.ly/Boiling2](http://bit.ly/Boiling2))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boiling water by abrez ([http://bit.ly/Boiling3](http://bit.ly/Boiling3))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I downloaded these in the `.mp3` file format; this should be fairly cross platform.
    Copy these into a new folder called `sounds` in the directory of `static_assets`
    too. I only used one of them in the actual world, but you can experiment with
    the others. Sometimes you don't know if it works until you hear it in the world.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sound is a node that has to be attached to a View, Image, or Text—React VR''s
    only components. You probably want to attach it to a box, model, or whatever;
    just wrap the object with a `<View>`, and put the `sound` component inside it,
    as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: One thing that is a bit funny is that the sounds don't come from where our teapot
    is (the upper left as you first view the world). Why is that? Look at the preceding
    code; we've simply wrapped the `View` tag around the `Model`; so it is transformed
    differently than the sound.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some sounds work better than others; you''ll have to experiment or record your
    own. Fixing the transformation is left as an exercise for the reader. (Actually,
    it''s easy, but ensure that you don''t paste the transform as a child XML element.)
    The correct code is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We learned how to build animations both by procedurally changing an object's
    position and by using the more advanced methods of using timers and the Animated
    API. We dramatically saw what happens if we use the wrong `<View>` to animate,
    and developed a way to make objects animate forever. The Energizer bunny will
    be proud. We also added sound, which is a very important thing for virtual worlds.
  prefs: []
  type: TYPE_NORMAL
- en: There is a lot you can do with timers; I highly recommend that you study the
    online documentation and experiment!
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have stayed within React VR. Sometimes, there are things we need
    to do that React doesn't allow us to do. In the next chapter, we'll go Native
    (native React, that is)!
  prefs: []
  type: TYPE_NORMAL
- en: Can someone turn off that boiling pot?
  prefs: []
  type: TYPE_NORMAL
