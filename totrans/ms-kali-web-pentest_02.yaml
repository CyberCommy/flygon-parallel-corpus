- en: Chapter 3. Stalking Prey Through Target Recon
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The American President Abraham Lincoln, quotable as he may have been, is often
    (incorrectly) heldÂ to have once said,
  prefs: []
  type: TYPE_NORMAL
- en: '*"Give me six hours to chop down a tree and I will spend the first four sharpening
    the axe."*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Regardless of where the quote truly came from, weÂ can certainly relate this
    withÂ hacking. Much success in web penetration testing is determined by what we
    uncover here, how we sift through the information, and how we couple it with tools
    covered later in this book. A thorough and methodical approach here will save
    time, focus efforts, and aid in planning our attacks. The methodologies from the
    various frameworks and organizations we discussed in [Chapter 2](000.html#), *Guidelines
    for Preparation and Testing*, all include some aspects of information gathering,
    and the tools available in Kali Linux should be familiar to you.Â
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this book, we''ll be following along with the Pen Test Kill Chain discussed
    in *Penetration Testing with the Raspberry Pi â�� Second Edition* (by *Jason Beltrame*
    and *Mike McPhee*, available atÂ [https://www.packtpub.com/networking-and-servers/penetration-testing-raspberry-pi-second-edition](https://www.packtpub.com/networking-and-servers/penetration-testing-raspberry-pi-second-edition))
    shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B03918_03_01-1.png)'
  prefs: []
  type: TYPE_IMG
- en: The Pen Test Kill Chain helps to understand what tools are involved when. Build
    your own version to help visualize the workflow.
  prefs: []
  type: TYPE_NORMAL
- en: This information gathering takes many forms, but as a practicing hacker, you
    have probably developed your own preferences and routines. A healthy mix of open
    source information gathering, passive reconnaissance of the target itself, and
    subtle, focused scanning and *spidering* can go a long way toward laying out the
    rest of your project's game plan. The challenge is to expose as much as possible
    without triggering defensive awareness (also known as **paranoia**) in our target's
    operators. My hope is that I can help provide some tweaks to your processes that
    can help you get further into your discovery without getting caught.
  prefs: []
  type: TYPE_NORMAL
- en: The universal vulnerability of all systems is the user, and web applications
    present their developers with an outlet to express themselves and show what they
    are made of. Effective social engineering can often short-circuit a tremendous
    amount of technical engineering to obtain credentials and other key elements of
    the web application's architecture. We'll look at how to exploit trust and pride
    to encourage the target's users and developers to squeeze as much out of this
    approach as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s not forget that artifacts themselves can help the customer understand
    their information exposure. Keenly aware cyber security initiatives will not only
    drawÂ attention to what is publicly available with respect to their organizations,
    but they may even engage in misinformation. In your discovery, catalog your findings:
    customers should be commended for reducing their public exposure.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll discuss the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Gathering and using offline archives of websites
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reconnaisance of yourÂ target using public resources and a fancy old browser
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using social engineering to hack the users
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automating open source information gathering to map and characterize the target
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying key aspects of our target and focusing later efforts through active
    scanning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The imitation game
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: If one challenge in the recon phase of the attack gets your blood pumping, it'll
    be trying to find out every last detail about a site without getting caught looking
    too curious. Casual, normal users crawl websites randomly with a focus on certain
    high-traffic transactions, and anything more methodical than this may arouse suspicion.
    Inefficient workflows may also raise flags, so being able to surf the site and
    game plan attacks is an incredibly useful trick to learn. In this section, we'll
    look at how to create a mirror of a site (without waking the defenders) for a
    risk-free simulation. They do say that imitation is the best form of flattery.
  prefs: []
  type: TYPE_NORMAL
- en: We'll also find that there are limitations to the site's mirror. Back-end data,
    higher-level scripting, and intelligence all fail to replicate without the same
    infrastructures at the application and data tiers. The business logic that we
    may be counting on to actually exploit the application doesn't replicate over,
    and the vast array of data that is our end goal cannot be pulled in this fashion.
    We'll need to better understand how to surf safely. We'll discuss some better
    poking and prodding techniques for the actual site with stealth in this section
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: Making (then smashing) a mirror with HTTrack
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Military operations, sports teams, and business proposal teams operating at
    their best will rehearse or perfect their tactics and overall strategyÂ against
    a mock opponent or in an environment that is an authentic copy of what they will
    be up against. The benefits of this are many, but chief among them is that these
    rehearsal environmentsÂ provide a safe environment to build confidence and competenceÂ without
    the risk of losing the actual battle, game, or project. In the movieÂ *Ocean's
    Eleven*, they actually mocked up a complete copy of the vault they were breaching
    to rehearse their plan (and more, but I won't spoil the fun if you haven't seen
    it yet â��go rent or stream it if you can). The point is that the more accurate
    and realistic the simulation, the greater theÂ chance of success when the real
    deal is happening.
  prefs: []
  type: TYPE_NORMAL
- en: Now that my movie reference is over, think about our role as pen testers. If
    you can pull down a copy of the HTML, JavaScript, CGI, and CSS code for a full
    website and a hierarchy intact, then wouldn't that be a great way to explore the
    site without tripping alarms at the real target? All of the brainstorming you
    and your team engage in can now be used on a replica, and because there is no
    target organization monitoring the dashboard, we can test a bunch of vectors rather
    than fretting over just one.Â  In training along with the pen test, this is also
    a useful method of creating local, travel-ready copies of sites that can be used
    without fear of retribution or dependence on actual network connectivity.
  prefs: []
  type: TYPE_NORMAL
- en: These archives can also form the basis of a spoof attack, allowing us to take
    the actual web pages and modify them before hosting them in a rogue honeypot using
    **Browser Exploitation Framework** (**BeEF**) or a credential skimmer using **Social
    Engineering Toolkit** (**SET**).
  prefs: []
  type: TYPE_NORMAL
- en: Several site mirroring utilities such as`wget` and `w3af` can do archives, but
    **HTTrack** is the most fully-featured tool in Kali that can create a mirror.
    You may already use it for base archives, but with a few tweaks, it can do so
    much more. Let's take a look at some of the most useful CLI options for recon
    and their equivalent **Graphical User Interface** (**GUI**) versions wherever
    applicable.
  prefs: []
  type: TYPE_NORMAL
- en: Making a stealthy initial archive
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Â As a refresher, you can create an archive of a website by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `â��O` points to the output location (some locally accessible drive where
    you plan to access the mirror from). Â While help may prove useful (Â `hattrack
    --help`Â orÂ `man help`), you'll get more out of the manual volunteered by Fred
    Cohen on the HTTrack website ([https://www.httrack.com/html/fcguide.html](https://www.httrack.com/html/fcguide.html)).
    As *Mr. Cohen* reveals, there are a ton of switches in the CLI, and understanding
    the defaults for many of those is useful in crafting your own go-to mirror operation.
    More sophisticated sites will take measures to prevent mirroring from utilities
    such asÂ HTTrack, including recursive links and directory structures, domain splitting,
    and obfuscating links using scripts to impair your ability to mirror them. Drastic
    measures such as IP blacklisting or throttling may also be employed, so it is
    best to only employ these tools with care, tuning, and respect for the website's
    owners.
  prefs: []
  type: TYPE_NORMAL
- en: Tuning stealthier archives
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Conducting a stealthier mirror is certainly worth learning about, but we have
    some trade-offs to consider. Throttling and threadÂ limits help keep us off their
    radar, but that means a mirror operation will take that much longer. We can limit
    what we are looking for through filters and directory restrictions, which is something
    that social engineering and our own experience can assist with. Are there efficiencies
    to be gained elsewhere?
  prefs: []
  type: TYPE_NORMAL
- en: 'There is considerable overhead as HTTrack processes queries, and a big factor
    in the time and compute power consumed is the parsing ofÂ **Multipurpose Internet
    Mail Extensions** (**MIME**) types on sites. There are many customizable features
    of HTTrack that can be leveraged through modification to the `.httrackrc` file,
    but the most useful one I picked up was the addition of the followingÂ line, which
    drastically cut my mirror time from hours to minutes. This line speeds up transfers
    by telling HTTrack to assume that HTML, PHP, CGI, DAT, and MPG files correspond
    to a standard MIME type and can be resolved to their usual end-state, avoiding
    all of the churn. Simply add this in its entirety (after modifying it to your
    liking) to the `.httrackrc` file using your favorite editor and save the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Once I've made this modification to my defaults, the stealthier command string
    that I find useful will do a bunch of non-default things. Â Keep in mind, once
    you've honed your own switches, you can save them in the `.httrackrc` file as
    well. Here is the command I used:Â
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is aÂ brief description of the options I used. *N*Â denotes a variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '`-cN`: This limits the number of simultaneous downloads or file handles to
    avoid overwhelming our target'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-AN`: This throttles the bandwidth to stay under the radar'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-mN` and `â��mN''`: These limit total downloads for the non-HTML and HTML
    file sizes respectively to ensure we do not overrun our disk'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-M`: This sets the overall mirror size limit â�� again keeping the disk size
    manageable'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-rN`: This puts a safety on recursion depth so we don''t get into a loop'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-H2`: This stops the download if slow traffic is detected'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-<path>/*`: This skips a path (in this case, I didn''t want to pull down their
    extensive forums or user profiles)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can also use the GUI version, **WebHTTrack**, which is handy for learning
    how to tweak your favorite filters and options:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B03918_03_02-1.png)'
  prefs: []
  type: TYPE_IMG
- en: WebHTTrack offers an intuitive way to master filters and tunings, and also enables
    the saving scan settings for repeat use.
  prefs: []
  type: TYPE_NORMAL
- en: 'This command against the [https://www.hackthissite.org/](https://www.hackthissite.org/)Â website
    took a little over an hour to pull down 200 MB of information. I omitted the forums
    and users in this example, but I could just as easily have omitted other directories
    to focus on a specific area of the site or to avoid violating the boundaries established
    by my customer. If you press *Enter* while the command line is running, you''ll
    get a rundown of how long it has run, the number of links found, and the total
    download size to that point in time:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B03918_03_03-1.png)'
  prefs: []
  type: TYPE_IMG
- en: The status screen is an easy way to see your progress. Pressing Ctrl + C will
    quit the mirror should you decide to end it early.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B03918_03_04-1.png)'
  prefs: []
  type: TYPE_IMG
- en: WebHTTrack's other advantage is that you can interact to skip files live in
    the archival process.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the archive is complete, you can surf it as if it was the live web by
    visiting the local path in your browser: `file:///tmp/hackthissite/www.hackthissite.org/index.html`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You''ll see in the following screenshot that we''ve successfully captured the
    dynamic advertising banner content([http://infosecaddicts.com/](_wp_link_placeholder)),
    which may be worth filtering as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B03918_03_05.png)'
  prefs: []
  type: TYPE_IMG
- en: Use theÂ local mirror created by HTTrack to interact with and surf the website,
    which is critical in identifying potential vectors.
  prefs: []
  type: TYPE_NORMAL
- en: Is the mirror complete and up-to-date?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There is a plethora of switches out there that I would encourage you to explore,
    but one in particular that I find useful helps to mirror even those places on
    the site that the developer tells Google, Yahoo, and other crawlers to omit.Â 
    `robots.txt` files or meta tags are used to tell browsers to skip archival or
    search scans. They usually do this to avoid allowing something to be searchable,
    which is certainly of interest in a pen test. Appending the `â��s0` option ensures
    we won't miss anything in our scans.
  prefs: []
  type: TYPE_NORMAL
- en: Updating our mirror is a pretty simple process.Â  Assuming you are storing it
    in a non-volatile location (`/tmp` goes away on reboots), you can manually gather
    or even assign a **cron** job to automatically update your mirror's content and
    links. A prompt will ensure that you mean to update the cache; and assuming this
    is the case, it will remove the lock file and perform an update. I would recommend
    exploring archival switches that can allow you to keep older files or perform
    incremental updates to make better use of your time. Some older copies may hold
    content that was removed to cover an inadvertent disclosure, so it is well worth
    hoarding some historical files until they have been scanned.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before we leave the HTTrack discussion, it is worth mentioning that tailoring
    your options and settings while practicing on known sites can make your mirroring
    process more efficient and useful. Be sure to take notes and documentÂ your favorite
    alternatives!
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B03918_03_06.png)'
  prefs: []
  type: TYPE_IMG
- en: HTTrack provides intelligent updates, and this saves bandwidth and time. CLI
    options forÂ multiple copies and versions if needed.
  prefs: []
  type: TYPE_NORMAL
- en: Touring the target environment
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Local copies allow us to scope out the site in a safe manner, but where do we
    start? Manual hands-on scanning will help us understand the flow and give us some
    hints as to the next steps. I would first recommend getting a feel for the site's
    hierarchy and where various dynamic content portals may reside. Where can users
    log into the applications hosted there, query for information, or provide or view
    feedback? We should also be making note of entity information that we can use
    later to enumerate names, e-mail addresses, and organization information, and
    better understand inter-entity relationships. If we are repurposing this mirror
    for MITM or honeypot duties, we'll want to be able to replicate not only the look
    and feel, but also the workflow.
  prefs: []
  type: TYPE_NORMAL
- en: Several tools exist that can assist with these walk-throughs, such as those
    that reveal the underlying HTML and JavaScript elements.Â Viewing the page source
    through the **Developer Tools** in **Firefox**, using a plugin from the **OWASP
    Mantra** add-on bundle, **HackBar**, or another HTML viewer. To save time, I would
    recommend that anything more than initial familiarization with the application
    or website be done with the use of a full proxy toolset such asÂ **Burp** or **Firebug**.
    Using a web application testing suite (covered in the next couple of chapters)
    helps you to efficiently pivot from the Recon stage to activities in the **weaponize**,
    **exploit**, or **install** stages.
  prefs: []
  type: TYPE_NORMAL
- en: Open source awesomeness
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: The first thing I do before accepting a task or job is to figure out what I
    am up against. It wasn't always this way. As a young engineer working on communications
    systems, I was once asked to lead the development of a specification for a subsystem
    that sounded cool. Woo hoo â�� a time to shine! I committed based on the sales
    pitch that the team lead provided. Reality hit me sometime around the second week
    in the task, as it was only then that I could look up from my keyboard to envision
    the remaining path ahead of me. Had I done that research ahead of my commitment,
    I could have avoided the trouble that was ahead of me. Needless to say, the job
    got done, but I always look back and wonder how much better it could have been
    and how much happier and better rested I would have been had I researched the
    process, constraints, and expectations before accepting the task.
  prefs: []
  type: TYPE_NORMAL
- en: Penetration testing is no different. While some testers (and black hats, for
    that matter) may accept a job before researching the target, the most experienced
    professionals take a different approach and do their homework. We're all Google
    search experts, but there are ways we can all improve these queries and leverage
    additional tools to complete the picture of what our target looks like. We need
    to take advantage of the many links between search engines, social media, forums
    and boards, and other public domain information. The followingÂ figure shows usÂ how
    raw **Open Source Intelligence** (**OSINT**) comes from many sources, and it can
    be accessed through search engines and Kali's own toolsets alike. An efficient
    use of OSINT helps to better understand *the ask* of a project and can help us
    develop the strategies, uncover vulnerabilities, harvest user information, and
    gain details that can help us map out the infrastructure. We'll take a look at
    a couple of tools that are likely familiar, but we will see if we can unlock some
    more of their potential.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B03918_03_07-2.png)'
  prefs: []
  type: TYPE_IMG
- en: Browsers and Kali's toolsets can help access the massive amount of OSINT available.
  prefs: []
  type: TYPE_NORMAL
- en: Open source Intel with Google and the Google hacking database
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Search engines are now so integral to our hyper-connected global society that
    it is easy to overlook each engine's strengths and capabilities. Google, Bing,
    and to a lesser degree, Yahoo have dominated the market in the United States,
    but given that our role as a pen tester may cross borders, it is useful to work
    with engines and their localizations to ensure we are getting the most up-to-date
    information.Â  The **Search Engine Colossus** ([https://www.searchenginecolossus.com](https://www.searchenginecolossus.com))
    provides the leading options in each of the countries, including those that are
    embargoed. General information searches, especially those in non-technical realms,
    should include search engines local to the target or their partner organizations.
    Google's search engine, however, provides excellent coverage and extensive syntax
    all its own that can take those general engine findings and use them with great
    efficacy to unearth architectural details, sensitive files, and potential ways
    into our target's servers.
  prefs: []
  type: TYPE_NORMAL
- en: Tuning your Google search skills
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'There are books written specifically on advancing Google search skills, but
    for web penetration testing, we can focus on some tips and practices that can
    better leverage the engine and eliminate useless search hits, commonly referred
    to as noise. We can use some operators to filter or focus our results, while others
    will perform logical combinations or modify the engine''s behavior. Let''s take
    a look at the most effective modifiers and options, filtering or focusing first,
    followed by logical operators:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The site: operator**: Using the site: operator tells Google''s engine to
    only accept files hosted on a particular domain. When we''re looking for legitimate
    contact information, exposed files, and content, we''ll want to use this operator
    to allow us to focus purely on that domain''s results, rather than on a full dump
    of links in page-hit order that may spamÂ many other sites. Take, for instance,
    a search on Cisco ASA documentation, both before (left) the site: operator and
    after (right):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B03918_03_08-1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The Site: Operator is a great first filter to ensure results focused on your
    target.'
  prefs: []
  type: TYPE_NORMAL
- en: '**TheÂ credentials operators**: Using keywords such as `username`, `password`,
    `userid`, `pwd`, `passcode`, credentials, or any other variant can help us locate
    password or username recovery details. A quick targeted search on these terms
    can not only point you to portal entries you will likely target, but may, in fact,
    provide the keys to unlock them. We''ll discuss using default credentials against
    the results of these queries later in this book:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B03918_03_09.png)'
  prefs: []
  type: TYPE_IMG
- en: Credential search may not yield credentials itself, but may point to the next
    best thing â�� recovery!
  prefs: []
  type: TYPE_NORMAL
- en: '**The inurl: operator**: An early recon of a target, including lessons learned
    from social engineering, may provide us with clues as to the platform used, developers
    involved, or points of interest in a web application. We can combine the inurl:
    operator with the site: operator to probe those specific points of interest:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B03918_03_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Inurl: can help eliminate thousands of potential locations and focus.'
  prefs: []
  type: TYPE_NORMAL
- en: '**The file handle (ext:) operator**: Using standard file handles allows us
    to call out and include (or exclude) file extensions of interest. Using typical
    file extensions, you can invoke each of them using the ext: operator. For instance,
    we''d search for all PHP files in [www.hackthissite.org](http://www.hackthissite.org)
    with the word index in the URL using the following string:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '**The filetype: operator:** If we''re looking for a file type that may not
    be displayed but linked to or archived on a site, we''d instead use the filetype:
    operator. Invoking `filetype:xls` in your search, for instance, would scour your
    search area for Excel spreadsheets:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '**The intitle: operator**: When we want a specific file, we can use the intitle:
    operator. This is very useful to locate platform-specific configuration files,
    or it can help to expose the `robots.txt` file. As you may recall from our HTTrack
    use, the utility''s default behavior is to avoid spidering the sections of the
    website identified in the `robots.txt` file. This was envisioned to allow web
    developers to preventÂ certain necessary but sensitive locations from being searchable
    by reputable browsers. If other precautions aren''t followed, `robots.txt` can
    provide a hacker with a list of files and folders they may want to see. Well,
    forÂ hackers, there is a good chance that there are some juicy details in there
    that would be very helpful.Â  To see what is in the `robots.txt` files, you can
    simply enter this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Each of the preceding operators can help narrow searches alone or in combination,
    but learning more about the processing engine of Google''s search can also help
    us eliminate extraneous information and understand the results. Here are some
    quick tip highlights:'
  prefs: []
  type: TYPE_NORMAL
- en: Using the logical operator **OR**Â is helpful (**AND**Â is assumed). If written
    out, OR must always be all caps to be considered the logical OR, lest it is considered
    part of the search phrase itself. You can also use the **|**Â operator, commonly
    referred to as the **pipe**Â operator.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google search will focus on the first 10 non-trivial words of a search phrase.
    UsingÂ *****Â in the place of optional or throw-away words in a search phrase
    won't count against the ten-word limit but effectively extends the phrase for
    more complex searches.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can use **-**Â before an operator or filter to exclude (negate) the effect
    of that filter or operation. An example might be where we want to determine what,
    other than web servers, a particular domain may be presenting:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B03918_03_11.png)'
  prefs: []
  type: TYPE_IMG
- en: Using the "-" modifier excludes a filter from the result set.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is not the same as the keyword **NOT**, which is actually only useful
    to exclude a word from the search but has no effect on the special operators.
    If we were to run the following, it would yield plenty of **www** results, unlike
    the search with **-** used as a modifier:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B03918_03_12.png)'
  prefs: []
  type: TYPE_IMG
- en: Using the NOT only excludes that string â�� not useful if you don't anticipate
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Work smarter with the Google hacking DB and Netcraft
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Google search skills will always be useful, but a lot of the most useful strings
    for hackers are captured in the **Google hacking database** (also known as **The
    Exploit DB**), a project hosted by the Offensive Security folks ([https://www.exploit-db.com/google-hacking-database/](https://www.exploit-db.com/google-hacking-database/)).
    While it is fun to browse, the best use of it is to seed your search queries,
    combining the strings they have catalogued with your own modifiers from the previous
    section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The bulk of their categories are useful for web penetration testing, but I
    would start with the **Web Server Detection** queries:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B03918_03_13.png)'
  prefs: []
  type: TYPE_IMG
- en: The Google Hacking DB is ripe with awesome search queries you can repurpose.
  prefs: []
  type: TYPE_NORMAL
- en: These queries and others from categories such asÂ **vulnerable servers**, **sensitive
    directories**, and so on, coupled with the `inurl:` and `site:` modifiers can
    prove quite useful in getting a high-level look at the exposure in an environment.
    If you get lucky and unearth credentials or vulnerabilities, this information
    should be disclosed immediately to your sponsoring customer. These searches are
    in use continuously on both sides of the hacking landscape, and this sort of information
    should not wait until the debrief.
  prefs: []
  type: TYPE_NORMAL
- en: '**Netcraft**, a company based in Bath, England, offers many services, but their
    free web scan tool ([https://searchdns.netcraft.com](https://searchdns.netcraft.com))
    is a great quick-and-dirty scanner that can help focus more detailed efforts.
    You can search on a domain name and burrow down into a report of all of the technologies
    and versions that can be publicly analyzed based on responses to harmless queries.
    A quick search of [https://www.packtpub.com/](https://www.packtpub.com/)Â on their
    site reveals that they have two mail IP addresses currently hosting a Packt platform
    on FreeBSD.Â  What else does the report tell us?'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B03918_03_14.png)'
  prefs: []
  type: TYPE_IMG
- en: Netcraft's online web scanner gives us a great peek at what we have in store
    for future phases.
  prefs: []
  type: TYPE_NORMAL
- en: We can see that there are two trackers in place (Google and Amazon). XML and
    SSL are in use server-side while JavaScript is in use on the clients, Drupal is
    used both as the **Content Management System** (**CMS**) and PHP scripting engine,
    and HTML5 and CSS sheets are in also use. All of these are useful in refining
    our pen testing approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Mastering your own domain
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Search engines are easy and accessible, but we also need to understand what
    a network's domain structure, addressing plan, and supporting services are, as
    that perspective is vital to our efforts in probing the application. Domains hosting
    applications can have intricate domain structures that can be exploited. The hosts,
    network IP addresses and blocks, nameservers, and related elements can help identify
    target entities, pivots to adjacent hosts, underlying services and daemons, and
    open ports and protocols that are in use as well. We'll look at some tools that
    incorporate some of these into a larger solution, but mastering **dig**, **fierce**,
    **dnsenum**, **dnsmap**, **WHOIS**, and **DNSRecon** will go a long way toward
    improving accuracy and efficacy.
  prefs: []
  type: TYPE_NORMAL
- en: The WHOIS database has been in use since the early days of the Internet, and
    while the intricate service provider and hosting paradigms mean WHOIS rarely contains
    the end user of the domain and their contact information, it is this information
    that can start an investigation. We've all used it in our experience, so we'll
    hop into the next-level tools.
  prefs: []
  type: TYPE_NORMAL
- en: Digging up the dirt
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: DNS records provide human-relatable aliases for IP addresses associated with
    the various functions of a domain. I would encourage a good review of DNS operations
    and the associated record types at periodic intervals to ensure you are always
    up to speed on any new trends in DNS use and to jog your memory. It is not uncommon
    to find new applications and protocols borrowing DNS record space for their own
    use. Keeping DNS knowledge fresh ensures you are well prepared to leverage those
    new applications.
  prefs: []
  type: TYPE_NORMAL
- en: The utility `dig` has been a stalwart of the pen testing community for DNS enumeration;
    chances are you've used it and have some favorite switches you like to employ.
    When it comes to web pen testing, we'll be concentrating on the answer field,
    and with the various switches that dig offers, we can use it to map out other
    related record types as well.
  prefs: []
  type: TYPE_NORMAL
- en: Digging record types
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Dig can be used to query for and map out the associated record types for **A**,
    **MX**, **NS**, **SOA**, or other records quickly and easily. The default is A
    records, which indicate the domain''s main IPv4 addresses, but you may only want
    to locate the associated name servers (NS records), for instance, to attempt MITM
    attacks. MX records and pointers to the mail servers on a domain can be useful
    in crafting phishing campaigns to target users. If we want to see all of the record
    types associated with a domain, we could use the `ANY` keyword:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B03918_03_15.png)'
  prefs: []
  type: TYPE_IMG
- en: Basic dig output - useful, but could be more succinct.
  prefs: []
  type: TYPE_NORMAL
- en: In order to find the mail servers associated with Packt Publishing, we would
    merely enter the MX keyword to filter just those record types.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each of the subsections in the basic `dig` output can be filtered, either by
    naming the specific section, such as `+nocomments`, `+noquestion`, `+noauthority`,
    `+noadditional`, or `+nostats` for instance. To turn all of these sections off,
    you can use the `+noall` shortcut and then turn on your desired section (for example
    `+answer`) to the end, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B03918_03_16.png)'
  prefs: []
  type: TYPE_IMG
- en: The dig output shortened to focus only on records of interest to us
  prefs: []
  type: TYPE_NORMAL
- en: The `+short` modifier can eliminate a lot of superfluous information as well
    and is well worth appending to your standard queries to help shorten outputs.
  prefs: []
  type: TYPE_NORMAL
- en: '`dig` also offers the ability to do a **zone transfer**, which, if the target
    is not protected against it, allows an attacker to pull down the entire forwarding
    zone of a domain. Something that is only supposed to happen between legitimate
    nameservers on the domain, a successful zone transfer is a windfall to the attacker
    and is something we should always test and look for. To demonstrate a zone transfer,
    we''ll use the wonderful training site Diji Ninja''s own domain ([https://digi.ninja/projects/zonetransferme.php](https://digi.ninja/projects/zonetransferme.php))
    and type this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B03918_03_17.png)'
  prefs: []
  type: TYPE_IMG
- en: Conducting a zone transfer is quite a coup, when it works.
  prefs: []
  type: TYPE_NORMAL
- en: '`dig` offers a clean and easy toolset, but often, the target environment is
    larger than what `dig` can present on well, or we are looking for more in-depth
    results. This is where `dnsrecon` comes in. I would recommend repeating the same
    sorts of exercises with `dnsrecon` to see how it compares with dig and help you
    determine which tool is to be your primary effort.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting fierce
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '`dig` and `dnsrecon` are fantastic tools, but wouldn''t it be nice if we could
    go a little further and have a tool that tries to connect to the site''s address
    blocks, automates the zone transfer, and does it all while logging? **Fierce**
    (written in Perl by Robert *RSnake* Hansen) can do just that. There are many options
    and modifiers that can be used when invoking Fierce, but in most cases, I do initial
    discovery using dig, move to Fierce for an attempted zone transfer and some connection
    probing, and then move into a more graphical and organized tool such as Maltego
    to build my network maps and enumerate relationships. To use Fierce to attempt
    a zone transfer and send the logs to a file, you can simply invoke the tool and
    it will do so automatically:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Because this site allows zone transfers, I''ll see the results in the running
    output and the `txt` file I designated:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B03918_03_18.png)'
  prefs: []
  type: TYPE_IMG
- en: Fierce automates what it takes several dig or dnsrecon queries to do.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fierce also allows you to attempt to connect to open ports on any public IPs
    using the `â��connect` switch. You''ll need to provide `wordlist` so that Fierce
    has some potential credentials to try, and you''ll want to run this on a dedicated
    machine or overnight, as the process can be lengthy, depending on the size of
    the domain. We can kick this off using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Next steps with Nikto
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Once we have a full array of DNS records and other relevant intelligence, we
    typically shift into scanning for vulnerabilities (also known as **vulns**). **Nikto**
    is my preferred scanner and I'll usually keep these results for tuning tools that
    scan vulnerabilities but also pivot into later phases. Nikto exports into several
    file types, including HTML, XML, TXT, and CSV, and using it begins the active
    recon phase.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Because it is an active tool, its use constitutes a legally provoking act, and
    as such, it is advised to only use it in practice against lab machines and for
    systems where you have explicit permission to test. I don't have enough collateral
    for posting bail on your behalf.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use Nikto, we''ll need to identify the host or host list (the latter defined
    in a host file) and a location for our output logs, but there is an extensive
    list of menu items worth considering to tailor our scans. Besides the output file
    and logging parameters, there are actually predefined tunings that are available
    to run some common, best-practice test sets against the specified hosts. These
    options are a great shortcut to making the best use of Nikto in your scans, and
    are detailed in the main page:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'A default scan will run all tests, but if there are restrictions as to what
    is permitted, these tunings can help keep the test compliant. When you require
    anonymity, it may also be desired to leverage an intentional proxy (either one
    you have established or one of many free ones (for example those on [http://proxy-list.org](http://proxy-list.org)),
    or better yet, a host you''ve already compromised for the purpose). To do so,
    you would specify the proxy server in `config.txt` (or an explicitly called alternative)
    using your favorite editor. **Nano** is my first choice, but **vim** or **emacs**
    works just fine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Scroll down to the **`P`****`roxy settings`** section and enter the appropriate
    details:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then launch our scans using the configured proxy as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B03918_03_19.png)'
  prefs: []
  type: TYPE_IMG
- en: Nikto is a versatile and powerful scanner - practice in a closed environment
    makes a huge difference.
  prefs: []
  type: TYPE_NORMAL
- en: As with any tool, it is sometimes important to realize which switches to avoid.
    For black-box testing (pen testing with a more realistic covert charter, where
    the tester tries to emulate an attacker and is provided with no advantageous access),
    it is essential to avoid options that cause excessive queries and chatty scans,
    and most of the time the `+mutate` switch is not worth the trouble. If you are
    white-box testing (known to the operators, not focused on stealth, and just exploring
    in the open), then it can make sense to provide greater coverage.
  prefs: []
  type: TYPE_NORMAL
- en: Employing Maltego to organize
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Maltego** is one of my favorite recon tools in that it helps visualize the
    many links and relationships between disparate data sources. *Jason Beltrame*
    and I covered it in the *Penetration Testing with Raspberry Pi â�� Second Edition*
    ([https://www.packtpub.com/networking-and-servers/penetration-testing-raspberry-pi-second-edition](https://www.packtpub.com/networking-and-servers/penetration-testing-raspberry-pi-second-edition)),
    but since then, I have begun to use it in use cases I could not have imagined.
    As fun as it has been to plunge into this, there are certainly some best-practices
    that have assisted in avoiding information overload. The most recent version available
    in Kali''s distribution, 4.0.11, includes new footprinting techniques such as
    **Company Stalker**, **Find Wikipedia Edits**, **Twitter Digger**, and **Monitor**.
    All of the transforms can be of use in web pen testing, but these new social-focused
    starting points stress the move by **Paterva** to make Maltego indispensable to
    all hacking communities.'
  prefs: []
  type: TYPE_NORMAL
- en: 'I tend toward using it as a graphical documentation of information gleaned
    from social engineering, LinkedIn/email searches, and pinning them on domains.
    The ability to pivot and transform against an entity has even helped me to uncover
    multiple domains across multiple hosting companies that through two or three layers
    of obfuscation are actually run by the same network of scammers. Recursion through
    transforms can help find additional users that may have local accounts or indicate
    relatives or friends whose names and information could populate our dictionaries.
    A quick example would be to do a Company Stalker machine against Packt Publishing''s
    web domain:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B03918_03_20.png)'
  prefs: []
  type: TYPE_IMG
- en: This Maltego graph is zoomed out to protect the innocent, but also to show the
    relational nature of information it tracks.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, there are several documents found in the base machine's process
    (orange dots) and each of those files has associated metadata, such as people
    (green), certificates (yellow), and locations (red). If we burrow down into a
    person, we can ask for transforms that search for all potential email addresses
    (blue). I find Maltego to be very helpful when you provide it with additional
    seed information from other OSINT sources to help focus, or nudge the model towards
    linking the original machine and other information. You can add any form of identity,
    but additional web domains or e-mail addresses, social networking usernames, or
    IP blocks and interfaces can greatly improve the fidelity and usefulness of Maltego
    graphs.
  prefs: []
  type: TYPE_NORMAL
- en: Being social with your target
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are not using **Social-Engineer Toolkit** (**SET**, [https://www.trustedsec.com/social-engineer-toolkit/](https://www.trustedsec.com/social-engineer-toolkit/)),
    you are missing out on something important. We can certainly use it to spoof Google,
    Facebook, and Twitter to attract victims and launch attacks or scrape their credentials,
    but we can also use it in spoofing our target web application so as to hijack
    sessions and map user behaviors. As victims unknowingly browse these duplicate
    websites from the comfort of a coffee shop chair, attackers can gather the victims''
    passwords or even inject a command shell that gives them full access to the victims''
    systems. It is a great tool for security professionals to demonstrate how users
    more often than not will not pay attention to the location where they enter sensitive
    information as long as the page looks legit. Let''s take a look at how to use
    SET against the mirror that we pulled down from [www.hackthissite.org.](http://www.hackthissite.org.)
    Here is a diagram we can use to help envision what this attack looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B03918_03_21-2.png)'
  prefs: []
  type: TYPE_IMG
- en: SET can be used for many attacks, but who doesn't like a classic MITM?
  prefs: []
  type: TYPE_NORMAL
- en: 'My typical use for SET is to select option **`1) Social Engineering Attacks`**,
    then select **`2) Website Attack Vectors`**. What I''m looking for is in **`3)
    Credential Harvester Attack Method`**, so we can grab our poor target users''
    login credentials. We can use the built-in templates or import custom sites (useful
    for corporate portals or lesser-used web applications); but why wouldn''t we want
    to just use the mirror we already captured? We''ll choose option **`3) Custom
    Import`**. This will turn our Kali Linux VM into a malicious front-end for [www.hackthissite.org](http://www.hackthissite.org),
    presenting itself as the real deal and scraping credentials or any other HTML-based
    information fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '`**`![](img/B03918_03_22.png)`**'
  prefs: []
  type: TYPE_NORMAL
- en: SET configuration using a previous mirror - modify and tweak to make it even
    more convincing.
  prefs: []
  type: TYPE_NORMAL
- en: A quick check of our mirror shows it is now up-and-running; our task now is
    to persuade users to direct their initial sessions to here.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B03918_03_23.png)'
  prefs: []
  type: TYPE_IMG
- en: A quick check pointing to my copy of the site shows our MITM clone is ready
    to roll.
  prefs: []
  type: TYPE_NORMAL
- en: Entering some credentials in the **`Login`** fields and submitting them, I can
    see that they are captured live and recorded in a log file.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B03918_03_24.png)'
  prefs: []
  type: TYPE_IMG
- en: Any HTTP messages that arriveÂ are captured, so credentials or personal information
    is ours to own.`  `## Summary
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: As I mentioned in the beginning of this chapter, the recon phase can make or
    break the subsequent phases. The information gathering will feed your cracking
    and fuzzing operations, narrowing search fields to something significantly more
    manageable. The work saved in focusing the testing translates into tighter test
    criteria, more successful testing approaches, less churn and trial and error,
    and much more salient reports. Customers often learn as much about what we find
    in this phase as they will in the remaining phases, and this brings up a crucial
    point. The quality and quantity of information available online about their systems
    and the people using them can have dramatic consequences in the future. Proactive
    actions to limit or reduce this exposure improves their security posture and should
    be both encouraged and coached.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we explored some deeper uses of the most popular OSINT gathering
    tools. We saw how we can quickly map the various network and domain components
    in a web application's hosting architecture, and even began to scan that infrastructure
    with tighter command line options that yield more succinct and useful data than
    the defaults. We also delved into better uses of search engines and leveraged
    some popular online resources that have documented some truly scary query strings.
    Social engineering in many forms were discussed, and we built our own MITM attack
    to capture credentials based on our mirrored website. Wrapping up, we looked at
    how Maltego begins to unravel the target environment's layers and aid in visualizing
    our adversary.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you'll learn how to crawl web applications more effectively
    for quick scans using the Arachni framework. As an intercepting proxy to interact
    with the conversation between the server and client, we'll see how Arachni can
    go further to automate some attacks to provide additional test vectors, launch
    scans, trace flows on DOM, and JavaScript environments. As a bonus, you'll learn
    to use Arachni to mimic mobile platforms and even produce higher quality reports,
    either as stand-alone or as the basis for a multi-tool pen test deliverable. The
    work in this chapter is about to pay off, folks!`
  prefs: []
  type: TYPE_NORMAL
