- en: Deploying Java on Kubernetes in the Cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In previous chapters, we have managed to run the Kubernetes cluster locally.
    Using `minikube` is a great way to learn Kubernetes and experiment on your own
    machine. The `minikube` powered cluster behaves exactly the same as the normal
    cluster that runs on the server. However, if you decide to run your clustered
    software in a production, the cloud is one of the best solutions. In this chapter,
    we will briefly cover the advantages of using cloud environments in the context
    of microservices running on Docker. Next, we are going to deploy our Kubernetes
    cluster on the Amazon AWS. Configuring AWS and running Kubernetes on it is not
    the easiest and most straightforward process from the start but, following this
    chapter will give you an overview of the process, you will be able to run your
    own cloud cluster quickly and deploy your own or third-party Docker images on
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The list of topics covered includes:'
  prefs: []
  type: TYPE_NORMAL
- en: The benefits of using cloud, Docker, and Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing the needed tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring AWS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying the cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's begin with the advantages of using a cloud-deployed Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Benefits of using the cloud, Docker, and Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having an application deployed on a Kubernetes cluster has its advantages. It's
    fail resilient, scalable, and has efficient architecture. What's the difference
    between having your own infrastructure and using the cloud? Well, it comes down
    to couple of factors. First, it can be a significant cost reduction. For small
    services or applications, which could be shut down when not in use, the price
    of deploying applications in the cloud can be lower, due to lower hardware costs,
    there will be more effective usage of physical resources. You will not have to
    pay for the nodes that do not use the computing power or network bandwidth.
  prefs: []
  type: TYPE_NORMAL
- en: Having your own servers requires you to pay for the hardware, energy, and operating
    system software. Docker and Kubernetes are free of charge, even for commercial
    purposes; so, if you run it in the cloud, the cloud provider fee will be the only
    cost. Cloud providers update their software stack often; you can benefit from
    this by having the latest and greatest versions of the operating system software.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to the computing power or network bandwidth, large cloud providers
    such as, Amazon or Google cannot be easily beaten. Their cloud infrastructure
    is huge. Since they provide services to many different clients, they buy large,
    high-performance systems that offer performance levels much higher than a small
    company can afford to run internally. Also, as you will see in the next sections
    of this chapter, cloud providers can spin up new servers or services in minutes
    or even seconds. As a result, if there's a need, new instances will be brought
    to life in a way that is almost transparent for the users of your software. If
    your application needs to handle a lot of requests, sometimes having it deployed
    in the cloud can be the only option.
  prefs: []
  type: TYPE_NORMAL
- en: As for fault-tolerance, because cloud providers have their infrastructure spread
    out over the whole world (such as AWS zones, as you will see later in this chapter),
    your software can be fail-proof. No single accident such as power outage, fire,
    or an earthquake, can stop your application from running. Adding Kubernetes to
    the equation can scale the deployment up or down and will increase the fault tolerance
    of your application, even reducing the chance of complete failure to zero.
  prefs: []
  type: TYPE_NORMAL
- en: Let's move our software to the cloud. To do this, we need to create a toolset
    first, by installing the required software.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To be able to manage Kubernetes cluster on Amazon EC2, we will need to install
    some command-line tools first. Of course, using the Amazon EC2 web interface is
    also possible. Spinning up a cluster is quite a complicated process; you will
    need to have a user with proper access and permissions, storage for a cluster
    state, EC2 instances to run your Kubernetes master and worker nodes, and so on.
    Doing everything manually is possible, but can be time consuming and error prone.
    Luckily, we have tools that can automate most of the things for us, this will
    be the AWS command-line client (`awscli` ) and `kops` , Kubernetes operations,
    production Grade K8s installation, upgrades, and management. There are some requirements
    though. `Kops` runs on Linux and macOS, it's written in Go, like Docker. The `awscli`
    is written in Python, so let's focus on Python installation first.
  prefs: []
  type: TYPE_NORMAL
- en: Python and PIP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To run the AWS command-line tools (`awscli` ), we will need `python3` present
    on our machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'It may be present already, you can verify that using the command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'If the output is `command not found` , the fastest way of installing it will
    be using the package manager you have on your system, such as `apt` on Debian/Ubuntu,
    `yum` on Fedora, or Homebrew on macOS. If you work on macOS and do not have Homebrew
    installed, I highly recommend doing so; it''s a wonderful tool that gives you
    the possibility to easily install thousands of packages together with all the
    needed dependencies. Homebrew is available freely at [https://brew.sh/](https://brew.sh/)
    . To install it, execute the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: From now on, you should have the `brew` command available in your macOS terminal.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install Python on Linux using the `apt` package manager (on Debian or Ubuntu),
    execute the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'On macOS, this will be the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The process of installing Python depends on the speed of your machine and internet
    connection, but it should not take long. Once Python is installed, we will need
    another tool, which is `pip` . `pip` is the recommended tool for installing Python
    packages. It''s written in Python itself. You can install it using the package
    manager of your choice, executing the following, for example, on Ubuntu or Debian:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'An alternative way of installing `pip` is using the installation script. In
    this case, the process is exactly the same for Linux and macOS. First, we need
    to download the installation script using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'After a while, we need to run the installation script by executing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'After a while, `pip` should be available for you in the terminal shell. To
    verify if it''s working, execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have Python and pip installed and working properly, it's time to
    move on to more interesting things, installing Amazon AWS command-line utilities.
  prefs: []
  type: TYPE_NORMAL
- en: AWS command-line tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Amazon **AWS command-line tool** (**awscli** ) interface is a unified tool
    for managing your AWS services. The `awscli` is built on top of the AWS SDK for
    Python, which provides commands for interacting with AWS services. With minimal
    configuration (actually, providing login id and a secret is enough, we will do
    it in a while), you can start using all of the functionality provided by the AWS
    Management Console web interface. Moreover, the `awscli` is not only about EC2,
    which we will be using to deploy our cluster on, but also other services such
    as S3 (a storage service) for example.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install `awscli` , execute the following `pip` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'After a while, `pip` will download and install the necessary files in the `python3`
    folder structure on your drive. It will be `~/Library/Python/3.6/bin` in case
    of macOS and Python 3.6\. It''s very convenient to add this folder to your `PATH`
    environment variable, to make it available from anywhere in the shell. This is
    straightforward; you will need to edit the `PATH` variable in one of those files,
    depending on the shell you use:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bash** : `.bash_profile` , `.profile` , or `.bash_login`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Zsh** : `.zshrc`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tcsh** : `.tcshrc` , `.cshrc` or `.login`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An example `PATH` entry could look the same as this, on macOS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'After logging back in or launching a new terminal, you can verify if the `aws`
    command is available, by executing the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see in the output, this will give you a detailed `aws` command-line
    tools version also with the Python version it''s running on:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00112.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The `awscli` is ready to use, but we have one more tool to add to our tool setup.
    It will be Kubernetes `kops` .
  prefs: []
  type: TYPE_NORMAL
- en: Kops
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes operations or `kops` , for short, is the production grade Kubernetes
    installation, upgrades, and management tool. It''s a command-line utility that
    helps you create, destroy, upgrade, and maintain highly available Kubernetes clusters
    on AWS. AWS is officially supported by the tool. You can find the `kops` releases
    on GitHub: [https://github.com/kubernetes/kops/releases](https://github.com/kubernetes/kops/releases)'
  prefs: []
  type: TYPE_NORMAL
- en: 'To install on either macOS or Linux, you will just need to download the binary,
    change the permission to executable and you are done. To download, execute, for
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, if you are using Linux, execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, again, using the package manager will be the easiest way to
    get the latest `kops` binary, for example using `brew` on macOS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Note that you must have `kubectl` ([https://kubernetes.io/docs/tasks/tools/install-kubectl/](https://kubernetes.io/docs/tasks/tools/install-kubectl/)
    ) installed in order for `kops` to work. If you use the package manager, the dependency
    to `kubectl` will be probably defined in the `kops` package, so the `kubernetes-cli`
    will be installed first.
  prefs: []
  type: TYPE_NORMAL
- en: The last tool is the `jq` . Although not mandatory, i t's very useful when dealing
    with JSON data. All the AWS, Kubernetes, and `kops` commands will post and receive
    JSON objects, so having a tool for parsing JSON comes in handy, I highly recommend
    installing `jq` .
  prefs: []
  type: TYPE_NORMAL
- en: jq
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`jq` is a command-line JSON processor. It works like `sed` for JSON data; you
    can use it to filter, parse, and transform structured data with the same ease
    that `sed` , `awk` , or `grep` let you do with raw text. `Jq` is available on
    GitHub at [https://stedolan.github.io/jq/](https://stedolan.github.io/jq/) . The
    installation is very simple; it''s just a single binary, available for Windows,
    macOS, and Linux. Just download it and copy it into the folder available on your
    system `PATH` to be able to run it from the shell or command-line.'
  prefs: []
  type: TYPE_NORMAL
- en: Assuming we have all the tools installed before we start using kops, we will
    need to configure our AWS account first. This will be creating an administrative
    user and then, using the `aws` command-line tool, creating the user for running
    `kops` .
  prefs: []
  type: TYPE_NORMAL
- en: Configuring Amazon AWS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The configuration of AWS before setting up a Kubernetes cluster goes down to
    creating a user, basically. All the rest will be done more or less automatically
    by the `kops` command. Before we can use `kops` from the command-line, it's good
    to have a user dedicated to `kops` . But first, we will need to create an administrator
    user. We will do it from the Web Management Console.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an administrative user
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Depending on the AWS region you have chosen, the AWS Management Console is available
    at a subdomain of `console.aws.amazon.com` , this will be [https://eu-central-1.console.aws.amazon.com](https://eu-central-1.console.aws.amazon.com)
    , for example. After logging in, go to the IAM page of the Security, Identity,
    and Compliance section, then switch to the Users page, then click on the Add user
    button.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will be presented with the user creation screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00113.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We will need this user for using `awscli` , so the only option we need to mark
    is the Programmatic Access . After clicking on Next: Permissions , let''s give
    our `admin` user full administrative rights by adding him to the `admin` group:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00114.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'On the last page of the user creation wizard, you will be able to see the Access
    key ID and Secret access key ID . Do not close the page, we will need both in
    a short while to authenticate using `awscli` :'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: That's it. We have created an admin user with all the administrative rights
    and have the access keys. It's all we need to manage our AWS instances using `awscli`
    . Running `kops` using the `admin` user is probably not the best idea, so let's
    create a separate user for that. This time, however, we will do it from the command-line.
    It will be a lot easier in comparison to UI clicking on the Web Console . First,
    let's authenticate using the admin user's Access key ID and `Secret access key
    ID` , presented on the last page of the user creation wizard.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a user for kops
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `kops` user will need to have the following permissions in AWS to function
    properly:'
  prefs: []
  type: TYPE_NORMAL
- en: '`AmazonEC2FullAccess`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AmazonS3FullAccess`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AmazonRoute53FullAccess`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`IAMFullAccess`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AmazonVPCFullAccess`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'First, we are going to create a group named `kops` and give the needed permissions
    to the group. Execute the following list of commands to create a group and assign
    permissions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The `create-group` command will give you some JSON response, but there will
    be no response when attaching a permission (group policy) to the group if all
    goes well:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00116.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, let''s create the `kops` IAM user and add the user to the `kops` group,
    using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'If you are curious you can now login into the web AWS console. You will see
    that our `kops` user has all the permissions we need:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00117.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'To list all the registered users, execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see in the following screenshot, we should now have two users: `admin`
    and `kops` :'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00118.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The last thing we need to do regarding our new `kops` user is to generate the
    access keys. We will need them to authenticate using the `aws configure` command.
    Execute the following to generate the access keys for the `kops` user:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see in the following screenshot, AWS will answer with the JSON response
    containing `AccessKeyId` and `SecretAccessKey` ; we will need both when authenticating
    using the `aws configure` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00119.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'All we need to do now is to authenticate using the `aws configure` command,
    providing the `AccessKeyId` and `SecretAccessKey` we got in the response. Execute
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Because the `aws configure` command doesn''t export these variables for `kops`
    to use, we need to export them now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: That's it, we have authenticated with our new user named `kops` , which has
    all the permissions needed to spin up a Kubernetes cluster. From now on, every
    `kops` command we execute will use the AWS `kops` user. It's time to get back
    to the point and create our cluster, eventually.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are going to create a simple cluster with one master node and two worker
    nodes. To do it using `kops` , we will need:'
  prefs: []
  type: TYPE_NORMAL
- en: A user profile declared in `~/.aws/credentials` (this is done automatically
    if you authenticate using `aws configure` ).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An S3 bucket to store `kops` cluster state. In order to store the representation
    of our cluster and its state, we need to create a dedicated S3 bucket for `kops`
    to use. This bucket will become the source of truth for our cluster configuration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DNS configured. This means we will need a Route 53 hosted zone in the same AWS
    account. Amazon Route 53 is a highly available and scalable cloud **Domain Name
    System** (**DNS** ) web service. Kops will use it to create records needed by
    the cluster. If you are using newer kops (1.6.2 or later), then DNS configuration
    is optional. Instead, a gossip-based cluster can be easily created. For the purposes
    of the example's simplicity, we will use the gossip-based cluster. To make it
    work, the cluster name must end with `k8s.local` . Let's look at other options
    we have regarding DNS setup, though.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DNS settings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Four scenarios are possible for our cluster''s domain, basically: the root
    domain, which is hosted on AWS, the subdomain of the domain hosted on AWS, using
    Amazons Route 53 for a domain hosted elsewhere, and finally, a subdomain for your
    cluster set up in Route 53 while having the root domain elsewhere. Let''s briefly
    look at those setups now.'
  prefs: []
  type: TYPE_NORMAL
- en: Root domain on AWS hosted domain
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you have your domain bought and hosted on AWS, you will probably have the
    Route 53 configured for you automatically already. If you would like to use this
    root level domain for your cluster, you need do nothing to be able to use that
    domain name with your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: The subdomain of the domain hosted on AWS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you have your domain bought and hosted on AWS, but would like to use the
    subdomain for the cluster, you will need to create a new hosted zone in Route
    53 and then delegate the new route to this new zone. This is basically about copying
    the NS servers of your subdomain up to the parent domain in Route 53\. Let''s
    assume our domain is [mydomain.com](http://www.mydomain.com/) ; we need to get
    some information first. Note that the `jq` command-line tool comes in handy now,
    when executing `aws` commands. First, we need the ID of our main parent zone:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'To create a new subdomain, execute the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the previous command will list the name servers of the new domain.
    If you created the subdomain before, and would like to list the name servers (to
    copy the NS servers list to the parent zone, we will need to know them first),
    execute the following command to get the subdomain zone ID:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Having the ID of the subdomain zone, we can list its name servers, by executing
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'So far, we have our parent''s zone ID, subdomain zone''s ID and a list of subdomain''s
    name servers. We are ready to copy them into the parent. The most convenient way
    will be to prepare the JSON file, as it''s quite a long input. The file will look
    the same as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'You will need to save this as a file, let''s say `my-service-subdomain.json`
    , and execute the last command. It will copy the name servers list into the parent
    zone:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: After a while, all network traffic to `*.myservice.mydomain.com` will be routed
    to the correct subdomain hosted zone in AWS Route 53.
  prefs: []
  type: TYPE_NORMAL
- en: Route 53 for a domain purchased with another registrar
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you bought your domain elsewhere, and would like to dedicate the entire domain
    to your AWS hosted cluster, things can get a little complicated, as this setup
    requires you to make crucial changes in another domain registrar.
  prefs: []
  type: TYPE_NORMAL
- en: If the registrar for your domain is also the DNS service provider for the domain
    (which is, actually, very often the case), it's recommended to transfer your DNS
    service to Amazon Route 53 before you continue with the process to transfer the
    domain registration.
  prefs: []
  type: TYPE_NORMAL
- en: The reason for that is that when you transfer the registration, the previous
    registrar might disable the DNS service for the domain, as soon as they receive
    a transfer request from Route 53\. As a result, any service you have on this domain,
    such as a web application or an email, might become unavailable. To transfer the
    domain registration to Route 53 from another registrar, you will need to use the
    Route 53 console, available at [https://console.aws.amazon.com/route53/](https://console.aws.amazon.com/route53/)
    . In the navigation pane, choose Registered Domains and then Transfer Domain ,
    and enter the name of the domain which you would like to transfer and click on
    Check . If the domain is unavailable for transfer, the console will list the probable
    reasons and a recommended way to handle them. If everything is ok and the domain
    is available for transfer, you will have an option to add it to the cart. You
    will need to enter some details then, such as your contact information, the authorization
    code for transfer (you should get it from the previous registrar) and the name
    server settings. I highly recommend selecting the Route 63 managed DNS server,
    as it's quite easy to configure and reliable. The Route 63 will take care of communication
    with your previous registrar, but you may receive some emails requiring you to
    confirm some things. The transfer process can take a longer time, but when it's
    done, you may proceed with configuring the domain for your AWS based cluster in
    the same way as in the previous two cases.
  prefs: []
  type: TYPE_NORMAL
- en: Subdomain for cluster in AWS Route 53, the domain elsewhere
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you have your domain registered at a registrar other than Amazon and would
    like to use the subdomain of that domain to point to your cluster, you will need
    to modify your name servers entries in your registrar. This would require a new
    hosted zone subdomain to be created in Route 53 and then migration of this subdomain's
    name server records to your registrar.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to the subdomain on the AWS-hosted domain, let''s create a subdomain
    first, by executing the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The output of the previous command will list the name servers for the subdomain.
    You will need to log in to your registrar's settings page and create a new subdomain,
    providing the four name server records received from the previous command. You
    can find detailed instructions on how to edit the name servers for your domain
    in your specific registrar help guides.
  prefs: []
  type: TYPE_NORMAL
- en: The previous guides should make your cluster available under a specific domain
    or subdomain. For the rest of our chapter, however, we will be running the gossip-based
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Before we create anything on AWS, we must see what zones are available for use.
    You should know that Amazon EC2 is hosted in multiple locations world-wide. These
    locations are composed of regions and availability zones. Each region is a separate
    geographic area. Each region has multiple, isolated locations known as availability
    zones. You can pick the location you want, but first, you will need to check the
    zones availability. Let's do that now.
  prefs: []
  type: TYPE_NORMAL
- en: Checking the zones' availability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To list the zones available for the specific region, execute the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see on the following screenshot, AWS will give you the list of zones
    in the response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00120.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Creating the storage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our cluster needs to store its state somewhere. Kops uses Amazon S3 buckets
    for that purpose. An S3 bucket is a logical unit of storage in the **Amazon Web
    Services** (**AWS** ) object storage service, **Simple Storage Solution** (**S3**
    )*.* Buckets are used to store objects, which consist of data and metadata that
    describes the data. To create a bucket, execute the following `aws` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'As you will see on the following screenshot, AWS will give you back the concise
    information about the location of the store:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00121.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Having the store created, we will need to make it available for `kops` when
    creating a cluster. To do this, we need to export the bucket''s name into the
    `KOPS_STATE_STORE` environment variable to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: We are now ready to create a cluster.
  prefs: []
  type: TYPE_NORMAL
- en: As you remember, we are going to use a gossip-based cluster instead of configured
    DNS, so the name must end with `k8s.local` .
  prefs: []
  type: TYPE_NORMAL
- en: Creating a cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s first export our cluster name to the environment variable. This will
    be useful, because we are going to refer to the cluster''s name often. Execute
    the following command to export the cluster name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The `kops create cluster` is the command we are going to use to create our cluster.
    Note that this will not affect our Amazon EC2 instances yet. The outcome of the
    command will be just a local cluster template which we can review and edit before
    rolling out real, physical changes on the AWS.
  prefs: []
  type: TYPE_NORMAL
- en: 'The syntax of the command is very simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The command takes a lot of options; you can always find the up-to-date description
    on GitHub at [https://github.com/kubernetes/kops/blob/master/docs/cli/kops_create_cluster.md](https://github.com/kubernetes/kops/blob/master/docs/cli/kops_create_cluster.md)
    . Let''s focus on the most important ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Option** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `--master-count [number]` | Sets the number of master nodes. The default
    is one master node per master-zone. |'
  prefs: []
  type: TYPE_TB
- en: '| `--master-size [string]` | Sets instance size for masters, for example:`--master-size=t2.medium`
    . |'
  prefs: []
  type: TYPE_TB
- en: '| `--master-volume-size [number]` | Sets instance volume size for master nodes
    in gigabytes. |'
  prefs: []
  type: TYPE_TB
- en: '| `--master-zones [zone1,zone2]` | Specifies AWS zones in which to run masters
    (this must be an odd number). |'
  prefs: []
  type: TYPE_TB
- en: '| `--zones [zone1,zone2 ]` | Zones in which to run the cluster, for example:
    `--zones eu-central-1a,eu-central-1b` . |'
  prefs: []
  type: TYPE_TB
- en: '| `--node-count [number]` | Sets the number of nodes. |'
  prefs: []
  type: TYPE_TB
- en: '| `--node-size [string]` | Sets instance size for nodes, for example:`--node-size=t2.medium`
    . |'
  prefs: []
  type: TYPE_TB
- en: '| `--node-volume-size int32` | Sets instance volume size (in GB) for nodes.
    |'
  prefs: []
  type: TYPE_TB
- en: 'If you would like to make your cluster private (it''s public by default) you
    will need to consider using these options additionally:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Option** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `--associate-public-ip [true&#124;false]` | Specifies if you want your cluster
    to have a public IP assigned or not. |'
  prefs: []
  type: TYPE_TB
- en: '| `--topology [public&#124;private]` | Specifies the internal networking topology
    for the cluster, it can be `public` or `private` . |'
  prefs: []
  type: TYPE_TB
- en: '| `--bastion` | The `--bastion` flag enables a bastion instance group. The
    option is valid only with the private topology. It will generate a dedicated SSH
    jump host for SSH access to cluster instances. A jump host provides a point of
    entry into a private network of your cluster. It can be started and stopped to
    enable or disable inbound SSH communication from the internet. |'
  prefs: []
  type: TYPE_TB
- en: 'Let''s create our cluster now, using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'In the response, `kops` will list all the details of the configuration that
    has been created and suggest some next steps you can take with your new cluster
    configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00122.jpg)'
  prefs: []
  type: TYPE_IMG
- en: After running the command, `kops` will configure your `kubectl` Kubernetes client
    to point to your new cluster; this will be `my-rest-cluster.k8s.local` in our
    example.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we have said before, at this stage, only the cluster''s template is created,
    not the cluster itself. You can still change any option by editing your cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This will bring up the default editor you have defined in your shell, where
    you can see the cluster template that has been generated. It will contain a lot
    more settings, not only those you have specified when running the `cluster create`
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00123.jpg)'
  prefs: []
  type: TYPE_IMG
- en: If you are satisfied with your cluster template, it's time to spin it up to
    create real cloud-based resources, such as networks and EC2 instances. Once the
    infrastructure is ready, `kops` will install Kubernetes on the EC2 instances.
    Let's do it.
  prefs: []
  type: TYPE_NORMAL
- en: Starting up clusters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To start the cluster and spin up all the necessary EC2 instances, you will
    need to execute the `update` command. It''s recommended in the `kops` manual that
    you should do it first in the preview mode without the `--yes` switch. This will
    not spin up any EC2 instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'If all is looking correct, execute the update command with the `--yes` switch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '![](Image00124.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Your cluster is starting and should be ready in a few minutes. If you now log
    in into the WAS Management Console, you will see your EC2 instances starting up,
    as you can see in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00125.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You can also check the whole cluster state, issuing the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will contain information about the number and status of the cluster''s
    nodes, including the master node:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00126.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Of course, as the `kubectl` is now configured to act on our AWS cluster, we
    can list nodes using `kubectl get nodes` command, exactly the same as we did in
    the [Chapter 9](text00180.html) , *Working with Kubernetes API* , with `minikube`
    base cluster. Execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'You will be given the information about the name and status of your cluster''s
    nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00127.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Updating a cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`Kops` behaves similarly to `kubectl` ; you can edit the configuration files
    in the editor before actually doing any changes on the cluster. The `kops update`
    command will apply configuration changes, but will not modify the running infrastructure.
    To update the running cluster, you will need to execute the `rolling-update` command.
    The following will start the update or recreation process of the cluster''s infrastructure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Our fresh cluster is running, but it's empty. Let's deploy something.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the dashboard
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Having the cluster running, it would be nice to have a dashboard deployed,
    to see the status of your services, deployments, pods and so on. The dashboard
    is included in the `minikube` cluster by default, but on our brand new Amazon
    cluster we will need to install it manually. This is a straightforward process.
    As we have `kubectl` configured to act on the remote cluster, we can execute the
    following `kubectl create` command with the `kubernetes-dashboard.yaml` template
    as an input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The next thing would be to proxy the network traffic, using the following `kubectl
    proxy` command we already know:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'That''s it! After a while the dashboard will be deployed and we will be able
    to access it using the localhost address:'
  prefs: []
  type: TYPE_NORMAL
- en: '`http://localhost:8001/` , as you can see in the following screenshot, is the
    same dashboard we have already seen in the [Chapter 9](text00180.html) , *Working
    with Kubernetes API* :'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00128.jpg)'
  prefs: []
  type: TYPE_IMG
- en: From now on, you can use the `kubectl` and the dashboard to manage your cluster
    as we did before in the [Chapter 9](text00180.html) , *Working with Kubernetes
    API* . All the `kubectl create` commands will work the same as with the local
    cluster. This time, however, your software will go to the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you decide to remove the cluster, execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that if you just created the cluster template, without executing `kops
    update cluster ${NAME} --yes` first, you can also delete the cluster, as you can
    see in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00129.jpg)'
  prefs: []
  type: TYPE_IMG
- en: If the cluster is already created on Amazon, the process of deleting it will
    take longer, as all EC2 instances for master and worker nodes needs to be shutdown
    first.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have set up a cluster in the real cloud, Amazon AWS. `Kops`
    is one of the best tools that we have available right now to manage Kubernetes
    on AWS. Using it, you can easily create and manage clusters on AWS. It can be
    a test or a production-grade cluster; `kops` will make the creation and management
    of it a breeze.
  prefs: []
  type: TYPE_NORMAL
