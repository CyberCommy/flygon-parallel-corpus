- en: Working with Kernel Timers, Threads, and Workqueues
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
- en: What if the low-level specification for your device driver demands that, between
    the execution of `func_a()` and `func_b()`, there should be a 50-millisecond delay?
    Furthermore, depending on your circumstances, the delay should work when you're
    running in either process or interrupt contexts. What if, in another part of the
    driver, you require a monitoring function of some sort to be executed asynchronously
    and periodically (say, every second)? Or do you need to have a thread (or several
    threads) silently performing work in the background but within the kernel?
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: These are very common requirements in all kinds of software, including our corner
    of the universe – Linux kernel module (and driver) development! In this chapter,
    you will learn how to set up, understand, and use delays while running in kernel
    space, as well as how to work with kernel timers, kernel threads, and workqueues.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will learn how to optimally perform these tasks. In a
    nutshell, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Delaying for a given time in the kernel
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up and using kernel timers
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating and working with kernel threads
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using kernel workqueues
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's get started!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I assume that you have gone through the Preface section To get the most out
    of this book and have appropriately prepared a guest VM running Ubuntu 18.04 LTS
    (or a later stable release) and installed all the required packages. If not, I
    highly recommend you do this first. To get the most out of this book, I strongly
    recommend you first set up the workspace environment, including cloning this book''s
    GitHub repository for the code, and work on it in a hands-on fashion. The repository
    can be found here: [https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2](https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2/tree/main/ch5).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Delaying for a given time in the kernel
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Often, your kernel or driver code will need to wait for a given time before
    moving on to the next instruction. This can be achieved within the Linux kernel
    space via a set of delay APIs. Right from the outset, a key point to understand
    is that you can enforce a delay in two broad ways:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Delay via non-blocking or atomic APIs that will never cause a sleep process
    to occur (in other words, it will never schedule out)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Delay via blocking APIs that cause the current process context to sleep (in
    other words, by scheduling out)
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (As we covered in detail in the companion guide *Linux Kernel Programming,*
    our chapters on CPU scheduling  *Chapter 10,* *The CPU Scheduler – Part 1*, and
    *Chapter 11*, *The CPU Scheduler – Part 2*), putting a process context to sleep
    internally implies that the kernel's core `schedule()` function is invoked at
    some point, ultimately causing a context switch to occur. This leads up to a really
    important point (one we've mentioned previously!): you must never, ever invoke
    `schedule()` while running in an atomic or interrupt context of any sort.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Often, as is our case here with inserting delays, you have to figure out what
    context the code where you intend to insert a delay is running in. We covered
    this in the companion guide *Linux Kernel Programming -* *Chapter 6*, *Kernel
    Internals Essentials – Processes and Threads*, in the *Determining the context* section;
    please refer back to it if you're unclear. (We went into even more detail on this
    in [*Chapter 4*](cfd1ca5d-cd0b-451d-8a35-31e65a09d2e4.xhtml), *Handling Hardware
    Interrupts*.)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, think about this carefully: if you are indeed in an atomic (or interrupt)
    context, is there really a need to delay? The whole point of an atomic or interrupt
    context is that the execution within it is limited to an as-brief-as-possible
    duration; it is strongly recommended that you design it in this way. This implies
    that you don''t insert delays into atomic code unless you can''t avoid doing so.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '**Use the first type**: These are the non-blocking or atomic APIs that will
    never cause a sleep to occur. You should use this when your code is in an atomic
    (or interrupt) context and you really do require a non-blocking delay with a short
    duration; but how short is that? As a rule of thumb, use these APIs for non-blocking
    atomic delays that are 1 millisecond or less. Even if you need to delay for longer
    than a millisecond in an atomic context – say, within the code of an interrupt
    handler (*but why delay in an interrupt!?*) – use these `*delay()` APIs (the `*` character
    implies a wildcard; here, as you will see, it implies the `ndelay()`, `delay()`,
    and `mdelay()` routines).'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用第一种类型**：这些是永远不会导致休眠发生的非阻塞或原子API。当您的代码处于原子（或中断）上下文中，并且您确实需要一个短暂的非阻塞延迟时，您应该使用这些API；但是多短呢？作为一个经验法则，对于1毫秒或更短的非阻塞原子延迟使用这些API。即使您需要在原子上下文中延迟超过一毫秒
    - 比如，在中断处理程序的代码中（*但为什么要在中断中延迟！？*） - 使用这些`*delay()`API（`*`字符表示通配符；在这里，您将看到它表示`ndelay()`、`delay()`和`mdelay()`例程）。'
- en: '**Use the second type**: These are the blocking APIs that cause the current
    process context to sleep. You should use this when your code is in a process (or
    task) context, for delays that are blocking in nature and of a longer duration;
    in effect, for delays over a millisecond. These kernel APIs follow the form `*sleep()`.
    (Again, without going into too much detail, think about this: if you are in a
    process context *but* within the critical section of a spinlock, it''s an atomic
    context – if you must incorporate a delay, then you must use the `*delay()` APIs!
    We''ll cover spinlocks and much more in the last two chapters of this book.)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用第二种类型**：这些是导致当前进程上下文休眠的阻塞API。当您的代码处于进程（或任务）上下文中，需要阻塞性较长时间的延迟时，您应该使用这些；实际上，对于超过一毫秒的延迟。这些内核API遵循`*sleep()`的形式。（再次，不详细讨论，想想这个：如果您在进程上下文中，但在自旋锁的临界区内，那就是一个原子上下文
    - 如果您必须加入延迟，那么您必须使用`*delay()`API！我们将在本书的最后两章中涵盖自旋锁等更多内容。）'
- en: Now, let's look at these kernel APIs and see how they're used. We'll begin by
    looking at `*delay()` atomic APIs.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看这些内核API，看看它们是如何使用的。我们将首先看一下`*delay()`原子API。
- en: Understanding how to use the *delay() atomic APIs
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解如何使用*delay()原子API
- en: 'Without further ado, let''s take a look at a table that quickly summarizes
    the available (to us module authors) non-blocking or atomic `*delay()` kernel
    APIs; *they''re meant to be used in any kind of atomic or interrupt context where
    you cannot block or sleep* (or invoke `schedule()`):'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 话不多说，让我们来看一张表，快速总结一下可用的（对于我们模块作者来说）非阻塞或原子`*delay()`内核API；*它们旨在用于任何类型的原子或中断上下文，其中您不能阻塞或休眠*（或调用`schedule()`）：
- en: '| **API** | **Comment** |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| **API** | **注释** |'
- en: '| `ndelay(ns);` | Delay for `ns` nanoseconds. |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| `ndelay(ns);` | 延迟`ns`纳秒。 |'
- en: '| `udelay(us);` | Delay for `us` microseconds. |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| `udelay(us);` | 延迟`us`微秒。 |'
- en: '| `mdelay(ms);` | Delay for `ms` milliseconds. |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| `mdelay(ms);` | 延迟`ms`毫秒。 |'
- en: Table 5.1 – The *delay() non-blocking APIs
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.1 - *delay()非阻塞API
- en: 'There are a few points to note regarding these APIs, their internal implementation,
    and their usage:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这些API、它们的内部实现和使用，有一些要注意的地方：
- en: Always include the `<linux/delay.h>` header when using these macros/APIs.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在使用这些宏/API时，始终包括`<linux/delay.h>`头文件。
- en: You are expected to call an appropriate routine based on the time you must delay
    for; for example, if you need to perform an atomic non-blocking delay of, say,
    30 milliseconds, you should call `mdelay(30)` and not`udelay(30*1000)`. The kernel
    code mentions this very point: `linux/delay.h` – *"Using udelay() for intervals
    greater than a few milliseconds can risk overflow for high loops_per_jiffy (high
    bogomips) machines ...".*
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你应该根据你需要延迟的时间调用适当的例程；例如，如果你需要执行一个原子非阻塞延迟，比如30毫秒，你应该调用`mdelay(30)`而不是`udelay(30*1000)`。内核代码提到了这一点：`linux/delay.h`
    - *"对于大于几毫秒的间隔使用udelay()可能会在高loops_per_jiffy（高bogomips）的机器上出现溢出风险...".*
- en: 'The internal implementation of these APIs, like many on Linux, is nuanced:
    there is a higher-level abstracted implementation for these functions (or macros,
    as the case may be) in the `<linux/delay.h>` header; there is often a low-level
    arch-specific implementation within an arch-specific header (`<asm-<arch>/delay.h>`
    *or *`<asm-generic/delay.h>`; where `arch`, of course, means CPU) that will automatically
    override the high-level version at call time (the linker will ensure this).'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些API的内部实现，就像Linux上的许多API一样，是微妙的：在`<linux/delay.h>`头文件中，这些函数（或宏）有一个更高级的抽象实现；在特定于体系结构的头文件中（`<asm-<arch>/delay.h>`或`<asm-generic/delay.h>`；其中`arch`当然是CPU），通常会有一个特定于体系结构的低级实现，它会在调用时自动覆盖高级版本（链接器会确保这一点）。
- en: 'In the current implementation, these APIs ultimately boil down to wrappers
    over `udelay()`; this function itself boils down to a tight assembly loop that
    performs what''s called "busy looping"! (for x86, the code can be found in `arch/x86/lib/delay.c:__const_udelay()`).
    Without going into the gory details, early in the boot process, the kernel calibrates
    a couple of values: the so-called **bogomips –** bogus MIPS – and **loops per
    jiffy** (**lpj**) values. Essentially, the kernel figures out, on that particular
    system, how many times a loop must be iterated over in order for 1 timer tick
    or a jiffy to elapse. This value is known as the system''s bogomips value and
    can be seen in the kernel log. For example, on my Core-i7 laptop, it''s as follows:'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在当前的实现中，这些API最终都会转换为对`udelay()`的包装；这个函数本身会转换为一个紧凑的汇编循环，执行所谓的“忙循环”！（对于x86，代码可以在`arch/x86/lib/delay.c:__const_udelay()`中找到）。不详细讨论，早期在引导过程中，内核会校准一些值：所谓的**bogomips
    -**虚假MIPS - 和**每个jiffy的循环**（**lpj**）值。基本上，内核会在那个特定系统上找出，为了使一个定时器滴答或一个jiffy经过多少次循环。这个值被称为系统的bogomips值，并且可以在内核日志中看到。例如，在我的Core-i7笔记本上，它是这样的：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: For delays over `MAX_UDELAY_MS` (set to 5 ms), the kernel will internally call
    the `udelay()` function in a loop.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于超过`MAX_UDELAY_MS`（设置为5毫秒）的延迟，内核将在循环中内部调用`udelay()`函数。
- en: 'Remember the `*delay()` APIs must be used when you require a delay in any type
    of atomic context, such as an interrupt handler (top or bottom half), as they
    guarantee that no sleep – and thus no call to `schedule()` – ever occurs. A reminder
    (we mentioned this point in [*Chapter 4*](cfd1ca5d-cd0b-451d-8a35-31e65a09d2e4.xhtml), *Handling
    Hardware Interrupts*): `might_sleep()` is used as a debug aid; the kernel (and
    drivers) internally uses the `might_sleep()` macro in places in the code base
    where the code runs in the process context; that is, where it can sleep. Now,
    if `might_sleep()` is ever invoked within an atomic context, that''s just plain
    wrong – a noisy printk stack trace is then emitted, thus helping you catch these
    issues early and fix them. You can use these `*delay()` APIs in the process context
    as well.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，`*delay()` APIs必须在任何类型的原子上下文中使用，例如中断处理程序（顶部或底部），因为它们保证不会发生睡眠 - 因此也不会调用`schedule()`。提醒一下（我们在[*第4章*](cfd1ca5d-cd0b-451d-8a35-31e65a09d2e4.xhtml)中提到过这一点，*处理硬件中断*）：`might_sleep()`用作调试辅助工具；内核（和驱动程序）在代码库中的某些地方内部使用`might_sleep()`宏，即代码在进程上下文中运行时；也就是说，它可以睡眠。现在，如果`might_sleep()`在原子上下文中被调用，那就是完全错误的
    - 然后会发出一个嘈杂的`printk`堆栈跟踪，从而帮助您及早发现并修复这些问题。您也可以在进程上下文中使用这些`*delay()` APIs。
- en: In these discussions, you will often come across the `jiffies` kernel variable;
    essentially, think of `jiffies` as a global unsigned 64-bit value that is incremented
    on every timer interrupt (or timer tick; it's internally protected against overflow).
    Thus, the continually incrementing variable is used as a way to measure uptime,
    as well as a means of implementing simple timeouts and delays.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些讨论中，您经常会遇到`jiffies`内核变量；基本上，将`jiffies`视为一个全局的无符号64位值，它在每次定时器中断（或定时器滴答）时递增（它在内部受到溢出的保护）。因此，这个不断递增的变量被用作测量正常运行时间的一种方式，以及实现简单超时和延迟的手段。
- en: Now, let's look at the second type of delay APIs available – the blocking type.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看可用的第二种类型的延迟APIs - 阻塞类型。
- en: Understanding how to use the *sleep() blocking APIs
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解如何使用*sleep*() 阻塞APIs
- en: 'Let''s look at another table that quickly summarizes the available (to us module
    authors) blocking `*sleep*()` kernel APIs; these are *only meant to be used in
    the process context when it''s safe to sleep*; that is, where the invocation of
    `schedule()` is not a problem. In other words, the delay is implemented by the
    process context actually going to sleep for the duration of the delay and is then
    woke up when it''s done:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再看一个表，它快速总结了可用的（对我们模块作者来说）阻塞`*sleep*()`内核APIs；这些只能在进程上下文中使用，当安全睡眠时；也就是说，在进程上下文实际上进入睡眠状态的延迟期间，然后在完成时唤醒：
- en: '| **API** | **Internally "backed by"** | **Comment** |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| **API** | **内部“支持”** | **评论** |'
- en: '| `usleep_range(umin, umax);` | `hrtimers` (high-resolution timers) | Sleep
    for between `umin` and `umax` microseconds. Use where the wakeup time is flexible.
    This is the **recommended API** to use. |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '`usleep_range(umin, umax);` | `hrtimers`（高分辨率定时器） | 睡眠介于`umin`和`umax`微秒之间。在唤醒时间灵活的情况下使用。这是**推荐的API**。'
- en: '| `msleep(ms);` | `jiffies`/`legacy_timers` | Sleep for `ms` milliseconds.
    Typically meant for a sleep with a duration of 10 ms or more. |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '`msleep(ms);` | `jiffies`/`legacy_timers` | 睡眠`ms`毫秒。通常用于持续时间为10毫秒或更长的睡眠。'
- en: '| `msleep_interruptible(ms);` | `jiffies`/`legacy_timers` | An interruptible
    variant of `msleep(ms);`. |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '`msleep_interruptible(ms);` | `jiffies`/`legacy_timers` | `msleep(ms);`的可中断变体。'
- en: '| `ssleep(s);` | `jiffies`/`legacy_timers` | Sleep for `s` seconds. This is meant
    for sleeps > 1 s (wrapper over `msleep()`). |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '`ssleep(s);` | `jiffies`/`legacy_timers` | 睡眠`s`秒。这是用于睡眠时间大于1秒的情况（对`msleep()`的封装）。'
- en: Table 5.2 – The *sleep*() blocking APIs
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.2 - *sleep*() 阻塞APIs
- en: 'There''s a few points to note regarding these APIs, their internal implementation,
    and their usage:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这些API、它们的内部实现和使用，有一些要注意的地方：
- en: Ensure you include the `<linux/delay.h>` header when using these macros/APIs.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在使用这些宏/ API时，请确保包含`<linux/delay.h>`头文件。
- en: All these `*sleep()` APIs are internally implemented in such a manner that they *cause
    the current process context to sleep *(that is, by internally invoking `schedule()`);
    thus, of course, they must only ever be invoked in the process context when it's
    "safe to sleep". Again, just because your code is in the process context does
    not necessarily mean it's safe to sleep; for example, the critical section of
    a spinlock is atomic; thus, you must not invoke the aforementioned `*sleep()`
    APIs there!
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有这些`*sleep()` API都是以这样一种方式内部实现的，即它们会使当前进程上下文进入睡眠状态（也就是通过内部调用`schedule()`）；因此，当进程上下文“安全睡眠”时，它们必须只能被调用。再次强调，仅仅因为您的代码在进程上下文中，并不一定意味着它是安全的睡眠；例如，自旋锁的临界区是原子的；因此，在那里您不能调用上述的`*sleep()`
    API！
- en: We mentioned that `usleep_range()` is the **preferred/recommended API** to use
    when you want a short sleep – but why? This will become clearer in the *Let's
    try it – how long do delays and sleeps really take?* section.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们提到`usleep_range()`是**首选/推荐的API**，当您需要短暂的睡眠时使用它 - 但是为什么？这将在*让我们试试 - 延迟和睡眠实际需要多长时间？*部分中变得更清晰。
- en: 'As you are aware, sleeps on Linux can be of two types: interruptible and uninterruptible.
    The latter means that no signal task can "disturb" the sleep. So, when you invoke
    `msleep(ms);`,i t puts the current process context to sleep for `ms` by internally
    invoking the following:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所知，Linux上的睡眠可以分为两种类型：可中断和不可中断。后者意味着没有信号任务可以“打扰”睡眠。因此，当您调用`msleep(ms);`时，它会通过内部调用以下内容将当前进程上下文置于睡眠状态，持续`ms`：
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The `schedule_timeout()` routine works by setting up a kernel timer (our next
    topic!) that will expire in the desired time, then immediately putting the process
    to sleep by calling `schedule()`! (For the curious, have a peek at its code here: `kernel/time/timer.c:schedule_timeout()`.)
    The `msleep_interruptible()` implementation is very similar, except that it calls `__set_current_state(TASK_INTERRUPTIBLE);`.
    As a design heuristic, follow the UNIX paradigm of *provide mechanism, not policy*;
    this way, calling `msleep_interruptible()` might be a good idea in situations
    where, if the userspace app aborts the work (by the user pressing `^C` perhaps),
    the kernel or driver obediently releases the task: its process context is awoken,
    it runs the appropriate signal handler, and life continues. In situations where
    it''s important that the kernel space is not disturbed by user-generated signals,
    use the `msleep()` variant.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`schedule_timeout()`例程通过设置一个内核定时器（我们下一个话题！）来工作，该定时器将在所需的时间内到期，然后立即通过调用`schedule()`将进程置于睡眠状态！（对于好奇的人，可以在这里查看它的代码：`kernel/time/timer.c:schedule_timeout()`。）`msleep_interruptible()`的实现非常类似，只是调用了`__set_current_state(TASK_INTERRUPTIBLE);`。作为设计启发，遵循*提供机制，而不是策略*的UNIX范式；这样，调用`msleep_interruptible()`可能是一个好主意，因为在用户空间应用程序中终止工作（例如用户按下`^C`）时，内核或驱动程序会顺从地释放任务：它的进程上下文被唤醒，运行适当的信号处理程序，生活继续。在内核空间不受用户生成的信号干扰很重要的情况下，使用`msleep()`变体。'
- en: 'Again, as a rule of thumb, use the following APIs, depending on the duration
    of the delay:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，作为一个经验法则，根据延迟的持续时间使用以下API：
- en: '**For delays of over 10 milliseconds**: `msleep()` or `msleep_interruptible()`'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**超过10毫秒的延迟**：`msleep()`或`msleep_interruptible()`'
- en: '**For delays of over 1 second**: `ssleep()`'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**超过1秒的延迟**：`ssleep()`'
- en: As you might expect, `ssleep()` is a simple wrapper over `msleep();` and becomes `msleep(seconds
    * 1000);`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所期望的，`ssleep()`是`msleep()`的简单包装；并且变成了`msleep(seconds * 1000);`。
- en: 'One simple way to implement the (approximate) equivalent of the user space
    `sleep(3)` API can be seen in our `convenient.h` header; at heart, it employs
    the `schedule_timeout()` API:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 实现（近似）等效于用户空间`sleep(3)`API的一种简单方法可以在我们的`convenient.h`头文件中看到；本质上，它使用了`schedule_timeout()`API：
- en: '[PRE2]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now that you''ve learned how to delay (yes, smile please), let''s move on and
    learn a useful skill: timestamping kernel code. This allows you to quickly calculate
    how long a particular piece of code takes to execute.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经学会了如何延迟（是的，请微笑），让我们继续学习一个有用的技能：给内核代码加上时间戳。这样可以快速计算特定代码执行所需的时间。
- en: Taking timestamps within kernel code
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在内核代码中获取时间戳
- en: 'It''s important to be able to take an accurate timestamp as kernels open employ
    this facility. For example, the `dmesg(1)` utility shows the time since the system
    booted in `seconds.microseconds` format; Ftrace traces typically show the time
    a function takes to execute. When in user mode, we often employ the `gettimeofday(2)`
    system call to take a timestamp. Within the kernel, several interfaces exist;
    commonly, the `ktime_get_*()` family of routines is employed for the purpose of
    obtaining accurate timestamps. For our purposes, the following routine is useful:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 能够获取准确的时间戳对内核开放使用这一设施非常重要。例如，`dmesg(1)`实用程序以`seconds.microseconds`格式显示系统启动以来的时间；Ftrace跟踪通常显示函数执行所需的时间。在用户模式下，我们经常使用`gettimeofday(2)`系统调用来获取时间戳。在内核中，存在多个接口；通常使用`ktime_get_*()`系列例程来获取准确的时间戳。对于我们的目的，以下例程很有用：
- en: '[PRE3]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This routine internally queries the wall (clock) time via the `ktime_get_real()`
    API and then converts the result into a nanosecond quantity. We won't bother with
    the internal details here. Also, several variants of this API are available; for
    example, `ktime_get_real_fast_ns()`, `ktime_get_real_ts64()`, and so on. The former
    is both fast and NMI-safe.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例程通过`ktime_get_real()`API内部查询墙（时钟）时间，然后将结果转换为纳秒数量。我们不会在这里烦恼内部细节。此外，这个API还有几个变体；例如，`ktime_get_real_fast_ns()`，`ktime_get_real_ts64()`等。前者既快速又NMI安全。
- en: 'Now that you know how to get a timestamp, you can calculate how long some code
    takes to execute to a good degree of accuracy, with nanosecond resolution no less!
    You can use the following pseudocode to achieve this:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你知道如何获取时间戳，你可以计算一段代码执行所需的时间，而且精度相当高，甚至可以达到纳秒级别的分辨率！你可以使用以下伪代码来实现这一点：
- en: '[PRE4]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here, the time taken for the (fictional) `foo()` and `bar()` functions to execute
    is calculated, and the result – in nanoseconds – is available in the `time_taken_ns` variable.
    The `<linux/ktime.h>` kernel header itself includes the `<linux/timekeeping.h>`
    header, which is where the `ktime_get_*()` family of routines is defined.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，计算了（虚构的）`foo()`和`bar()`函数执行所需的时间，并且结果（以纳秒为单位）存储在`time_taken_ns`变量中。`<linux/ktime.h>`内核头文件本身包括了`<linux/timekeeping.h>`头文件，其中定义了`ktime_get_*()`系列例程。
- en: A macro to help you calculate the time taken between two timestamps has been
    provided in our `convenient.h` header file: `SHOW_DELTA(later, earlier);`. Ensure
    that you pass the later timestamp as the first parameter and the first timestamp
    as the second parameter.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的`convenient.h`头文件中提供了一个宏来帮助你计算两个时间戳之间的时间：`SHOW_DELTA(later, earlier);`。确保将后一个时间戳作为第一个参数，第一个时间戳作为第二个参数。
- en: The code example in the next section will help us employ this kind of approach.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节的代码示例将帮助我们采用这种方法。
- en: Let's try it – how long do delays and sleeps really take?
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 让我们来试试看-延迟和睡眠实际上需要多长时间？
- en: By now, you know how to use the `*delay()` and `*sleep()` APIs to construct
    delays and sleeps (non-blocking and blocking, respectively). Hang on, though –
    we haven't really tried it out in a kernel module. Not only that, are the delays
    and sleeps as accurate as we have been led to believe? Let's, as usual, be *empirical*
    (this is important!) and not make any assumptions. Let's actually try it out for
    ourselves!
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经知道如何使用`*delay()`和`*sleep()`API来构建延迟和睡眠（非阻塞和阻塞）。不过，我们还没有真正在内核模块中尝试过。而且，延迟和睡眠是否像我们所相信的那样准确呢？让我们像往常一样*经验主义*（这很重要！）而不是做任何假设。让我们亲自尝试一下！
- en: 'The demo kernel module we''ll be looking at in this subsection performs two
    kinds of delays, in order:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: First, it employs the `*delay()` routines (which you learned about in the *Understanding
    how to use the *delay() atomic **APIs* section) to implement atomic non-blocking
    delays of 10 ns, 10 us, and 10 ms.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, it employs the `*sleep()` routines (which you learned about in the *Understanding
    how to use the *sleep() blocking **APIs* section) to implement blocking delays
    of 10 us, 10 ms, and 1 second.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We call the code for this like so:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here, `DILLY_DALLY()` is a custom macro. Its implementation is as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here, we have implemented the time delta calculation trivially; a good implementation
    will involve checking that the value of `t2` is greater than `t1`, that no overflow
    occurs, and so on.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: 'We invoke it, for various delays and sleeps, within our kernel module''s `init`
    function, like this:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here''s some sample output when the kernel module is run on our trusty x86_64
    Ubuntu VM:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f9d48d06-517c-4f1c-8883-91e2d9d6f34e.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 – A partial screenshot showing the output of our delays_sleeps.ko
    kernel module
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: 'Carefully study the preceding output; it''s peculiar that both the `udelay(10)` and
    `mdelay(10)` routines seem to complete their execution *before *the desired delay
    period has expired (in our sample output, in `9 us` and `9 ms`, respectively)!
    How come? The reality is that **the `*delay()` routines tend to finish earlier**.
    This fact is documented within the kernel source. Let''s take a look at the relevant
    portion of code here (it''s self-explanatory):'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `*sleep()` routines have the reverse characteristic; they pretty much always
    tend to **sleep for *longer *than asked**. Again, these are expected issues in
    a non-real-time OS such as standard Linux.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: 'You can **mitigate these issues** in a few ways:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: 'On standard Linux, in user mode, do the following:'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First of all, it's best to use the **High-Resolution Timer (HRT)** interfaces
    for high accuracy. This, again, is code that's been merged from the RTL project
    into mainstream Linux (way back in 2006). It supports timers that require a resolution
    of less than a single *jiffy *(which, as you know, is tightly coupled to the timer
    "tick", the kernel `CONFIG_HZ` value); for example, with the `HZ` value being
    100, a jiffy is 1000/100 = 10 ms; with `HZ` being 250, a jiffy is 4 ms, and so
    on.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you've done this, why not employ the soft RT scheduling features of Linux?
    Here, you can specify a scheduling policy of `SCHED_FIFO` or `SCHED_RR` and a
    high priority for your user mode thread (the range is `1` to `99`; we covered
    these details in the companion guide *Linux Kernel Programming -* *Chapter 10,*
    *The CPU Scheduler – Part 1*).
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Most modern Linux systems will have HRT support. However, how do you exploit
    it? This is simple: you''re recommended to write your timer code *in user space* and
    employ standard POSIX timer APIs (such as the `timer_create(2)` and `timer_settime(2)` system
    calls). Since this book is concerned with kernel development, we won''t delve
    into these user space APIs here. In fact, this topic was covered in some detail
    in my earlier book, *Hands-On System Programming with Linux*, in *Chapter 13,
    Timers*, in the *The newer POSIX (interval) timers mechanism* section.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: The kernel developers have taken the trouble to clearly document some excellent
    recommendations for when you're using these delay and sleep APIs within the kernel.
    It's really important that you browse through this document within the official
    kernel documentation: [https://www.kernel.org/doc/Documentation/timers/timers-howto.rst](https://www.kernel.org/doc/Documentation/timers/timers-howto.rst).
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configure and build the Linux OS as an RTOS; this will significantly reduce
    scheduling "jitter" (we covered this topic in detail in the companion guide *Linux
    Kernel Programming -* *Chapter 11,* *The CPU Scheduler – Part 2*, in the *Converting
    mainline Linux into an RTOS *section).
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Interestingly, using our "better" Makefile''s checkpatch target can be a real
    boon. Let''s take a look at what it (the kernel''s checkpatch Perl script) has
    caught (first ensure you''re in the correct source directory):'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，使用我们“更好”的Makefile的checkpatch目标可能会带来真正的好处。让我们看看它（内核的checkpatch Perl脚本）已经捕捉到了什么（首先确保你在正确的源目录中）：
- en: '[PRE9]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: That's really good! Ensure that you use the targets in our "better" `Makefile` (we
    covered this in detail in the companion guide *Linux Kernel Programming -* *Chapter
    5, Writing Your First Kernel Module LKMs – Part 2*, in the *A "better" Makefile
    template for your kernel modules* section).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这真的很好！确保你使用我们“更好”的`Makefile`中的目标（我们在伴随指南*Linux内核编程*的*第5章，编写你的第一个内核模块LKM - 第2部分*中详细介绍了这一点，在*为你的内核模块提供一个“更好”的Makefile模板*部分）。
- en: With that, we've finished looking at kernel delays and sleeping within the kernel.
    With this as a base, you shall now learn how to set up and use kernel timers,
    kernel threads, and workqueues in the remaining sections of this chapter.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，我们已经完成了对内核延迟和内核内睡眠的研究。有了这个基础，你现在将学习如何在本章的其余部分设置和使用内核定时器、内核线程和工作队列。
- en: The "sed" drivers – to demo kernel timers, kthreads, and workqueues
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: “sed”驱动程序——演示内核定时器、内核线程和工作队列
- en: To make this chapter more interesting and hands-on, we shall begin evolving
    a miscellaneous class character "driver" called a **simple encrypt decrypt** –
    or **sed** for short – driver (not to be confused with the well-known `sed(1)`
    utility). No, you won't get a grand prize for guessing that it provides some kind
    of – very simplistic – text encryption/decryption support.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使本章更有趣和实用，我们将开始演变一个名为**简单加密解密**的杂项字符“驱动程序”（简称**sed**驱动程序）（不要与著名的`sed(1)`实用程序混淆）。不，你猜对了也不会得到大奖，它提供了一些非常简单的文本加密/解密支持。
- en: The point here is that we shall imagine that in the specification for this driver,
    one clause demands that the work (practically speaking, the encryption/decryption
    functionality) is carried out within a given time interval – in effect, *within
    a given deadline*. In order to check this, we shall design our driver so that
    it has a kernel timer that will expire in the given time interval; the driver
    will check that the functionality does indeed complete within this time constraint!
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的重点是，我们应该想象在这个驱动程序的规范中，有一个条款要求工作（实际上是加密/解密功能）在给定的时间间隔内完成——实际上是*在给定的截止日期内*。为了检查这一点，我们将设计我们的驱动程序，使其具有一个内核定时器，在给定的时间间隔内到期；驱动程序将检查功能确实在这个时间限制内完成！
- en: 'We shall evolve a series of `sed` drivers and their user space counterparts
    (apps):'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将演变一系列`sed`驱动程序及其用户空间对应程序（应用程序）：
- en: 'The first driver – the `sed1` driver and user mode app (`ch5/sed1`) – will
    perform what we just described: the demo user mode app will employ `ioctl` system
    calls to interface with the driver and get the encrypt/decrypt message functionality
    going. The driver will focus on a kernel timer that we will set up to expire by
    the given deadline. If it does expire, we deem the operation to have failed; if
    not, the timer is canceled and the operation is a success.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个驱动程序——`sed1`驱动程序和用户模式应用程序（`ch5/sed1`）——将执行我们刚才描述的操作：演示用户模式应用程序将使用`ioctl`系统调用与驱动程序进行接口，并启动加密/解密消息功能。驱动程序将专注于一个内核定时器，我们将设置它在给定的截止日期前到期。如果它到期了，我们认为操作失败；如果没有，定时器被取消，操作就成功了。
- en: The second version, `sed2` (`ch5/sed2`), will do the same as `sed1`, except
    that the actual encrypt/decrypt message functionality here will be carried out
    in the context of a separately created kernel thread! This changes the design
    of the project.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个版本，`sed2`（`ch5/sed2`），将执行与`sed1`相同的操作，只是这里实际的加密/解密消息功能将在一个单独创建的内核线程的上下文中执行！这改变了项目的设计。
- en: The third version, `sed3` (`ch5/sed3`), will again do the same as `sed1` and
    `sed2`, except that this time the actual encrypt/decrypt message functionality
    will be carried out by a kernel workqueue!
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三个版本，`sed3`（`ch5/sed3`），将再次执行与`sed1`和`sed2`相同的操作，只是这次实际的加密/解密消息功能将由内核工作队列执行！
- en: Now that you have learned how to perform delays (both atomic and blocking) and
    capture timestamps, let's learn how to set up and use kernel timers.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经学会了如何执行延迟（原子和阻塞）和捕获时间戳，让我们学习如何设置和使用内核定时器。
- en: Setting up and using kernel timers
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置和使用内核定时器
- en: A **timer** provides software with a means of being asynchronously notified
    when a designated amount of time has passed. All kinds of software, both in user
    and kernel space, require timers; this commonly includes network protocol implementations,
    block layer code, device drivers, and various kernel subsystems. This timer provides
    a means of asynchronous notification, thus allowing the driver to execute work
    in parallel with the running timer. An important question that arises is, *how
    will I know when the timer expires?* In user space apps, typically, the kernel
    sends a signal to the relevant process (the signal is typically `SIGALRM`).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**定时器**提供了软件在指定时间过去时异步通知的手段。各种软件，无论是在用户空间还是内核空间，都需要定时器；这通常包括网络协议实现、块层代码、设备驱动程序和各种内核子系统。这个定时器提供了异步通知的手段，从而允许驱动程序与运行的定时器并行执行工作。一个重要的问题是，*我怎么知道定时器何时到期？*在用户空间应用程序中，通常情况下，内核会向相关进程发送一个信号（信号通常是`SIGALRM`）。'
- en: In kernel space, it's a bit nuanced. As you will know from our discussion on
    top and bottom halves for hardware interrupts (see *Chapter 4, Handling Hardware
    Interrupts*, the *Understanding and using top and bottom halves* section), after
    the timer interrupt's top half (or ISR) completes, the kernel will ensure it runs
    the timer interrupt bottom half or timer softirq (as we showed in the table in [Chapter
    4](cfd1ca5d-cd0b-451d-8a35-31e65a09d2e4.xhtml), *Handling Hardware Interrupts*
    section* Available softirqs and what they are for*). This is a very high priority
    softirq called `TIMER_SOFTIRQ`. This softirq is what consumes expired timers!
    In effect – and this is very important to understand – your timer's "callback"
    function – the function that will run when the timer expires – is run by the timer
    softirq *and thus runs in atomic (interrupt) context*. Thus, it's limited in what
    it can and cannot do (again, this was explained in detail in *Chapter 4*, *Handling
    Hardware Interrupts*).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在内核空间中，这有点微妙。正如您从我们对硬件中断的上半部分和下半部分的讨论中所了解的（请参阅*第4章，处理硬件中断*，*理解和使用上半部分和下半部分*部分），在定时器中断的上半部分（或ISR）完成后，内核将确保运行定时器中断的下半部分或定时器softirq（正如我们在[第4章](cfd1ca5d-cd0b-451d-8a35-31e65a09d2e4.xhtml)中所示，*处理硬件中断*部分*可用的softirq及其用途*）。这是一个非常高优先级的softirq，称为`TIMER_SOFTIRQ`。这个softirq就是消耗已到期的定时器！实际上-这一点非常重要-您的定时器的“回调”函数-定时器到期时将运行的函数-由定时器softirq运行*因此在原子（中断）上下文中运行*。因此，它在能够和不能做的方面受到限制（同样，这在*第4章*，*处理硬件中断*中有详细解释）。
- en: In the following section, you will learn how to set up and use a kernel timer.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将学习如何设置和使用内核定时器。
- en: Using kernel timers
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用内核定时器
- en: 'In order to use a kernel timer, you must follow a few steps. Here''s what to
    do in a nutshell (we''ll discuss this in more detail afterward):'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用内核定时器，您必须遵循一些步骤。简而言之，要做的是（我们稍后会详细讨论）：
- en: 'Initialize the timer metadata structure (`struct timer_list`) with the `timer_setup()`
    macro. The key items that get initialized here are as follows:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`timer_setup()`宏初始化定时器元数据结构（`struct timer_list`）。这里初始化的关键项目如下：
- en: The time to expire by (that value that `jiffies` should reach for the timer
    to expire)
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 到期时间（`jiffies`应达到的值，定时器才会到期）
- en: The function to invoke when the timer expires – in effect, the timer "callback"
    function
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定时器到期时要调用的函数-实际上是定时器的“回调”函数
- en: Write the code for your timer callback routine.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写定时器回调例程的代码。
- en: When appropriate, "arm" the timer – that is, have it start – by invoking the
    `add_timer()` (or `mod_timer()`) function.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在适当的时候，“启动”定时器-也就是，通过调用`add_timer()`（或`mod_timer()`）函数来启动。
- en: When the timer times out (expires), the OS will automatically invoke your timer's
    callback function (the one you set up in *step 2*); remember, it will be running
    in the timer softirq or an atomic or interrupt context.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当定时器超时（到期）时，操作系统将自动调用您的定时器回调函数（在*步骤2*中设置的函数）；请记住，它将在定时器softirq或原子或中断上下文中运行。
- en: (Optional) *Timers are not cyclic, they are one-time by default*. To have your
    timer run again, you will have to invoke the `mod_timer()` API; this is how you
    can set up an interval timer – one that times out at a given fixed time interval.
    If you don't perform this step, your timer will be a one-shot timer - it will
    count down and expire exactly once.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （可选）*定时器默认不是循环的，它们默认是一次性的*。要使定时器再次运行，您将需要调用`mod_timer()` API；这是如何设置间隔定时器-在给定的固定时间间隔后超时。如果不执行此步骤，您的定时器将是一次性定时器-它将倒计时并到期一次。
- en: When you are done, delete the timer with `del_timer[_sync]()`; this can also
    be used to cancel the timeout. It returns a value denoting whether a pending timer
    has been deactivated or not; that is, it returns `1` for an active timer or `0`
    for an inactive timer being canceled.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，使用`del_timer[_sync]()`删除定时器；这也可以用于取消超时。它返回一个值，表示是否已停用挂起的定时器；也就是说，对于活动定时器返回`1`，对于被取消的非活动定时器返回`0`。
- en: 'The `timer_list` data structure is the one that''s relevant to our work here;
    within it, the relevant members (the module/driver authors) are shown:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`timer_list`数据结构是我们这里相关的；其中，相关成员（模块/驱动程序作者）如下所示：'
- en: '[PRE10]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Use the `timer_setup()` macro to initialize it:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`timer_setup()`宏进行初始化：
- en: '[PRE11]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The parameters of `timer_setup()` are as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '`timer_setup()`的参数如下：'
- en: '`@timer`: The pointer to the `timer_list` data structure (this should be allocated
    memory first; also, prefixing the formal parameter name with an `@` is a common
    convention).'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`@timer`：指向`timer_list`数据结构的指针（这应该首先分配内存；另外，用`@`作为形式参数名的前缀是一种常见的约定）。'
- en: '`@callback`: The pointer to the callback function. This is the function that
    the OS invokes (in the softirq context) when the timer expires. Its signature
    is `void (*function)(struct timer_list *);`. The parameter you receive in the
    callback function is the pointer to the `timer_list` data structure. So, how can
    we pass and access some arbitrary data within our timer callback? We''ll answer
    this question shortly.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`@callback`：回调函数的指针。这是操作系统在定时器到期时调用的函数（在softirq上下文中）。它的签名是`void (*function)(struct
    timer_list *);`。回调函数中接收的参数是指向`timer_list`数据结构的指针。那么，我们如何在定时器回调中传递和访问一些任意数据呢？我们很快就会回答这个问题。'
- en: '`@flags`: These are the timer flags. We typically pass this as `0` (implying
    no special behavior). The flags you can specify are `TIMER_DEFERRABLE`, `TIMER_PINNED`, and `TIMER_IRQSAFE`.
    Let''s look at both in the kernel source code:'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`@flags`：这些是定时器标志。我们通常将其传递为`0`（意味着没有特殊行为）。您可以指定的标志是`TIMER_DEFERRABLE`、`TIMER_PINNED`和`TIMER_IRQSAFE`。让我们在内核源代码中看一下：'
- en: '[PRE12]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Using the `TIMER_DEFERRABLE` flag is useful when power consumption must be watched
    (such as on a battery-backed device). The third flag, `TIMER_IRQSAFE`, is special-purpose
    only; avoid using it.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在必要时，使用`TIMER_DEFERRABLE`标志是有用的，当需要监视功耗时（例如在备电设备上）。第三个标志`TIMER_IRQSAFE`只是特定目的；避免使用它。
- en: 'Next, use the `add_timer()` API to arm, or start, the timer. Once called, the
    timer is "live" and starts counting down:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用`add_timer()` API来启动定时器。一旦调用，定时器就是“活动的”并开始倒计时：
- en: '[PRE13]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Its parameter is the pointer to the `timer_list` structure that you just initialized
    (via the `timer_setup()` macro).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Our simple kernel timer module – code view 1
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Without further ado, let''s dive into the code of a simple kernel timer, written
    using the **Loadable Kernel Module** (**LKM**) framework (this can be found at `ch5/timer_simple`).
    As with most drivers, we keep a context or private data structure containing the
    information required while running; here, we call it `st_ctx`. We instantiate
    it as the `ctx` variable. We also specify the time to expire (as 420 ms) in a
    global named `exp_ms`:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now, let''s check out the first portion of our *init *code:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This is pretty straightforward. First, we initialize the `ctx` data structure,
    setting a `data` member to the value `3`. The one key point here is that the `timer_list`
    structure is within our `ctx` structure, so we must initialize it. Now, setting
    the timer callback function (the `function` parameter) and the `flags` parameter values
    is simple; what about setting the time to expire? You must set the `timer_list.expires`
    member to the value that the `jiffies` variable (macro, actually) in the kernel
    must reach; at that point, the timer will expire! So, we prime it to have the
    timer expire 420 milliseconds in the future by adding the current value of jiffies
    to the jiffies value that the 420 ms elapsed time will take, like this:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The `msecs_to_jiffies()` convenience routine helps us out here as it converts
    the millisecond value that's passed to `jiffies`. Adding this result to the current
    value of `jiffies` will give us the value that `jiffies` will be in the future,
    in 420 ms from now, which is when we want our kernel timer to expire.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: This code is an inline function in `include/linux/jiffies.h:msecs_to_jiffies()`;
    the comments help us understand how it works. In a similar fashion, the kernel
    contains the `usecs_to_jiffies()`, `nsecs_to_jiffies()`, `timeval_to_jiffies()`,
    and `jiffies_to_timeval()` (inline) function helper routines.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: 'The next portion of the *init *code is as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'As we can see, by invoking the `add_timer()` API, we have armed (start) our
    kernel timer. It''s now live and counting down... in (approximately) 420 ms, it
    will expire. (Why approximately? As you saw in the *Let''s try it – how long do
    delays and sleeps really take?* section, delay and sleep APIs aren''t all that
    precise. In fact, a suggested exercise for you to work on later is to test the
    accuracy of the timeout; you can find this in the *Questions/kernel_timer_check* section.
    Also, in a sample solution for this exercise, we will show how using the `time_after()`
    macro is a good idea; it performs a validity check to ensure that the second timestamp
    is actually later than the first. Similar macros can be found in `include/linux/jiffies.h`;
    see the comment preceding this line: `include/linux/jiffies.h:#define time_after(a,b)`).'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Our simple kernel timer module – code view 2
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`add_timer()` started our kernel timer. As you just saw, it will soon expire.
    Internally, as we mentioned earlier, the kernel''s timer softirq will run our
    timer''s callback function. In the preceding section, we initialized the callback
    function to the `ding()` function (ha, *onomatopoeia* – a word that suggests the
    sound it describes – in action!) via the `timer_setup()` API. Hence, this code
    will run when the timer expires:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'There are a few things to keep in mind regarding this function:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: The timer callback handler code (`ding()` here) runs in atomic (interrupt, softirq)
    context; thus, you aren't allowed to invoke any perform any blocking APIs, memory
    allocation other than with the `GFP_ATOMIC` flag, or any kind of data transfer
    between kernel and user space (we covered this in detail in the previous chapter
    in the *Interrupt context guidelines – what to do and what not to do* section).
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The callback function receives, as a parameter, the pointer to the `timer_list`
    structure. Since we have (very deliberately) kept `struct timer_list` within our
    context or private data structure, we can usefully employ the `from_timer()` macro
    to retrieve the pointer to our private structure; that is, `struct st_ctx`). The
    first line of code shown previous does this. How does this work? Let''s look at
    its implementation:'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: It's really a wrapper over the `container_of()` macro!
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: We then print and decrement our `data` value.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We then issue our `PRINT_CTX()` macro (recall that it's defined in our `convenient.h` header
    file). It will show that we're running in softirq context.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, as long as our data member is positive, we force another timeout (of
    the same period) by invoking the `mod_timer()` API:'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: As you can see, with `mod_timer()`, when the timer triggers again is completely
    up to you; it's considered an efficient way of updating a timer's expiry date.
    By using `mod_timer()`, you can even arm an inactive timer (the job that `add_timer()`
    does); in this case, the return value is `0`, else it's `1` (implying that we've
    modified an existing active timer).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Our simple kernel timer module – running it
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now, let''s test our kernel timer module. On our x86_64 Ubuntu VM, we will
    use our `lkm` convenience script to load up the kernel module. The following screenshot
    shows a partial view of this and the kernel log:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8d3fa66c-52cc-44fa-98b5-e7f92ccd785d.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 – A partial screenshot of running our timer_simple.ko kernel module
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Study the `dmesg` (kernel log) output shown here. Since we've set the initial
    value of our private structure's `data` member to `3`, the kernel timer expires
    three times (just as our logic demands). Check out the timestamps in the left-most
    column; you can see that the second timer expiry occurred at `4234.289334` (sec.us)
    and the third at `4234.737346`; a quick subtraction reveals that the time difference
    is 448,012 microseconds; that is, about 448 milliseconds. This is reasonable since
    we asked for a 420 ms timeout (its a bit over that; the overheads of the printks
    do matter as well).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: 'The `PRINT_CTX()` macro''s output is revealing as well; let''s look at the
    second one shown in the preceding screenshot:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This shows that (as explained in detail in *Chapter 4*, *Handling Hardware Interrupts*)
    the code ran on CPU 1 (the `001)`) in softirq context (`s` in `..s1`). Furthermore,
    the process context that got interrupted – by the timer interrupt and softirq
    – is the `swapper/1` kernel thread; this is the CPU idle thread running on CPU
    1 when it's idle. This makes sense and is quite typical on an idle or lightly
    loaded system. The system (or at least CPU 1) was idle when the timer interrupt
    was initiated and a subsequent softirq came along and ran our timer callback.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: sed1 – implementing timeouts with our demo sed1 driver
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we'll write a bit of a more interesting driver (the code's
    for this can be found at `ch5/sed1/sed1_driver`). We'll design it so that it encrypts
    and/or decrypts a given message (very trivially, of course). The basic idea is
    that a user mode app (this can be found in `ch5/userapp_sed`) serves as its user
    interface. When run, it opens our `misc` character driver's device file (`/dev/sed1_drv`)
    and issues an `ioctl(2)` system call upon it.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: 'We have provided material online to help you understand how to interface a
    kernel module or device driver to a user space process via several common methods:
    via procfs, sysfs, debugfs, netlink sockets, and the `ioctl()` system call ([https://github.com/PacktPublishing/Learn-Linux-Kernel-Development/blob/master/User_kernel_communication_pathways.pdf](https://github.com/PacktPublishing/Learn-Linux-Kernel-Development/blob/master/User_kernel_communication_pathways.pdf))!'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ioctl()` call passes a data structure that encapsulates the data being
    passed, its length, the operation (or transform) to perform upon it, and a `timed_out` field
    (to figure out if it failed due to it missing its deadline). The valid ops are
    as follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Encrypt: `XF_ENCRYPT`
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decrypt: `XF_DECRYPT`
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Due to lack of space, we don't intend to show the code in great detail here –
    after all, having read so much of this book, you're now in a good position to
    browse and try and understand the code on your own! Nevertheless, certain key
    details relevant to this section will be shown.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at its overall design:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Our `sed1` driver (`ch5/sed1/sed1_driver/sed1_drv.c`) is really a pseudo driver,
    in the sense that it doesn't operate on any peripheral hardware controller or
    chip but on memory; nevertheless, it's a full-fledged `misc` class character device
    driver.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It registers itself as a `misc` device; in the process, a device node is auto-created
    by the kernel (here, we will call it `/dev/sed1_drv`).
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We arrange for it to have a driver "context" structure (`struct stMyCtx`) containing
    key members that it uses throughout; one of them is a `struct timer_list` structure
    for a kernel timer, which we initialize in the init code path (with the `timer_setup()` API).
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A user space app (`ch5/sed1/userapp_sed/userapp_sed1.c`) opens the device file
    of our `sed1` driver (it''s passed as a parameter to it, along with the message
    to encrypt). It invokes an `ioctl(2)` system call – the command being to encrypt –
    and the `arg` parameter, which is a pointer to a duly populated structure containing
    all the required information (including the message payload to encrypt). Let''s
    take a look at it in brief:'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Our `sed1` driver's `ioctl` method takes over. After performing validity checks,
    it copies the metadata structure (via the usual `copy_from_user()`) and fires
    off our `process_it()` function, which then invokes our `encrypt_decrypt_payload()` routine.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encrypt_decrypt_payload()` is the key routine here. It does the following:'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Starts our kernel timer (with the `mod_timer()` API), setting it to expire in `TIMER_EXPIRE_MS` milliseconds
    from now (here, we've set `TIMER_EXPIRE_MS` to `1`).
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grabs a timestamp, `t1 = ktime_get_real_ns();`.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kicks off the actual work – it''s either an encrypt or decrypt operation (we''ve
    kept it very simplistic: a mere `XOR` operation followed by an increment for each
    byte of the payload; the reverse for decryption).'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As soon as the work''s complete, do two things: grab a second timestamp, `t2
    = ktime_get_real_ns();`, and cancel the kernel timer (with the `del_timer()` API).'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Show the time taken to complete (via our `SHOW_DELTA()` macro).
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The user space app then sleeps for 1 second (to gather itself) and runs the `ioctl` decryption,
    resulting in our driver decrypting the message.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, it terminates.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is the relevant code from the `sed1` driver:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'That''s pretty much it! To get a feel for how it works, let''s see it in action.
    First, we must insert our kernel driver (LKM):'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The following screenshot shows a sample run of it encrypting and decrypting
    (here, we deliberately run the **Address Sanitizer** (**ASan**) debug version
    of this app; it might just reveal bugs, so why not!):'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b69c5a7c-64ac-4b18-83fb-5b944288b6eb.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
- en: Figure 5.3 – Our sed1 mini-project encrypting and decrypting a message within
    the prescribed deadline
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Everything went well here.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the code of our kernel timer''s callback function. Here,
    in our simple `sed1` driver, we merely have it do the following:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: Atomically set an integer in our private structure, `timed_out`, to a value of `1`, indicating
    failure. As we copy the data structure back to our user mode app (over `ioctl()`),
    this allows it to easily detect the failure and report/log it (the details on
    using atomic operators and much more will be covered in the last two chapters
    of this book).
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Emit a `printk` to the kernel log (at the `KERN_NOTICE` level), indicating that
    we timed out.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Invoke our `PRINT_CTX()` macro to show the context details.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code for our kernel timer''s callback function is as follows:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Can we see this code – the `timesup()` timer expiry function – run? We arrange
    to do just this next.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: Deliberately missing the bus
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The part I left out earlier is an interesting wrinkle: just before the second
    timestamp is taken, we insert a bit of code to deliberately miss the sacrosanct
    deadline! How? It''s really very simple:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '`make_it_fail` is a module parameter that is set to `0` by default; thus, only
    if you want to live dangerously (yes, a bit exaggerated!) should you pass it as `1`.
    Let''s try it out and see our kernel timer expire. The user mode app will detect
    this and report the failure as well:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/29cfeb09-64fd-40e7-92e9-8752bcd8fde6.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
- en: Figure 5.4 – Our sed1 mini-project running with the make_it_fail module parameter
    set to 1, causing the deadline to be missed
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: This time, the deadline is exceeded before the timer is canceled, thus causing
    it to expire and fire. Its `timesup()` callback function then runs (highlighted
    in the preceding screenshot). I highly recommend that you take the time to read
    the code of the driver and user mode app in detail and try it out on your own.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: 'The `schedule_timeout()` function that we briefly used earlier is a great example
    of using kernel timers! Its internal implementation can be seen here: `kernel/time/timer.c:schedule_timeout()`.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Additional information on timers can be found within the `proc` filesystem;
    among the relevant (pseudo) files is `/proc/[pid]/timers` (per-process POSIX timers)
    and the `/proc/timer_list` pseudofile (this contains information about all pending
    high-resolution timers, as well as all clock event sources. Note that the `/proc/timer_stats`
    pseudo-file disappeared after kernel version 4.10). You can find out more information
    about them on the man page about `proc(5)` at [https://man7.org/linux/man-pages/man5/proc.5.html](https://man7.org/linux/man-pages/man5/proc.5.html).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you will learn how to create and use kernel threads to
    your benefit. Read on!
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Creating and working with kernel threads
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A thread is an execution path; it''s purely concerned with executing a given
    function. That function is its life and scope; once it returns from that function,
    it''s dead. In user space, a thread is an execution path within a process; processes
    can be single or multi-threaded. Kernel threads are very similar to user mode
    threads in many respects. In kernel space, a thread is also an execution path,
    except that it runs within the kernel VAS, with kernel privilege. This means that
    kernels are also multi-threaded. A quick look at the output of `ps(1)` (run with
    the **Berkeley Software Distribution** (**BSD**) style `aux` option switches)
    shows us the kernel threads – they''re the ones whose names are enclosed in square
    brackets:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The majority of the kernel threads have been created for a definite purpose;
    often, they're created at system startup and run forever (in an infinite loop).
    They put themselves into a sleep state, and, when some work is required to be
    done, wake up, perform it, and go right back to sleep. A good example is that
    of the `ksoftirqd/n` kernel thread(s) (there's typically one per CPU core; that's
    what the `n` signifies – it's the core number); when the softirq load gets too
    heavy, they're woken up by the kernel to help consume the pending softirqs and
    thus help out (we discussed this in [Chapter 4](cfd1ca5d-cd0b-451d-8a35-31e65a09d2e4.xhtml), *Handling
    Hardware Interrupts*, in the *Employing the ksoftirqd kernel threads* section;
    in the preceding `ps` output, you can see them on a dual-core VM; they have PID
    10 and 18). Similarly, the kernel also employs *"kworker" worker threads*, which
    are dynamic – they come and go as work is required (a quick `ps aux | grep kworker`
    should reveal several of them).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at a few characteristics of kernel threads:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: They always execute in kernel VAS, in kernel mode with kernel privilege.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They always run in process context (refer to the companion guide *Linux Kernel
    Programming -* *Chapter 6*, *Kernel Internals Essentials – Processes and Threads*,
    the *Understanding process and interrupt contexts* section) and they have a task
    structure (and thus a PID and all other typical thread attributes, though their
    *credentials* always are set to `0`, implying root access).
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They compete for the CPU resource with other threads (including user mode threads)
    via the CPU scheduler; kernel threads (often abbreviated as **kthreads**) do get
    a slight bump in priority.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since they run purely in kernel VAS, they're blind to user VAS; thus, their
    `current->mm` value is always `NULL` (indeed, it's a quick way to identify a kthread).
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All kernel threads descend from the kernel thread named `kthreadd`, which has
    a PID of `2`. This is created by the kernel (technically, the first `swapper/0`
    kthread with a PID of `0`) during early boot; you can verify this by doing `pstree
    -t -p 2` (look up the man page on `pstree(1)` for usage details).
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They have naming conventions. kthreads are named differently, though some conventions
    are followed. Often, the name ends in `/n`; this signifies that it's a per-CPU
    kernel thread. The number specifies the CPU core it's been affined to run upon
    (we covered CPU affinity in the companion guide *Linux Kernel Programming -* *Chapter
    11*,* The CPU Scheduler – Part 2*, in the *Understanding, querying, and setting
    the CPU affinity mask* section). Furthermore, kernel threads are used for specific
    purposes and their name reflects that; for example, `irq/%d-%s` (where `%d` is
    the PID and `%s` is the name) is a threaded interrupt handler (covered in *Chapter
    4*, *Handling Hardware Interrupts*). You can learn how to find out the kthread
    name and about many practical uses of kthreads (and how to tune them to reduce
    jitter) by reading the kernel documentation, *Reducing OS jitter due to per-cpu
    kthreads*, at [https://www.kernel.org/doc/Documentation/kernel-per-CPU-kthreads.txt](https://www.kernel.org/doc/Documentation/kernel-per-CPU-kthreads.txt).
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bit we're interested in is that the kernel modules and device drivers often
    need to run a certain code path in the background, in parallel with other work
    that it and the kernel routinely performs. Let's say you need to block upon an
    asynchronous event that's occurring, or need to, upon some event, execute a user
    mode process from within the kernel, which is time-consuming. The kernel thread
    is just the ticket here; thus, we shall focus on how you, as a module author,
    can create and manage kernel threads.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: Yes, you can execute a user mode process or app from within the kernel! The
    kernel provides some**user mode helper** (**umh**) APIs to do so, with a common
    one being `call_usermode_helper()`. You can view its implementation  here: `kernel/umh.c:int call_usermodehelper(const
    char *path, char **argv, char **envp, int wait)`. Be careful, though; you are
    not meant to abuse this API to invoke just any app from the kernel – that's simply
    bad design! There are very few actual use cases of using this API in the kernel;
    use `cscope(1)` to check it out.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: Great; with that, let's learn how to create and work with a kernel thread.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: A simple demo – creating a kernel thread
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The primary API for creating kernel threads (that''s exposed to us module/driver
    authors) is `kthread_create()`; it''s a macro that invokes the `kthread_create_on_node()`
    API. The fact is, calling `kthread_create()` alone isn''t sufficient to have your
    kernel thread do anything useful; this is because, while this macro does create
    the kernel thread, you need to make it a candidate for the scheduler by setting
    it''s stated to running and waking it up. This can be done with the `wake_up_process()`
    API (once successful, it''s enqueued onto a CPU runqueue, which makes it schedulable
    so that it runs in the near future). The good news is that the `kthread_run()` helper
    macro can be used to invoke both `kthread_create()` and `wake_up_process()` in
    one go. Let''s take a look at its implementation in the kernel:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The comments in the preceding code snippet make the parameters and return value
    of `kthread_run()` clear.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate how to create and use a kernel thread, we will write a kernel
    module called `kthread_simple`. The following is the relevant code of its `init`
    method:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The first parameter to `kthread_run()` is the new kthread's lifeblood – its
    function! Here, we don't intend to pass any data to our newborn kthread, which
    is why the second parameter is `NULL`. The remaining parameters are the printf-style
    format string specifying its name. Once successful, it returns the pointer to
    the new kthread's task structure (we covered the task structures in some detail
    in the companion guide *Linux Kernel Programming -* *Chapter 6*, *Kernel Internals
    Essentials – Processes and Threads*, in the *Understanding and accessing the kernel
    task structure* section). Now, the `get_task_struct()` inline function is important
    – it increments the reference count of the task structure passed to it. This marks
    the task as being in use (later, in the cleanup code, we will issue the `kthread_stop()`
    helper routine; it will perform the converse operation, thus decrementing (and
    ultimately freeing up) the task structure's reference count).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s look at our kernel thread itself (we''ll only show the relevant
    code snippets):'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The moment `kthread_run()` succeeds in creating the kernel thread, it will
    begin running its code in parallel with the rest of the system: it''s now a schedulable
    thread! Our `PRINT_CTX()` macro reveals that it runs in process context and is
    indeed a kernel thread. (We have mimicked the tradition of enclosing its name
    in square brackets to show just this. The check to verify that the current `mm`
    pointer is `NULL` confirms the same.) You can see the output in *Figure 5.5*.
    All the code in your kernel thread routine is going to be running in the *process
    context*; hence, you can perform blocking operations (unlike with interrupt context).'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, by default, the kernel thread runs with root ownership and all signals
    are masked. However, as a simple test case, we can turn on a couple of signals
    via the `allow_signal()` helper routine. After that, we simply loop (we''ll get
    to the `kthread_should_stop()` routine shortly); in the loop body, we put ourselves
    to sleep by setting our task''s state to `TASK_INTERRUPTIBLE` (implying that the
    sleep can be interrupted by signals) and invoking `schedule()`:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Thus, only when we''re awoken– which will happen when you send the kernel thread
    either the `SIGINT` or `SIGQUIT` signal – will we resume execution. When this
    occurs, we break out of the loop (notice how we first verify that this is indeed
    the case with the `signal_pending()` helper routine!). Now, our kthread resumes
    execution outside the loop, only to (deliberately, and quite dramatically) die:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The cleanup code of the kernel module is as follows:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Here, within the cleanup code path, you're expected to call `kthread_stop()`,
    which performs the necessary cleanup. Internally, it actually waits for the kthread
    to die (via the `wait_for_completion()` routine). So, if you call the `rmmod`
    without having killed the kthread by sending it the `SIGINT` or `SIGQUIT` signal,
    the `rmmod` process will appear to hang here; it's (the `rmmod` process, that
    is) waiting (well, `kthread_stop()` is really the one waiting) for the kthread
    to die! This is why, if the kthread hasn't been signaled yet, this could cause
    a problem.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: 'There should be a better way to deal with stopping a kernel thread than sending
    it signals from user space. Indeed there is: the correct way is to employ the
    `kthread_should_stop()` routine as the (inverse) condition of the `while` loop
    it runs, so this is exactly what we''ll do! In the preceding code, we have the
    following:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The `kthread_should_stop()` routine returns a Boolean value that's true if the
    kthread should stop (terminate) now! Calling `kthread_stop()` in the cleanup code
    path will cause `kthread_should_stop()` to return true, thus causing our kthread
    to break out of the `while` loop and terminate via a simple `return 0;`. This
    value (`0`) is passed back to `kthread_stop()`. Due to this, the kernel module
    is successfully unloaded, *even if no signal is ever sent to our kernel thread*.
    We will leave testing this case as a simple exercise for you!
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the return value of `kthread_stop()` can be useful: it''s an integer
    and the result of the thread function that ran – in effect, it states whether
    your kthread succeeded (`0` returned) in its work or not. It will be the value `-EINTR`
    if your kthread was never woken up.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: Running the kthread_simple kernel thread demo
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let''s try it out (`ch5/kthread_simple`)! We can perform module insertion
    via `insmod(8)`; the module gets inserted into the kernel as planned. The kernel
    log shown in the following screenshot, as well as a quick `ps`, proves that our
    brand new kernel thread has indeed been created. Also, as you can see from the
    code (`ch5/kthread_simple/kthread_simple.c`), our kthread puts itself to sleep
    (by setting its state to `TASK_INTERRUPTIBLE` and then calling `schedule()`):'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9c126689-076e-44b5-9a88-b20b3004f4d4.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
- en: Figure 5.5 – A partial screenshot showing that our kernel thread is born, alive
    – and, well, asleep
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: 'Quickly running `ps(1) grep` for our kernel thread by name shows that our kthread
    is alive and well (and asleep):'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Let''s shake things up a bit and send the `SIGQUIT` signal to our kthread.
    This has it wake up (since we''ve set its signal mask to allow the `SIGINT` and
    `SIGQUIT` signals), set its state to `TASK_RUNNING`, and then, well, simply exit.
    We then use `rmmod(8)` to remove the kernel module, as shown in the following
    screenshot:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c3f089f4-57d3-4048-a739-8fe84c1e7292.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
- en: Figure 5.6 – A partial screenshot showing our kernel thread waking up and the
    module successfully unloaded
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have understood how to create and work with kernel threads, let's
    move on and design and implement the second version of our `sed` driver.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: The sed2 driver – design and implementation
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section (as mentioned in the *The "sed" drivers – to demo kernel timers, kthreads,
    and workqueues* section), we will write the next evolution of the `sed1`driver,
    called `sed2`.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: sed2 – the design
  id: totrans-260
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Our `sed` v2 (`sed2`*;* code: `ch5/sed2/`) mini-project is very similar to
    our `sed1` project. The key difference is that this time, we''ll carry out the
    "work" via a kernel thread created by the driver for just this purpose. The key
    differences between this version and the previous one are as follows:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: There's just one global shared memory buffer for holding the metadata, along
    with the payload; that is, the message to encrypt/decrypt. This is the `struct
    sed_ds->shmem` member within our driver context structure, `struct stMyCtx`.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The work of encryption/decryption is now performed within a kernel thread (that
    this driver spawns); we keep the kernel thread asleep. Only when work arises does
    the driver wake up the kthread and have it consume (execute) the work.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We now run the kernel timer within the kthread's context and show if it expires
    prematurely (indicating that the deadline wasn't met).
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A quick test reveals that eliminating the several `pr_debug()` printks within
    the kernel thread's critical section goes a long way toward reducing the time
    taken to complete the work! (You can always change the Makefile's `EXTRA_CFLAGS`
    variable to undefine the `DEBUG` symbol if you wish to eliminate this overhead (by
    using `EXTRA_CFLAGS += -UDEBUG`)!). Hence, here, the deadline is longer (10 ms).
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, in a nutshell, the whole idea here is to primarily demonstrate using a
    custom kernel thread, along with a kernel timer, to timeout an operation. A key
    point to understand that changes the overall design (especially the way that the
    user space app interacts with our `sed2` driver) is that since we''re running
    the work in the context of a kernel thread, it''s not the same context as that
    of the process that `ioctl()` is issued to. Due to this, it''s very important
    to realize the following things:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: 'You cannot simply transfer data from the kernel thread''s process context to
    the user space process – they''re completely different (they run in different
    virtual address spaces: the user mode process has its own complete VAS and PID,
    and so on; the kernel thread literally lives within the kernel VAS with its own
    PID and kernel mode stack). Due to this, using the `copy_{from|to}_user()` (and
    similar) routine is out of question for communicating from the kthread to the
    user mode app.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The potential for dangerous *races *is significant; the kernel thread runs asynchronously
    with respect to the user process context; thus, we can end up creating concurrency-related
    bugs if we're not careful. This is the entire reason for the last two chapters
    of this book, where we'll cover kernel synchronization, locking (and related)
    concepts, and technologies. For now, bear with us – we keep things as simple as
    possible by using some simple polling tricks in place of proper synchronization.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We have four operations inside our `sed2` project:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '**Encrypt** the message (this also gets the message from user space into the
    driver; thus, this has to be done first).'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decrypt**the message.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Retrieve **the message (sent from the driver to the user space app).'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Destroy**the message (in effect, it''s reset – the memory and metadata are
    wiped clean within the driver).'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It''s important to realize that due to the potential for races, we *cannot
    simply *transfer data directly from the kthread to the user space app. Due to
    this, we must do the following:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: We must carry out the retrieve and destroy operations in the process context
    of the user space process by issuing the `ioctl()` system calls.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We must carry out the encrypt and decrypt operations in the process context
    of our kernel thread, asynchronously with respect to the user space app (we run
    it within a kernel thread, not because we *have to *but because we want to; this
    is, after all, the point of this topic!).
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This design can be summarized by a simple ASCII-art diagram:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f2d0e4db-7478-467d-b76a-16fcd637e48b.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
- en: Figure 5.7 – The high-level design of our sed2 mini-project
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: Right, let's now check out the relevant code implementation for `sed2`.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: sed2 driver – code implementation
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In terms of code, the `ioctl()` method''s code within the `sed2`driver for
    the encrypt operation is as follows (for clarity, we won''t show all the error
    checking code here; we will show only the most relevant parts). You can find the
    full code at `ch5/sed2/`:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The driver, after performing several validity checks in its `ioctl()` method,
    gets down to work: for the encryption operation, we check if the current payload
    is already encrypted (obviously, we have a state member within our context structure
    that is updated to hold this information; that is, `priv->msg_state`). If everything
    is fine, it copies in the message (along with the required metadata in `struct
    sed_ds`) from the user space app. Then, it *wakes up our kernel thread*(via the
    `wake_up_process()` API; the parameter is the pointer to its task structure, which
    is the return value from the `kthread_create()` API). This causes the kernel thread
    to resume execution!'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: In the `init` code, we created the kthread with the `kthread_create()` API (and
    not the `kthread_run()` macro) as we do *not* want the kthread to run immediately!
    Instead, we prefer to keep it asleep, only awakening it when work is required
    of it. This is the typical approach we should follow when employing a worker thread
    (the so-called manager-worker model).
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code within our `init` method creates the kernel thread:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'After this, the timer is initialized (via the `timer_setup()` API). The (truncated)
    code of our worker thread looks as follows:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Here, you can see the timer being started (`mod_timer()`), the actual encrypt/decrypt
    functions being invoked as required, the timestamps being captured, and then the
    kernel timer being canceled. This is what happened in `sed1`except that, this
    time (`sed2`), the work happens in the context of our kernel thread! The kernel
    thread function then makes itself go to sleep while yielding the processor by
    (as was covered in the companion guide *Linux Kernel Programming -* *Chapter 10*,
    *The CPU Scheduler – Part 1*, and *Chapter 11*, *The CPU Scheduler – Part 2*)
    setting the task state to a sleep state (`TASK_INTERRUPTIBLE`) and invoking `schedule()`.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: 'Hang on a minute – within the `ioctl()` method, did you notice the call to
    the `POLL_ON_WORK_DONE(1);` macro just before the kernel thread was woken up?
    Take a look at the following code:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The poll is used to circumvent a possible race: what if one (user mode) thread
    invokes `ioctl()` to, say, encrypt a given message, and simultaneously on another
    CPU core, another user mode thread invokes `ioctl()` to, say, decrypt a given
    message? This will cause concurrency issues! Again, the last two chapters of this
    book are devoted to understanding and handling these; but here and now, what can
    we do? Let''s implement a poor man''s synchronization solution: *polling*.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 'This is not ideal but will have to do. We''ll make use of the fact that the
    driver sets an atomic variable in the driver''s context structure, named `work_done`,
    to `1` when the work is done; its value is `0` otherwise. We poll for this within
    this macro:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: To keep this code somewhat palatable, we aren't hogging the processor; if the
    work isn't done (yet), we sleep for a millisecond (via the `msleep_interruptible()`
    API) and try again.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, we''ve covered the relevant code for the encrypt and decrypt functionality
    of `sed2` (both of which run in our worker kthread''s context). Now, let''s look
    at the remaining two pieces of functionality – retrieving and destroying messages.
    These are carried out in the original user space process context – the process
    (or thread) that issues the `ioctl()` system calls. Here''s the relevant code
    for them:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Now that you've seen the (relevant) `sed2` code, let's try it out!
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: sed2 – trying it out
  id: totrans-300
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s take a look at a sample run of our `sed2` mini project over a couple
    of screenshots; ensure that you look at them carefully:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a00d3a39-6d42-400c-aa33-930747f6a037.png)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
- en: Figure 5.8 – Our sed2 mini-project showing off an interactive menu system. Here,
    a message has been successfully encrypted
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: 'So, we have encrypted a message, but how do we view it? Simple: we use the
    menu! Select option `2` to retrieve the (encrypted) message (it will be displayed
    for your leisurely perusal), option `3` to decrypt it, option `2` once more to
    view it, and option `5` to see the kernel log – quite useful! Some of these options
    are shown in the following screenshot:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/35866e17-68c1-4168-abb3-8c5e3c2d856c.png)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
- en: Figure 5.9 – Our sed2 mini-project showing off an interactive menu system. Here,
    a message has been successfully encrypted
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in the kernel log, our user mode app (`userapp_sed2_dbg_asan`) has
    opened the device and issued the retrieve operation, followed by the encrypt operation
    a few seconds later (the timestamps in the bottom-left corner of the preceding
    screenshot help you figure this out). Then, the driver wakes up the kernel thread;
    you can see its printk output, as well as the output of `PRINT_CTX()`, here:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The encrypt operation then completes (successfully and within the deadline;
    the timer is canceled):'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Similarly, other operations are carried out. We shall refrain from showing the
    user space app's code here since it's a simple user mode "C" program. This time
    (unusually), it's an interactive app with a simple menu (as shown in the screenshots);
    do check it out. I'll leave it to you to read and understand the `sed2`code in
    detail and try it out for yourself.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: Querying and setting the scheduling policy/priority of a kernel thread
  id: totrans-312
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In closing, how can you query and/or change the scheduling policy and (real-time)
    priority of a kernel thread? The kernel provides APIs for this (the `sched_setscheduler_nocheck()`
    API is often used within the kernel). As a practical example, the kernel will
    require kernel threads for the purpose of servicing interrupts – the *threaded
    interrupt *model, which we covered in [Chapter 4](cfd1ca5d-cd0b-451d-8a35-31e65a09d2e4.xhtml),
    *Handling Hardware Interrupts, *in the *Internally implementing the threaded interrupt*
    section).
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: 'It creates these threads (via `kthread_create()`) and changes their scheduling
    policy and real-time priority via the `sched_setscheduler_nocheck()` API. We won''t
    explicitly cover their usage here as we covered this in the companion guide *Linux
    Kernel Programming -* *Chapter 11*, *The CPU Scheduler – Part 2*. It''s interesting:
    the `sched_setscheduler_nocheck()` API is just a simple wrapper over the underlying `_sched_setscheduler()`
    routine. Why? The `_sched_setscheduler()` API isn''t exported at all and is thus
    unavailable to module authors; the `sched_setscheduler_nocheck()` wrapper is exported
    via the `EXPORT_SYMBOL_GPL()` macro (implying that only GPL licensed code can
    actually make use of it!).'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: What about querying and/or changing the scheduling policy and (real-time) priority
    of **user space threads**? The Pthreads library provides wrapper APIs to do just
    this; the `pthread_[get|set]schedparam(3)` pair can be used here since they're
    wrappers around system calls such as `sched_[get|set]scheduler(2)` and `sched_[get|set]attr(2)`.
    They require root access and, for security purposes, have the `CAP_SYS_NICE` capability
    bit set in the binary executable file.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: 'Though this book only covers kernel programming, I''ve mentioned this here
    as it''s a really powerful thing: in effect, the user space app designer/developer
    has the ability to create and deploy application threads perfectly suited to their
    purpose: real-time threads at differing scheduling policies, real-time priorities
    between 1 and 99, non-RT threads (with the base nice value of `0`), and so on. Indiscriminately
    creating kernel threads is frowned upon, and the reason is clear – every additional
    kernel thread adds overhead, both in terms of memory and CPU cycles. When you''re
    in the design phase, pause and think: do you really require one or more kernel
    threads? Or is there a better way of doing things? Workqueues are often exactly
    that – a better way!'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's look at workqueues!
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: Using kernel workqueues
  id: totrans-318
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A **workqueue** is an abstraction layer over the creation and management of
    kernel worker threads. They help solve a crucial problem: directly working with
    kernel threads, especially when several are involved, is not only difficult but
    can quite easily result in dangerous bugs such as races (and thus the potential
    for deadlock), as well as poor thread management, resulting in efficiency losses.
    Workqueues are *bottom-half *mechanisms that are employed within the Linux kernel
    (along with tasklets and softirqs).'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: The modern workqueue implementation in the Linux kernel – called the **concurrency
    managed work queue** (**cmwq**) – is really a pretty elaborate framework, with
    various strategies for dynamically and efficiently provisioning kernel threads
    based on specific requirements.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we prefer to focus on the *usage *of the kernel-global workqueue
    rather than its internal design and implementation. If you'd like to learn more
    about the internals, I recommend that you read the "official" kernel documentation
    here: [https://www.kernel.org/doc/Documentation/core-api/workqueue.rst](https://www.kernel.org/doc/Documentation/core-api/workqueue.rst).
    The *Further reading *section also contains some useful resources.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: 'The key characteristics of the workqueue are as follows:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: The workqueue task(s) (callbacks) always execute in a preemptible process context.
    This is obvious once you realize that they are executed by kernel (worker) threads,
    which run in a preemptible process context.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By default, all interrupts are enabled and no locks are taken.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The aforementioned points imply that you can do lengthy, blocking, I/O-bound
    work within your workqueue function(s) (this is diametrically opposite to an atomic
    context such as a hardirq, tasklet, or softirq!).
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Just as you learned about kernel threads, transferring data to and from user
    space (via the typical `copy_[to|from]_user()` and similar routines) is *not *possible;
    this is because your workqueue handler (function) executes within its own process
    context – that of a kernel thread. As we know, kernel threads have no user mapping.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The kernel workqueue framework maintains worker pools. These are literally
    several kernel worker threads organized in differing ways according to their needs.
    The kernel handles all the complexity of managing them, as well as concurrency
    concerns. The following screenshot shows several workqueue kernel worker threads
    (this was taken on my x86_64 Ubuntu 20.04 guest VM):'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/3c46ac29-5b59-49ec-bb67-8209b7f52082.png)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
- en: Figure 5.10 – Several kernel threads serving the kernel workqueue's bottom-half
    mechanism
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned in the *Creating and working with kernel threads* section, one
    way to figure out the kthread's name and learn about the many practical uses of
    kthreads (and how to tune them to reduce jitter) is by reading the relevant kernel
    documentation; that is, *Reducing OS jitter due to per-cpu kthreads* ([https://www.kernel.org/doc/Documentation/kernel-per-CPU-kthreads.txt](https://www.kernel.org/doc/Documentation/kernel-per-CPU-kthreads.txt)).
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: In terms of how to use workqueues (and the other bottom-half mechanisms), refer
    back to [*Chapter 4*](cfd1ca5d-cd0b-451d-8a35-31e65a09d2e4.xhtml), *Handling Hardware
    Interrupts*, the *Hardirqs, tasklets, and threaded handlers – what to use when*
    section,especially the table there.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: It's important to understand that the kernel has an always-ready default workqueue
    available for use; it's known as the ***kernel-global workqueue*** or ***system
    workqueue***. To avoid stressing the system, it's highly recommended that you
    use it. We shall use the kernel-global workqueue, enque our work task(s) on it,
    and have it consume our work.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: You can even use and create other kinds of workqueues! The kernel provides the
    elaborate *cmwq* framework, along with a set of APIs, to help you create specific
    types of workqueues. We'll look at this in more detail in the next section.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: The bare minimum workqueue internals
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We don't go into too much depth about the internals of the workqueue here; in
    fact, we will merely scratch the surface (as we mentioned previously, our purpose
    here is to only focus on using the kernel-global workqueue).
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s always recommended that you use the default kernel-global (system) workqueue
    to consume your asynchronous background work. If this is deemed to be insufficient,
    don''t worry – certain interfaces are exposed that let you create your workqueues.
    (Keep in mind that doing so will increase stress on the system!) To allocate a
    new workqueue instance, you can use the `alloc_workqueue()` API; this is the primary
    API that''s used for creating (allocating) workqueues (via the modern *cmwq* framework):'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Note that it''s exported via `EXPORT_SYMBOL_GPL()`, which means it''s only
    available to modules and drivers that use the GPL license. `fmt` (and the parameters
    following `max_active`) specifies how to name the workqueue threads in the pool.
    The `flags` parameter specifies a bitmask of special behavioral values or other
    characteristics, such as the following:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: Use the `WQ_MEM_RECLAIM` flag when the workqueue needs forward progress guarantees
    under memory pressure.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the `WQ_HIGHPRI` flag when work items are to be serviced by a worker pool
    of kthreads at an elevated priority level.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the `WQ_SYSFS` flag to make some of the workqueue details visible to user
    space via sysfs (practically, look under `/sys/devices/virtual/workqueue/`).
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarly, there are several other flags. Take a look at the official kernel
    documentation for more details ([https://www.kernel.org/doc/Documentation/core-api/workqueue.rst](https://www.kernel.org/doc/Documentation/core-api/workqueue.rst);
    it provides some interesting coverage on reducing "jitter" due to workqueue execution
    within the kernel).
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `max_active` parameter is used to specify the maximum number of kernel threads
    per CPU that can be assigned to a work item.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: 'Broadly speaking, there are two types of workqueues:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: '**Single-threaded** (**ST**) **workqueues or ordered workqueues**: Here, only
    one thread can be active at any given point in time across the system. They can
    be created with `alloc_ordered_workqueue()` (it''s really just a wrapper over `alloc_workqueue()`
    specifying the ordered flags with `max_active` set to exactly `1`).'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multi-threaded** (**MT**) **workqueues**: This is the default option. The
    exact `flags` specify the behavior; `max_active` specifies the maximum number
    of worker kernel threads the work item can possibly have per CPU.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'All workqueues can be created via the `alloc_workqueue()` API. The code for
    creating them is as follows:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: This happens early in the boot process (literally in the early init kernel code
    path). The first is highlighted in bold; this is the kernel-global workqueue or
    the system workqueue being created. Its worker pool is named `events`. (The name
    of the kernel threads that belong to this pool follow this naming convention and
    have the word `events` in their name; see *Figure 5.10* again. The same happens
    with kthreads belonging to other worker pools.)
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: 'The underlying framework has evolved a great deal; an earlier *legacy* workqueue
    framework (prior to 2010) used to use the `create_workqueue()` and friends APIs;
    however, these are now considered deprecated. The modern **concurrency managed
    workqueue** (**cmwq**) framework (around 2010 onward) is, interestingly, backward
    compatible with the old one. The following table summarizes the mapping of the
    older workqueue APIs to the modern cmwq ones:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: '| **Legacy (old and deprecated) workqueue API** | **Modern (cmwq) workqueue
    API** |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
- en: '| `create_workqueue(name)` | `alloc_workqueue(name,WQ_MEM_RECLAIM, 1)` |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
- en: '| `create_singlethread_workqueue(name)` | `alloc_ordered_workqueue(name, WQ_MEM_RECLAIM)`
    |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
- en: '| `create_freezable_workqueue(name)` | `alloc_workqueue(name, WQ_FREEZABLE
    &#124; WQ_UNBOUND &#124; WQ_MEM_RECLAIM, 1)` |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
- en: Table 5.3 – Mapping of the older workqueue APIs to the modern cmwq ones
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram summarizes (in a simple, conceptual manner) the kernel 
    workqueue subsystem:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6a2e40f7-3546-45d4-843f-520afe0c298b.png)'
  id: totrans-357
  prefs: []
  type: TYPE_IMG
- en: Figure 5.11 – A simple conceptual view of the workqueue subsystem within the
    kernel
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: The kernel's workqueue framework dynamically maintains these worker pools (of
    kernel threads); some, such as the `events` workqueue (corresponding to the kernel-global
    workqueue) are general-purpose, while others are created and maintained for a
    specific purpose (in terms of the names given to their kernel threads, such as
    block I/O, `kworker*blockd`, memory control, `kworker*mm_percpu_wq`, device-specific
    ones such as tpm, `tpm_dev_wq`, CPU frequency governor drivers, `devfreq_wq`,
    and so on).
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: Note that the kernel workqueue subsystem maintains all these workqueues (and
    their associated worker pools of kernel threads) automatically, elegantly, and
    efficiently.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: So, how do you actually make use of the workqueue? The next section will show
    you how to use the kernel-global workqueue. This will be followed by a demo kernel
    module that clearly demonstrates its usage.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: Using the kernel-global workqueue
  id: totrans-362
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we shall learn how exactly to use the kernel-global (also known
    as the system or events workqueue, which is the default) workqueue. This typically
    involves initializing the workqueue with your work task, having it consume your
    work, and finally, performing cleanup.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: Initializing the kernel-global workqueue for your task – INIT_WORK()
  id: totrans-364
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Enqueuing work onto this workqueue is actually very easy: use the `INIT_WORK()` macro!
    This macro takes two parameters:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The `work_struct` structure is the workhorse structure for work queues (from
    the module/driver author's point of view, at least); you are to allocate memory
    to it and pass the pointer as the first parameter. The second parameter to `INIT_WORK()`
    is a pointer to the workqueue callback function – the function that will be consumed
    by the worker thread(s) of the workqueue! `work_func_t` is a `typedef` that specifies
    the signature for this function, which is `void (*work_func_t)(struct work_struct
    *work)`.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: Having your work task execute – schedule_work()
  id: totrans-368
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Calling `INIT_WORK()` registers the specified work structure and function with
    the in-house default kernel-global workqueue. But it doesn''t execute it – yet!
    You have to tell it when to execute your "work" by calling the `schedule_work()` API
    at the appropriate moment:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Clearly, the parameter to `schedule_work()` is the pointer to the `work_struct`
    structure (which you initialized earlier via the `INIT_WORK()` macro). It returns
    a Boolean (quoting directly from the source): `%false if @work was already on
    the kernel-global workqueue and %true otherwise True`. In effect, `schedule_work()` checks
    if the function that was specified (via the work structure) is already on the
    kernel-global workqueue; if not, it enqueues it there; if it already was there,
    it leaves it alone in the same position (it doesn't add one more instance). It
    then marks the work item for execution. This typically happens as soon as the
    underlying kernel thread(s) corresponding to the workqueue get scheduled, thus
    giving you a chance to run your work.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: 'To have two work items (functions) within your module or driver execute via
    the (default) kernel-global workqueue, simply call the `INIT_WORK()` macro twice,
    each time passing different work structures and functions. Similarly, for more
    work items, call `INIT_WORK()` for each of them... (For example, take this kernel
    block driver (`drivers/block/mtip32xx/mtip32xx.c`): apparently, for Micron PCIe
    SSDs, it calls `INIT_WORK()` eight times in a row (!) with its probe method, using
    arrays to hold all the items).'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: Note that you can call `schedule_work()` in an atomic context! The call is non-blocking;
    it merely schedules the work item to be consumed at a later, deferred (and safe)
    point in time, when it will run in process context.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: Variations of scheduling your work task
  id: totrans-374
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'There are a few variations of the `schedule_work()` API we just described,
    all of which are available via the `schedule[_delayed]_work[_on]()` APIs. Let''s
    briefly enumerate them. First, let''s look at the `schedule_delayed_work()` inline
    function, whose signature is as follows:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Use this routine when you want to delay the execution of the workqueue handler
    function by a specified amount of time; the second parameter, `delay`, is the
    number of `jiffies` you want to wait for. Now, we know that the `jiffies` variable
    increments by `HZ` jiffies per second; thus, to have your work task delayed by
    `n` seconds, specify `n * jiffies`. Similarly, you could always pass the `msecs_to_jiffies(n)` value
    as the second parameter to have it execute `n` milliseconds from now.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: Next, notice that the first parameter to `schedule_delayed_work()` is different;
    it's a `delayed_work` structure, which itself contains the now-familiar `work_struct`
    structure as a member, along with other housekeeping members (a kernel timer,
    a pointer to the workqueue structure, and a CPU number). To initialize it, just allocate
    memory to it and then make use of the  `INIT_DELAYED_WORK()` macro (the syntax
    remains identical to `INIT_WORK()`); it will take care of all initialization.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: 'Another slight variation on the theme is the `schedule[_delayed]_work_on()`
    routine; `on` in the name allows you to specify which CPU core your work task
    will be scheduled upon when it executes. Here''s the signature of the `schedule_delayed_work_on()`
    inline function:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The first parameter specifies the CPU core to execute the work task upon, while
    the remaining two parameters are identical to the `schedule_delayed_work()` routine's
    parameters. (You can employ the `schedule_delayed_work()` routine to schedule
    your task – immediately – on a given CPU core).
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning up – canceling or flushing your work task
  id: totrans-382
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'At some point, you will want to ensure that your work task(s) have actually
    completed execution. You may wish to do this before destroying your workqueue
    (assuming it''s a custom created one and not the kernel-global one) or, more likely,
    when using the kernel-global workqueue in the cleanup method of your LKM or driver.
    The typical API to use here is `cancel_[delayed_]work[_sync]()`. Its variations
    and signatures are as follows:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'It''s quite simple, really: use `cancel_work_sync()` once you have used the
    `INIT_WORK()` and `schedule_work()` routines; use the latter two when you''ve
    delayed your work task. Notice that two of the routines are suffixed with `_sync`;
    this implies that the cancellation is *synchronous* – the kernel will wait until
    your work tasks have completed execution before these functions return! This is
    usually what we want. These routines return a boolean: `True` if there was work
    pending and `False` otherwise.'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: Within a kernel module, not canceling (or flushing) your work task(s) in your
    cleanup (`rmmod`) code path is a sure-fire way to cause serious issues; ensure
    you do so!
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: The kernel workqueue subsystem also provides a few `flush_*()` routines (including `flush_scheduled_work()`, `flush_workqueue()`,
    and `flush_[delayed_]work()`). The kernel documentation ([https://www.kernel.org/doc/html/latest/core-api/workqueue.html](https://www.kernel.org/doc/html/latest/core-api/workqueue.html))
    clearly warns us that these routines are not the easiest to use as you can easily
    cause deadlock issues with them. It's recommended that you use the aforementioned `cancel_[delayed_]work[_sync]()` APIs
    instead.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: A quick summary of the workflow
  id: totrans-388
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When using the kernel-global workqueue, a simple pattern (workflow) emerges:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: '*Initialize* the work task.'
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At the appropriate point in time, *schedule* it to execute (perhaps with a delay
    and/or on a particular CPU core).
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Clean up. Typically, in the kernel module (or driver's) cleanup code path, *cancel*
    it. (Preferably, do this with synchronization so that any pending work tasks are
    completed first. Here, we will stick to employing the recommended `cancel*work*()`
    routines, avoiding the `flush_*()` ones).
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s summarize this using a table:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: '| **Using the kernel-global workqueue** | **Regular work task** | ** Delayed
    work task** | ** Execute work task on given CPU** |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
- en: '| 1\. Initialization  | `INIT_WORK()` | `INIT_DELAYED_WORK()` | *< either immediate or
    delayed''s fine >* |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
- en: '| 2\. Schedule work task to execute | `schedule_work()` | `schedule_delayed_work()`
    | `schedule_delayed_work_on()` |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
- en: '| 3\. Cancel (or flush) it; *foo_sync()* to ensure it''s complete | `cancel_work_sync()`
    | `cancel_delayed_work_sync()` | *< either immediate or delayed''s fine >* |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
- en: Table 5.4 – Using the kernel-global workqueue – summary of the workflow
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: In the next few sections, we'll write a simple kernel module using the kernel-default
    workqueue in order to execute a work task.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: Our simple work queue kernel module – code view
  id: totrans-400
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s get hands-on with a work queue! In the following sections, we will write
    a simple demo kernel module (`ch5/workq_simple`) that demonstrates using the kernel-default
    workqueue to execute a work task. It''s actually built upon our earlier LKM, which
    we used to demonstrate kernel timers (`ch5/timer_simple`). Let''s check it out
    code-wise (as usual, we won''t show the full code here, only the most relevant
    portions). We''ll begin by looking at its private context data structure and *init*
    method:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'A key point to ponder: how will we manage to pass along some useful data items
    to our work function? The `work_struct` structure only has an atomic long integer
    that''s used for internal purposes. A good (and very typical!) trick is to have
    your `work_struct` structure embedded within your driver''s context structure;
    then, within the work task callback function, use the `container_of()` macro to
    gain access to the parent context data structure! This is a strategy that''s often
    employed. (The `container_of()` is a powerful macro, but not really easy to decipher!
    We''ve provided a couple of useful links for this in the *Further reading *section.)
    So, in the preceding code, we have our driver''s context structure embed a `struct
    work_struct` within it. You can see the initialization of our work task within
    the `INIT_WORK()` macro.'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the timer''s been armed (`add_timer()` does the trick here), it will expire
    in approximately 420 milliseconds and the timer callback function will run in
    the timer softirq context (this is very much an atomic context):'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: After decrementing the `data` variable, it sets up the timer to fire again (in
    420 ms, via `mod_timer()`), after which, via the `schedule_work()` API, it schedules
    our work queue callback to run! The kernel will recognize that the work queue
    function must now be executed (consumed) as soon as is viable. But hang on – the
    work queue callback must and will run *only in the process context, via a global
    kernel worker thread* – the so-called events thread(s). Thus, only once we're
    out of this softirq context and (one of) the "events" kernel worker threads is
    on a CPU runqueue and actually runs will our work queue callback function be invoked.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: Relax – it will happen soon enough... the whole point of using workqueues is
    that not only is the thread management completely taken care of by the kernel,
    but the function runs in the process context, where it's then possible to perform
    lengthy blocking or I/O operations.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, how soon is soon? Let''s attempt to measure this: we take a timestamp
    (via the usual `ktime_get_real_ns()` inline function) immediately after `schedule_work()` as
    the first line of code in the work queue function. Our trusty `SHOW_DELTA()` macro
    shows the difference in time. As expected, it''s small, typically within a few
    hundredths of a microsecond''s range (of course, this depends on several factors,
    including the hardware platform, kernel version, and so on). A highly loaded system
    would result in it taking longer to context switch to the events kernel thread(s),
    which could cause a delay in your work queue''s functionality executing. You will
    see it in a sample run within a screenshot capture (*Figure 5.12*) in the following
    section.'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code is of our work task function. This is where we employ the
    `container_of()` macro to gain access to our module''s context structure:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Furthermore, our `PRINT_CTX()` macro's output conclusively shows that this function
    runs in the process context.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: Be careful when you're using `container_of()` within a *delayed* work task callback
    function – you'll have to specify the third parameter as a `work` member of `struct
    delayed_work` (one of our exercise questions has you try out this very thing!
    There's a solution provided as well...). I suggest that you master the basics
    first before trying this out for yourself.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will run our kernel module.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: Our simple work queue kernel module – running it
  id: totrans-414
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s take it for a spin! Take a look at the following screenshot:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a9d89aad-617f-47e8-88d5-37443a49ce5b.png)'
  id: totrans-416
  prefs: []
  type: TYPE_IMG
- en: Figure 5.12 – Our workq_simple.ko LKM with the work queue function execution
    highlighted
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at this code in more detail:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: Via our `lkm` helper script, we build and then `insmod(8)` the kernel module;
    that is, `workq_simple.ko`.
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The kernel log is displayed via `dmesg(1)`:'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here, the workqueue and kernel timer are initialized and armed within the init
    method.
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The timer expires (in approximately 420 ms); you can see its printks (showing `timed
    out...` and the value of our `data` variable).
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It invokes the `schedule_work()` API, causing our workqueue function to run.
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As highlighted in the preceding screenshot, our work queue function, `work_func()`,
    indeed runs; it displays the data variable's current value, proving that it correctly
    gained access to our "context" or private data structure.
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Note that we used our `PRINT_CTX()` macro in this LKM (it''s within our `convenient.h`
    header) to reveal something interesting:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: When it runs in the context of the timer callback function, its status bits
    contain the `s` character (the third character within the four-character field
    – `.Ns1` or similar), showing that it's running in *softirq* (an interrupt, atomic)
    context.
  id: totrans-426
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: When it runs in the context of the work queue callback function, its status
    bit's third character will *never* contain the `s` character; it will always be
    a `.`, *proving that the workqueue always executes in the process context!*
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, the `SHOW_DELTA()` macro calculates and spits out the time difference
    between the workqueue being scheduled and actually executing. As you can see (here,
    at least, on our lightly loaded x86_64 guest VM), it's in the range of a few hundred
    microseconds.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: 'Why not look up the actual kernel worker thread that was used to consume our
    work queue? A simple `ps(1)` on the PID is all that''s required here. In this
    particular case, it happens to be one of the kernel''s per CPU core generic workqueue
    consumer threads – a kernel worker (`kworker/...`) thread:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Of course, the kernel code base is littered with workqueue usage (especially
    many device drivers). Please use `cscope(1)` to find and browse through instances
    of such code.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
- en: The sed3 mini project – a very brief look
  id: totrans-432
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's conclude this chapter by taking a very brief look at the evolution of
    our `sed2` project to `sed3`. This mini-project is identical to `sed2` except
    that it's simpler! The (en/de)crypt work **is now carried out by our work task
    (function) via the kernel's workqueue functionality** or bottom-half mechanism.
    We use a workqueue – the default kernel-global workqueue – to get the work done
    instead of manually creating and managing kthreads (as we did in `sed2`)!
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows us accessing the kernel log of a sample run;
    in the run, we had the user mode app encrypt, then decrypt, and then retrieve
    the message for viewing. We''ve highlighted the interesting bit here – the execution
    of our work task via the kernel-global workqueue''s worker threads – in the two
    red rectangles:'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/670779a5-067a-4d15-be9b-d4dcd7b862b5.png)'
  id: totrans-435
  prefs: []
  type: TYPE_IMG
- en: Figure 5.13 – Kernel log when running our sed3 driver; the work task running
    via the default kernel-global workqueue is highlighted
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: By the way, the user mode app is identical to the one we used in `sed2`. The
    preceding screenshot shows (via our trusty `PRINT_CTX()` macro) the actual kernel
    worker threads that the kernel-global workqueue employed to run our encrypt and
    decrypt work; in this particular case, it's `[kworker/1:0]` PID 9812 for the encrypt
    work and `[kworker/0:2]` PID 9791 for the decrypt work. Note how they both run
    in the process context. We shall leave it to you to browse through the code of
    `sed3` (`ch5/sed3`).
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: This brings this section to a close. Here, you learned how the kernel workqueue
    infrastructure is indeed a blessing for module/driver authors as it helps you
    add a powerful abstraction layer over the underlying details regarding kernel
    threads, their creation, and intricate management and manipulation. It makes it
    very easy for you to perform work in the kernel – especially by employing the
    pre-existing kernel-global (default) workqueue – without having to worry about
    the gory details.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-439
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Well done! We covered a lot of ground in this chapter. First, you learned how
    to create delays in kernel space, both the atomic and the blocking types (via
    the `*delay()` and `*sleep()` routines, respectively). Next, you learned how to
    set up and use kernel timers within your LKM (or driver) – a very common and required
    task. Directly creating and working with kernel threads can be a heady (and even
    difficult) experience, which is why you learned the basics of doing so. After
    that, you looked at the kernel workqueue subsystem, which solves complexity (and
    concurrency) issues. You learned what it is and how to practically make use of
    the kernel-global (default) workqueue to make your work task(s) execute when required.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
- en: 'The series of three `sed` (simple encrypt decrypt) demo drivers we designed
    and implemented showed you a bit of a more sophisticated use case for these interesting
    technologies: `sed1` with the timeout implementation, `sed2` adding to the kernel
    thread to perform work, and `sed3` using the kernel-global workqueue to have work
    consumed when required.'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
- en: 'Please take some time to work on the following *Questions*/exercises for this
    chapter and browse through the *Further reading *resources. When you''re done,
    I suggest that you take a well-deserved break and jump back in. We''re almost
    there: the final two chapters cover a really key topic – kernel synchronization!'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-443
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Spot the bug(s) in the following pseudocode:'
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-445
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '`timer_simple_check`: Enhance the `timer_simple` kernel module so that it checks
    the amount of time that elapsed between setting up a timeout and it actually being
    serviced.'
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`kclock`: Write a kernel module that sets up a kernel timer so that it times
    out every second. Then, use this to print the timestamp to the kernel log to get,
    in effect, a simple "clock app" in the kernel.'
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`mutlitime`*:* Develop a kernel module that takes the number of seconds to
    issue a timer callback in as a parameter. Have it default to zero (implying no
    timer and thus a validity error). Here''s how it should work: if the number that''s
    passed is 3, it should create three kernel timers; the first one will expire in
    3 seconds, the second in 2 seconds, and the last in 1 second. In other words, if
    the number passed is "n", it should create "n" kernel timers; the first one will
    expire in "n" seconds, the second in "n-1" seconds, the third in "n-2" seconds,
    and so on until the count hits zero.'
  id: totrans-448
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build and run the `sed[123]` mini-projects provided in this chapter and verify
    (by looking at the kernel logs) that they work the way they should.
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`workq_simple2`: The `ch5/workq_simple` LKM we provided sets up and "consumes"
    one work item (function) via the kernel-global workqueue; enhance it so that it
    sets up and executes two "work" tasks. Verify that it works correctly.'
  id: totrans-450
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`workq_delayed`: Build upon the previous assignment (`workq_simple2`) to execute
    two work tasks, plus one more task (from the init code path). This one (the third
    one) should be delayed; the amount of time to delay by should be passed as a module parameter
    named `work_delay_ms` (in milliseconds; the default should be 500 ms).'
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[*Tip:* Be careful when using `container_of()` within the delayed work task
    callback function; you''ll have to specify the third parameter as a `work` member
    of `struct delayed_work`; check out a solution we''ve provided].'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
- en: 'You will find some of the questions answered in the book''s GitHub repo: [https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2/tree/main/solutions_to_assgn](https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2/tree/main/solutions_to_assgn).'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-454
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kernel documentation: *Delays, sleep mechanisms*: [https://www.kernel.org/doc/Documentation/timers/timers-howto.tx](https://www.kernel.org/doc/Documentation/timers/timers-howto.txt)'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kernel Timer Systems: [https://elinux.org/Kernel_Timer_Systems#Timer_information](https://elinux.org/Kernel_Timer_Systems#Timer_information)
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Workqueues:'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This is a very good presentation: *Async execution with workqueues*, Bhaktipriya
    Shridhar: [https://events.static.linuxfound.org/sites/events/files/slides/Async%20execution%20with%20wqs.pdf](https://events.static.linuxfound.org/sites/events/files/slides/Async%20execution%20with%20wqs.pdf)'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kernel documentation: *Concurrency Managed Workqueue (cmwq)*: [https://www.kernel.org/doc/html/latest/core-api/workqueue.html#concurrency-managed-workqueue-cmwq](https://www.kernel.org/doc/html/latest/core-api/workqueue.html#concurrency-managed-workqueue-cmwq)'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `container_of()` macro explained:'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*The Magical container_of() Macro*, November 2012: [https://radek.io/2012/11/10/magical-container_of-macro/](https://radek.io/2012/11/10/magical-container_of-macro/)'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Understanding of container_of macro in Linux kernel*: [https://embetronicx.com/tutorials/linux/c-programming/understanding-of-container_of-macro-in-linux-kernel/](https://embetronicx.com/tutorials/linux/c-programming/understanding-of-container_of-macro-in-linux-kernel/)'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
