- en: Interacting with the OpenStack API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For a long time, IT infrastructure depended on commercial software (from vendors
    such as VMWare, Microsoft, and Citrix) to provide virtual environments for running
    workloads and managing resources (such as computing, storage, and networking).
    However, IT industry is moving to cloud era and engineers are migrating workloads
    and applications to the cloud (either public or private), and that requires a
    new framework that is able to manage all application resources, providing an open
    and robust API interface to interact with external calls from other applications.
  prefs: []
  type: TYPE_NORMAL
- en: OpenStack provides an open access and integration to manage all of your computing,
    storage, and networking resources, avoiding a vendor lock-in when you're building
    your cloud. It can control a large pool of compute nodes, storage arrays, and
    networking devices, regardless of the vendor for each resource and provide a seamless
    integration between all resources. The core idea of OpenStack is to abstract all
    configuration applied on the underlay infrastructure into a *project* which is
    responsible for managing the resource. so you will find a project that manage
    the compute resources (called Nova) , another project that provide networking
    to the instances (neutron) and a projects to interact with different storage type
    (Swift and Cinder).
  prefs: []
  type: TYPE_NORMAL
- en: You can find a full list of the current OpenStack  projects in this link
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.OpenStack.org/software/project-navigator/](https://www.openstack.org/software/project-navigator/)'
  prefs: []
  type: TYPE_NORMAL
- en: Also OpenStack provide unified API access to the application developer and system
    administrators  to orchestrate the resource creation.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will explore the new and open world of OpenStack, and will
    learn how we can leverage Python and Ansible to interact with it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding RESTful web services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up the environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sending requests to OpenStack
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating workloads from Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing OpenStack instances using Ansible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding RESTful web services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Representational State Transfer** (**REST**) depends on HTTP protocol to
    transfer messages between the client and server. HTTP was originally designed
    to deliver HTML pages from web servers (servers) to browsers (clients), when requested.
    The pages represent a set of resources that the user wants to access, and are
    requested by **Universal Resource Identifiers** (**URIs**).'
  prefs: []
  type: TYPE_NORMAL
- en: 'An HTTP request typically contains a method that indicates the type of operation
    that needs to be executed on the resource. For example, when visiting a website
    from your browser, you can see (in the following screenshot) that the method is
    `GET`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00195.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following are the most common HTTP methods, and their usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '| HTTP Method | Action |'
  prefs: []
  type: TYPE_TB
- en: '| `GET` | The client will ask the server to retrieve the resource. |'
  prefs: []
  type: TYPE_TB
- en: '| `POST` | The client will instruct the server to create a new resource. |'
  prefs: []
  type: TYPE_TB
- en: '| `PUT` | The client will ask the server to modify/update the resource. |'
  prefs: []
  type: TYPE_TB
- en: '| `DELETE` | The client will ask the server to delete the resource. |'
  prefs: []
  type: TYPE_TB
- en: The application developer can expose certain resources of his application, to
    be consumed by the clients in the outside world. The transport protocol that carries
    the requests from the clients to servers and returns the responses back is HTTP.
    It is responsible for securing the communication and  encoding the packet with
    the appropriate data encoding mechanism that is accepted by the server, and it
    is a stateless communication across both of them.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the packet payloads are usually encoded in either XML or
    JSON, to represent the structure of the request handled by the server and how
    the client prefers the response back.
  prefs: []
  type: TYPE_NORMAL
- en: There are many companies around the world that provide public access to their
    data for developers, in real time. For example, the Twitter API ([https://developer.twitter.com/](https://developer.twitter.com/))
    provides a data fetch in real time, allowing other developers to consume the data
    in third-party applications like ads, searches, and marketing. The same goes for
    big names like Google ([https://developers.google.com/apis-explorer/#p/discovery/v1/](https://developers.google.com/apis-explorer/#p/discovery/v1/)),
    LinkedIn ([https://developer.linkedin.com/](https://developer.linkedin.com/)),
    and Facebook ([https://developers.facebook.com/](https://developers.facebook.com/)).
  prefs: []
  type: TYPE_NORMAL
- en: Public access to APIs is usually limited to a specific number of requests, either
    per hour of per day, for a single application, in order to not overwhelm the public
    resources.
  prefs: []
  type: TYPE_NORMAL
- en: Python provides a large set of tools and libraries to consume the APIs, encode
    the messages, and parse the responses. For example, Python has a `requests` package
    that can format and send HTTP requests to external resources. Also, it has tools
    to parse the responses in a JSON format and convert them to the standard dictionary
    in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Python also has many frameworks that can expose your resources to the external
    world. `Django` and `Flask` are among the best, serving as full stack frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenStack is a free and open source project, used with **Infrastructure as a
    Service** (**IaaS**), that can control your hardware resources in terms of CPU,
    memory, and storage and provide an open framework for many vendors to build and
    integrate plugins.
  prefs: []
  type: TYPE_NORMAL
- en: To set up our lab, I will use the latest `OpenStack-rdo` release (at the time
    of writing), Queens, and install it onto CentOS 7.4.1708\. The installation steps
    are pretty straightforward, and can be found at [https://www.rdoproject.org/install/packstack/](https://www.rdoproject.org/install/packstack/).
  prefs: []
  type: TYPE_NORMAL
- en: Our environment consists of a machine that has 100 GB storage, 12 vCPU, and
    32 GB of RAM, This server will contains the OpenStack controller, the compute
    and neutron roles on the same server. The OpenStack server is connected to the
    same switch that has our automation server and in same subnet. Note that this
    is not always the case in a production environment, but you need to make sure
    that your server that runs Python code can reach the OpenStack.
  prefs: []
  type: TYPE_NORMAL
- en: 'The lab topology is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00196.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Installing rdo-OpenStack package
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The steps for installing rdo-OpenStack on RHEL 7.4 and CentOS are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: On RHEL 7.4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, make sure that your system is up to date, and then install the `rdo-release.rpm`
    from the website to get the latest version. Finally, install the `OpenStack-packstack`
    package that will automate the OpenStack installation, as shown in the following
    snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: On CentOS 7.4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, make sure that your system is up to date, and then install the rdoproject
    to get the latest version. Finally, install the `centos-release-OpenStack-queens`
    package that will automate the OpenStack installation, as shown in the following
    snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Generating answer file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, you will need to generate the answer file that contains the deployment
    parameters. Most of these parameters are fine on their defaults, but we will change
    a few things:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Editing answer file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Edit the `EnterpriseAutomtion` file with your favorite editor, and change the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The `CELIOMETER` and `AODH` are an optional projects within OpenStack ecosystem
    and could be ignored in lab environment.
  prefs: []
  type: TYPE_NORMAL
- en: Also we setup a `KEYSTONE` password that used to generate temp token for accessing
    the resource using API and used also to access the OpenStack GUI
  prefs: []
  type: TYPE_NORMAL
- en: Run the packstack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Save the file and run the installation through the `packstack`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This command will download the packages from the Queens repository and install
    the OpenStack services, then start them. After the installation has completed
    successfully, the following message will be printed on the console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Access the OpenStack GUI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can now access the OpenStack GUI using `http://<server_ip_address>/dashboard`.
    The credentials will be admin and access123 (depending on what you wrote in `CONFIG_KEYSTONE_ADMIN_PW`
    in the previous steps):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00197.gif)'
  prefs: []
  type: TYPE_IMG
- en: Our cloud is now up and running, ready to receive requests.
  prefs: []
  type: TYPE_NORMAL
- en: Sending requests to the OpenStack keystone
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenStack contains collections of services that work together to manage the
    virtual machine **create, read, update, and delete** (**CRUD**) operations. Each
    service can expose its resources to be consumed by external requests. For example,
    the `nova` service is responsible for spawning the virtual machine and acts as
    a hypervisor layer (though it's not a hypervisor itself, it can control other
    hypervisors, like KVM and vSphere). Another service is `glance`, responsible for
    hosting the instance images in either an ISO or qcow2 format. The `neutron` service
    is responsible for providing networking services to spawned instances and ensures
    that the instances located on different tenants (projects) are isolated from each
    other, while instances on the same tenants can reach each others through an overlays
    network (VxLAN or GRE).
  prefs: []
  type: TYPE_NORMAL
- en: In order to access the APIs of each of the preceding services, you will need
    to have an authenticated token that is used for a specific period of time. That's
    the role of the `keystone`, which provides an identity service and manages the
    roles and permissions of each user.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to install the Python bindings on our automation server. These
    bindings contain python code used to access each service and authenticate the
    request with the token generated from KEYSTONE. Also bindings contains supported
    operation for each project (like create/delete/update/list):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Note that the Python client name is `python-<service_name>client`
  prefs: []
  type: TYPE_NORMAL
- en: 'You can download into your site''s global packages or the Python `virtualenv`
    environment. Then, you will need OpenStack admin privileges, which can be found
    in the following path, inside the OpenStack server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we will use the keystone version 3 in both the `OS_AUTH_URL` and
    `OS_IDENTITY_API_VERSION` parameters when we communicate with the OpenStack keystone
    service. Most of the Python clients are compatible with older versions, but require
    you to change your script a little bit. Other parameters are also required during
    token generation, so make sure that you have access to the `keystonerc_admin`
    file. Also the access credentials can be found in `OS_USERNAME` and `OS_PASSWORD`
    in the same file
  prefs: []
  type: TYPE_NORMAL
- en: 'our Python script will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, the following applies:'
  prefs: []
  type: TYPE_NORMAL
- en: '`python-keystoneclient` made a request to the keystone API using the `v3` class
    (which reflects the keystone API version). This class is available inside of `keystoneayth1.identity`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we supplied the full credentials taken from the `keystonerc_admin` file
    to the `auth` variable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we established the session, using the session manager inside of the
    keystone client. Notice that we set `verify` to `False`, since we don't use the
    certificate to generate the token. Otherwise, you can supply the certificate path.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The token generated can be used with any service, and it will last for one hour,
    then expire. Also, if you change the user role, the token will expire immediately,
    without waiting for an hour.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenStack administrators can configure the `admin_token` field inside the `/etc/keystone/keystone.conf`
    file, which never expires. However, this is not recommended in a production environment,
    for security reasons.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you don''t want to store the credentials inside the Python script, you can
    store them in the `ini` file and load them using the `configparser` module. First,
    create a `creds.ini` file in the automation server, and give it appropriate Linux
    permissions, so it can only be opened with your own account:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The modified script is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The `configparser` module will parse the `creds.ini` file and look at the `os_creds`
    section inside the file. Then, it will get the value in front of each parameter
    by using the `get()` method.
  prefs: []
  type: TYPE_NORMAL
- en: The `config.get()` method will accept two arguments. The first argument is the
    section name inside the `.ini` file, and the second is the parameter name. The
    method will return the value associated with the parameter.
  prefs: []
  type: TYPE_NORMAL
- en: This method should provide additional security to your cloud credentials. Another
    valid method to secure your file is to load the `keystonerc_admin` file into the
    environmental variables using the Linux `source` command, and read the credentials
    using the `environ()` method inside of the `os` module.
  prefs: []
  type: TYPE_NORMAL
- en: Creating instances from Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To get instance up and running, OpenStack instances require three components.
    The boot image, which is provided by `glance`, the network ports, which provided
    by `neutron`, and finally, the compute flavor that defines the number of  CPUs,
    amount of RAM that will be allocated to the instance and disk size. The flavor
    is provided by `nova` project.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will start by downloading a `cirros` image to the automation server. `cirros`
    is a lightweight, Linux-based image, used by many OpenStack developers and testers
    around the world to validate the functionality of OpenStack services:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Then, we will upload the image to the OpenStack image repository using `glanceclient`.
    Notice that we need to have the keystone token and the session parameter first,
    in order to communicate with `glance`, otherwise, `glance` won't accept any API
    requests from us.
  prefs: []
  type: TYPE_NORMAL
- en: 'The script will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, the following applies:'
  prefs: []
  type: TYPE_NORMAL
- en: Since we are communicating with `glance` (the image hosting project), we will
    import the `client` from the installed `glanceclient` module.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The same keystone scripts  used to generate the `sess` that holds the keystone
    token.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We created the glance parameter that initializes the client manager with `glance`
    and provide the version (`version 2` ) and the generated token.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can see all supported API versions by accessing the OpenStack GUI | API
    Access tab as in below screenshot. notice also the supported version for each
    project.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../images/00198.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The glance client manager is designed to operate on the glance OpenStack service.
    the manager is instructed to create an image with a name `CirrosImage` and disk
    type is in `qcow2` format.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we will open the downloaded image as a binary, using the `'rb'` flag,
    and will upload it to the created image. Now, `glance` will import the image to
    the newly created file in the image repository.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can validate that the operation was successful in two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: If no error is printed back after executing `glance.images.upload()`, it means
    that the request is correctly formatted and has been accepted by the OpenStack
    `glance` API.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Run the `glance.images.list()` . The returned output will be a generate which
    you can iterate over it to see more details about the uploaded image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Assigning a flavor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Flavors are used to determine the CPU, memory, and storage size of the instance.
    OpenStack comes with a predefined set of flavors, with different sizes that range
    from tiny to extra large. For the `cirros` image, we will use the small flavor,
    which has 2 GB RAM, 1 vCPU, and 20 GB storage. Access to flavors doesn't have
    a standalone API client; rather, it's a part of the `nova` client.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see all available built-in flavors at OpenStack GUI | Admin | Flavors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00199.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'The script will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding script, the following applies:'
  prefs: []
  type: TYPE_NORMAL
- en: Since we will communicate with `nova`  (the compute service) to retrieve the
    flavor, we will import the `novaclient` module as `nclient`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The same keystone script is used to generate the `sess` that holds the keystone
    token.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We created the `nova` parameter that initialized the client manager with the
    `nova` and provide the version to the client (version 2.1) and the generated token.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we used the `nova.flavors.find()` method to locate the desired flavor,
    which is `m1.small`. The name has to match the name in OpenStack exactly, otherwise
    it will throw an error.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating the network and subnet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Creating the network for the instance requires two things: the network itself,
    and associating subnet with it. First, we need to supply the network properties,
    such as the ML2 driver (Flat, VLAN, VxLAN, and so on), the segmentation ID that
    differentiates between the networks running on the same interface, the MTU, and
    the physical interface, if the instance traffic needs to traverse external networks.
    Second, we need to provide the subnet properties, such as the network CIDR, the
    gateway IP, The IPAM parameters (DHCP/DNS server if defined), and which network
    ID is associated with the subnet as in below screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00200.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Now we will develop a Python script to interact with the neutron project and
    create a network with a subnet
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding script, the following applies:'
  prefs: []
  type: TYPE_NORMAL
- en: Since we will communicate with `neutron` (the network service) to create both
    the network and associated subnet, we will import the `neutronclient` module as
    the `neuclient`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The same keystone script is used to generate the `sess` that holds the keystone
    token used later to access neutron resource.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will create the `neutron` parameter that initializes the client manager with
    neutron and provide the version to it (version 2) and the generated token.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we created two Python dictionaries, `body_network` and `body_subnet` which
    hold the message bodies for the network and subnet respectively. Note that the
    dictionary keys are static and can't be changed, while the values could be changed
    and usually provided from external portal system or Excel sheet, depending on
    your deployment. Also, I commented on the parts that are not necessary during
    network creation, such as `provider:physical_network` and `provider:network_type`,
    since our `cirros` image won't communicate with the provider network (networks
    defined outside OpenStack domains) but provided here for reference.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally the subnet and the network associated together by getting first the
    `network_id` through the `list_networks()` method and access the id and providing
    it as a value to `network_id` key inside the `body_subnet` variable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Launching the instance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The final part is to glue everything together. We have the boot image, the
    instance flavor, and the network that connects the machine with the other instances.
    We''re ready to launch the instance using the `nova` client (remember that `nova`
    is responsible for the virtual machine life cycle and the CRUD operations on the
    VM):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding script, we used the `nova.servers.create()` method and passed
    all of the information required to spawn the instance(instance name, operating
    system, flavor and networks). Additionally, we implemented a polling mechanism
    that polls the nova service for the server current status. If the server is still
    in `BUILD` phase,  then the script will sleeps for five seconds then poll again.
    The loop will exit when the server status is changes to either `ACTIVE` or `FAILURE`
    and will prints the server status at the end.
  prefs: []
  type: TYPE_NORMAL
- en: 'The script''s output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, you can check the instance from the OpenStack GUI | Compute | Instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00201.gif)'
  prefs: []
  type: TYPE_IMG
- en: Managing OpenStack instances from Ansible
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ansible provides modules that can manage the OpenStack instance life cycle,
    just like we did using APIs. You can find the full list of supported modules at
    [http://docs.ansible.com/ansible/latest/modules/list_of_cloud_modules.html#OpenStack](http://docs.ansible.com/ansible/latest/modules/list_of_cloud_modules.html#openstack).
  prefs: []
  type: TYPE_NORMAL
- en: All OpenStack modules rely on the Python library called `shade` ([https://pypi.python.org/pypi/shade](https://pypi.python.org/pypi/shade)),
    which provides a wrapper around OpenStack clients.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have installed `shade` on the automation server, you will have access
    to the `os-*` modules that can manipulate the OpenStack configuration, such as
    `os_image` (to handle OpenStack images), `os_network` (to create the network),
    `os_subnet` (to create and associate the subnet with the created network), `os_nova_flavor` (to
    create flavors, given the RAM, CPU, and disk), and finally, the `os_server` module
    (to bring up the OpenStack instance).
  prefs: []
  type: TYPE_NORMAL
- en: Shade and Ansible installation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the automation server, use the Python `pip` to download and install `shade`,
    with all dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: After installation, you will have `shade` under the normal `site-packages` in
    Python, but we will use Ansible instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, you will need to install Ansible in the automation server, if you haven''t
    done it in previous chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Verify that Ansible has installed successfully by querying the Ansible version
    from the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Building the Ansible playbook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we saw in [Chapter 13](part0168.html#506UG0-9cfcdc5beecd470bbeda046372f0337f),
    *Ansible for Administration*, depends on a YAML file to contain everything you
    will need to execute against hosts in the inventory. In this case, we will instruct
    the playbook to establish a local connection to the `shade` library on the automation
    server, and provide the playbook with the `keystonerc_admin` credentials that
    help `shade` to send requests to our OpenStack server.
  prefs: []
  type: TYPE_NORMAL
- en: 'The playbook script is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: In the playbook, we make use of the `os_*` modules to upload the image to the
    OpenStack `glance` server, create a new flavor (and not using this built-in),
    and create the network with the subnet associated; then, we glue everything together
    in `os_server`, which communicates with the `nova` server to spawn the machine.
  prefs: []
  type: TYPE_NORMAL
- en: Please note that the hosts will be the localhost (or the machine name that hosts
    the `shade` library), while we added the OpenStack keystone credentials in the
    environmental variables.
  prefs: []
  type: TYPE_NORMAL
- en: Running the playbook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Upload the playbook to the automation server and execute the following command
    to run it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The playbook''s output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'You can access the OpenStack GUI to validate that the instance was created
    from the Ansible playbook:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00202.gif)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Nowadays, the IT industry is trying to avoid vendor lock-in by moving to the
    open source world whenever possible. OpenStack provides a window into this world;
    many large organizations and telecom operators are considering moving their workloads
    to OpenStack, to build their private clouds in its data center. They can then
    build their own tools to interact with the open source APIs provided by OpenStack.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore another (paid) public Amazon cloud, and
    will learn how we can leverage Python to automate instance creation.
  prefs: []
  type: TYPE_NORMAL
