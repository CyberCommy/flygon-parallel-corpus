- en: Building for Large-Scale Database Operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the area of enterprise software development, developers have always built
    applications that deal with large amounts of data. In the early days of computing,
    systems used to span rooms bigger than the ones we currently live in, and data
    was stored in a flat file format, whereas today, systems have shrunk so much that
    in the same sized room that used to store a single system, we can now have thousands
    of systems running, each coordinating with the others, providing us with machines
    that can crunch data at the speed of light. Over time, the way data is stored
    has also evolved from using flat files to sophisticated database management systems.
  prefs: []
  type: TYPE_NORMAL
- en: With enterprises growing in size and their ever-expanding operations due to
    emerging fields, the amount data that needs to be processed by enterprise applications
    is also growing, and this makes it important to understand how to build our applications
    to deal with large-scale database-related operations. Though building for large-scale
    database operations can never be a one-approach-fits-all solution, we'll cover
    some points that are common to building applications that can scale easily to
    handle the increase in data, the requirements of schema modification, increasing
    application complexity, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Although there are multiple types of databases, such as SQL, NoSQL, and Graph,
    that can be used to store application data, depending what kind of application
    is required by the enterprise, this chapter focuses on the use of relational database
    management systems using SQL, due to their vast popularity and their ability to
    handle a large amount of use cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will have learned about the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Using **Object Relational Mappers** (**ORMs**) and the benefits they provide
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Structuring database models for efficiency and ease of modification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Focusing on maintaining database consistency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The differences between eager loading and lazy loading
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Taking advantage of caching to speed up queries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The code listings in this book can be found under `chapter03` directory at [https://github.com/PacktPublishing/Hands-On-Enterprise-Application-Development-with-Python.](https://github.com/PacktPublishing/Hands-On-Enterprise-Application-Development-with-Python)
  prefs: []
  type: TYPE_NORMAL
- en: 'The code samples can be cloned by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The code samples provided in this chapter require you to have the following
    system packages installed and configured on their systems:'
  prefs: []
  type: TYPE_NORMAL
- en: '`python-devel`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PostgreSQL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python – `virtualenv`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Beyond these three packages, you will also require the `sqlalchemy` package,
    which provides the ORM we will be using throughout the chapter, and `psycopg2`,
    which provides `postgres` database bindings to allow `sqlalchemy ...`
  prefs: []
  type: TYPE_NORMAL
- en: Database and object relational mappers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we discussed in the previous chapters, Python provides us with a lot of object-oriented
    capabilities, and allows us to map our use cases in terms of classes and objects.
    Now, when we can map our problem set into a class and its objects, why shouldn't
    we also map our database tables as objects, where a particular class represents
    a table, and its objects represent the rows in the table. Going down this route
    helps us to maintain not only the consistency of how we write our code, but also
    how we model our problem.
  prefs: []
  type: TYPE_NORMAL
- en: The frameworks that provide the functionality through which we can map our databases
    to objects are known as ORMs and they help us to visualize our database as a set
    of classes and objects.
  prefs: []
  type: TYPE_NORMAL
- en: In the Python landscape, it is quite common to see ORMs. For example, a popular
    Python web framework, Django, provides its own ORM solution. Then, there is SQLAlchemy,
    which provides a fully-fledged ORM solution and database toolkit supporting a
    wide variety of relational databases.
  prefs: []
  type: TYPE_NORMAL
- en: 'But to convince developers to use ORM frameworks, there should be better advantages
    than merely saying that they are able to map your database into classes and objects,
    and provide you with an object-oriented interface to access the database. Let''s
    take a look at a few of the advantages the use of ORMs brings to the table:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Abstraction from the vendor-specific SQL**: The relational database space
    is full of choices, with several companies marketing their products. Each of these
    products can have differences in how to achieve a certain functionality through
    the use of SQL. Sometimes, some of the databases may implement some SQL keywords
    that are not yet supported in other databases. For developers, this can become
    a problem if they need to support multiple databases with a disjointed set of
    functionality. Since ORMs already know how to deal with these differences in databases,
    they help the developer alleviate the problem of supporting multiple databases.
    Most of the time, when using an ORM, all the developer has to do is modify a database
    connection Uniform Resource Identifier (**URI**) and they are ready to work with
    a new database in their application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reduces the need for repetitive SQL**: When writing an application, there
    are quite a lot of places where the data needs to be retrieved from the same tables
    using similar queries. This will cause a lot of repetitive SQL being written in
    a lot of places, not only giving rise to quite a lot of poorly formatted code,
    but also opening doors for errors to creep in due to an improperly constructed
    SQL query (humans are quite vulnerable to losing their focus when doing repetitive
    work, so won''t this apply to developers also?). ORM solutions help by reducing
    the need for writing SQL to achieve the same results, by providing abstractions
    over SQL commands and generating SQL on the fly, based on how we call the different
    methods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Increased application maintainability**: Since ORMs allow you to define a
    database model once and reuse it throughout the application by instantiating the
    classes, it allows you to make changes in one place, which are then reflected
    across the whole application. This makes the task of maintaining the application
    a bit less tiresome, (at least the parts related to the handling of the database).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Increased productivity**: This in itself is not a feature but a side effect
    of the points mentioned previously. With the use of ORM solutions, developers
    are now a bit more relaxed about always thinking about SQL queries, or trying
    to follow a particular design pattern. They can now just focus on how to best
    architect their applications. This significantly improves developers'' productivity,
    and allows them to get more done and improve the utilization of their time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will focus on how we can utilize ORMs to best develop our
    enterprise applications so that they can easily interact with databases and handle
    large-scale database operations efficiently. For the sake of keeping the chapter
    simple, we will stick with the use of SQLAlchemy, which markets itself as an SQL
    toolkit, and an ORM solution for Python, and provides a lot of bindings for different
    frameworks in the Python landscape. It is being used by some quite large-scale
    projects, such as OpenStack, the Fedora Project, and Reddit.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up SQLAlchemy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we dive into how to create optimal database models for your application
    to promote efficient large-scale database operations, we will first need to set
    up our ORM solution. Since we are going to use SQLAlchemy here, let's see how
    we can set it up in our development environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'For SQLAlchemy to work, you should have a database management system setup,
    either on your system or a remote machine, that you can connect to. A container
    with an exposed port will also get the work done for us. To keep the examples
    simple, we assume the reader is using PostgreSQL as their database solution here,
    and is knowledgeable about how the PostgreSQL setup works. Now, let''s see how
    we can set up SQLAlchemy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Building optimal database models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first step to achieve any efficient access to your database is to build
    an optimal model for your database. If a model is not optimal, the rest of the
    techniques to speed up access to the database will make very little difference.
  prefs: []
  type: TYPE_NORMAL
- en: But before we dive into how we can build an optimal model for the database,
    let's first see how we can actually build any model for our database using SQLAlchemy.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this example, let''s imagine we want to build a model to represent a user
    in our BugZot application. In our BugZot application, a user will be required
    to provide the following fields:'
  prefs: []
  type: TYPE_NORMAL
- en: First name and last name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Username
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Email address
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Password
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additionally, our BugZot application also needs to maintain some more information
    about the user, such as their membership level in the system, the privileges the
    user is entitled to, whether the user account is active or not, and the activation
    key that is sent to the user to activate their account.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s see what happens if we try to model our user table with these requirements
    using SQLAlchemy. The following code depicts how we build a user model in SQLAlchemy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This example shows how we can build a model using SQLAlchemy. Now, let's take
    a look at what we did in the code sample.
  prefs: []
  type: TYPE_NORMAL
- en: In the starting part of the code sample, we first imported the `declarative_base`
    method that is responsible for providing the base class for our models.
  prefs: []
  type: TYPE_NORMAL
- en: The `Base = declarative_base()` line assigns the base model to our base variable.
  prefs: []
  type: TYPE_NORMAL
- en: The next thing we did was to include the different datatypes from SQLAlchemy
    that we will be using in our definition of the model.
  prefs: []
  type: TYPE_NORMAL
- en: The final import imports the Python `datetime` library that we will be using
    in our database model.
  prefs: []
  type: TYPE_NORMAL
- en: Now, without considering how our code will populate the different fields of
    the database model, let's take a look at how we designed our user model.
  prefs: []
  type: TYPE_NORMAL
- en: The first step of designing the model was to define a class user that acts as
    our model class. This class derives from the base model that we initialized earlier
    in our code.
  prefs: []
  type: TYPE_NORMAL
- en: The `__tablename__ = 'users'` line defines the name that should be given to
    the table when this database model is realized inside the database.
  prefs: []
  type: TYPE_NORMAL
- en: Following on from there, we start to define the columns our table will consist
    of. To define the column, we use a `key=value` type approach, where the key defines
    the name of the column, and the value defines the attributes of the column.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, to define the column id, which should be of integer type and should
    act as a primary key for table users, we define it like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now see how simple it is. We did not have to write any SQL to define
    our column. Similarly, it is quite easy to enforce that a particular field should
    have a unique value and cannot have null as a value by just passing `unique=True`
    and `nullable=False` parameters to the column constructor, as can be taken as
    an example from the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: After we have defined all the columns, we provide the definition for the `__repr__`
    method. The `__repr__` method is a magic method that is called by the internal
    `repr()` Python method to provide the representation of the object, such as when
    a user issues `print(userobj)`.
  prefs: []
  type: TYPE_NORMAL
- en: This completes our definition of our user model using SQLAlchemy. It was simple,
    wasn't it? We did not have to write any SQL; we just quickly added the columns
    to a class and left everything else for SQLAlchemy to deal with. Now, while all
    of this was quite fun and easy to achieve, we made some mistakes, which doesn't
    seem to have caused any harm now, but will prove to be costly as our application
    scales up. Let's take a look at these mistakes.
  prefs: []
  type: TYPE_NORMAL
- en: Issues with our model definition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While SQLAlchemy provided us with a lot of abstraction to easily define our
    user model, it also makes it easy for us to make some mistakes, which can prove
    to be costly once the application use scales up and the enterprise grows. Let''s
    take a look at some of the mistakes that we have made while defining this model:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Vulnerability to changes**: The current definition of our user model makes
    it very hard to make changes to the model once the application scales up. Let''s
    take the example of the organization deciding to provide users with more permissions
    on a bug report. In terms of SQL, to achieve the effect, we will need to write
    a query that will traverse through all the records and has `user_role` as the
    user ...'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizing our models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we discuss how to build optimal models, we first need to understand
    the characteristics that need to be present in an optimal model. Let''s take a
    look at the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Easy to adapt**: An optimal model should be easy to adapt according to the
    changing needs of the application as its user base grows. This means changing
    a particular model should not require changes all across the application, and
    should be high in cohesion.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Maximizes the throughput on a host**: Every host has a different architecture,
    and a data model should be able to exploit the underlying host resources in a
    manner that maximizes its throughput. This can be made possible by using the correct
    data storage engine for a particular architecture and use case, or running the
    database across a cluster of machines to increase the parallel execution capabilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Efficient storage**: A database model should also be considerate of the storage
    it may use as the data being stored inside it grows. This can be done by carefully
    choosing data types. For example, just to represent a column that can have only
    two values, true or false, an integer type would be overkill, wasting a lot of
    disk space, as the number of records in the database grows. A nominal data type
    for such a column could be Boolean, which doesn''t takes that much space internally.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Easy to tune**: An efficient model will carefully index the columns that
    can speed up the processing of queries against a particular table. This results
    in an improved response time for the database, and having happy users who don''t
    get frustrated because your application takes up to 20 minutes to return 10,000
    records from the database.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To achieve these goals, we now need to simplify our models, and use the concept
    of relationships that relational databases provide. Let's now start re-factoring
    our user model to make it a bit more optimal.
  prefs: []
  type: TYPE_NORMAL
- en: To achieve this, first we need to break it down from one large model to multiple
    small models, which live independently in our code base and don't have everything
    coupled so hard. Let's get started.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing that we will move out of the model is how we deal with roles
    and permissions. Since roles and their permissions are not something that will
    differ too much from user to user (for sure not every user will have a unique
    role, and not every role can have a varying set of permissions), we can move these
    fields to a different model, known as permissions. The following code illustrates
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Now, we have the roles decoupled from the user model. This makes it easy for
    us to make a modification to the provided roles without causing much of an issue.
    These modifications may include renaming a role or changing the permissions for
    an existing role. All we do is make a modification in a single place and it can
    be reflected for all the users that have the same role. Let's see how we can do
    this with the help of relations in **Relational Database Management System** (**RDBMS**)
    in our user model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code example shows how to achieve the relation between the role
    model and the user model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In this code example, we modified the `user_role` to be an integer, and stored
    a value that is present in the `roles` model. Any attempt to insert a value into
    this field that is not present in the roles model will raise an SQL exception
    that the operation is not permitted.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, continuing with the same example, let''s think about the `activation_key`
    column of the user model. We might not need an activation key once the user has
    activated their account. This provides us with an opportunity to perform one more
    optimization in our user model. We can move this activation key out of the user
    model and store it in a separate model. Once the user has successfully activated
    their account, the record can be safely deleted without the risk of the user model
    being modified. So, let''s develop the model for the activation key. The following
    code sample illustrates what we want to do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we implemented the `ActivationKey` model. Since every activation
    key belongs to a unique user, we need to store which user has which activation
    key. We achieve this by introducing a foreign key to the user model's `id` field.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can safely remove the `activation_key` column from our user model without
    causing any trouble.
  prefs: []
  type: TYPE_NORMAL
- en: Taking advantage of indexes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Indexes are something that can provide a huge amount of performance advantages
    if done on fields that are good candidates for being indexed. But indexes can
    also prove to be of no use or can even harm database performance if the columns
    that are being indexed are not selected with care. For example, indexing every
    single column inside a table may not prove to be of any advantage and will unnecessarily
    eat up disk space, while also making database operations slow.
  prefs: []
  type: TYPE_NORMAL
- en: So, before jumping into how to index a particular field using the ORM we have
    taken up as an example here, let's first clarify what exactly an index is in this
    context of databases, (without diving too deeply into how exactly they work),
    which data structure ...
  prefs: []
  type: TYPE_NORMAL
- en: Maintaining database consistency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Databases usually have a lot of operations happening in parallel throughout
    the life of an application after it has been deployed. These operations can be
    as simple as retrieval of information from the database, or can be operations
    that modify the state of the database by inserting new records, updating existing
    ones, or deleting others. Most of the databases that are currently being used
    in production by large organizations have been built with quite a lot of resilience,
    in terms of dealing with errors and crashes that can happen in the environment
    to disturb the normal functioning of a database. These methods prevent the corruption
    of data and downtime.
  prefs: []
  type: TYPE_NORMAL
- en: But this does not relieve the application developer completely of the fact that
    they still need to be careful about maintaining the consistency of the data inside
    the database. Let's try to understand this situation.
  prefs: []
  type: TYPE_NORMAL
- en: In an enterprise-grade application, there will be a number of database queries
    running in parallel at any given point in time. These queries arise from the use
    of applications from a number of users or internal application maintenance jobs.
    One major fact or in this is that, not all of the queries can be successfully
    executed. This could be due to several reasons, such as data in the query not
    conforming to the schema, an incorrect data type being provided for a column value,
    and violations of constraints. When this happens, the database engine just blocks
    the query from executing and returns an error for the query. This is absolutely
    fine as our incorrect query didn't make any incorrect changes to the database.
    But the situation gets tricky when this query is part of a larger set of operations
    creating a new resource in the database. Now we need to make sure that the changes
    made by other queries before the failed query are reverted.
  prefs: []
  type: TYPE_NORMAL
- en: This kind of behavior can still be fixed with some hard work by the developer
    of the application by tracking the SQL queries and reverting their changes manually
    when things go bananas in between.
  prefs: []
  type: TYPE_NORMAL
- en: But what if the database engine crashes due to an error in between, while one
    of the queries was executing. Now we are in a situation where we cannot predict
    the state of the database, and dealing with these kinds of situations can become
    really tiresome, and can be a task that halts the operations of the whole organization
    for a long time until database consistency is validated. So, what we can do? Is
    there some way through which we can prevent these types of issues from arising?
    The answer is a big yes. Let's take a look.
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing transactions to maintain consistency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A transaction in a relational database provides us with the power to solve the
    issues that we have just discussed. In terms of a relational database, a transaction
    can be considered an envelope consisting of multiple database queries that are
    either executed as one task or are completely reverted if any of them fails. We
    can also consider a transaction an atomic unit in terms of database's operations,
    where even a single failure will revert the whole transaction. But, isn't this
    exactly what we require to solve the issue with our database consistency?
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's take a look at how our ORM solution can help us to implement transactional
    support.
  prefs: []
  type: TYPE_NORMAL
- en: To understand this, let's take an example. Our BugZot ...
  prefs: []
  type: TYPE_NORMAL
- en: Understanding lazy loading versus eager loading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we make a query to load the data from a database, there is a huge possibility
    that this operation might define the response time of the applications we build.
    This happens mainly when there is a lot of data that needs to be loaded and the
    application waits on the database to return all those rows and columns back to
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Such operations may take some time, ranging from a few milliseconds to more
    than 10 seconds, depending on how much data is being queried from the database.
    The question here is, can we optimize this to improve the response times of our
    application?
  prefs: []
  type: TYPE_NORMAL
- en: The answer to this lies in the use of SQL relationships and ORM layer loading
    techniques. While relationships can help us to define how the two models relate
    to each other, loading techniques define how relationships are retrieved by the
    ORM. When a lot of data needs to be loaded, this can prove to be of great help,
    by not only providing a mechanism through which we can defer the loading of data
    of the relationships until they are required, but by also saving quite a lot in
    terms of memory footprint of the application. So, let's take a look at these techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Using relationships
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With relational database management systems in picture, we can now define how
    two models relate to each other. The databases support the modeling of different
    kinds of relationships between the two models, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '**One to One Relationships**: These are the kind of relationships where a record
    from one model relates to only one record from another model. For example, a user
    in our user model has only one activation key mapped to it from our ActivationKey
    model. This is a one to one relationship.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**One to Many Relationships**: These are the kind of relationships where a
    record from one model maps to multiple records from another model. For example,
    if we have a model named Bug, describing the bug entries, then we can say, a user
    ...'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lazy loading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A lot of ORM layers, as well as SQLAlchemy, try to make the effort to delay
    the loading of data for as long as possible. Usually, data is loaded only when
    the object is actually accessed by the application. This technique of delaying
    the loading of data until there is an attempt to access that data is known as
    lazy loading.
  prefs: []
  type: TYPE_NORMAL
- en: This technique is really helpful for reducing the response times of an application,
    since the entire data is not loaded in one go but is instead loaded on demand.
    This optimization comes at the expense of running a few more SQL queries, which
    will retrieve the actual data as the request is made. But is there some way we
    can have explicit control over this technique?
  prefs: []
  type: TYPE_NORMAL
- en: The answer to this will differ for every ORM solution, but quite a lot of them
    actually allow you to enable or disable lazy loading behavior. So, how do we control
    this in SQLAlchemy?
  prefs: []
  type: TYPE_NORMAL
- en: 'Taking a look at the user model modification we made in the previous section,
    we can explicitly tell SQLAlchemy to lazy load the data from our role model by
    adding an extra attribute in our role field, as can be seen in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This extra `lazy_load` attribute defines the technique SQLAlchemy uses to load
    the data from our role model. The following example shows the flow of a request
    during a lazy load:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: As we can see from this example, SQLAlchemy dosen't make an attempt to load
    the data of the role model until and unless we try to access it. As soon as we
    try accessing the data from the role model, SQLAlchemy makes a `SELECT` query
    to the database, fetches the results in the object, and returns the populated
    object, which we can use now.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast to the technique of loading data on demand, we can also ask SQLAlchemy
    to load all the data as soon as the first request is made. This can save us waiting
    those few extra milliseconds that the application will wait until the ORM layer
    fetches the data on demand from the database.
  prefs: []
  type: TYPE_NORMAL
- en: This technique is called **eager loading**, as we will explain in the upcoming
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Eager loading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are situations when we want the data of the object we want to be loaded
    along with the relationships our object maps to. This is a valid use case, such
    as when the developer is sure they will be accessing the data of the relationship,
    no matter the situation.
  prefs: []
  type: TYPE_NORMAL
- en: In these kinds of use cases, there is no point wasting time while the ORM layers
    load the relationships on demand. This technique of loading the object data along
    with the data of the associated objects to which our main object is related is
    known as eager loading.
  prefs: []
  type: TYPE_NORMAL
- en: SQLAlchemy provides an easy way to achieve this behavior. Remember the `lazy_load`
    attribute we specified in the previous section? Yes, that's all you need to switch
    from lazy load behavior to eager load ...
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing data loading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the boosts that we can give to our application's performance is by optimizing
    the way it loads data from the database. This is not something that is complex
    to implement, and ORM solutions make it much simpler to get all of this up and
    running.
  prefs: []
  type: TYPE_NORMAL
- en: 'Optimizing data loading just has a few rules. So, let''s take a look at what
    these are, and how they can prove to be advantageous:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Defer the loading of data that can be skipped**: When we know that we won''t
    require all the data that we are fetching from the database, we can safely defer
    the loading of that data by utilizing the lazy loading technique. For example,
    if we wanted to send a mail to all those users of our BugZot application who have
    more then 10 bugs pending against them and who are not an administrator, we could
    just defer the loading of the role''s relationship.  Considering a big database
    with a lot of users, this can help to significantly reduce the response time of
    the application, as well as its overall memory footprint, at the expense of a
    few extra queries, which might be a desirable trade-off to make.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Load data early if it is going to be used**: In complete contrast to the
    first point, if we know that the application will use data, no matter the situation,
    then it makes complete sense to load it in one shot rather than emitting extra
    queries to load data on demand. For example, if we wanted to promote all the administrators
    to super administrators, we know we will be accessing the role field of all the
    users. Then, it doesn''t makes sense to make the application lazy load the roles
    field. We can simply ask the application to eager load the required data so that
    the application doesn''t wait for the data to get loaded on demand. This type
    of optimization comes at the cost of increased memory usage and slow initial response
    times, but provides the advantage of fast execution, once all the data has been
    loaded.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Do not load data that won''t be required**: There are times when some of
    the relationships an object maps to are not required at all during processing.
    In these kinds of situations, we can save a lot of memory and time by simply not
    loading those relationship objects at all. This can be fairly easily achieved
    in SQLAlchemy by simply setting `lazy_load=''noload''`. One example of such a
    use case is where loading of the relation is not required when all we want to
    do is to update the `last_active` time of the user in the database. In this case,
    we know that we are not required to validate anything related to the role of the
    user, and hence we can skip the loading of the role altogether.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Achieving these effects clearly cannot be done if the loading technique is embedded
    in the model definition altogether. So, SQLAlchemy does provide another way to
    achieve these effects through the use of different methods, named, aptly, based
    on the technique they use to load the data from the database, for example, `lazyload()`
    for lazy loading, `joinedload()` for joined eager loading, `subqueryload()` for
    subquery eager loading, and `noload()` for no loading, which we will explain in
    later chapters, including how they can be used in a real application.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we're familiar with loading techniques and how we can use them to our
    advantage, now let's take a look at one of the final topics of this chapter, where
    we will see how we can utilize caching to speed up our application response times,
    as well as saving the effort of querying our database again and again, which will
    indeed help us during times when the application is performing a lot of data-intensive
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing caching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In most enterprise applications, data that has been accessed once is used again
    and again. This could be in different requests, or could be because the requests
    are operating on the same set of data.
  prefs: []
  type: TYPE_NORMAL
- en: In these kinds of scenarios, it would be a huge waste of resources if we tried
    to access the same data again and again from the database, causing the application
    to make a lot of queries to the database, resulting in high database loads and
    poor response times.
  prefs: []
  type: TYPE_NORMAL
- en: The ORM layers we use provide some degree of caching to already accessed data,
    but still, most of the control resides in the hands of the application developer,
    who can use his wisdom to make the application performant by analyzing which data
    will be used again and again, ...
  prefs: []
  type: TYPE_NORMAL
- en: Caching at the database level
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Databases are quite a complex piece of software. Not only do they store our
    data efficiently, they provide us with mechanisms to retrieve that data with the
    same efficiency as well. This involves quite a lot of complex logic going on behind
    the scenes.
  prefs: []
  type: TYPE_NORMAL
- en: One of the advantages of using an ORM is the caching the database can perform
    at the query level. Since databases are supposed to return data in the fastest
    manner possible, database systems usually cache queries that are performed again
    and again. This caching happens at the query parsing level so that some time can
    be saved by not parsing the same query again and again when it is done on the
    database.
  prefs: []
  type: TYPE_NORMAL
- en: This kind of caching boosts response times since quite a lot of effort is saved
    parsing queries.
  prefs: []
  type: TYPE_NORMAL
- en: Caching at the block level
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, let's take a look at the kind of caching we can use at the application
    level, which can prove to be a major help.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand the concept of caching at the application block level, let''s
    take a look at the following simple code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'From what we can assume, this could have done a query once and then retrieved
    the data from the database, and then will have used it again and again to compare
    it with the name variable. But let''s take a look at the output of the preceding
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Using user-level caching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: User-level caching is another level of caching that can prove to be of quite
    a lot of use. Imagine querying the personal details of the user from the database
    every time the user moves from one page to another. This would not only be inefficient,
    but would also penalize during high-load situations, when the response times of
    the database could be so high that a request could just time out and the user
    would not be able to log in to the application until the overall load reduced.
  prefs: []
  type: TYPE_NORMAL
- en: So, is there anything that can help here?
  prefs: []
  type: TYPE_NORMAL
- en: The answer to this is user-level caching. When we know that some data is specific
    to the user and is not critical to security, we can simply load it once from the
    database and save it on the user side. This can be achieved by implementing cookies
    or creating temporary files on the client side. These cookies or temporary files
    store non-confidential data about the user, such as user ID or username, or other
    non-important data, such as the name of the user.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever the application wants to load this data, instead of going to the database
    directly, it first checks whether the user has this data available at their end.
    If the data is found, then the data is loaded from there. If the data is not found
    on the user side, the request is made to the database, and the data is loaded
    from there, before being finally cached on the client side.
  prefs: []
  type: TYPE_NORMAL
- en: This kind of technique helps a lot when trying to reduce the impact of data
    loading that is specific to users and does not need to be refreshed from the database
    frequently.
  prefs: []
  type: TYPE_NORMAL
- en: There are much more sophisticated techniques for caching data by using key-value
    caching mechanisms, as we will see in later chapters, such as implementing in-memory
    caches using tools such as memcached, which can prove to be of great help when
    dealing with huge amounts of data. However, this is beyond the scope of this book,
    due to the complexity of the topics involved, which can span several hundreds
    of pages.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about how to build database models that can help
    us make our application performant when dealing with data on a large scale. We
    saw how optimizing a model can be the first stage of optimization, and how it
    can help us make our application more maintenance-friendly, by reducing coupling
    across database models. We then moved on to cover how indexes can be useful for
    making accessing data inside the database faster, by indexing columns that are
    more frequently accessed.
  prefs: []
  type: TYPE_NORMAL
- en: We later covered one of the important aspects of maintaining the consistency
    of the database, through the use of transactions.
  prefs: []
  type: TYPE_NORMAL
- en: The final part of the chapter covered data loading techniques, such as lazy
    loading, eager loading, and no loading, ...
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is the benefit of normalizing database tables?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between lazy loading through `select` versus lazy loading
    through `joined`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can we maintain the integrity of data while running database update queries?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the different levels of caching data from a database?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
