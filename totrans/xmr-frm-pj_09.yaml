- en: Hot Dog or Not Hot Dog Using Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will learn how to use machine learning to create a model
    that we can use for image classification. We will export the model as a TensorFlow
    model that we can use on Android devices and a CoreML model that we can use on
    iOS devices. In order to train and export models, we will use Azure Cognitive
    Services and the Custom Vision service.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have exported the models, we will learn how to use them for Android
    and iOS apps.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Training a model with Azure Cognitive Service Custom Vision
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to use TensorFlow models for image classification on an Android device
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to use CoreML models for image classification on an iOS device
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To be able to complete this project, you need to have Visual Studio for Mac
    or PC installed, as well as the Xamarin components. See [Chapter 1](80b2455c-7174-4e4b-b2eb-916d03b9d3f6.xhtml), *Introduction
    to Xamarin*, for more details on how to set up your environment. To use Azure
    Cognitive Services, you need a Microsoft account. The source code for this chapter
    is available at the GitHub repository at [https://github.com/PacktPublishing/Xamarin.Forms-Projects/tree/master/Chapter-9](https://github.com/PacktPublishing/Xamarin.Forms-Projects/tree/master/Chapter-9).
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The term machine learningwas coined in 1959 by Arthur Samuel, an American pioneer
    in artificial intelligence. Tom M. Mitchell, an American computer scientist, provided
    a more formal definition of machine learning later:'
  prefs: []
  type: TYPE_NORMAL
- en: A computer program is said to learn from experience E with respect to some class
    of tasks T and performance measure P if its performance at tasks in T, as measured
    by P, improves with experience E.
  prefs: []
  type: TYPE_NORMAL
- en: In simpler terms, this quote describes a computer program that has the ability
    to learn without being explicitly programmed. In machine learning, algorithms
    are used to build a mathematical model of sample data or training data. The models
    are used for computer programs to make predictions and decisions without being
    explicitly programmed for the task in question.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Cognitive Services – Custom Vision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Custom Vision is a tool or service that can be used for training models for
    image classification and for detecting objects in images. In Custom Vision, we
    are able to upload our own images and tag them so that they can be trained for
    image classification. If we train a model for object detection, we can also tag
    specific areas of an image. Because models are already pretrained for basic image
    recognition, we don't need a large amount of data to get a great result. The recommendation
    is to have at least 30 images per tag.
  prefs: []
  type: TYPE_NORMAL
- en: When we have trained a model, we can use it with an API that is part of the
    Custom Vision service. We can also, however, export models for CoreML (iOS), TensorFlow
    (Android), ONNX (Windows), and Dockerfile (Azure IoT Edge, Azure Functions, and
    AzureML). These models can be used to carry out classification or object detection
    without having a connection to the Custom Vision service.
  prefs: []
  type: TYPE_NORMAL
- en: CoreML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CoreML is a framework that was introduced in iOS 11\. CoreML makes it possible
    to integrate Machine Learning models into iOS apps. On top of CoreML, we have
    three high-level APIs—Vision APIs for image analysis, natural language APIs for
    natural language processing, and Gameplay Kit for evaluating learned decision
    trees. More information about CoreML can be found in the official documentation
    from Apple at [https://developer.apple.com/documentation/coreml](https://developer.apple.com/documentation/coreml).
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TensorFlow is an open source machine learning framework, which can be found
    at [https://www.tensorflow.org/](https://www.tensorflow.org/). TensorFlow can
    be used for more than simply running models on mobile devices—it can also be used
    for training models. For running it on mobile devices, we have TensorFlow Mobile
    and TensorFlow Lite. The models that are exported from Azure Cognitive Services
    are for TensorFlow Mobile. There are also Xamarin bindings for both TensorFlow
    Mobile and TensorFlow Lite, which are available as NuGet packages. However, bear
    in mind that plans have been made to depreciate TensorFlow Mobile during 2019\.
    This does not mean that we can't use it after that, but it does mean that it is
    unlikely to get any more updates after they have depreciated it, and as long as
    Custom Vision still exports models for TensorFlow Mobile, we will continue to
    use it. The concepts will be the same, even if the APIs look a bit different.
  prefs: []
  type: TYPE_NORMAL
- en: Project overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you have seen the TV series *Silicon Valley*, you have probably heard of
    the *Not Hotdog* application. In this chapter, we will learn how to build that
    app. The first part of this chapter will involve collecting the data that we will
    use for creating a machine learning model that can detect whether or not a photo
    has a hot dog.
  prefs: []
  type: TYPE_NORMAL
- en: In the second part of the chapter, we will build an app for iOS and an app for
    Android where the user can pick a photo in the photo library in order to analyze
    it to see whether it has a hot dog. The estimated time for completing this project
    is 120 minutes.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can use either Visual Studio 2017 on a PC or Visual Studio for Mac to do
    this project. To build an iOS app using Visual Studio for PC, you must have a
    Mac connected. If you don't have access to a Mac at all, you can choose to just
    do the Android parts of this project. Similarly, if you only have a Mac, you can
    choose to just do the iOS or Android parts of this project.
  prefs: []
  type: TYPE_NORMAL
- en: Building the Hot Dog or Not Hot Dog application using machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's get started! We will first train a model for image classification that
    we can use later in the chapter to decide whether a photo has a hot dog.
  prefs: []
  type: TYPE_NORMAL
- en: Training a model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To train a model for image classification, we need to collect photos of hot
    dogs and photos that aren't of hot dogs. Because most items in the world are not
    hot dogs, we need more photos that don't contain hot dogs. It's better if the
    photos of hot dogs cover a lot of different hot-dog scenarios—with bread, with
    ketchup, or with mustard, such as. This is so the model will be able to recognize
    hot dogs in different situations. When we are collecting photos that aren't of
    hot dogs, we also need to have a big variety of photos that are both of items
    that are similar to hot dogs and that are completely different to hot dogs.
  prefs: []
  type: TYPE_NORMAL
- en: The model that is in the solution on GitHub was trained with 240 photos, 60
    of which were of hot dogs and 180 of which were not.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have collected all the photos, we will be ready to start training the
    model by going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://customvision.ai](https://customvision.ai).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log in and create a new project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Give the project a name—in our case, `HotDogOrNot`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The project type should be Classification.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select General (compact) as the domain. We use a compact domain if we want to
    export models and run them on a mobile device.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click Create project to continue, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/63c7c8a3-0227-4c15-b2f4-312c4ade4165.png)'
  prefs: []
  type: TYPE_IMG
- en: Tagging images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once we have created a project, we can start to upload images and tag them.
    We will start by adding photos of hot dogs by going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Click Add images.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the photos of hot dogs that should be uploaded.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Tag the photos with hotdog, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/efe2e175-e770-4e68-997c-8d7494336788.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once we have uploaded all the photos of hot dogs, it is time to upload photos
    that aren''t of hot dogs by going through the following steps. For best results,
    we should also include photos of objects that look similar to hot dogs but are
    not:'
  prefs: []
  type: TYPE_NORMAL
- en: Click Add images.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the photos that aren't of hot dogs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Tag the photos with not-hotdog, as shown in the following screenshot. Set this
    tag as a negative tag. A negative tag is used for photos that don''t contain any
    objects that we have created other tags for. In this case, none of the photos
    we will upload contain hot dogs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7e8a8e61-fa42-4767-9e77-d53590b6cabe.png)'
  prefs: []
  type: TYPE_IMG
- en: Training a model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once we have uploaded the photos, it is time to train a model. Not all the photos
    that we are uploading will be used for training; some will be used for verification,
    to give us a score about how good the model is. If we upload photos in chunks
    and train the model after each chunk, we will be able to see our scores improving. To
    train a model, click the green Train button at the top of the page.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the result of a training iteration, where the
    precision of the model is 93.4%:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3fdce6a7-9a2a-435c-be74-15400236186b.png)'
  prefs: []
  type: TYPE_IMG
- en: Exporting a model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once we have trained a model, we will be able to export it so that it can be
    used on a device. We can use the APIs if we want to, but to make fast classifications,
    and to be able to do this offline, we will add the models to the app packages.
    Export and download the CoreML model and the TensorFlow model, as shown in the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2d31e16a-cd98-4f10-847a-fc0f27fa2258.png)'
  prefs: []
  type: TYPE_IMG
- en: Building the app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once we have one CoreML model and one TensorFlow model, it is time to build
    the app. Our app will use the trained models to classify photos according to whether they
    are photos of hot dogs. The CoreML model that we exported from the Custom Vision
    service will be used for iOS and the TensorFlow model for Android.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new project with the template for Mobile App (Xamarin.Forms). The
    template can be found under the Cross-Platform tab. Use `HotDotOrNot` as the name
    of the project, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a1ba39cd-ba5a-43a5-83b7-eeada2179706.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the next step, we will select what Xamarin.Forms template we should use.
    For our project, select Blank. For this project, we will target Android and iOS
    as the platforms and use .NET Standard as the code-sharing strategy, as shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/292ca4cd-e87f-4563-8e81-c0d2340024fe.png)'
  prefs: []
  type: TYPE_IMG
- en: Before doing anything else we will update the Xamarin.Forms NuGet package to
    make sure that we have the latest version of it.
  prefs: []
  type: TYPE_NORMAL
- en: Classifying images with machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The code that we will use for image classification cannot be shared between
    the iOS and the Android projects. However, to be able to carry out classifications
    from shared code (the `HotDogOrNot` project), we will create an interface. First,
    however, we will create a class for the `EventArgs` that we will use in the interface
    by going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: In the `HotDogOrNot` project, create a new class called `ClassificationEventArgs`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add `EventArgs` as a base class, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have created the `ClassificationEventArgs`, we can create the interface
    by going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: In the `HotdogOrNot` project, create a new interface called `IClassifier` in
    the `HotdogOrNot` project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a method called `Classify` that doesn't return anything but takes a byte
    array as an argument.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add an event that uses the `ClassificationEventArgs` and call it `ClassificationCompleted`,
    as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Using CoreML for image classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first thing we will do is add the CoreML model to the `HotDogOrNot.iOS`
    project by going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Extract the ZIP file that we get from the Custom Vision service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the `.mlmodel` file and rename it as `hotdog-or-not.mlmodel`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add it to the `Resources` folder in the iOS project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make sure that the build action is `BundleResource`. If you are using Visual
    Studio on a Mac, a `.cs` file will be created. Remove this file, because it will
    be easier to use the model without the code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'When we have added the file to the iOS project, we will be ready to create
    the iOS implementation of the `IClassifier` interface by going through the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new class called `CoreMLClassifier` in the `HotDogOrNotDog.iOS` project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the `IClassifier` interface.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Implement the `ClassificationCompleted` event and the `Classify` method from
    the interface, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The first thing we will do in the `Classify` method is compile the CoreML model by
    going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Get the path of the model with the `NSBundle.MainBundle.GetUrlForResource` method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compile the model with the `MLModel.CompileModel `method. Pass the model's URL
    and an error object that will indicate whether one or more errors occurred during
    the compilation of the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the URL from the `CompileModel` method and pass it to `MLModel.Create`
    to create a model object that we can work with, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Because we are going to use a photo for the CoreML model, we can use the Vision
    APIs that are built on top of the CoreML. To do this, we will use `VNCoreMLRequest`.
    Before creating the request, however, we will create a callback that will handle
    when the request is completed by going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the `CoreMLClassifier.cs`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new private method called `HandleVNRequest`with two parameters, one
    of the `VNRequst` type and one of the `NSError` type.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the error is `null`, invoke the `ClassificationCompleted` event with `ClassificationEventArgs`,
    which contains an empty `Dictionary`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the error is not null, get the result with the `GetResults` method on the
    `VNRequest` object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Order the classifications by `Confidence` so that the classification with the
    highest confidence is first.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Convert the result to a `Dictionary` using the `ToDictionary` method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Invoke the `ClassificationCompleted` event with `ClassificationEventArgs`,
    which contains the sorted dictionary. This is shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'When we have created the callback, we will go back to the `Classify` method
    and perform the classification by going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Convert the model to a `VNCoreMLModel`, because we need this to use the Vision
    APIs. Use the `VNCoreMLModel.FromMLModel` method to convert the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new `VNCoreMLRequest` object and pass the `VNCoreMLModel` and the callback
    we created as arguments to the constructor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Convert the input data to an `NSData` object using the `NSData.FromArray` method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new `VNImageRequestHandler` object and pass the data object, `CGImagePropertyOrientation.Up`,
    and a new `VNImageOptions` object to the constructor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the `Perform` method on the `VNImageRequestHandler` and pass the `VNCoreMLRequest`
    in an array and an error object as an argument, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Using TensorFlow for image classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have written the code in iOS to recognize hot dogs, it is now time
    to write the code for Android. The first things to do is to add the files we exported
    from the Custom Vision to the Android project. For TensorFlow, the actual model
    and the labels (the tags) are separated into two files. Let''s set this up by
    going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Extract the ZIP file that we got from the Custom Vision service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the `model.pb` file and rename it as `hotdog-or-not-model.pb`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the `labels.txt` file and rename it as `hotdog-or-not-labels.txt`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Import the files to the `Assets` folder in the Android project. Make sure that
    the build action is Android Asset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'When we have imported the files into the Android project, we can start to write
    code. To get the libraries we need for TensorFlow, we also need to install a NuGet
    package by going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: In the `HotDogOrNotDog.Android` project, install the `Xam.Android.Tensorflow`
    NuGet package.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, create a new class called `TensorflowClassifier` in the `HotDogOrNotDog.Android`
    project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the `IClassifier` interface to the `TensorflowClassifier` class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Implement the `ClassificationCompleted` event and the `Classify` method from
    the interface, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The first thing we will do in the `Classify` method is read the model and the
    label files from the `Assets` folder by going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Use the `TensorFlowInferenceInterface` class to import the model. After that,
    use the path to the asset folder and the name of the model file as arguments for
    the constructor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use `StreamReader` to read the labels.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Read the whole text file, split by line breaks (`''/n''`), and trim the text
    on each row to remove whitespaces. We will also filter away items that are empty
    or null and convert the result to a list of strings, as shown in the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '`TensorFlow` models do not understand images, so we need to convert them to
    binary data. The images need to be converted to a float array of point values,
    one per red, green, and blue value for each pixel. Some adjustments to the color
    values are also necessary. As well as this, we need to resize the images so that
    they are `227 x 227` pixels. To do this, write the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We are now ready to run the model by going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new array of floats with the same size as the list of labels. The output
    of the model will be fetched into this array. An item in the array will represent
    the confidence for a tag. The matching label will have the same position in the
    labels list as the confidence result in the float array.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the `Feed` method of the `TensorFlowInferenceInterface`and pass `"Placeholder"` 
    as the first argument, the binary data as the second argument, and the dimensions
    of the image as the third argument.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the `Run` method of `TensorFlowInferenceInterface` and pass an array that
    contains a string with the value `"loss"`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the `Fetch` method of the `TensorFlowInferenceInterface`. Pass `"loss"`
    as the first argument and the float arrays for the outputs as the second argument.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a `Dictionary <string, float>` and fill it with the labels and the confidence
    for each label.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Invoke the `ClassificationCompleted` event with `ClassificationEventArgs`,
    which contains the dictionary, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Creating a base ViewModel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we initialize the app, we will create a base ViewModel so that we can
    use it when we are registering the other ViewModels. In this, we will put the
    code that can be shared between all the ViewModels of the app. Let''s set this
    up by going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: In the `HotDogOrNot` project, create a new folder called `ViewModels`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new class called `ViewModel` in the `ViewModels` folder we created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make the new class public and abstract.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add and implement the `INotifiedPropertyChanged` interface. This is necessary
    because we want to use data bindings.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a `Set` method that will make it easier for us to raise the `PropertyChanged` event
    from the `INotifiedPropertyChanged` interface. The method will check whether the
    value has changed. If it has, it will raise the event.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add a static property of the `INavigation` type called `Navigation`, as shown
    in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Initializing the app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are now ready to write the initialization code for the app. We will set up
    **inversion of control** (**IoC**) and carry out the necessary configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Resolver
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will now create a helper class that will ease the process of resolving object
    graphs through `Autofac`. This will help us to create types based on a configured
    IoC container. In this project, we will use `Autofac` as the IoC library by going
    through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: In the `HotDogOrNot` project, install the NuGet package `Autofac` to the `HotDogOrNot`
    project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new class called `Resolver` in the root.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a private static field of the `IContainer` type called `container` (from
    `Autofac`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a public static method called `Initialize` with `IContainer` as a parameter.
    Set the value of the parameter to the container field.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add a generic `static public` method called `Resolve`, which will return an
    instance that is based on the type argument with the `Resolve` method of `IContainer`,
    as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Creating a Bootstrapper
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To configure the dependency injection and initialize the `Resolver`, we will
    create a bootstrapper. We will have one shared bootstrapper and one bootstrapper
    for each platform to match their specific configurations. We will have different
    implementations of the `IClassifier` in iOS and Android. To create a bootstrapper, go
    through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new class in the `HotDogOrNot` project and name it `Bootstrapper`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Write the following code in the new class, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Creating the iOS bootstrapper
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the iOS bootstrapper, we will have configurations that are specific to the
    iOS app. To create an iOS app, we go through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: In the `HotDogOrNot.iOS` project, create a new class and name it `Bootstrapper`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make the new class inherit from `HotDogOrNot.Bootstrapper`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Write the following code and resolve all the references:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Go to `AppDelegate.cs` in the iOS project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Before the call to `LoadApplication`, in the `FinishedLaunching` method, call
    the `Init` method of the platform-specific bootstrapper, as shown in the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Creating the Android bootstrapper
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the Android bootstrapper, we will have configurations that are specific
    to the Android app. To create bootstrapper in Android, we go through the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: In the Android project, create a new class and name it `Bootstrapper`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make the new class inherit from `HotDogOrNot.Bootstrapper`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Write the following code and resolve all the references:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Go to the `MainActivity.cs` file in the Android project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Before the call to `LoadApplication`, in the `OnCreate` method, call the `Execute` method
    of the platform-specific bootstrapper, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Building the first view
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first view in this app will be a simple view with two buttons. One button
    will be for starting the camera so the users can take a photo of something to
    determine whether it is a hot dog. The other button will be for picking a photo
    from the photo library of the device.
  prefs: []
  type: TYPE_NORMAL
- en: Building the ViewModel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will start by creating the `ViewModel`, which will handle what will happen
    when a user taps one of the buttons. Let''s set this up by going through the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new class called  `MainViewModel` in the `ViewModels` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add `ViewModel` as a base class for `MainViewModel`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a private field of the `IClassifier` type and call it `classifier`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a constructor that has the `IClassifier` as a parameter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Set the value of the classifier field to the value of the parameter in the
    constructor, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use the `Xam.Plugin.Media` NuGet package for taking the photo and accessing
    the photo library of the device. We need to install the package for all projects
    in the solution by using the NuGet package manager. Before we can use the package,
    however, we need to do some configuration for each platform. We will start with
    Android. Let''s set this up by going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: The plugin needs the `WRITE_EXTERNAL_STORAGE`and `READ_EXTERNAL_STORAGE` permissions.
    The plugin will add these for us, but we need to override the `OnRequestPermissionResult`
    in the `MainActivity.cs`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Call the `OnRequestPermissionsResult` method, as shown in the following code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add `CrossCurrentActivity.Current.Init(this, savedInstanceState)` after initializing
    Xamarin.Forms in the `OnCreate` method in the `MainActivity.cs` file, as shown
    in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We also need to add some configuration about the file paths from which the
    users can pick photos. Let''s set this up by going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: In the `HotDogOrNot.Android` project, add a folder called `xml` to the `Resources`
    folder
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new XML file called `file_paths.xml` in the new folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following code to `file_paths.xml`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The last thing we need to do to set up the plugin for the Android project is
    add the following code in the `AndroidManifest.xml` (it can be found in the `Properties`
    folder of the Android project) inside the application element:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'For the iOS project, the only thing we need to do is add the following four
    usage descriptions to the `info.plist`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Once we have finished with the configuration for the plugin, we can start using
    it. We will start by creating a method that will handle the media file that we
    will get both when the user is taking a photo and when the user is picking a photo.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s set this up by going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the `MainViewModel.cs` file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a private method called `HandlePhoto` that has a parameter of the `MediaFile`type.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add an `if` statement to check whether the `MediaFile` parameter is `null`.
    If so, perform an empty return.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Get the stream of the photo using the `GetStream` method of the `MediaFile`
    class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a private field of the `byte []` type called `bytes`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Convert the stream into a byte array with the `ReadFully` method that we will
    create in the next step.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add an event handler to the `ClassificationCompleted` event of the classifier.
    We will create the event handler later in this chapter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Finally, add a call to the `Classify` method of the classifier and use the
    byte array as the argument, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now create the `ReadFully` method that we called in the preceding code.
    We will use this to read the full stream into a byte array. The code will look
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Before we create the event handler, we will create a model that we will use
    inside the event handler by going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: In the `HotDogOrNot` project, create a new folder called `Models` in the `HotDogOrNot`
    project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new class in the `Models` folder called `Result`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a property of the `bool` type called `IsHotdog`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a property of the `float` type called `Confidence`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add a property of the `byte[]` type called `PhotoBytes`, as shown in the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now add an event handler to the ViewModel by going through the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a method called `Classifier_ClassificationCompleted` that has an `object` and
    a `ClassificationEventArgs` parameter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Remove the event handler from the classifier so that we don't allocate unnecessary
    memory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check whether the classifications dictionary contains any items. If it does,
    order the dictionary so that the classifications with the highest confidence (values)
    will be first.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a new `Result` object and set the properties as shown in the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'When we have created the result view, we will go back to the event handler
    to add the navigation to the result view. The last thing we will do in this `ViewModel`
    is create a `Command` property for the buttons that we have in the view. Let''s
    start by setting up the take photo button by going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new property of the `ICommand` type called `TakePhoto` in the `MainViewModel.cs`
    file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use an expression to return a new `Command`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pass an `Action `as an expression to the constructor of the `Command`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the `Action`, use the `CrossMedia.Current.TakePhotoAsync` method and pass
    a `StoreCameraMediaOptions` object to it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In `StoreCameraMediaOptions`, set the default camera as the rear camera using
    the `DefaultCamera` property.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Pass the result of the call to the `TakePhotoAsync` method to the `HandlePhoto`
    method, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The final thing we will do in the `MainViewModel` for now is to handle what
    happens when the pick photo from library button is tapped. Let''s set this up
    by going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new property of the `ICommand` type called `PickPhoto`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use an expression to return a new `Command`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pass an `Action `as an expression to the constructor of the `Command`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the `Action`, use the `CrossMedia.Current.PickPhotoAsync` to open the default
    photo picker of the operating system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Pass the result of the call to the `TakePhotoAsync` method of the `HandlePhoto` method,
    as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Building the view
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, once we have created the `ViewModel`, it is time to create the code for
    the GUI. Go through the following steps to create the GUI for the `MainView`:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new folder called `Views` in the `HotDogOrNot` project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a new `XAML ContentPage` called `MainView`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the `Title` property of the `ContentPage` to `Hotdog or Not hotdog`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a `StackLayout` to the page and set its `VerticalOptions` property to `Center`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a `Button` to the `StackLayout` with the text `Take Photo`. For the `Command`
    property, add a binding to the `TakePhoto` property in the `ViewModel`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add a `Button` to the `StackLayout` with the text `Pick Photo`. For the `Command` property,
    add a binding to the `Pick``Photo` property in the `ViewModel`, as shown in the
    following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'In the code behind the `MainView`, we will set the binding context of the view
    by going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Add `MainViewModel` as a parameter of the constructor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After the `InitialComponent` method call, set the `BindingContext` property
    of the view to the `MainViewModel` parameter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the static method `SetBackButtonTitle` on the `NavigationPage` class so
    that an arrow for navigation back to this view will be shown in the navigation
    bar on the result view, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can go to `App.xaml.cs` and set the `MainPage` to `MainView` by going
    through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: In the `HotDogOrNot` project, go to `App.xaml.cs`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an instance of `MainView` using the `Resolve` method on the `Resolver`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a `NavigationPage` and pass the `MainView` to the constructor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the static `Navigation` property on the `ViewModel` to the value of the
    `Navigation` property on the `NavigationPage`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the `MainPage` property to the instance of the `NavigationPage` that we
    created in step 3.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Delete `MainPage.xaml`, because we no longer need it. You should be left with
    the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Building the result view
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The last thing we need to do in this project is to create the result view. This
    view will show the input photo, and whether or not it is a hot dog.
  prefs: []
  type: TYPE_NORMAL
- en: Building the ViewModel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we create the view, we will create a `ViewModel` that will handle all
    the logic for the view by going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a class called `ResultViewModel` in the `ViewModels` folder in the `HotdogOrNot`
    project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add `ViewModel` as a base class to the `ResultViewModel`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a property of the `string` type called `Title`. Add a private field for
    the property.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a property of the `string` type called `Description`. Add a private field
    for the property.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a property of the `byte[]` type called `PhotoBytes`. Add a private field
    for the property, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The final thing we will do in the `ViewModel` is to create an `Initialize`
    method that will have the result as a parameter. Let''s set this up by going through
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: In the `Initialize` method, set the `PhotoBytes` property to the value of the
    `PhotoBytes` property of the `result` parameter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add an `if` statement that checks whether the `IsHotDog` property of the `result`
    parameter is `true` and whether the `Confidence` is higher than 90%. If this is
    the case, set the `Title` to `"Hot dog"` and the `Description` to `"This is for
    sure a hotdog"`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add an `else if` statement to check whether the `IsHotdog` property of the `result`
    parameter is `true`. If this is the case, set the `Title` to `"Maybe"` and the
    `Description` to `"This is maybe a hotdog"`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add an `else` statement that sets the `Title` to `"Not a hot dog"` and the
    `Description` to `"This is not a hot dog"`, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Building the view
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Because we want to show the input photo in the input view, we need to convert
    it from `byte[]` to `Xamarin.Forms.ImageSource`. We will do this in a value converter
    that we can use together with the binding in the XAML by going through the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new folder called `Converters` in the `HotDogOrNot` project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new class called `BytesToImageConverter`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add and implement the  `IValueConverter` interface, as shown in the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Convert` method will be used when a `ViewModel` updates a view. The `ConvertBack`
    method will be used in two-way bindings when the `View` updates the `ViewModel`.
    In this case, we only need to write code for the `Convert` method by going through
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: First, check whether the `value` parameter is `null`. If so, we should return
    `null`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the value not is `null`, cast it as `byte[]`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a `MemoryStream` from the byte array.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Return the result of the `ImageSource.FromStream` method to which we will pass
    the stream to, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The view will contain the photo, which will take up two-thirds of the screen.
    Under the photo, we will add a description of the result. Let''s set this up by
    going through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: In the `Views` folder, create a new `XAML ContentPage` and name it `ResultView`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Import the namespace for the converter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the `BytesToImageConverter` to the `Resources` for the page and give it
    the key `"ToImage"`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bind the `Title` property of the `ContentPage` to the `Title` property of the
    `ViewModel`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a `Grid` to the page with two rows. The `Height` value for the first `RowDefinition`
    should be `2*`. The height of the second row should be `*`. These are relative
    values that mean that the first row will take up two-thirds of the `Grid`, while
    the second row will take up one-third of the `Grid`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add an `Image` to the `Grid` and bind the `Source` property to the `PhotoBytes`
    property in the `ViewModel`. Use the converter to convert the bytes to the `ImageSource`
    of the `Source` property.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add a `Label` and bind the `Text` property to the `Description` property of
    the `ViewModel`, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'We also need to set the `BindingContext` of the view. We will do this in the
    same way as we did in the `MainView`—in the code-behind file (`ResultView.xaml.cs`),
    as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The very last thing we need to do is add navigation from the `MainView` to
    the `ResultView`. We will do this by adding the following code at the end of the `Classifier_ClassificationCompleted`
    method in the `MainViewModel`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Below could you see how the app will look if we upload a photo of a hot dog:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f01177fa-ae26-4075-84b9-8a3e29936821.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we built an app that can recognize whether or not a photo has
    a hot dog. We accomplished this by training a machine learning model for image
    classification using Azure Cognitive Services and the Custom Vision service.
  prefs: []
  type: TYPE_NORMAL
- en: We exported models for CoreML and TensorFlow and we learned how to use them
    in apps for both iOS and Android. In these apps, a user can take a photo or pick
    a photo from their photo library. This photo will be sent to the model to be classified,
    and we will get a result that tells us whether or not the photo is of a hot dog.
  prefs: []
  type: TYPE_NORMAL
