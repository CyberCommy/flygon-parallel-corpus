- en: 2\. Trees, Heaps, and Graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Learning Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will be able to:'
  prefs: []
  type: TYPE_NORMAL
- en: Analyze and identify where non-linear data structures can be used
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement and manipulate tree structures to represent data and solve problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traverse a tree using various methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement a graph structure to represent data and solve problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Represent a graph using different methods based on a given scenario
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will look at two non-linear data structures, namely trees
    and graphs, and how they can be used to represent real-world scenarios and solve
    various problems.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous chapter, we implemented different types of linear data structures
    to store and manage data in a linear fashion. In linear structures, we can traverse
    in, at most, two directions – forward or backward. However, the scope of these
    structures is very limited, and they can't be used to solve advanced problems.
    In this chapter, we'll explore a more advanced class of problems. We will see
    that the solutions we implemented previously are not good enough to be used directly.
    Due to this, we'll expand upon those data structures to make more complex structures
    that can be used to represent non-linear data.
  prefs: []
  type: TYPE_NORMAL
- en: After looking at these problems, we'll discuss basic solutions using the **tree**
    data structure. We'll implement different types of trees to solve different kinds
    of problems. After that, we'll have a look at a special type of tree called a
    **heap**, as well as its possible implementation and applications. Following that,
    we'll look at another complex structure – **graphs**. We'll implement two different
    representations of a graph. These structures help translate real-world scenarios
    into a mathematical form. Then, we will apply our programming skills and techniques
    to solve problems related to those scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: A strong understanding of trees and graphs serves as the basis for understanding
    even more advanced problems. Databases (B-trees), data encoding/compression (Huffman
    tree), graph coloring, assignment problems, minimum distance problems, and many
    more problems are solved using certain variants of trees and graphs.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's look at some examples of problems that cannot be represented by linear
    data structures.
  prefs: []
  type: TYPE_NORMAL
- en: Non-Linear Problems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Two main categories of situations that cannot be represented with the help of
    linear data structures are hierarchical problems and cyclic dependencies. Let's
    take a closer look at these cases.
  prefs: []
  type: TYPE_NORMAL
- en: Hierarchical Problems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s look at a couple of examples that inherently have hierarchical properties.
    The following is the structure of an organization:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1: Organization structure](img/C14498_02_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.1: Organization structure'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As we can see, the CEO is the head of the company and manages the Deputy Director.
    The Deputy Director leads three other officers, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data is inherently hierarchical in nature. This type of data is difficult
    to manage using simple arrays, vectors, or linked lists. To solidify our understanding,
    let''s look at another use case; that is, a university course''s structure, as
    shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C14498_02_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.2: Course hierarchy in a university course structure'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The preceding figure shows the course dependencies for some courses in a hypothetical
    university. As we can see, to learn Advanced Physics II, the student must have
    successfully completed the following courses: Advanced Physics and Advanced Mathematics.
    Similarly, many other courses have their own prerequisites.'
  prefs: []
  type: TYPE_NORMAL
- en: Given such data, we can have different types of queries. For example, we may
    want to find out which courses need to be completed successfully so that we can
    learn Advanced Mathematics.
  prefs: []
  type: TYPE_NORMAL
- en: These kinds of problems can be solved using a data structure called a tree.
    All of the objects are known as the nodes of a tree, while the paths leading from
    one node to another are known as edges. We'll take a deeper look at this in the
    *Graphs* section, later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Cyclic Dependencies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s look at another complex real-world scenario that can be represented
    better with a non-linear structure. The following figure represents the friendship
    between a few people:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3: A network of friends](img/C14498_02_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.3: A network of friends'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This structure is called a graph. The names of people, or the elements, are
    called nodes, and the relations between them are represented as edges. Such structures
    are commonly used by various social networks to represent their users and the
    connections between them. We can observe that Alice is friends with Charlie, who
    is friends with Eddard, who is friends with Grace, and so on. We can also infer
    that Alice, Bob, and Charlie know each other. We may also infer that Eddard is
    a first-level connection for Grace, Charlie is a second-level connection, and
    Alice and Bob are third-level connections.
  prefs: []
  type: TYPE_NORMAL
- en: Another area where graphs are useful is when we want to represent networks of
    roads between cities, as you will see in the *Graphs* section later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Tree – It's Upside Down!
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we discussed in the previous section, a tree is nothing but some objects
    or nodes connected to other nodes via a relationship that results in some sort
    of hierarchy. If we were to show this hierarchy in a graphical way, it would look
    like a tree, while the different edges would look like its branches. The main
    node, which is not dependent on any other node, is also known as a root node and
    is usually represented at the top. So, unlike an actual tree, this tree is upside
    down, with the root at its top!
  prefs: []
  type: TYPE_NORMAL
- en: Let's try to construct a structure for a very basic version of an organizational
    hierarchy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7: Creating an Organizational Structure'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will implement a basic version of the organizational tree
    we saw in the introduction to this chapter. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s include the required headers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'For simplicity, we''ll assume that any person can have, at most, two subordinates.
    We''ll see that this is not difficult to extend to resemble real-life situations.
    This kind of tree is also known as a **binary tree**. Let''s write a basic structure
    for that:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, any node will have two links to other nodes – both of their subordinates.
    By doing this, we can show the recursive structure of the data. We are only storing
    the position at the moment, but we can easily extend this to include a name at
    that position or even a whole struct comprising all the information about the
    person in that position.
  prefs: []
  type: TYPE_NORMAL
- en: 'We don''t want end users to deal with this kind of raw data structure. So,
    let''s wrap this in a nice interface called `org_tree`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s add a function to create the root, starting with the highest commanding
    officer of the company:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This is a static function just to create the tree. Now, let's see how we can
    extend the tree.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we want to add a subordinate of an employee. The function should take
    two parameters – the name of the already existing employee in the tree and the
    name of the new employee to be added as a subordinate. But before that, let''s
    write another function that will help us find a particular node based on a value
    to make our insertion function easier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: While we are traversing the tree in search of an element, either the element
    will be the node we are at, or it will be in either of the right or left subtrees.
  prefs: []
  type: TYPE_NORMAL
- en: Hence, we need to check the root node first. If it is not the desired node,
    we'll try to find it in the left subtree. Finally, if we haven't succeeded in
    doing that, we'll look at the right subtree.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s implement the insertion function. We''ll make use of the `find`
    function in order to reuse the code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the function returns a Boolean, indicating whether we can insert
    the node successfully or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s use this code to create a tree in the `main` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get the following output upon executing the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This output is illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4: Binary family tree based on an organization’s hierarchy](img/C14498_02_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.4: Binary tree based on an organization''s hierarchy'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Up until now, we've just inserted elements. Now, we'll look at how we can traverse
    the tree. Although we've already seen how to traverse using the `find` function,
    that's just one of the ways we can do it. We can traverse a tree in many other
    ways, all of which we'll look at in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Traversing Trees
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Once we have a tree, there are various ways we can traverse it and get to the
    node that we require. Let''s take a brief look at the various traversal methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Preorder traversal**: In this method, we visit the current node first, followed
    by the left child of the current node, and then the right child of the current
    node in a recursive fashion. Here, the prefix "pre" indicates that the parent
    node is visited before its children. Traversing the tree shown in *figure 2.4*
    using the preorder method goes like this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, we are always visiting the parent node, followed by the left
    child node, followed by the right child node. We do this not just for the root,
    but for any node with respect to its subtree. We implement preorder traversal
    using a function like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '**In-order traversal**: In this type of traversal, first we''ll visit the left
    node, then the parent node, and finally the right node. Traversing the tree that''s
    shown in *figure 2.4* goes like this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We can implement this in a function like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '**Post-order traversal**: In this traversal, we first visit both the children,
    followed by the parent node. Traversing the tree that''s shown in *figure 2.4*
    goes like this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We can implement this in a function like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '**Level order traversal**: This requires us to traverse the tree level by level,
    from top to bottom, and from left to right. This is similar to listing the elements
    at each level of the tree, starting from the root level. The results of such a
    traversal are usually represented as per the levels, as shown here:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The implementation of this method of traversal is demonstrated in the following
    exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 8: Demonstrating Level Order Traversal'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we''ll implement level order traversal in the organizational
    structure we created in *Exercise 7*, *Creating an Organizational Structure*.
    Unlike the previous traversal methods, here, we are not traversing to the nodes
    that are directly connected to the current node. This means that traversing is
    easier to achieve without recursion. We will extend the code that was shown in
    *Exercise 7* to demonstrate this traversal. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we''ll add the following function inside the `org_tree` structure from
    *Exercise 7*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: As shown in the preceding code, first, we're traversing the root node, followed
    by its children. While visiting the children, we push their children in the queue
    to be processed after the current level is completed. The idea is to start the
    queue from the first level and add the nodes of the next level to the queue. We
    will continue doing this until the queue is empty – indicating there are no more
    nodes in the next level.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what our output should look like:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Variants of Trees
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous exercises, we've mainly looked at the **binary tree**, which
    is one of the most common kinds of trees. In a binary tree, each node can have
    two child nodes at most. However, a plain binary tree doesn't always serve this
    purpose. Next, we'll look at a more specialized version of the binary tree, called
    a binary search tree.
  prefs: []
  type: TYPE_NORMAL
- en: Binary Search Tree
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A **binary search tree** (**BST**) is a popular version of the binary tree.
    BST is nothing but a binary tree with the following properties:'
  prefs: []
  type: TYPE_NORMAL
- en: Value of the parent node ≥ value of the left child
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Value of the parent node ≤ value of the right child
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In short, left child ≤ parent ≤ right child.
  prefs: []
  type: TYPE_NORMAL
- en: This leads us to an interesting feature. At any point in time, we can always
    say that all the elements that are less than or equal to the parent node will
    be on the left side, while those greater than or equal to the parent node will
    be on the right side. So, the problem of searching an element keeps on reducing
    by half, in terms of search space, at each step.
  prefs: []
  type: TYPE_NORMAL
- en: If the BST is constructed in a way that all the elements except those at the
    last level have both children, the height of the tree will be *log n*, where *n*
    is the number of elements. Due to this, the searching and insertion will have
    a time complexity of *O(log n)*. This type of binary tree is also known as a **complete
    binary tree**.
  prefs: []
  type: TYPE_NORMAL
- en: '**Searching in a BST**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at how we can search, insert, and delete elements in a binary search
    tree. Consider a BST with unique positive integers, as shown in the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5: Searching for an element in a binary search tree](img/C14498_02_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.5: Searching for an element in a binary search tree'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Let's say that we have to search for 7\. As we can see from the steps represented
    by arrows in the preceding figure, we choose the side after comparing the value
    with the current node's data. As we've already mentioned, all the nodes on the
    left will always be less than the current node, and all the nodes on the right
    will always be greater than the current node.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, we start by comparing the root node with 7\. If it is greater than 7,
    we move to the left subtree, since all the elements there are smaller than the
    parent node, and vice versa. We compare each child node until we stumble upon
    7, or a node less than 7 with no right node. In this case, coming to node 4 leads
    to our target, 7.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, we're not traversing the whole tree. Instead, we are reducing
    our scope by half every time the current node is not the desired one, which we
    do by choosing either the left or the right side. This works similar to a binary
    search for linear structures, which we will learn about in *Chapter* *4*, *Divide
    and Conquer*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Inserting a New Element into a BST**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s look at how insertion works. The steps are shown in the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6: Inserting an element into a binary search tree](img/C14498_02_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.6: Inserting an element into a binary search tree'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see, first, we have to find the parent node where we want to insert
    the new value. Thus, we have to take a similar approach to the one we took for
    searching; that is, by going in the direction based on comparing each node with
    our new element, starting with the root node. At the last step, 18 is greater
    than 17, but 17 doesn't have a right child. Therefore, we insert 18 in that position.
  prefs: []
  type: TYPE_NORMAL
- en: '**Deleting an Element from a BST**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s look at how deletion works. Consider the following BST:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7: Binary search tree rooted at 12](img/C14498_02_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.7: Binary search tree rooted at 12'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We will delete the root node, 12, in the tree. Let's look at how we can delete
    any value. It's a bit trickier than insertion since we need to find the replacement
    of the deleted node so that the properties of the BST remain true.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to find the node to be deleted. After that, there are three
    possibilities:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The node has no children: simply delete the node.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The node has only one child: point the parent node''s corresponding pointer
    to the only existing child.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The node has two children: in this case, we replace the current node with its
    successor.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The successor is the next biggest number after the current node. Or, in other
    words, the successor is the smallest element among all the elements greater than
    the current one. Therefore, we'll first go to the right subtree, which contains
    all the elements greater than the current one, and find the smallest among them.
    Finding the smallest node means going to the left side of the subtree as much
    as we can because the left child node is always less than its parent. In the tree
    shown in *figure 2.7*, the right subtree of 12 starts at 18\. So, we start looking
    from there, and then try to move down to the left child of 15\. But 15 does not
    have a left child, and the other child, 16, is larger than 15\. Hence, 15 should
    be the successor here.
  prefs: []
  type: TYPE_NORMAL
- en: 'To replace 12 with 15, first, we will copy the value of the successor at the
    root while deleting 12, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8: Successor copied to the root node](img/C14498_02_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.8: Successor copied to the root node'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Next, we need to delete the successor, 15, from its old place in the right
    subtree, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.9: Successor deleted from its old place](img/C14498_02_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.9: Successor deleted from its old place'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the last step, we're deleting node 15\. We use the same process for this
    deletion as well. Since 15 had just one child, we replace the left child of 18
    with the child of 15\. So, the whole subtree rooted at 16 becomes the left child
    of 18.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The successor node can only have one child at most. If it had a left child,
    we would have picked that child and not the current node as the successor.
  prefs: []
  type: TYPE_NORMAL
- en: Time Complexities of Operations on a Tree
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now, let's look at the time complexity of these functions. Theoretically, we
    can say that we reduce the scope of the search by half each time. Hence, the time
    that's required to search for the BST with *n* nodes is *T(n) = T(n / 2) + 1*.
    This equation results in a time complexity of *T(n) = O(log n)*.
  prefs: []
  type: TYPE_NORMAL
- en: But there's a catch to this. If we look at the insertion function closely, the
    order of insertion actually determines the shape of the tree. And it is not necessarily
    true that we'll always reduce the scope of the search by half, as described by
    *T(n/2)* in the previous formula. Therefore, the complexity *O(log n)* is not
    always accurate. We'll look at this problem and its solution in more depth in
    the *Balanced Tree* section, where we will see how we can calculate time complexity
    more accurately.
  prefs: []
  type: TYPE_NORMAL
- en: For now, let's implement the operations we just saw in C++.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 9: Implementing a Binary Search Tree'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will implement the BST shown in *figure 2.7* and add a
    `find` function to search for elements. We will also try our hand at the insertion
    and deletion of elements, as explained in the previous subsections. Let''s get
    started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s include the required headers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s write a node. This will be similar to our previous exercise, except
    we''ll have an integer instead of a string:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s add a wrapper over the node to provide a clean interface:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Before writing the insertion function, we''ll need to write the `find` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Since this is recursive, we have kept the implementation in a separate function
    and made it private so as to prevent someone from using it directly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s write an `insert` function. It will be similar to the `find` function,
    but with small tweaks. First, let''s find the parent node, which is where we want
    to insert the new value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, we are checking whether the value should be inserted in the left
    or right subtree. If there's nothing on the desired side, we directly insert the
    node there; otherwise, we call the `insert` function for that side recursively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s write an `inorder` traversal function. In-order traversal provides
    an important advantage when applied to BST, as we will see in the output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s implement a utility function to get the successor:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: This follows the logic we discussed in the *Deleting an Element in BST* subsection.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s look at the actual implementation of `delete`. Since deletion requires
    repointing the parent node, we''ll do that by returning the new node every time.
    We''ll hide this complexity by putting a better interface over it. We''ll name
    the interface `deleteValue` since `delete` is a reserved keyword, as per the C++
    standard:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s write the `main` function so that we can use the BST:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The output upon executing the preceding code should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Observe the preceding results of in-order traversal for a BST. In-order will
    visit the left subtree first, then the current node, and then the right subtree,
    recursively, as shown in the comments in the code snippet. So, as per BST properties,
    we'll visit all the values smaller than the current one first, then the current
    one, and after that, we'll visit all the values greater than the current one.
    And since this happens recursively, we'll get our data sorted in ascending order.
  prefs: []
  type: TYPE_NORMAL
- en: Balanced Tree
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Before we understand a balanced tree, let''s start with an example of a BST
    for the following insertion order:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This BST can be visualized with the help of the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.10: Skewed binary search tree](img/C14498_02_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.10: Skewed binary search tree'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'As shown in the preceding figure, almost the whole tree is skewed to the left
    side. If we call the `find` function, that is, `bst.find(4)`, the steps will look
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.11: Finding an element in a skewed binary search tree](img/C14498_02_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.11: Finding an element in a skewed binary search tree'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'As we can see, the number of steps is almost equal to the number of elements.
    Now, let''s try the same thing again with a different insertion order, as shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The BST and the steps required to find element 4 will now look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.12: Finding an element in a balanced tree](img/C14498_02_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.12: Finding an element in a balanced tree'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As we can see, the tree is not skewed anymore. Or, in other words, the tree
    is balanced. The steps to find 4 have been considerably reduced with this configuration.
    Thus, the time complexity of `find` is not just dependent on the number of elements,
    but also on their configuration in the tree. If we look at the steps closely,
    we are always going one step toward the bottom of the tree while searching for
    something. And at the end, we end up at the leaf nodes (nodes without any children).
    Here, we return either the desired node or NULL based on the availability of the
    element. So, we can say that the number of steps is always less than the maximum
    number of levels in the BST, also known as the height of the BST. So, the actual
    time complexity for finding an element is O(height).
  prefs: []
  type: TYPE_NORMAL
- en: In order to optimize the time complexity, we need to optimize the height of
    the tree. This is also called *balancing a tree*. The idea is to reorganize the
    nodes after insertion/deletion to reduce the skewness of the tree. The resultant
    tree is called a height-balanced BST.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are various ways in which we can do this and get different types of trees,
    such as an AVL tree, a Red-Black tree, and so on. The idea behind an AVL tree
    is to perform some rotations to balance the height of the tree, while still maintaining
    the BST properties. Consider the example that''s shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.13: Rotating a tree](img/C14498_02_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.13: Rotating a tree'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As we can see, the tree on the right is more balanced compared to the one on
    the left. Rotation is out of the scope of this book and so we will not venture
    into the details of this example.
  prefs: []
  type: TYPE_NORMAL
- en: N-ary Tree
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Up until now, we''ve mainly seen binary trees or their variants. For an N-ary
    tree, each node can have *N* children. Since *N* is arbitrary here, we are going
    to store it in a vector. So, the final structure looks something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, there can be any number of children for each node. Hence, the
    whole tree is completely arbitrary. However, just like a plain binary tree, a
    plain N-ary tree also isn't very useful. Therefore, we have to build a different
    tree for different kinds of applications, where the hierarchy is of a higher degree
    than a binary tree. The example shown in *figure 2.1*, which represents an organization's
    hierarchy, is an N-ary tree.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the computer world, there are two really good, well-known implementations
    of N-ary trees, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Filesystem structures in computers: Starting from `root` (`/`) in Linux or
    drives in Windows, we can have any number of files (terminal nodes) and any number
    of folders inside any folder. We''ll look at this in greater detail in *Activity
    1, Creating a Data Structure for a Filesystem*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Compilers: Most compilers build an Abstract Syntax Tree (AST) based on syntax
    defined by the standard that''s used for the source code. Compilers generate lower-level
    code by parsing the AST.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Activity 4: Create a Data Structure for a Filesystem'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Create a data structure using an N-ary tree for a filesystem that supports
    the following operations: go to directory, find file/directory, add file/directory,
    and list file/directory. Our tree will hold the information and folder hierarchy
    (path) of all the elements (files and folders) in the filesystem.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to solve this activity:'
  prefs: []
  type: TYPE_NORMAL
- en: Create an N-ary tree with two data elements in a node – the name of the directory/file
    and a flag indicating whether it's a directory or a file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a data member to store the current directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize the tree with a single directory root (`/`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the find directory/file function, which takes a single parameter – `path`.
    The `path` can be either absolute (starting with `/`) or relative.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add functions to add a file/directory and list files/directories located at
    a given path.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Similarly, add a function to change the current directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution to this activity can be found on page 490.
  prefs: []
  type: TYPE_NORMAL
- en: We've printed directories with `d` in front to distinguish them from files,
    which are printed with a "`–`" (hyphen) in front. You can experiment by creating
    more directories and files with absolute or relative paths.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we haven't supported certain Linux conventions, such as addressing any
    directory with a single dot and addressing a parent directory with double dots.
    This can be done by extending our node to also hold a pointer to its parent node.
    This way, we can traverse in both directions very easily. There are various other
    extensions possible, such as the addition of symlinks, as well as globing operators
    to expand the names of the various files/directories using "`*`". This exercise
    provides us with a base so that we can build something on our own based on our
    requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Heaps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous chapter, we had a brief look at heaps and how C++ provides
    heaps via STL. In this chapter, we''ll take a deeper look at heaps. Just to recap,
    the following are the intended time complexities:'
  prefs: []
  type: TYPE_NORMAL
- en: '*O(1)*: Immediate access to the max element'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*O(log n)*: Insertion of any element'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*O(log n)*: Deletion of the max element'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To achieve *O(log n)* insertion/deletion, we''ll use a tree to store data.
    But in this case, we''ll ''use a complete tree. A **complete tree** is defined
    as a tree where nodes at all the levels except the last one have two children,
    and the last level has as many of the elements on the left side as possible. For
    example, consider the two trees shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.14: Complete versus non-complete tree](img/C14498_02_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.14: Complete versus non-complete tree'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Thus, a complete tree can be constructed by inserting elements in the last level,
    as long as there's enough space there. If not, we will insert them at the leftmost
    position on the new level. This gives us a very good opportunity to store this
    tree using an array, level by level. So, the root of the tree will be the first
    element of the array/vector, followed by its left child and then the right child,
    and so on. Unlike other trees, this is a very efficient memory structure because
    there is no extra memory required to store pointers. To go from a parent to its
    child node, we can easily use the index of the array. If the parent is the *i**th*
    node, its children will always be *2*i + 1* and *2*i + 2* indices. And similarly,
    we can get the parent node for the *i**th* child node by using *(i – 1) / 2*.
    We can also confirm this from the preceding figure.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's have a look at the invariants (or conditions) we need to maintain
    upon every insertion/deletion. The first requirement is instant access to the
    max element. For that, we need to fix its position so that it is accessible immediately
    every time. We'll always keep our max element at the top – the root position.
    Now, to maintain this, we also need to maintain another invariant – the parent
    node must be greater than both of its children. Such a heap is also known as a
    **max heap**.
  prefs: []
  type: TYPE_NORMAL
- en: As you can probably guess, the properties that are required for fast access
    to the maximum element can be easily inverted for fast access to the minimum element.
    All we need to do is invert our comparison function while performing heap operations.
    This kind of heap is known as a **min heap**.
  prefs: []
  type: TYPE_NORMAL
- en: Heap Operations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will see how we can perform different operations on a heap.
  prefs: []
  type: TYPE_NORMAL
- en: '**Inserting an Element into a Heap**'
  prefs: []
  type: TYPE_NORMAL
- en: As the first step of insertion, we will preserve the most important invariant,
    which provides us with a way to represent this structure as an array – a complete
    tree. This can easily be done by inserting the new element at the end since it
    will represent the element in the last level, right after all the existing elements,
    or as the first element in a new level if the current last level is full.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we need to preserve the other invariant – all the nodes must have a value
    greater than both of their children, if available. Assuming that our current tree
    is already following this invariant, after the insertion of the new element in
    the last position, the only element where the invariant may fail would be the
    last element. To resolve this, we swap the element with its parent if the parent
    is smaller than the element. Even if the parent already has another element, it
    will be smaller than the new element (new element > parent > child).
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, the subtree that''s created by considering the new element as the root
    satisfies all the invariants. However, the new element may still be greater than
    its new parent. Therefore, we need to keep on swapping the nodes until the invariant
    is satisfied for the whole tree. Since the height of a complete tree is *O(log
    n)* at most, the entire operation will take a maximum of *O(log n)* time. The
    following figure illustrates the operation of inserting elements into a tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.15: Inserting an element into a heap with one node](img/C14498_02_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.15: Inserting an element into a heap with one node'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'As shown in the preceding figure, after inserting 11, the tree doesn''t have
    the heap property anymore. Therefore, we''ll swap 10 and 11 to make it a heap
    again. This concept is clearer with the following example, which has more levels:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.16: Inserting an element into a heap with several nodes](img/C14498_02_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.16: Inserting an element into a heap with several nodes'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Deleting an Element from a Heap**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing to notice is that we can only delete the max element. We can''t
    directly touch any other element. The max element is always present at the root.
    Hence, we''ll remove the root element. But we also need to decide who''ll take
    its position. For that, we first need to swap the root with the last element,
    and then remove the last element.That way, our root will be deleted, but it will
    break the invariant of having each parent node greater than its children. To resolve
    this, we''ll compare the root with its two children and swap it with the greater
    one. Now, the invariant is broken at one of the subtrees. We continue the swapping
    process recursively throughout the subtree. That way, the breaking point of the
    invariant is bubbled down the tree. Just like insertion, we follow this until
    we meet the invariant. The maximum number of steps required will be equal to the
    height of the tree, which is *O(log n)*. The following figure illustrates this
    process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.17: Deleting an element in a heap](img/C14498_02_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.17: Deleting an element in a heap'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Initialization of a Heap**'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's look at one of the most important steps – the initialization of a
    heap. Unlike vectors, lists, deques, and so on, a heap is not simple to initialize
    because we need to maintain the invariants of the heap. One easy solution would
    be to insert all the elements starting from an empty heap, one by one. But the
    time required for this would be *O(n * log(n))*, which is not efficient.
  prefs: []
  type: TYPE_NORMAL
- en: However, there's a `std::make_heap`, which can take any array or vector iterators
    and convert them into a heap.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 10: Streaming Median'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we''ll solve an interesting problem that frequently occurs
    in data analysis-related applications, including machine learning. Imagine that
    some source is giving us data one element at a time continuously (a stream of
    data). We need to find the median of the elements that have been received up until
    now after receiving each and every element. One simple way of doing this would
    be to sort the data every time a new element comes in and return the middle element.
    But this would have an *O(n log n)* time complexity because of sorting. Depending
    on the rate of incoming elements, this can be very resource-intensive. However,
    we''ll optimize this with the help of heaps. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s include the required headers first:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s write a container to store the data we''ve received up until now.
    We''ll store the data among two heaps – one min heap and one max heap. We''ll
    store the smaller, first half of the elements in a max heap, and the larger, or
    the other half, in a min heap. So, at any point, the median can be calculated
    using only the top elements of the heaps, which are easily accessible:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s write an `insert` function so that we can insert the newly arrived
    data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s write a `get` function so that we can get the median from the containers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s write a `main` function so that we can use this class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding program is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: This way, we only need to insert any newly arriving elements, which only has
    a time complexity of *O(log n)*, compared to the time complexity of *O(n log n)*
    if we were to sort the elements with each new element.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 5: K-Way Merge Using Heaps'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Consider a biomedical application related to genetics being used for processing
    large datasets. It requires ranks of DNA in a sorted manner to calculate similarity.
    But since the dataset is huge, it can't fit on a single machine. Therefore, it
    processes and stores data in a distributed cluster, and each node has a set of
    sorted values. The main processing engine requires all of the data to be in a
    sorted fashion and in a single stream. So, basically, we need to merge multiple
    sorted arrays into a single sorted array. Simulate this situation with the help
    of vectors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to solve this activity:'
  prefs: []
  type: TYPE_NORMAL
- en: The smallest number will be present in the first element of all the lists since
    all the lists have already been sorted individually. To get that minimum faster,
    we'll build a heap of those elements.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After getting the minimum element from the heap, we need to remove it and replace
    it with the next element from the same list it belongs to.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The heap node must contain information about the list so that it can find the
    next number from that list.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution to this activity can be found on page 495.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's calculate the time complexity of the preceding algorithm. If there
    are *k* lists available, our heap size will be k, and all of our heap operations
    will be *O(log k)*. Building heap will be *O(k log k)*. After that, we'll have
    to perform a heap operation for each element in the result. The total elements
    are *n × k*. Therefore, the total complexity will be *O(nk log k)*.
  prefs: []
  type: TYPE_NORMAL
- en: The wonderful thing about this algorithm is that, considering the real-life
    scenario we described earlier, it doesn't actually need to store all the *n ×
    k* elements at the same time; it only needs to store *k* elements at any point
    in time, where *k* is the number of lists or nodes in the cluster. Due to this,
    the value of *k* will never be too large. With the help of a heap, we can generate
    one number at a time and either process the number immediately or stream it elsewhere
    for processing without actually storing it.
  prefs: []
  type: TYPE_NORMAL
- en: Graphs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although a tree is a pretty good way to represent hierarchical data, we can't
    represent circular or cyclic dependencies in a tree because we always have a single
    and unique path to go from one node to another. However, there are more complex
    scenarios that have a cyclic structure inherently. For example, consider a road
    network. There can be multiple ways to go from one place (places can be represented
    as nodes) to another. Such a set of scenarios can be better represented using
    graphs.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike a tree, a graph has to store data for the nodes, as well as for the edges
    between the nodes. For example, in any road network, for each node (place), we
    have to store the information about which other nodes (places) it connects to.
    This way, we can form a graph with all the required nodes and edges. This is called
    an **unweighted graph**. We can add *weights*, or more information, to each of
    the edges. For our road network example, we can add the distance of each edge
    (path) from one node (place) to another. This representation, called a **weighted
    graph**, has all the information about a road network that's required to solve
    problems such as finding the path that has the minimum distance between one place
    and another.
  prefs: []
  type: TYPE_NORMAL
- en: There are two types of graphs – undirected and directed. An **undirected graph**
    indicates that the edges are bidirectional. Bidirectional indicates a bilateral
    or commutative property. For the road network example, a bidirectional edge between
    points A and B implies that we can go from A to B, as well as from B to A. But
    let's say we have some roads with a one-way restriction – we need to use a **directed
    graph** to represent that. In a direct graph, whenever we need to indicate that
    we can go in either direction, we use two edges – from point A to B, and B to
    A. We'll mainly focus on bidirectional graphs, but the things we'll learn here
    about structure and traversing methods hold true for directed graphs as well.
    The only change will be how we add edges to the graph.
  prefs: []
  type: TYPE_NORMAL
- en: Since a graph can have cyclic edges and more than one way to go from one node
    to another, we need to identify each node uniquely. For that, we can assign an
    identifier to each node. To represent the graph's data, we don't really need to
    build a node-like structure programmatically, as we did in trees. In fact, we
    can store the whole graph by combining `std` containers.
  prefs: []
  type: TYPE_NORMAL
- en: Representing a Graph as an Adjacency Matrix
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Here is one of the simplest ways to understand a graph – consider a set of nodes,
    where any node can connect to any other node among the set directly. This means
    that we can represent this using a 2D array that's *N × N* in size for a graph
    with *N* nodes. The value in each cell will indicate the weight of the edge between
    the corresponding nodes based on the indices of the cell. So, `data[1][2]` will
    indicate the weight of the edge between node 1 and node 2\. This method is known
    as an **adjacency matrix**. We can indicate the absence of an edge using a weight
    of -1.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the weighted graph shown in the following figure, which represents
    an aviation network between a few major international cities, with hypothetical
    distances:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.18: Aviation network between some cities](img/C14498_02_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.18: Aviation network between some cities'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As shown in the preceding figure, we can go from London to Dubai via Istanbul
    or directly. There are multiple ways to go from one place to another, which was
    not the case with trees. Also, we can traverse from one node to another and come
    back to the original node via some different edges, which was also not possible
    in a tree.
  prefs: []
  type: TYPE_NORMAL
- en: Let's implement the matrix representation method for the graph shown in the
    preceding figure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 11: Implementing a Graph and Representing it as an Adjacency Matrix'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will implement a graph representing the network of cities
    shown in the preceding figure, and demonstrate how it can be stored as an adjacency
    matrix. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s include the required headers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s add an `enum` class so that we can store the names of the cities:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s also add a `<<` operator for the `city` enum:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s write the `struct graph`, which will encapsulate our data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s add a constructor that will create an empty graph (a graph without
    any edges) with a given number of nodes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s add the most important function – `addEdge`. It will take three
    parameters – the two cities to be connected and the weight (distance) of the edge:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s add a function so that we can remove an edge from the graph:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s write the `main` function so that we can use these functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Upon executing this program, we should get the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, we are storing the data in a vector of a vector, with both dimensions
    equal to the number of nodes. Hence, the total space required for this representation
    is proportional to *V2*, where *V* is the number of nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Representing a Graph as an Adjacency List
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A major problem with a matrix representation of a graph is that the amount of
    memory required is directly proportional to the number of nodes squared. As you
    might imagine, this adds up quickly with the number of nodes. Let's see how we
    can improve this so that we use less memory.
  prefs: []
  type: TYPE_NORMAL
- en: In any graph, we'll have a fixed number of nodes, and each node will have a
    fixed maximum number of connected nodes, which is equal to the total nodes. In
    a matrix, we have to store all the edges for all the nodes, even if two nodes
    are not directly connected to each other. Instead, we'll only store the IDs of
    the nodes in each row, indicating which nodes are directly connected to the current
    one. This representation is also called an **adjacency list**.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see how the implementation differs compared to the previous exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 12: Implementing a Graph and Representing it as an Adjacency List'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will implement a graph representing the network of cities
    shown in *figure 2.18*, and demonstrate how it can be stored as an adjacency list.
    Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll implement an adjacency list representation in this exercise. Let''s
    start with headers, as usual:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s add an `enum` class so that we can store the names of the cities:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s also add the `<<` operator for the `city` enum:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s write the `struct graph`, which will encapsulate our data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see how our constructor defers from a matrix representation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, we are initializing the data with a 2D vector, but all the rows
    are initially empty because there are no edges present at the start.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s implement the `addEdge` function for this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s write `removeEdge` so that we can remove an edge from the graph:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s write the `main` function so that we can use these functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Upon executing this program, we should get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Since we are storing a list of adjacent nodes for each node, this method is
    called an adjacency list. This method also uses a vector of a vector to store
    the data, just like the former method. But the dimension of the inner vector is
    not equal to the number of nodes; instead, it depends on the number of edges.
    For each edge in the graph, we'll have two entries, as per our `addEdge` function.
    The memory that's required for this type of representation would be proportional
    to E, where E is the number of edges.
  prefs: []
  type: TYPE_NORMAL
- en: Up until now, we've only seen how to build a graph. We need to traverse a graph
    to be able to perform any operations while using it. There are two widely used
    methods available – Breadth-First Search (BFS) and Depth-First Search (DFS), both
    of which we'll look at in *Chapter 6*, *Graph Algorithms I*.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we looked at a more advanced class of problems compared to
    the previous chapter, which helped us to describe a wider range of real-world
    scenarios. We looked at and implemented two major data structures – trees and
    graphs. We also looked at various types of trees that we can use in different
    situations. Then, we looked at different ways of representing data programmatically
    for these structures. With the help of this chapter, you should be able to apply
    these techniques to solve real-world problems of similar kinds.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've looked at linear and non-linear data structures, in the next
    chapter, we'll look at a very specific but widely used concept called lookup,
    where the goal is to store values in a container so that searching is super fast.
    We will also look at the fundamental idea behind hashing and how can we implement
    such a container.
  prefs: []
  type: TYPE_NORMAL
