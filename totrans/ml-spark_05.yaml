- en: Building a Recommendation Engine with Spark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you have learned the basics of data processing and feature extraction,
    we will move on to explore individual machine learning models in detail, starting
    with recommendation engines.
  prefs: []
  type: TYPE_NORMAL
- en: Recommendation engines are probably among the best types of machine learning
    models known to the general public. Even if people do not know exactly what a
    recommendation engine is, they have most likely experienced one through the use
    of popular websites, such as Amazon, Netflix, YouTube, Twitter, LinkedIn, and
    Facebook. Recommendations are a core part of all these businesses, and in some
    cases, they drive significant percentages of their revenue.
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind recommendation engines is to predict what people might like
    and to uncover relationships between items to aid in the discovery process; in
    this way, they areÂ similar and, in fact, often complementary to search engines,
    which also play a role in discovery. However, unlike search engines, recommendation
    engines try to present people with relevant content that they did not necessarily
    search for or that they might have not even heard of.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, a recommendation engine tries to model the connections between users
    and some type of item. In our movie stream scenario from [Chapter 3](fbb4c025-a861-4b26-8284-a8ae5f0f0d88.xhtml),
    *Designing a Machine Learning System*, for example, we can use a recommendation
    engine to show our users movies that they might enjoy. If we can do this well,
    we could keep our users engaged using our service, which is good for both our
    users and us. Similarly, if we can do a good job of showing our users movies related
    to a given movie, we could aid in discovery and navigation on our site, again
    improving our users' experience, engagement, and the relevance of our content
    to them.
  prefs: []
  type: TYPE_NORMAL
- en: However, recommendation engines are not limited to movies, books, or products.
    The techniques we will explore in this chapter can be applied to just about any
    user-to-item relationship as well as user-to-user connections, such as those found
    on social networks, allowing us to make recommendations, such as people you may
    know or who to follow.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recommendation engines are most effective in two general scenarios, which are
    not mutually exclusive. They are explained here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Large number of available options for users**: When there are a very large
    number of available items, it becomes increasingly difficult for the user to find
    something they want. Searching can help when the user knows what they are looking
    for, but often, the right item might be something previously unknown to them.
    In this case, being recommended relevant items that the user may not already know
    about can help them discover new items.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A significant degree of personal taste involved**: When personal taste plays
    a large role in selection, recommendation models, which often utilize a wisdom-of-the-crowd
    approach, can be helpful in discovering items based on the behavior of others
    that have similar taste profiles.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduce the various types of recommendation engines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build a recommendation model using data about user preferences
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the trained model to compute recommendations for a given user as well compute
    similar items for a given item, that is, related items
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apply standard evaluation metrics to the model that we created to measure how
    well it performs in terms of predictive capability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Types of recommendation models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Recommender systems are widely studied, and there are many approaches used,
    but there are two that are probably most prevalent: content-based filtering and
    collaborative filtering. Recently, other approaches, such as ranking models, have
    also gained in popularity. In practice, many approaches are hybrids, incorporating
    elements of many different methods into a model or combination of models.'
  prefs: []
  type: TYPE_NORMAL
- en: Content-based filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Content-based methods try to use the content or attributes of an item, together
    with some notion of similarity between two pieces of content, to generate items
    similar to a given item. These attributes are often textual content, such as titles,
    names, tags, and other metadata attached to an item, or in the case of media,
    they could include other features of the item, such as attributes extracted from
    audio and video content.
  prefs: []
  type: TYPE_NORMAL
- en: In a similar manner, user recommendations can be generated based on attributes
    of users or user profiles, which are then matched to item attributes using the
    same measure of similarity. For example, a user can be represented by the combined
    attributes of the items they have interacted with. This becomes their user profile,
    which is then compared to item attributes to find items that match the user profile.
  prefs: []
  type: TYPE_NORMAL
- en: 'These are a few examples of creating a profile for each user or item to characterize
    its nature:'
  prefs: []
  type: TYPE_NORMAL
- en: Movie profile includes attributes regarding actors, genre, popularity, and so
    on.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User profile includes demographic information or answers given to specific questions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Content filtering uses profiles to associate users or items.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compute similarity of a new item with the user profile based on keyword overlap
    example using Dice coefficient. There are other approaches as well.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collaborative filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Collaborative filtering relies only on past behavior, such as previous ratings
    or transactions. The idea behind this is the notion of similarity.
  prefs: []
  type: TYPE_NORMAL
- en: The basic idea is that the user gives ratings to items, implicitly or explicitly.
    Users who had a similar taste in the past will have a similar taste in the future.
  prefs: []
  type: TYPE_NORMAL
- en: In a user-based approach, if two users have exhibited similar preferences, that
    is, patterns of interacting with the same items in broadly the same way, then
    we would assume that they are similar to each other in terms of taste. To generate
    recommendations for unknown items for a given user, we can use the known preferences
    of other users that exhibit similar behavior. We can do this by selecting a set
    of similar users and computing some form of combined score based on the items
    they have shown a preference for. The overall logic is that if others have tastes
    similar to a set of items, these items would tend to be good candidates for recommendation.
  prefs: []
  type: TYPE_NORMAL
- en: We can also take an item-based approach that computes some measure of similarity
    between items. This is usually based on the existing user-item preferences or
    ratings. Items that tend to be rated the same by similar users will be classed
    as similar under this approach. Once we have these similarities, we can represent
    a user in terms of the items they have interacted with and find items that are
    similar to these known items, which we can then recommend to the user. Again,
    a set of items similar to the known items is used to generate a combined score
    to estimate for an unknown item.
  prefs: []
  type: TYPE_NORMAL
- en: The user- and item-based approaches are usually referred to as nearest-neighbor
    models, since the estimated scores are computed based on the set of most similar
    users or items, that is, their neighbors.
  prefs: []
  type: TYPE_NORMAL
- en: 'A traditional collaborative filtering algorithm represents a user as an N-dimensional
    vector of items, where N is the number of distinct items. The components of the
    vector are positive or negative items. To calculate for best items, the algorithm
    typically multiplies the vector components by the inverse frequency, that is,
    the inverse of the number of users who have rated the item, making less well-known
    items much more relevant. For most users, this vector is extremely sparse. The
    algorithm generates recommendations based on a few users who are most similar
    to the user. It can measure the similarity of two users, *X* and *Y*, using a
    common method called cosine of the angle between the two vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_05_001.png)'
  prefs: []
  type: TYPE_IMG
- en: Finally, there are many model-based methods that attempt to model the user-item
    preferences themselves, so that new preferences can be estimated directly by applying
    the model to unknown user-item combinations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Two primary modeling methods for collaborative filtering are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Neighborhood methods**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The user-oriented approach is centered on computing the relationships between
    users
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The item-oriented approach evaluates a user's preference for an item based on
    ratings of a neighboring item by the same user
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use centered cosine distance for similarity calculation, which is also known
    as **Pearson correlation coefficients**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Latent factor models**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Latent factor model** (**LFM**) approach explains ratings by characterizing
    both users and items to find the hidden latent features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In movies, features such as action or drama, type of actors, and so on, are
    the latent factors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In users, features such as liking the score for movie is an example of a latent
    factor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Types are neural networks, latent dirichlet allocation, matrix factorization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we will discuss Matrix Factorization models.
  prefs: []
  type: TYPE_NORMAL
- en: Matrix factorization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since Spark's recommendation models currently only include an implementation
    of Matrix factorization, we will focus our attention on this class of models.
    This focus is with good reason; however, these types of models have consistently
    been shown to perform extremely well in collaborative filtering and were among
    the best models in well-known competitions, such as the Netflix prize.
  prefs: []
  type: TYPE_NORMAL
- en: 'Matrix Factorization assumes that:'
  prefs: []
  type: TYPE_NORMAL
- en: Each user can be described by n attributes or features. For example, feature
    one might be a number that says how much each user likes action movies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each item can be described by a set of n attributes or features. To connect
    with the preceding example, feature one for the movie might be a number that says
    how close the movie is to pure action.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we multiply each feature of the user by the corresponding feature of the
    item and add everything together, this will be a good approximation for the rating
    the user would give that item.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more information on and a brief overview of the performance of the best
    algorithms for the Netflix prize, see [http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html](http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html).
  prefs: []
  type: TYPE_NORMAL
- en: Explicit matrix factorization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we deal with data that consists of preferences of users, which are provided
    by the users themselves, we refer to explicit preference data. This includes,
    for example, ratings, thumbs up, likes, and so on that are given by users to items.
  prefs: []
  type: TYPE_NORMAL
- en: We can take these ratings and form a two-dimensional matrix with users as rows
    and items as columns. Each entry represents a rating given by a user to a certain
    item. Since, in most cases, each user has only interacted with a relatively small
    set of items, this matrix has only a few non-zero entries, that is, it is very
    sparse.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a simple example, let''s assume that we have the following user ratings
    for a set of movies:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Tom: Star Wars, 5'
  prefs: []
  type: TYPE_NORMAL
- en: 'Jane: Titanic, 4'
  prefs: []
  type: TYPE_NORMAL
- en: 'Bill: Batman, 3'
  prefs: []
  type: TYPE_NORMAL
- en: 'Jane: Star Wars, 2'
  prefs: []
  type: TYPE_NORMAL
- en: 'Bill: Titanic, 3'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will form the following ratings matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_05_002.png)'
  prefs: []
  type: TYPE_IMG
- en: A simple movie-rating matrix
  prefs: []
  type: TYPE_NORMAL
- en: 'Matrix Factorization (or matrix completion) attempts to directly model this
    user-item matrix by representing it as a product of two smaller matrices of lower
    dimension. Thus, it is a dimensionality-reduction technique. If we have **U**
    users and **I** items, then our user-item matrix is of dimension U x I and might
    look something like the one shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_05_003.png)'
  prefs: []
  type: TYPE_IMG
- en: A sparse ratings matrix
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to find a lower dimension (low-rank) approximation to our user-item
    matrix with the dimension **k**, we would end up with two matrices: one for users
    of size U x k and one for items of size I x k; these are known as factor matrices.
    If we multiply these two factor matrices, we willÂ reconstruct an approximate version
    of the original ratings matrix. Note that while the original ratings matrix is
    typically very sparse, each factor matrix is dense, as shown in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_05_004.png)'
  prefs: []
  type: TYPE_IMG
- en: The user- and item-factor matrices
  prefs: []
  type: TYPE_NORMAL
- en: These models are often also called latent feature models, as we are trying to
    discover some form of hidden features (which are represented by the factor matrices)
    that account for the structure of behavior inherent in the user-item rating matrix.
    While the latent features or factors are not directly interpretable, they might,
    perhaps, represent things such as the tendency of a user to like movies from a
    certain director, genre, style, or group of actors.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we are directly modeling the user-item matrix, the prediction in these models
    is relatively straightforward: to compute a predicted rating for a user and item,
    we will compute the vector dot product between the relevant row of the user-factor
    matrix, that is, the user''s factor vector, and the relevant row of the item-factor
    matrix, that is, the item''s factor vector.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is illustrated with the highlighted vectors in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_05_005.png)'
  prefs: []
  type: TYPE_IMG
- en: Computing recommendations from user- and item-factor vectors
  prefs: []
  type: TYPE_NORMAL
- en: 'To find out the similarity between two items, we can use the same measures
    of similarity as we would use in the nearest-neighbor models, except that we can
    use the factor vectors directly by computing the similarity between two item-factor
    vectors, as illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_05_006.png)'
  prefs: []
  type: TYPE_IMG
- en: Computing similarity with item-factor vectors
  prefs: []
  type: TYPE_NORMAL
- en: The benefit of factorization models is the relative ease of computing recommendations
    once the model is created. However, for very large user and item sets, this can
    become a challenge, as it requires storage and computation across potentially
    many millions of user- and item-factor vectors. Another advantage, as mentioned
    earlier, is that they tend to offer very good performance.
  prefs: []
  type: TYPE_NORMAL
- en: Projects such as Oryx ([https://github.com/OryxProject/oryx](https://github.com/OryxProject/oryx))
    and Prediction.io ([https://github.com/PredictionIO/PredictionIO](https://github.com/PredictionIO/PredictionIO))
    focus on model serving for large-scale models, including recommenders based on
    matrix factorization.
  prefs: []
  type: TYPE_NORMAL
- en: On the down side, factorization models are relatively more complex to understand
    and interpret compared to nearest-neighbor models and are often more computationally
    intensive during the model's training phase.
  prefs: []
  type: TYPE_NORMAL
- en: Implicit Matrix Factorization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have dealt with explicit preferences such as ratings. However, much
    of the preference data that we might be able to collect is implicit feedback,
    where the preferences between a user and item are not given to us, but are, instead,
    implied from the interactions they might have with an item. Examples include binary
    data, such as whether a user viewed a movie, whether they purchased a product,
    and so on, as well as count data, such as the number of times a user watched a
    movie.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many different approaches to deal with implicit data. MLlib implements
    a particular approach that treats the input rating matrix as two matrices: a binary
    preference matrix, **P**, and a matrix of confidence weights, **C**.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, let's assume that the user-movie ratings we saw previously were,
    in fact, the number of times each user had viewed that movie. The two matrices
    would look something like the ones shown in the following screenshot. Here, the
    matrix **P** informs us that a movie was viewed by a user, and the matrix **C**
    represents the confidence weighting, in the form of the view counts--generally,
    the more a user has watched a movie, the higher the confidence that they actually
    like it.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_05_007.png)'
  prefs: []
  type: TYPE_IMG
- en: Representation of an implicit preference and confidence matrix
  prefs: []
  type: TYPE_NORMAL
- en: The implicit model still creates a user- and item-factor matrix. In this case,
    however, the matrix that the model is attempting to approximate is not the overall
    ratings matrix, but the preference matrix **P**. If we compute a recommendation
    by calculating the dot product of a user- and item-factor vector, the score will
    not be an estimate of a rating directly. It will rather be an estimate of the
    preference of a user for an item; although, not strictly between 0 and 1, these
    scores will generally be fairly close to a scale of 0 to 1.
  prefs: []
  type: TYPE_NORMAL
- en: In a nutshell, Matrix Factorization methods characterize both users and items
    by vectors of factors inferred from a rating pattern. High confidence or correspondence
    between user and item factors leads to a recommendation. Two main data types are
    Explicit feedback, such as ratings (represented by sparse matrix), and Implicit
    feedback, such as purchase history, search patterns, browse history, and clickstream
    data (represented by dense matrix).
  prefs: []
  type: TYPE_NORMAL
- en: Basic model for Matrix Factorization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Both users and items are mapped to a joint latent factor space of dimensionality
    *f*, where user-item interaction is modeled as inner product in this space. Item
    *i* is associated with vector *q* where *q* measures the extent to which the item
    possesses the latent factors and User *u* is associated with vector *p*, where
    *p* measures the extent of interest the user has in the item.
  prefs: []
  type: TYPE_NORMAL
- en: The dot product ![](img/image_6.png)Â between *q* and *p* captures the interaction
    between user u and item I, that is, a user's interest in an item. Key to model
    is finding vectors *q* and *p*.
  prefs: []
  type: TYPE_NORMAL
- en: To design the model, get latent relationship between users and items. Produce
    a low dimensional representation of rating matrix. Perform SVD on thye rating
    matrix to get *Q*, *S*, *P*. Reduce matrix *S* to dimension *k* to get *q* and
    *p*.
  prefs: []
  type: TYPE_NORMAL
- en: '**![](img/Screen-Shot-2017-04-27-at-3.55.57-PM.png)**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, calculate the recommendations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Screen-Shot-2017-04-27-at-3.56.04-PM.png)'
  prefs: []
  type: TYPE_IMG
- en: Optimization function (on observed ratings) is shown in the following diagram;
    learn the latent factor vectors *q* and *p*, the system minimizes the regularized
    squared error on set of ratings.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Screen-Shot-2017-04-27-at-3.56.08-PM.png)'
  prefs: []
  type: TYPE_IMG
- en: Learning algorithms used are **stochastic gradient descent** (**SGD**) or **alternating
    least squares** (**ALS**).
  prefs: []
  type: TYPE_NORMAL
- en: Alternating least squares
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ALS is an optimization technique to solve Matrix Factorization problems; this
    technique is powerful, achieves good performance, and has proven to be relatively
    easy to implement in a parallel fashion. Hence, it is well suited for platforms
    such as Spark. At the time of writing this book, it is the only recommendation
    model implemented in Spark ML.
  prefs: []
  type: TYPE_NORMAL
- en: 'ALS works by iteratively solving a series of least squares regression problems.
    In each iteration, one of the user- or item-factor matrices is treated as fixed,
    while the other one is updated using the fixed factor and the rating data. Then,
    the factor matrix that was solved for is, in turn, treated as fixed, while the
    other one is updated. This process continues until the model has converged (or
    for a fixed number of iterations):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Screen-Shot-2017-04-27-at-3.56.08-PM.png)'
  prefs: []
  type: TYPE_IMG
- en: Objective function is not convex since both *q* and *p* are not known, but if
    we fix one of the unknown optimization can be solved. ALS rotates between fixing
    *q*'s and *p*'s as explained earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Spark's documentation for collaborative filtering contains references to the
    papers that underlie the ALS algorithms implemented each component of explicit
    and implicit data. You can view the documentation at http://spark.apache.org/docs/latest/ml-collaborative-filtering.html.
  prefs: []
  type: TYPE_NORMAL
- en: The following code explains how to implement ALS algorithm from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take an example and show how it is implemented and look at a real matrix
    of 3 movies and 3 users:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The first iteration of movie matrix is chosen randomly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The first iteration of user matrix is chosen randomly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Pickup the first row of user matrix `us`, Calculate `XtX` (matrix) and `Xty`
    (a vector) as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: j:0
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Pickup the second row of user matrix `us`, and add values to `XtX` (matrix)
    and `Xty` (a vector) as shown in the folowing code:'
  prefs: []
  type: TYPE_NORMAL
- en: j:1
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: j:2
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Calculate value of first row of `ms` (movie matrix using Cholesky decomposition
    of `XtX` and `XtY`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'After going through each row of us and following the steps above we arrive
    at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing the following source code for the mathematical implementation explained
    previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'You can find the code listing at: [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/AlternatingLeastSquares.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/AlternatingLeastSquares.scala)'
  prefs: []
  type: TYPE_NORMAL
- en: Extracting the right features from your data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will use explicit rating data, without additional user,
    item metadata, or other information related to the user-item interactions. Hence,
    the features that we need as inputs are simply the user IDs, movie IDs, and the
    ratings assigned to each user and movie pair.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting features from the MovieLens 100k dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this example, we will use the same MovieLens dataset that we used in the
    previous chapter. Use the directory in which you placed the MovieLens 100k dataset
    as the input path in the following code.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s inspect the raw ratings dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'You can find the code listing at: [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/FeatureExtraction.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/FeatureExtraction.scala)'
  prefs: []
  type: TYPE_NORMAL
- en: 'You will see an output similar to these lines of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Recall that this dataset (mapped to the `Rating` class using case) consisted
    of the `userID`, `movieID`, `rating`, and `timestamp` fields separated by a tab
    (`"t"`) character. We don''t need the time when the rating was made to train our
    model, so in the following code snippet we simply extracted the first three fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'You can find the code listing at: [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/FeatureExtraction.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/FeatureExtraction.scala)'
  prefs: []
  type: TYPE_NORMAL
- en: We will first split each record on the `"t"` character, which gives us a `String[]`
    array. We will then use case class to map and keep only the first `3` elements
    of the array, which correspond to `userID`, `movieID`, and `rating`, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Training the recommendation model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once we have extracted these simple features from our raw data, we are ready
    to proceed with model training; ML takes care of this for us. All we have to do
    is provide the correctly-parsed input dataset we just created as well as our chosen
    model parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Split the dataset in to training and testing sets with ratio 80:20, as shown
    in the following lines of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You can find the code listing at: [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala)'
  prefs: []
  type: TYPE_NORMAL
- en: 'You will see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Training a model on the MovieLens 100k dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''re now ready to train our model! The other inputs required for our model
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`rank`: This refers to the number of factors in our ALS model, that is, the
    number of hidden features in our low-rank approximation matrices. Generally, the
    greater the number of factors, the better, but this has a direct impact on memory
    usage, both for computation and to store models for serving, particularly for
    large numbers of users or items. Hence, this is often a trade-off in real-world
    use cases. It also impacts the amount of training data required.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A rank in the range of 10 to 200 is usually reasonable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`iterations`: This refers to the number of iterations to run. While each iteration
    in ALS is guaranteed to decrease the reconstruction error of the ratings matrix,
    ALS models will converge to a reasonably good solution after relatively little
    iterations. So, we don''t need to run too many iterations in most cases--around
    10 is often a good default.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`numBlocks`: This is the number of blocks the users and items will be partitioned
    into, to parallelize computation (defaults to 10). The number depends on the number
    of cluster nodes as well as how data is partitioned.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`regParam`: This specifies the regularization parameter in ALS (defaults to
    1.0). The constant *Î»* is called the regularization parameter and essentially
    penalizes the components of the user and item matrices if they get too large (in
    magnitude). This is important for numerical stability, and some kind of regularization
    is almost always used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`implicitPrefs`: This specifies whether to use the Explicit feedback ALS variant
    or one adapted for Implicit feedback data; it defaults to false, which means using
    Explicit feedback.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`alpha`: This is a parameter applicable to the Implicit feedback variant of
    ALS that governs the *baseline* confidence in preference observations (defaults
    to 1.0).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`nonnegative`: This specifies whether or not to use nonnegative constraints
    for least squares (defaults to `false`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We''ll use default `rank`, `5``maxIter`, and a `regParam` parameter of `0.01`
    to illustrate how to train our model which is shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: You can find the code listing at [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala).
  prefs: []
  type: TYPE_NORMAL
- en: This returns a `ALSModel` object, which contains the user and item factors.
    These are called `userFactors` and `itemFactors`, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: For example, `model.userFactors`.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will see the output as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the factors are in the form of `Array[float]`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the operations used in MLlib''s ALS implementation are lazy transformations,
    so the actual computation will only be performed once we call some sort of action
    on the resulting DataFrame of the user and item factors. In the following code
    we can force the computation using a Spark action such as `count`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This will trigger the computation, and we will see quite a bit of output texts
    similar to the following lines of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'If we call `count` for the movie factors, it will be done with the help of
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This will trigger the computation, and we will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: As expected, we have a factor array for each user (`943` factors) and each movie
    (`1651` factors).
  prefs: []
  type: TYPE_NORMAL
- en: Training a model using Implicit feedback data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The standard Matrix Factorization approach in MLlib deals with explicit ratings.
    To work with implicit data, you can use the `trainImplicit` method. It is called
    in a manner similar to the standard `train` method. There is an additional parameter,
    `alpha`, that can be set (and in the same way, the regularization parameter, `lambda`,
    should be selected via testing and cross-validation methods).
  prefs: []
  type: TYPE_NORMAL
- en: The `alpha` parameter controls the baseline level of confidence, weighting applied.
    A higher level of `alpha` tends to make the model more confident about the fact
    that missing data equates to no preference for the relevant user-item pair.
  prefs: []
  type: TYPE_NORMAL
- en: 'From Spark version 2.0, if the rating matrix is derived from another source
    of information that is, it is inferred from other signals, you can `setImplicitPrefs`
    to `true` to get better results, as shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: As an exercise, try to take the existing MovieLens dataset and convert it into
    an implicit dataset. One possible approach is to convert it to binary feedback
    (0s and 1s) by applying a threshold on the ratings at some level.
  prefs: []
  type: TYPE_NORMAL
- en: Another approach could be to convert the ratings' values into confidence weights
    (for example, perhaps, low ratings could imply zero weights, or even negative
    weights, which are supported by MLlib's implementation).
  prefs: []
  type: TYPE_NORMAL
- en: Train a model on this dataset and compare the results of the following section
    with those generated by your implicit model.
  prefs: []
  type: TYPE_NORMAL
- en: Using the recommendation model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have our trained model, we're ready to use it to make predictions.
  prefs: []
  type: TYPE_NORMAL
- en: ALS Model recommendations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Starting Spark v2.0, `org.apache.spark.ml.recommendation.ALS` modeling is a
    blocked implementation of the factorization algorithm that groups "users" and
    "products" factors into blocks and decreases communication by sending only one
    copy of each user vector to each product block at each iteration, and only for
    the product blocks that need that user's feature vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we will load the rating data from the movies dataset where each row consists
    of a user, movie, rating, and a timestamp. We will then train an ALS model by
    default works on explicit preferences (`implicitPrefs` is `false`). We will evaluate
    the recommendation model by measuring the root-mean-square error of rating prediction
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'You can find the code listing at: [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the output for the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Before we proceed further, please note that the following examples for User
    and Item recommendations use MLlib from Spark v1.6\. Kindly follow the code listing
    to get the details of creating recommendation models using `org.apache.spark.mllib.recommendation.ALS`.
  prefs: []
  type: TYPE_NORMAL
- en: User recommendations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this case, we would like to generate recommended items for a given user.
    This usually takes the form of a *top-K* list, that is, the *K* items that our
    model predicts will have the highest probability of the user liking them. This
    is done by computing the predicted score for each item and ranking the list based
    on this score.
  prefs: []
  type: TYPE_NORMAL
- en: The exact method to perform this computation depends on the model involved.
    For example, in user-based approaches, the ratings of similar users on items are
    used to compute the recommendations for a user; while in an item-based approach,
    the computation is based on the similarity of items the user has rated to the
    candidate items.
  prefs: []
  type: TYPE_NORMAL
- en: In matrix factorization, because we are modeling the ratings matrix directly,
    the predicted score can be computed as the vector dot product between a user-factor
    vector and an item-factor vector.
  prefs: []
  type: TYPE_NORMAL
- en: Generating movie recommendations from the MovieLens 100k dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As MLlib's recommendation model is based on matrix factorization, we can use
    the factor matrices computed by our model to compute predicted scores (or ratings)
    for a user. We will focus on the explicit rating case using MovieLens data; however,
    the approach is the same when using the implicit model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `MatrixFactorizationModel` class has a convenient `predict` method that
    will compute a predicted score for a given user and item combination as shown
    in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, this model predicts a rating of `3.12` for user `789` and movie
    `123`.
  prefs: []
  type: TYPE_NORMAL
- en: Note that you might see different results than those shown in this section because
    the ALS model is initialized randomly. So, different runs of the model will lead
    to different solutions.
  prefs: []
  type: TYPE_NORMAL
- en: The `predict` method can also take an RDD of `(user, item)` IDs as the input
    and will generate predictions for each of these. We can use this method to make
    predictions for many users and items at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: 'To generate the *top-K* recommended items for a user, `MatrixFactorizationModel`
    provides a convenience method called `recommendProducts`. This takes two arguments:
    `user` and `num`, where `user` is the user ID and `num` is the number of items
    to recommend.'
  prefs: []
  type: TYPE_NORMAL
- en: It returns the top `num` items ranked in the order of the predicted score. Here,
    the scores are computed as the dot product between the user-factor vector and
    each item-factor vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s generate the top `10` recommended items for user `789` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have a set of predicted ratings for each movie for user `789`. If we
    print this out, by writing the following line of code, we could inspect the top
    10 recommendations for this user:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output on your console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Inspecting the recommendations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can give these recommendations a sense check by taking a quick look at the
    titles of the movies a user has rated and the recommended movies. First, we will
    need to load the movie data, which is one of the datasets we explored in the previous
    chapter. In the following code we''ll collect this data as a `Map[Int, String]`
    method, mapping the movie ID to the title:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will produce the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'For our user `789`, we can find out what movies they have rated, take the `10`
    movies with the highest rating, and then check the titles. We will do this now
    by first using the `keyBy` Spark function to create an RDD of key-value pairs
    from our `ratings` RDD, where the key will be the user ID. We will then use the
    `lookup` function to return just the ratings for this key (that is, that particular
    user ID) to the driver which is described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see how many movies this user has rated. This will be the `size` of
    the `moviesForUser` collection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: We will see that this user has rated `33` movies.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will take the 10 movies with the highest ratings by sorting the `moviesForUser`
    collection using the `rating` field of the `Rating` object. We will then extract
    the movie title for the relevant product ID attached to the `Rating` class from
    our mapping of movie titles and print out the top `10` titles with their ratings
    as shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the following output displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s take a look at the top 10 recommendations for this user and see
    what the titles are, using the same approach as the one we used earlier (note
    that the recommendations are already sorted):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: We leave it for you to decide whether these recommendations make sense.
  prefs: []
  type: TYPE_NORMAL
- en: Item recommendations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Item recommendations are about answering the following question: for a certain
    item, what are the items most similar to it? Here, the precise definition of similarity
    is dependent on the model involved. In most cases, similarity is computed by comparing
    the vector representation of two items using some similarity measure. Common similarity
    measures include Pearson correlation and cosine similarity for real-valued vectors,
    and Jaccard similarity for binary vectors.'
  prefs: []
  type: TYPE_NORMAL
- en: Generating similar movies for the MovieLens 100k dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The current `MatrixFactorizationModel` API does not directly support item-to-item
    similarity computations. Therefore, we will need to create our own code to do
    this.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the cosine similarity metric, and we will use the jblas linear algebra
    library (a dependency of MLlib) to compute the required vector dot products. This
    is similar to how the existing `predict` and `recommendProducts` methods work,
    except that we will use cosine similarity as opposed to just the dot product.
  prefs: []
  type: TYPE_NORMAL
- en: 'We would like to compare the factor vector of our chosen item with each of
    the other items using our similarity metric. In order to perform linear algebra
    computations, we will first need to create a vector object out of the factor vectors,
    which are in the form of `Array[Double]`. The `JBLAS` class, `DoubleMatrix`, takes
    `Array[Double]` as the constructor argument, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Use the following constructor to instantiate `DoubleMatrix` from an array.
  prefs: []
  type: TYPE_NORMAL
- en: The `jblas` class is a linear algebra library written in Java. It is based on
    BLAS and LAPACK, the de-facto industry standard for matrix computations, and uses
    implementations like `ATLAS` for its computational routines, making jBLAS very
    fast.
  prefs: []
  type: TYPE_NORMAL
- en: It is a light-weight wrapper around the BLAS and LAPACK routines. BLAS and LAPACK
    packages have originated in the Fortran community.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see an example of it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Create a column vector using `newData` as the data array. Any change in the
    created `DoubleMatrix` will change in input array `newData`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a simple `DoubleMatrix`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output of the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Note that using jblas, vectors are represented as a one-dimensional `DoubleMatrix`
    class, while matrices are a two-dimensional `DoubleMatrix` class.
  prefs: []
  type: TYPE_NORMAL
- en: We will need a method to compute the cosine similarity between two vectors.
    Cosine similarity is a measure of the angle between two vectors in an *n*-dimensional
    space. It is computed by first calculating the dot product between the vectors
    and then dividing the result by a denominator, which is the norm (or length) of
    each vector multiplied together (specifically, the L2-norm is used in cosine similarity).
  prefs: []
  type: TYPE_NORMAL
- en: In linear algebra, the size of a vector ![](img/image_05_014.png) is called
    the norm of ![](img/image_05_015.png). We will discuss a few different kinds of
    norms. For this discussion, we will define a vector v as an ordered tuple of numbers.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_05_016.png)'
  prefs: []
  type: TYPE_IMG
- en: 'One Norm: The one-norm (also known as the L1-norm, or mean norm) of vector
    ![](img/image_05_017.png) is denoted as shown in the following diagram and is
    defined as the sum of the absolute values of its components:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_05_018.png)'
  prefs: []
  type: TYPE_IMG
- en: Two-norm (also known as the L2-norm, mean-square norm, least-squares norm)
  prefs: []
  type: TYPE_NORMAL
- en: 'of a ![](img/image_05_019.png) vector is denoted as shown in this diagram::'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_05_020.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Moreover, it is defined as the square root of the sum of the squares of the
    absolute values of its components:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_05_021.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this way, cosine similarity is a normalized dot product. The cosine similarity
    measure takes on values between `-1` and 1\. A value of `1` implies completely
    similarity, while a value of 0 implies independence (that is, no similarity).
    This measure is useful because it also captures negative similarity, that is,
    a value of `-1` implies that not only are the vectors not similar, but they are
    also completely dissimilar:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_05_022.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s create our `cosineSimilarity` function here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Note that we defined a return type for this function of `Double`. We are not
    required to do this since Scala features type inference. However, it can often
    be useful to document return types for Scala functions.
  prefs: []
  type: TYPE_NORMAL
- en: Let's try it out on one of our item factors for item `567`. We will need to
    collect an item factor from our model; we will do this using the `lookup` method
    in a similar way that we did earlier to collect the ratings for a specific user.
    In the following lines of code, we will also use the `head` function, since `lookup`
    returns an array of values, and we will only need the first value (in fact, there
    will only be one value, which is the factor vector for this item).
  prefs: []
  type: TYPE_NORMAL
- en: 'Since this will be an constructor `Array[Double]`, we will then need to create
    a `DoubleMatrix` object from it and compute the cosine similarity with itself
    which is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'A similarity metric should measure how close, in some sense, two vectors are
    to each other. In the following example, we can see that our cosine similarity
    metric tells us that this item vector is identical to itself, which is what we
    would expect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we are ready to apply our similarity metric to each item which is shown
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we can compute the top 10 most similar items by sorting out the similarity
    score for each item:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code snippet, we used Spark's `top` function, which is an efficient
    way to compute *top-K* results in a distributed fashion, instead of using `collect`
    to return all the data to the driver and sorting it locally (remember that we
    could be dealing with millions of users and items in the case of recommendation
    models).
  prefs: []
  type: TYPE_NORMAL
- en: We will need to tell Spark how to sort the `(item id, similarity score)` pairs
    in the `sims` RDD. To do this, we will pass an extra argument to `top`, which
    is a Scala `Ordering` object that tells Spark that it should sort by the value
    in the key-value pair (that is, sort by `similarity`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can print the 10 items with the highest computed similarity metric
    to our given item:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see an output like the following one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Not surprisingly, we can see that the top-ranked similar item is our item. The
    rest are the other items in our set of items, ranked in order of our similarity
    metric.
  prefs: []
  type: TYPE_NORMAL
- en: Inspecting the similar items
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see what the title of our chosen movie is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will print the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'As we did for user recommendations, we can sense check our item-to-item similarity
    computations and take a look at the titles of the most similar movies. This time,
    we will take the top 11, so that we can exclude our given movie. So, we will take
    the numbers 1 to 11 in the list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the movie titles and scores displayed similar to this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Once again, note that you might see quite different results due to random model
    initialization.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have computed similar items using cosine similarity, see if you
    can do the same with the user-factor vectors to compute similar users for a given
    user.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating the performance of recommendation models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How do we know whether the model we have trained is a good model? We will need
    to be able to evaluate its predictive performance in some way. Evaluation metrics
    are measures of a model's predictive capability or accuracy. Some are direct measures
    of how well a model predicts the model's target variable, such as Mean Squared
    Error, while others are concerned with how well the model performs at predicting
    things that might not be directly optimized in the model, but are often closer
    to what we care about in the real world, such as Mean Average Precision.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation metrics provide a standardized way of comparing the performance of
    the same model with different parameter settings and of comparing performance
    across different models. Using these metrics, we can perform model selection to
    choose the best-performing model from the set of models we wish to evaluate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we will show you how to calculate two common evaluation metrics used
    in recommender systems and collaborative filtering models: **Mean Squared Error**
    (**MSE**) and **Mean Average Precision at K** (**MAPK**).'
  prefs: []
  type: TYPE_NORMAL
- en: ALS Model Evaluation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'From Spark v2.0, we will use `org.apache.spark.ml.evaluation.RegressionEvaluator`
    for regression problems. Regression evaluation is a metric to measure how well
    a fitted model does on held-out test data. Here, we will use **Root Mean Squared
    Error** (**RMSE**), which is just the square root of the MSE metric:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: You can find the code-listing at [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/2.0.0/scala-spark-app/src/main/scala/com/spark/recommendation/ALSModeling.scala).
  prefs: []
  type: TYPE_NORMAL
- en: 'You will see an output like the following one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Before we proceed further, please note that the following evaluation examples
    use MLLib from Spark v1.6\. Kindly follow the code listing to get the details
    of creating recommendation model using `org.apache.spark.mllib.recommendation.ALS`.
  prefs: []
  type: TYPE_NORMAL
- en: Mean Squared Error
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The MSE is a direct measure of the reconstruction error of the user-item rating
    matrix. It is also the objective function being minimized in certain models, specifically
    many matrix-factorization techniques, including ALS. As such, it is commonly used
    in explicit ratings settings.
  prefs: []
  type: TYPE_NORMAL
- en: It is defined as the sum of the squared errors divided by the number of observations.
    The squared error, in turn, is the square of the difference between the predicted
    rating for a given user-item pair and the actual rating.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use our user `789` as an example. Let''s take the first rating for
    this user from the `moviesForUser` set of `Ratings` that we previously computed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'We will see that the rating for this user-item combination is 4\. Next, we
    will compute the model''s predicted rating:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the model''s predicted rating is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'We will see that the predicted rating is about 4, very close to the actual
    rating. Finally, we will compute the squared error between the actual rating and
    the predicted rating:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will output the squared error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: So, in order to compute the overall MSE for the dataset, we will need to compute
    this squared error for each (`user`, `movie`, `actual rating`, `predicted rating`)
    entry, sum them up, and divide them by the number of ratings. We will do this
    in the following code snippet.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: the following code is adapted from the Apache Spark programming guide
    for ALS at [http://spark.apache.org/docs/latest/mllib-collaborative-filtering.html](http://spark.apache.org/docs/latest/mllib-collaborative-filtering.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will extract the user and product IDs from the `ratings` RDD and
    make predictions for each user-item pair using `model.predict`. We will use the
    user-item pair as the key and the predicted rating as the value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will extract the actual ratings and also map the `ratings` RDD so
    that the user-item pair is the key and the actual rating is the value. Now that
    we have two RDDs with the same form of key, we can join them together to create
    a new RDD with the actual and predicted ratings for each user-item combination:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will compute the MSE by summing up the squared errors using `reduce`
    and dividing by the `count` method of the number of records:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'It is common to use the RMSE, which is just the square root of the MSE metric.
    This is somewhat more interpretable, as it is in the same units as the underlying
    data (that is, the ratings in this case). It is equivalent to the standard deviation
    of the differences between the predicted and actual ratings. We can compute it
    simply as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will print the RMSE:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: To interpret the preceding result, keep following the definition in mind. Lowering
    the value of RMSE closer is the fit of predicted value to the actual value. While
    interpreting RMSE, keep the minimum and maximum of the actual data in mind.
  prefs: []
  type: TYPE_NORMAL
- en: Mean Average Precision at K
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Mean Average Precision at *K* is the mean of the **average precision at K**
    (**APK**) metric across all instances in the dataset. APK is a metric commonly
    used for information retrieval. APK is a measure of the average relevance scores
    of a set of the *top-K* documents presented in response to a query. For each query
    instance, we will compare the set of *top-K* results with the set of actual relevant
    documents, that is, a ground truth set of relevant documents for the query.
  prefs: []
  type: TYPE_NORMAL
- en: In the APK metric, the order of the result set matters, in that the APK score
    would be higher if the result documents are both relevant and the relevant documents
    are presented higher in the results. It is, thus, a good metric for recommender
    systems; in that, typically, we would compute the *top-K* recommended items for
    each user and present these to the user. Of course, we prefer models where the
    items with the highest predicted scores, which are presented at the top of the
    list of recommendations, are, in fact, the most relevant items for the user. APK
    and other ranking-based metrics are also more appropriate evaluation measures
    for implicit datasets; here, MSE makes less sense.
  prefs: []
  type: TYPE_NORMAL
- en: In order to evaluate our model, we can use APK, where each user is the equivalent
    of a query, and the set of *top-K* recommended items is the document result set.
    The relevant documents, that is, the ground truth, in this case, is the set of
    items that a user interacted with. Hence, APK attempts to measure how good our
    model is at predicting items that a user will find relevant and choose to interact
    with.
  prefs: []
  type: TYPE_NORMAL
- en: The code for the following average precision computation is based on [https://github.com/benhamner/Metrics](https://github.com/benhamner/Metrics).
  prefs: []
  type: TYPE_NORMAL
- en: More information on MAPK can be found at [https://www.kaggle.com/wiki/MeanAveragePrecision](https://www.kaggle.com/wiki/MeanAveragePrecision).
  prefs: []
  type: TYPE_NORMAL
- en: 'Our function to compute the APK is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, this takes as input a list of `actual` item IDs that are associated
    with the user and another list of `predicted` IDs so that our estimate will be
    relevant for the user.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can compute the APK metric for our example user `789` as follows. First,
    we will extract the actual movie IDs for the user, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'We will then use the movie recommendations we made previously to compute the
    APK score using `K = 10`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code will produce the average precision:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will print the following command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: In this case, we can see that our model is not doing a very good job of predicting
    relevant movies for this user, as the APK score is `0`.
  prefs: []
  type: TYPE_NORMAL
- en: In order to compute the APK for each user and average them to compute the overall
    MAPK, we will need to generate the list of recommendations for each user in our
    dataset. While this can be fairly intensive on a large scale, we can distribute
    the computation using our Spark functionality. However, one limitation is that
    each worker must have the full item-factor matrix available so that it can compute
    the dot product between the relevant user vector and all item vectors. This can
    be a problem when the number of items is extremely high, as the item matrix must
    fit in the memory of one machine.
  prefs: []
  type: TYPE_NORMAL
- en: There is actually no easy way around this limitation. One possible approach
    is to only compute recommendations for a subset of items from the total item set,
    using approximate techniques such as Locality Sensitive Hashing ([http://en.wikipedia.org/wiki/Locality-sensitive_hashing](http://en.wikipedia.org/wiki/Locality-sensitive_hashing)).
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now see how to go about this. First, we will collect the item factors
    and form a `DoubleMatrix` object from them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us a matrix with `1682` rows and `50` columns, as we would expect
    from `1682` movies with a factor dimension of `50`. Next, we will distribute the
    item matrix as a broadcast variable so that it is available on each worker node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the output as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we are ready to compute the recommendations for each user. We will do this
    by applying a `map` function to each user factor within which we will perform
    a matrix multiplication between the user-factor vector and the movie-factor matrix.
    The result is a vector (of length `1682`, that is, the number of movies we have)
    with the predicted rating for each movie. We will then sort these predictions
    by the predicted rating:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the following on the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, we now have an RDD that contains a list of movie IDs for each
    user ID. These movie IDs are sorted in order of the estimated rating.
  prefs: []
  type: TYPE_NORMAL
- en: Note that we needed to add 1 to the returned movie IDs (as highlighted in the
    preceding code snippet), as the item-factor matrix is 0-indexed, while our movie
    IDs start at `1`.
  prefs: []
  type: TYPE_NORMAL
- en: We will also need the list of movie IDs for each user to pass into our APK function
    as the `actual` argument. We already have the `ratings` RDD ready, so we can extract
    just the user and movie IDs from it.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we use Spark''s `groupBy` operator, we will get an RDD that contains a list
    of `(userid, movieid)` pairs for each user ID (as the user ID is the key on which
    we perform the `groupBy` operation) shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can use Spark''s `join` operator to join these two RDDs together
    on the user ID key. Then, for each user, we have the list of actual and predicted
    movie IDs that we can pass to our APK function. In a manner similar to how we
    computed MSE, we will sum each of these APK scores using a `reduce` action and
    divide by the number of users, that is, the count of the `allRecs` RDD as shown
    in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will print the `Mean Average Precision at``K` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: Our model achieves a fairly low MAPK. However, note that typical values for
    recommendation tasks are usually relatively low, especially if the item set is
    extremely large.
  prefs: []
  type: TYPE_NORMAL
- en: Try out a few parameter settings for `lambda` and `rank` (and `alpha`, if you
    are using the implicit version of ALS) and see whether you can find a model that
    performs better based on the RMSE and MAPK evaluation metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Using MLlib's built-in evaluation functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While we have computed MSE, RMSE, and MAPK from scratch, and it's a useful learning
    exercise to do so, MLlib provides convenience functions to do this for us in the
    `RegressionMetrics` and `RankingMetrics` classes.
  prefs: []
  type: TYPE_NORMAL
- en: RMSE and MSE
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we will compute the MSE and RMSE metrics using `RegressionMetrics`.
    We will instantiate a `RegressionMetrics` instance by passing in an RDD of key-value
    pairs that represent the predicted and true values for each data point, as shown
    in the following code snippet. Here, we will again use the `ratingsAndPredictions`
    RDD we computed in our earlier example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then access various metrics, including MSE and RMSE. We will print out
    these metrics here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following command lines, you will see that the output for MSE and RMSE,
    is exactly the same as the metrics we computed earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: MAP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we did for MSE and RMSE, we can compute ranking-based evaluation metrics
    using MLlib's `RankingMetrics` class. Similarly, to our own average precision
    function, we will need to pass in an RDD of key-value pairs, where the key is
    `Array` of predicted item IDs for a user, while the value is an array of actual
    item IDs.
  prefs: []
  type: TYPE_NORMAL
- en: The implementation of the average precision at the K function in `RankingMetrics`
    is slightly different from ours, so we will get different results. However, the
    computation of the overall Mean Average Precision (MAP, which does not use a threshold
    at K) is the same as our function if we select `K` to be very high (say, at least
    as high as the number of items in our item set).
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will calculate MAP using `RankingMetrics` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will use our function to compute the MAP in exactly the same way as
    we did previously, except that we set `K` to a very high value, say `2000`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see that the MAP from our own function is the same as the one computed
    using `RankingMetrics`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: We will not cover cross-validation in this chapter, as we will provide a detailed
    treatment in the next few chapters. However, note that the same techniques for
    cross-validation that are explored in the upcoming chapters can be used to evaluate
    recommendation models using the performance metrics such as MSE, RMSE, and MAP,
    which we covered in this section.
  prefs: []
  type: TYPE_NORMAL
- en: FP-Growth algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will apply the FP-Growth algorithm to find frequently recommended movies.
  prefs: []
  type: TYPE_NORMAL
- en: The FP-Growth algorithm has been described in the paper by Han et al., *Mining
    frequent patterns without candidate generation*Â available at:Â [http://dx.doi.org/10.1145/335191.335372](http://dx.doi.org/10.1145/335191.335372),
    where **FP** stands for the **frequent pattern**. For given a dataset of transactions,
    the first step of FP-Growth is to calculate item frequencies and identify frequent
    items. The second step of FP-Growth algorithm implementation uses a suffix tree
    (FP-tree) structure to encode transactions; this is done without generating candidate
    sets explicitly, which are usually expensive to generate for large datasets.
  prefs: []
  type: TYPE_NORMAL
- en: FP-Growth Basic Sample
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s start with a very simple dataset of random numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'We will find out the most frequent items (character in this case). First, we
    will get the spark context as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'Convert our data in an RDD:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'Initialize the `FPGrowth` instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'FP-Growth can be configured with the following parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`minSupport`: the minimum support number for an itemset to be identified as
    frequent. For example, if an item appears in 3 out of 10 transactions, it has
    a support of 3/10=0.3.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`numPartitions`: the number of partitions to distribute the work.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Set `minsupport` and number of partitions for the FP-Growth instance and call
    run on the RDD object. Number of partitions should be set to the number of partitions
    in the dataset--number of worker nodes from where data will be loaded, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'Get the item sets of the output and print:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'The output for the preceding code is listed as follows, as you can see `[Z]`
    occurs the most:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: FP-Growth Applied to Movie Lens Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s apply the algorithm to Movie Lens data to find our frequent movie titles:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Instantiate the `SparkContext` by writing the following lines of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'Get raw ratings and print first by writing the following lines of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'Load the movie data and get the titles as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will find out the most frequent movies for 400 users from 501 to 900
    using the FP-Growth algorithm.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The FP-Growth model is created first by writing the following lines of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: Where `0.1` is the minimum cutoff to be considered, `rddx` is the RDD with raw
    movie ratings loaded into RDD for 400 users. Once we have the model we can iterate
    `overitemsetr`, the `itemset` and print the results.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The complete code listing is given here and can also be found at [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/scala-spark-app/src/main/scala/MovieLensFPGrowthApp.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_05/scala-spark-app/src/main/scala/MovieLensFPGrowthApp.scala).
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be done by writing the following lines of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding sample is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: This provides movies with the maximum frequency for user IDs 501 to 900.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we used Spark's ML and MLlib library to train a collaborative
    filtering recommendation model, and you learned how to use this model to make
    predictions for the items that a given user may have a preference for. We also
    used our model to find items that are similar or related to a given item. Finally,
    we explored common metrics to evaluate the predictive capability of our recommendation
    model.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn how to use Spark to train a model to classify
    your data and to use standard evaluation mechanisms to gauge the performance of
    your model.
  prefs: []
  type: TYPE_NORMAL
