- en: Thinking About Business Object Data Persistence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It's a given that most programs and systems have a need to store and retrieve
    data to operate with. The alternative, embedding data into the code itself, is
    simply not practical, after all. The specific shape of the data storage involved
    can vary wildly, based on the underlying storage mechanism, the specific needs
    of an application or service, and even on nominally non-technical constraints
    such as the need to not require end users to install other software, but the fundamental
    need remains the same, no matter what those factors add up to.
  prefs: []
  type: TYPE_NORMAL
- en: 'The various component projects/sub-systems of `hms_sys` are no exception to
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: The **Artisan** **Application** will need to allow **Artisan** users to manage
    the **products** that the **Artisan** is creating and selling, and to manage at
    least some of their own business entity data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Artisan** **Gateway** service will probably need to at least stage data
    for **artisans**, **products**, and **orders**, with associated **Customer** and
    **Address** objects, as the data those objects contain moves through various processes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Central Office Application** will need to be able to manage parts of **Artisan** and
    **Product** data, and may need to read order data, if only for troubleshooting
    purposes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So far, no specific requirements exist for how this data is going to be persisted,
    or even where, though it''s probable that the **Artisan Application** will need
    to keep data locally and propagate it up to or through the **Artisan Gateway**,
    where the **Central Office Application** will access it, as shown in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/3153758b-360e-4547-8b76-8a2ecadae869.png)'
  prefs: []
  type: TYPE_IMG
- en: This iteration will work through the requirements, implementation, and testing
    of the data persistence mechanisms involved for each of the component projects
    in `hms_sys`, starting with some basic analysis of the needs and scope that is
    specific to each component project. However, at this point, we don't have any
    clear direction as to what the backend data storage even looks like, so we can't
    really write any stories that provide useful guidance for how to implement data
    persistence. Clearly, then, more investigation will be needed before planning
    and executing this iteration.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will examine the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: How an iterative (Agile) process usually handles stories that don't have sufficient
    information to execute against
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What data storage and persistence options are available, in general
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What data access strategies should be examined, before making a decision about
    how the various `hms_sys` component projects will deal with data access
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Iterations are (somewhat) flexible
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In many Agile methodologies, there are specific artefacts and/or processes
    intended to handle the kinds of scenario that this iteration is starting in—there
    is a need, even if it''s only implied, for some functionality, but not enough
    information is available to actually make any development progress against that
    need. There might even be stories already in place that appear to be complete,
    but that are lacking some nuts-and-bolts details that are needed for development
    to progress. In this case, those stories might resemble the following:'
  prefs: []
  type: TYPE_NORMAL
- en: As an **Artisan**, I need my **Product **data to be stored locally, so that
    I can work with it without having to worry about connecting to an external system
    that I may not have ready access to at the moment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a **Product Manager**/**Approver**, I need to be able to access **Product**
    information across any/all **artisans** so that I can manage the availability
    of those products in the web store
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a **System Administrator**, I need the **Artisan Gateway** to store **Product**
    and related data separate from the main **Web Store** application so that it can
    be safely staged before being released to the public site
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of these stories might look complete in that they are defining what needs
    to happen from each user's perspective, but they lack any information about how
    those should function.
  prefs: []
  type: TYPE_NORMAL
- en: Enter the Spike.
  prefs: []
  type: TYPE_NORMAL
- en: 'Spikes, which originated with the XP methodology and have been adopted (officially
    or otherwise) across several other Agile methodologies, are essentially stories
    whose purpose is to research and return usable planning details for other stories.
    Ideally, stories that need Spikes generated around them will be identified before
    they enter an iteration—if that doesn''t occur, stories whose information is lacking
    will be unworkable, and some sort of shuffle will inevitably take place to either
    defer the incomplete stories until their spikes have been completed, or incorporate
    the spikes and their results into a revised iteration plan. The former will frequently
    be the more likely of the two, though, since without the information from the
    Spike estimating the target stories will be difficult at best, and perhaps impossible.
    The spike stories that relate to the original stories that we mentioned previously
    might be written like so:'
  prefs: []
  type: TYPE_NORMAL
- en: As a developer, I need to know how **Artisan** **Application** data is to be
    stored and retrieved so that I can write code for those processes accordingly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a developer, I need to know how **Central** **Office Application** data is
    to be stored and retrieved so that I can write code for those processes accordingly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a developer, I need to know how **Artisan Gateway** data is to be stored
    and retrieved so that I can write code for those processes accordingly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In order to work through and resolve these spikes, and to finalize the stories
    for this iteration, it'll be helpful to know what options are available. Once
    those have been explored, they can be weighed in the context of the applications
    and the service layer of the system, and some final decisions about implementation
    approaches can be made, along with some final stories being written to work against.
  prefs: []
  type: TYPE_NORMAL
- en: Data storage options
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'All of the options that will be given serious consideration have a few common
    properties:'
  prefs: []
  type: TYPE_NORMAL
- en: They will allow data to be stored offline, so that the application or service
    program doesn't need to be running constantly in order to ensure that the relevant
    data isn't lost
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'They have to allow the applications and service to perform at least three of
    the four standard **CRUD** operations:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**C****reate**: Allowing data for new objects to be stored.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**R****ead**: Allowing access to data for existing objects, one at a time,
    all at once, and possibly with some filtering/searching capabilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**U****pdate**: Allowing existing data to be altered when/if needed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**D****elete**: Allowing (perhaps) the ability to remove data for objects that
    are no longer relevant. At a minimum, flagging such data so that it''s not generally
    available will work as well.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'They should also be examined and evaluated in terms of **ACID** characteristics,
    though not all of these properties may be essential in the context of the data
    needs of `hms_sys`. None should be unachievable, however:'
  prefs: []
  type: TYPE_NORMAL
- en: '**A****tomicity**: Data transactions should be all or nothing, so that if part
    of a data-write fails, the entire dataset being written should also fail, leaving
    data in a stable state'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**C****onsistency**: Data transactions should always result in a valid data
    state across the entire dataset, observing and obeying any storage system rules
    (application-level rules are the responsibility of the applications, though)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Isolat****ion**: Data transactions should always result in the same end state
    that would occur if their component changes were executed one at a time in the
    same order'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**D****urability**: Data transactions should, once committed, be stored in
    a fashion that prevents loss due to system crashes, power-down, and so on'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Relational databases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Relational Database Management Systems** (**RDBMSes**) are one of the more
    mature data storage approaches available for applications, with options that have
    been in common use for decades. They typically store data as individual records
    (sometimes called **rows**) in tables (or relations*)* that define field names
    (**columns**) and types for all member records. Tables often define a primary
    key field that provides a unique identifier for each record in the table. A simple
    example of a table that defines user records might resemble the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/5e038e50-4222-4c9f-be26-bedad3bd993e.png)'
  prefs: []
  type: TYPE_IMG
- en: Each record in a table is, then, a consistent structure of data—all users in
    the preceding example would have `user_id`, `first_name`, `last_name`, and `email_address`
    values, though the values for the fields other than `user_id` might be empty,
    or `NULL`. The data from any table can be accessed or assembled through a query
    without having to change the tables themselves, and it's possible to join tables
    in a query so that, say, users in one table can be associated with records that
    they own in another—orders, perhaps.
  prefs: []
  type: TYPE_NORMAL
- en: This structure is often referred to as a schema, and it both defines structure
    and enforces data constraints such as value type and size.
  prefs: []
  type: TYPE_NORMAL
- en: The most common query language for relational databases is the **Structured
    Query Language** (**SQL**)—or at least some variant of it. SQL is an ANSI standard,
    but there are a number of variants available. There may be others, but SQL is
    almost certainly the most popular option, and is very mature and stable.
  prefs: []
  type: TYPE_NORMAL
- en: SQL is a complex enough topic in its own right, even setting aside its variations
    across database engines, to warrant a book of its own. We'll explore a little
    bit of SQL as `hms_sys` iterations progress, though, with some explanation of
    what is happening.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and drawbacks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the more significant advantages of a relational database data store is
    its ability to retrieve related records in a single query request—the user/orders
    structure mentioned earlier, for example. Most relational databases systems will
    also allow multiple queries to be made in a single request, and will return a
    collection of records for each of those queries as a single result set. The same
    user- and orders-table structure could, for example, be queried to return a single
    user and all of that user's orders, which has some advantages in application object
    structures where one object type has one or more collections of objects associated
    with them.
  prefs: []
  type: TYPE_NORMAL
- en: Another potentially significant advantage to most relational database engines
    is their support for transactions—allowing a potentially complex set of changes
    to, or insertions of data, to roll back as a whole if any single data manipulation
    fails for any reason. This is virtually guaranteed to be available in any SQL
    RDBMS, and is a very significant advantage when dealing with financial systems.
    Support for transactions may be a functional requirement for systems that deal
    with moving money around—if it isn't, it's probably worth asking why it isn't.
    Support for transactions that encompass multiple operations is a key aspect of
    full ACID compliance—without it, the atomicity, consistency, and (to some extent)
    isolation criteria will be suspect. Fortunately, almost any relational database
    system that's worthy of being called one at all will provide transaction support
    sufficient enough for any need likely to arise.
  prefs: []
  type: TYPE_NORMAL
- en: Many relational database systems also support the creation of views and stored
    procedures/functions that can make data access faster and more stable as well.
    Views are, for all practical purposes, predefined queries, often across multiple
    tables, and are often built to retrieve specific data subsets across the tables
    they are tied to. Stored procedures and functions can be thought of as approximate
    equivalents to application functions, accepting certain input, performing some
    set of tasks, and perhaps returning data that was generated by the execution of
    those tasks. At a minimum, stored procedures can be used in place of writing queries,
    which has some performance and security benefits.
  prefs: []
  type: TYPE_NORMAL
- en: The schema inherent to tables in most relational databases is both an advantage
    and a drawback, potentially. Since that schema enforces data constraints, there
    is less likelihood of having bad data living in a table. Fields that are expected
    to be string values, or integer values, will always be string or integer values,
    because it's simply not possible to set a string field to a non-string value.
    Those constraints ensure data type integrity. The trade-off for that, though,
    is that value types (and sometimes the values themselves) may have to be checked
    and/or converted when going into or coming out of the data store.
  prefs: []
  type: TYPE_NORMAL
- en: If relational databases have a downside, it's probably that the structures of
    the tables containing data are fixed, so making changes to those requires more
    time and effort, and those changes can have effects on the code that accesses
    them. Changing a field name in a database, for example, may well break application
    functionality that references that field name. Most relational database systems
    also require separate software installations, and server hardware that is operational
    at all times, like associated applications are. This may or may not be a concern
    for any given project, but can be a cost consideration, particularly if that server
    lives in someone else's infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling an RDBMS may be limited to adding more horsepower to the server itself—improving
    the hardware specifications, adding RAM, or moving databases to new, more powerful
    servers. Some of the aforementioned database engines have additional packages
    that can provide multi-server scale, though, such as scaling horizontally into
    multiple servers that still act like a single database server.
  prefs: []
  type: TYPE_NORMAL
- en: MySQL/MariaDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MySQL is a popular RDBMS that started as an open source project in the mid 1990s.
    MariaDB is a community-maintained fork of MySQL, intended to serve as a drop-in
    replacement for MySQL, and to remain available as an open source option in case
    MySQL (now owned by Oracle) every ceases to be released under an open source license.
    MySQL and MariaDB are, at the time of writing this book, interchangeable.
  prefs: []
  type: TYPE_NORMAL
- en: Both use the same variant of SQL, with mostly trivial syntax differences from
    standard SQL that are typically very straightforward. MySQL is—and MariaDB is
    presumed to be—more optimized for reading/retrieving data than for writing it,
    but for many applications, those optimizations will likely not be noticeable.
  prefs: []
  type: TYPE_NORMAL
- en: MySQL and MariaDB can be horizontally scaled through the use of clustering and/or
    replication software additions to a base installation to meet high availability
    or load needs, though for this to really be effective additional servers (real
    or virtual) are necessary.
  prefs: []
  type: TYPE_NORMAL
- en: There are several Python libraries for connecting to and interacting with MySQL,
    and since MariaDB is intended to be able to directly replace MySQL, those same
    libraries are expected to work without modification for MariaDB access.
  prefs: []
  type: TYPE_NORMAL
- en: MS-SQL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microsoft's SQL Server is a proprietary SQL-based DBMS, using its own variant
    of standard SQL (T-SQL—like MySQL's variants, the differences are generally trivial,
    at least for simple to somewhat complex needs).
  prefs: []
  type: TYPE_NORMAL
- en: MS-SQL also has clustering and replication options for high availability and
    load scenarios, with the same need for discrete servers to maximize the effectiveness
    of horizontal scaling.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are at least two Python options for connecting to and working with MS-SQL
    databases:'
  prefs: []
  type: TYPE_NORMAL
- en: '`pymssql`: This specifically leverages the **Tabular Data Stream** (**TDS**)
    protocol used by MS-SQL, and allows more direct connection to a backend engine'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pyodbc`: This provides database connectivity through the **Open Database Connectivity**
    (**ODBC**) protocol, which Microsoft has placed its confidence in as of mid-2018'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PostgresQL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PostgreSQL is another open source database option—an object-relational database
    system that is designed with an emphasis on standards compliance. As an ORDBMS,
    it allows data structures to be defined in a more object-oriented fashion, with
    tables that act like classes with the ability to inherit from other tables/classes.
    It still uses SQL—its own variant, but again, with mostly trivial differences
    for most development purposes—and has several Python options for connecting to
    and working with a database. It also has replication and clustering support, with
    the same sort of caveats noted for previous options.
  prefs: []
  type: TYPE_NORMAL
- en: NoSQL databases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At the time of writing, there were dozens of NoSQL database options available,
    both as standalone/local service installations and as cloud database options.
    The driving factors behind the designs of most of them include an emphasis on
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Support for massive numbers of users:** Tens of thousands of concurrent users,
    maybe millions—and supporting them should have as small a performance impact as
    possible'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**High availability and reliability:** Being able to interact with the data
    even if one or more database nodes were to go completely offline'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Supporting highly fluid data structures:** Allowing structured data that
    isn''t bound to a rigid data schema, perhaps even across records in the same data
    store collection'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From a development perspective, the last point in this list is perhaps the most
    significant, allowing almost arbitrary data structures to be defined as needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the concept of a table in a RDBMS is a storage model, there are a number
    of alternative storage models across the NoSQL database continuum:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Document stores:** Each record equivalent is a document containing whatever
    data structure it was created with. Documents are often JSON data structures,
    and as such allow for some differentiation between different data types—strings,
    numbers, and booleans as simple values, nested lists/arrays and objects for more
    complex data structures—and also allow for the use of a formal `null` value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Key/Value stores:** Each record equivalent is simply a value, of whatever
    type, and is identified by a single unique key. This approach could be thought
    of as a database that is equivalent to a single Python `dict` structure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Wide column stores:** Each record could be thought of as belonging to a RDBMS
    table with a very large (infinite?) number of columns available, perhaps with
    a primary key, or perhaps not.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are also some variants that feel like they combine aspects of these basic
    models. Creating a data store in Amazon's DynamoDB, for example, starts by defining
    a table, which requires a key field to be defined, and allows a secondary key
    field to be defined as well. Once those have been created, though, the contents
    of those tables acts like a document store. The net result, then, act like a key/document
    store (a key/value store where each key points to a document).
  prefs: []
  type: TYPE_NORMAL
- en: 'NoSQL databases are typically non-relational, though there are exceptions to
    this. From a development perspective, this implies that one of at least three
    approaches needs to be taken into consideration when dealing with application
    data that is stored and retrieved from a NoSQL data store:'
  prefs: []
  type: TYPE_NORMAL
- en: Never use data that relates to other data—assure that every record contains
    everything it needs as a single entity. The trade-off here is that it will be
    difficult, if not impossible, to account for situations where a record (or the
    object that the record is associated with) is shared by two or more other records/objects.
    An example of that might be a user group that multiple users are a member of.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deal with the relationships between records in the code that works with those
    records. Using the same users/groups concept just mentioned, that might involve
    a `Group` object, reading all the relevant `User` records and populating a `users`
    property with `User` objects from that data during instantiation. There might
    be some risk of concurrent changes interfering with each other, but not significantly
    more than the same sort of process would risk in a RDBMS-backed system. This approach
    also implies that data will be organized by object type—a distinct collection
    of `User` object data and a distinct collection of `Group` object data, perhaps—but
    any mechanism that allows the different object types to be differentiated will
    work.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pick a backend data store engine that provides some sort of relational support.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NoSQL databases are also less likely to support transactions, though again there
    are options that do provide full ACID-compliant transaction capabilities, and
    the criteria/options for dealing with transactional requirements at the data store
    level are very similar to those mentioned previously, that is, dealing with relational
    capabilities. Even those without any transaction support are still going to be
    ACID-compliant for single records—at that level of complexity, all that is required
    to be compliant is that the record is successfully stored.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and drawbacks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Given the high availability and concurrent user focus behind most NoSQL options,
    it should come as no great surprise that they are better suited than their RDBMS
    counterparts for applications where availability and the ability to scale is important.
    Those properties are even more important in big data applications, and applications
    that live in the cloud—as evidenced by the fact that the major cloud providers
    all have their own offerings in that space, as well as providing starting-points
    for some well-known NoSQL options:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon (AWS):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DynamoDB
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Google:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bigtable (for big data needs)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Datastore
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Microsoft (Azure):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cosmos DB (formerly DocumentDB)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Table Storage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ability to more or less arbitrarily define data structures can also be a
    significant advantage during development, since it eliminates the need for defining
    database schemas and tables. The trade-off for that, potentially, at least, is
    that since data structures can change just as arbitrarily, code that uses them
    has to be written to be tolerant of those structure changes, or some sort of conscious
    effort may have to be planned to apply the changes to existing data items without
    disrupting systems and their usage.
  prefs: []
  type: TYPE_NORMAL
- en: Consider, as an example, the `User` class mentioned earlier—if a `password_hash`
    property needs to be added to the class, in order to provide authentication/authorization
    support, the instantiation code will likely have to account for it, and any existing
    user-object records won't have the field already. On the code side, that may not
    be that big a deal—making `password_hash` an optional argument during initialization
    would take care of allowing the objects to be created, and storing it as a null
    value in the data if it hasn't been set would take care of the data storage side,
    but some sort of mechanism would need to be planned, designed, and implemented
    to prompt users to supply a password in order to store the real value. The same
    sort of process would have to occur if a similar change were made in an RDBMS-backed
    system, but the odds are good enough that there would be established processes
    for making changes to database schemas, and those would probably include both
    altering the schema and assuring that all records have a known starting value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given the number of options available, it should also not be surprising that
    there are differences (sometimes significant ones) between them with respect to
    performing similar tasks. That is, retrieving a record from the data, given nothing
    more than a unique identifier for the item to be retrieved (`id_value`), uses
    different libraries and syntax/structure based on the engine behind the data store:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In MongoDB (using a `connection` object):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`connection.find_one({''unique_id'':''id_value''})`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In Redis (using a `redis connection`):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`connection.get(''id_value'')`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In Cassandra (using a `query` value and a `criteria` list, executing against
    a Cassandra `session` object):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`session.execute(query, criteria)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's quite possible that each different engine will have its own distinct methods
    for performing the same tasks, though there may be some common names that emerge—there
    are only so many alternatives for function or method names, like get or find,
    that make sense, after all. If a system needs to be able to work with multiple
    different data store backend engines, those are good candidates for designing
    and implementing a common (probably abstract) data store adapter.
  prefs: []
  type: TYPE_NORMAL
- en: Since relational and transactional support varies from one engine to another,
    this inconsistency can be a drawback to a NoSQL-based data store as well, though
    there are at least some options that can be pursued if they are lacking.
  prefs: []
  type: TYPE_NORMAL
- en: MongoDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MongoDB is a free, open source, NoSQL document store engine—that is, it stores
    whole data structures as individual documents that are, if not JSON, very JSON-like.
    Data sent to and retrieved from a `MongoDB` database in Python uses Python-native
    data types (`dict` and `list` collections, any simple types such as `str` and
    `int`, and probably other standard types like `datetime` objects).
  prefs: []
  type: TYPE_NORMAL
- en: MongoDB was designed to be usable as a distributed database, supporting high
    availability, horizontal scaling, and geographic distribution out of the box.
  prefs: []
  type: TYPE_NORMAL
- en: Like most NoSQL data storage solutions, MongoDB is schema-less, allowing documents
    within a MongoDB collection (roughly equivalent to a table in an RDBMS) to have
    totally different structures.
  prefs: []
  type: TYPE_NORMAL
- en: Other NoSQL options
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are, as noted, dozens of NoSQL database options to pick and choose from.
    Three of the more popular options for locally installed NoSQL databases with Python
    drivers/support are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Redis**: A key/value store engine'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cassandra**: A wide-column store engine'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neo4j**: A graph database'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other data storage options
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another option—one that is probably not going to work well for large quantities
    of data, or under significant concurrent user-load—is simply to store application
    data locally as one to many files on the local machine. With the advent of simple
    structured data representation formats such as JSON, this can be a better option
    than it might seem at first glance, at least for certain needs: JSON, in particular,
    with its basic value-type support and the ability to represent arbitrarily complex
    or large data structures, is a reasonable storage format.'
  prefs: []
  type: TYPE_NORMAL
- en: The most significant impediment is making sure that data access has at least
    some degree of ACID compliance, though, as with NoSQL databases, if all transactions
    are single records, ACID compliance can still be counted on, for the same reason—the
    sheer simplicity of the transaction.
  prefs: []
  type: TYPE_NORMAL
- en: The other significant concern that would have to be addressed in using files
    to store application data is how the language or the underlying OS handles file
    locking. If either allows a file that's open for writing to be read while the
    write is in process or incomplete, it's just a matter of time until a read of
    an incomplete data file misreads the data available, then commits the bad data
    to the file, probably resulting in loss of data at a minimum, and perhaps breaking
    the entire data store in the process.
  prefs: []
  type: TYPE_NORMAL
- en: That would be bad, obviously.
  prefs: []
  type: TYPE_NORMAL
- en: Speed of access could be a concern as well, since file access is slower than
    access to and from data stored in memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'That said, there are strategies that can be applied to make a local file-based
    data store immune to that sort of failure, provided that the data is only accessed
    from a single source in the code. Addressing the potential access-speed concern
    can also be accomplished in the same process, which would resemble the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The program that uses data starts:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data is read into memory from a persistent file system data store
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The program is used, and a data-access occurs:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data is read from the copy in memory, and passed off to the user
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data is altered in some fashion:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The alteration is noted, and the change(s) is/are committed to the file system
    data store before returning control to the user
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The program is shut down:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before terminating, all data is checked to assure that no changes are still
    pending
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If there are changes, wait for them to complete
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If necessary, re-write all data to the file system data store
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selecting a data storage option
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Looking at the logical architecture for `hms_sys`, and allowing for a local
    data store for the **Artisan Application** that wasn''t in the original diagram,
    there are three databases that development needs to be concerned with:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/f7054630-6ba8-4568-b1a2-e938bd1bb3e3.png)'
  prefs: []
  type: TYPE_IMG
- en: The **Web-Store Database** is attached to the **Web-Store Application**, and
    cannot be modified as a result. The current expectation is that modifications
    to data in that database will be handled by a call to the API that the **Web-Store
    Application** makes available. At this point, then, data access to and from this
    database can be set aside.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `artisan` **Database**, on the other hand, doesn''t exist yet at all, and
    will have to be created as part of the development of `hms_sys`. It feels safe
    to assume, given the artisan-level, installation-related stories from the first
    iteration, that keeping the number of software installations they need to perform
    to the minimum possible is preferable. That, in turn, suggests that a local file
    system data store is probably going to be the preferred option at the **Artisan
    Application** level. That allows for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The data store is generated locally during the installation or initial setup
    of the application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Artisan**'s can manage their data locally, even if they are offline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data storage to be managed without any additional software installation on the
    part of the **Artisan**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since the **Artisan Application** is expected to be a local desktop application,
    this fits neatly into the set of processes noted previously for making a file-based
    data store safe and stable. There is some risk of data conflicts if the **Artisan**
    has more than one **Artisan** **Application** installed (one each on multiple
    machines, for example), but that risk would exist for any local data store option,
    realistically—short of moving the data store to a common online database, there
    really isn't a way to mitigate that particular concern, and that's outside the
    development scope for `hms_sys` at present.
  prefs: []
  type: TYPE_NORMAL
- en: The idea of centralizing data and applications alike will be examined in more
    detail later. For now, everything at the Artisan level will reside locally with
    the Artisan Application.
  prefs: []
  type: TYPE_NORMAL
- en: The `hms_sys` **Database** also doesn't exist at all yet. Unlike the `artisan`
    **Database**, though, it is intended to allow multiple concurrent users—any number
    of central office users might be reviewing or managing products at any given time
    as artisans are submitting product information to be reviewed, and orders relayed
    or pulled from the web store could be set in motion to the relevant artisans while
    those activities are going on, too. Taken together, these are sufficient to rule
    out the local file store approach—it might well still be doable, and might even
    be viable at current levels of usage, but could quickly run into scaling concerns
    if the usage/load grew too much.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given that, even if we don''t really know what backend engine will be in use,
    knowing that it won''t be the same storage mechanism that the **Artisan Application**
    uses confirms the idea noted earlier that we''d be well-served to define a common
    data access method set, generate some sort of abstraction around that structure,
    and define concrete implementations at each application- or service-object level.
    The advantages of taking that approach really boil down to variations of the same
    **Object-Oriented Design Principle** (**OODP**): polymorphism.'
  prefs: []
  type: TYPE_NORMAL
- en: Polymorphism (and programming to an interface)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Polymorphism**, in its simplest terms, is the ability for objects to be interchangeable
    in the code without breaking anything. In order to accomplish that, those objects
    must present common public interface members—the same accessible properties and
    methods—across the board. Ideally, those common interface members should be the
    only interface members as well, otherwise there is a risk of breaking the interchangeability
    of those objects. In a class-based structure, it''s usually a good idea to have
    that interface defined as an individual abstraction—an ABC in Python, with or
    without concrete members. Consider the following collection of classes for making
    connections to and querying against various relational database backends:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ce655e2f-48f4-4520-82d8-e47db56b42eb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Where:'
  prefs: []
  type: TYPE_NORMAL
- en: '`BaseDatabaseConnector` is an abstract class that requires a query method to
    be implemented by all derived classes, and provides `host`, `database`, `user`,
    and `password` properties that will be used to actually connect to a given database'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The concrete classes, `MySQLConnector`, `MSSQLConnector`, and `ODBCConnector`,
    each implement the required `query` method, allowing instances to actually execute
    queries against the database that the instance is connected to
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provided that the connection properties (`host`, …, `password`) were stored
    in a configuration file (or anywhere outside the actual code itself, really),
    along with some way to specify which connector type to use, it wouldn't be difficult
    to allow those different connection types to be defined at runtime, or maybe even
    switched out during execution.
  prefs: []
  type: TYPE_NORMAL
- en: This interchangeability, in turn, allows code to be written that doesn't need
    to know anything about how a process works, just how it should be called, and
    what it's expected to return as a result. This is a practical illustration of
    the idea of programming to an interface, not to an implementation, which was mentioned
    in [Chapter 5](https://cdp.packtpub.com/hands_on_software_engineering_with_python/wp-admin/post.php?post=29&action=edit), *The
    hms_sys System Project,* as well as the concept of encapsulating what varies.
    The two often go hand-in-hand, as they do in this case.
  prefs: []
  type: TYPE_NORMAL
- en: There is another benefit to the ability to replace objects in this fashion,
    which might be called future-proofing a code base. If, at some time in the future,
    the code that uses the data connectors shown previously were suddenly in need
    of being able to connect to and use a database engine that wasn't available already,
    the level of effort to make it available would be relatively small, provided that
    it used the same connection arguments and a similar connection process as the
    ones that were already in place. All that would need to be done, for example,
    to create a `PostgreSQLConnector` (used to connect to a `PostgreSQL` database),
    would be to create the class, derive it from `BaseDatabaseConnector`, and implement
    the required `query` method. It would still require some development effort, but
    not as much as would probably be needed if each database connection process had
    its own distinct classes to contend with.
  prefs: []
  type: TYPE_NORMAL
- en: Data access design strategies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The last bit of analysis that we need to undertake before we can start writing
    out the stories for this iteration involves determining where the responsibility
    for object data access is going to live. In a script or another purely procedural
    context, it would probably suffice to simply connect to a data source, read the
    data from it as needed, modify it as needed, and write any changes back out again,
    but that would only be viable because the entire procedure would be relatively
    static.
  prefs: []
  type: TYPE_NORMAL
- en: In an application or service such as `hms_sys`, data use is very much a random-access
    scenario—there may be common procedures that might even look a lot like a simple
    script's step-by-step implementations, but those processes could (and will) be
    initiated in a fashion that may be totally unpredictable.
  prefs: []
  type: TYPE_NORMAL
- en: That, then, means that we need to have data access processes that are easily
    called and repeatable with minimal effort. Given that we already know that at
    least two different data storage mechanisms will be in play, it would also make
    future support and development a lot easier if we could design these processes
    so that the exact same method calls could be used, no matter what the underlying
    data store looks like—again, abstracting the processes, and allowing code to use
    interfaces, not implementations.
  prefs: []
  type: TYPE_NORMAL
- en: One option that would accomplish this sort of abstraction starts at the data
    source, making each data source aware of the object-types that are in play, and
    storing the information that it needs to be able to perform CRUD operations for
    each object-type somewhere. That's technically a workable implementation, but
    it will get very complicated very quickly, because each combination of data store
    and business object type needs to be accounted for and maintained. Even if the
    initial class set is limited to three data store variants (the file system data
    store of the **Artisan Application**, a generic RDBMS data store, and a generic
    NoSQL data store), that's four operations (CRUD) across three data store types
    for four business objects, for a total of 48 permutations (4 × 3 × 4) that have
    to be built, tested, and maintained. Each new operation added into the mix, such
    as, say, the ability to search a business object data store, as well as each new
    business object type to be persisted and each new data store type, increases that
    permutation count multiplicatively—adding one of each increases the count to 75
    items (5 × 3 × 5) that have to be dealt with—which could easily get out of control.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we take a step back and think about what we actually need for all of those
    combinations, a different and more manageable solution is possible. For each and
    every business object that needs to be persisted, we need to be able to do the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a record for a new object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Read a record for a single object, identified somehow, and return an instance
    for that item.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the record for a single object after changes have been made to it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Delete the record for a single object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find and return zero-to-many objects based on matches to some criteria.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It might also be useful to be able to flag objects as being in specific states—active
    versus inactive, and deleted (without actually deleting the underlying record),
    perhaps. Tracking created and/or updated dates/times is also a common practice—it's
    sometimes useful for sorting purposes, if nothing else.
  prefs: []
  type: TYPE_NORMAL
- en: 'All of the CRUD operations relate directly to the object type itself—that is,
    we need to be able to create, read, update, delete, and find `Artisan` objects
    in order to work with them. The various object properties of those instances can
    be retrieved and populated as needed in the context of the instance''s creation,
    created as part of the instance''s creation process, or updated with the owning
    instance or individually as needed. With those subordinate actions in mind, keeping
    track of whether an object''s record needs to be created or updated will probably
    be useful as well. Finally, we''ll need to keep track of some unique identifier
    for each object''s state data record in the data store. Putting all of those together,
    the following is what a `BaseDataObject` ABC might look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/27441a06-1d8a-4271-a12f-d043113f975b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The properties are all concrete, with implementations baked in at the `BaseDataObject`
    level:'
  prefs: []
  type: TYPE_NORMAL
- en: '`oid` is the unique identifier of the object, and is a `UUID` value that will
    be stored as, and converted from, a string during data access.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`created` and `modified` are Python `datetime` objects, and may also need to
    be converted to and from string-value representations during data access.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_active` is a flag that indicates whether or not a given record should be
    considered active, which allows for some management of active/inactive state for
    records and thus for objects that those records represent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_deleted` is a similar flag, indicating whether the record/object should
    be considered as deleted, even if it really still exists in the database.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_dirty` and `is_new` are flags that keep track of whether an object''s corresponding
    record needs to be updated (because it''s been changed) or created (because it''s
    new), respectively. They are local properties, and will not be stored in a database.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a `UUID` instead of a numeric sequence requires a bit more work, but has
    some security advantages, especially in web application and service implementations—`UUID`
    values are not easily predictable, and have 16^(32) possible values, making automated
    exploits against them much more time-consuming.There may be requirements (or at
    least a desire) to not really delete records, ever. It's not unusual in certain
    industries, or for publicly traded companies who are required to meet certain
    data-audit criteria, to want to keep all data, at least for some period of time.
  prefs: []
  type: TYPE_NORMAL
- en: '`BaseDataObject` defines two concrete and three abstract instance methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`create` (abstract and protected) will require derived classes to implement
    a process for creating and writing a state data record to the relevant database.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`matches` (concrete) will return a Boolean value if the property values of
    the instance that it''s called from match the corresponding values of the criteria
    passed to it. This will be instrumental in implementing criteria-based filtering
    in the get method, which will be discussed shortly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`save` (concrete) will check the instance''s `is_dirty` flag, calling the instance''s
    `update` method and exiting if it''s `True`, then check the `is_new` flag, calling
    the instance''s `create` method if it is `True`. The net result of this is that
    any object deriving from `BaseDataObject` can simply be told to `save` itself,
    and the appropriate action will be taken, even if it''s no action.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`to_data_dict` (abstract) will return a `dict` representation of the object''s
    state data, with values in formats and of types that can be written to the database
    that state data records live in.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`update` (abstract and protected) is the update implementation counterpart
    to the `create` method, and is used to update an existing state data record for
    an object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BaseDataObject` also defines four class methods, all of which are abstract—each
    of these methods, then, is bound to the *class* itself, not to instances of the
    class, and must be implemented by other classes that derive from `BaseDataObject`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`delete` performs a physical record deletion for each record identified by
    the provided `*oids`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`from_data_dict` returns an instance of the class, populated with the state
    data in the `data_dict` provided, which will usually result from a query against
    the database that those records live in. It''s the counterpart of the `to_data_dict`
    method, which we already described.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`get` is the primary mechanism for returning objects with state data retrieved
    from the database. It''s been defined to allow both specific records (the `*oids`
    argument list) and filtering criteria (in the `**criteria` keyword arguments,
    which is expected to be the criteria argument passed to matches for each object),
    and will return an unsorted list of object instances according to those values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sort` accepts a list of objects and sorts them using a callback function or
    method passed in `sort_by`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BaseDataObject` captures all of the functional requirements and common properties
    that would need to be present in order to let the business object classes and
    instances take responsibility for their data storage interactions. Setting aside
    any database engine concerns for the moment, defining a data persistence-capable
    business object class such as an `Artisan` in the **Artisan Application** becomes
    very simple—the final, concrete `Artisan` class just needs to inherit from `BaseArtisan`
    and `BaseDataObject`, as follows, and then implement the nine required abstract
    methods that are required by those parent classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/3df11c98-040d-47f9-b173-7dd6316a8127.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This approach would suffice if it could be safely assumed that any given application
    or service instance will always use the same data store backend for each business
    object type. Any engine-specific needs or capabilities could simply be added to
    each final concrete class. It would also be possible, though, to collect any properties
    needed by specific data store engines (MongoDB and MySQL, for example) into an
    additional layer of abstraction, then have the final concrete objects derive from
    one of those instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/cf623f73-1b8e-4027-b16d-50774d8ca167.png)'
  prefs: []
  type: TYPE_IMG
- en: In this scenario, the final `Artisan` class could derive from either `MongoDataObject`
    or `MySQLDataObject`, and those could enforce the provision of any data required
    to execute the data access methods against those specific backend engines. Those
    middle-layer ABCs might also provide some helper methods for tasks that are relevant
    for each engine type—taking the template SQL in the `create_sql` class attribute,
    for example, and populating it with instance data values from `to_data_dict()`
    results in being able to create the final SQL for a MySQL call to create an instance.
    This approach would keep most of the data access information needed by any given
    business object class in that class, and associated with the business object itself,
    which doesn't feel like a bad idea, though it has the potential to get complex
    if a lot of combinations need to be supported. It would also keep the level of
    effort involved in adding adding new functionality to all data objects (at the
    `BaseDataObject` level of the class tree) more manageable—the addition of new
    abstract functionality would still require implementation in all derived concrete
    classes, but any concrete changes would simply be inherited and immediately available.
  prefs: []
  type: TYPE_NORMAL
- en: Data access decisions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With all of these factors in mind, then, it's time to make some decisions about
    how the various component projects' objects will deal with keeping track of their
    data. In the interests of having a single interface around all object data access,
    we'll implement the `BaseDataObject` ABC described previously, or something very
    similar to it, and derive our final data-persisting concrete classes from a combination
    of that ABC and the relevant business object class built in the previous iteration.
    Finally what we'll end up with are classes for what we'll call data objects, which
    are capable of reading and writing their own data.
  prefs: []
  type: TYPE_NORMAL
- en: In the **Artisan Application**, since we don't need to worry about concurrent
    users interacting with the data at the same time, and since we don't want to burden
    an **Artisan** user with additional software installations unless there's no better
    alternative, we'll construct a data persistence mechanism by using local files
    to store object data.
  prefs: []
  type: TYPE_NORMAL
- en: In the code that will be running in a Central Office context, we will have concurrent
    users, at least potentially, so data storage will need to be centralized in a
    dedicated database system. There's no discernible need for a formal, database
    resident schema (though having one wouldn't be a bad thing), so using a NoSQL
    option should allow shorter development time, and allow some flexibility in case
    data structures need to change unexpectedly. We'll reexamine those options in
    more detail when we get to that portion of the development effort.
  prefs: []
  type: TYPE_NORMAL
- en: Why start from scratch?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This functional structure is going to be built from the ground up, but there
    are other options that might work as well, or even better in other contexts. There
    are, for example, several **Object Relational Mapper** (**ORM**) packages/libraries
    available that would allow the definition of databases and structure to be defined
    in code and propagated out to a data store, some of which are integrated into
    full application frameworks. These include Django's `models` module, which is
    part of the overall Django web application framework, a common and popular option
    for developing web applications. Other variants include SQLAlchemy, providing
    an abstraction layer over SQL operations and an ORM to work with an object's data.
  prefs: []
  type: TYPE_NORMAL
- en: There are also specific driver libraries for several database options (SQL and
    NoSQL both), some of which may provide ORM functionality, but all of which provide
    at least the basic capability to connect to a data source and execute queries
    or perform operations against those data sources. It's quite possible to write
    code that simply executes SQL against an RDBMS such as MySQL or MariaDB, or executes
    functions that correspond to that SQL against a NoSQL engine like MongoDB or even
    cloud-resident data stores such as Amazon's DynamoDB. For simple applications,
    that may actually be a better approach, at least initially. It would keep the
    development time down, since the various abstraction layers that we've explored
    so far simply wouldn't be in the picture at all, and the code itself would have
    a certain type of simplicity, since all it would need to do is execute basic CRUD
    operations, and maybe not even all of those.
  prefs: []
  type: TYPE_NORMAL
- en: The data objects structure that is being developed for `hms_sys` will expose
    a lot of the underlying principles that go into the design of a data access framework,
    and that's part of the reason that the from-the-ground-up approach it entails
    was selected. Another reason is that, because it will live somewhere between a
    full-on ORM approach and the a low-level "execute a query against a connection"
    implementation strategy, it will show a lot of the relevant aspects of both of those
    approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a lot of options available for data access mechanisms and processes,
    and while there will occasionally be requirements in play that more or less mandate
    one of them over the others, there may not be a single right approach across all
    development efforts. In particular, if time is of the essence, looking for an
    off-the-shelf solution is probably a good place to start, but if requirements
    or other constraints don't allow for one of those to be easily applied, creating
    a custom solution is not out of the question either.
  prefs: []
  type: TYPE_NORMAL
- en: The logical starting point, before getting into the weeds with specific data
    storage mechanisms, is probably to define the abstraction layer over the collective
    data access needs— that is, defining the `BaseDataObject` ABC—so that's what we'll
    tackle next.
  prefs: []
  type: TYPE_NORMAL
