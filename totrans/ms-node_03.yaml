- en: Streaming Data Across Nodes and Clients
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '"A jug fills drop by drop."'
  prefs: []
  type: TYPE_NORMAL
- en: – Buddha
  prefs: []
  type: TYPE_NORMAL
- en: We now have a clearer picture of how the evented, I/O-focused design ethic of
    Node is reflected across its various module APIs, delivering a consistent and
    predictable environment for development.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will discover how data, pulled from files or other sources,
    can be read, written, and manipulated just as easily using Node. Ultimately, we
    will learn how to use Node to develop networked servers with rapid I/O interfaces
    that support highly concurrent applications, sharing real-time data across thousands
    of clients, simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: Why use streams?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Presented with a fancy new language feature, design pattern, or software module,
    a novice developer may begin using it because it is new and fancy. An experienced
    developer, on the other hand, might ask, *why is this required?*
  prefs: []
  type: TYPE_NORMAL
- en: 'Streams are required because files are big. A few simple examples can demonstrate
    their necessity. To begin, let''s say we want to copy a file. In Node, a naive
    implementation looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: It's very straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: The call to `readFileSync()` blocks while Node copies the contents of `source.bin`,
    a file in the same folder as the script, into memory, returning a `ByteBuffer`
    here named `block`.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have `block`, we can check and print out its size. Then, the code hands
    `block` to `writeFileSync`, which copies the memory block to the contents of a
    newly made or overwritten file, `destination.bin`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This code assumes the following things:'
  prefs: []
  type: TYPE_NORMAL
- en: It's OK to block the event loop (it's not!)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can read the whole file into memory (we can't!)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you will recall from the previous chapter, Node processes one event after
    another, a single event at a time. Good asynchronous design allows a Node program
    to appear to be doing all sorts of things simultaneously, both to connected software
    systems and human users alike, while simultaneously offering developers in the
    code a straightforward presentation of logic that's easy to reason about and resistant
    to bugs. This is true, especially when compared to multithreaded code that might
    be written to solve the same task. Your team may have even turned to Node to make
    an improved replacement to such a classically multithreaded system. Also, good
    asynchronous design never blocks the event loop.
  prefs: []
  type: TYPE_NORMAL
- en: Blocking the event loop is bad because Node can't do anything else, while your
    one blocking line of code is blocking. The example prior, written as a rudimentary
    script that copies a file from one place to another, might work just fine. It
    would block the terminal of the user while Node copies the file. The file might
    be small enough that there's little time to wait. If not, you could open another
    shell prompt while you're waiting. In this way, it's really no different from
    familiar commands like `cp` or `curl`.
  prefs: []
  type: TYPE_NORMAL
- en: From the computer's perspective, this is quite inefficient, however. Each file
    copy shouldn't require its own operating system process.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, incorporating the previous code into a larger Node project could
    destabilize the system as a whole.
  prefs: []
  type: TYPE_NORMAL
- en: Your server-side Node app might be simultaneously letting three users log in,
    while sending large files to another two. If that app executes the previous code
    as well, two downloads will stick, and three browser throbbers will spin.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let''s try to fix this, one step at a time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: At least now we're not using Node methods that have *Sync* in their titles.
    The event loop can breathe freely again.
  prefs: []
  type: TYPE_NORMAL
- en: 'But still:'
  prefs: []
  type: TYPE_NORMAL
- en: How about big files? (Big explosions)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That's quite a pyramid you've got there (of doom)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Try the code prior with a 2 GB (2.0 x 2^30, or 2,147,483,648 byte) source file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: If you're watching a video on YouTube at 1080p, 2 GB will last you about an
    hour. The previous `RangeError` happens because `2,147,483,647` is `1111111111111111111111111111111`
    in binary, the largest 32-bit signed binary integer. Node uses that type internally
    to size and address the contents of a `ByteBuffer`.
  prefs: []
  type: TYPE_NORMAL
- en: 'What happens if you hand our poor example? Smaller, but still very large, files
    are less deterministic. When it works, it does because Node successfully gets
    the required amount of memory from the operating system. The memory footprint
    of the Node process grows by the file size during the copy operation. Mice may
    turn to hourglasses, and fans may noisily spin up. Would promises help?:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: No, essentially. We've flattened the pyramid, but the size limitation and memory
    issues remain in force.
  prefs: []
  type: TYPE_NORMAL
- en: What we really need is some code that is both asynchronous, and also *piece
    by piece*, grabbing a little part of the source file, shuttling it over to the
    destination file for writing, and repeating that cycle until we're done, like
    a bucket brigade from antique fire fighting.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0e4e9db3-d056-41d5-a94f-5edb81573357.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Such a design would let the event loop breathe freely the entire time.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is exactly what streams are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In practice, scaled network applications are typically spread across many instances,
    requiring that the processing of data streams be distributed across many processes
    and servers. Here, a streaming file is simply a stream of data partitioned into
    slices, where each slice can be viewed independently irrespective of the availability
    of others. You can write to a data stream, or listen on a data stream, free to
    dynamically allocate bytes, to ignore bytes, to reroute bytes. Streams of data
    can be chunked, many processes can share chunk handling, chunks can be transformed
    and reinserted, and data flows can be precisely emitted and creatively managed.
  prefs: []
  type: TYPE_NORMAL
- en: Recalling our discussion on modern software and the Rule of Modularity, we can
    see how streams facilitate the creation of independent share-nothing processes
    that do one task well, and in combination, can compose a predictable architecture
    whose complexity does not preclude an accurate appraisal of its behavior. If the
    interfaces to data are uncontroversial, the data map can be accurately modeled,
    independent of considerations about data volume or routing.
  prefs: []
  type: TYPE_NORMAL
- en: Managing I/O in Node involves managing data events bound to data streams. A
    Node Stream object is an instance of `EventEmitter`. This abstract interface is
    implemented in numerous Node modules and objects, as we saw in the previous chapter.
    Let's begin by understanding Node's Stream module, then move on to a discussion
    of how network I/O in Node is handled via various Stream implementations; in particular,
    the HTTP module.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'According to Bjarne Stoustrup in his book, *The C++ Programming Language*,
    (third edition):'
  prefs: []
  type: TYPE_NORMAL
- en: '"Designing and implementing a general input/output facility for a programming
    language is notoriously difficult... An I/O facility should be easy, convenient,
    and safe to use; efficient and flexible; and, above all, complete."'
  prefs: []
  type: TYPE_NORMAL
- en: It shouldn't surprise anyone that a design team, focused on providing efficient
    and easy I/O, has delivered such a facility through Node. Through a symmetrical
    and simple interface, which handles data buffers and stream events so that the
    implementer does not have to, Node's Stream module is the preferred way to manage
    asynchronous data streams for both internal modules, and the module's developers
    will create.
  prefs: []
  type: TYPE_NORMAL
- en: 'A stream in Node is simply a sequence of bytes. At any time, a stream contains
    a buffer of bytes, and this buffer has a zero or greater length:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2723e2fe-cae1-4f74-ba59-fa5f464f0c2c.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As each character in a stream is well-defined, and because every type of digital
    data can be expressed in bytes, any part of a stream can be redirected, or *piped*,
    to any other stream, different chunks of the stream can be sent to different handlers,
    and so on. In this way, stream input and output interfaces are both flexible and
    predictable, and can be easily coupled.
  prefs: []
  type: TYPE_NORMAL
- en: 'Node also offers a second type of streams: object streams. Instead of chunks
    of memory flowing through the stream, an object stream shuttles JavaScript objects.
    Byte streams pass around serialized data like streaming media, while object streams
    are the right choice for parsed, structured data like JSON records.'
  prefs: []
  type: TYPE_NORMAL
- en: Digital streams are well described using the analogy of fluids, where individual
    bytes (drops of water) are being pushed through a pipe. In Node, streams are objects
    representing data flows that can be written to and read from asynchronously.
  prefs: []
  type: TYPE_NORMAL
- en: The Node philosophy is a non-blocking flow, I/O is handled via streams, and
    so the design of the Stream API naturally duplicates this general philosophy.
    In fact, there is no other way of interacting with streams except in an asynchronous,
    evented manner—Node prevents developers, by design, from blocking I/O.
  prefs: []
  type: TYPE_NORMAL
- en: 'Five distinct base classes are exposed via the abstract Stream interface: **Readable**,
    **Writable**, **Duplex**, **Transform**, and **PassThrough**. Each base class
    inherits from `EventEmitter`, which we know of as an interface to which event
    listeners and emitters can be bound.'
  prefs: []
  type: TYPE_NORMAL
- en: As we will learn, and here will emphasize, the Stream interface is an abstract
    interface. An abstract interface functions as a kind of blueprint or definition,
    describing the features that must be built into each constructed instance of a
    Stream object. For example, a Readable stream implementation is required to implement
    a `public read` method which delegates to the interface's `internal _read` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, all stream implementations should follow these guidelines:'
  prefs: []
  type: TYPE_NORMAL
- en: As long as data exists to send, write to a stream until that operation returns
    `false`, at which point the implementation should wait for a drain event, indicating
    that the buffered stream data has emptied.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continue to call read until a `null` value is received, at which point wait
    for a readable event prior to resuming reads.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Several Node I/O modules are implemented as streams. Network sockets, file readers
    and writers, `stdin` and `stdout`, zlib, and so on are all streams. Similarly,
    when implementing a readable data source, or data reader, one should implement
    that interface as a Stream interface.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is important to note that over the history of Node, the Stream interface
    changed in some fundamental ways. The Node team has done its best to implement
    compatible interfaces, so that (most) older programs will continue to function
    without modification. In this chapter, we will not spend any time discussing the
    specific features of this older API, focusing on the current design. The reader
    is encouraged to consult Node's online documentation for information on migrating
    older programs. As often happens, there are modules that *wrap* streams with convenient,
    reliable interfaces. A good one is: [https://github.com/rvagg/through2.](https://github.com/rvagg/through2)
  prefs: []
  type: TYPE_NORMAL
- en: Implementing readable streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Streams producing data that another process may have an interest in are normally
    implemented using a `Readable` stream. A `Readable` stream saves the implementer
    all the work of managing the read queue, handling the emitting of data events,
    and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a `Readable` stream, use this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'As previously mentioned, `Readable` is exposed as a base class, which can be
    initialized through three options:'
  prefs: []
  type: TYPE_NORMAL
- en: '`encoding`: Decode buffers into the specified encoding, defaulting to UTF-8.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`highWaterMark`: Number of bytes to keep in the internal buffer before ceasing
    to read from the data source. The default is 16 KB.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`objectMode`: Tell the stream to behave as a stream of objects instead of a
    stream of bytes, such as a stream of JSON objects instead of the bytes in a file.
    Default `false`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the following example, we create a mock `Feed` object whose instances will
    inherit the `Readable` stream interface. Our implementation need only implement
    the abstract `_read` method of `Readable`, which will push data to a consumer
    until there is nothing more to push, at which point it triggers the `Readable`
    stream to emit an `end` event by pushing a `null` value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have an implementation, a consumer might want to instantiate the
    stream and listen for stream events. Two key events are `readable` and `end`.
  prefs: []
  type: TYPE_NORMAL
- en: The `readable` event is emitted as long as data is being pushed to the stream.
    It alerts the consumer to check for new data via the `read` method of `Readable`.
  prefs: []
  type: TYPE_NORMAL
- en: Note again how the `Readable` implementation must provide a `private _read`
    method that services the `public read` method exposed to the consumer API.
  prefs: []
  type: TYPE_NORMAL
- en: The `end` event will be emitted whenever a `null` value is passed to the `push`
    method of our `Readable` implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we see a consumer using these methods to display new stream data, providing
    a notification when the stream has stopped sending data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, we can implement a stream of objects through the use of the `objectMode`
    option:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Having been placed in objectMode, each chunk pushed is expected to be an object.
    The reader for this stream can then work on the assumption that each `read()`
    event will produce a single object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Here, we see that each read event is receiving an object, rather than a buffer
    or string.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the `read` method of a `Readable` stream can be passed a single argument,
    indicating the number of bytes to be read from the stream''s internal buffer.
    For example, if it was desired that a file should be read one byte at a time,
    one might implement a consumer using a routine similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that we''re pushing the entirety of news into the stream, and terminating
    with null. The stream is primed with the entire string of bytes. Now the consumer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Here, it should be clear that the `Readable` stream's buffer was filled with
    a number of bytes all at once, but was read from discretely.
  prefs: []
  type: TYPE_NORMAL
- en: Pushing and pulling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have seen how a `Readable` implementation will use `push` to populate the
    stream buffer for reading. When designing these implementations, it is important
    to consider how volume is managed, at either end of the stream. Pushing more data
    into a stream than can be read can lead to complications around exceeding available
    space (memory). At the consumer end, it is important to maintain awareness of
    termination events, and how to deal with pauses in the data stream.
  prefs: []
  type: TYPE_NORMAL
- en: We might compare the behavior of data streams running through a network with
    that of water running through a hose.
  prefs: []
  type: TYPE_NORMAL
- en: As with water through a hose, if a greater volume of data is being pushed into
    the read stream than can be efficiently drained out of the stream at the consumer
    end through `read`, a great deal of back pressure builds, causing a data backlog
    to begin accumulating in the stream object's buffer. Because we are dealing with
    strict mathematical limitations, `read` simply cannot be compelled to release
    this pressure by reading more quickly—there may be a hard limit on available memory
    space, or other limitations. As such, memory usage can grow dangerously high,
    buffers can overflow, and so forth.
  prefs: []
  type: TYPE_NORMAL
- en: A stream implementation should therefore be aware of, and respond to, the response
    from a `push` operation. If the operation returns `false`  , this indicates that
    the implementation should cease reading from its source (and cease pushing) until
    the next `_read` request is made.
  prefs: []
  type: TYPE_NORMAL
- en: In conjunction with the above, if there is no more data to push but more is
    expected in the future, the implementation should `push` an empty string `("")`,
    which adds no data to the queue but does ensure a future `readable` event.
  prefs: []
  type: TYPE_NORMAL
- en: While the most common treatment of a stream buffer is to `push` to it (queuing
    data in a line), there are occasions where you might want to place data on the
    front of the buffer (jumping the line). Node provides an `unshift` operation for
    these cases, whose behavior is identical to push, outside of the aforementioned
    difference in buffer placement.
  prefs: []
  type: TYPE_NORMAL
- en: Writable streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A `Writable` stream is responsible for accepting some value (a stream of bytes,
    a string) and writing that data to a destination. Streaming data into a file container
    is a common use case.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a `Writable` stream:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Writable` streams constructor can be instantiated with two options:'
  prefs: []
  type: TYPE_NORMAL
- en: '`highWaterMark`: The maximum number of bytes the stream''s buffer will accept
    prior to returning `false` on writes. Default is 16 KB.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decodeStrings`: Whether to convert strings into buffers before writing. Default
    is `true`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As with `Readable` streams, custom `Writable` stream implementations must implement
    a `_write` handler, which will be passed the arguments sent to the `write` method
    of instances.
  prefs: []
  type: TYPE_NORMAL
- en: 'One should think of a `Writable` stream as a data target, such as for a file
    you are uploading. Conceptually, this is not unlike the implementation of push
    in a `Readable` stream, where one pushes data until the data source is exhausted,
    passing `null` to terminate reading. For example, here, we write 32 "A" characters
    to a stream, which will log them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: There are two key things to note here.
  prefs: []
  type: TYPE_NORMAL
- en: First, our `_write` implementation fires the `callback` function immediately
    after writing a callback that is always present, regardless of whether the instance
    `write` method is passed a `callback` directly. This call is important for indicating
    the status of the write attempt, whether a failure (error) or a success.
  prefs: []
  type: TYPE_NORMAL
- en: Second, the call to write returned `true`. This indicates that the internal
    buffer of the `Writable` implementation has been emptied after executing the requested
    write. What if we sent a very large amount of data, enough to exceed the default
    size of the internal buffer?
  prefs: []
  type: TYPE_NORMAL
- en: 'Modifying the previous example, the following would return `false`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The reason this `write` returns `false` is that it has reached the `highWaterMark`
    option—default value of 16 KB (16 * 1,024). If we changed this value to `16383`,
    `write` would again return `true` (or one could simply increase its value).
  prefs: []
  type: TYPE_NORMAL
- en: 'What should you do when `write` returns `false`? You should certainly not continue
    to send data! Returning to our metaphor of water in a hose: when the stream is
    full, one should wait for it to drain prior to sending more data. Node''s Stream
    implementation will emit a `drain` event whenever it is safe to write again. When
    `write` returns `false` , listen for the `drain` event before sending more data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Putting together what we have learned, let''s create a `Writable` stream with
    a `highWaterMark` value of 10 bytes. We''ll then set up a simulation where we
    push the a string of data to `stdout` larger than the `highWaterMark` some number
    of times. We catch buffer overflows and wait for the drain event to fire prior
    to sending more data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Each time we right we check if the stream write action returned false, and if
    so we wait for the next drain event before running our `write` method again.
  prefs: []
  type: TYPE_NORMAL
- en: You should be careful to implement proper stream management, respecting the
    "warnings" emitted by write events, and properly waiting for the drain event to
    occur prior to sending more data.
  prefs: []
  type: TYPE_NORMAL
- en: The fluid data in a `Readable` stream can be easily redirected to a `Writable`
    stream. For example, the following code will take any data sent by a terminal
    (`stdin` is a `Readable` stream) and echo it back to the destination `Writable`
    stream (`stdout`): `process.stdin.pipe(process.stdout)`. Whenever a `Writable`
    stream is passed to a `Readable` stream's pipe method, a **pipe** event will fire.
    Similarly, when a `Writable` stream is removed as a destination for a `Readable`
    stream, the **unpipe** event fires. To remove a `pipe`, use the following: `unpipe(destination
    stream)`
  prefs: []
  type: TYPE_NORMAL
- en: Duplex streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A **duplex stream** is both readable and writeable. For instance, a TCP server
    created in Node exposes a socket that can be both read from, and written to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'When executed, this code will create a TCP server that can be connected to
    via Telnet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Start the server in one terminal window, open a separate terminal, and connect
    to the server via telnet. Upon connection, the connecting terminal will print
    out `Go ahead and type something!`—writing to the socket. Any text entered in
    the connecting terminal (after hitting **ENTER**) will be echoed to the `stdout`
    of the terminal running the TCP server (reading from the socket), creating a sort
    of chat application.
  prefs: []
  type: TYPE_NORMAL
- en: This implementation of a bidirectional (duplex) communication protocol demonstrates
    clearly how independent processes can form the nodes of a complex and responsive
    application, whether communicating across a network or within the scope of a single
    process.
  prefs: []
  type: TYPE_NORMAL
- en: The options sent when constructing a `Duplex` instance merge those sent to `Readable`
    and `Writable` streams, with no additional parameters. Indeed, this stream type
    simply assumes both roles, and the rules for interacting with it follow the rules
    for the interactive mode being used.
  prefs: []
  type: TYPE_NORMAL
- en: As a `Duplex` stream assumes both read and write roles, any implementation is
    required to implement both `­_write` and `_read` methods, again following the
    standard implementation details given for the relevant stream type.
  prefs: []
  type: TYPE_NORMAL
- en: Transforming streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: On occasion, stream data needs to be processed, often in cases where one is
    writing some sort of binary protocol or other *on the fly* data transformation.
    A `Transform` stream is designed for this purpose, functioning as a `Duplex` stream
    that sits between a `Readable` stream and a `Writable` stream.
  prefs: []
  type: TYPE_NORMAL
- en: A `Transform` stream is initialized using the same options used to initialize
    a typical `Duplex` stream, where `Transform` differs from a normal `Duplex` stream
    is in its requirement that the custom implementation merely provides a `_transform`
    method, excluding the `_write` and `_read` method requirement.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `_transform` method will receive three arguments, first the sent buffer,
    an optional encoding argument, and finally a callback which `_transform` is expected
    to call when the transformation is complete:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s imagine a program that helps to convert **ASCII (American Standard Code
    for Information Interchange)** codes into ASCII characters, receiving input from
    `stdin`. You type in an ASCII code, and the program responds with the alphanumeric
    character corresponding to that code. Here we can simply pipe our input to a `Transform`
    stream, then pipe its output back to `stdout`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Interacting with this program might produce an output resembling the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: A more involved example of a transform stream will be demonstrated in the example
    that ends this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Using PassThrough streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This sort of stream is a trivial implementation of a `Transform` stream, which
    simply passes received input bytes through to an output stream. This is useful
    if one doesn't require any transformation of the input data, and simply wants
    to easily pipe a `Readable` stream to a `Writable` stream.
  prefs: []
  type: TYPE_NORMAL
- en: '`PassThrough` streams have benefits similar to JavaScript''s anonymous functions,
    making it easy to assert minimal functionality without too much fuss. For example,
    it is not necessary to implement an abstract base class, as one does with for
    the `_read` method of a `Readable` stream. Consider the following use of a `PassThrough`
    stream as an event spy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Normally a Transform or Duplex stream is what you want (where you can set up
    a proper implementation of `_read` and `_write`), but in certain scenarios, such
    as tests, it can be useful to place "watchers" on a stream.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an HTTP server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'HTTP is a stateless data transfer protocol built upon a request/response model:
    clients make requests to servers, which then return a response. As facilitating
    this sort of rapid-pattern network communication is the sort of I/O Node was designed
    to excel at, Node gained early widespread attention as a toolkit for creating
    servers—though it can certainly be used to do much, much more. Throughout this
    book, we will be creating many implementations of HTTP servers, as well as other
    protocol servers, and will be discussing best practices in more depth, contextualized
    within specific business cases. It is expected that you have already had some
    experience doing the same. For both of these reasons, we will quickly move through
    a general overview into some more specialized uses.'
  prefs: []
  type: TYPE_NORMAL
- en: 'At its simplest, an HTTP server responds to connection attempts, and manages
    data as it arrives and as it is sent along. A Node server is typically created
    using the `createServer` method of the `http` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The object returned by `http.createServer` is an instance of `http.Server`,
    which extends `EventEmitter`, broadcasting network events as they occur, such
    as a client connection or request. The code prior is a common way to write Node
    servers. However, it is worth pointing out that directly instantiating the `http.Server`
    class is sometimes a useful way to distinguish distinct server/client interactions.
    We will use that format for the following examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we create a basic server that simply reports when a connection is made,
    and when it is terminated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: When building multiuser systems, especially authenticated multiuser systems,
    this point in the server-client transaction is an excellent place for client validation
    and tracking code, including setting or reading of cookies and other session variables,
    or the broadcasting of a client arrival event to other clients working together
    in a concurrent real-time application.
  prefs: []
  type: TYPE_NORMAL
- en: 'By adding a listener for requests, we arrive at the more common request/response
    pattern, handled as a `Readable` stream. When a client POSTs some data, we can
    catch that data like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Try sending some data to this server using **curl**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: By using connection events, we can nicely separate our connection handling code,
    grouping it into clearly defined functional domains correctly described as executing
    in response to particular events. In the example above we saw how to set a timer
    that kicks server connections after two seconds.
  prefs: []
  type: TYPE_NORMAL
- en: If one simply wants to set the number of milliseconds of inactivity before a
    socket is presumed to have timed out, simply use `server.timeout = (Integer)num_milliseconds`.
    To disable socket timeouts, pass a value of `0` (zero).
  prefs: []
  type: TYPE_NORMAL
- en: Let's now take a look at how Node's HTTP module can be used to enter into more
    interesting network interactions.
  prefs: []
  type: TYPE_NORMAL
- en: Making HTTP requests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is often necessary for a network application to make external HTTP calls.
    HTTP servers are also often called upon to perform HTTP services for clients making
    requests. Node provides an easy interface for making external HTTP calls.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the following code will fetch the HTML front page of `www.example.org`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, we are working with a `Readable` stream, which can be written
    to a file.
  prefs: []
  type: TYPE_NORMAL
- en: A popular Node module for managing HTTP requests is Mikeal Roger's request: [https://github.com/request/request](https://github.com/request/request)
  prefs: []
  type: TYPE_NORMAL
- en: 'Because it is common to use `HTTP.request` in order to `GET` external pages,
    Node offers a shortcut:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Let's now look at some more advanced implementations of HTTP servers, where
    we perform general network services for clients.
  prefs: []
  type: TYPE_NORMAL
- en: Proxying and tunneling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes, it is useful to provide a means for one server to function as a proxy,
    or broker, for other servers. This would allow one server to distribute a load
    to other servers, for example. Another use would be to provide access to a secured
    server to users who are unable to connect to that server directly. It is also
    common to have one server answering for more than one URL—using a proxy, that
    one server can forward requests to the right recipient.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because Node has a consistent streams interface throughout its network interfaces,
    we can build a simple HTTP proxy in just a few lines of code. For example, the
    following program will set up an HTTP server on port `8080` which will respond
    to any request by fetching the front page of a website and piping that page back
    to the client:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Go ahead and start this server, and connect to it. Once this server receives
    the client socket, it is free to push content from any readable stream back to
    the client, and here, the result of `GET` of `www.example.org` is streamed. One
    can easily see how an external content server managing a caching layer for your
    application might become a proxy endpoint, for example.
  prefs: []
  type: TYPE_NORMAL
- en: Using similar ideas, we can create a tunneling service, using Node's native
    `CONNECT` support. Tunneling involves using a proxy server as an intermediary
    to communicate with a remote server on behalf of a client. Once our proxy server
    connects to a remote server, it is able to pass messages back and forth between
    that server and a client. This is advantageous when a direct connection between
    a client and a remote server is not possible, or not desired.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we''ll set up a proxy server responding to `HTTP` `CONNECT` requests,
    then make a `CONNECT` request to that server. The proxy receives our client''s
    `Request` object, the client''s socket itself, and the head (the first packet)
    of the tunneling stream:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Once we make a request to our local tunneling server running on port 8080 it
    will set up a remote socket connection to our destination and maintain this "bridge"
    between the remote socket and the (local) client socket. The remote connection
    of course only sees our tunneling server, and in this way clients can connect
    in a sense anonymously to remote services (which isn't always a shady practice!).
  prefs: []
  type: TYPE_NORMAL
- en: HTTPS, TLS (SSL), and securing your server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The security of web applications has become a significant discussion topic in
    recent years. Traditional applications normally benefited from the well-tested
    and mature security models designed into the major servers and application stacks
    underpinning major deployments. For one reason or another, web applications were
    allowed to venture into the experimental world of client-side business logic and
    open web services shielded by a diaphanous curtain.
  prefs: []
  type: TYPE_NORMAL
- en: As Node is regularly deployed as a web server, it is imperative that the community
    begins to accept responsibility for securing these servers. HTTPS is a secure
    transmission protocol—essentially encrypted HTTP formed by layering the HTTP protocol
    on top of the SSL/TLS protocol.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a self-signed certificate for development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to support SSL connections, a server will need a properly signed certificate.
    While developing, it is much easier to simply create a self-signed certificate,
    which will allow you to use Node's HTTPS module.
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the steps needed to create a certificate for development. The certificate
    we create won''t demonstrate identity, as a certificate from a third party does,
    but it is all we need to use the encryption of HTTPS. From a terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'These keys may now be used to develop HTTPS servers. The contents of these
    files need simply be passed along as options to a Node server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Free low-assurance SSL certificates are available from [http://www.startssl.com/](http://www.startssl.com/)
    for cases where self-signed certificates are not ideal during development. Additionally, [https://www.letsencrypt.org](https://www.letsencrypt.org)
    has started an exciting initiative toward providing free certificates for all
    (and a safer web).
  prefs: []
  type: TYPE_NORMAL
- en: Installing a real SSL certificate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to move a secure application out of a development environment and into
    an internet-exposed environment, a real certificate will need to be purchased.
    The prices of these certificates has been dropping year by year, and it should
    be easy to find reasonably priced providers of certificates with a high-enough
    level of security. Some providers even offer free person-use certificates.
  prefs: []
  type: TYPE_NORMAL
- en: 'Setting up a professional cert simply requires changing the HTTPS options we
    introduced previously. Different providers will have different processes and filenames.
    Typically, you will need to download or otherwise receive from your provider a
    `private` `.key` file, your signed domain certificate `.crt` file, and a bundle
    describing certificate chains:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: It is important to note that the `ca` parameter must be sent as an *array*,
    even if the bundle of certificates has been concatenated into one file.
  prefs: []
  type: TYPE_NORMAL
- en: The request object
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'HTTP request and response messages are similar, consisting of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A status line, which for a request would resemble GET/`index.html` HTTP/1.1,
    and for a response would resemble HTTP/1.1 200 OK
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zero or more headers, which in a request might include `Accept-Charset`: `UTF-8
    or From: user@server.com`, and in responses might resemble `Content-Type: text/html
    and Content-Length: 1024`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A message body, which for a response might be an HTML page, and for a `POST`
    request might be some form data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We've seen how HTTP server interfaces in Node are expected to expose a request
    handler, and how this handler will be passed some form of a request and response
    object, each of which implement a readable or writable stream.
  prefs: []
  type: TYPE_NORMAL
- en: We will cover the handling of `POST` data and `Header` data in more depth later
    in this chapter. Before we do, let's go over how to parse out some of the more
    straightforward information contained in a request.
  prefs: []
  type: TYPE_NORMAL
- en: The URL module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Whenever a request is made to an HTTP server, the request object will contain
    URL property, identifying the targeted resource. This is accessible via `request.url`.
    Node''s URL module is used to decompose a typical URL string into its constituent
    parts. Consider the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/27aa88e6-d9b5-48b5-bdd3-9e3ce3cdd794.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We see how the `url.parse` method decomposes strings, and the meaning of each
    segment should be clear. It might also be clear that the `query` field would be
    more useful if it was itself parsed into key/value pairs. This is accomplished
    by passing `true` as the second argument of to the `parse` method, which would
    change the query field value given above into a more useful key/value map:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This is especially useful when parsing GET requests. There is one final argument
    for `url.parse` that relates to the difference between these two URLs:'
  prefs: []
  type: TYPE_NORMAL
- en: '`http://www.example.org`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`//www.example.org`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The second URL here is an example of a (relatively unknown) design feature
    of the HTTP protocol: the protocol-relative URL (technically, a **network-path
    reference**), as opposed to the more common absolute URL.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To learn more about how network-path references are used to smooth resource
    protocol resolution, visit: [http://tools.ietf.org/html/rfc3986#section-4.2](http://tools.ietf.org/html/rfc3986#section-4.2).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The issue under discussion is this: `url.parse` will treat a string beginning
    with slashes as indicating a path, not a host. For example, `url.parse("//www.example.org")`
    will set the following values in the host and path fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'What we actually want is the reverse:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'To resolve this issue, pass `true` as the third argument to `url.parse`, which
    indicates to the method that slashes denote a host, not a path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: It is also the case that a developer will want to create an URL, such as when
    making requests via `http.request`. The segments of said URL may be spread across
    various data structures and variables, and will need to be assembled. You accomplish this
    by passing an object like the one returned from `url.parse` to the method `url.format`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code will create the URL string `http://www.example.org`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, you may also use the `url.resolve` method to generate URL strings
    in the common scenario of requiring the concatenating of a base URL and a path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: The Querystring module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we saw with the `URL` module, query strings often need to be parsed into
    a map of key/value pairs. The `Querystring` module will either decompose an existing
    query string into its parts, or assemble a query string from a map of key/value
    pairs.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, `querystring.parse("foo=bar&bingo=bango")` will return:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: If our query strings are not formatted using the normal `"&"` separator and
    `"="` assignment character, the `Querystring` module offers customizable parsing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second argument to `Querystring` can be a custom separator string, and
    the third, a custom assignment string. For example, the following will return
    the same mapping as given previously on a query string with custom formatting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'You can compose a query string using the `Querystring.stringify` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'As with parse, `stringify` also accepts custom separator and assignment arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Query strings are commonly associated with `GET` requests, seen following the
    `?` character. As we saw previously, in these cases, automatic parsing of these
    strings using the `url` module is the most straightforward solution. However,
    strings formatted in such a manner also show up when we're handling `POST` data,
    and in these cases, the `Querystring` module is of real use. We'll discuss this
    usage shortly, but first, something about HTTP headers.
  prefs: []
  type: TYPE_NORMAL
- en: Working with headers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Each HTTP request made to a Node server will likely contain useful header information,
    and clients normally expect to receive similar package information from a server.
    Node provides straightforward interfaces for reading and writing headers. We'll
    briefly go over those simple interfaces, clarifying some details. Finally, we'll
    discuss how more advanced header usage might be implemented in Node, studying
    some common network responsibilities a Node server will likely need to accommodate.
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical request header will look something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b618caa1-547a-47f7-b781-5baaab74e9b1.png)'
  prefs: []
  type: TYPE_IMG
- en: Headers are simple key/value pairs. Request keys are always lowercased. You
    may use any case format when setting response keys.
  prefs: []
  type: TYPE_NORMAL
- en: Reading headers is straightforward. Read header information by examining the
    `request.header` object, which is a 1:1 mapping of the header's key/value pairs.
    To fetch the *accept* header from the previous example, simply read `request.headers.accept`.
  prefs: []
  type: TYPE_NORMAL
- en: The number of incoming headers can be limited by setting the `maxHeadersCount`
    property of your HTTP server.
  prefs: []
  type: TYPE_NORMAL
- en: If it is preferred that headers are read programmatically, Node provides the
    `response.getHeader` method, accepting the header key as its first argument.
  prefs: []
  type: TYPE_NORMAL
- en: 'While request headers are simple key/value pairs, when writing headers, we
    need a more expressive interface. As a response typically must send a status code,
    Node provides a straightforward way to prepare a response status line and header
    group in one command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'To set headers individually, you can use `response.setHeader`, passing two
    arguments: the header key, followed by the header value.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To set multiple headers with the same name, you may pass an array to `response.setHeader`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Occasionally, it may be necessary to remove a response header after that header
    has been *queued*. This is accomplished using `response.removeHeader`, passing
    the header name to be removed as an argument.
  prefs: []
  type: TYPE_NORMAL
- en: Headers must be written prior to writing a response. It is an error to write
    a header after a response has been sent.
  prefs: []
  type: TYPE_NORMAL
- en: Using cookies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The HTTP protocol is stateless. Any given request has no information on previous
    requests. For a server, this meant that determining if two requests originated
    from the same browser was not possible. Cookies were invented to solve this problem.
    Cookies are primarily used to share state between clients (usually a browser)
    and a server, existing as small text files stored in browsers.
  prefs: []
  type: TYPE_NORMAL
- en: Cookies are insecure. Cookie information flows between a server and a client
    in plain text. There is any number of tamper points in between. Browsers allow
    easy access to them, for example. This is a good idea, as nobody wants information
    on their browser or local machine to be hidden from them, beyond their control.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, cookies are also used rather extensively to maintain state information,
    or pointers to state information, particularly in the case of user sessions or
    other authentication scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: It is assumed that you are familiar with how cookies function in general. Here,
    we will discuss how cookies are fetched, parsed, and set by a Node HTTP server.
    We will use the example of a server that echoes back the value of a sent cookie.
    If no cookie exists, the server will create that cookie and instruct the client
    to ask for it again.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we create a server that checks request headers for cookies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that cookies are stored as the `cookie` attribute of `request.headers`.
    If no cookies exist for this domain, we will need to create one, giving it the
    name `session` and a value of `123456`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'If we have set this cookie for the first time, the client is instructed to
    make another request to this same server, using a 302 Found redirect, instructing
    the client to call our server location again. As there is now a cookie set for
    this domain, the subsequent request will contain our cookie, which we handle next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Now if you visit `localhost:8080` you should see something like this displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Understanding content types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A client will often pass along a request header indicating the expected response
    **MIME** (**Multi-purpose Internet Mail Extension**) type. Clients will also indicate
    the MIME type of a request body. Servers will similarly provide header information
    about the MIME type of a response body. The MIME type for HTML is text/html, for
    example.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we have seen, it is the responsibility of an HTTP response to set headers
    describing the entity it contains. Similarly, a `GET` request will normally indicate
    the resource type, the MIME type, it expects as a response. Such a request header
    might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'It is the responsibility of a server receiving such instructions to prepare
    a body entity conforming to the sent MIME type, and if it is able to do so, it
    should return a similar response header:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Because requests also identify the specific resource desired (such as `/files/index.html`),
    the server must ensure that the requested resource it is streaming back to the
    client is in fact of the correct MIME type. While it may seem obvious that a resource
    identified by the extension `html` is in fact of the MIME type text/html, this
    is not at all certain—a filesystem does nothing to prevent an image file from
    being given an `html` extension. Parsing extensions is an imperfect method of
    determining file type. We need to do more.
  prefs: []
  type: TYPE_NORMAL
- en: 'The UNIX `file` program is able to determine the MIME type of a system file.
    For example, one might determine the MIME type of a file without an extension
    (for example, `resource`) by running this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: We pass arguments instructing `file` to output the MIME type of resource, and
    that the output should be brief (only the MIME type, and no other information).
    This command might return something like `text/plain; charset=us-ascii`. Here,
    we have a tool to solve our problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'For more information about the file utility consult, go to: [http://man7.org/linux/man-pages/man1/file.1.html](http://man7.org/linux/man-pages/man1/file.1.html)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Recalling that Node is able to spawn child processes, we have a solution to
    our problem of accurately determining the MIME type of system files. We can use
    the Node command `exec` method of Node''s `child_process` module in order to determine
    the MIME type of a file, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: This technique is also useful when validating a file streamed in from an external
    location. Following the axiom "never trust the client", it is always a good idea
    to check whether the `Content-type` header of a file posted to a Node server matches
    the actual MIME type of the received file as it exists on the local filesystem.
  prefs: []
  type: TYPE_NORMAL
- en: Handling favicon requests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When visiting a URL via a browser, you will often notice a little icon in the
    browser tab or in the browser's address bar. This icon is an image named `favicon.ico`,
    and it is fetched on each request. As such, an HTTP GET request normally combines
    two requests—one for the favicon, and another for the requested resource.
  prefs: []
  type: TYPE_NORMAL
- en: 'Node developers are often surprised by this doubled request. Any implementation
    of an HTTP server must deal with favicon requests. To do so, the server must check
    the request type and handle it accordingly. The following example demonstrates
    one method of doing so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: This code will simply send an empty image stream for the favicon. If there is
    a favicon to send, you would simply push that data through the response stream,
    as we've discussed previously.
  prefs: []
  type: TYPE_NORMAL
- en: Handling POST data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most common `REST` methods used in network applications is POST.
    According to the `REST` specification, a `POST` is not idempotent, as opposed
    to most of the other well-known methods (`GET`, `PUT`, `DELETE`, and so on) that
    are. This is mentioned in order to point out that the handling of `POST` data
    will very often have a consequential effect on an application's state, and should
    therefore be handled with care.
  prefs: []
  type: TYPE_NORMAL
- en: We will now discuss the handling of the most common type of `POST` data, that
    which is submitted via forms. The more complex type of `POST`—multipart uploads—will
    be discussed in [Chapter 4](886e76b5-09f3-4ab0-bb0e-191b2c40c299.xhtml), *Using
    Node to Access the Filesystem*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a server which will return a form to clients, and echo back any
    data that client submits with that form. We will need to first check the request
    `URL`, determining if this is a form request or a form submission, returning `HTML`
    for a form in the first case, and parsing submitted data in the second:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the form we respond with has a single field named `sometext`. This
    form should POST data in the form `sometext=entered_text` to the path `/submit`.
    To catch this data, add the following conditional:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Once our `POST` stream ends we parse the body using `Querystring.parse`, giving
    us a key/value map from which we can pluck the value of the form element with
    name `sometext`, and respond to the client that we have received their data.
  prefs: []
  type: TYPE_NORMAL
- en: Creating and streaming images with Node
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having gone over the main strategies for initiating and diverting streams of
    data, let's practice the theory by creating a service to stream (aptly named)
    **PNG** (**Portable Network Graphics**) images to a client. This will not be a
    simple file server, however. The goal is to create PNG data streams by piping
    the output stream of an **ImageMagick** convert operation executing in a separate
    process into the response stream of an HTTP connection, where the converter is
    translating another stream of **SVG** (**Scalable Vector Graphics**) data generated
    within a virtualized **DOM** (**Document Object Model**), existing in the Node
    runtime. Let's get started.
  prefs: []
  type: TYPE_NORMAL
- en: The full code for this example can be found in your code bundle.
  prefs: []
  type: TYPE_NORMAL
- en: Our goal is to use Node to generate pie charts dynamically on a server based
    on client requests. A client will specify some data values, and a PNG representing
    that data in a pie will be generated. We are going to use the **D3.js** library,
    which provides a Javascript API for creating data visualizations, and the **jsdom**
    NPM package, which allows us to create a virtual DOM within a Node process. Additionally
    we'll use **ImageMagick** to transform a **SVG (Scalable Vector Graphics)** representation
    into a **PNG (Portable Network Graphics) **representation.
  prefs: []
  type: TYPE_NORMAL
- en: Visit [https://github.com/tmpvar/jsdom](https://github.com/tmpvar/jsdom) to
    learn about how **jsdom** works, and [https://d3js.org/](https://d3js.org/) to
    learn about using D3 to generate SVG.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the PNG we create will be written to a file. If future requests
    pass the same query arguments to our service, we will then be able to rapidly
    pipe the existing rendering immediately, without the overhead of regenerating
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'A pie graph represents a range of percentages whose sum fills the total area
    of a circle, visualized as slices. Our service will draw such a graph based on
    the values a client sends. In our system, the client is required to send values
    adding up to 1, such as .5, .3, .2\. Our server, when it receives a request, will
    therefore need to fetch query parameters as well as create a unique key that maps
    to future requests with the same query parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we see the URL module in action, pulling out our data values. As well,
    we create a key on these values by first sorting the values, then joining them
    into a string we will use as the filename for our cached pie graph. We sort values
    for this reason: the same graph is achieved by sending .5 .3 .2 and .3 .5 .2\.
    By sorting and joining, these both become the filename .2 .3 .5.'
  prefs: []
  type: TYPE_NORMAL
- en: In a production application, more work would need to be done to ensure that
    the query is well formed, is mathematically correct, and so on. In our example,
    we assume proper values are being sent.
  prefs: []
  type: TYPE_NORMAL
- en: Creating, caching, and sending a PNG representation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To start, install ImageMagick: [http://www.imagemagick.org/script/download.php](http://www.imagemagick.org/script/download.php).
    We will spawn a Node process to interface with the installed binary, below.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we build the graph dynamically, assume that there already exists an
    SVG definition stored on variable `svg`, which will contain a string similar to
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: To convert that SVG to a PNG we would spawn a child process running the ImageMagick
    convert program, and stream our SVG data to the `stdin` of that process, which
    will output a PNG. In the example that follows we continue this idea to stream
    the generated PNG to the client.
  prefs: []
  type: TYPE_NORMAL
- en: We'll skip the server boilerplate -- suffice it to say that the server will
    be running on 8080 and will a client calling with some data to graph. What's important
    is how we generate and stream the pie chart back.
  prefs: []
  type: TYPE_NORMAL
- en: 'The client will send some querystring arguments indicating the `values` for
    this graph (such as 4,5,8, the relative size of the slices). What the server will
    do is generate a "virtual DOM" using the jsdom module, into which the D3 graphics
    library is inserted, as well as some javascript (`pie.js` in your code bundle)
    to take the values we have received and draw an SVG pie chart using D3, all within
    this server-side virtual DOM. We then grab that generated SVG code and convert
    it to a PNG using ImageMagick. In order to allow caching we store this PNG using
    a string filename formed from the cache values as a cacheKey, and while writing
    we pipe the streaming PNG back to the client:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Recalling our discussion on streams, what is happening here should be clear.
    We generate a DOM (`window`) with jsdom, run the `insertPie` function to generate
    the SVG, and then spawn two streams: one to write the cache file, and one to the
    ImageMagick process. Using a `TransformStream`  (both readable and writable) we
    implement its abstract `_transform` method to expect input from `stdout` of our
    ImageMagick stream, write that data to the local filesystem, and then re-push
    the data back into the stream, which is piped forward onto the response stream.
    We can now achieve the desired stream chaining:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'The client receives a pie graph, and a copy is written on the local file cache.
    In cases where the requested pie chart has already been rendered it can be directly
    streamed from a filesystem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'If you start the server and paste the following into your browser:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see a pie chart displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/53cbc2e5-db0f-4769-8b62-ea7fddcc0431.png)'
  prefs: []
  type: TYPE_IMG
- en: While somewhat artificial, hopefully this shows how chains of different processes
    can be connected via streams, avoiding any intermediate storage in memory, which
    can be especially useful when passing data through and out of a highly trafficked
    network server.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have learned, Node's designers have succeeded in creating a simple, predictable,
    and convenient solution to the challenging design problem of enabling efficient
    I/O between disparate sources and targets, while keeping code easy to manage.
    Its abstract Stream interface facilitates the instantiation of consistent readable
    and writable interfaces, and the extension of this interface into HTTP requests
    and responses, the filesystem, child processes, and other data channels makes
    stream programming with Node a pleasant experience.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've learned how to set up HTTP servers to handle streams of data
    arriving from many simultaneously connected clients, and how to feed those clients
    buffets of buffered streams, we can begin to engage more deeply with the task
    of building enterprise-grade concurrent real-time systems with Node.
  prefs: []
  type: TYPE_NORMAL
