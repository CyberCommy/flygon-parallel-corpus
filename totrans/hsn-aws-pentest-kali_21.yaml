- en: Pentesting CloudTrail
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AWS CloudTrail is described as an AWS service that helps you enable governance,
    compliance, and operational and risk auditing of your AWS account ([https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-user-guide.html](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-user-guide.html))
    and is basically advertised as the central logging source for API activity in
    an AWS account. CloudTrail is an always-on service in some sense, in that it logs
    read/write API operations to an immutable archive of the last 90 days of logs,
    known as the CloudTrail Event history. We will get more into Event history in
    the *Reconnaissance* section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will take a look at CloudTrail and the features that it
    provides us with as diligent AWS users. We will also look at it from the pentester's
    point of view, covering how to audit CloudTrail best practices in a target account,
    but also how to perform reconnaissance on the environment through CloudTrail,
    how to bypass the CloudTrail service to stay under the radar, and how to disrupt
    any logging mechanisms that are already in place. These topics are beneficial
    to our client because they can help them understand where their blind spots are
    in the environment; however, they can also help us discover more information about
    our attack target, without necessarily needing to make direct API calls to each
    service they are using.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll cover following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Setup, best practices, and auditing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reconnaissance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bypassing logging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disrupting trails
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More about CloudTrail
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although CloudTrail is meant to be the central logging source for an AWS account,
    the way that it is built leaves some undesirable risks out in the open as new
    AWS services are being developed. The team working at AWS that is creating a new
    service must create the CloudTrail integration with their service to allow its
    API calls to be logged to CloudTrail. Also, because of how fast AWS pushes out
    new services and functionality, there are many services that get released without
    any support for CloudTrail. That list can be found here: [https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-unsupported-aws-services.html](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-unsupported-aws-services.html).
    Later in this chapter, we will dive into abusing unsupported services for our
    advantage as an attacker, as any API call that doesn't get logged to CloudTrail
    can do wonders for us as attackers.
  prefs: []
  type: TYPE_NORMAL
- en: CloudTrail is also not the only option for logging in an AWS account. It aggregates
    logs from most AWS services, but some services also offer their own specific kinds
    of logging. These types of log include things such as S3 bucket access logs, Elastic
    Load Balancer access logs, CloudWatch logs, VPC flow logs, and many others. These
    other types of logging exist because they don't record API activity like CloudTrail
    does, but instead they log other types of activity that can be useful.
  prefs: []
  type: TYPE_NORMAL
- en: Before we get started with CloudTrail pentesting, we will see how to set it
    up.
  prefs: []
  type: TYPE_NORMAL
- en: Setup, best practices, and auditing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will run through setting up a new CloudTrail trail that
    follows all the recommended best practices for the most effective/secure setup.
    We will show the setup steps using the AWS web console, but everything we do is
    also possible through the AWS CLI and we will go through auditing CloudTrail through
    the CLI.
  prefs: []
  type: TYPE_NORMAL
- en: Setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Lets begin to set up CloudTrail by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we will do is navigate to the CloudTrail service in the AWS
    web console and click the Create trail button on the main page:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/53723408-3f16-4c43-8543-57f5ba0b8904.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Where to find the Create trail button on the CloudTrail service page'
  prefs: []
  type: TYPE_NORMAL
- en: We are going to name our trail `ExampleTrail`, then the next option we are presented
    with on the page is the first best practice that we will look at. The option asks
    if we would like to apply this trail to all regions, which best practices say
    to say yes, apply my trail to all regions. This is because CloudTrail can operate
    on a per-region basis, so you would in theory need a trail for every single region
    that exists without this option. With this option, we can create a single trail
    that monitors API activity across every region, so we always will have insight
    into our environment, wherever that activity is happening.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next up is the Management events section, where we will want to select All.
    There are two types of event in AWS: management events and data events, where
    management events are essentially the high-level APIs that are being used when
    interacting with AWS and data events can be thought of as interactions with resources
    within an AWS account. An example of a data event would be the `s3:GetObject`
    event, which would be someone accessing an object in S3\. We want to ensure that
    all API activity is being recorded, so selecting All for Management events is
    what should be done.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After that, we now are in the Data events section. Data events cost a little
    bit more money to record, so it may not always be the right decision to record
    all read and write data activity. Also, if you are only using a single account
    for the trail and an S3 bucket to store the logs, you would essentially be logging
    that CloudTrail is writing logs to its log bucket by recording all S3 data events.
    For this reason, we are going to add a single S3 bucket under data events, which
    would be the bucket-for-lambda-pentesting that we created in the previous chapter.
    Under the Lambda tab of the Data events section, we are going to enable Log all
    current and future invocations so that we can monitor invocation activity for
    all our Lambda functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/001dfc21-54b9-4d46-b5a0-2216456f278a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: The current configuration for our new trail'
  prefs: []
  type: TYPE_NORMAL
- en: Under the Storage location section, we are going to check Yes for Create a new
    S3 bucket because we do not have a bucket set up to store our logs yet. We're
    going to name it `example-for-cloudtrail-logs`, then we will click the Advanced link
    to drop-down a few more options that we will want to enable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log file prefix can be filled in or left blank, as it is just adding something
    to the path of the CloudTrail logs for easier identification/separation if you
    have multiple types of log written to a single bucket.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will want to check Yes for Encrypt log files with SSE-KMS.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We don''t have a KMS key set up yet, so we''ll also select Yes or Create a
    new KMS key and give it the name `CloudTrail-Encryption-Key`. This will ensure
    that all our CloudTrail log files will be encrypted when they are stored in S3,
    and if we would like, it provides us with the ability to manage permissions on
    who can/can''t decrypt those log files for a more fine-grained permission model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/32503746-96cb-40e5-83bc-047e3629c393.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: The rest of the configuration for our new trail'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we'll select Yes for Enable log file validation, which tells CloudTrail
    to also write digest files to the S3 bucket alongside the logs, which can then
    be used to determine if our log files have been tampered with since CloudTrail
    delivered them to the S3 bucket. This is important to ensure that we have a trustworthy,
    complete recording of API activity in the account.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For the last option, Send SNS notification for every log file delivery, we will
    be selecting No for the time being. CloudTrail logs are written often, and this
    can end up with many SNS notifications being sent, so it is better to take a strategic
    approach to this problem if you are interested in these notifications.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now we can finish up and click Create in the bottom right to create our new
    trail.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now the trail will be created and enabled, at which point it will immediately
    start sending log files and digests to your S3 bucket to be read, verified, exported,
    and so on.
  prefs: []
  type: TYPE_NORMAL
- en: You might find it necessary to create more than one trail for organisational
    reasons, such as one that logs management events and one that logs data events.
    Often it is recommended to send these logs to another account altogether, because
    then they will be separated from the account, in the event of a compromise, where
    they will likely be safer.
  prefs: []
  type: TYPE_NORMAL
- en: Auditing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have gone through the process of setting up a new CloudTrail trail,
    we can move away from the AWS web console to the AWS CLI, where we will now cover
    how to audit CloudTrail to ensure that all best practices are being followed.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will want to see if there are any active trails in our target account.
    We can do this with the CloudTrail `DescribeTrails` API, which allows us to view
    trails across all AWS regions, even if they are managed by the account''s organization.
    The command will look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `--include-shadow-trails` flag is what allows us to see trails from other
    regions/our organization. The only trails that won't show up are region-specific
    trails outside the region the command is run against, so it is possible there
    is some CloudTrail logging going on and you just need to find it. This would still
    be a poor setup because those logs were not expanded across every region. The
    output of that command will give us most of the information that we are interested
    in.
  prefs: []
  type: TYPE_NORMAL
- en: We'll want to ensure that CloudTrail logging is expanded across all regions
    and we can determine that by looking at the `IsMultiRegionalTrail` key of the
    specific trail we are looking at. It should be set to true. If not, then that
    is something that needs to be remediated. A single multi-regional trail makes
    far more sense than a single trail per region for many reasons, but especially
    because as new AWS regions are released, you'd need to create trails for them,
    whereas a multi-regional trail will automatically cover them as they are added.
  prefs: []
  type: TYPE_NORMAL
- en: Then we want to ensure that `IncludeGlobalServiceEvents` is set to `true`, as
    that enables the trail to log API activity for non-region-specific AWS services,
    such as IAM, which is global. We will miss a lot of important activity if this
    is disabled. After that, we want to ensure `LogFileValidationEnabled` is set to
    `true` so that deletion and modification of logs can be detected and verified.
    Then we will look for the `KmsKeyId` key, which, if it is present, will be the
    ARN of the KMS key that is being used to encrypt the log files, and if it is not
    present then that means that the log files aren't being encrypted with SSE-KMS.
    This is another setting that should be added if it is not already present.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to determine whether data events have been enabled, we can first
    check by looking at the `HasCustomEventSelectors` key and confirming it is set
    to `true`. If it is `true`, we''ll then want to call the `GetEventSelectors` API
    in the region that the trail was created in to see what has been specified. The
    `ExampleTrail` that we created was created in the `us-east-1` region, so we will
    run the following command to look at event selectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'That API call returned the following data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The values for the different event selectors tell us what kinds of event are
    being logged by this trail. We can see that `ReadWriteType` is set to `All`, which
    means we are recording both read and write events, and not just one of them. We
    can also see `IncludeManagementEvents` is set to `true`, which means the trail
    is logging management events like we want. Under `DataResources` we can see that
    S3 object logging is enabled for the bucket with the ARN `arn:aws:s3:::bucket-for-lambda-pentesting/`,
    but no others, and that Lambda function invocation logging is enabled for functions
    with `arn:aws:lambda` in their ARN, which means all Lambda functions.
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, read and write events should be logged, management events should be
    logged, and all S3 buckets/Lambda functions should be logged, but that might not
    always be possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have checked the configuration of the trail, we need to make sure
    it is enabled and logging! We can do this with the `GetTrailStatus` API from the
    same region the trail was created in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'It will return output that looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The number-one most important thing to look for is that the `IsLogging` key
    is set to `true`. If it is set to `false`, then that means the trail is disabled
    and none of that configuration we just checked even matters, because it is not
    actually logging anything.
  prefs: []
  type: TYPE_NORMAL
- en: Further, we can look at the `LatestDeliveryAttemptTime` and `LatestDeliveryAttemptSucceeded` keys
    to ensure that logs are being delivered correctly. If logs are being delivered,
    then those two values should be the same. If not, then there is something wrong
    that is preventing CloudTrail from delivering those logs to S3.
  prefs: []
  type: TYPE_NORMAL
- en: That essentially wraps up the basics of CloudTrail setup and best practices,
    but it is possible to get even more in-depth and secure by creating a custom policy
    for the KMS encryption key used on the trail and by modifying the S3 bucket policy
    to restrict access to the logs even further, prevent the deletion of logs, and
    more.
  prefs: []
  type: TYPE_NORMAL
- en: Reconnaissance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now be switching gears to cover how CloudTrail can help us out as an
    attacker. One of the ways it can help us is with reconnaissance and information
    gathering.
  prefs: []
  type: TYPE_NORMAL
- en: 'You might not always be able to compromise a user who has the necessary S3
    read permissions and has access to encrypt the data with the KMS key used originally.
    If you don''t have both of those permissions, then you won''t be able to read
    the log files. There might even be other restrictions in place that make it difficult
    for you. To get around this, we can use our `cloudtrail:LookupEvents` permission
    to interact with the CloudTrail Event history. The CloudTrail Event history is
    an always-on, immutable record of read/write management events that is made available
    through the CloudTrail API. These logs can be fetched by using the `LookupEvents`
    API or by visiting the Event history page in the AWS web console:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f1fc9b2c-1d15-4ec4-bf04-9374ebd25f70.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Where to find CloudTrail Event history in the AWS web console'
  prefs: []
  type: TYPE_NORMAL
- en: Because the CloudTrail Event history is immutable and separate from S3, it can
    be a useful tool for both defenders and attackers. As a defender, if something
    happens and your CloudTrail logs get modified or deleted and you can recover them,
    the CloudTrail Event history could be a useful place to go to find out what happened
    during that time period (if it is in the last 90 days). As an attacker, we can
    use it to gather information about the target environment without needing to access
    S3 or KMS.
  prefs: []
  type: TYPE_NORMAL
- en: 'Due to the number of logs that get stored in Event history and the incredibly
    slow API calls required to download them, it can be difficult to review large
    amounts of information without some sort of filter. For reasons that can likely
    be attributed to you should use a real trail and not just the Event history; the
    CloudTrail `LookupEvents` API will only return 50 events at a time and is rate-limited
    to one call per-second. In big environments, this means it could take huge amounts
    of time to download all the logs for even just the past day. This leaves us with
    two options: one is to just wait out the download and try to get as many as possible,
    but that is not recommended due to the huge amount of time that may be involved.
    The second option is to inspect and filter the logs prior to downloading them,
    so that there are far fewer to wait on.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can gather a lot of information from looking at different events in the
    Event history. On a large scale, we can determine what users/services are active
    and what kind of activity they do, and we can learn about their habits in AWS.
    This helps us because we can then use this knowledge during the attack. This way,
    we can stay under the radar by not doing anything that could be out of the ordinary
    in the account. Through the AWS web console, we have gone ahead and selected the
    CloudTrail `CreateTrail` Event that was generated when we set up the trail earlier
    in this chapter. The web console will aggregate the information into an easily
    viewable format, but we can click the View event button that appears in order
    to look at the raw JSON of the request. That JSON looks something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Even just from this single event, we can gather quite a bit of information about
    the user and the environment. The first thing we can see is that this API call
    was made by an IAM user along with a list of the user ID, ARN, account ID, access
    key ID used, user name, and whether they were MFA authenticated. Also, the `invokedBy` key
    has the value of `signin.amazonaws.com`, which tells us they were logged into
    the AWS web console when they performed this action, rather than using the CLI.
    Then we can see information about the request itself, which includes what event
    it was, what service that event was for, when the event happened, and then a few
    parameters included in the request. After that we see parameters returned from
    the API in the response, which tell us a little about the newly created CloudTrail
    trail.
  prefs: []
  type: TYPE_NORMAL
- en: Two of the most important things we skipped over included the IP address that
    the request originated from and the user agent used for the request. The IP will
    tell us where the call came from and with a larger sample set could potentially
    allow us to determine where the users work from, what the office IP address is,
    and more. For example, if we see that multiple users are originating from the
    same IP address during work hours (9am to 5pm), it would be safe to assume that
    they are all at the office or all on a VPN when working with AWS APIs. We then
    know that it would be strange if one of those users started coming from some external
    IP we haven't seen before when we compromise them, so we can build our attack
    plan around that to try and avoid it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The same thing goes for user agents. In the preceding example event, the user
    agent was `signin.amazonaws.com`, which is the user agent that appears when using
    the AWS web console. If we look at a different event, such as when we used the
    `GetEventSelectors` API from the AWS CLI, we can see that the user agent is much
    more specific:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The user agent from this request is set to `aws-cli/1.16.81 Python/3.7.0 Windows/10
    botocore/1.12.71`, which gives us a lot of information about the system the user
    is using. We can see they used version 1.16.81 of the AWS CLI, which is using
    Python version 3.7.0, on Windows 10, and using version 1.12.71 of the botocore
    library. This information on its own gives us an insight into the systems that
    may be in use at our target company, but also it allows us to gather a list of
    known user agents in the environment. With that list, we can then spoof our own
    user agent to look like a known one so that we don't stand out as abnormal in
    our API requests.
  prefs: []
  type: TYPE_NORMAL
- en: There are many things you can do by looking through CloudTrail logs/Event history,
    including the small amount of information gathering we did earlier. You could
    also determine what AWS services are in use in the account based on API calls
    made to those services, and you can potentially discover helpful information about
    specific resources in the account. For example, let's say that you don't have
    the `ec2:DescribeInstances` permission, but you have the `ec2:ModifyInstance`
    permission. In theory, you wouldn't be able to get a list of EC2 instances to
    then use the `ec2:ModifyInstance` API on because you don't have access, but you
    could look through CloudTrail logs to find an event where someone interacted with
    an EC2 instance in the past. That event will likely include the instance ID and
    possibly other information that could be helpful to you in discovering those assets
    in the environment.
  prefs: []
  type: TYPE_NORMAL
- en: Event history isn't the only place to look for this information either, because
    if you do have the necessary S3 and KMS permissions, you could just download the
    logs straight from the S3 bucket they are delivered to, which would be much quicker
    and much easier to parse than the output of the Event history API. Be careful
    to not trip any wires, though, as activity within that bucket might be being monitored,
    and a bunch of requests to download files from it could potentially look suspicious
    to a defender.
  prefs: []
  type: TYPE_NORMAL
- en: Bypassing logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now we are going to bypass CloudTrail to discover information about an account
    you have gained access to. The first method uses services that aren't supported
    in CloudTrail to gather basic account information and the second method uses some
    of that information to enumerate IAM resources in the account, all without generating
    CloudTrail logs in the target account.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupported CloudTrail services for attackers and defenders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we mentioned earlier in this chapter, CloudTrail doesn''t log everything,
    including many services that are completely unsupported. Again, that list of unsupported
    services can be found here: [https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-unsupported-aws-services.html](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-unsupported-aws-services.html).
    What this means is that our API calls to these services will not get logged anywhere
    by CloudTrail (including Event history!). Some of these services can prove to
    be very lucrative for us as attackers, so if you compromise a user and find that
    they have access to any of those services, they are worth checking out because
    you can stay under the radar and still benefit greatly. Another big point about
    unsupported CloudTrail services is that that means you can''t create CloudWatch
    Events rules for those API actions, which means you can''t instantly respond to
    events happening in those services.'
  prefs: []
  type: TYPE_NORMAL
- en: As an attacker, if we are looking for compute resources, we can abuse a few
    different unlogged services. At the time of writing, AppStream 2.0, Amplify, and
    Cloud9 all provide us with access to managed EC2 servers in one way or another.
    This means we can spin up servers and interact with them without ever getting
    logged.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a defender, it is important to ensure that no users have access to these
    services unless necessary. If it is required to provide access to any of the unlogged
    services, then utilize any built-in logging the service may provide and make use
    of some of the other features that IAM provides to monitor this access. If you
    download an IAM credential report, you can see if a service was accessed recently
    by looking in the `access_key_1_last_used_service` and `access_key_2_last_used_service` columns,
    where those unlogged services will still show up. To get an IAM credential report,
    you can run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Another option is to use the IAM `GenerateServiceLastAccessedDetails` and `GetServiceLastAccessDetails`
    APIs to determine when/if a user accessed a certain service, including the services
    that aren''t logged by CloudTrail. To do this, we can first run the generate command
    to generate the report:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The value for the ARN argument must be the ARN of an IAM resource, including
    users, groups, roles, and managed policies. This API command should return a `JobId` back
    to you. Then we can get the report by using that ID:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The response from that command will include information about whether a resource
    has authenticated to a certain service and when that last authentication took
    place. These APIs won't tell you exactly what kind of activity is going on, but
    you can at least check to see who is trying to access those services.
  prefs: []
  type: TYPE_NORMAL
- en: These APIs also help detect the use of unlogged CloudTrail services for account
    enumeration. The Wired company released an article on research from Rhino Security
    Labs that entailed a method that essentially allows an attacker with keys to gather
    a small amount of AWS account information without getting logged by CloudTrail
    ([https://www.wired.com/story/aws-honeytoken-hackers-avoid/](https://www.wired.com/story/aws-honeytoken-hackers-avoid/)).
    The reason this research is so important is because there are many canary token
    services that rely on CloudTrail to alert when keys have been compromised. Canary
    tokens are typically placed somewhere in an environment and are rigged to set
    off an alarm when used, which would indicate an attacker is in the environment
    and found those tokens. For AWS, canary token providers typically rely on CloudTrail
    for these alarms, but Rhino Security Labs showed that it was possible to bypass
    these alarms and determine whether AWS keys were canary tokens or not while staying
    under the radar.
  prefs: []
  type: TYPE_NORMAL
- en: At the time, it was found that some of the most popular canary token providers
    for AWS used a single account to generate these keys *or* would include identifying
    information in the user that indicated they were being used as a canary token.
    This information could then be exposed through verbose error messages returned
    from unsupported CloudTrail services, thus allowing the attacker to identify if
    AWS keys are canary tokens based on the account ID or user name/path without ever
    triggering the alarm the keys were meant to trigger. One project that was vulnerable
    to this attack was `SpaceCrab` by Atlassian.
  prefs: []
  type: TYPE_NORMAL
- en: 'Originally, the default `SpaceCrab` setting would set a path for the IAM user
    it created with `/SpaceCrab/` as the value. An attacker could then run an AWS
    CLI command against an unsupported CloudTrail service, where the user''s ARN would
    get disclosed in an error message. The ARN includes the user''s path, so it was
    clear that the keys were canary tokens created by `SpaceCrab`. The following is
    an example error message returned when running the AppStream `DescribeFleets`
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c581e8bf-a547-4728-a25b-5454b0553d85.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: The IAM user path contained SpaceCrab, disclosing that they were
    canary tokens'
  prefs: []
  type: TYPE_NORMAL
- en: The issue was reported to Atlassian and the vulnerability was fixed. The issue
    was also reported to AWS themselves, but it was rejected because they don't consider
    an ARN to be sensitive information. This is correct, but a user should not be
    able to fetch that information without generating any logs.
  prefs: []
  type: TYPE_NORMAL
- en: 'AWS Amplify is another newer service that is unsupported in CloudTrail and
    it outputs similar verbose error messages. The following message was returned
    when trying to run the `ListApps` command without the right permissions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This small attack is essentially timeless if the AWS service output error messages
    like that and if there are services that CloudTrail doesn't support. This same
    attack will likely work for any new service that gets released and isn't logged.
  prefs: []
  type: TYPE_NORMAL
- en: Even this small amount of information can be helpful to an attacker, because
    they can then use other non-logged attack vectors, such as cross-account IAM user/role
    enumeration, to gather more information ([https://rhinosecuritylabs.com/aws/aws-iam-user-enumeration/](https://rhinosecuritylabs.com/aws/aws-iam-user-enumeration/)).
  prefs: []
  type: TYPE_NORMAL
- en: Bypassing logging through cross-account methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Like we just noted, it is possible to enumerate users and roles in an AWS account
    without any permissions or logs in the target account. All that we need to make
    this happen is our own AWS account and the AWS account ID of our target.
  prefs: []
  type: TYPE_NORMAL
- en: Enumerating users
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Like we covered in the IAM chapter earlier on, an IAM role has a trust policy
    document that specifies what IAM resources/accounts can request temporary credentials
    from it. Behind the scenes, all IAM resources are created uniquely and IAM role
    trust policies recognize that. The reason for this is that, if you specify that
    the user `Mike` can assume a certain role, then `Mike` is deleted; in theory,
    an attacker could create another IAM user named `Mike` and assume that role. In
    practice, that is not the case, because behind the scenes, the roles trust policy
    is referencing a unique user ID rather than just the user name.
  prefs: []
  type: TYPE_NORMAL
- en: Because of that conversion from user ARN to a unique user ID behind the scenes,
    IAM will not let you set a trust policy that allows access to a non-existent user.
    Also, roles can be assumed to be cross-account, so you can specify other account
    IDs in the trust policy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given both those facts, if we as an attacker have the account ID of another
    account, we can essentially brute-force which users exist in their account. This
    process has been automated in a Pacu module named `iam__enum_users`. With Pacu
    open and configured, we can run the following command to enumerate IAM users in
    the account with the ID `000000000000`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '`TestRole` is an IAM role that was created in my own account. Pacu uses that
    role to update the trust policy document for enumeration, so it is important that
    this module is run with your own AWS access keys and you give it the role name
    of a role that those keys have access to update.'
  prefs: []
  type: TYPE_NORMAL
- en: When running the module, your own AWS CloudTrail logs will get flooded with
    `iam:UpdateAssumeRolePolicy` logs, but the target account will not see a thing,
    allowing you to stealthily gather information on the target environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using a custom wordlist, we were able to enumerate two users, `Alexa` and `Test`,
    from the target account with the ID `000000000000` (this is just a demo, this
    won''t work for you because `000000000000` is not a real AWS account). The output
    from the Pacu module looks something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The output shows that it found two valid users out of seven total guesses from
    our modified wordlist. At the time of writing, the default wordlist that Pacu
    uses has 1,136 names that it will try.
  prefs: []
  type: TYPE_NORMAL
- en: Enumerating roles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It used to be possible to use a similar attack to enumerate what roles exist
    in another AWS account and again, if only the AWS account ID was needed, then
    we could essentially brute-force all the roles that exist. Since the release by
    Rhino Security Labs, AWS has modified the error messages that the STS `AssumeRole`
    API call returns from the API, which means it is no longer possible to determine
    whether a role exists or not with this method. The `iam__enum_assume_role` Pacu
    module was written to exploit this, but no longer works due to this change.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the plus side, a new method was discovered that allows you to enumerate
    roles on a cross-account basis. This method is the same as the method used to
    enumerate cross-account users. Originally this method didn''t work like it does
    now, but some API changes must have been made that now make this enumeration possible.
    A new Pacu module was written to abuse this attack vector and it is named `iam__enum_roles`.
    It works exactly the same as the `iam__enum_users` module, so it can be run with
    essentially the same command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The module will enumerate roles that exist in the target account, then try
    to assume those roles to retrieve temporary credentials, in the event its policy
    is misconfigured and will allow you access. Part of that module is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The preceding example shows that a few roles were found and that one of them
    was misconfigured to allow us to request credentials for it. At the time of writing,
    the default wordlist that Pacu uses 1,136 names that it will try.
  prefs: []
  type: TYPE_NORMAL
- en: Both user and role enumeration are essentially timeless, such as the verbose
    AWS CLI error messages, because it is exploiting intended functionality and not
    any sort of bug in the API.
  prefs: []
  type: TYPE_NORMAL
- en: Disrupting trails
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many ways to disrupt the logging of CloudTrail trails to try and stay
    under the radar during our attack, but they all will likely trigger alerts that
    will expose our activity to someone paying attention. It is still important to
    know about these methods though, because not every account we attack will have
    even the most basic monitoring capabilities (such as GuardDuty), so it would make
    sense to disable any CloudTrail logging in that case. There are partial solutions
    to this problem though; those solutions and their limitations will be discussed
    at the end of this section.
  prefs: []
  type: TYPE_NORMAL
- en: Turning off logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One easy method to disrupt CloudTrail logging would be to just simply turn
    off any active trails. There is an API made just for this, the `StopLogging` API.
    From the AWS CLI, we can turn off logging for a trail named `test` within our
    account with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This command must be run from the region that the target trail was created in,
    otherwise it will return an `InvalidHomeRegionException` error.
  prefs: []
  type: TYPE_NORMAL
- en: 'This same task can also be accomplished with the `detection__detection` Pacu
    module. That Pacu command would look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'You would then be prompted with four different options: disable, delete, minimize,
    or skip. To stop the logging of the trail, we would select disable (dis). Pacu
    would then disable logging for the targeted trail(s).'
  prefs: []
  type: TYPE_NORMAL
- en: More information on GuardDuty can be found in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In either case, if GuardDuty was running, it would trigger a `Stealth:IAMUser/CloudTrailLoggingDisabled` alert
    ([https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_stealth.html#stealth2](https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_stealth.html#stealth2)),
    indicating that a trail has been disabled. This would expose our unauthorized
    access to the environment and likely shut down our attack if someone was paying
    attention.
  prefs: []
  type: TYPE_NORMAL
- en: Deleting trails/S3 buckets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another set of options that avoid the `StopLogging` API would be to either
    delete the CloudTrail trail altogether or delete the S3 bucket it is sending its
    logs to. We can delete a trail named `test` from the AWS CLI with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This can also be done with Pacu, by running the same command we used earlier
    to disable the trail, but by choosing the delete (del) option instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Once prompted for what to do to the trail, we would select `del`, which would
    subsequently delete the CloudTrail completely, meaning logging has stopped.
  prefs: []
  type: TYPE_NORMAL
- en: 'We could also delete the S3 bucket that a certain trail is delivering logs
    to, which would prevent an active trail from logging anything. This can avoid
    the CloudTrail API completely (if you know what bucket to delete), but it is still
    very noisy because it will leave the trail in an error state. We can use the AWS
    CLI to identify the name of the bucket that the trail is sending logs to, if we
    don''t already know it, with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we would look at the value of the `S3BucketName` key for the trail we
    want to target, which we will say is `cloudtrail_bucket`. We could then delete
    that S3 bucket with the following AWS CLI command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Now the CloudTrail would keep attempting to deliver logs to that bucket, but
    it will fail, meaning no logs will be written for the duration that the bucket
    is deleted. If you already knew what bucket was being targeted, you wouldn't ever
    need the run any CloudTrail API calls; only the S3 `DeleteBucket` call. There
    is no Pacu module available to perform this task (grabbing the bucket targeted
    by a trail, then deleting it). Afterwards, you could even go ahead and create
    that bucket in your own attacker account and provide the correct cross-account
    write permissions; then you would be supplied all the CloudTrail logs and your
    target account would not be able to access them.
  prefs: []
  type: TYPE_NORMAL
- en: Just like disabling a trail, deleting a trail or its target bucket with GuardDuty
    enabled will trigger the `Stealth:IAMUser/CloudTrailLoggingDisabled` alert ([https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_stealth.html#stealth2](https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_stealth.html#stealth2)),
    indicating that a trail or its bucket has been deleted. Again, this would expose
    our unauthorized access to the environment and likely shut down our attack if
    someone was paying attention.
  prefs: []
  type: TYPE_NORMAL
- en: Minifying trails
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another option that avoids disabling or deleting in the target account would
    be to modify a trail to minimize what exactly it is logging. For this example,
    let's say that there is a trail named `test` that is logging for every region;
    it logs global services events, log file validation is enabled, log file encryption
    is enabled, and it logs access to every S3 bucket and Lambda function in the account.
  prefs: []
  type: TYPE_NORMAL
- en: 'To avoid disabling or deleting this trail, we could use the `UpdateTrail` API
    to remove all the bells and whistles it has set up. We could run the following
    AWS CLI command to disable global service events, change it from a global trail
    to a single-region trail, disable log file encryption, and disable log file validation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: By setting the KMS key ID to a blank value, all logs from then on will be unencrypted.
    You could also pick and choose which settings to modify, such as if you want to
    target the `us-west-2` region with a non-global API, and the trail is a global
    trail that was created in `us-east-1`. In that case, all you would need to do
    is include the `--no-is-multi-region-trail` flag and make sure you stay within
    `us-west-2`. If the trail was sending notifications to an SNS topic, you could
    also disable that by setting the topic to a blank string. The same goes for CloudWatch
    logs associated with the trail as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Just like disabling/deleting a trail, the `detection__disruption` Pacu module
    will automate this process for you. We can run the same command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Then when prompted, we select the minimize (`m`) option, which will remove any
    associated SNS topics, disable global service events, change it from a global
    trail to a single-region trail, disable log file validation, remove any associations
    with CloudWatch log groups and the associated role, and remove log file encryption.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to disabling/deleting a trail, with GuardDuty enabled, these types of
    modification have the potential to trigger the `Stealth:IAMUser/CloudTrailLoggingDisabled` ([https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_stealth.html#stealth2](https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_stealth.html#stealth2))
    and/or `Stealth:IAMUser/LoggingConfigurationModified` ([https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_stealth.html#stealth3](https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_stealth.html#stealth3))
    alerts, which would likely end up with us getting detected in the environment.
    At the time of writing, we have never seen GuardDuty trigger on this type of attack
    on CloudTrail, though the descriptions for the two finding types seem to indicate
    that they should be triggered, so it is unknown whether this is detected for sure
    or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'To modify S3 data and Lambda invocation event settings for the trail, we will
    need to use the `PutEventSelectors` API instead of `UpdateTrail`. We can modify
    the event selectors to remove any selectors for data events (S3/Lambda), so those
    will no longer be logged by the trail. We could also modify `ReadWriteType`, which
    specifies whether the trail should log read events, write events, or both. It
    would be simple to modify that and set it to only record read events, so our malicious
    write events don''t get logged. We could remove all data event logging and only
    record read events by using the following AWS CLI command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Inside `event_selectors.json`, we would have the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This JSON document tells CloudTrail to only record read events and to not record
    any data events (S3/Lambda). Once this is applied to the trail, it will now log
    information that is missing a majority of the story, allowing us attackers to
    get by log analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Problems with disruption (and some partial solutions)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The main problem with these types of attack on CloudTrail is that GuardDuty
    is designed to detect them, but there are a few potential bypasses that allow
    us to make changes without being discovered.
  prefs: []
  type: TYPE_NORMAL
- en: The first and most simple bypass would be to detect what the usual activity
    is for the user you have compromised. GuardDuty uses machine learning (more in
    [Chapter 16](14f5f864-8cf1-4232-86f5-8d0fa4ec28e4.xhtml), *GuardDuty*) to detect
    these attacks as being unusual, so if you compromised a user who has a history
    of disabling/deleting/modifying CloudTrail trails, then it might be possible for
    you to do the same without GuardDuty detecting that as an anomaly.
  prefs: []
  type: TYPE_NORMAL
- en: Another partial solution would be to modify logs after they are delivered to
    their S3 bucket. If the target is properly utilizing the log file validation setting
    on their trail, would be able to detect this, but if they were not, then it would
    be simple to go into the S3 bucket where the logs are being delivered, where we
    then could modify the logs to remove any traces of our attacker activity. There
    are multiple things that could be put in place to defend against such attack,
    but it might be possible in an environment that you encounter during a pentest.
  prefs: []
  type: TYPE_NORMAL
- en: One thing to keep in mind is that deleting/modifying logs in an S3 bucket does
    not mean those logs are deleted/modified in CloudTrail Event history, because
    those logs will stay there immutably for 90 days. CloudTrail Event history can
    be difficult to work with due to its speed and limitations, so in a worst-case-scenario
    (where a defender investigates your activity almost immediately), you still buy
    yourself some time before they can properly inspect your activity.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered setting up a CloudTrail Event that follows best
    practices where possible, and also how to audit for the best practices in a target
    environment. CloudTrail is not a perfect service, and we have demonstrated that
    through the use of services that it does not support it is possible to perform
    reconnaissance in an account without ever generating any logs. For this reason,
    it is useful to keep track of what services are unsupported in CloudTrail so that
    you can exploit them as they are released while in a target environment, without
    every showing up in the logs. Cross-account enumeration methods also allow us
    to discover information about our target account without generating logs (in the
    target account), meaning that we can get an understanding of who uses the environment
    and what is used in the environment without making API calls with the compromised
    set of keys. We also showed how we can use Pacu to automate some of our attacks
    on CloudTrail, but also where GuardDuty steps in to try and detect these actions.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will be discussing GuardDuty in more depth, focusing
    on what it detects and flags and how we can bypass those detections beyond what
    we have discussed in this chapter. These bypasses and an understanding of the
    detection methods used by GuardDuty will allow us to attack an environment with
    force, while still staying stealthy.
  prefs: []
  type: TYPE_NORMAL
