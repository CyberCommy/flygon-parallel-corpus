- en: Chapter 2. Machine Learning Best Practices
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章 机器学习最佳实践
- en: 'The purpose of this chapter is to provide a conceptual introduction to statistical
    **machine learning** (**ML**) techniques for those who might not normally be exposed
    to such approaches during their typical required statistical training. This chapter
    also aims to take a newcomer from minimal knowledge of machine learning all the
    way to a knowledgeable practitioner in a few steps. The second part of the chapter
    is focused on giving some recommendations for choosing the right machine learning
    algorithms depending on the application types and requirements. It will then lead
    through some best practices when applying large-scale machine learning pipelines. In
    a nutshell, the following topics will be discussed in this chapter:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目的是为那些在典型的统计培训中可能不会接触到这些方法的人提供统计机器学习（ML）技术的概念介绍。本章还旨在通过几个步骤，将新手从对机器学习的最小知识带到了解的实践者。本章的第二部分侧重于根据应用类型和要求选择合适的机器学习算法的一些建议。然后，它将引导人们在应用大规模机器学习流程时遵循一些最佳实践。简而言之，本章将讨论以下主题：
- en: What is machine learning?
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是机器学习？
- en: Machine learning tasks
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习任务
- en: Practical machine learning problems
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实际机器学习问题
- en: Large scale machine learning APIs in Spark
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spark中的大规模机器学习API
- en: Practical machine learning best practices
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实际机器学习最佳实践
- en: Choosing the right algorithm for your application
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为您的应用选择合适的算法
- en: What is machine learning?
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是机器学习？
- en: In this section, we will try to define the term machine learning from the computer
    science, statistics and data analytical perspectives. Then we will show the steps
    of analytical machine learning applications. Finally, we will discuss some typical
    and emerging machine learning tasks and then name some practical machine learning
    problems that need to be addressed.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将尝试从计算机科学、统计学和数据分析的角度定义机器学习这个术语。然后我们将展示分析机器学习应用的步骤。最后，我们将讨论一些典型和新兴的机器学习任务，并列举一些需要解决的实际机器学习问题。
- en: Machine learning in modern literature
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 现代文献中的机器学习
- en: 'Let''s see how a renowned professor of machine learning, Tom Mitchell, Chair
    of the CMU Machine Learning Department and Professor at the Carnegie Mellon University
    defines the term machine learning in his literature (*Tom M. Mitchell, The Discipline
    of Machine Learning, CMU-ML-06-108, July 2006*, [http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf](http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf)):'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看机器学习著名教授Tom Mitchell是如何定义机器学习这个术语的。他是CMU机器学习系主任，也是卡内基梅隆大学的教授。在他的文献中（*Tom
    M. Mitchell, The Discipline of Machine Learning, CMU-ML-06-108, July 2006*，[http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf](http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf)）中定义了机器学习这个术语：
- en: '*Machine Learning is a natural outgrowth of the intersection of Computer Science
    and Statistics. We might say the defining question of Computer Science is ''How
    can we build machines that solve problems, and which problems are inherently tractable/intractable?''
    The question that largely defines Statistics is ''What can be inferred from data
    plus a set of modelling assumptions, with what reliability?'' The defining question
    for Machine Learning builds on both, but it is a distinct question. Whereas Computer
    Science has focused primarily on how to manually program computers, Machine Learning
    focuses on the question of how to get computers to program themselves (from experience
    plus some initial structure). Whereas Statistics has focused primarily on what
    conclusions can be inferred from data, Machine Learning incorporates additional
    questions about what computational architectures and algorithms can be used to
    most effectively capture, store, index, retrieve and merge these data, how multiple
    learning subtasks can be orchestrated in a larger system, and questions of computational
    tractability.*'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*机器学习是计算机科学和统计学交叉的自然产物。我们可以说，计算机科学的定义性问题是“我们如何构建解决问题的机器，哪些问题本质上是可解的/不可解的？”统计学的定义性问题主要是“在数据加上一组建模假设的情况下，可以推断出什么，以及推断的可靠性是什么？”机器学习的定义性问题建立在这两者之上，但它是一个独特的问题。计算机科学主要关注如何手动编程计算机，而机器学习关注的是如何让计算机自己编程（从经验中加上一些初始结构）。统计学主要关注从数据中可以推断出什么结论，而机器学习还包括关于如何最有效地捕获、存储、索引、检索和合并这些数据的计算架构和算法，以及如何在更大的系统中协调多个学习子任务，以及计算可解性的问题。*'
- en: We believe that this definition from Prof. Tom is self-explanatory. However,
    we will provide some clearer understanding of machine learning in the next two
    sub-sections from the computer science, statistics, and data analytical perspectives.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们相信Tom教授的这个定义是不言自明的。然而，我们将在接下来的两个小节中从计算机科学、统计学和数据分析的角度提供对机器学习的更清晰的理解。
- en: Tip
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 'Interested readers should follow other resources to get more insights about
    machine learning and its theoretical perspective. Here we have provided some links
    as follows: *Machine learning*: [https://en.wikipedia.org/wiki/Machine_learning](https://en.wikipedia.org/wiki/Machine_learning).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 感兴趣的读者应该查阅其他资源，以获取有关机器学习及其理论视角的更多见解。在这里，我们提供了一些链接如下：*机器学习*：[https://en.wikipedia.org/wiki/Machine_learning](https://en.wikipedia.org/wiki/Machine_learning)。
- en: '*Machine learning: what it is and why matters* - [http://www.sas.com/en_us/insights/analytics/machine-learning.html](http://www.sas.com/en_us/insights/analytics/machine-learning.html).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*机器学习：它是什么，为什么重要* - [http://www.sas.com/en_us/insights/analytics/machine-learning.html](http://www.sas.com/en_us/insights/analytics/machine-learning.html)。'
- en: '*A Gentle Introduction To Machine Learning*: [https://www.youtube.com/watch?v=NOm1zA_Cats](https://www.youtube.com/watch?v=NOm1zA_Cats).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*机器学习的初步介绍*：[https://www.youtube.com/watch?v=NOm1zA_Cats](https://www.youtube.com/watch?v=NOm1zA_Cats)。'
- en: '*What is machine learning, and how does it work*: [https://www.youtube.com/watch?v=elojMnjn4kk](https://www.youtube.com/watch?v=elojMnjn4kk).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*什么是机器学习，它是如何工作的*：[https://www.youtube.com/watch?v=elojMnjn4kk](https://www.youtube.com/watch?v=elojMnjn4kk)。'
- en: '*Introduction to Data Analysis using Machine Learning*: [https://www.youtube.com/watch?v=U4IYsLgNgoY](https://www.youtube.com/watch?v=U4IYsLgNgoY).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*使用机器学习进行数据分析入门*：[https://www.youtube.com/watch?v=U4IYsLgNgoY](https://www.youtube.com/watch?v=U4IYsLgNgoY)。'
- en: Machine learning and computer science
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习和计算机科学
- en: Machine learning is a branch of computer science that studies the design of
    algorithms that can learn from its heuristics that typically evolved from the
    study of pattern recognition and computational learning theory in artificial intelligence.
    An interesting question came into the mind of Alan Turing about the machine, which
    is, *Can a machine think?* In fact, there are some good reasons to believe a sufficiently
    complex machine could one day pass the unrestricted Turing test; let's postpone
    this question until the Turing test, but gets passed. However, machines can learn
    at least. Subsequently, Arthur Samuel was the first man who defined the term **machine
    learning** as a f*ield of study that gives computers the ability to learn without
    being explicitly programmed* in 1959\. Typical machine learning tasks are concept
    learning, predictive modeling, classification, regression, clustering, dimensionality
    reduction, recommender system, deep learning and finding useful patterns from
    the large-scale dataset.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是计算机科学的一个分支，研究可以从启发式学习中学习的算法，这通常源自于模式识别和人工智能中的计算学习理论。艾伦·图灵脑海中出现了一个有趣的问题，即*机器能思考吗？*实际上，有一些很好的理由相信一个足够复杂的机器有一天可以通过无限制的图灵测试；让我们推迟这个问题，直到图灵测试通过。然而，机器至少可以学习。随后，阿瑟·塞缪尔是第一个在1959年将术语**机器学习**定义为*一种研究领域，使计算机能够在没有明确编程的情况下学习*的人。典型的机器学习任务包括概念学习、预测建模、分类、回归、聚类、降维、推荐系统、深度学习以及从大规模数据集中找到有用模式。
- en: The ultimate goal is to improve the learning in such a way that it becomes automatic,
    so that no human interactions are needed any more, or the level of human interaction
    is reduced as much as possible. Although machine learning is sometimes conflated
    with **Knowledge Discovery and Data Mining** (**KDDM**), the latter sub-field
    on the other hand focuses more on exploratory data analysis and is known as unsupervised
    learning - such as clustering analysis, anomaly detection, **Artificial Neural
    Networks** (**ANN**), and so on.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 最终目标是通过改进学习方式使其变得自动化，以至于不再需要人类干预，或者尽可能减少人类干预的程度。尽管机器学习有时与**知识发现和数据挖掘**（**KDDM**）混淆，但后者更专注于探索性数据分析，被称为无监督学习
    - 例如聚类分析、异常检测、**人工神经网络**（**ANN**）等。
- en: Other machine learning techniques include supervised learning, where a learning
    algorithm analyzes the training data and produces an inferred function that can
    be used for mapping new examples towards prediction. Classification and regression
    analysis are two typical examples of supervised learning. Reinforcement learning,
    on the other hand, is inspired by behaviorist psychology (see also [https://en.wikipedia.org/wiki/Behaviorism](https://en.wikipedia.org/wiki/Behaviorism)),
    which is is typically concerned with how a software agent performs an action in
    a new *environment* by maximizing the `reward` function. Dynamic programming and
    intelligent agent are two examples of reinforcement learning.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 其他机器学习技术包括监督学习，其中学习算法分析训练数据并生成可用于映射新示例进行预测的推断函数。分类和回归分析是监督学习的两个典型示例。另一方面，强化学习受行为主义心理学（参见[https://en.wikipedia.org/wiki/Behaviorism](https://en.wikipedia.org/wiki/Behaviorism)）的启发，通常关注软件代理如何通过最大化`奖励`函数在新的*环境*中执行动作。动态规划和智能代理是强化学习的两个示例。
- en: Typical machine learning applications can be classified into scientific knowledge
    discovery and more commercial applications, ranging from Robotic or **Human Computer
    Interaction** (**HCI**) to anti-spam filtering and recommender systems.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的机器学习应用可以分为科学知识发现和更多商业应用，从机器人或**人机交互**（**HCI**）到反垃圾邮件过滤和推荐系统。
- en: Machine learning in statistics and data analytics
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 统计学和数据分析中的机器学习
- en: Machine learning reconnoitres the study and construction of algorithms (see
    also [https://en.wikipedia.org/wiki/Algorithm](https://en.wikipedia.org/wiki/Algorithm))
    that can learn (see also [https://en.wikipedia.org/wiki/Learning](https://en.wikipedia.org/wiki/Learning))
    from the heuristics and make meaningful predictions on data. However, in order
    to make data-driven predictions or decisions, such algorithms operate by building
    a model (see also [https://en.wikipedia.org/wiki/Mathematical_model](https://en.wikipedia.org/wiki/Mathematical_model))
    from training datasets, quicker than following a stringently static program or
    instructions. Machine learning is also closely related and often overlaps with
    the nature of computational statistics. Computational statistics is, on the other
    hand, an applied field of statistics that focuses on making predictions through
    a computerised approach. In addition, it has strong stalemates to mathematical
    optimisation, which delivers methods and computing tasks along with theory and
    application domains. The tasks that are not feasible in mathematics due to the
    demands for a strong background knowledge of mathematics, machine learning suits
    best and can be applied as the alternative to that.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是研究和构建算法的学科（参见[https://en.wikipedia.org/wiki/Algorithm](https://en.wikipedia.org/wiki/Algorithm)），这些算法可以从启发式学习（参见[https://en.wikipedia.org/wiki/Learning](https://en.wikipedia.org/wiki/Learning)）并对数据进行有意义的预测。然而，为了进行数据驱动的预测或决策，这些算法通过从训练数据集中构建模型（参见[https://en.wikipedia.org/wiki/Mathematical_model](https://en.wikipedia.org/wiki/Mathematical_model)）来操作，比严格遵循静态程序或指令更快。机器学习也与计算统计学密切相关并经常重叠。另一方面，计算统计学是统计学的一个应用领域，专注于通过计算机化方法进行预测。此外，它与数学优化有着密切的关系，提供了方法和计算任务以及理论和应用领域。由于对数学背景知识的强烈需求，数学中不可行的任务最适合机器学习，并可以作为替代方法应用。
- en: 'Within the field of data analytics, on the other hand, machine learning is
    a method used to devise complex models and algorithms that advance themselves
    towards prediction for a future outcome. These analytical models allow researchers,
    data scientists, engineers, and analysts to produce reliable, repeatable, and
    reproducible results and mine hidden insights through learning from past relationships
    (heuristics) and trends in the data. Again we will refer to a famous definition
    from Prof. Tom, where he explained what learning really means from the computer
    science perspective in the literature (*Tom M. Mitchell, The Discipline of Machine
    Learning, CMU-ML-06-108, July 2006*, [http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf](http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf)):'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，在数据分析领域，机器学习是一种用于设计复杂模型和算法的方法，这些模型和算法朝着预测未来结果的方向发展。这些分析模型允许研究人员、数据科学家、工程师和分析师通过从过去的关系（启发式）和数据中的趋势中学习来产生可靠、可重复和可再现的结果，并挖掘隐藏的见解。我们再次引用Tom教授的著名定义，他在文献中解释了从计算机科学的角度来看学习的真正含义（*Tom
    M. Mitchell, The Discipline of Machine Learning, CMU-ML-06-108, July 2006*, [http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf](http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf)）：
- en: '*A computer program is said to learn from experience E with respect to some
    class of tasks T and performance measure P, if its performance at tasks in T,
    as measured by P, improves with experience E.*'
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*如果一个计算机程序在某类任务T上的表现，根据性能度量P，随着经验E的积累而提高，那么就可以说它在任务T上从经验E中学习。*'
- en: 'Therefore, we can conclude that a computer program or machines can:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以得出结论，计算机程序或机器可以：
- en: Learn from data and histories
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从数据和历史中学习
- en: Can be improved with experience
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以通过经验进行改进
- en: Interactively enhance a model that can be used to predict the outcomes of questions
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交互式地增强模型，以用于预测问题的结果
- en: 'Furthermore, the following diagram helps us to understand the whole process
    of machine learning:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，以下图表帮助我们理解机器学习的整个过程：
- en: '![Machine learning in statistics and data analytics](img/00109.jpeg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![统计学和数据分析中的机器学习](img/00109.jpeg)'
- en: 'Figure 1: Machine learning at a glance.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：一览机器学习。
- en: Typical machine learning workflow
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 典型的机器学习工作流程
- en: 'A typical machine learning application involving several steps from input,
    processing to output that form a scientific workflow is shown in Figure 2\. The
    following steps are involved in typical machine learning applications:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的机器学习应用包括从输入、处理到输出的几个步骤，形成了一个科学工作流程，如图2所示。典型的机器学习应用涉及以下步骤：
- en: Load the sample data.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载样本数据。
- en: Parse the data into the input format for the algorithm.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据解析成算法的输入格式。
- en: Pre-process the data and handle the missing values.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理数据并处理缺失值。
- en: Split the data into two sets, one for building the model (training dataset)
    and one for testing the model (test dataset or validation dataset).
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分成两组，一组用于构建模型（训练数据集），另一组用于测试模型（测试数据集或验证数据集）。
- en: Run the algorithm to build or train your ML model.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行算法来构建或训练您的机器学习模型。
- en: Make predictions with the training data and observe the results.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练数据进行预测并观察结果。
- en: Test and evaluate the model with the test data or alternatively validate the
    model with some cross-validator technique using the third dataset, called the
    validation dataset.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用测试数据测试和评估模型，或者使用第三个数据集（验证数据集）使用交叉验证技术验证模型。
- en: Tune the model for better performance and accuracy.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调整模型以获得更好的性能和准确性。
- en: Scale-up the model so that it can handle massive datasets in the future.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扩展模型，以便将来能处理大规模数据集。
- en: Deploy the ML model in commercialization:![Typical machine learning workflow](img/00069.jpeg)
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在商业化中部署机器学习模型：![典型的机器学习工作流程](img/00069.jpeg)
- en: 'Figure 2: Machine learning workflow.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：机器学习工作流程。
- en: Often the machine learning algorithms have some ways to handle the skewness
    in the datasets; that skewness can sometimes be immensely skewed though. In step
    4, the experimental dataset is split often into a training set and test sets randomly,
    which is called sampling. The training dataset is used to train the model, whereas
    the test dataset is used to evaluate the performance of the best model at the
    very end. The better practice is to use the training dataset as much as you can
    to increase the generalization performance. On the other side, it is recommended
    to use the test dataset only once to avoid the overfitting and underfitting problem
    while computing the prediction error and the related metrics.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，机器学习算法有一些方法来处理数据集中的偏斜；这种偏斜有时可能非常严重。在第4步中，实验数据集通常被随机分成训练集和测试集，这被称为抽样。训练数据集用于训练模型，而测试数据集用于评估最佳模型的性能。更好的做法是尽可能多地使用训练数据集，以提高泛化性能。另一方面，建议只使用测试数据集一次，以避免在计算预测误差和相关指标时出现过拟合和欠拟合问题。
- en: Tip
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Overfitting is a statistical property by which random error and noise is described
    apart from the normal and underlying relationships. It mostly occurs when there
    are too many hyperparameters relative to the number of observations or features.
    Under fitting on the other hand refers to a model that can neither model the training
    data nor generalize to new data towards the model evaluation or adaptability.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合是一种统计特性，描述了除了正常和基础关系之外的随机误差和噪音。当超参数相对于观察值或特征的数量过多时，它通常会发生。另一方面，欠拟合是指既不能对训练数据建模，也不能对新数据进行泛化，以适应模型评估或适应性。
- en: However, these steps consist of several techniques and we will discuss those
    in [Chapter 5](part0043_split_000.html#190862-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 5.  Supervised and Unsupervised Learning by Examples"), *Supervised and
    Unsupervised Learning by Examples* in detail. Step 9 and 10 are usually considered
    as advanced steps, and they consequently will be discussed in later chapters.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这些步骤包括几种技术，我们将在[第5章](part0043_split_000.html#190862-0b803698e2de424b8aa3c56ad52b005d
    "第5章。通过示例进行监督和无监督学习")中详细讨论这些技术。第9步和第10步通常被认为是高级步骤，因此它们将在后面的章节中讨论。
- en: Machine learning tasks
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习任务
- en: 'Machine learning tasks or machine learning processes are typically classified
    into three broad categories, depending on the nature of the learning feedback
    available to a learning system. Supervised learning, unsupervised learning, and
    reinforcement learning; these three kinds of machine learning tasks are shown
    in *Figure 3*, and will be discussed in this section:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习任务或机器学习过程通常根据学习系统可用的学习反馈的性质分为三类。监督学习、无监督学习和强化学习；这三种机器学习任务在*图3*中显示，并将在本节中讨论：
- en: '![Machine learning tasks](img/00112.jpeg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习任务](img/00112.jpeg)'
- en: 'Figure 3: Machine learning tasks.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：机器学习任务。
- en: Supervised learning
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监督学习
- en: A **supervised learning** application makes predictions based on a set of examples,
    and the goal is to learn general rules that map inputs to outputs aligning with
    the real world. For example, a dataset for spam filtering usually contains spam
    messages as well as non-spam messages. Therefore, we could know which messages
    in a training set are spams or non-spams. Nevertheless, we might have the opportunity
    to use this information to train our model in order to classify new and unseen
    messages. Figure 4 shows the schematic diagram of the supervised learning.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**监督学习**应用程序基于一组示例进行预测，其目标是学习将输入映射到与现实世界一致的输出的一般规则。例如，用于垃圾邮件过滤的数据集通常包含垃圾邮件和非垃圾邮件。因此，我们可以知道训练集中哪些消息是垃圾邮件或非垃圾邮件。然而，我们可能有机会使用这些信息来训练我们的模型，以便对新的和未见过的消息进行分类。图4显示了监督学习的示意图。'
- en: 'In other words, the dataset for training the ML model in this case is labeled
    with the value of interest and a supervised learning algorithm looks for patterns
    in those value labels. After the algorithm has found the required patterns, those
    patterns can be used to make predictions for unlabeled test data. This is the
    most popular and useful type of machine learning tasks, which is not an exception
    for Spark as well, where most of the algorithms are a supervised learning technique:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，在这种情况下，用于训练机器学习模型的数据集带有感兴趣的值标签，并且监督学习算法会寻找这些值标签中的模式。算法找到所需的模式后，这些模式可以用于对未标记的测试数据进行预测。这是最流行和有用的机器学习任务类型，对于Spark也不例外，其中大多数算法都是监督学习技术：
- en: '![Supervised learning](img/00122.jpeg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![监督学习](img/00122.jpeg)'
- en: 'Figure 4: Supervised learning in action.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：监督学习实例。
- en: Unsupervised learning
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无监督学习
- en: In **unsupervised learning**, data points have no labels related or in other
    words, the correct classes of the training dataset in unsupervised learning are
    unknown, as shown in *Figure 5*. As a result, classes have to be inferred from
    the unstructured datasets, which implies that the goal of an unsupervised learning
    algorithm is to pre-process the data in some structured ways by describing its
    structure.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在**无监督学习**中，数据点没有相关的标签，或者换句话说，在无监督学习的训练数据集中，正确的类别是未知的，如*图5*所示。因此，类别必须从非结构化数据集中推断出来，这意味着无监督学习算法的目标是通过描述其结构来对数据进行预处理。
- en: To overcome this obstacle in unsupervised learning, clustering techniques are
    used typically to group the unlabeled samples based on certain similarity measures,
    mining hidden patterns towards feature learning. More technically, we can write
    down a generative model, and then tell the data to find parameters that explain
    the data to us. Now what will happen next if we are not satisfied with the possibility
    of this elucidation? The answer is that we should tell the data to do it again
    until we are using some efficient algorithms or techniques.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服无监督学习中的这一障碍，通常使用聚类技术来基于某些相似性度量对未标记的样本进行分组，挖掘隐藏模式以进行特征学习。更技术上地说，我们可以编写一个生成模型，然后告诉数据找到解释数据的参数。现在，如果我们对这种阐释的可能性不满意，接下来会发生什么？答案是，我们应该告诉数据再做一次，直到我们使用一些有效的算法或技术为止。
- en: Now a new question may arise in your mind, why do we have to put labels on the
    data? Or cannot we just appreciate the data in its current order recognizing that
    each datum is unique and pre snowflake? In other words, with a little supervision,
    our data can grow up to be whatever it wants to be! So why should the unlabeled
    data be taken into consideration too?
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可能会产生一个新的问题，为什么我们必须在数据上贴标签？或者我们不能只欣赏当前顺序的数据，认识到每个数据都是独特的，就像雪花一样？换句话说，通过一点监督，我们的数据可以成长为任何它想成为的东西！那么为什么未标记的数据也应该被考虑进来呢？
- en: 'Well, there are some deeper issues regarding this. For example, most of the
    variation in the data comes from phenomena that are irrelevant to our desired
    labeling scheme. A more realistic example would be how Gmail classifies e-mails
    as spam and ham using the supervised learning technique, where the data might
    use its parameters to explain its semantics, when all we care about is its syntactic
    properties:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，关于这个问题还有一些更深层次的问题。例如，数据中的大部分变化来自于与我们所期望的标记方案无关的现象。一个更现实的例子是Gmail如何使用监督学习技术将电子邮件分类为垃圾邮件和正常邮件，其中数据可能使用其参数来解释其语义，而我们关心的只是其句法属性：
- en: '![Unsupervised learning](img/00134.jpeg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![无监督学习](img/00134.jpeg)'
- en: 'Figure 5: Unsupervised learning.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：无监督学习。
- en: Reinforcement learning
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 强化学习
- en: '**Reinforcement learning** is the technique where the model itself learns from
    a series of actions or behaviors. Complexity of datasets or sample complexity
    is very important in the reinforcement learning needed for the algorithms to learn
    a target function successfully. Moreover, in response to each data point for achieving
    the ultimate goal, maximization of the reward function should be ensured while
    interacting with an external environment, as demonstrated in *Figure 6*. To make
    the maximization easier, the reward function can either be exploited by penalizing
    the bad actions or rewarding for the good actions.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to achieve the highest reward, the algorithm should be modified with
    a strategy that also allows the machine or software agent to learn its behavior
    periodically. These behaviors can be learned once and for all, or the machine
    learning model can keep adapting as times passes:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '![Reinforcement learning](img/00143.jpeg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Reinforcement learning.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: For example, reinforcement learning is common in robotics; the algorithm must
    choose the robot's next action based on a set of sensor readings. It is also a
    natural fit for **Internet of Things** (**IoT**) applications, where a computer
    program interacts with a dynamic environment in which it must perform a certain
    goal, without an explicit mentor. Another example is the game **Flappy Bird**,
    which has been trained to play itself.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Recommender system
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A recommender system is an emerging application, which is a subclass of information
    filtering system use for making a prediction of the rating or preference from
    the users that they usually provide to an item. The concept of recommender systems
    has become very common in recent years and subsequently applied in different applications.
    The most popular ones are probably products (for examples, movies, music, books,
    research articles, news, search queries, social tags, and so on). Recommender
    systems can be typed into four categories typically:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative filtering system, where accumulation of a consumer's preferences
    and recommendations to other users is based on likeness in behavioral patterns.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Content-based systems, where the supervised machine learning is used to persuade
    a classifier to distinguish between interesting and uninteresting items for the
    users.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hybrid recommender systems is a recent research and hybrid approach (that is,
    combining collaborative filtering and content-based filtering). Netflix is a good
    example of such a recommendation system that uses **Restricted Boltzmann Machines**
    (**RBM**) and a form of the Matrix Factorization algorithm for large movie databases,
    such as IMDb. This recommendation, which simply recommends movies or dramas or
    streaming by comparing the watching and searching habits of similar users, is
    called rating prediction.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Knowledge-based systems, where knowledge about users and products is used to
    reason what fulfills the user's requirements, using the perception tree, decision
    support systems, and case-based reasoning.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semi-supervised learning
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Between supervised and unsupervised learning, there is a small place for **semi-supervised
    learning**; where the ML model usually receives an incomplete training signal.
    More statistically, the ML model receives a training set with some of the target
    outputs missing. The semi-supervised learning is more or less assumption-based
    and often uses three kinds of assumption algorithms as the learning algorithm
    for the unlabeled datasets. The following assumptions are used: smoothness, cluster,
    and manifold assumption.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: In other words, semi-supervised learning can furthermore be denoted as a **weakly
    supervised** or **bootstrapping** technique for using the hidden wealth of unlabeled
    examples to enhance the learning from a small amount of labeled data. Emerging
    examples include *semi-supervised expectation minimization, and concept learning
    in human cognition and transitive SVMs*.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Practical machine learning problems
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What does machine learning really mean? We already saw some convincing definitions
    of this term as well as the meaning of the term *learning* at the very beginning
    of this chapter. However, the reality is machine learning itself is defined by
    the problems to be resolved. In this section, we will first emphasize the machine
    learning classes and then we will list some well-known and popularly-used examples
    of real world machine learning problems. The typical classes include classification,
    clustering, rule extraction, and regression, which will all be discussed.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习到底是什么意思？我们在本章的开头已经看到了一些令人信服的对这个术语的定义，以及术语“学习”的含义。然而，机器学习本身的定义取决于要解决的问题。在本节中，我们将首先强调机器学习的类别，然后列举一些现实世界中广为人知和广泛使用的机器学习问题的例子。典型的类别包括分类、聚类、规则提取和回归，这些都将被讨论。
- en: In addition, we will also discuss those problems based on the main taxonomy
    of standard machine learning problems. This is important, since knowing the type
    of problems we could face allows us to think about the data we need. Another important
    fact is that before knowing some practical machine learning problems, you might
    face difficulties in having an idea about developing your machine learning applications.
    In other words, to know the problem we need to know the data in the very first
    place. Therefore, the types of algorithm and their optimality to be addressed
    will be discussed throughout this chapter; data manipulation, however, will be
    discussed to dig-down the problems in [Chapter 3](part0031_split_000.html#TI1E2-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 3. Understanding the Problem by Understanding the Data"), *Understanding
    the Problem by Understanding the Data*.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还将讨论基于标准机器学习问题的主要分类法的问题。这很重要，因为了解我们可能面临的问题类型可以让我们考虑我们需要的数据。另一个重要的事实是，在了解一些实际的机器学习问题之前，你可能会在开发机器学习应用程序的想法上遇到困难。换句话说，要知道问题，我们首先需要了解数据。因此，本章将讨论算法的类型及其优化问题；数据处理将在[第三章](part0031_split_000.html#TI1E2-0b803698e2de424b8aa3c56ad52b005d
    "第三章。通过了解数据来理解问题")中进行讨论，*通过了解数据来理解问题*。
- en: Machine learning classes
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习类别
- en: The problem classes we mentioned above are standards for most of the problems
    we refer to in everyday life while doing and applying machine learning techniques.
    However, knowing only the ML classes is not enough we also need to know what type
    of problems machines are learning, since you will find many problems that are
    simply problem solving that does not help a ML model or agent to learn at all.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们上面提到的问题类别是我们在日常生活中使用和应用机器学习技术时所指的大多数问题的标准。然而，仅仅知道机器学习类别是不够的，我们还需要知道机器正在学习什么类型的问题，因为你会发现许多问题只是简单的问题解决，并没有帮助机器学习模型或代理进行学习。
- en: 'When you think a problem is a machine learning problem, more technically, you
    are thinking of a decision problem that needs to be modeled from data that could
    be termed as a machine learning problem. In other words, as a data scientist or
    human expert, if you have enough time to answer a particular question by knowing
    the available dataset, you can more or less apply a suitable machine learning
    problem. Therefore, we can assume that a solvable problem using some ML algorithms
    would have mainly two parts - the data itself, which could be used to point to
    specific observations of the problem, and secondly the quantitative measurement
    of the quality of an available solution. Once you have succeeded in identifing
    a problem as an ML problem, you would probably be able to think about what types
    of problems you could formulate with it easily, or the type of aftermath your
    client will be asking for, or what sorts of requirements are to be satisfied.
    As already stated in the above section, the more frequently used machine learning
    classes are: classification, clustering, regression, and rule extraction. We will
    now provide a short overview of each class.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 当你认为一个问题是一个机器学习问题时，更准确地说，你在考虑一个需要从数据中建模的决策问题，这可以被称为一个机器学习问题。换句话说，作为数据科学家或人类专家，如果你有足够的时间通过了解可用的数据集来回答一个特定的问题，你可以或多或少地应用一个合适的机器学习问题。因此，我们可以假设使用一些机器学习算法可以解决的问题主要有两个部分
    - 数据本身，可以用来指向问题的特定观察结果，以及可用解决方案的质量的定量测量。一旦你成功地将一个问题确定为机器学习问题，你可能能够思考如何轻松地制定出什么类型的问题，或者你的客户将会要求什么样的后果，或者需要满足什么样的要求。正如上面所述，更常用的机器学习类别包括：分类、聚类、回归和规则提取。我们现在将对每个类别进行简要概述。
- en: Classification and clustering
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分类和聚类
- en: If the experimental dataset is labeled, it means a class has been assigned to
    it already. For instance, spam/non-spam during spam e-mail detection or fraud/non-fraud
    during credit card fraud identification. However, if the dataset based on which
    the fundamental decision will be made or modeled is unlabeled, new labels need
    to be made manually or algorithmically. This might be difficult, and can be thought
    of a judgment problem. On the contrary, sculpting the differences or resemblances
    between several groups might be computationally harder.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果实验数据集已经标记，这意味着已经为其分配了一个类别。例如，在垃圾邮件检测中的垃圾邮件/非垃圾邮件，或者在信用卡欺诈识别中的欺诈/非欺诈。然而，如果基本决策的数据集是未标记的，新的标签需要手动或算法地制作。这可能很困难，可以被视为一个判断问题。相反，雕刻出几个群体之间的差异或相似之处可能在计算上更加困难。
- en: Clustering, on the other hand, handles the data that is not labeled or un-labeled.
    However, it still can be divided into groups based on similarity and other measures
    of natural structure in the data you have. Organizing pictures from a digital
    album by faces only without names could be an example, where the human users like
    us have to assign names to groups manually. Again, the same computational complexity
    might arise to label multiple image files manually; we will provide some examples
    in later chapters of how Spark provides several APIs to solve these issues.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，聚类处理的是未标记或无标记的数据。然而，它仍然可以根据相似性和数据中的自然结构的其他度量来分成组。将数字相册中的图片仅按面孔组织起来而不带有姓名可能是一个例子，人类用户必须手动为组分配名称。同样，手动标记多个图像文件可能会产生相同的计算复杂性；我们将在后面的章节中提供一些示例，说明Spark如何提供多个API来解决这些问题。
- en: Rule extraction and regression
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 规则提取和回归
- en: From the given dataset, propositional rules can be generated by means of antecedent
    and consequent in the *if...then* style that defines the behavior of a machine
    learning agent. This type of rule generation technique is commonly referred to
    as *rule extraction*. You might be wondering if such rules might exist, however,
    they are typically not directed. That means the methods used to discover statistically
    meaningful or statistically significant relationships between attributes in your
    data.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 从给定的数据集中，可以通过前提和结论以*if...then*的方式生成命题规则，定义了机器学习代理的行为。这种规则生成技术通常被称为*规则提取*。你可能会想知道这样的规则是否存在，然而，它们通常不是有针对性的。这意味着用于发现数据中属性之间的统计显著或统计相关关系的方法。
- en: An example of rule extraction is the mining association rules between items
    from business oriented transactional databases. Non-technically, a practical example
    could be the discovery of the relationship or association between the purchase
    of beer and diapers, which is illustrative of the desire and opportunity for the
    customers. However, some situation, might arise where some predictions out of
    the rules or data are not necessarily involved directly.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 规则提取的一个例子是在面向业务的事务性数据库中挖掘项目之间的关联规则。非技术上，一个实际的例子可能是发现啤酒购买和尿布购买之间的关系或关联，这说明了顾客的愿望和机会。然而，可能会出现一些预测不一定直接涉及规则或数据的情况。
- en: Now let's talk about the regression where the data is labeled with a real value.
    To be more exact, some floating point value rather than having labels in the data.
    The easiest way to understand an example would be time series data similar to
    the price of a stock or currency that changes over time. In these types of data,
    the regression task is to make a prediction for new and unpredicted data by some
    regression modeling techniques.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们谈谈回归，其中数据带有实际值的标签。更确切地说，一些浮点值而不是数据中的标签。理解一个例子的最简单方法是时间序列数据，类似于股票或货币随时间变化的价格。在这些类型的数据中，回归任务是通过一些回归建模技术对新的和不可预测的数据进行预测。
- en: Most widely used machine learning problems
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最广泛使用的机器学习问题
- en: 'You will find an extensive amount of examples of the use of machine learning
    related problems in daily life, since they solve the difficult parts of the available
    problems that are widely used techniques or algorithms. We often use many desktop
    or web-based applications that solve your problems out of the data even without
    knowing that what underlying techniques have been used. You will be wondered to
    know that many of them actually use widely used machine learning algorithms to
    make your life easier. There are many machine learning problems around. Here we
    will mention some example problems that really represent what machine learning
    is all about:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现在日常生活中使用机器学习相关问题的大量例子，因为它们解决了广泛使用的技术或算法中的困难部分。我们经常使用许多桌面或基于网络的应用程序，即使不知道使用了哪些基础技术，也可以解决你的问题。你会惊讶地发现，其中许多实际上使用了广泛使用的机器学习算法，使你的生活更轻松。周围有许多机器学习问题。在这里，我们将提到一些真正代表机器学习的例子问题：
- en: '**Spam detection or spam filtering**: Given some e-mails in an inbox, the task
    is to identify those e-mails that are spam and those that are non-spam (often
    called ham) e-mail messages. Now the challenging part is to develop an ML application
    that can be applied so that it can identify only the non-spam e-mails to stay
    in the inbox. and move the spam emails to the corresponding spam folder or delete
    them permanently from the email account. A typical example could be what you may
    do while using Gmail manually, but if you have an ML application, that application
    will do it automatically.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**垃圾邮件检测或垃圾邮件过滤**：给定收件箱中的一些电子邮件，任务是识别哪些电子邮件是垃圾邮件，哪些是非垃圾邮件（通常称为正常）电子邮件。现在具有挑战性的部分是开发一个可以应用的ML应用，以便它只能识别非垃圾邮件电子邮件留在收件箱中，并将垃圾邮件移动到相应的垃圾邮件文件夹中，或者永久从电子邮件帐户中删除它们。一个典型的例子可能是在使用Gmail时手动执行的操作，但如果你有一个ML应用程序，该应用程序将自动执行。'
- en: '**Anomaly detection or outlier detection**: The anomaly detection deals with
    the identification of items, events, or observations that are unexpected or non-confirming
    to the expected patterns in a dataset; in other words, the identification of suspect
    patterns. The most common example is network anomaly detection using some machine
    learning applications. Now the challenging task is to develop an ML application
    that can be applied successfully to simply identify the unusual data points from
    the data propagating across the network.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常检测或异常值检测**：异常检测涉及识别数据集中意外或不符合预期模式的项目、事件或观察结果；换句话说，是怀疑模式的识别。最常见的例子是使用一些机器学习应用进行网络异常检测。现在具有挑战性的任务是开发一个可以成功应用于简单识别网络中传播的异常数据点的ML应用。'
- en: '**Credit card fraud detection**: Credit card fraud is very common nowadays.
    Stealing credit card related information from online shopping and using it in
    an illegal way happens in many countries. Suppose you have a transactional database
    for a customer for a particular month. Now the challenging task is to develop
    an ML application to identify those transactions that were made by the customer
    themselves and those done by others illegally.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信用卡欺诈检测：信用卡欺诈现在非常普遍。从网上购物中窃取信用卡相关信息，并以非法方式使用在许多国家都有发生。假设你有一个客户一个月的交易数据库。现在具有挑战性的任务是开发一个机器学习应用程序，以识别客户自己进行的交易和他人非法进行的交易。
- en: '**Voice recognition**: Recognizing a voice and converting it into a corresponding
    text command and later performing some actions, as an intelligent agent does.
    The most widely used applications include Apple Siri, Samsung S-Voice, Amazon''s
    Echo (consumer space), and Microsoft Cortana (especially because Cortana has SDKs
    for extensibility and integration, and so on). Another example would be locking
    or unlocking your smartphone by using the recognised voice.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音识别：识别声音并将其转换为相应的文本命令，然后执行一些操作，就像智能代理一样。最常用的应用包括苹果的Siri，三星的S-Voice，亚马逊的Echo（消费领域）和微软的Cortana（特别是因为Cortana具有用于可扩展性和集成等的SDK）。另一个例子是使用识别的声音来锁定或解锁智能手机。
- en: '**Digit/character recognition**: Suppose you have a handwritten zip code or
    address or message on/inside an envelope, now the task of digit/character recognition
    is to identify and classify the digits or characters for each handwritten character
    that is made by different people. An efficient ML application could help in this
    regard to read and understand handwritten zip codes or characters and sort the
    contents of the envelope by the geographic region, or more technically, by the
    image segmentations.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数字/字符识别：假设你有一个手写的邮政编码、地址或信件，现在数字/字符识别的任务是识别和分类每个不同人写的手写字符的数字或字符。一个高效的机器学习应用可以帮助阅读和理解手写的邮政编码或字符，并按地理区域或更技术上的说法，按图像分割对信封内容进行分类。
- en: '**Internet of Things**: Large-scale sensor data analytics for prediction and
    classification from real-time streamed data. For example, smart living room monitoring
    including water level checking, room temperature checking, home appliances controlling,
    and so on.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 物联网：大规模传感器数据分析，用于实时流数据的预测和分类。例如，智能客厅监控，包括水位检测，室温检测，家用电器控制等。
- en: '**Gaming analytics**: Analytics for sports, games, and console-based gaming
    profiles in order to predict upsell and target in-app purchases and modifications.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 游戏分析：用于预测升级销售和针对应用内购买和修改的体育、游戏和基于控制台的游戏档案分析
- en: '**Face detection**: Given a digital photo album of hundreds or thousands of
    photographs, the task is to identify those photos that resemble a given person.
    An efficient ML application, in this case, could help to organise photos by person.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人脸检测：给定数百或数千张照片的数字相册，任务是识别与给定人相似的照片。在这种情况下，高效的机器学习应用可以帮助按人员组织照片。
- en: '**Product recommendation**: Provided a purchase history of a customer along
    with a large inventory of products, the target is to identify those products that
    the customer will likely be interested in purchasing with an ML system. Business
    and tech giants such as Amazon, Facebook, and Google Plus have this recommended
    feature for the users.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品推荐：根据客户的购买历史和大量的产品库存，目标是识别客户可能有兴趣购买的产品。亚马逊、Facebook和Google Plus等商业和科技巨头为用户提供了这一推荐功能。
- en: '**Stock trading**: Given the current and historical prices for a stock market,
    predict whether stock should be bought or sold in order to profit with the help
    of an ML system.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 股票交易：根据股票市场的当前和历史价格，预测是否应该买入或卖出股票，以便利用机器学习系统获利。
- en: 'The following are some examples of machine learning that are emerging and the
    demands of current research:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些新兴的机器学习示例和当前研究的需求：
- en: '**Privacy preserving data mining**: Mining customer''s purchase rules from
    the maximal frequent pattern and association rules from business oriented retail
    databases to increase purchases in the future'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐私保护数据挖掘：从面向业务的零售数据库中挖掘最大频繁模式和关联规则，以增加未来的购买
- en: '**Author name disambiguation**: Disambiguation performance is evaluated with
    manual verification of random samples of pairs from clustering results from a
    list of authors from a set of given publications'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作者姓名消歧：使用手动验证从给定出版物集合的作者列表的聚类结果中的随机样本来评估消歧性能
- en: '**Recommendation systems**: Recommender system based on click stream data using
    association rule mining'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐系统：基于点击流数据的推荐系统，使用关联规则挖掘
- en: '**Text mining**: Plagiarism checking from a given text corpus for example'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本挖掘：例如，从给定的文本语料库中检查抄袭
- en: '**Sentiment analysis**: A lot of decisions these days are being made by business
    and tech companies based on the opinion of others, and it will be a good place
    to innovate machine learning'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 情感分析：如今很多商业和科技公司的决策都是基于他人的意见，这将是创新机器学习的好地方
- en: '**Speech understanding**: Given an utterance from a user, the target is to
    identify the specific request made by the user. A model of this problem would
    allow a program to understand and make an attempt to fulfill that request. For
    example, iPhone with Siri and Samsung Voice Recorder in meeting mode have this
    feature implemented'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音理解：给定用户的话语，目标是识别用户提出的具体请求。这个问题的模型将允许程序理解并尝试满足该请求。例如，iPhone的Siri和三星的语音记录器在会议模式下都实现了这个功能
- en: Some of these problems are the hardest problems in artificial intelligence,
    natural language processing, and computer vision that can be addressed and solved
    using ML algorithms. Similarly, we will try to develop some ML applications emphasizing
    these problems in upcoming chapters.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Large scale machine learning APIs in Spark
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will describe two key concepts introduced by the Spark machine
    learning libraries (Spark MLlib and Spark ML) and the most widely used implemented
    algorithms that align with the supervised and unsupervised learning techniques
    we discussed in the above sections.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: Spark machine learning libraries
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As already stated, in the pre-Spark era, big data modelers typically used to
    build their ML models using statistical languages such as R, STATA, and SAS. Then
    the data engineers used to re-implement the same model in Java, for example, to
    deploy on Hadoop.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: However, this kind of workflow lacks efficiency, scalability, throughput, and
    accuracy as well as extended execution time.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: 'Using Spark, the same ML model can be re-built, adopted, and deployed, making
    the whole workflow much more efficient, robust, and faster, which allows you to
    provide hands-on insight to increase the performance. The Spark machine learning
    libraries are divided into two packages: Spark MLlib (`spark.mllib`) and Spark
    ML (`spark.ml`).'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Spark MLlib
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'MLlib is Spark''s scalable machine learning library, which is the extension
    of the Spark Core API that provides a library of easy to use machine learning
    algorithms. Algorithms are implemented and written in Java, Scala, and Python.
    Spark provides support for local vectors and matrix data types stored on a single
    machine, as well as distributed matrices backed by one or multiple RDDs:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '| **Spark MLlib** |   |   |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
- en: '| **ML tasks** | **Discrete** | **Continuous** |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
- en: '| Supervised | Classification:Logistic regressionand regularized variantsLinear
    SVMNaïve BayesDecision treesRandom forestsGradient-boosted trees | Regression:Linear
    regressionand regularized variantsLinear least squaresLasso and ridge regressionIsotonic
    regression |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
- en: '| Unsupervised | Clustering:K-meansGaussian matrix**Power iteration clustering**
    (**PIC**)**Latent Dirichlet Allocation** (**LDA**)Bisecting K-meansStreaming K-means
    | Dimensionality reduction, matrix factorization:Principal components analysisSingular
    value decompositionAlternate least square |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
- en: '| Reinforcement | N/A | N/A |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
- en: '| Recommender systems | Collaborative filtering:Netflix recommendation | N/A
    |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
- en: 'Table 1: Spark MLlib at a glance.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '**Legend**: Continuous: making predictions about continuous variables, for
    example, prediction of the maximum temperature for the upcoming days'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Discrete**: Assigning discrete class labels to particular observations as
    outcomes of a prediction, for example, in weather forecasting it could be the
    prediction of a sunny, rainy, or snowy day'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The beauty of Spark MLlib is numerous. For example, the algorithms implemented
    using Scala, Java, and Python are highly-scalable and leverage Spark's ability
    to work with a massive amount of data. They are fast towards designed for parallel
    computing with in-memory based operation, which is 100 times faster compared to
    MapReduce data processing (they also support disk-based operation that is 10 times
    faster than what MapReduce has as normal data processing) using Dataset, DataFrame,
    or **Directed Acyclic Graph** (**DAG**)-based RDD APIs.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: They are also diverse, since they cover common machine learning algorithms for
    regression analysis, classification, clustering, recommender systems, text analytics,
    frequent pattern mining, and they obviously cover all the steps required to build
    scalable machine learning applications.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Spark ML
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Spark ML adds a new set of machine learning APIs to let users quickly assemble
    and configure practical machine learning pipelines on top of Datasets. Spark ML
    targets to offer a uniform set of high-level APIs built on top of DataFrames rather
    than RDDs that help users create and tune practical machine learning pipelines.
    Spark ML API standardizes machine learning algorithms to make the learning tasks
    easier to combine multiple algorithms into a single pipeline or data workflow
    for data scientists.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: 'Spark ML uses the concept of DataFrame (although it''s obsolete in Java but
    still the main programming interface in Python and R), which is introduced in
    the Spark 1.3.0 release from Spark SQL as machine learning Datasets. The Datasets
    hold diverse data types such as columns storing text, feature vectors, and true
    labels for the data. In addition to this, Spark ML also uses the transformer to
    transform one DataFrame into another or vice-versa, where the concept of the estimator
    is used to fit on a DataFrame to produce a new transformer. The pipeline API,
    on the other hand, can restrain multiple transformers and estimators together
    to specify an ML data-workflow. The concept of the parameter was introduced to
    specify all the transformers and estimators to share a common API under an umbrella
    during the development of an ML application:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '| **Spark ML** |   |   |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
- en: '| **ML tasks** | **Discrete** | **Continuous** |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
- en: '| Supervised | Classification:Logistic regressionDecision tree classifierRandom
    forest classifierGradient-boosted tree classifierMultilayer perception classifierOne-vs-Rest
    classifier | Regression:Linear regressionDecision tree regressionRandom forest
    regressionGradient-boosted tree regressionSurvival regression |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
- en: '| Unsupervised | Clustering:K-means**Latent Dirichlet allocation** (**LDA**)
    | Tree Ensembles:Random forestsGradient-boosted Trees |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
- en: '| Reinforcement | N/A | N/A |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
- en: '| Recommender systems | N/A | N/A |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Spark ML at a glance (legend same as Table 1).'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: As shown in table 2, Spark ML also provides several classifications, regression,
    decision trees, and tree ensembles as well as a clustering algorithm implemented
    for developing ML pipelines on top of DataFrames. The optimization algorithm under
    active implementation is called **Orthant-Wise Limited-memory QuasiNewton** (**OWL-QN**),
    which is also an advanced algorithm that is an extension of L-BFGS that can effectively
    handle L1 regularization and elastic net (see also at Spark ML Advanced topic,
    [https://spark.apache.org/docs/latest/ml-advanced.html](https://spark.apache.org/docs/latest/ml-advanced.html)).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Important notes for practitioners
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: However, currently only Pearson's and Spearman's correlation are supported and
    more are to be added in future Spark releases. Unlike the other statistical functions,
    stratified sampling is also supported by Spark and it can be performed on RDDs
    as key-value pairs; however, some functionalities are yet to be added to Python
    developers. Currently there are no reinforcement learning algorithm modules in
    Spark Machine Learning libraries (please refer to *Table 1* and *Table 2*). The
    current implementation of Spark MLlib provides a parallel implementation of FP-growth
    for mining frequent patterns and the association rules. However, you will have
    to customize the algorithm for mining maximal frequent patterns accordingly. We
    will provide a scalable ML application for mining privacy preserving maximal frequent
    pattern in upcoming chapters.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Another fact is that the current implementation of the collaborative based recommendation
    system in Spark does not support the use of real time stream data, however, in
    later chapters we will try to show a practical recommender system based on click
    stream data using association rule mining (see Mitchell, Tom M. *The Discipline
    of Machine Learning*, 2006, [http://www.cs.cmu.edu/](http://www.cs.cmu.edu/).
    CMU. Web. Dec. 2014). However, some algorithms are not available or are yet to
    be added to Spark ML, most notably dimensionality reduction is such an example.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: However, developers can seamlessly combine the implementation of these techniques
    found in Spark MLlib with the rest of the algorithms found in Spark ML as hybrid
    or interoperable ML applications. Spark's neural networks and perception are brain-inspired
    learning algorithms covering multiclass, two-class, and regression problems that
    are not yet implemented in Spark ML APIs.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: Practical machine learning best practices
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will describe some good machine learning practices that
    need to be followed before developing a machine learning application of particular
    interest, as described in *Figure 7*:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '![Practical machine learning best practices](img/00156.jpeg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Machine learning systematic process.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: 'A scalable and accurate ML application demand for following a systematic approach
    to its development from problem definition to presenting results can be summarized
    into four steps: problem definition and formulation, data preparation, finding
    suitable algorithms for machine learning, and finally, presenting the results
    after the machine learning model deployment. Well, these steps can be depicted
    as shown in *Figure 6*.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Best practice before developing an ML application
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The learning of a machine learning system can be formulated as the sum of representation,
    evaluation, and optimisation. In other words, according to Pedro D et al. (Pedro
    Domingos, *A Few Useful Things to Know about Machine Learning*, [https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)):'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '*Learning = Representation + Evaluation + Optimization*'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Taking this formulation into consideration, we will provide some recommendations
    for practitioners before getting into ML application development.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Good machine learning and data science worth huge
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'So what do we need for an effective machine learning applications development?
    We actually need four arsenals before we start developing an ML application; including:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: The data primitives (or the experimental data to be more frank).
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A pipeline synthesis tool (to understand the data and control flow during the
    machine learning steps).
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An effective and robust error analysis tools.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A verification or validation tool (to verify or validate the prediction accuracy
    or performance of the ML model). However, most importantly, without some strong
    theoretical basement with good data science that is worth a huge amount, the whole
    process will be in vain. In fact, many data scientists and machine learning experts
    often quote something like this statement: *if you can pose your problem as a
    simple optimization problem then you is almost done* (see *Data Analytics & R*,
    [http://advanceddataanalytics.net/2015/01/31/condensed-news-7/](http://advanceddataanalytics.net/2015/01/31/condensed-news-7/)).
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That means before you start your machine learning voyage, if you can identify
    if your problem is a machine learning problem, you will be able to find some suitable
    algorithms to develop your ML application altogether. Of course, in practice,
    most machine learning applications can't be changed into simple optimization problems.
    Therefore, it's the duty of a data scientist like you to manage and maintain complex
    datasets. After that, you will have to handle other issues such as the analytical
    problems that evolve when engineering the machine learning pipeline to tackle
    those issues we mentioned earlier.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, the best practice is to use Spark MLlib, Spark ML, GraphX, and Spark
    Core APIs along with the best practice data science heuristics for developing
    your machine learning applications together. Now you might think of getting benefits
    out of it; yes, the benefits are obvious, and they are as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，最佳实践是使用Spark MLlib、Spark ML、GraphX和Spark Core API以及最佳实践的数据科学启发式方法来共同开发您的机器学习应用程序。现在你可能会想从中获益；是的，好处是显而易见的，它们如下：
- en: Built-in distributed algorithms
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内置的分布式算法
- en: In-memory and disk-based data computation and processing
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存和基于磁盘的数据计算和处理
- en: In-memory capabilities for iterative workloads
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迭代工作负载的内存能力
- en: Algorithmic accuracy and performance
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法的准确性和性能
- en: Faster data cleaning, feature engineering and feature selection, training, and
    testing
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更快的数据清理、特征工程和特征选择、训练和测试
- en: Real-time visualization of the predictive results
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测结果的实时可视化
- en: Tuning towards better performance
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朝着更好的性能调整
- en: Adaptability for new datasets
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适应新数据集
- en: Scalability with the increasing datasets
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着数据集的增加而扩展性
- en: Best practice – feature engineering and algorithmic performance
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最佳实践-特征工程和算法性能
- en: In best practice, feature engineering should be considered as one of the most
    important parts of machine learning. The thing is to find a better representation
    of features out of the experimental dataset non-technically. In parallel to this,
    which learning algorithms or techniques are to be used are also important. Parameter
    tuning, of course in addition, however, the final choice is more about  experimentation
    through the ML model you will be developing.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在最佳实践中，特征工程应被视为机器学习中最重要的部分之一。关键是在实验数据集中非技术性地找到特征的更好表示。与此同时，使用哪些学习算法或技术也很重要。参数调整当然也很重要，但最终的选择更多取决于您将要开发的ML模型的实验。
- en: In practice, however, it is trivial to grasp the naive performance baseline
    by means of an **out-of-the-box** method (also referred to as functionality or
    **OOTB** in short, which is a feature of a product of interest that works straight
    away after installing or configuring) and good data pre-processing. Therefore,
    you might be doing it continually in order to know where the baseline is and whether
    this performance is of a satisfactory level or good enough for your requirements.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，通过“开箱即用”方法（也称为功能性或OOTB，是指产品安装或配置后立即可用的功能）和良好的数据预处理，轻松掌握天真的性能基线是微不足道的。因此，您可能会不断地这样做，以了解基线在哪里，以及这种性能是否达到了令人满意的水平或足够满足您的要求。
- en: Once you've trained all of your out-of-the-box methods, it's always recommended
    and is a good idea to try bagging them together. Moreover, in order to solve the
    ML problems, very often you might need to know the reality that computationally
    hard problems (shown in section 2, for example) need either domain-specific knowledge
    or lots of digging down in the data or both. Consequently, the combination of
    a widely accepted feature engineering technique and domain-specific knowledge
    would help your ML algorithm/application/system to solve prediction related problems.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您训练了所有的开箱即用方法，总是建议并且是一个好主意将它们一起尝试。此外，为了解决ML问题，您可能经常需要知道计算上困难的问题（例如第2节中所示）需要领域特定的知识或大量挖掘数据或两者兼而有之。因此，广泛接受的特征工程技术和领域特定知识的结合将有助于您的ML算法/应用/系统解决与预测相关的问题。
- en: In a nutshell, if you have the required dataset and a robust algorithm that
    can take the advantages of the dataset by learning the complex features, it's
    almost guaranteed that you will be successful. Furthermore, sometimes domain experts
    might be wrong in selecting the good features; therefore, incorporation of multiple
    domain experts (problem domain expert), more well-structured data, and ML expertise
    is always helpful.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，如果您拥有所需的数据集和一个强大的算法，可以利用数据集学习复杂的特征，几乎可以保证您会成功。此外，有时领域专家在选择好的特征时可能会出错；因此，多个领域专家（问题领域专家）、更结构化的数据和ML专业知识的整合总是有帮助的。
- en: Last but not least, sometimes it is recommended from our side to consider the
    error rate rather than only the accuracy. For example, suppose an ML system with
    99% accuracy and 50% errors is worse than the one with 90% accuracy but 25% errors,
    for example.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，有时我们建议考虑错误率而不仅仅是准确性。例如，假设一个ML系统的准确率为99%，错误率为50%，比起准确率为90%，错误率为25%的系统更糟糕。
- en: Beware of overfitting and underfitting
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意过拟合和欠拟合
- en: 'A common mistake often made by novice data scientists is subject to the overfitting
    issue that might evolve while building your ML model by hearing without generalizing.
    More technically, if you evaluate your model on the training data instead of test
    or validated data, you probably won''t be able to articulate whether your model
    is overfitting or not. The common symptoms are:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 初学者数据科学家经常犯的一个常见错误是在构建ML模型时受到过拟合问题的影响，这可能是由于听而不是泛化。更具体地说，如果您在训练数据上评估模型而不是测试或验证数据，您可能无法确定您的模型是否过拟合。常见的症状包括：
- en: Predictive accuracy of the data used for training can be over accurate (that
    is, sometimes even 100%)
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于训练的数据的预测准确性可能过高（有时甚至达到100%）
- en: And the model might show a little better compared to the random prediction for
    new data
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并且与新数据相比，模型可能会稍微好一些
- en: 'Sometimes the ML model itself becomes under-fit for a particular tuning or
    data point, which means the model has become too simplistic. Our recommendation
    (like others as well we believe) is as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 有时ML模型本身对特定调整或数据点变得欠拟合，这意味着模型变得过于简单。我们的建议（我们相信其他人也是如此）如下：
- en: Split the dataset into two sets to detect overfitting situations, the first
    one being for training and model selection, called the training set; the second
    one is the test set for evaluating the model stated in place of the ML workflow
    section
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据集分为两组以检测过拟合情况，第一组用于训练和模型选择，称为训练集；第二组是用于评估模型的测试集，取代了ML工作流程部分中所述的模型。
- en: Alternatively, you also could void the overfitting by consuming simpler models
    (for example, linear classifiers in preference to Gaussian kernel SVM) or by swelling
    the regularisation parameters of your ML model (if available)
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 或者，您还可以通过使用更简单的模型（例如，线性分类器优先于高斯核SVM）或通过增加ML模型的正则化参数（如果可用）来避免过拟合。
- en: Tune the model with a correct data value of parameters to avoid both overfitting
    as well as underfitting
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整模型的参数值以避免过拟合和欠拟合
- en: 'Hastie et al. (Hastie Trevor, Tibshirani Robert, Friedman Jerome, *The Elements
    of Statistical Learning: Data Mining, Inference, and Prediction*, Second Edition,
    2009) on the other hand, have recommended splitting the large-scale dataset into
    three sets: Training set (50%), Validation set (25%), and Test set (25%) (roughly).
    They also suggested building the model using the training set and calculating
    the prediction errors using the validation set. The test set was recommended to
    be used to assess the generalization error of the final model.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，Hastie等人（Hastie Trevor，Tibshirani Robert，Friedman Jerome，《统计学习的要素：数据挖掘、推断和预测》，第二版，2009年）建议将大规模数据集分为三组：训练集（50%）、验证集（25%）和测试集（25%）（大致）。他们还建议使用训练集构建模型，并使用验证集计算预测误差。建议使用测试集来评估最终模型的泛化误差。
- en: If the amount of labeled data available during the supervised learning is smaller,
    it is not recommended to split the datasets. In that case, use cross-validation
    or Train split techniques (this will be discussed in [Chapter 7](part0059_split_000.html#1O8H62-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 7. Tuning Machine Learning Models"), *Tuning Machine Learning Models,*
    with several examples). More specifically, divide the data set into 10 parts of
    (roughly) equal size, after that for each of these ten parts, train the classifier
    iteratively and use the 10th part to test the model.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在监督学习期间可用的标记数据量较小，则不建议拆分数据集。在这种情况下，使用交叉验证或训练拆分技术（将在[第7章](part0059_split_000.html#1O8H62-0b803698e2de424b8aa3c56ad52b005d
    "第7章。调整机器学习模型")中讨论，*调整机器学习模型*，并附有几个示例）。更具体地说，将数据集分为大致相等的10部分，然后对这10部分中的每一部分进行迭代训练分类器，并使用第10部分来测试模型。
- en: Stay tuned and combining Spark MLlib with Spark ML
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 保持关注并将Spark MLlib与Spark ML结合使用
- en: The first step of the pipeline designing is to create the building blocks (as
    a directed or undirected graph consisting of nodes and edges) and make a link
    between those blocks. Nevertheless, as a data scientist, you should be focused
    on scaling and optimizing nodes (primitives) too, so that you are able to scale-up
    your application for handling large-scale datasets in the later stage to make
    your ML pipeline consistently perform. The pipeline process will also help you
    to make your model adaptive for new datasets. However, some of these primitives
    might be explicitly defined to particular domains and data types (for example,
    text, images, video, audio, and spatiotemporal).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 管道设计的第一步是创建构建模块（作为由节点和边组成的有向或无向图）并在这些模块之间建立联系。然而，作为数据科学家，您还应专注于扩展和优化节点（基元），以便在后期处理大规模数据集时能够扩展应用程序，使您的ML管道始终保持高性能。管道过程还将帮助您使您的模型适应新数据集。然而，其中一些基元可能会明确定义为特定领域和数据类型（例如文本、图像、视频、音频和时空数据）。
- en: 'And beyond these types of data, the primitives should also be working for the
    general purpose domain statistics or mathematics. The casting of your ML model
    in terms of these primitives will make your workflow more transparent, interpretable,
    accessible, and explainable. A recent example would be the ML-Matrix, which is
    a distributed matrix library that can be used on top of Spark:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些类型的数据之外，基元还应适用于通用领域的统计学或数学。将您的ML模型转换为这些基元的形式将使您的工作流程更加透明、可解释、可访问和可解释。最近的一个例子是ML-Matrix，它是一个可以在Spark之上使用的分布式矩阵库：
- en: '![Stay tuned and combining Spark MLlib with Spark ML](img/00133.jpeg)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![保持关注并将Spark MLlib与Spark ML结合使用](img/00133.jpeg)'
- en: 'Figure 8: Stay tune and interoperate ML, MLlib, and GraphX.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：保持关注并使ML、MLlib和GraphX互操作。
- en: As we already stated in the previous section, as a developer you can seamlessly
    combine the implementation techniques in Spark MLlib along with the algorithms
    developed in Spark ML, Spark SQL, GraphX, and Spark Streaming as hybrid or interoperable
    ML applications on top of RDD, DataFrame, and Datasets, as shown in Figure 8\.
    For example, an IoT-based real-time application could be developed using a hybrid
    model. Therefore, the recommendation here is to stay tuned or synchronized with
    the latest technologies around you for the betterment of your ML application.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前一节中已经提到的，作为开发人员，您可以无缝地将Spark MLlib中的实现技术与Spark ML、Spark SQL、GraphX和Spark
    Streaming中开发的算法结合起来，作为基于RDD、DataFrame和Datasets的混合或可互操作的ML应用程序，如图8所示。例如，可以使用混合模型开发基于物联网的实时应用程序。因此，建议您与您周围的最新技术保持同步，以改进您的ML应用程序。
- en: Making ML applications modular and simplifying pipeline synthesis
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使ML应用程序模块化并简化管道合成
- en: Another good and often used practice when building your ML pipeline is to make
    the ML system modular. Some supervised learning problems can be solved using very
    simple models commonly referred to as generalized linear models. However, it depends
    on the data you will be using and others simply don't.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建ML管道时的另一个常用做法是使ML系统模块化。一些监督学习问题可以使用常称为广义线性模型的非常简单的模型来解决。然而，这取决于您将要使用的数据，有些数据可能不适用于这些模型。
- en: 'Therefore, to conglomerates a series of simple linear binary classifiers, try
    to employ a lightweight modular architecture. This might be at the workflow stems
    or at the algorithms level. The advantages are obvious, since the modular architecture
    of your application handles massive amounts of data flow in a parallel and distributed
    way. Consequently, we suggest you have the three key innovative mechanisms: weighted
    threshold sampling, logistic calibration, and intelligent data partitioning as
    mentioned in the literature (for example, Yu Jin; Nick Duffield; Jeffrey Erman;
    Patrick Haffner; Subhabrata Sen; Zhi Li Zhang, *A Modular Machine Learning System
    for Flow-Level Traffic Classification in Large Networks*, ACM Transactions on
    Knowledge Discovery from Data, V-6, Issue-1, March 2012). The target is to achieve
    scalability and high-throughput while attaining a high accuracy of the predicted
    results from your ML application/system. While primitives can serve as building
    blocks, you still need some other tools that enable users to build ML pipelines.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，要将一系列简单的线性二元分类器合并成一个轻量级的模块化架构。这可能是在工作流程或算法级别。优势是显而易见的，因为应用程序的模块化架构以并行和分布式的方式处理大量数据流。因此，我们建议您采用文献中提到的三种关键创新机制：加权阈值抽样、逻辑校准和智能数据分区（例如，Yu
    Jin；Nick Duffield；Jeffrey Erman；Patrick Haffner；Subhabrata Sen；Zhi Li Zhang，《大型网络中基于流级流量分类的模块化机器学习系统》，ACM数据发现知识交易，V-6，Issue-1，2012年3月）。目标是在实现高吞吐量的同时，实现ML应用/系统预测结果的高准确性。虽然原语可以作为构建块，但您仍需要其他工具来使用户能够构建ML管道。
- en: Subsequently, workflow tools have become more common these days, and such tools
    exist for data engineers, data scientists, and even for business analysts such
    as Alteryx, RapidMiner, Alpine Data, and Dataiku. At this point, we are talking
    about and stressing the business analysts since at the very last phase your target
    customer will be a business company who will value your ML model, right? The latest
    release of Spark comes with Spark ML APIs for building machine learning pipelines
    and making a domain specific language (see [https://en.wikipedia.org/wiki/Domain-specific_language](https://en.wikipedia.org/wiki/Domain-specific_language))
    for pipelines.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，工作流程工具如今变得更加普遍，这些工具适用于数据工程师、数据科学家，甚至适用于业务分析师，如Alteryx、RapidMiner、Alpine Data和Dataiku。在这一点上，我们谈论并强调业务分析师，因为在最后阶段，您的目标客户将是一家重视您的ML模型的商业公司，对吧？Spark的最新版本配备了用于构建机器学习管道的Spark
    ML API，并制定了领域特定语言（参见[https://en.wikipedia.org/wiki/Domain-specific_language](https://en.wikipedia.org/wiki/Domain-specific_language)）用于管道。
- en: Thinking of an innovative ML system
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 思考一个创新的ML系统
- en: However, in order to develop the algorithms to learn the ML models continuously
    with the help of available data, the viewpoint behind the machine learning is
    to automate the creation of analytical models. Unremittingly evolving models produce
    increasingly positive results and reduce the need for human interaction. This
    enables the ML models to automatically produce reliable and repeatable predictions.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为了开发算法以利用可用数据持续学习ML模型，机器学习背后的观点是自动化分析模型的创建。不断发展的模型产生越来越积极的结果，并减少了对人类干预的需求。这使得ML模型能够自动产生可靠且可重复的预测。
- en: More technically, suppose you are planning to develop a recommender system using
    ML algorithms. So, what is the target of developing that recommender system? And
    what are some innovative ideas for product development in machine learning? These
    two are typical questions that should be considered before you start developing
    your ML application or system. Consistent innovation might be challenging, especially
    when stirring advancing with new ideas, it can also be tough to comprehend where
    the greatest benefit lies. Machine learning can provision innovation from end
    to end of a variety of paths, such as determining weaknesses with current products,
    predictive analysis, or identifying previously concealed patterns.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，假设您计划使用ML算法开发推荐系统。那么，开发该推荐系统的目标是什么？在机器学习产品开发方面有哪些创新的想法？这两个问题在您开始开发ML应用程序或系统之前应该考虑。持续的创新可能具有挑战性，特别是在推动新想法的同时，理解最大利益所在也可能很困难。机器学习可以通过各种途径提供创新，例如确定当前产品的弱点、预测分析或识别以前隐藏的模式。
- en: 'As a result, you will have to think of large-scale computing to train your
    ML model offline, and later on your recommender system has to be able to work
    as a conventional search engine analysis for online recommendations. Thus, your
    ML application will be valued by a business company if your system:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，您将不得不考虑大规模计算来离线训练您的ML模型，随后您的推荐系统必须能够像传统的搜索引擎分析一样进行在线推荐。因此，如果您的系统：
- en: Can forecast buying items using your machine learning application
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用您的机器学习应用程序预测购买商品
- en: Can do product analysis
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以进行产品分析
- en: Can work as an emerging trend in production
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以作为生产中的新趋势
- en: Thinking and becoming smarter about Big Data complexities
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 思考并变得更加聪明，以应对大数据的复杂性
- en: As shown in Figure 9, new business models are the unavoidable extension of the
    available data utilisation, so consideration of big data and its business values
    can make the business analyst's job, life and thinking smarter, which results
    in your targeted company delivering value to customers. In addition to this, you
    will also have to investigate (analyze to be more exact) rival or better companies.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 如图9所示，新的商业模式是可利用数据的不可避免的延伸，因此考虑大数据及其商业价值可以使业务分析师的工作、生活和思维更加智能，从而使您的目标公司为客户提供价值。除此之外，您还需要调查（更准确地说是分析）竞争对手或更好的公司。
- en: Now the question is, how do you collect and use enterprise data? Big data is
    not only about the size (volume), it is also related to its velocity, veracity,
    variety, and value. For these types of complexities, for example, velocity can
    be addressed using Spark Streaming since streaming-based data is also big data
    that needs a real-time analytical approach. Other parameters such as volume and
    variety can be handled using Spark Core and Spark MLlib/ML towards big data processing.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: 'Well, you will have to manage the data by hook or by crook. If you are able
    to manage the data, the insights from the data can really shake up the way businesses
    operate with the useful features of big data:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '![Thinking and becoming smarter about Big Data complexities](img/00013.jpeg)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Machine learning in Big Data best practice.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, data alone is not enough (see Pedro Domingos, *A Few Useful
    Things to Know about Machine Learning,* [https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)),
    but extracting meaningful features from the data and putting semantics of data
    into the model is more important. This is like what most of the tech giants such
    as LinkedIn are developing through large-scale machine learning frameworks from
    feature targeting for their community, which is more or less a supervised learning
    technique. The workflow is as follows:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Fetch the data, extract the feature, and set the target
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature and target join
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a snapshot from the concatenated data
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Partition the snapshot into two parts: training set and test set'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From the training set, prepare the sample data by sampling techniques
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Train the model using the sampled data
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scoring
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluate the model from the previously developed persistent model, as well as
    the test data prepared in step 4
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the best model is found
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploy the model for the target audience
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So what's next? Your model also should be adaptable to large-scale dynamic data
    such as real-time streaming IoT data PLUS real-time feedback is also important
    so that your ML system can learn from the mistakes. The next sub-section discusses
    that.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: Applying machine learning to dynamic data
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The reasons are obvious, since machine learning brings concrete and dynamic
    aspects to IoT projects. Recently, machine learning has experienced a pep talk
    in popularity amongst industrial companies and they profit out of the box. As
    a result, all but every IT vendor are precipitously announcing IoT platforms and
    consulting services. But achieving financial benefits through IoT data is not
    an easy job. Moreover, many businesses have failed to clearly determine what areas
    will change with the implementation of an IoT strategy.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: Considering these positive and negative issues together, your ML model should
    adapt to large dynamic data since the large-scale data means billions of records,
    large feature spaces, and low positive rates from the sparsity issue. Nevertheless,
    data is dynamic so consequently, the ML models have to be adaptive enough; otherwise
    you will have to face a bad experience or be lost in the black hole.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Best practice after developing an ML application
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The typical steps that are best practice after an ML model/system has been
    developed are: visualization for understanding the predictive values, model validation,
    error and accuracy analysis, model tuning, model adapting, and scaling up for
    handling large-scale datasets with ease.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: How to enable real-time ML visualization
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Visualization provides an interactive interface to stay tune the ML model itself.
    Therefore, without visualizing the predictive results, it merely becomes difficult
    to further improve the performance of an ML application. The best practice could
    be something like this:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: Incorporate some third-party tools along with GraphX for your visualization
    for large-scale graph related data (more to be discussed in *[Chapter 9](part0073_split_000.html#25JP22-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 9.  Advanced Machine Learning with Streaming and Graph Data")*, *Advanced
    Machine Learning with Streaming and Graph Data*)
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For non-graph data, a call-back interface for the Spark ML algorithm to send
    and receive messages by incorporating other tools like Apache Kafka:'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Algorithms decide when and what message to send
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Algorithms don't care how the message is delivered
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A task channel to handle the message delivery service from the Spark Driver
    program to Spark Client or Spark cluster nodes. The task channel would be communicating
    using Spark Core at a lower level of abstraction:'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It does not care about the content of the message or recipient of the message
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The message is delivered from Spark Client to the browser or visualization
    client:'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We recommend using HTML5 **Server-Sent Events** (**SSE**) and HTTP Chunked Response
    (PUSH) together. Incorporation of Spark with this type of technology will be discussed
    in [Chapter 10](part0079_split_000.html#2BASE2-0b803698e2de424b8aa3c56ad52b005d
    "Chapter 10.  Configuring and Working with External Libraries"), *Configuring
    and Working with External Libraries*
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pull is possible; however, it requires a message queue
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualization using JavaScript frameworks such as `Plot.ly` (please refer to
    [https://plot.ly/](https://plot.ly/)) and `D3.js` (please refer to [https://d3js.org/](https://d3js.org/))
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do some error analysis
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As algorithms become more prevalent, we need better tools for building complex
    hitherto, robust, and stable machine learning systems. A popular distributed framework
    like Apache Spark takes these ideas to extremely large datasets for the wider
    audience. Therefore, it would be better if we could bind approximation errors
    and convergence rates for the layered pipelines.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Assuming we can compute error bars for nodes, the next step would be to have
    a mechanism for extracting error bars for these pipelines. However, in practice,
    when the ML model is deployed for the production, we might need tools to confirm
    that the pipeline will work and will not do make malfunction or stop halfway through and
    that it can provide some expected measure of the errors.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: Keeping your ML application tuned
  id: totrans-248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Devising one or two algorithms that perform solidly well on a simple problem
    can be considered as a good kick-off. However, sometimes you may be thirsty to
    get the best accuracy, by even sacrificing your valuable time and available computational
    resources. This would be a smarter way, and it will help you not only to squeeze
    out extra performance, but also to improve the results in terms of accuracy that
    you were receiving out of the machine learning algorithms you designed previously.
    In order to do that, when you tune the model and related algorithm, essentially,
    you must have a high confidence in the results.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, those results will be available after you specify the testing and
    validation. This means you should only be using those techniques that reduce the
    variance of the performance measure so that you can assess the algorithms that
    are running more smoothly.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: 'In parallel, like most data practitioners, we also suggest you to use the cross-validation
    technique (also often called rotation estimation) with a reasonably high number
    of folds (that is, K-fold cross-validation, where a single subsample is used as
    the validation dataset for testing the model itself , and the remaining K-1 subsamples
    are used to train the data). Although the exact number of folds, or K, depends
    on your dataset, however, 10-fold cross-validation is commonly used, but most
    often the value of K remains unfixed. We will mention three strategies here that
    you will need to tune your machine learning model:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '**Algorithm tuning**: Makes your machine learning algorithm parameterized.
    After that, adjust the value of those parameters (if they have multiple parameters)
    to influence the outcome of the overall learning process.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ensembles**: Sometimes it is good to be naïve! Therefore, in order to get
    improved results, keep trying to combine the outcomes from multiple machine learning
    methods or algorithms.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Extreme feature engineering**: If your data has complex and multi-dimensional
    structures embedded in it, ML algorithms know how to find and exploit it to make
    decisions.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keeping your ML application adaptive and scale-up
  id: totrans-255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As shown in Figure 10, the adaptive learning conglomerates the previous generations
    of rule-based, simple machine learning, and deep learning approaches to machine
    intelligence according to Rob Munro:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: '![Keeping your ML application adaptive and scale-up](img/00026.jpeg)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Four generation of machine intelligence (Figure courtesy of Rob
    Munro).'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: 'The fourth generation of machine learning: adaptive learning, (`http://idibon.com/the-fourth-generation-of-machine-learning-adaptive-learning/#comment-175958`).'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: 'Research also shows that adaptive learning is 95% accurate in predicting people''s
    intention to purchase a car, for example (please refer to Rob Munro, *The fourth
    generation of machine learning: Adaptive learning*, `http://idibon.com/the-fourth-generation-of-machine-learning-adaptive-learning/#comment-175958`).
    Moreover, if your ML application is adaptive with the new environment and new
    data, it is expected that if enough infrastructure is provided, your ML system
    can be scaled-up for the increasing data loads.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the right algorithm for your application
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*What machine learning algorithm should I use?* is a very frequently asked
    question for the Naive machine learning practitioners, but the answer is always
    i*t depends on*. More elaborately:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: It depends on the volume, quality, complexity, and the nature of the data that
    has to be tested/used
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It depends on external environments and parameters such as your computing system's
    configuration or underlying infrastructures
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It depends on what you want to do with the answer
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It depends on how the mathematical and statistical formulation of the algorithm
    was translated into machine instructions for the computer
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And it depends on how much time you have
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Figure 11* provides a complete work-flow for choosing the right algorithm
    for your ML problem. However, note that some tricks might not work-flow depending
    upon data and problem types:![Choosing the right algorithm for your application](img/00039.jpeg)'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Figure 11: A work-flow for choosing the right algorithm'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: 'The reality is, even the most experienced data scientists or data engineers
    can''t give a straight recommendation about which ML algorithm performs best before
    trying them all together. Most of the statements of agreement/disagreement begins
    with *It depends on...hmm...*Habitually, you might be contemplative if there are
    cheat sheets of machine learning algorithms and if so, how to use that cheat sheet.
    Several data scientists we talked to said that the only sure way to find the very
    best algorithm is to try all of them; therefore, there is no shortcut dude! Let''s
    make it clear, suppose you do have a set of data and you want to do some clustering.
    Thus, technically, this could be classification or regression if your data is
    labeled/unlabeled or values or training set data. Now, the first concern that
    evolves in your mind is:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: Which factors should I consider before choosing an appropriate algorithm? Or
    should I just choose an algorithm randomly?
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do I choose any data pre-processing algorithm or tools that can be applied
    to my data?
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What sort of feature engineering techniques should I be using to extract the
    useful features?
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What factors can improve the performance of my ML model?
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can I adopt my ML application for new data types?
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can I scale-up my ML application for large-scale datasets? And so on.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will always expect the best answer that is much more justified and explains
    everything that someone should consider. In this section, we will try to answer
    these questions with our little machine learning knowledge.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: Considerations when choosing an algorithm
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The recommendation or suggestions we are providing here are for the novice
    data scientist with learner machine learning to expert data scientists who are
    trying to choose an optimal algorithm to start with the Spark ML APIs. That means,
    it makes some overviews and oversimplifications, but it will point you in a safe
    direction, believe us! Suppose you are planning to develop an ML system to answer
    the following question based on the rule:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '`IF` feature X has property Z `THEN` do Y'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Affirmatively, there should be such rules:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: IF X `THEN` it is sensible to try Y using property Z and avoid W
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, what is sensible and what is not depends on:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: Your application and the expected complexity of the problem.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Size of the data set (that is, how many rows/columns, how many independent cases).
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is your dataset labeled or unlabeled?
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Type of data and the kind of measurement, since different nature of data suggests
    a different order or structure, right?
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And obviously in practice your experience in applying different methods efficiently
    and intelligently.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Moreover, if you want to have a general answer to a general problem, we recommend
    the Elements of Statistical Learning (Hastie Trevor, Tibshirani Robert, Friedman
    Jerome, *The Elements of Statistical Learning: Data Mining, Inference, and Prediction*,
    Second Edition, 2009) for a fresh start. Nevertheless, we also recommend going
    with the following algorithmic properties that:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: Show excellent accuracy
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have fast training times
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And the use of linearity
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accuracy
  id: totrans-293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Getting the most accurate results from your ML application isn't always indispensable.
    Depending on what you want to use it for, sometimes an approximation is adequate
    enough. If the situation is something like this, you may be able to reduce the
    processing time drastically by incorporating the better-estimated methods. When
    you are familiar with the workflow with the Spark machine learning APIs, you will
    enjoy the advantage of having more approximation methods, because those approximation
    methods will tend to avoid the overfitting problem out of your ML model automatically.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: Training time
  id: totrans-295
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The execution time requires finishing the data preprocessing or building the
    model and varies a great deal across different algorithms, the inherited complexities,
    and of course the robustness. The training time is often closely related to the
    accuracy. In addition, often you will discover that some of the algorithms you
    will be using are elusive to the number of data points compared to others. However,
    when your time is sufficient and especially when the dataset is larger, for doing
    all the formalities, it can get-up-and-go the choice of algorithm. Therefore,
    if you are concerned particularly with the time, try to sacrifice the accuracy
    or performance and use a simple algorithm that fulfils your minimum requirements.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: Linearity
  id: totrans-297
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are many machine learning algorithms developed recently that make use
    of linearity (also available in the Spark MLlib and Spark ML). For example, the
    linear classification algorithms allow classes to be separated by plotting a differentiating
    straight line or otherwise by the higher-dimensional equivalents of the datasets.
    A linear regression algorithm, on the other hand, assumes that data trends follow
    a simple straight line. This assumption is not naive for some machine learning
    problems; however, there might be some other cases where the accuracy will be
    down. Despite their hazards, linear algorithms are very popular for the data engineers
    or data scientists as the first line of the outbreak. Moreover, these algorithms
    also tend to be algorithmically simple and fast to train your models during the
    whole process.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: Talking to your data when choosing an algorithm
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You will find many machine learning datasets available for free here at [http://machinelearningmastery.com/tour-of-real-world-machine-learning-problems/](http://machinelearningmastery.com/tour-of-real-world-machine-learning-problems/)
    or at the UC Irvine Machine Learning Repository (at [http://archive.ics.uci.edu/ml/](http://archive.ics.uci.edu/ml/)).
    The following data properties should also be placed first:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: Number of parameters
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of features
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Size of the training dataset
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of parameters
  id: totrans-304
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Parameters or data properties are the handholds for a data scientist like you
    that gets to turn when setting up an algorithm. They are numbers that affect the
    algorithm's performance, such as error tolerance or the number of iterations,
    or options between variants of how the algorithm acts. The training time and accuracy
    of the algorithm can sometimes be quite sensitive to getting the right settings.
    Typically, algorithms with a large number of parameters require trial and error
    to find an optimal combination.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: Despite the fact that this is a great way to span the parameter space, the model
    building or training time increases exponentially with the increased number of
    parameters. This is a dilemma as well as a time-performance trade-off. The positive
    sides are having many parameters characteristically indicates greater flexibility
    of the ML algorithms. And secondly, your ML application achieves much better accuracy.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: How large is your training set?
  id: totrans-307
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If your training set is smaller, high bias with low variance classifiers such
    as Naive Bayes have an advantage over low bias with high variance classifiers
    such as kNN. Therefore, the latter will over fit. But low bias with high variance
    classifiers, on the other hand, start to win out as your training set grows linearly
    or exponentially since they have lower asymptotic errors. This is because high
    bias classifiers aren't powerful enough to provide accurate models. You can also
    think of this as a trade-off between generative models versus discriminative model
    distinction.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: Number of features
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For certain types of experimental datasets, the number of extracted features
    can be very large compared to the number of data points itself. This is often
    the case with genomics, biomedical, or textual data. A large number of features
    can swamp some learning algorithms, making training time ridiculously high. Support
    vector machines are particularly well suited in this case for its high accuracy,
    nice theoretical guarantees regarding overfitting, and an appropriate kernel.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: Special notes on widely used ML algorithms
  id: totrans-311
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will provide some special notes for the most commonly used
    machine learning algorithm or techniques. The techniques we will emphasis are
    logistic regression, linear regression, recommender system, SVM, decision tree,
    random forest, Bayesian method and decision forests, decision jungles, and variants. Table
    3 shows the pros and cons of some widely used algorithms including where and when
    to chose these algorithms.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: '| **Algorithm** | **Pros** | **Cons** | **Better at** |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
- en: '| **Linear regression (LR)** | Very fast and often runs in a constant timeEasy
    to understand the modellingLess prone to overfitting and underfitting Intrinsically
    simpleVery fast so less model building timeLess prone to overfitting and underfittingHas
    low variance | Often unable for complex data modellingOften unable to conceptualize
    the nonlinear relationships without transforming the input DatasetNot suitable
    for complex modellingWorks better with only single decision boundary Requires
    large sample size to achieve stable resultsHigh bias | Numerical dataset with
    large collection of featuresWidely used in biological, behavioral and social sciences
    to predict possible relationships among variablesWorks well for numerical as well
    as categorical variablesUsed in various fields, including the medical and social
    sciences |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
- en: '| **Decision trees (DT)** |  Less model building and prediction timeRobust
    against the noise and missing valuesHigh accuracy | Interpretation is hard with
    large and complex treesDuplication may occur within the same sub-treePossible
    issues with diagonal decision boundaries |  Targeting high accurate classificationMedical
    diagnosis and prognosisCredit risk analytics |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
- en: '| **Neural networks (NN)** |  Extremely powerful and robustCapable of modelling
    very complex relationshipsCan be working without knowing the underlying data |
    Highly overfitting and underfitting proneHigh training and prediction timeComputationally
    expensive requiring significant computing powerModel is not readable or reusable
    |  Image processingVideo processingHuman-intelligenceRoboticsDeep learning |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
- en: '| **Random forest (RF)** | Good for bagged treesLow varianceHigh accuracyCan
    handle the overfitting problem | Not as easy to visually and interpretHigh training
    and prediction time | When dealing with multiple features which may be correlatedBiomedical
    diagnosis and prognosisCan be applied both for classification and regression |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
- en: '| **Support vector machines (SVM)** | High accuracy | Susceptible to overfitting
    and underfittingNo numerical stabilityComputationally expensive requiring large
    computing power | Image classificationHandwriting recognition |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
- en: '| **K-nearest neighbors (K-NN)** | Simple and powerfulLazy training involvedCan
    be applied for both multiclass classification and regression | High training and
    prediction timeNeed to have accurate distance functionLow performance with high
    dimensional dataset | Low-dimensional datasetsAnomaly detection like outlier detectionFault
    detection in semiconductorGene expressionProtein-protein interaction |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
- en: '| **K-means** | Linear execution timePerform better than hierarchical clusteringExcellent
    with hyper-spherical  clusters | Repeatable and lack consistencyRequires prior
    knowledge of K | Is not a good choice if the natural clusters occurring in the
    dataset are non-sphericalGood for large dataset |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
- en: '| **Latent Dirichilet Allocation (LDA)** | Can be applied for large-scale text
    datasetsCan overcome the overfitting problem of pLSACan be applied for both document
    classification and clustering through topic modelling | Cannot be applied with
    high dimensional and complex texts databasesRequires the specification of the
    number of topicsCannot find the granularity at optimum levelHierarchical Dirichlet
    Process (HDP) is the better choice | Document classification and clustering through
    topic modelling from large-scale text datasetCan be applied in NLP and other text
    analytics |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
- en: '| **Naive Bayes (NB)** | Computationally fastSimple to implementWorks well
    with high dimensionsCan handle missing valuesIs adaptable since the model can
    be modified with new training data without rebuilding the model | Relies on independence
    assumption so performs badly if the assumption does not metRelatively low accuracy
    | When data has lots of missing valuesDependencies of features from each other
    are similar between featuresSpam filtering and classificationClassifying a news
    article about technology, politics, or sportsText mining |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
- en: '| **Singular Value decomposition (SVD) and Principal Component Analysis (PCA)**
    | Reflects the real intuitions about the dataAllows estimation probabilities in
    high-dimensional dataDramatic reduction in size of dataBoth are based on strong
    linear algebra | Too expensive for many applications like Twitter and web analyticsDisastrous
    for task with fine-grained classesNeed proper understanding of the linearityOften
    complexity is cubicComputationally slower | SVD is applied for low-rank matrix
    approximation, image processing, bioinformatics,  signal processing,  NLPPCA is
    used for interest rate derivatives portfolios, neuroscience and so onBoth are
    suitable for the dataset having high dimension and multivariate data |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
- en: 'Table 3: Pros and cons of some widely used algorithms'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression and linear regression
  id: totrans-325
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Logistic regression is a powerful tool developed around the globe for its two-class
    and multiclass classification since it's fast as well as simple. The fact is that
    it uses an *S*-shaped curve instead of a straight line. making it a natural fit
    for partitioning data into groups. It provides linear class boundaries, so that
    when you use it, make sure a linear approximation is something you can survive
    with. Unlike the decision trees or SVMs, you also have a nice probabilistic interpretation,
    so you will be able to update your model to adapt for new datasets easily.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the recommendation is, use it if you want to have a flavor of probabilistic
    framework or if you expect to receive more training data in the future to be incorporated
    into your model. As mentioned previously, linear regression fits a line, plane,
    or hyperplane to the dataset. It's a workhorse, simple and fast, but it may be
    overly simplistic for some problems.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: Recommendation systems
  id: totrans-328
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We already talked about the accuracy and performance issues of mostly used ML
    algorithms and tools. However, beyond the accuracy research on recommender systems
    is concern about finding another environmental factor or/and parameter diversity.
    Therefore, a recommendation system with good accuracy and higher intra-list diversity
    will be the winner. As a result, your product will be precious to your target
    customers. It would be, however, more effective to let the users re-rate the items,
    rather than showing new items only. If your clients have some extra requirements
    that need to be fulfilled, such as privacy or security, your system has to be
    able to deal with the privacy related issues.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: This is particularly important because customers have to provide some personal
    information as well, so it is recommended not to expose that sensitive information
    publicly.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: Building user profiles using some robust techniques or algorithms such as collaborative
    filtering, on the other hand, could be problematic from the privacy perspective.
    Moreover, research in this area has found that user demographics information may
    influence how satisfied the other users are with recommendations (see also in
    Joeran Beel, Stefan Langer, Andreas Nürnberger, Marcel Genzmehr, *The Impact of
    Demographics (Age and Gender) and Other User Characteristics on Evaluating Recommender
    Systems*. In Trond Aalberg and Milena Dobreva and Christos Papatheodorou and Giannis
    Tsakonas and Charles Farrugia. *Proceedings of the 17th International Conference
    on Theory and Practice of Digital Libraries, Springer, pp. 400-404, Retrieved
    1 November 2013*).
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: Although the serendipity is a crucial measure of how surprising the recommendations
    are, ultimately trust needs to be built using the recommender system. This can
    be made possible by explaining how it generates the recommendations, and why it
    recommends an item even with little demographic information, from the user.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, if the user does not trust the system at all, they will not provide
    any demographic information or will not re-rate the items. A SVMs, according to
    *Cowley et al*. (G. C. Cawley and N. L. C. Talbot, *Over-fitting in model selection
    and subsequent selection bias in performance evaluation, Journal of Machine Learning
    Research, vol. 11, pp. 2079-2107, July 2010*), there are several advantages of
    Support Vector Machines:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: You can tackle the problem of the over-fitting problem since SVMs provide you
    with a regularization parameter
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SVM use the kernel trick that helps to build the machine learning model via
    engineering the kernel with ease
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An SVM algorithm is developed, designed, and defined based on a convex optimization
    problem, therefore, there is no concept of local minima
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is a ballpark figure to a bound on the test error rate, where there is a
    significant and well-studied theory that works
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These promising features of SVM really would help you, and it is suggested
    that it should be used frequently. On the other hand, the cons are:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: The theory only can really cover determination of the parameters for a given
    value of the regularization and kernel parameters. Therefore, you could only choose
    the kernel.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There might be a worse scenario as well, where the kernel model itself can be
    quite sensitive to over-fitting during the model selection criterion.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision trees
  id: totrans-341
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Decision trees are cool because of their usability they are easy to interpret
    and explain the machine learning problem around. In parallel, they can easily
    be handled for the feature related interactions. Most importantly, they are often
    non-parametric. Therefore, even if you are an ordinary data scientist with limited
    working proficiencies, you don''t need to be worried about the issues such as
    outliers, parameter setting, and tuning. Sometimes fundamentally, you can relay
    with the decision trees so that they will make your stress for handling issue
    of the data linearity, or more technically, whether your data is linearly separable
    or not, you need not be worried. On the contrary, there are some cons as well.
    For example:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, the decision tree will not be suitable, sometimes they don't
    support online learning for real-time datasets. In that case, you have to rebuild
    your tree when new examples or datasets come; more technically, gaining model
    adaptability would not be possible.
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Secondly, if you are not aware, they will easily become over-fitting.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random forests
  id: totrans-345
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Random forests are quite popular and are a winner for the data scientist, since
    they are divine for a package with plenty of classification problems. They are
    usually slightly ahead of SVMs in terms of usability and have faster operation
    for most of the classification problems. In addition to this, they are also scalable
    when increasing the datasets you have available. In parallel, you don't need to
    be worried about tuning a cluster of parameters. On the contrary, you need to
    take care of many parameters and tuning when handling your data.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: Decision forests, decision jungles, and variants
  id: totrans-347
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Decision forests, decision jungles, and boosted decision trees are all based
    on decision trees, a foundational machine learning concept that is less used.
    There are many variants of decision trees are there; nonetheless, they all do
    the same thing, which is subdividing the feature space into regions with the same
    label. In order to avoid the over-fitting problem, a large set of trees are constructed
    with mathematical and statistical formulations, where the trees are not correlated
    at all.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: The average of this is referred to as a decision forest; which is a tree that
    avoids the overfitting problem as stated earlier. However, the disadvantage is
    that decision forests can use a lot of memory. Decision jungles, on the other
    hand, are a variant that consume less memory by sacrificing a slightly longer
    training time. Fortunately, the boosted decision trees avoid overfitting by limiting
    the number of subdivision and the number of permitted data points in each region.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian methods
  id: totrans-350
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When the experimental or sample dataset size is large, the Bayesian method often
    provides results for parametric models that are very similar to the results produced
    by other classical statistical methods. Some potential advantages of using the
    Bayesian method was summarized by Elam et al (W. T. Elam, B. Scruggs, F. Eggert,
    and J. A. Nicolosi, *Advantages and Disadvantages of Methods for Obtaining XRF
    NET Intensities*, Copyright ©JCPDS-International Centre for Diffraction Data 2011
    ISSN 1097-0002). For example, it provides a natural way of combining prior information
    with data. Therefore, as a data scientist, you can incorporate that past information
    regarding the parameters and form a prior distribution for future analysis for
    new datasets. It also provides inferences that are conditional on the data without
    the need of asymptotic approximation of the algorithm.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: It provides some suitable settings for a wide range of models, such as hierarchical
    models and missing data problems. There are also disadvantages of using Bayesian
    analysis. For example, it does not tell you how to select a prior over world models
    or even that there is no correct way to choose a prior. Therefore, if you do not
    proceed with caution, you might generate many false positive or false negative
    results that often come with a high computational cost, if the number of parameters
    in a model is large.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-353
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This ends our rather quick tour of machine learning and the best practice that
    needs to be followed. Although we have tried to cover some of the most basic things
    to remember, suitable data often beats better algorithms and better demand. Most
    importantly, to design good features out of your data might take a long time;
    however, it would very much aid you. However, if you have a large-scale dataset
    to be applied to your machine learning algorithms or model, whichever classification,
    clustering, or regression algorithm you use might not be a matter of fact concerning
    the machine learning classes and their respective classification performance.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, it would be a wise decision to choose an appropriate machine learning
    algorithm that can fulfill requirements such as speed, memory usage, throughput,
    scalability, or usability. In addition to going over what we said in the sections
    above, if you are really concerned about achieving the accuracy, you should undoubtedly
    try a group of different classifiers to find the best one using the cross-validation
    technique or just use an ensemble method to choose them alltogether.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: You can also be motivated and take a lesson from the Netflix Prize PLUS. We
    spoke at length about the Spark machine learning APIs, some best practice in ML
    application development, machine learning tasks and classes, some widely used
    best practices, and so on. However, we have not shown in depth analysis of the
    machine learning techniques. We intend to talk about this in more detail in [Chapter
    4](part0038_split_000.html#147LC2-5afe140a04e845e0842b44be7971e11a "Chapter 4. Extracting
    Knowledge through Feature Engineering"), *Extracting Knowledge through Feature
    Engineering*.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will cover in detail the DataFrame, Dataset, and **Resilient
    Distributed Dataset** (**RDD**) APIs for working with structured data targeting
    to provide a basic understanding of machine learning problems with the available
    data. Therefore, at the end, you will be able to apply from basic to complex data
    manipulation with ease.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
