- en: Chapter 9. Storm Management and Maintenance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will understand scaling of the Storm cluster. You will
    also see how to adapt the Storm topology worker and parallelism.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Adding new supervisor nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up workers and parallelism to enhance processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Troubleshooting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling the Storm cluster – adding new supervisor nodes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In production, one of the most common scenarios one can run into is when the
    processing need outgrows the size of the cluster. Scaling then becomes necessary;
    there are two options: we can perform vertical scaling wherein we can add more
    compute capability, or we can use horizontal scaling where we add more nodes.
    The latter is more cost-effective and also makes the cluster more robust.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the steps to be executed to add a new node to the Storm cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: Download and install the 0.9.2 version of Storm as it is used in the rest of
    the cluster by extracting the downloaded ZIP file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create the required directories:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: All Storm nodes, the Nimbus nodes, and the supervisor require a location on
    to store a small amount of data related to configurations on the local disk. Please
    ensure you create the directory and assign read/write permissions on all Storm
    nodes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create the required directories for the logs, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Update the `storm.yaml` file with necessary changes for Nimbus and Zookeeper:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The values of the slots of the supervisor ports are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `supervisor.slots.ports` |'
  prefs: []
  type: TYPE_TB
- en: '| - 6700 |'
  prefs: []
  type: TYPE_TB
- en: '| - 6701 |'
  prefs: []
  type: TYPE_TB
- en: '| - 6702 |'
  prefs: []
  type: TYPE_TB
- en: '| - 6703 |'
  prefs: []
  type: TYPE_TB
- en: 'Set the `STORM_HOME` environment in the `~/.bashrc` file and add Storm''s `bin`
    directory in the `PATH` environment variable. This is added to execute Storm binaries
    from any location. The entry to be added is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Update `/etc/hosts` on each of the following machines and the node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The nimbus machine: This is done to add an entry for the new supervisor that''s
    being added'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'All existing supervisor machines: This is done to add an entry for the new
    supervisor that''s being added'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The new supervisor node: This is done to add the nimbus entry, to add the entry
    for all other supervisors, and to add an entry for the Zookeeper node'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the supervisor has been added, start the process and it should be visible
    on the UI, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Scaling the Storm cluster – adding new supervisor nodes](img/00057.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Note that the first row in the preceding screenshot points to the newly added
    supervisor; it has 16 slots in total and `0` slots are being used as it has been
    just added to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling the Storm cluster and rebalancing the topology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once a new supervisor is added, the next obvious step would be to rebalance
    the topologies, which are executed on the cluster so that the load could be shared
    across to the newly added supervisor.
  prefs: []
  type: TYPE_NORMAL
- en: Rebalancing using the GUI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Rebalance option is available on the Nimbus UI where you can choose the topology
    that is to be rebalanced, and then use the option from the GUI. The topology drains
    as per the specified time-out. During that duration, it stops accepting any messages
    from the spout and the ones in the internal queues are processed and once completely
    clear, the workers and tasks are redistributed. The user also has option to increase
    or decrease the parallelism for various bolts and spouts using the rebalance options.
    The following screenshot describes how to rebalance a topology using the Storm
    UI options:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Rebalancing using the GUI](img/00058.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Rebalancing using the CLI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The second option for rebalancing is using the Storm CLI. The command for this
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Here, `–n` specifies the number of workers allocated to the topology post-rebalance,
    `-e my-spout` refers to parallelism assigned to the spout, and similarly `–e my-bolt`
    refers to parallelism to be assigned to the bolt. In the preceding command, we
    executed the Storm shell from the `bin` directory under the Storm installation
    JAR, and while rebalancing the Storm topology by changing the parallelism of the
    spout and bolts as well.
  prefs: []
  type: TYPE_NORMAL
- en: The changes to the execution of the preceding commands can be verified from
    the Storm UI.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up workers and parallelism to enhance processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Storm is a highly scalable, distributed, and fault tolerant real-time parallel
    processing compute framework. Note that the emphasis is on scalability, distributed,
    and parallel processing—well, we already know that Storm operates in clustered
    mode and is therefore distributed in its basic nature. Scalability was covered
    in the previous section; now, let''s have a closer look at parallelism. We introduced
    you to this concept in an earlier chapter, but now we''ll get you acquainted with
    how to tweak it to achieve the desired performance. The following points are the
    key criteria for this:'
  prefs: []
  type: TYPE_NORMAL
- en: A topology is allocated a certain number of workers at the time it's started.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each component in the topology (bolts and spouts) has a specified number of
    executors associated with it. These executors specify the number or degree of
    parallelism for each running component of the topology.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The whole efficiency and speed factor of Storm are driven by the parallelism
    feature of Storm, but we need to understand one thing: all the executors that
    attribute to parallelism are running within the limited set of workers allocated
    to the topology. So, one needs to understand that increasing the parallelism would
    help achieve efficiency only to a point, but beyond that the executors will struggle
    for resource is the intention. Going beyond this increasing parallelism would
    not fetch efficiency, but increasing the workers allocated to the topology would
    would make computation efficient.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another point to understand in terms of efficiency is network latency; we'll
    explore this in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Scenario 1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This following figure illustrates a simple topology with three moving components:
    one spout and two bolts. Here, all the components are executing on separate nodes
    in the cluster, thus every tuple has to do two network hops to complete its execution.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Scenario 1](img/00059.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s say we are not satisfied with the throughput and decide to increase
    the parallelism. The moment we try to move into this technique, the question that
    arises is where to increase it and by how much. That could be computed based on
    the capacity of the bolt, which should be visible from the Storm UI. The following
    screenshot illustrates this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Scenario 1](img/00060.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Here, the circled value is the capacity of the second bolt, which is around
    0.9 and it's already in red, which means this bolt is over-worked and increasing
    parallelism here should help. Any topology would actually break and stop acking
    when the bolt capacity crosses `1`. To fix this, let's see the next scenario,
    which provides a solution for this issue.
  prefs: []
  type: TYPE_NORMAL
- en: Scenario 2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, we have acted on the realization that **Bolt B** is overloaded and has
    increased the parallelism, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Scenario 2](img/00061.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The preceding figure describes one scenario capturing the distribution of various
    instances of the bolts and spouts across different nodes in the cluster. Here,
    we have acted on the realization that a bolt is overloaded and we observed the
    capacity, and by brute force, increased the parallelism of only that bolt.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, having done this, we have achieved the required parallelism; let''s now
    have a look at the network latency, in terms of how many tuples are moving between
    nodes (internode communication is a mandatory element in a distributed computing
    setup):'
  prefs: []
  type: TYPE_NORMAL
- en: 50 percent of the traffic is hopping between spouts on **Machine 1** and **Machine
    2**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 50 percent of the traffic is hopping between **Machine 1** and **Machine 3**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 100 percent of the traffic is hopping between **Machine 2** and **Machine 3**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now let's see another illustration with a slight variation in the parallelism.
  prefs: []
  type: TYPE_NORMAL
- en: Scenario 3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The scenario 3 is the most optimal scenario that is possible in the setup in
    the example where we use network and parallelism very efficiently, as shown in
    the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Scenario 3](img/00062.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Now, the preceding figure is an illustration of where we get the maximum benefit
    of parallelism usage. If you look at the preceding figure, you'll see that we
    have achieved efficiency and no network hop; the best of both the worlds.
  prefs: []
  type: TYPE_NORMAL
- en: What I am trying to illustrate is that parallelism should be changed judicially
    keeping the impact of network latency, hops, and the speed of localized processing
    in mind.
  prefs: []
  type: TYPE_NORMAL
- en: Storm troubleshooting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As developers, we need to accept the reality that things do go wrong and debugging
    is required. This section is going to equip you to handle such situations effectively
    and efficiently. The first thing is to understand two root mantras of the programming
    world:'
  prefs: []
  type: TYPE_NORMAL
- en: Work as if everything that could break will break
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anything that could break can be fixed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having accepted the reality, let's address the situation first by understanding
    what could fail and then have a clear understanding of where we should start the
    analysis to help us handle any situation with the Storm cluster. Let's get to
    grips with the various pointers that show us the problems and thus guide us to
    prospective solutions.
  prefs: []
  type: TYPE_NORMAL
- en: The Storm UI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First of all, let's understand which statistics and indicators are present on
    the UI itself. The latest UI has scores of indicators that give us an insight
    into what is going on in the cluster and what could go wrong (just in case things
    break).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at Storm UI where the **Cluster Summary** entails, for example,
    `http:// ip of nimbus:8080` in my case is `http://10.4.2.122:8080` and my UI process
    executes on the nimbus machine that has this IP: 10.4.2.122.'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Storm UI](img/00063.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the preceding screenshot, we can see the following parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: The version of Storm being used is in the first column.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The uptime of Nimbus (second column) tells us how long the Nimbus node has been
    running since the last restart. Nimbus, as we know, is required only at the time
    when the topology is submitted or when a supervisor or worker has gone down and
    the tasks are being delegated again. Nimbus is also required to be up during the
    rebalancing of the topology.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The third column gives us the number of supervisors on the cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Columns four, five, and six show the number of used worker slots, number of
    free worker slots, and total number of worker slots across the Storm supervisors.
    This is a very important statistic. In any production grade cluster, one should
    always have a provision for some of the workers going down or one or two supervisors
    being killed. So, I recommend that you always have enough free slots on your cluster
    to accommodate such sudden failures.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Column seven and column eight specify the moving tasks in the topology, that
    is, in terms of the number of tasks and executors running in the system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s have a look at the second section on the Storm UI opening page; this
    one captures the topology summary:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Storm UI](img/00064.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'This section depicts various parameters Storm captures and displays at the
    topology level:'
  prefs: []
  type: TYPE_NORMAL
- en: Column one and column two display the **Name** field of the topology and the
    **Id** field of topology, respectively.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Column three reads the status of the topology, which is **ACTIVE** for a topology
    that's executing and processing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Column four displays the uptime since the topology has been started.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next three columns display **Numworkers**, **Num tasks**, and **Num executors**;
    these are very important aspects for the performance of the topology. While tuning
    the performance, one has to realize that just increasing the **Num tasks** and
    **Num executors** field value may not result in greater efficiency. If the number
    of workers is low, and we just increase the number of executors and tasks, then
    the starvation of resource high because of the limited number of workers, so the
    topology performance will deteriorate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarly, if we assign too many workers to a topology with not enough executors
    and tasks to utilize all of them, we'd waste the precious resources by keeping
    them blocked and idle.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if we have a high number of workers and a high number of
    executors and tasks, the chances are that performance may degrade due to network
    latency.
  prefs: []
  type: TYPE_NORMAL
- en: Having stated these facts, I want to emphasize the fact that the performance
    tuning should be done cautiously and judiciously to arrive at what number works
    for the use case we are trying to implement.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot captures the details about the supervisors, in terms
    of the statistics, with the corresponding information:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Storm UI](img/00065.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Column one has the **Id** field for the supervisors, and column two has the
    names of the **hosts** field that have supervisor processes running.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Column three captures the amount of time the supervisor has been running for.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Columns five and six capture the number of slots available on the supervisor
    and the number of slots used respectively. These two numbers provide a very important
    metric in terms of how many slots are available and how many are used. They help
    us judge and understand what capacity the supervisors are operating at and how
    much bandwidth they have to handle the scenarios of failures; for instance, all
    my supervisors are operating at 100 percent capacity, so in that case, my cluster
    can't handle any failures.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following screenshot is captured from the Storm UI depicting supervisors
    and their attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Storm UI](img/00066.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding section gives us details about the supervisor slots, timeouts,
    and so on. These values are specified on `storm.yaml`, but can be verified from
    the UI. For example, `http:// ip of nimbus:8080` in my case is `http://10.4.2.122:8080`,
    and my UI process executes on the Nimbus machine that has this IP: 10.4.2.122,
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Storm UI](img/00067.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now in the section depicted in the following screenshot one can get into by
    drilling deeper into the topology details. This can be achieved on the Storm UI
    by clicking on any of the topology names. This section holds the details about
    the components of the topology including the level of bolts, spouts, and details
    about them, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Storm UI](img/00068.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The preceding screenshot has details ranging from the number of executors or
    tasks allocated to each component, to the number of tuples emitted by the bolts
    or spouts and the number of tuples transferred to the next component in the **Directed
    Acyclic Graph** (**DAG**).
  prefs: []
  type: TYPE_NORMAL
- en: 'Other notable details one should observe on the topology detail page are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Capacity** of bolts in the last 10 minutes: This should be well below 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Execute latency** is time in milliseconds: This determines how long it would
    take to execute a tuple through this component. If this value is too high, then
    we would probably want to break the execution into two or more bolts to utilize
    parallelism and have better efficiency.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Executed**: This stores the number of tuples executed successfully by this
    component.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Process latency**: This value displays the average total time taken to execute
    a tuple by the component. This value should be analyzed with the execute latency.
    These are practical cases that may happen:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Execute latency** and **Process latency** are both low (that''s the best
    possible case)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Execute latency** is low but process latency is very high (that means actual
    execution time is lower in comparison to the total execution time and increasing
    parallelism might help achieve efficiency)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both **Execute latency** and **Process latency** are high (again, increasing
    parallelism might help)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storm logs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The next place to debug if things don''t go as expected is the Storm log. First
    of all, one needs to know the location for Storm logs, which also update the path
    on `cluster.xml` at `storm-0.9.2-incubating.zip\apache-storm-0.9.2-incubating\logback\cluster.xml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Now the line in bold gets you the path/location where the Storm logs will be
    created. Let's take a closer look to find out what kinds of logs are created by
    different Storm daemons.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Nimbus node logs can be obtained by using the following commands on shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The listing of the Nimbus log directory is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Storm logs](img/00069.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Notice that we have `nimbus.log`, which has details about Nimbus' startup, error,
    and info logs; `ui.log` is created on the node where we start the Storm UI application.
  prefs: []
  type: TYPE_NORMAL
- en: 'The logs on the supervisor nodes can be obtained by using the following commands
    on shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The listing of the supervisor log directory is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Storm logs](img/00070.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: One can see supervisor logs and worker logs. The supervisor logs capture the
    details about the supervisor starting up, any errors, and so on. The worker logs
    are the ones where the developer's topology logs appear along with Storm logs
    for various bolts and spouts.
  prefs: []
  type: TYPE_NORMAL
- en: So if we want to troubleshoot the Storm daemon processes, we would look at `nimbus.log`
    and `supervisor.log`. If you're having issues, then you need to debug using the
    corresponding worker log. The scenario of nimbus and worker node failures has
    been covered in [Chapter 4](part0032_split_000.html#page "Chapter 4. Storm in
    a Clustered Mode"), *Storm in a Clustered Mode*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s imagine a scenario. I am a developer whose topology is not behaving
    as expected, and I doubt that one of the bolts is not functioning as expected.
    So we need to debug the worker logs and find the root cause. Now we need to find
    out which worker log to look at out of multiple supervisors and numerous worker
    logs; we''ll get this information from the Storm UI. Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open **Storm UI** and click on the troublesome topology.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the suspected bolt or spout of the topology. A screen analogous to
    what is shown in this screenshot should appear:![Storm logs](img/00071.jpeg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Here is the clue to debug what's happening in this bolt; I will look into `Supervisor5`
    and `Supervisor6`, of `worker-6705.log` on `supervisor5` and `supervisor6`.
  prefs: []
  type: TYPE_NORMAL
- en: Quiz time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Q.1\. State whether the following statements are true or false:'
  prefs: []
  type: TYPE_NORMAL
- en: Storm nodes can't be added to the cluster with topologies being executed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A topology can't survive the Storm node failure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Storm logs are created on each node in the cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The location of the Storm log creation is configurable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Q.2\. Fill in the blanks:'
  prefs: []
  type: TYPE_NORMAL
- en: _______________ is the heartbeat tracker of the cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: _______________ is the daemon that's mandatory for topology submission and rebalancing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The ___________ file holds the worker configuration for the topology.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Q.3\. Execute the following use cases to see the internals of Storm:'
  prefs: []
  type: TYPE_NORMAL
- en: Start nimbus and check `nimbus.log` to see what a successful startup should
    look like.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start the supervisor and check `Supervisor.log` to see what a successful startup
    should look like.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Submit the topology, say a simple `WordCount` topology, and figure out the `worker.log`
    file creation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update `log4j.properties` to change the logging level and verify its impact.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have covered the maintenance concepts of Storm in terms
    of adding new nodes, rebalancing, and killing topologies. We have understood and
    tweaked internals such as `numtasks` and parallelism in combination with to `numworkers`
    and network latency. You learned to locate and decipher logs of Storm components.
    You also understood the metrics of the Storm UI and their implications on topology
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss advanced concepts of Storm, including micro-batching
    and Trident APIs.
  prefs: []
  type: TYPE_NORMAL
