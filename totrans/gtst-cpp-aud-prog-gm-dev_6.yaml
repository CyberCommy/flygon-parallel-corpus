- en: Chapter 6. Low-level Audio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have now reached the final chapter of this book. So far, we have worked with
    audio at many different levels of complexity and abstraction, using both low-level
    and high-level audio engines. These audio engines provide an invaluable help to
    the developers, and we should definitely use them whenever possible. With their
    help, we have loaded and played audio files, learnt how to control sound parameters,
    simulated sound in 3D environments, and created complex, multi-layered, interactive
    sounds.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, however, we will pretend that these audio engines do not exist,
    and work with nothing more than the bits and bytes that represent sound in a computer.
    We will then re-implement, in a simplified form, many of the features that FMOD
    takes care for us. We will also take a brief look at sound synthesis, which is
    the act of generating sound using mathematical formulas, instead of relying on
    recorded audio.
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of this chapter is to further our understanding of how sound works,
    and to gain some insight into many of the features that audio engines implement
    for us. It should also serve as a starting point for those who are looking to
    implement complex audio features in their games.
  prefs: []
  type: TYPE_NORMAL
- en: Representing audio data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 1](ch01.html "Chapter 1. Audio Concepts"), *Audio Concepts*, we
    discussed the most important concepts of digital audio theory. In particular,
    we saw that a simple array of numbers could represent an audio signal, and talked
    about topics such as PCM, sampling rate, bit depth, and multi-channel audio.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will be putting all of those concepts into practice, so
    make sure you understand them before continuing. For starters, let us look into
    the meaning of audio data, both in theory and in code.
  prefs: []
  type: TYPE_NORMAL
- en: Audio data is nothing more than a sequence of numbers that represent the amplitude
    of a sound wave at even time intervals. However, there are many ways to represent
    numbers on a computer, depending on the amount of memory used to represent them,
    whether they should be able to store negative numbers, and whether the numbers
    are integers or floating point numbers. These differences result in the multiple
    data types provided by C++ to store numbers, such as `int`, `short`, `float`,
    and `double`. It makes sense then, that audio data can also be stored in several
    formats, depending on the chosen data type.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will limit ourselves to the most common audio format, which
    is the signed 16-bit linear PCM format. In this format, every sample is a 16-bit
    signed integer (a `signed short` in C++) ranging from -32768 at the minimum amplitude,
    to 32767 at the maximum amplitude. To simplify the notation when dealing with
    PCM samples and other quantities, we will be using the following aliases:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'After deciding what format to use, we need to create an array to hold all of
    the audio samples. The size of the array depends directly on the sampling rate
    of the sound we want to store, its duration in seconds, and the number of channels
    being used, according to the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'For example, assuming a sampling rate of 44100 Hz, we could create an array
    to store exactly 1 second of mono audio data like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'If we wanted to store a stereo signal instead, we would need to store twice
    that amount of information (and the same idea applies to higher amounts of channels).
    Remember that the most common way to represent stereo audio data is to interleave
    samples, left and right, in the same array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Playing audio data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We need a way to submit the audio data to the sound card, so that we can hear
    the resulting sound. We could use a very low-level audio API, such as PortAudio,
    which provides the bare minimum functionality required to communicate with an
    audio device. However, FMOD is also perfectly capable of handling this task, and
    since we have been using it so far, there is little benefit in changing to a different
    API now. Therefore, we will use FMOD once again, but only as bridge between the
    application and the hardware, and our code will handle all of the processing.
  prefs: []
  type: TYPE_NORMAL
- en: The way FMOD allows us to play user created audio data is by first creating
    a sound with the `FMOD_OPENUSER` flag, and specifying a callback function that
    will provide the audio data to the sound.
  prefs: []
  type: TYPE_NORMAL
- en: We must create and fill a `FMOD_CREATESOUNDEXINFO` structure with a few details
    regarding the audio data that we will be submitting, such as the sampling rate,
    format, and number of channels, as well as a pointer to the function that will
    provide the data itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'For all of our examples, we will work with a sampling rate of 44100 Hz, use
    the 16-bit PCM format, and have two channels (stereo). Read the comments for more
    information about each attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create a looping, streaming sound, specifying the `FMOD_OPENUSER`
    mode, and passing it the sound info structure to the third parameter of `createStream()`.
    We can then begin playing the sound as normal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: As long as the sound is playing, the audio engine invokes our callback function
    periodically to get the data it requires. The callback function must follow a
    certain signature that takes three parameters, a reference to the sound object
    that we created, an array for us to write the audio data into, and the total number
    of bytes that we should write to the data array. It should also return `FMOD_OK`
    at the end.
  prefs: []
  type: TYPE_NORMAL
- en: The data array is defined by a pointer to void (`void*`) because, as we discussed
    earlier, there are many different formats for the data to be in. It is up to us
    to cast the data array to the correct format. Since we created the sound with
    `FMOD_SOUND_FORMAT_PCM16`, we have to cast the data array to a `signed short*`
    first.
  prefs: []
  type: TYPE_NORMAL
- en: Another important detail is that the `length` parameter specifies the amount
    of data to write to the array in `bytes`, but each of our samples is a `signed
    short`, which occupy 2 bytes each. Therefore, we should make sure to write no
    more than `length/2` samples to the data array.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of a callback function, which outputs silence by filling
    the entire audio buffer with zeros. Not very interesting, but it should serve
    as a good starting point:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Loading a sound
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most common way to get audio data is to read it from an audio file. However,
    as we have seen before, there are many different audio file formats, and reading
    the audio data out of them is usually a non-trivial task. This is particularly
    true with compressed audio file formats, which require decoding the audio data
    using some algorithm, before we can use it in our application. In general, it
    is usually better to use an audio engine, or an external library, to read the
    contents of an audio file.
  prefs: []
  type: TYPE_NORMAL
- en: For educational purposes, we will be reading the audio data from a WAV file.
    We will, however, work under the assumption that the WAV file we read from is
    in the canonical form (that is, it contains only a format and a data subchunk,
    in that order) and that the audio data is stored without any compression. Under
    these conditions, we know where all of the data is stored, and can simply index
    into the file to read it. That is certainly not the case for every WAV file, which
    would require a more complex loading sequence.
  prefs: []
  type: TYPE_NORMAL
- en: The WAV file format builds upon the more generic RIFF file format. A RIFF file
    is divided into chunks of data. Every chunk begins with a 4-character ASCII identifier,
    and a 32-bit integer describing how much data is stored in the chunk. Next, there
    is the actual data of the chunk, which varies depending on the type of the chunk.
  prefs: []
  type: TYPE_NORMAL
- en: 'All WAV files contain at least the following three chunks (with two of them
    considered subchunks of the first):'
  prefs: []
  type: TYPE_NORMAL
- en: 'A **RIFF** chunk containing the string literal: WAVE'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **Format** subchunk containing information about the audio file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **Data** subchunk containing the actual audio data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following figure shows the contents of a WAV file in a canonical format.
    Note that if the file contains compressed data, the format subchunk can contain
    more data than the one shown in the following figure. It is also possible for
    other chunks to appear in the file, or in a different order:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Loading a sound](img/9099OT_06_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Now that we have a table listing the contents of a canonical WAV file, let us
    create a class to load and store all of the information that we care about from
    the file (that is, the sampling rate, bit depth, number of channels, and the audio
    data).
  prefs: []
  type: TYPE_NORMAL
- en: 'Keeping in line with what we used previously in FMOD, we will name this class
    `MySound`. For simplicity, every member of the class has public accessibility,
    although we could provide a few accessor methods instead, while making the data
    private:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'On the constructor, we open the audio file and read all of the relevant data
    into the member variables. Note that there is no error checking anywhere, and
    that this will only work under the conditions described earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The destructor takes care of cleaning up the memory allocated in the constructor
    to hold the audio data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Playing a sound
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have all of the audio data stored in memory, we are ready to begin
    playing the sound. In order to do so we must essentially take each of the values
    stored in the data array, and send them in order to the audio card (in our case,
    using the callback method that we created earlier).
  prefs: []
  type: TYPE_NORMAL
- en: 'If the format, sampling rate, and number of channels in the audio data are
    the same as the output, then this process is as simple as copying values from
    one array to another. However, the process becomes significantly more complicated
    if they differ in any way, in particular:'
  prefs: []
  type: TYPE_NORMAL
- en: If our audio data has a different sampling rate from the output, we need to
    resample the data so that it matches the sampling rate of the output, or the sound
    will play at a different rate than we expect. This operation is not trivial, and
    is beyond the scope of this chapter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If our audio data is in a different format from the output, we need to convert
    the data to the new format first. For example, we may need to convert a 32-bit
    floating point sample into a signed 16-bit integer sample. This is not that complicated,
    and mostly requires scaling numbers from one range to another.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If our audio data has different number of channels from the output, we have
    to adapt the signal to the new number of channels. Adapting a mono signal to a
    stereo is easy, as we simply need to send a duplicate of the data to both channels.
    Adapting a stereo signal to mono usually involves adding the values of both channels
    together, and dividing the result by two.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For the sake of keeping our examples simple, we will assume that the audio
    data has a very specific format, so that no conversions need to take place:'
  prefs: []
  type: TYPE_NORMAL
- en: It has a sampling rate of 44100 Hz, the same as the output
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is stored in the PCM16 audio format, the same as the output
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It only has one channel (mono) of data, although the output has two channels
    (stereo), so that we can see an example of how to implement panning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Under these conditions, we only need two things to play the sound, we need to
    be able to access the audio data, and we need a variable to keep a track of the
    current position within the sound (that is, how many samples we have written so
    far) so that we know which sample to write next. Once the position becomes larger
    than the number of samples in the data, it means that the sound has finished playing,
    and we interrupt the process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Like we did with the sound class, let us also create a class to encapsulate
    all of the data and behaviors related to playing sounds, which we will name `MyChannel`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Like the channels in FMOD, we should be able to reuse a single channel object
    for different sounds. Therefore, instead of taking a sound object in the constructor,
    we only assign the sound object inside the `Play()` method. This method also resets
    the position value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Stop()` method, on the other hand, simply clears the reference to the
    sound object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the most important portion of the process occurs inside the `WriteSoundData()`
    method, which will be called from within the audio callback. This method takes
    two parameters, the array of PCM samples to write to and the size of this array.
    Notice that this method already expects the `data` array to be in the correct
    format, instead of the `void*` provided to the audio callback. The `count` also
    refers to the number of samples in the array, not the number of bytes. There are
    comments in the code explaining what each line is doing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Using this class, our audio callback becomes a lot simpler, as we can delegate
    most of the work to the `WriteSoundData()` method of the channel. In the following
    example there is a single channel object, so we can only play one sound at a time,
    but later we will see how easy it is to add support for multiple sounds, as well
    as several other features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Notice that in the preceding example, we begin by clearing the audio buffer
    with `memset`. This is necessary because we will not be filling the output with
    values once the sound stops playing, and FMOD does not clear the buffer automatically
    between callback calls.
  prefs: []
  type: TYPE_NORMAL
- en: 'Playing a sound with this architecture is as simple as instantiating the sound,
    and asking the channel object to play it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Pausing a sound
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have the basic functionality for playing sounds implemented using
    the `MySound` and `MyChannel` classes, we can begin adding more features to it.
    We will start with the simplest of all, pausing the sound.
  prefs: []
  type: TYPE_NORMAL
- en: 'We must add a member variable to hold the pause state, and some methods to
    modify it. We must also remember to initialize this value to `false` inside the
    constructor, and inside the `Play()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Next, all we have to do is add a very simple condition at the beginning of the
    `WriteSoundData()` method so that it does nothing when the sound is paused. That
    is as simple as it gets!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Looping a sound
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next feature that we will implement is the ability to endlessly make a
    sound loop. Like the ability to pause a sound, this is also quite trivial to implement.
    We begin by repeating everything that we did for pausing, but for looping instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Inside the `WriteSoundData()` method, in the part where we used to detect if
    the sound had already reached the end, we first check if the loop variable is
    set to `true`, and if that is the case, we set the position back to the beginning
    instead of stopping the sound:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Changing volume
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The next few features that we will implement involve modifying the values that
    are sent to the output. Changing the volume of a sound is probably the simplest
    of them, as it only requires a multiplication.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us start by creating a variable and some methods to control the volume.
    The volume will be stored as a floating point number between 0 (silence) and 1
    (full volume). The `SetVolume()` method makes sure that the value is always inside
    this range. We should also reset the volume to 1 whenever a sound begins playing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to play the sound at this volume, all we have to do is multiply each
    of the original values in the audio data by the value of the volume variable,
    before we write them to the output. Because the volume variable is a floating
    point number, we need to cast the result back to PCM16 after the multiplication:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Changing pitch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Changing the pitch of a sound is slightly more complicated than changing its
    volume. The most basic way to modify the pitch of a sound (although the speed
    of the sound is also affected) is to control how fast we advance the position
    value.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have used a `position` variable that was an integer, and incremented
    its value by a full unit every time. In order to provide pitch control, we will
    change that variable to a floating point number, and add a `pitch` variable that
    determines how much to increment the position.
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, the `pitch` variable will have a value of 1, which plays the sound
    at the normal pitch. A value of 2 will double the frequency of the sound, making
    it sound one octave higher, and a value of 0.5 will halve the frequency of the
    sound, making it sound one octave lower. For practical reasons, we will limit
    its value to the range between 0.25 (two octaves below the original sound) and
    4 (two octaves above the original sound):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Inside our `WriteSoundData()` method, we increment the position variable by
    the pitch amount. The hardest part in the process is how to convert the `position`
    variable that is now a floating point number, back into an array index. The simplest
    solution is to use a simple cast, which truncates the value to an integer, and
    that is what we will use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: However, the truncation from the cast can introduce distortion into the signal.
    For example, if the position is advancing at a slower pace than normal, it will
    have many values that are between whole numbers, but because of the truncation
    from the cast, we will get the same value written multiple times to the output,
    instead of a flowing sound wave.
  prefs: []
  type: TYPE_NORMAL
- en: A better approach is to use linear interpolation (or another type of interpolation)
    to calculate a value for the sample that takes the surrounding values and the
    fractional portion of the position into consideration. For example, using linear
    interpolation, if the position was 2.25, instead of outputting the value of `data[2]`,
    we would output a mix of 75 percent of the value of `data[2]` with 25 percent
    of the value of `data[3]` instead.
  prefs: []
  type: TYPE_NORMAL
- en: Changing panning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many different approaches to implement stereo panning of a sound.
    In this section, we will cover a simple approach that works just by modifying
    the volumes of the left and right channels independently.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before actually doing any calculations, let us prepare the class for panning
    by adding two private variables, `leftGain` and `rightGain`, to store the volumes
    of each channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, inside the `WriteSoundData()` method, we can apply these gains to the
    data before writing it to the output, just as we did for the volume before. Naturally,
    we should only apply the values of `leftGain` and `rightGain` to their respective
    channels. In addition, because we need to cast to PCM16 after applying the gains,
    there is no need to keep the cast from earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'With these out of the way, we now need to create a floating point variable
    called `pan` and some methods to modify it. The `pan` variable should take values
    between -1 (full left) and 1 (full right). Whenever the value of `pan` changes,
    we call the private `UpdatePan()` method to calculate new values for `leftGain`
    and `rightGain`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'All that is left is to write the `UpdatePan()` method. There are a few different
    formulas to calculate the gain values for stereo panning. One of the simplest
    approaches is to use linear panning, where each channel starts at 0 percent volume
    in one side, and increases linearly to 100 percent on the other side, while being
    at 50 percent in the middle. Here is an implementation of linear panning:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Another approach, which usually yields a smoother transition when panning,
    is to use **constant-power panning**, where the volume of each channel follows
    a circular curve, with the volume of each channel being roughly 71 percent in
    the middle. We have already discussed constant-power panning before, since it
    is the type of panning used by FMOD for panning mono sounds. Without going into
    details about the math involved, here is an implementation of constant-power panning:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Mixing multiple sounds
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So far, we have only been playing one sound at a time, but it is quite easy
    to extend what we are doing to play multiple sounds at once. The act of combining
    multiple sounds into a single output is known as **audio mixing**, and it can
    be implemented by adding all the audio signals together, and clamping the result
    to the available range. Looking at our `WriteSoundData()` method, all we need
    to do is change the lines of code that write to the data array, so that the samples
    are added to the existing values, instead of completely replacing them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'In our main application, instead of having a single channel instance, we can
    now create multiple instances, and call `WriteSoundData()` on all of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Implementing a delay effect
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have already discussed, back in [Chapter 4](ch04.html "Chapter 4. 3D Audio"),
    *3D Audio*, that DSP effects are algorithms that modify the audio data to achieve
    a certain goal. Now we will see an example of how to implement a simple delay
    effect. The way a basic delay effect works, is to keep a separate buffer of data,
    and store the audio data that has already played in it. The size of the buffer
    determines how long it takes between the original sound and its echo plays. Then,
    we simply need to mix the audio data that is playing, with a portion of the old
    signal that was stored in the buffer, which produces a delay. Let us examine the
    following `MyDelay` class definition, which encapsulates the effect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The `MyDelay` class constructor takes two parameters, `time` and `decay`. The
    first parameter controls how many seconds it takes between the sound and the first
    echo occurs. The second parameter controls how much energy is lost during each
    echo.
  prefs: []
  type: TYPE_NORMAL
- en: 'The class stores a buffer of PCM16 samples, which we initialize in the constructor
    so that it can store the equivalent of `time` seconds of data at a sampling rate
    of 44100 Hz. This buffer starts completely filled with zeros. It also contains
    a `position` variable that will be used to cycle through the buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The destructor deletes all the data allocated in the constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the `WriteSoundData()` method does all of the work. It begins by taking
    each sample in the output, and mixing it with a portion of the sample stored in
    the buffer at the current position. Next, we take this new value and write it
    back to the output, as well as to the buffer. Finally, we increment the position
    variable to the next sample, wrapping around the end of the buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'To test this effect out, simply create an instance of it in the main application,
    and call the `WriteSoundData()` method at the end of the audio callback:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Synthesizing a sound
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we end this chapter, it is also worth realizing that not every sound
    needs to come from an audio file. It is also possible to generate sounds from
    scratch, using only mathematical formulas. We call this process, **sound synthesis**,
    and there are entire books just about this subject.
  prefs: []
  type: TYPE_NORMAL
- en: 'Certain sound waves are particularly common in sound synthesis because of how
    easy they are to calculate. We have already talked about one of these sound waves
    before, the sine wave. Other common examples are the square wave, the sawtooth
    wave, and the triangle wave, all represented in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Synthesizing a sound](img/9099OT_06_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We will now see how to synthesize each of these sound waves, by creating a
    class `MyOscillator`. The use case for this class is pretty much the same as the
    `MyDelay` class described earlier; just create an instance of it, and call the
    `WriteSoundData()` method from the audio callback to make it play:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: The class contains three member variables, `phase`, which describes how far
    we are along the sound wave, `increment`, which depends on the frequency of the
    sound and describes how much we should advance the phase between each sample,
    and `volume`, which can be changed through the `SetVolume()` method. Note that
    we are using doubles for everything instead of floats, as sound synthesis tends
    to require more precision in its calculations.
  prefs: []
  type: TYPE_NORMAL
- en: 'All that the class constructor does is initialize the phase to zero, the volume
    to one, and set the increment by calling `SetFrequency()` with a default value
    of 440 Hz:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The `SetFrequency()` method calculates the correct increment value using the
    following formula. In this case, we have hardcoded the sampling rate to be 44100
    Hz, but there could be a parameter to control the sampling rate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'As usual, most of the work is handled inside the `WriteSoundData()` method.
    First, we calculate the value of the sound wave for the current phase, and scale
    it into the correct range for a PCM16 sample (by multiplying by 32767, which is
    the highest number that can be stored in a signed short). Next, we write this
    result to the audio output, mixing it with anything that was already there. Finally,
    we increment the phase, and wrap it so that it always stays within the 0 to 2
    PI range:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The actual audio data is generated by the `sine_wave()` method highlighted
    in the previous code. All that this method does is call the standard `sin()` function
    on the phase value and return the result. We can easily swap this method with
    any of the following implementations, depending on the type of sound wave that
    we want to play:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have seen how to work directly with the bits and bytes of
    audio data, how to load the audio data from a canonical WAV file, how to play
    and control audio data using only low-level operations, how to implement a simple
    delay effect, and how to synthesize some basic sound waves.
  prefs: []
  type: TYPE_NORMAL
