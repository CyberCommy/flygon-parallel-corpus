- en: Chapter 1. Introducing Kafka
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In today's world, real-time information is continuously being generated by applications
    (business, social, or any other type), and this information needs easy ways to
    be reliably and quickly routed to multiple types of receivers. Most of the time,
    applications that produce information and applications that are consuming this
    information are well apart and inaccessible to each other. These heterogeneous
    application leads to redevelopment for providing an integration point between
    them. Therefore, a mechanism is required for the seamless integration of information
    from producers and consumers to avoid any kind of application rewriting at either
    end.
  prefs: []
  type: TYPE_NORMAL
- en: Welcome to the world of Apache Kafka
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the present big-data era, the very first challenge is to collect the data
    as it is a huge amount of data and the second challenge is to analyze it. This
    analysis typically includes the following types of data and much more:'
  prefs: []
  type: TYPE_NORMAL
- en: User behavior data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application performance tracing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Activity data in the form of logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Event messages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Message publishing is a mechanism for connecting various applications with the
    help of messages that are routed between—for example, by a message broker such
    as Kafka. Kafka is a solution to the real-time problems of any software solution;
    that is to say, dealing with real-time volumes of information and routing it to
    multiple consumers quickly. Kafka provides seamless integration between information
    from producers and consumers without blocking the producers of the information
    and without letting producers know who the final consumers are.
  prefs: []
  type: TYPE_NORMAL
- en: 'Apache Kafka is an open source, distributed, partitioned, and replicated commit-log-based
    publish-subscribe messaging system, mainly designed with the following characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Persistent messaging**: To derive the real value from big data, any kind
    of information loss cannot be afforded. Apache Kafka is designed with O(1) disk
    structures that provide constant-time performance even with very large volumes
    of stored messages that are in the order of TBs. With Kafka, messages are persisted
    on disk as well as replicated within the cluster to prevent data loss.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**High throughput**: Keeping big data in mind, Kafka is designed to work on
    commodity hardware and to handle hundreds of MBs of reads and writes per second
    from large number of clients.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distributed**: Apache Kafka with its cluster-centric design explicitly supports
    message partitioning over Kafka servers and distributing consumption over a cluster
    of consumer machines while maintaining per-partition ordering semantics. Kafka
    cluster can grow elastically and transparently without any downtime.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multiple client support**: The Apache Kafka system supports easy integration
    of clients from different platforms such as Java, .NET, PHP, Ruby, and Python.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Real time**: Messages produced by the producer threads should be immediately
    visible to consumer threads; this feature is critical to event-based systems such
    as **Complex Event Processing** (**CEP**) systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kafka provides a real-time publish-subscribe solution that overcomes the challenges
    of consuming the real-time and batch data volumes that may grow in order of magnitude
    to be larger than the real data. Kafka also supports parallel data loading in
    the Hadoop systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows a typical big data aggregation-and-analysis scenario
    supported by the Apache Kafka messaging system:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Welcome to the world of Apache Kafka](img/3090OS_01_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'On the production side, there are different kinds of producers, such as the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: Frontend web applications generating application logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Producer proxies generating web analytics logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Producer adapters generating transformation logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Producer services generating invocation trace logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'On the consumption side, there are different kinds of consumers, such as the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: Offline consumers that are consuming messages and storing them in Hadoop or
    traditional data warehouse for offline analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Near real-time consumers that are consuming messages and storing them in any
    NoSQL datastore, such as HBase or Cassandra, for near real-time analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Real-time consumers, such as Spark or Storm, that filter messages in-memory
    and trigger alert events for related groups
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why do we need Kafka?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A large amount of data is generated by companies having any form of web- or
    device-based presence and activity. Data is one of the newer ingredients in these
    Internet-based systems and typically includes user activity; events corresponding
    to logins; page visits; clicks; social networking activities such as likes, shares,
    and comments; and operational and system metrics. This data is typically handled
    by logging and traditional log aggregation solutions due to high throughput (millions
    of messages per second). These traditional solutions are the viable solutions
    for providing logging data to an offline analysis system such as Hadoop. However,
    the solutions are very limiting for building real-time processing systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'According to the new trends in Internet applications, activity data has become
    a part of production data and is used to run analytics in real time. These analytics
    can be:'
  prefs: []
  type: TYPE_NORMAL
- en: Search-based on relevance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommendations based on popularity, co-occurrence, or sentimental analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Delivering advertisements to the masses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Internet application security from spam or unauthorized data scraping
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Device sensors sending high-temperature alerts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any abnormal user behavior or application hacking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Real-time usage of these multiple sets of data collected from production systems
    has become a challenge because of the volume of data collected and processed.
  prefs: []
  type: TYPE_NORMAL
- en: Apache Kafka aims to unify offline and online processing by providing a mechanism
    for parallel load in Hadoop systems as well as the ability to partition real-time
    consumption over a cluster of machines. Kafka can be compared with Scribe or Flume
    as it is useful for processing activity stream data; but from the architecture
    perspective, it is closer to traditional messaging systems such as ActiveMQ or
    RabitMQ.
  prefs: []
  type: TYPE_NORMAL
- en: Kafka use cases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are number of ways in which Kafka can be used in any architecture. This
    section discusses some of the popular use cases for Apache Kafka and the well-known
    companies that have adopted Kafka. The following are the popular Kafka use cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Log aggregation**: This is the process of collecting physical log files from
    servers and putting them in a central place (a file server or HDFS) for processing.
    Using Kafka provides clean abstraction of log or event data as a stream of messages,
    thus taking away any dependency over file details. This also gives lower-latency
    processing and support for multiple data sources and distributed data consumption.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stream processing**: Kafka can be used for the use case where collected data
    undergoes processing at multiple stages—an example is raw data consumed from topics
    and enriched or transformed into new Kafka topics for further consumption. Hence,
    such processing is also called stream processing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Commit logs**: Kafka can be used to represent external commit logs for any
    large scale distributed system. Replicated logs over Kafka cluster help failed
    nodes to recover their states.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Click stream tracking**: Another very important use case for Kafka is to
    capture user click stream data such as page views, searches, and so on as real-time
    publish-subscribe feeds. This data is published to central topics with one topic
    per activity type as the volume of the data is very high. These topics are available
    for subscription, by many consumers for a wide range of applications including
    real-time processing and monitoring.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Messaging**: Message brokers are used for decoupling data processing from
    data producers. Kafka can replace many popular message brokers as it offers better
    throughput, built-in partitioning, replication, and fault-tolerance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Some of the companies that are using Apache Kafka in their respective use cases
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**LinkedIn** ([www.linkedin.com](http://www.linkedin.com)): Apache Kafka is
    used at LinkedIn for the streaming of activity data and operational metrics. This
    data powers various products such as LinkedIn News Feed and LinkedIn Today, in
    addition to offline analytics systems such as Hadoop.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DataSift** ([www.datasift.com](http://www.datasift.com)): At DataSift, Kafka
    is used as a collector to monitor events and as a tracker of users'' consumption
    of data streams in real time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Twitter** ([www.twitter.com](http://www.twitter.com)): Twitter uses Kafka
    as a part of its Storm—a stream-processing infrastructure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Foursquare** ([www.foursquare.com](http://www.foursquare.com)): Kafka powers
    online-to-online and online-to-offline messaging at Foursquare. It is used to
    integrate Foursquare monitoring and production systems with Foursquare-and Hadoop-based
    offline infrastructures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Square** ([www.squareup.com](http://www.squareup.com)): Square uses Kafka
    as a *bus* to move all system events through Square''s various datacenters. This
    includes metrics, logs, custom events, and so on. On the consumer side, it outputs
    into Splunk, Graphite, or Esper-like real-time alerting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The source of the preceding information is [https://cwiki.apache.org/confluence/display/KAFKA/Powered+By](https://cwiki.apache.org/confluence/display/KAFKA/Powered+By).
  prefs: []
  type: TYPE_NORMAL
- en: Installing Kafka
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kafka is an Apache project and its current version 0.8.1.1 is available as
    a stable release. This Kafka 0.8.x offers many advanced features compared to the
    older version (prior to 0.8.x). A few of its advancements are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Prior to 0.8.x, any unconsumed partition of data within the topic could be lost
    if the broker failed. Now the partitions are provided with a replication factor.
    This ensures that any committed message would not be lost, as at least one replica
    is available.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The previous feature also ensures that all the producers and consumers are replication-aware
    (the replication factor is a configurable property). By default, the producer's
    message sending request is blocked until the message is committed to all active
    replicas; however, producers can also be configured to commit messages to a single
    broker.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Like Kafka producers, the Kafka consumer polling model changes to a long-pulling
    model and gets blocked until a committed message is available from the producer,
    which avoids frequent pulling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additionally, Kafka 0.8.x also comes with a set of administrative tools, such
    as controlled cluster shutdown and the Lead replica election tool, for managing
    the Kafka cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The major limitation with Kafka version 0.8.x is that it can't replace the version
    prior to 0.8, as it is not backward-compatible.
  prefs: []
  type: TYPE_NORMAL
- en: Coming back to installing Kafka, as a first step we need to download the available
    stable release (all the processes have been tested on 64-bit CentOS 6.4 OS and
    may differ on other kernel-based OS). Now let's see what steps need to be followed
    in order to install Kafka.
  prefs: []
  type: TYPE_NORMAL
- en: Installing prerequisites
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kafka is implemented in Scala and uses build tool **Gradle** to build Kafka
    binaries. Gradle is a build automation tool for Scala, Groovy, and Java projects
    that requires Java 1.7 or later.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Java 1.7 or higher
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following steps to install Java 1.7 or later:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the `jdk-7u67-linux-x64.rpm` release from Oracle''s website: [http://www.oracle.com/technetwork/java/javase/downloads/index.html](http://www.oracle.com/technetwork/java/javase/downloads/index.html).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Change the file mode as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Change to the directory in which you want to perform the installation. To do
    so, type the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'For example, to install the software in the `/usr/java/` directory, type the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the installer using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, add the environment variable `JAVA_HOME`. The following command will
    write the `JAVA_HOME` environment variable to the file `/etc/profile` that contains
    a system-wide environment configuration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Downloading Kafka
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following steps to download Kafka release 0.8.1.1:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the current beta release of Kafka (0.8) into a folder on your filesystem
    (for example, `/opt`) using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The preceding URL may change. Check the correct download version and location
    at [http://kafka.apache.org/downloads.html](http://kafka.apache.org/downloads.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'Extract the downloaded `kafka_2.9.2-0.8.1.1.tgz` file using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: After extraction of the `kafka_2.9.2-0.8.1.1.tgz` file, the directory structure
    for Kafka 0.8.1.1 looks as follows:![Downloading Kafka](img/3090OS_01_02.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Finally, add the Kafka bin folder to `PATH` as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Building Kafka
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The default Scala version that is used to build Kafka release 0.8.1.1 is Scala
    2.9.2 but the Kafka source code can also be compiled from other Scala versions
    as well, such as 2.8.0, 2.8.2, 2.9.1, or 2.10.1\. Use the following the command
    to build the Kafka source:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In Kafka 8.x onwards, the Gradle tool is used to compile the Kafka source code
    (available in `kafka-0.8.1.1-src.tgz`) and build the Kafka binaries (JAR files).
    Similar to Kafka JAR, the unit test or source JAR can also be built using the
    Gradle build tool. For more information on build-related instructions, refer to
    [https://github.com/apache/kafka/blob/0.8.1/README.md](https://github.com/apache/kafka/blob/0.8.1/README.md).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have seen how companies are evolving the mechanism of collecting
    and processing application-generated data, and are learning to utilize the real
    power of this data by running analytics over it.
  prefs: []
  type: TYPE_NORMAL
- en: You also learned how to install 0.8.1.x. The following chapter discusses the
    steps required to set up single- or multi-broker Kafka clusters.
  prefs: []
  type: TYPE_NORMAL
