- en: Memory Management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Memory efficiency is one of the major requirements for embedded applications.
    Since target embedded platforms often have limited performance and memory capabilities,
    developers need to know how to use available memory in the most efficient way.
  prefs: []
  type: TYPE_NORMAL
- en: Surprisingly, the most efficient way does not necessarily mean that the least
    amount of memory is used. Since embedded systems are specialized, developers know
    in advance which applications or components will be executed on the system. Saving
    memory in one application does not result in any gain unless another application
    running in the same system can use the extra memory. That is why the most important
    characteristic of memory management in embedded systems is determinism, or predictability.
    It is much more important to know that an application can use two megabytes of
    memory under any load than knowing an application can use one megabyte of memory
    most of the time, but can occasionally require three megabytes.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, predictability also applies to memory allocation and deallocation
    time. In many situations, embedded applications favor spending more memory to
    achieve deterministic timing.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will learn several of memory management techniques  that
    are widely used in embedded applications. The recipes covered in this chapter
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Using dynamic memory allocation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring object pools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using ring buffers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using shared memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using specialized memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These recipes will help you understand memory management best practices and
    can be used as building blocks when working with memory allocation in your applications.
  prefs: []
  type: TYPE_NORMAL
- en: Using dynamic memory allocation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Dynamic memory allocation is a common practice among C++ developers, and it
    is widely utilized in the C++ standard library; however, in the context of embedded
    systems, it often becomes a source of issues that are hard to discover and hard
    to avoid.
  prefs: []
  type: TYPE_NORMAL
- en: The most notable issue is timing. The worst-case time for memory allocation
    is not-bound; however, embedded systems, especially those controlling real-world
    processes or equipment, are often required to respond within a specific amount
    of time.
  prefs: []
  type: TYPE_NORMAL
- en: Another problem is fragmentation. When memory blocks of different sizes are
    allocated and deallocated, memory regions appear that are technically free but
    cannot be allotted because they are too small to fulfill an application request.
    Memory fragmentation grows over time and can lead to the situation where a memory
    allocation request fails despite a substantial total amount of free memory.
  prefs: []
  type: TYPE_NORMAL
- en: A simple yet powerful strategy to avoid these types of issue is to allocate
    all the memory that an application might need in advance at compile time or at
    startup time. Then the application uses this memory as needed. This memory, once
    allocated, is never freed until the application terminates.
  prefs: []
  type: TYPE_NORMAL
- en: A disadvantage of this approach is that the application allocates more memory
    than it really uses at this point in time instead of letting other applications
    use it. In practice, this is not an issue for embedded applications, since they
    are running within a controlled environment, where all applications and their
    memory needs are known in advance.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we will learn how to preallocate memory and use it later in
    your application:'
  prefs: []
  type: TYPE_NORMAL
- en: In your working `~/test` directory, create a subdirectory called `prealloc`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use your favorite text editor to create a file called `prealloc.cpp` in the
    `prealloc` subdirectory. Copy the following code snippet into the `prealloc.cpp` file
    to define a `SerialDevice` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the `main` function that uses the `SerialDevice` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a file called `CMakeLists.txt` in the `loop` subdirectory with the following
    content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You can now build and run the application. It does not output any data since
    its purpose is to demonstrate how we preallocate memory in advance without knowing
    the number of devices and the size of the messages we exchange with devices.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we define objects that encapsulate data exchange with serial
    devices. A device is identified by a device file name string of variable length.
    We can send and receive messages of variable length to and from devices.
  prefs: []
  type: TYPE_NORMAL
- en: Since we can only discover the number of devices connected to the system at
    runtime, we might be tempted to create a device object when it is discovered.
    Similarly, since we do not know the sizes of the messages we send and receive,
    it is natural to allocate memory for message dynamically.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, we preallocate arrays of uninitialized device objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In turn, each object preallocates a sufficient amount of memory to store messages
    and the device filename:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We use local variables to track the actual size of data in the input and output
    buffers. There is no need to track the size of the file name since it is expected
    to be zero-terminated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, we track the actual amount of devices discovered:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This way, we avoid dynamic memory allocation. It has its costs, though: we
    artificially limit the maximum number of devices and the maximum size of messages
    we support. Secondly, a substantial amount of allocated memory is never used.
    For example, if we support up to 16 devices and only 1 is present in the system,
    we actually use only 1/16 of allocated memory. As mentioned before, this is not
    a problem for embedded systems, since all applications and their requirements
    are predefined. There is no application that can benefit from the extra memory
    it can allocate.'
  prefs: []
  type: TYPE_NORMAL
- en: Exploring object pools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we discussed in the first recipe in this chapter, preallocation of all memory
    used by the application is an efficient strategy that helps embedded applications
    avoid various pitfalls related to memory fragmentation and allocation time.
  prefs: []
  type: TYPE_NORMAL
- en: One disadvantage of ad-hoc memory preallocation is that the application is now
    responsible for the tracking of preallocated object usage.
  prefs: []
  type: TYPE_NORMAL
- en: Object pools aim to hide the burden of object tracking by providing a generalized
    and convenient interface, similar to dynamic memory allocation but working with
    objects in the preallocated arrays.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we will create a simple implementation of an object pool and
    learn how to use it in your applications:'
  prefs: []
  type: TYPE_NORMAL
- en: In your working `~/test` directory, create a subdirectory called `objpool`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use your favorite text editor to create a  `objpool.cpp` file in the `objpool` subdirectory.
    Let''s define a templated `ObjectPool` class. We start with the private data members
    and a constructor:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s add a method to get elements from the pool:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we add a method that returns an element to the pool:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, wrap up the class definition with a small function that returns the number
    of elements that are requested from the pool:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a data type to be stored in the object pool as shown in the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Then add code that works with the object pool:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a file called `CMakeLists.txt` in the `loop` subdirectory with the following
    content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Build the application and copy the resulting executable binary to the target system.
    Use recipes from [Chapter 2](899e14bb-12be-4df1-a42b-60a316ea0af6.xhtml),*Setting
    Up the Environment*, to do it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Switch to the target system terminal. Log in using user credentials, if needed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the binary.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this application, we use the same idea  (static arrays of preallocated objects)
    that we used in the first recipe; however, we wrap it into a templated `ObjectPool` class to
    provide a generic interface for handling objects of different types.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our template has two parameters—a class or a data type of objects stored in
    an instance of the `ObjectPool` class, and the pool size. These parameters are
    used to define two private data fields of the class—an array of objects and an
    array of free indices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Since template parameters are being resolved at compile time, these arrays are
    allocated statically. Additionally, the class has a private data member called
    `top` that acts as an index in the `available` array and points to the next available
    object.
  prefs: []
  type: TYPE_NORMAL
- en: 'The available array contains indices of all objects in the `objects` array
    that are currently available for use. At the very beginning, all objects are free,
    and the available array is populated with indices of all elements in the objects
    array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'When the application needs to get an element from the pool, it invokes the
    `get` method. This method uses the top variable to get the index of the next available
    element in the pool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'When the `top` index reaches the size of the array, it means that no more elements
    can be allocated, and so the method throws an exception to indicate the error
    condition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Objects can be returned into the pool using  `free` . First, it detects an
    index of the element based on its address. The index is calculated as a difference
    between the object address and the pool start address. Since  pool objects are
    stored in memory contiguously, we can easily filter out objects of the same type,
    but not those that originate from this pool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Note that, since the `size_t` type is unsigned, we do not need to check that
    the resulting index is less than zero—it is not possible. If we try to return an
    object to the pool that does not belong to it and has an address less than the
    pool's start address, it will be treated as a positive index anyway.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the object we return belongs to the pool, we update the top counter and
    put the resulting index into the available array for further use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Otherwise, we throw an exception indicating that we tried to return an object
    that was not taken from this pool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The method requested is used to track pool object usage. It returns the top
    variable, which efficiently tracks the number of objects that were claimed but
    have not yet been returned to the pool.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s define a data type and try to work with objects from the pool. We declare
    a struct called `Point` that holds two `int` fields, as shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we create a pool of `Point` objects of size `10`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'We get one object from the pool and populate its data fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The program produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aac88c6f-a95e-44b3-8e8c-3173dac428a9.png)'
  prefs: []
  type: TYPE_IMG
- en: The first line of the output reports one object as requested.
  prefs: []
  type: TYPE_NORMAL
- en: We request one more object and print its data fields as-is, without any initialization.
    The pool reports that two objects were requested, as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Now we return our first object back to the pool and make sure that the count
    of requested objects decreases. We can also note that, even after returning the
    object to the pool, we can read data from it.
  prefs: []
  type: TYPE_NORMAL
- en: Let's claim one more object from the pool. The requested count increases, but
    the requested object is the same as the one we returned on the preceding step.
  prefs: []
  type: TYPE_NORMAL
- en: We can see that `Point c` was not initialized after it was taken from the pool,
    but its fields contain the same values as `Point a`. In fact, now `a` and `c`
    are references to the same object in the pool, and so the modification of variable
    `a` will affect variable `c`. This is one of the limitations of our implementation
    of the object pool.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we create a local `Point` object and try to return it into the pool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'It is expected to fail with an exception, and it does. In the program output,
    you can see an `Exception caught: Freeing object that does not belong to the pool` message.'
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even though the implementation of the object pool simplifies working with preallocated
    objects, it has a number of limitations.
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, all objects are created at the very beginning. As a result, calling
    the `get` method of our pool does not trigger an object constructor, and calling
    the `free` method does not call a destructor. Developers need to use various workarounds
    for the initialization and deinitialization of objects.
  prefs: []
  type: TYPE_NORMAL
- en: One possible workaround is to define special methods of the target object, such
    as `initialize` and `deinitialize`, which will be invoked respectively by the
    `get` and `free` methods of the `ObjectPool` class. This approach, however, couples
    the implementation of the classes to the `ObjectPool` implementation. Later in
    the chapter, we will look at more advanced techniques to overcome this limitation.
  prefs: []
  type: TYPE_NORMAL
- en: Our implementation of the pool does not detect whether the `free` method was
    called more than once for an object. It is a mistake, but it is common and leads
    to issues that are hard to debug.  While technically feasible, it adds extra complexity
    to the implementation that is not necessary for this example.
  prefs: []
  type: TYPE_NORMAL
- en: Using ring buffers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A ring buffer, or circular buffer, is a widely used data structure in the embedded
    world. It works as a queue placed on top of a fixed-size memory array. The buffer
    can contain a fixed number of elements. A function that generates these elements
    puts them into the buffer sequentially, one by one. When the end of the buffer
    is reached, it switches to the start of the buffer, as if its first element follows
    the last element.
  prefs: []
  type: TYPE_NORMAL
- en: This design has proven to be remarkably efficient when it comes  to organizing
    data exchange between data producers and consumers that are independent and cannot
    wait for each other, which is a common scenario in embedded development. For example,
    an interrupt service routine should quickly queue data coming from a device for
    further processing, while interrupts are disabled. It cannot wait for the function
    that processes the data if it lags behind. At the same time, the processing function
    does not need to be completely in sync with the **Interrupt Service Routine** (**ISR**);
    it can process several elements at once and catch up with the ISR later.
  prefs: []
  type: TYPE_NORMAL
- en: This, along with the fact that ring they can be preallocated statically, makes
    ring buffers the best choice in many cases.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we will learn how to create and use a ring buffer on top of
    a C++ array:'
  prefs: []
  type: TYPE_NORMAL
- en: In your working `~/test` directory, create a subdirectory called `ringbuf`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use your favorite text editor to create a `ringbuf.cpp` file in the `ringbuf` subdirectory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Define the `RingBuffer` class, starting from the `private` data fields:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we add a method to push data to the buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we add a method to pull data from the buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s add a small method to check whether the buffer contains any data and
    wrap up the class definition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'With `RingBuffer` defined, we can now add code that uses it. Firstly, let''s
    define the data type we are going to use:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Secondly, add the `main` function and define an instance of `RingBuffer` as
    its variable, along with code that tries to work with an empty buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, add code that works with five elements in the buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, add similar code that deals with a larger number of elements that
    can be added:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a file called `CMakeLists.txt` in the `loop` subdirectory with the following
    content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Build the application and copy the resulting executable binary to the target system.
    Use recipes from [Chapter 2](899e14bb-12be-4df1-a42b-60a316ea0af6.xhtml), *Setting
    Up the Environment*, to do it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Switch to the target system terminal. Log in using user credentials, if needed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the binary.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We implement our ring buffer as a templated C++ class that has three private
    data fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '`objects`: A static array of `N` elements of type `T`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`read`: An index to read elements from'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`write`: An index to write elements to'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `RingBuffer` class exposes three public methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`push()`: To write data into the buffer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pull()`: To read data from the buffer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`has_data()`: To check whether the buffer contains data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's take a close look at how they work.
  prefs: []
  type: TYPE_NORMAL
- en: The `push()` method is intended to be used by a function to store data in the
    buffer. Unlike the similar `push()` method for a dynamic queue or dynamic stack,
    which accepts a value to store as a parameter, our implementation does not accept
    any parameters. Since all elements are preallocated at compile time,  it returns
    a reference to a value in the buffer to be updated.
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation of the `push()` method is straightforward; it gets a pointer
    to the element via the `write` index, then advances the `write` index and increments
    the number of elements stored in the buffer. Note how the division remainder operator
    is used to wrap the `write` index to the beginning of the array once it reaches
    the size limit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'What happens if we try to push more elements than the capacity of the `objects`
    array can handle? That depends on the nature of the data we plan to store in the
    buffer. In our implementation, we assume that the receiver is interested in the
    most recent data and can tolerate the loss of intermediate data if it cannot catch
    up with the sender. If the receiver is too slow, it does not matter how many laps
    the sender runs before the receiver `read` data: all data more than `N` steps
    behind is overwritten at this point. That is why, as soon as the number of stored
    elements exceeds `N`, we start advancing the `read` index along with the `write`
    index to keep them exactly `N` steps apart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The `pull()` method is used by functions that read data from the buffer. Similarly
    to the `push()` method, it does not accept any parameters and returns a reference
    to an element in the buffer. Unlike the `push()` method, though, it returns a
    constant reference (as shown in the following code)  to indicate the fact that
    it is not supposed to modify data in the buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Firstly, it checks whether there is data in the buffer and throws an exception
    if the buffer does not contain elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'It gets a reference to an element by the read index, then advances the `read`
    index, applying the same division remainder operator that the `push()` method
    does for the `write` index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The implementation of the `has_data()` method is trivial. It returns `false`
    if the object counter is zero and `true` otherwise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s try it in action. We declare a simple data structure, `Frame`,
    that mimics data generated by a device. It contains a frame index and an opaque
    data buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'We define a ring buffer with a capacity of `10` elements of the `frame `type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s take a look at the program output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/45ab92d8-96c5-42ce-aee0-b49bd991217a.png)'
  prefs: []
  type: TYPE_IMG
- en: Firstly, we try to read from the empty buffer and get an exception, as expected.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we write five elements to the buffer, using characters of the Latin alphabet
    as the data payload:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Note how we get the reference to an element and then update it in-place rather
    than push a local copy of `frame` into the ring buffer. Then we read all the data
    in the buffer and print it on the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The program output indicates that we can successfully read all five elements.
    Now we try to write all 26 letters of the Latin alphabet to the array, way more
    than its capacity.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Then we read the data in the same way that we did for the five elements. The
    read is successful, but we receive only the last 10 elements written; all other
    frames were lost and overwritten by this point. It is not critical for our sample
    application, but maybe this isn't acceptable for many other applications. The
    best way to ensure that data is not being lost is to guarantee that the receiver
    is activated more frequently than the sender. Sometimes the receiver will be activated
    if no data is available in the buffer, but this is an acceptable price to pay
    to avoid data loss.
  prefs: []
  type: TYPE_NORMAL
- en: Using shared memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In modern operating systems running on hardware that supports an **MMU** (short
    for **memory management unit**), each application runs as a process and has its
    memory isolated from other applications.
  prefs: []
  type: TYPE_NORMAL
- en: Such isolation brings important reliability benefits. An application cannot
    accidentally corrupt the memory of another application. Similarly, an application
    that accidentally corrupts its own memory and crashes can be shut down by the
    operating system without affecting other applications in the system. Decoupling
    the functionality of the embedded system into several isolated applications that
    communicate with each other over a well-defined API significantly decreases the
    complexity of the implementation, resulting in improved stability.
  prefs: []
  type: TYPE_NORMAL
- en: The isolation, however, incurs costs. Since each process has its own isolated
    address space, data exchange between two applications implies data copying, context
    switching, and the use of operating system kernel synchronization mechanisms that
    can be relatively expensive.
  prefs: []
  type: TYPE_NORMAL
- en: Shared memory is a mechanism provided by many operating systems to declare certain
    memory regions as shared. This way,  applications can exchange data without copying.
    This is especially important for the exchange of large data objects, such as video
    frames or audio samples.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we will learn how to use a Linux shared memory API for data
    exchange between two or more applications:'
  prefs: []
  type: TYPE_NORMAL
- en: In your working `~/test` directory, create a subdirectory called `shmem`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use your favorite text editor to create a `shmem.cpp` file in the `shmem` subdirectory.
    Define the `SharedMem` class, starting with common headers and constants:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, define a constructor that does most of the work:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the definition of the destructor:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Finalize the class definition with a small method that returns a reference
    to the shared object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Our `SharedMem` class can work with different data types. Let''s declare a
    custom data structure that we want to use:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Now add code that writes data to the shared memory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, add code that reads data from the shared memory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the `main` function to tie everything together, as shown in the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a file called `CMakeLists.txt` in the `loop` subdirectory with the following
    content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Build the application and copy the resulting executable binary to the target system.
    Use recipes from [Chapter 2](899e14bb-12be-4df1-a42b-60a316ea0af6.xhtml),*Setting
    Up the Environment*, to do it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Switch to the target system terminal. Log in using user credentials, if needed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the binary.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we use the **POSIX** (short for **Portable Operating System
    Interface**) API to work with shared memory. This is a flexible and fine-grained
    C API, with lots of parameters that can be tuned or configured. Our goal is to
    hide the complexity of this low-level API by implementing a more convenient and
    type-safe C++ wrapper on top of it. We are going to use the **RAII **(short for **resource
    acquisition is initialization**) idiom to make sure all allocated resources are
    properly deallocated and we do not have memory or file descriptor leaks in our
    application.
  prefs: []
  type: TYPE_NORMAL
- en: 'We define a templated `SharedMem` class. The template argument defines a data
    type that is stored in our shared memory instance. This way, we make instances
    of the `SharedMem` class type safe. Instead of our working with void pointers
    and casting types in the application code, the C++ compiler does it for us automatically:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'All shared memory allocation and initialization is implemented in the `SharedMem`
    constructor. It accepts two parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: A shared memory object name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An ownership flag
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: POSIX defines a `shm_open` API, where shared memory objects are identified by
    names, similar to filenames. This way, two independent processes that use the
    same name can reference the same shared memory object. What is the lifetime of
    the shared object? The shared object is destroyed when the `shm_unlink` function
    is invoked for the same object name. If the object is used by multiple processes,
    the first one that calls `shm_open` will create it, and the others will reuse
    the same object. But which of them is responsible for its deletion? This is what
    the ownership flag is used for. When set to `true`, it indicates that the `SharedMem`
    instance is responsible for the shared object cleanup when it is destroyed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The constructor sequentially calls three POSIX API functions. Firstly, it creates
    a shared object using `shm_open`. Though the function accepts access flags and
    file permissions as its parameters, we always use the read–write access mode and
    read and write access for the current user:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we define the size of the shared region using the `ftruncate` call. We
    use the size of the template data type for this purpose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we map the shared region into our process memory address space using
    the `mmap` function. It returns a pointer that we can use to reference our data
    instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'The object holds the file descriptor for the shared memory block and the pointer
    to the memory region as its private members. The destructor deallocates them when
    the object is being destroyed. If the owner flag is set, we also keep the object
    name so that we can remove it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The `SharedMem` destructor unmaps the shared memory object from the address
    space:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'In the event that the object is the owner, we can remove it using a `shm_unlink`
    call. Note that we do not need the owner flag anymore since the name is set to
    `nullptr`, unless the object is the owner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'To access shared data, the class provides a simple `get` method. It returns
    a reference to the object stored in the shared memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s create two independent processes that use the shared memory API we created.
    We use a POSIX `fork` function to spawn a child process. The child process will
    be a data producer and the parent process will be a data consumer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'We define a `Payload` data type, used by both the producer and the consumer
    for data exchange:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'The data producer creates a `SharedMem` instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: It updates the shared object every 150 milliseconds using the reference it received
    using the `get` method. Each time, it increments the index field of the payload
    and fills its data with letters of the Latin alphabet that match the index.
  prefs: []
  type: TYPE_NORMAL
- en: 'The consumer is as simple as the producer. It creates a `SharedMem` instance
    with the same name as the producer, but it claims the ownership of the object.
    This means that it will be responsible for its deletion, as shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the application and observe the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/714b3428-c62d-4794-b090-b8a3bd2a72ee.png)'
  prefs: []
  type: TYPE_IMG
- en: Every 100 milliseconds, the application reads data from the shared object and
    prints it to the screen. In the consumer output, we can see that it receives data
    written by the producer. Since the duration of the consumer and the producer cycles
    does not match, we can see that sometimes the same data is being read twice
  prefs: []
  type: TYPE_NORMAL
- en: 'An important part of the logic that was intentionally omitted in this example
    is the synchronization of the producer and the consumer. Since they run as independent
    projects, there is no guarantee that the producer has updated any data by the
    time the consumer tries to read it. The following is what we see in the resulting
    output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the consumer opened the shared memory object and read some data
    before the producer opened the same object.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, there is no guarantee that data fields are updated completely by
    the producer when the consumer tries to read them. We will discuss this topic
    in more detail in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Shared memory is a fast and efficient mechanism for inter-process communication
    by itself, but it really shines when combined with ring buffers. By placing a
    ring buffer into shared memory, developers allow independent data producers and
    data consumers to exchange data asynchronously, and with minimal overhead for
    synchronization.
  prefs: []
  type: TYPE_NORMAL
- en: Using specialized memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Embedded systems often provide access to their peripheral devices over specific
    ranges of memory addresses. When a program accesses an address in such a region,
    it does not read or write a value in memory. Instead, data is sent to a device
    or read from a device mapped to this address.
  prefs: []
  type: TYPE_NORMAL
- en: This technique is commonly named **MMIO** (short for **memory-mapped input**/**output**).
    In this recipe, we will learn how to access peripheral devices of the Raspberry
    PI using MMIO from userspace Linux applications.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Raspberry PI has a number of peripheral devices that are accessible over
    MMIO. To demonstrate how MMIO works, our application will access the system timer:'
  prefs: []
  type: TYPE_NORMAL
- en: In your working `~/test` directory, create a subdirectory called `timer`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use your favorite text editor to create a file named `timer.cpp` in the `timer` subdirectory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Put the required headers, constants, and declarations of types into `timer.cpp`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the `main` function, which contains all the logic of the program:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a file called `CMakeLists.txt` in the `timer` subdirectory with the
    following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: You can now build and run the application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Please note that it should be run under `root` on a real Raspberry PI 3 device.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The system timer is a peripheral device that is connected to the processor using
    an MMIO interface. This means it has a dedicated range of physical addresses,
    each of them with a specific format and purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Our application works with a timer counter represented as two 32-bit values.
    Combined, they form a 64-bit read-only counter always incrementing when the system
    is running.
  prefs: []
  type: TYPE_NORMAL
- en: For the Raspberry PI 3, a physical memory address range allocated for the system
    timer has offset the following —`0x3F003000` (it may be different depending on
    the Raspberry PI hardware revision). We define it as a constant.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'To access individual fields within the region, we define a `SystemTimer` struct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: Now, we need to get the pointer to the timer address range and convert it to
    a pointer to  `SystemTimer`. This way, we can access the addresses of the counter
    by reading the `SystemTimer` data fields.
  prefs: []
  type: TYPE_NORMAL
- en: There is, however, a problem we need to solve. We know the offset in the physical
    address space, but our Linux application works within the virtual address space.
    We need to find a way to map physical addresses to virtual addresses.
  prefs: []
  type: TYPE_NORMAL
- en: Linux provides access to physical memory addresses using the special `/proc/mem` file.
    Since it contains a snapshot of all physical memory, it is accessible only by `root`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We open it as a regular file using the `open` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the file is open and we know its descriptor, we can map it into our virtual
    address space. We do not need to map the whole physical memory. A region related
    to the timer is sufficient; that is why we pass the system timer range start as
    an offset parameter and the size of the `SystemTimer` structure as the size parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can access the timer fields. We read the timer counter in the loop and
    display its current value and its variance from the preceding value. When we run
    our application as `root`, we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aa941e90-c2ed-49d6-a79c-c813bc3b95aa.png)'
  prefs: []
  type: TYPE_IMG
- en: As we can see, reading from this memory address returns increasing values. The
    value of the difference is around 10,000 and pretty constant. Since we added a
    10-millisecond delay into the counter read loop,  we can infer that the memory
    address is associated with the timer, not regular memory, and the timer counter
    granularity is 1 microsecond.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Raspberry Pi has a number of peripheral devices that are accessible over
    MMIO. You can find detailed information about their address ranges and access
    semantics in the *BCM2835 ARM Peripherals manual*, available at [https://www.raspberrypi.org/documentation/hardware/raspberrypi/bcm2835/BCM2835-ARM-Peripherals.pdf](https://www.raspberrypi.org/documentation/hardware/raspberrypi/bcm2835/BCM2835-ARM-Peripherals.pdf)
  prefs: []
  type: TYPE_NORMAL
- en: Please note that developers have to be extremely careful when working with memory
    that can be accessed by multiple devices simultaneously. When memory is accessible
    by multiple processors or multiple cores of the same processor, you may need to
    use advanced synchronization techniques such as memory barriers to avoid synchronization
    issues. We will discuss some of them in the next chapter. Things become even more
    complicated if you use **direct memory access** (**DMA**), or MMIO. Since the
    CPU may be unaware that memory is changed by external hardware, its cache may
    be out of sync, leading to data-coherency issues.
  prefs: []
  type: TYPE_NORMAL
