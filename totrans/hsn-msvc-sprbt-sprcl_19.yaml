- en: Deploying Our Microservices to Kubernetes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将我们的微服务部署到Kubernetes
- en: In this chapter, we will deploy the microservices in this book to Kubernetes.
    We will also learn about some of the core features of Kubernetes, such as using
    **Kustomize** to configure deployments for different runtime environments and
    using Kubernetes deployments object for rolling upgrades. Before we do that, we
    need to review how we use service discovery. Since Kubernetes comes with built-in
    support for service discovery, it seems unnecessary to deploy our own since we
    have been using Netflix Eureka up to this point.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将把本书中的微服务部署到Kubernetes。我们还将学习Kubernetes的一些核心功能，例如使用**Kustomize**为不同的运行时环境配置部署，以及使用Kubernetes部署对象进行滚动升级。在这之前，我们需要回顾一下我们如何使用服务发现。由于Kubernetes内置支持服务发现，似乎不必部署我们自己的服务发现，因为到目前为止我们一直在使用Netflix
    Eureka。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Replacing Netflix Eureka with Kubernetes `Service` objects and `kube-proxy`
    for service discovery
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Kubernetes `Service`对象和`kube-proxy`替换Netflix Eureka进行服务发现
- en: Using Kustomize to prepare the microservices to be deployed in different environments
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Kustomize准备微服务以在不同环境中部署
- en: Testing the deployments with a version of the test script, `test-em-all.bash`
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用测试脚本`test-em-all.bash`的版本测试部署
- en: Performing rolling upgrades
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行滚动升级
- en: Learning how to roll back a failed upgrade
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习如何回滚失败的升级
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: All the commands that are described in this book are run on a MacBook Pro using
    macOS Mojave but should be straightforward to modify if you want to run them on
    another platform such as Linux or Windows.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中描述的所有命令都在使用macOS Mojave的MacBook Pro上运行，但如果您想在其他平台上运行它们，如Linux或Windows，应该很容易修改。
- en: 'The only new tool that''s required for this chapter is the `siege` command-line
    tool, which is used for HTTP-based load testing and benchmarking. We will use
    `siege` to put some load on the Kubernetes cluster while performing rolling upgrades.
    The tool can be installed using Homebrew with the following commands:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章唯一需要的新工具是`siege`命令行工具，用于基于HTTP的负载测试和基准测试。我们将使用`siege`在执行滚动升级时对Kubernetes集群施加一些负载。该工具可以使用Homebrew安装，命令如下：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The source code for this chapter can be found in this book's GitHub repository: [https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter16](https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter16).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的源代码可以在本书的GitHub存储库中找到：[https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter16](https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter16)。
- en: 'To be able to run the commands that are described in this book, you need to
    download the source code to a folder and set up an environment variable, `$BOOK_HOME`,
    that points to that folder. Some sample commands are as follows:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够运行本书中描述的命令，您需要将源代码下载到一个文件夹，并设置一个环境变量`$BOOK_HOME`，指向该文件夹。一些示例命令如下：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: All the source code examples in this chapter come from the source code in `$BOOK_HOME/Chapter16` and have
    been tested using Kubernetes 1.15.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的所有源代码示例都来自`$BOOK_HOME/Chapter16`中的源代码，并且已经使用Kubernetes 1.15进行了测试。
- en: If you want to see the changes that were applied to the source code in this
    chapter, that is, see the changes that are required to be able to deploy the microservices
    on Kubernetes, you can compare it with the source code for [Chapter 15](87949e5b-2761-4dc1-a70c-d9d21f03d530.xhtml),
    *Introduction to Kubernetes*. You can use your favorite `diff` tool and compare
    the two folders, `$BOOK_HOME/Chapter15` and `$BOOK_HOME/Chapter16`.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想查看本章中应用于源代码的更改，即查看部署微服务到Kubernetes所需的更改，您可以将其与[第15章](87949e5b-2761-4dc1-a70c-d9d21f03d530.xhtml)的源代码进行比较，*Kubernetes简介*。您可以使用您喜欢的`diff`工具比较两个文件夹，`$BOOK_HOME/Chapter15`和`$BOOK_HOME/Chapter16`。
- en: Replacing Netflix Eureka with Kubernetes services
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Kubernetes服务替换Netflix Eureka
- en: As shown in the previous chapter, [Chapter 15](87949e5b-2761-4dc1-a70c-d9d21f03d530.xhtml),
    *Introduction to Kubernetes*, Kubernetes comes with a built-in discovery service
    based on Kubernetes `Service` objects and the `kube-proxy` runtime component.
    This makes it unnecessary to deploy a separate discovery service such as Netflix
    Eureka, which we used in the previous chapters. An advantage of using Kubernetes
    discovery service is that it doesn't require a client library such as Netflix
    Ribbon, which we have been using together with Netflix Eureka. This makes the
    Kubernetes discovery service easy to use, independent of which language or framework
    a microservice is based on. A drawback of using the Kubernetes discovery service
    is that it only works in a Kubernetes environment. However, since the discovery
    service is based on `kube-proxy`, which accepts requests to the DNS name or IP
    address of a service object, it should be fairly simple to replace it with a similar
    discovery service, for example, one that comes bundled with another container
    orchestrator.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一章[第15章](87949e5b-2761-4dc1-a70c-d9d21f03d530.xhtml)所示，*Kubernetes简介*，Kubernetes带有基于Kubernetes
    `Service`对象和`kube-proxy`运行组件的内置发现服务。这使得不必部署单独的发现服务，例如我们在前几章中使用的Netflix Eureka。使用Kubernetes发现服务的优势在于它不需要像Netflix
    Ribbon这样的客户端库，我们一直与Netflix Eureka一起使用。这使得Kubernetes发现服务易于使用，独立于微服务所基于的语言或框架。使用Kubernetes发现服务的缺点在于它仅在Kubernetes环境中工作。但是，由于发现服务基于`kube-proxy`，它接受对服务对象的DNS名称或IP地址的请求，因此应该很容易用类似的发现服务替换它，例如，与另一个容器编排器捆绑在一起的发现服务。
- en: 'To summarize this, we will remove the discovery server based on Netflix Eureka
    from our microservice landscape, as illustrated in the following diagram:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我们将从我们的微服务架构中删除基于Netflix Eureka的发现服务器，如下图所示：
- en: '![](img/8b8eed5f-e4b6-4d3a-85a1-e0df126462ee.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8b8eed5f-e4b6-4d3a-85a1-e0df126462ee.png)'
- en: 'To replace the discovery server based on Netflix Eureka with the Kubernetes
    built-in discovery service, the following changes have been applied to the source
    code:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 用Kubernetes内置的发现服务替换基于Netflix Eureka的发现服务器时，对源代码进行了以下更改：
- en: Netflix Eureka and the Ribbon-specific configuration (client and server) have
    been removed from the configuration repository, `config-repo`.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已从配置存储库`config-repo`中删除了Netflix Eureka和Ribbon特定的配置（客户端和服务器）。
- en: Routing rules in the gateway service to the Eureka server have been removed
    from the `config-repo/gateway.yml` file.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网关服务到Eureka服务器的路由规则已从`config-repo/gateway.yml`文件中删除。
- en: We've removed the Eureka server project, that is, we've removed the `spring-cloud/eureka-server` folder.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们已删除了Eureka服务器项目，也就是说，我们已删除了`spring-cloud/eureka-server`文件夹。
- en: We've removed the Eureka server from the Docker Compose files and the `settings.gradle` Gradle
    file.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们已经从Docker Compose文件和`settings.gradle`Gradle文件中删除了Eureka服务器。
- en: We've removed the dependency to `spring-cloud-starter-netflix-eureka-client`
    in all of Eureka's client build files, that is, `build.gradle`.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们已从所有Eureka的客户端构建文件中删除了对`spring-cloud-starter-netflix-eureka-client`的依赖，即`build.gradle`。
- en: We've removed the no-longer-required `eureka.client.enabled=false` property
    setting from all of Eureka's client integration tests.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们已从所有Eureka的客户端集成测试中删除了不再需要的`eureka.client.enabled=false`属性设置。
- en: The gateway service no longer uses routing based on the client-side load balancer
    in Spring Cloud using the `lb` protocol. For example,  the `lb://product-composite` routing
    destination has been replaced by the `http://product-composite` in the `config-repo/gateway.yml` file.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网关服务不再使用基于Spring Cloud中客户端负载均衡器的路由，使用`lb`协议。例如，`lb://product-composite`路由目的地已在`config-repo/gateway.yml`文件中被`http://product-composite`替换。
- en: 'The HTTP port used by the microservices and the authorization server has been
    changed from port the `8080` port (`9999` in the case of the authorization server)
    to the default HTTP port `80`. This has been configured in `config-repo` for each
    affected service like so:'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务和授权服务器使用的HTTP端口已从端口`8080`（授权服务器的情况下为`9999`）更改为默认的HTTP端口`80`。这已在`config-repo`中为每个受影响的服务进行了配置，如下所示：
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'None of the HTTP addresses that we are using are affected by the replacement
    of Netflix Eureka with Kubernetes services. For example, addresses used by the
    composite service are unaffected:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的HTTP地址都不受Netflix Eureka替换为Kubernetes服务的影响。例如，复合服务使用的地址不受影响：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This is achieved by changing the HTTP port used by the microservices and the
    authorization server to the default HTTP port, `80`, as described previously.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将微服务和授权服务器使用的HTTP端口更改为默认的HTTP端口`80`来实现这一点，如前所述。
- en: Using Docker Compose still works, even though Netflix Eureka has been removed.
    This can be used for running functional tests of the microservices without deploying
    them to Kubernetes, for example, running `test-em-all.bash` together with Docker
    for macOS in the same way as in the previous chapters. Removing Netflix Eureka,
    however, means that we no longer have a discovery service in place when using
    plain Docker and Docker Compose. Therefore, scaling microservices will only work
    when deploying to Kubernetes.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管已删除Netflix Eureka，但仍然可以使用Docker Compose。这可用于在不将微服务部署到Kubernetes的情况下运行功能测试，例如，在macOS上与Docker一起运行`test-em-all.bash`，就像在以前的章节中一样。然而，删除Netflix
    Eureka意味着在使用纯Docker和Docker Compose时，我们不再有发现服务。因此，只有在部署到Kubernetes时，才能扩展微服务。
- en: Now that we've familiarized ourselves with Kubernetes services, let's move on
    to Kustomize, a tool that's used for customizing Kubernetes objects.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经熟悉了Kubernetes服务，让我们继续学习Kustomize，这是一个用于定制Kubernetes对象的工具。
- en: Introducing Kustomize
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍Kustomize
- en: '**Kustomize** is a tool that''s used for creating environment-specific customizations
    of the Kubernetes definitions files, that is, the YAML files, for example, for development,
    test, staging, and production environments. Common definition files are stored
    in a `base` folder, while environment-specific additions are kept in environment-specific
    `overlay` folders. Environment-specific information can, for example, be any of
    the following:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kustomize**是一个用于创建Kubernetes定义文件的特定环境自定义的工具，即YAML文件，例如用于开发、测试、暂存和生产环境。通用定义文件存储在`base`文件夹中，而特定环境的附加内容存储在特定环境的`overlay`文件夹中。特定环境的信息可以是以下内容之一：'
- en: What version of the Docker images to use
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要使用的Docker镜像的版本
- en: Number of replicas to run
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要运行的副本数量
- en: Resource quotas in terms of CPU and memory
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 资源配额以CPU和内存为单位
- en: Each folder contains a `kustomization.yml` file that describes its content for
    Kustomize. When deploying to a specific environment, Kustomize will take the content
    from the `base` folder and the environment-specific `overlay` folder and send
    the combined result to `kubectl`. Properties from the files in the `overlay` folder
    will override the corresponding properties in the `base` folder, if any.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 每个文件夹都包含一个`kustomization.yml`文件，描述了其内容的Kustomize。在部署到特定环境时，Kustomize将从`base`文件夹和特定环境的`overlay`文件夹中获取内容，并将组合结果发送到`kubectl`。`overlay`文件夹中的文件属性将覆盖`base`文件夹中的相应属性（如果有）。
- en: 'In this chapter, we will set up customizations for two sample environments:
    development and production.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将为两个示例环境（开发和生产）设置自定义。
- en: 'The folder structure under `$BOOK_HOME/Chapter16` looks as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在`$BOOK_HOME/Chapter16`下的文件夹结构如下：
- en: '![](img/a62901e6-d94d-49e1-be8f-22ba37d810c2.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a62901e6-d94d-49e1-be8f-22ba37d810c2.png)'
- en: Since Kubernetes 1.14, `kubectl` comes with built-in support for Kustomize using
    the `-k` flag. As we will see as we proceed, deploying to the development environment
    using Kustomize will be done with the `kubectl apply -k kubernetes/services/overlays/dev` command.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 自Kubernetes 1.14以来，`kubectl`带有内置支持Kustomize，使用`-k`标志。随着我们的进行，使用Kustomize部署到开发环境将使用`kubectl
    apply -k kubernetes/services/overlays/dev`命令完成。
- en: Setting up common definitions in the base folder
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在基本文件夹中设置通用定义
- en: In the `base` folder, we will have one definition file for each microservice,
    but none for the resource managers (MongoDB, MySQL, and RabbitMQ). The resource
    managers will only be deployed in Kubernetes in the development environment and
    are expected to run outside of Kubernetes in the production environment—for example,
    in an existing database and queue manager service on premises or as a managed
    service in the cloud.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: 'The definition files in the `base` folder contain a deployment object and a
    service object for each microservice. Let''s go through a typical deployment object
    in `kubernetes/services/base/product.yml`. It is geared toward what is required
    in a development environment. It starts with the following code:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This part looks exactly the same as it does for the NGINX deployment we used
    in the previous chapter, [Chapter 15](87949e5b-2761-4dc1-a70c-d9d21f03d530.xhtml),
    *Introduction to Kubernetes*, in the *Trying out a sample deployment* section,
    so we don't need to go through it again.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: 'The next part looks a bit different:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let''s explain the preceding source code in more detail:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: The Docker image specified, `hands-on/product-service`, will be created underneath
    where we build our microservices. See the *Building Docker images* section for
    more information.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `imagePullPolicy: Never` declaration tells Kubernetes to not try to download
    the Docker image from a Docker registry. See the *Building Docker images* section
    for further information.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `SPRING_PROFILES_ACTIVE` environment variable is defined to tell the Spring
    application to use the `docker` Spring profile in the configuration repository.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A secret, `config-client-credentials`, is used to provide the container with
    credentials for accessing the configuration server.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The HTTP port that's used is the default HTTP port `80`.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A resource limit is defined to maximize the available memory to 350 MB, that
    is, in the same way as when we used Docker Compose in the previous chapters.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The last part of the declaration of the deployment object contains liveness
    and readiness probes:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let''s explain the preceding source code in more detail:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: The **liveness** **probe** is based on an HTTP request that's sent to the Spring
    Boot Actuator `info` endpoint. This means that if the microservice instance is
    in such bad shape that it is not capable of responding 200 (OK) to a request that's
    sent to the lightweight `info` endpoint, it is time for Kubernetes to restart
    the microservice instance.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **readiness probe** is based on an HTTP request that's sent to the Spring
    Boot Actuator `health` endpoint. Kubernetes will only send requests to the microservice
    instance if its `health` endpoint responds with the HTTP status 200 (OK). Not
    responding with 200 (OK) typically means that the microservice instance has problems
    with reaching some of the resources it depends on, and so it makes sense to not
    send any requests to a microservice instance when it does not respond with 200
    (OK) on the `health` endpoint.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The liveness and the readiness probes can be configured using the following
    properties:'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`initialDelaySeconds` specifies how long Kubernetes waits to probe a container
    after it''s started up.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`periodSeconds` specifies the time between probe requests sent by Kubernetes.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timeoutSeconds` specifies how long Kubernetes waits on a response before it
    treats the probe as failed.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`failureThreshold` specifies how many failed attempts Kubernetes makes before
    giving up. In the case of a liveness probe, this means restarting the pod. In
    the case of a readiness probe, it means that Kubernetes will not send any more
    requests to the container.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`successThreshold` specifies the number of successful attempts that are required
    for a probe to be considered successful again after a failure. This only applies
    to readiness probes since they must be set to `1` if specified for liveness probes.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding optimal settings for the probes can be challenging, that is, finding
    a proper balance between getting a swift reaction from Kubernetes when the availability
    of a pod changes and not overloading the pods with probe requests. Specifically
    configuring a liveness probe with values that are too low can result in Kubernetes
    restarting pods that just take some time to start, that is, that don't need to
    be restarted. Starting a large number of pods with values that have been set too
    low on the liveness probes can result in a lot of unnecessary restarts. Setting
    the configuration values too high on the probes (except for the `successThreshold`
    value) makes Kubernetes react slower, which can be annoying in a development environment.
    Proper values also depend on the available hardware, which affects the startup
    times for the pods. For the scope of this book, `failureThreshold` for the liveness
    probes is set to a high value, `20`, to avoid unnecessary restarts on computers
    with limited hardware resources.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: 'The service object in `kubernetes/services/base/product.yml` looks as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The service object looks similar to the NGINX service object we used in the
    previous chapter, [Chapter 15](87949e5b-2761-4dc1-a70c-d9d21f03d530.xhtml), *Introduction
    to Kubernetes*, in the *Trying out a sample deployment* section. One difference
    is that the service type is `ClusterIP` (which is the default type and therefore
    not specified). The service object will receive internal requests on port `80`
    and forward them to the target port, `80`, on the selected pod. The only exception
    to this is the gateway microservice that is exposed externally using a `NodePort`
    service on the host''s port, that is, `31443`:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Finally, we have the Kustomize file that binds everything together in the `base`
    folder:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: It simply lists the YAML definition files that Kustomize shall use in the `base`
    folder.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Now, we will see how we can use these base definitions with the definitions
    in the `overlay` folders, and see how they are applied using the `-k` switch with
    the `kubectl apply` command.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Deploying to Kubernetes for development and test
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will deploy the microservices in an environment to be used
    for development and test activities, for example, system integration tests. This
    type of environment is used primarily for functional tests and is therefore configured
    to use minimal system resources.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the deployment objects in the `base` folder are configured for a development
    environment, they don''t need any further refinement in the overlay for development.
    We only have to add deployment and service objects for the three resource managers
    for RabbitMQ, MySQL, and MongoDB in the same way as when using Docker Compose.
    We will deploy the resource managers in the same Kubernetes namespace as the microservices.
    This is illustrated by the following diagram:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c5ebe638-fb4c-4344-ab1d-2cd3b1698480.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
- en: The definition files for the resource managers can be found in the `kubernetes/services/overlays/dev` folder.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: 'The `kustomization.yml` file looks like this:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: It defines that the `base` folder shall be used as the base and adds the three
    resources we mentioned previously.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Building Docker images
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Normally, we have to push images to a Docker registry and configure Kubernetes
    to pull images from the registry. In our case, where we have a local single node
    cluster, we can shortcut this process by pointing our Docker client to the Docker
    engine in Minikube and then run the `docker-compose build` command. This will
    result in the Docker images being immediately available to Kubernetes. For development,
    we will be using `latest` as the Docker image version for the microservices.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: You might be wondering how we can update a pod that uses the `latest` Docker
    image.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: From Kubernetes 1.15, this is very simple. Just change the code and rebuild
    the Docker image, for example, using the `build` command that's described here.
    Then, update a pod with the `kubectl rollout restart` command.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: For example, if the `product` service has been updated, run the `kubectl rollout
    restart deploy product` command.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: 'You can build Docker images from source as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The `eval $(minikube docker-env)` command directs the local Docker client to
    communicate with the Docker engine in Minikube, for example, when building the
    Docker images.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: 'The `docker-compose.yml` file has been updated to specify a name for the Docker
    images it builds. For example, for the `product` service, we have the following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '`latest` is the default tag for a Docker image name, so it is not specified.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: With the Docker images built, we can start creating the Kubernetes resource
    objects!
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Deploying to Kubernetes
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we can deploy the microservices to Kubernetes, we need to create a namespace,
    the required config maps, and secrets. After the deployment is performed, we will
    wait for the deployments to be up and running, and also verify that we got the
    expected result in terms of deployed pods and Docker images that were used per
    pod.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a namespace, `hands-on`, and set it as the default namespace for `kubectl`:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: All application configuration is kept in the configuration repository that's
    managed by the configuration server. The only configuration information that needs
    to be stored outside of the configuration repository is the credentials for connecting
    to the configuration server and an encryption key. The encryption key is used
    by the configuration server to keep sensitive information in the configuration
    repository encrypted at rest, that is, on disk.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: We will store the configuration repository in a config map with all the sensitive
    information encrypted; see [Chapter 12](a250774a-03a1-41b1-b935-cbeb9624b6e3.xhtml),
    *Centralized Configuration*, for details. The credentials for connecting to the
    configuration server and the encryption key will be stored in two secrets, one
    for the configuration server and one for its clients.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: 'To check this, perform the following steps:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the config map for the configuration repository based on the files in
    the `config-repo` folder with the following command:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Create the secret for the configuration server with the following command:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Create the secret for the clients of the configuration server with the following
    command:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Since we have just entered commands that contain sensitive information in clear
    text, for example, passwords and an encryption key, it is a good idea to clear
    the `history` command. To clear the `history` command both in memory and on disk,
    run the `history -c; history -w` command.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: See the discussion at [https://unix.stackexchange.com/a/416831](https://unix.stackexchange.com/a/416831)
    for details on the `history` command.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: 'To avoid a slow deployment due to Kubernetes downloading Docker images (potentially
    causing the liveness probes we described previously to restart our pods), run
    the following `docker pull` commands to download the images:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Deploy the microservices for the development environment, based on the `dev`
    overlay, using the `-k` switch to activate Kustomize, as described previously:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Wait for the deployments and their pods to be up and running by running the
    following command:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Expect each command to respond with `deployment.extensions/... condition met`.
    `...` will be replaced with the name of the actual deployment.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: 'To see the Docker images that are used for development, run the following command:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The response should look similar to the following:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/42300572-7769-4a8b-9b4d-5efd9d361dab.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
- en: We are now ready to test our deployment!
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: But before we can do that, we need to go through changes that are required in
    the test script for use with Kubernetes.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Changes in the test script for use with Kubernetes
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To test the deployment we will, as usual, run the test script, that is, `test-em-all.bash`.
    To work with Kubernetes, the circuit breaker tests have been slightly modified.
    Take a look at the `testCircuitBreaker()` function for more details. The circuit
    breaker tests call the `actuator` endpoints on the `product-composite` service
    to check their health state and get access to circuit breaker events. The `actuator`
    endpoints are not exposed externally, so the test script needs to use different
    techniques to access the internal endpoints when using Docker Compose and Kubernetes:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: When using Docker Compose, the test script will launch a Docker container using
    a plain `docker run` command that calls the `actuator` endpoints from the inside
    of the network created by Docker Compose.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When using Kubernetes, the test script will launch a Kubernetes pod that it
    can use to run the corresponding commands inside Kubernetes.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's see how this is done when using Docker Compose and Kubernetes.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Reaching the internal actuator endpoint using Docker Compose
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The base command that''s defined for Docker Compose is as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note that the container will be killed using the `--rm` switch after each execution
    of a test command.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Reaching the internal actuator endpoint using Kubernetes
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since launching a pod in Kubernetes is slower than starting a container, the
    test script will launch a single pod, `alpine-client`. The pod will be launched at
    the start of the `testCircuitBreaker()` function, and the tests will use the `kubectl
    exec` command to run the test commands in this pod. This will be much faster than
    creating and deleting a pod for each test command.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: 'Launching the single pod is handled at the beginning of the `testCircuitBreaker()`
    function:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'At the end of the circuit breaker tests, the pod is deleted by using the following
    command:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Choosing between Docker Compose and Kubernetes
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To make the test script work with both Docker Compose and Kubernetes, it assumes
    that Docker Compose will be used if the `HOST` environment variable is set to
    `localhost`; otherwise, it assumes that Kubernetes will be used. See the following
    code:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The default value for the `HOST` environment variable in the test script is `localhost`.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the `EXEC` variable has been set up, depending on whether the tests are
    running on Docker Compose or on Kubernetes, it is used in the `testCircuitBreaker()` test
    function. The test starts by verifying that the circuit breaker is closed with
    the following statement:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: A final change in the test script occurs because our services are now reachable
    on the `80` port inside the cluster; that is, they are no longer on the `8080`
    port.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: If the various ports that we've used seem confusing, review the definitions
    of the services in the *Setting up common definitions in the base folder* section.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: Testing the deployment
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When launching the test script, we have to give it the address of the host that
    runs Kubernetes, that is, our Minikube instance, and the external port where our
    gateway service listens for external requests. The `minikube ip` command can be
    used to find the IP address of the Minikube instance and, as mentioned in the
    *Setting up common definitions in the base folder* section, we have assigned the
    external `NodePort 31443` to the gateway service.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: 'Start the tests with the following command:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'In the output from the script we will see how the IP address of the Minikube
    instance is used and also how the `alpine-client` pod is created and destroyed:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/97c12d92-177b-46e9-9f35-57cef2157850.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
- en: Before we move on and look at how to set up a corresponding environment for
    staging and production use, let's clean up what we have installed in the development
    environment to preserve resources in the Kubernetes cluster. We can do this by
    simply deleting the namespace. Deleting the namespace will recursively delete
    the resources that exist in the namespace.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: 'Delete the namespace with the following command:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: With the development environment removed, we can move on and set up an environment
    targeting staging and production.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 随着开发环境的移除，我们可以继续设置一个面向**暂存和生产**的环境。
- en: Deploying to Kubernetes for staging and production
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Kubernetes上部署到**暂存**和生产
- en: In this section, we will deploy the microservices in an environment for staging
    and production usage. A staging environment is used for performing **quality**
    **assurance** (**QA**) and **user acceptance tests** (**UAT**) as the last step
    before taking a new release into production. To be able to verify that the new
    release not only meets functional requirements but also non-functional requirements,
    for example, in terms of performance, robustness, scalability, and resilience,
    a staging environment is configured to be as similar as possible to the production
    environment.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将在用于暂存和生产的环境中部署微服务。暂存环境用于执行**质量** **保证**（**QA**）和**用户验收测试**（**UAT**），作为将新版本发布到生产之前的最后一步。为了能够验证新版本不仅满足功能要求，还满足非功能要求，例如性能、稳健性、可伸缩性和弹性方面的要求，暂存环境被配置为尽可能与生产环境相似。
- en: 'When deploying to an environment for staging or production, there are a number
    of changes required compared to when deploying for development or tests:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署到用于**暂存**或生产的环境时，与在部署到开发或测试时相比，需要进行一些变更：
- en: '**Resource managers should run outside of the Kubernetes cluster**: It is technically
    feasible to run databases and queue managers for production use on Kubernetes
    as stateful containers using `StatefulSets` and `PersistentVolumes`. At the time
    of writing this chapter, I recommend against it, mainly because the support for
    stateful containers is relatively new and unproven in Kubernetes. Instead, I recommend using
    the existing database and queue manager services on premises or managed services
    in the cloud, leaving Kubernetes to do what it is best for, that is, running stateless
    containers. For the scope of this book, to simulate a production environment,
    we will run MySQL, MongoDB, and RabbitMQ as plain Docker containers outside of
    Kubernetes using the already existing Docker Compose files.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源管理器应在Kubernetes集群之外运行**：从技术上讲，可以在Kubernetes上以有状态容器的形式使用`StatefulSets`和`PersistentVolumes`来运行数据库和队列管理器以供生产使用。在撰写本章时，我建议不要这样做，主要是因为对于有状态容器的支持在Kubernetes中是相对较新且未经验证的。相反，我建议在本地或云中使用现有的数据库和队列管理器服务，让Kubernetes专注于其最擅长的事情，即运行无状态容器。为了模拟生产环境，我们将在Kubernetes之外使用已有的Docker
    Compose文件运行MySQL、MongoDB和RabbitMQ作为普通的Docker容器。'
- en: '**Lockdown:**'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**封锁：**'
- en: For security reasons, things like `actuator` endpoints and log levels need to
    be constrained in a production environment.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 出于安全原因，诸如“执行器”端点和日志级别之类的东西在生产环境中需要受到限制。
- en: Externally exposed endpoints should also be reviewed from a security perspective.
    For example, access to the configuration server should most probably be locked
    down in a production environment, but we will keep it exposed in this book for
    convenience.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 外部暴露的端点也应从安全角度进行审查。例如，对配置服务器的访问在生产环境中很可能需要被限制，但出于方便起见，我们将在本书中保持其暴露。
- en: Docker image tags must be specified to be able to track which versions of the
    microservices have been deployed.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 必须指定Docker镜像标签，以便跟踪已部署的微服务的版本。
- en: '**Scale up available resources**: To meet the requirements of both high availability
    and higher load, we need to run at least two pods per deployment. We might also
    need to increase the amount of memory and CPU that are allowed to be used per
    pod. To avoid running out of memory in the Minikube instance, we will keep one
    pod per deployment but increase the maximum memory allowed in the production environment.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**扩大可用资源**：为了满足高可用性和更高负载的要求，我们需要至少运行每个部署的两个pod。我们可能还需要增加每个pod被允许使用的内存和CPU的数量。为了避免在Minikube实例中耗尽内存，我们将保持每个部署一个pod，但会增加生产环境中允许的最大内存。'
- en: '**Set up a production-ready Kubernetes cluster**:This is outside the scope
    of this book, but, if feasible, I recommend using one of the managed Kubernetes
    services provided by the leading cloud providers. For the scope of this book,
    we will deploy to our local Minikube instance.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设置一个生产就绪的Kubernetes集群**：这超出了本书的范围，但如果可行的话，我建议使用主要云服务提供商提供的托管Kubernetes服务之一。在本书的范围内，我们将部署到我们的本地Minikube实例。'
- en: This is not meant to be an exhaustive list of things that have to be considered
    when setting up an environment for production, but it's a good start.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不意味着在设置生产环境时必须考虑的事项的详尽清单，但这是一个很好的开始。
- en: 'Our simulated production environment will look as follows:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模拟生产环境将如下所示：
- en: '![](img/3ddfcf4d-89dd-4007-a19c-4568e6cb2220.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3ddfcf4d-89dd-4007-a19c-4568e6cb2220.png)'
- en: Changes in the source code
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 源代码的变更
- en: 'The following changes have been applied to the source code to prepare for deployment
    in an environment that''s used for production:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 已对源代码进行了以下更改，以便在用于生产的环境中进行部署：
- en: 'A Spring profile named `prod`  has been added to the configuration files in
    the `config-repo` configuration repository:'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`config-repo`配置存储库中的配置文件中添加了一个名为`prod`的Spring配置文件：
- en: '[PRE28]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'In the `prod` profiles, the following has been added:'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`prod`配置文件中，已添加了以下内容：
- en: 'URLs to the resource managers that run as plain Docker containers:'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为普通Docker容器运行的资源管理器的URL：
- en: '[PRE29]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We are using the `172.17.0.1` IP address to address the Docker engine in the
    Minikube instance. This is the default IP address for the Docker engine when creating
    it with Minikube, at least for Minikube up to version 1.2.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`172.17.0.1` IP地址来访问Minikube实例中的Docker引擎。这是在使用Minikube创建Docker引擎时的默认IP地址，至少对于Minikube
    1.2版本及以下。
- en: There is work ongoing for establishing a standard DNS name for containers to
    use if they need to access the Docker host they are running on, but at the time
    of writing this chapter, this work effort hasn't been completed.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 目前正在进行工作，为容器建立一个标准的DNS名称，以便它们在需要访问正在运行的Docker主机时使用，但在撰写本章时，这项工作尚未完成。
- en: 'Log levels have been set to warning or higher, that is, error or fatal. For
    example:'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志级别已设置为警告或更高，即错误或致命。例如：
- en: '[PRE30]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The only `actuator` endpoints that are exposed over HTTP are the `info` and `health` endpoints
    that are used by the liveness and readiness probes in Kubernetes, as well as the `circuitbreakerevents` endpoint
    that''s used by the test script, `test-em-all.bash`:'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只有通过HTTP公开的`actuator`端点是`info`和`health`端点，它们被Kubernetes中的活跃性和就绪性探针使用，以及`circuitbreakerevents`端点，它被测试脚本`test-em-all.bash`使用：
- en: '[PRE31]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'In the production `overlay` folder, `kubernetes/services/overlays/prod`, one
    deployment object for each microservice has been added with the following content
    so that it can be merged with the base definition:'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在生产`overlay`文件夹`kubernetes/services/overlays/prod`中，为每个微服务添加了一个部署对象，内容如下，以便与基本定义合并：
- en: 'For all microservices, `v1` is specified as the Docker `image` tag, and the
    `prod` profile is added to the active Spring profiles. For example, we have the
    following for the `product` service:'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于所有微服务，都将`v1`指定为Docker`image`标签，并将`prod`配置文件添加到活动的Spring配置文件中。例如，对于`product`服务，我们有以下内容：
- en: '[PRE32]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'For the Zipkin and configuration server, which don''t keep their configuration
    in the configuration repository, environment variables have been added in their
    deployment definitions with the corresponding configuration:'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于Zipkin和配置服务器，它们不会将配置保存在配置存储库中，因此在其部署定义中添加了相应配置的环境变量：
- en: '[PRE33]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Finally, a `kustomization.yml` file defines that the files in the `prod overlay`
    folder shall be merged by specifying the `patchesStrategicMerge` patch mechanism
    with the corresponding definition in the `base` folder:'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，`kustomization.yml`文件定义了`prod overlay`文件夹中的文件应该通过指定`patchesStrategicMerge`补丁机制与`base`文件夹中的相应定义合并。
- en: '[PRE34]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'In a real-world production environment, we should have also changed the `imagePullPolicy:
    Never` setting to `IfNotPresent`, that is, to download Docker images from a Docker
    registry. But since we will be deploying the production setup to the Minikube
    instance where we manually build and tag the Docker images, we will not update
    this setting.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '在真实的生产环境中，我们还应该将`imagePullPolicy: Never`设置更改为`IfNotPresent`，即从Docker注册表下载Docker镜像。但由于我们将部署生产设置到Minikube实例，我们将手动构建和标记Docker镜像，因此不会更新此设置。'
- en: Deploying to Kubernetes
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署到Kubernetes
- en: 'To simulate production-grade resource managers, MySQL, MongoDB, and RabbitMQ will
    run outside of Kubernetes using Docker Compose. We start them up as we did in
    the previous chapters:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟生产级的资源管理器，MySQL、MongoDB和RabbitMQ将在Kubernetes之外使用Docker Compose运行。我们将像在前几章中那样启动它们：
- en: '[PRE35]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We also need to tag the existing Docker images with `v1` using the following
    commands:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要使用以下命令为现有的Docker镜像打上`v1`的标签：
- en: '[PRE36]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: From here, the commands are very similar to how we deployed to the development
    environment.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里开始，命令与我们部署到开发环境的方式非常相似。
- en: 'We will use another Kustomize overlay and use different credentials for the
    configuration server, but, otherwise, it will be the same (which, of course, is
    a good thing!). We will use the same configuration repository but configure the
    pods to use the `prod` Spring profile, as described previously. Follow these steps
    to do so:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用另一个Kustomize叠加，并为配置服务器使用不同的凭据，但除此之外，它将是相同的（当然，这是一件好事！）。我们将使用相同的配置存储库，但配置pod以使用`prod`
    Spring配置文件，如前所述。按照以下步骤执行：
- en: 'Create a namespace, `hands-on`, and set this as the default namespace for `kubectl`:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`hands-on`的命名空间，并将其设置为`kubectl`的默认命名空间：
- en: '[PRE37]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Create the config map for the configuration repository based on the files in
    the `config-repo` folder with the following command:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据`config-repo`文件夹中的文件创建配置存储库的配置映射，使用以下命令：
- en: '[PRE38]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Create the secret for the configuration server with the following command:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令为配置服务器创建密钥：
- en: '[PRE39]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Create the secret for the clients of the configuration server with the following
    command:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令为配置服务器的客户端创建密钥：
- en: '[PRE40]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Remove the clear text encryption key and passwords from the command history:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从命令历史中删除明文加密密钥和密码：
- en: '[PRE41]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Deploy the microservices for the development environment, based on the `prod` overlay,
    using the `-k` switch to activate Kustomize, as described previously:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据`prod`叠加，使用`-k`开关部署用于开发环境的微服务，如前所述：
- en: '[PRE42]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Wait for the deployments to be up and running:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待部署完成并正常运行：
- en: '[PRE43]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'To see the Docker images that are currently being used for production, run
    the following command:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要查看当前用于生产的Docker镜像，请运行以下命令：
- en: '[PRE44]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The response should look something like the following:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 响应应该类似于以下内容：
- en: '![](img/3f3b0b67-78f2-4815-8c42-3f67a8931783.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3f3b0b67-78f2-4815-8c42-3f67a8931783.png)'
- en: Note the `v1` version of the Docker images!
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 注意Docker镜像的`v1`版本！
- en: Also note that the resource manager pods for MySQL, MongoDB, and RabbitMQ are
    gone; these can be found with the `docker-compose ps` command.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，MySQL、MongoDB和RabbitMQ的资源管理器pod已经消失；可以使用`docker-compose ps`命令找到它们。
- en: 'Run the test script, `thest-em-all.bash`, to verify the simulated production
    environment:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 运行测试脚本`thest-em-all.bash`，以验证模拟的生产环境：
- en: '[PRE45]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Expect the same type of output that we got when the test script was run against
    the development environment.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 期望与在开发环境中运行测试脚本时获得的相同类型的输出。
- en: Performing a rolling upgrade
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行滚动升级
- en: Historically, updates often result in some downtime of the component that is
    updated. In a system landscape with an increasing number of autonomous microservices
    that are updated independently of each other, recurring downtimes due to frequent
    updates of the microservices is not acceptable. Being able to deploy an update
    without downtime becomes crucial.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 从历史上看，更新通常会导致更新的组件出现一些停机时间。在一个具有越来越多独立更新的自治微服务的系统环境中，由于微服务频繁更新而导致的反复停机时间是不可接受的。能够在没有停机时间的情况下部署更新变得至关重要。
- en: In this section, we will see how we can perform a rolling upgrade, updating
    a microservice to a new version of its Docker image without requiring any downtime.
    Performing a rolling upgrade means that Kubernetes first starts the new version
    of the microservice in a new pod, and when it reports as being healthy, Kubernetes
    will terminate the old one. This ensures that there is always a pod up and running,
    ready to serve incoming requests during the upgrade. A prerequisite for a rolling
    upgrade to work is that the upgrade is backward compatible, both in terms of APIs
    and message formats that are used to communicate with other services and database
    structures. If the new version of the microservice requires changes to either
    the external APIs, message formats, or database structures that the old version
    can't handle, a rolling upgrade can't be applied. A deployment object is configured
    to perform any updates as a rolling upgrade by default.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: To try this out, we will create a v2 version of the Docker image for the `product`
    service and then start up a test client, `siege`, that will submit one request
    per second during the rolling upgrade. The assumption is that the test client
    will report 200 (OK) for all the requests that it sends during the upgrade.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the rolling upgrade
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To prepare for the rolling upgrade, first, verify that we have the `v1` version
    of the product pod deployed:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The expected output should reveal that `v1` of the Docker image is in use:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8ba120f8-86f6-4b8e-9f5c-88e9e66e05cf.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
- en: 'Create a `v2` tag on the Docker image for the `product` service with the following
    command:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: To try out a rolling upgrade from a Kubernetes perspective, we don't need to
    change any code in the `product` service. Deploying a Docker image with another
    tag than the existing one will start up a rolling upgrade.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: 'To be able to observe whether any downtime occurs during the upgrade, we will
    start a low volume load test using `siege`. The following command starts a load
    test that simulates one user (`-c1`) that submits one request per second on average
    (`-d1`):'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Since the test calls the gateways health endpoint, it verifies that all the
    services are healthy.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: 'You should receive an output that looks similar to the following screenshot:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a9f905e-809b-4146-9b64-208c924649cb.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
- en: The interesting part in the response is the HTTP status code, which we expect
    to be `200` at all times.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, monitor changes to the state of the product pods with the following command:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Upgrading the product service from v1 to v2
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To upgrade the `product` service, edit the `kubernetes/services/overlays/prod/product-prod.yml` file
    and change `image: hands-on/product-service:v1` to `image: hands-on/product-service:v2`.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: 'Apply the update with the following command:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Expect a response from the command that reports that most of the objects are
    left unchanged, except for the product deployment that should be reported to be
    updated to `deployment.apps/product configured`.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes comes with some shorthand commands. For example, `kubectl set image
    deployment/product pro=hands-on/product-service:v2` can be used to perform the
    same update that we did by updating the definitions file and running the `kubectl
    apply` command. A major benefit of using the `kubectl apply` command is that we
    can keep track of the changes by pushing the changes in the source code to a version
    control system such as Git. This is very important if we want to be able to handle
    our infrastructure as code. When playing around with a Kubernetes cluster, only
    use it to test shorthand commands, as this can be very useful.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: 'In the output from the `kubectl get pod -l app=product -w` command we launched in
    the *Preparing the rolling upgrade* section, we will see some action occurring.
    Take a look at the following screenshot:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e395b5c0-fc40-43f1-b8ec-f85a9ce86628.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
- en: Here, we can see how the existing pod (`ffrdh`) initially reported that it was
    up and running and also reported to be healthy when a new pod was launched (`t8mcl`).
    After a while (`16s`, in my case), it is reported as up and running as well. During
    a certain time period, both pods will be up and running and processing requests.
    After a while, the first pod is terminated (2 minutes, in my case).
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: 'When looking at the `siege` output, we can sometimes find a few errors being
    reported in terms of the `503` service unavailable errors:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3caab39b-4d02-4f93-ace5-5402b72aac09.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
- en: This typically happens when the old pod is terminated. Before the old pod is
    reported unhealthy by the readiness probe, it can receive a few requests during
    its termination, that is, when it is no longer capable of serving any requests.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 18](422649a4-94bc-48ae-b92b-e3894c014962.xhtml), *Using a Service
    Mesh to Improve Observability and Management*, we will see how we can set up routing
    rules that move traffic in a smoother way from an old pod to a newer one without
    causing 503 errors. We will also see how we can apply retry mechanisms to stop
    temporary failures from reaching an end user.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: 'Wrap this up by verifying that the pod is using the new `v2` version of the
    Docker image:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The expected output reveals that `v2` of the Docker image is in use:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bd38e1cd-b695-49b8-991b-63e395ee577d.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
- en: After performing this upgrade, we can move on to learning what happens when
    things fail. In the next section, we will see how we can roll back a failed deployment.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: Rolling back a failed deployment
  id: totrans-263
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From time to time, things don't go according to plan, for example, an upgrade
    of deployments and pods can fail for various reasons. To demonstrate how to roll
    back a failed upgrade, let's try to upgrade to `v3` without creating a `v3` tag
    on the Docker image!
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try out the following shorthand command to perform the update:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Expect to see the following changes reported by the `kubectl get pod -l app=product
    -w` command we launched in the *Preparing the rolling upgrade*section:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: <q>![](img/290f3cd4-de45-4a31-8abb-495b8f20c15e.png)</q>
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: We can clearly see that the new pod (ending with `m2dtn`, in my case) has failed
    to start because of a problem finding its Docker image (as expected). If we look
    at the output from the `siege` test tool, no errors are reported, only 200 (OK)!
    Here, the deployment hangs since it can't find the requested Docker image, but
    no errors are affecting end users since the new pod couldn't even start.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see what history Kubernetes has regarding the product''s deployment.
    Run the following command:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'You will receive output similar to the following:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f5e3c16a-efab-43df-a5a5-04dda9c5c4c9.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
- en: 'We can guess that revision 2 is the one with the latest successful deployment,
    that is, `v2` of the Docker image. Let''s check this with the following command:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'In the response, we can see that `revision #2` is the one with Docker image
    `v2`:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e3d11c8-a112-40c0-be6b-29631e196c19.png)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
- en: 'Let''s roll back our deployment to `revision=2` with the following command:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Expect a response that confirms the rollback, like so:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/936308fe-f3a2-45aa-949b-2fe8fe52cbe5.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
- en: 'The `kubectl get pod -l app=product -w` command we launched in the *Preparing
    the rolling upgrade* section will report that the new (not working) pod has been
    removed by the `rollback` command:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0f0d45ea-cb69-4f32-a2fa-55edca821532.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
- en: 'We can wrap this up by verifying that the current image version is still `v2`:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Cleaning up
  id: totrans-286
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To delete the resources that we used, run the following commands:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: Stop the watch command, `kubectl get pod -l app=product -w`, and the load test
    program, `siege`, with *Ctrl* *+* *C*.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Delete the namespace:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Shut down the resource managers that run outside of Kubernetes:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: The `kubectl delete namespace` command will recursively delete all Kubernetes
    resources that existed in the namespace, and the `docker-compose down` command
    will stop MySQL, MongoDB, and RabbitMQ. With the production environment removed,
    we have reached the end of this chapter.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to deploy the microservices in this book on
    Kubernetes. We also introduced some core features in Kubernetes, such as using Kustomize to
    configure deployments for different runtime environments, using Kubernetes deployment
    objects for rolling upgrades, and how to roll back a failed update if required. To
    help Kubernetes understand when the microservices need to be restarted and if
    they are ready to accept requests, we implemented liveness and readiness probes.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: Finally, to be able to deploy our microservices, we had to replace Netflix Eureka
    with the built-in discovery service in Kubernetes. Changing the discovery service
    was done without any code changes – all we had to do was apply changes to the
    build dependencies and some of the configuration.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will see how we can further utilize Kubernetes to reduce
    the number of supporting services we need to deploy in Kubernetes. Head over to
    the next chapter to see how we can eliminate the need for the configuration server
    and how our edge server can be replaced by a Kubernetes ingress controller.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why did we remove the Eureka server from the microservices landscape when deploying
    it on Kubernetes?
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What did we replace the Eureka server with and how was the source code of the
    microservices affected by this change?
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How are base and overlay folders used with Kustomize?
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can we get a running pod updated with changes in a config map or secret?
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If we are using the latest tag on a Docker image, how can we get running pods
    using a new build of the Docker image?
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What commands can we use to roll back a failed deployment?
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What's the purpose of liveness and readiness probes?
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the different ports that are being used in the following service definition?
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
