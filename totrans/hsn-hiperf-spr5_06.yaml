- en: Hibernate Performance Tuning and Caching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we learned how to access a database in our application
    using JDBC. We learned how to optimally design our database, transaction management,
    and connection pooling, to get the best performance from our application. We also
    learned how to prevent SQL injection by using a prepared statement in JDBC. We
    saw how we can remove traditional boilerplate code for managing transactions,
    exceptions, and commits by using JDBC templates.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will move toward some advanced ways of accessing the database
    using **object-relational mapping** (**ORM**) frameworks, such as Hibernate. We
    will learn how we can improve database access in an optimal way by using ORM.
    With Spring Data, we can further remove the boilerplate code of implementing the
    **Data Access Object** (**DAO**) interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the topics we will go through in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Spring Hibernate and Spring Data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spring Hibernate configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common Hibernate traps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hibernate performance tuning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to Spring Hibernate and Spring Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we saw in previous chapters, **Java Database Connectivity** (**JDBC**) exposes
    an API that hides the database vendor-specific communication. However, it suffers
    from the following limitations:'
  prefs: []
  type: TYPE_NORMAL
- en: JDBC development is very much verbose, even for trivial tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: JDBC batching requires a specific API and is not transparent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: JDBC does not provide built-in support for explicit locking and optimistic concurrency
    control
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is a need to handle transactions explicitly, with lots of duplicate code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Joined queries require additional processing to transform the `ResultSet` into
    domain models, or **data transfer objects** (**DTO**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Almost all limitations of JDBC are covered by ORM frameworks. ORM frameworks
    provide for object mapping, lazy loading, eager loading, managing resources, cascading,
    error handling, and other services at the data access layer. One of the ORM frameworks
    is Hibernate. **Spring Data** is a layer implemented by the Spring Framework to
    provide boilerplate code and ease the access to different kinds of persistence
    stores used in applications. Let's see an overview of Spring Hibernate and Spring
    Data in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Spring Hibernate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hibernate evolved from the frustration of EJB's complexities and performance
    issues. Hibernate provided a way to abstract SQL and allowed developers to focus
    on persisting objects. Hibernate, as an ORM framework, helps to map objects to
    tables in relational databases. Hibernate had its own standards when introduced,
    and code became tightly coupled with its standard implementation. So, to make
    persistence generic and vendors agnostic, **Java Community Process** (**JCP**)
    developed a standardized API specification, known as the **Java Persistence API**
    (**JPA**). All ORM frameworks started following this standard, and so does Hibernate.
  prefs: []
  type: TYPE_NORMAL
- en: Spring doesn't implement its own ORM; however, it supports any ORM framework,
    such as Hibernate, iBatis, JDO, and so on. With the ORM solution, we can easily
    persist and access data in the form of **Plain Old Java Object** (**POJO**) objects
    from relational databases. The Spring ORM module is an extension of the Spring
    JDBC DAO module. Spring also provides ORM templates, such as the JDBC-based templates
    we saw in [Chapter 5](a133d0e3-ad9e-49c9-aa2d-df9703b4e84a.xhtml), *Understanding
    Spring Database Interactions*.
  prefs: []
  type: TYPE_NORMAL
- en: Spring Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we know, in the last couple of years, unstructured and non-relational databases
    (known as NoSQL) have become popular. With the Spring JPA, talking to relational
    databases became easy; so, how can we talk to non-relational databases? Spring
    developed a module called Spring Data to provide a common approach to talk to
    a wide variety of data stores.
  prefs: []
  type: TYPE_NORMAL
- en: As each persistence store has different ways to connect and retrieve/update
    data, Spring Data provides a common approach to accessing data from each different
    store.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the features of Spring Data:'
  prefs: []
  type: TYPE_NORMAL
- en: Easy integration with multiple data stores, through various repositories. Spring
    Data provides generic interfaces for each data store in the form of repositories.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ability to parse and form queries based on repository method names provided
    the convention is followed. This reduces the amount of code to be written to fetch
    data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basic auditing support, such as created by and updated by a user.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fully integrated with the Spring core module.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrated with the Spring MVC to expose **REpresentational State Transfer**
    (**REST**) controllers through the Spring Data REST module.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is a small sample of the Spring Data repository. We don''t need
    to implement this method to write a query and fetch an account by ID; it will
    be done by Spring Data internally:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Spring Hibernate configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We know that Hibernate is a persistence framework that provides relationship
    mapping between objects and database tables and that it has rich features to improve
    performance and the optimal use of resources such as caching, eager and lazy loading,
    event listeners, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: The Spring Framework provides full support to integrate many persistence ORM
    frameworks, and so does Hibernate. Here, we will see Spring with JPA, using Hibernate
    as a persistence provider. Also, we will see Spring Data with the JPA repository
    using Hibernate.
  prefs: []
  type: TYPE_NORMAL
- en: Spring with JPA using Hibernate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we know, JPA is not an implementation; it is the specification for persistence.
    The Hibernate framework follows all of the specifications, and it also has its
    own additional features. Using the JPA specification in an application enables
    us to easily switch the persistence provider later if needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use Hibernate on its own requires `SessionFactory`, and to use Hibernate
    with JPA requires `EntityManager`. We are going to use JPA, and the following
    is the Spring Java-based Hibernate JPA configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding configuration, we configured `EntityManager` using the `LocalContainerEntityManagerFactoryBean`
    class. We set `DataSource` to provide information on where to find our database.
    As we are using JPA, which is the specification followed by a different vendor,
    we specified which vendor we are using in our application by setting `HibernateJpaVendorAdapter`
    and setting vendor-specific additional properties.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have configured the JPA-based ORM framework in our application,
    let's see how to create a DAO in our application when using ORM.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the `AbstractJpaDAO` class, having the basic common method
    required for all of our DAOs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the `AccountDAO` class, which manages the `Account` entity-related
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding examples of DAO implementation are pretty basic, and is what
    we generally do in our applications. In case DAO throws an exception such as `PersistenceException`,
    and instead of showing an exception to the user, we would want to show the right,
    human-readable message to the end users. To provide a readable message when an
    exception occurs, Spring provides a translator which we need to define in our
    configuration class as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The `BeanPostProcessor` command works when we annotate our DAOs with the `@Repository`
    annotation. The `PersistenceExceptionTranslationPostProcessor` bean will act as
    an advisor for the beans, which are annotated with the `@Repository` annotation.
    Remember that we learned about advises in [Chapter 3](6ad6974a-b108-4e80-b13c-cbc5916d1969.xhtml),
    *Tuning Aspect-Oriented Programming*. When advised, it will re-throw Spring-specific
    unchecked data access exceptions caught in the code.
  prefs: []
  type: TYPE_NORMAL
- en: So, this was the basic configuration of Spring JPA using Hibernate. Now, let's
    see the Spring Data configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Spring Data configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we learned in the introduction, Spring Data provides a common approach to
    connect different data stores. Spring Data provides basic abstraction through
    the `Repository` interface. The `Repository` interface is the core interface of
    Spring Data. Basic repositories provided by Spring Data are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`CrudRepository` provides basic CRUD operations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PagingAndSortingRepository` provides methods to do the pagination and sorting
    of records'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`JpaRepository` provides JPA-related methods, such as flush and insert/update/delete
    in a batch, and so on'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Repository`, in Spring Data, eliminates the implementation of DAOs and templates
    such as `HibernateTemplate` or `JdbcTemplate`. Spring Data is so abstract that
    we don''t even need to write any method implementation for basic CRUD operations;
    we just need to define interfaces based on `Repository` and define proper naming
    conventions for methods. Spring Data will take care of creating a query based
    on a method name, and execute it to a database.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Java configuration for Spring Data remains the same as what we saw for
    the Spring JPA, using Hibernate, except for the addition of defining repositories.
    The following is a snippet of declaring repositories to the configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In this chapter, we are not going to dive too deeply into Hibernate and Spring
    Data-specific development. However, we will dive into the problems faced when
    not using Hibernate or JPA optimally and with the right configuration in our application,
    and solutions to the problems, with the best practices to achieve high performance.
    Let's look at the common Hibernate problems we face when using it in our applications.
  prefs: []
  type: TYPE_NORMAL
- en: Common Hibernate traps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The JPA and Hibernate ORM are the most popular frameworks used in most Java
    applications to interact with a relational database. Their popularity increased
    because they use the mapping between the object-oriented domain and underlying
    relational database to abstract the database interactions and make it very easy
    to implement simple CRUD operations.
  prefs: []
  type: TYPE_NORMAL
- en: Under this abstraction, Hibernate uses a lot of optimizations and hides all
    database interactions behind its API. Oftentimes, don't even know when Hibernate
    will execute an SQL statement. Because of this abstraction, it becomes hard to
    find inefficiencies and potential performance problems. Let's see the common Hibernate
    problems that we face in our applications.
  prefs: []
  type: TYPE_NORMAL
- en: Hibernate n + 1 problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When using JPA and Hibernate, the fetch type adds a good amount of impact to
    an application's performance. We should always fetch as much data as we need to
    fulfill a given business requirement. To do so, we set the associated entities `FetchType` as
    `LAZY`. When we set these associated entities fetch type as `LAZY`*,* we implement
    a nested select in our applications, because we are not aware how these associations
    are fetched under the abstraction provided by ORM frameworks. Nested selects are
    nothing but two queries, where one is the outer, or main, query (which fetches
    the result from a table) and the other is executed for each row as a result of
    the main query (to fetch the corresponding or related data from other table/s).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example shows how we unintentionally implement something that
    does nested select:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Mostly, a developer tends to write code like the preceding example, and won't
    realize how an ORM framework like Hibernate could be fetching data internally.
    Here, ORM frameworks like Hibernate execute one query to get the `account`, and
    a second query to get transactions for that `account`. Two queries are fine, and
    won't impact the performance much. These two queries are for one association in
    an entity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s suppose that we have five associations in the `Account` entity: `Transactions`,
    `UserProfile`, `Payee`, and so on. When we try to fetch each association from
    the `Account` entity, the framework executes one query for each association, resulting
    in 1 + 5 = 6 queries. Six queries won''t impact much, right? These queries are
    for one user, so what if the number of concurrent users of our application is
    100? Then we will have 100 * (1 + 5) = 600 queries. Now, that is something that
    would impact the performance. This 1 + 5 queries while fetching `Account` is called
    the **n + 1** problem in Hibernate. We will see some approaches to avoiding this
    problem in the *Hibernate performance tuning* section of this chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: The open session in view anti-pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We saw in the preceding section that in order to defer fetching until the associated
    entity is needed, we set the fetch type of the associated entities as `LAZY`.
    When we try to access these associated entities in our presentation layer (if
    they are not initialized in our business (service) layer), an exception is thrown
    by Hibernate, called `LazyInitializationException`. When the service layer method
    completes its execution, Hibernate commits the transaction and closes the session.
    So, by the time the view is rendered, the active session is not available to fetch
    the associated entities.
  prefs: []
  type: TYPE_NORMAL
- en: To avoid `LazyInitializationException`, one of the solutions is an open session
    in view. This means that we keep the Hibernate session open in view so that the
    presentation layer can fetch the required associated entities, and then close
    the session.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to enable this solution, we need to add a web filter to our application.
    If we are using Hibernate on its own, we need to add `filter`, `OpenSessionInViewFilter`;
    if we are using JPA, then we need to add `filter` `OpenEntityManagerInViewFilter`.
    As we are using JPA with Hibernate in this chapter, the following is the snippet
    to add `filter`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The solution provided by the **Open Session in View **(**OSIV**) pattern to
    avoid the exception might not look terrible at first glance; however, there are
    problems with using the OSIV solution. Let''s go over some issues with the OSIV
    solution:'
  prefs: []
  type: TYPE_NORMAL
- en: The service layer opens the transaction when its method is invoked and closes
    it when the method execution completes. Afterward, there is no explicit open transaction.
    Every additional query executed from the view layer will be executed in auto-commit
    mode. Auto-commit mode could be dangerous from a security and database point of
    view. Due to the auto-commit mode, the database needs to flush all of the transaction
    logs to disk immediately, causing high I/O operations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It will violate the single responsibility of SOLID principles, or separation
    of concern because database statements are executed by both the service layer
    and the presentation layer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'It will lead to the n + 1 problem that we saw in the preceding *Hibernate n
    + 1 problem* section, though Hibernate offers some solutions that can cope with
    this scenario: `@BatchSize` and `FetchMode.SUBSELECT`, however, would apply to
    all of the business requirements, whether we want to or not.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The database connection is held until the presentation layer completes rendering.
    This increases the overall database connection time and impacts transaction throughput.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If an exception occurs in the fetching session or executing queries in the database,
    it will occur while rendering the view, so it will not be feasible to render a
    clean error page to the user.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Unknown Id.generator exception
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most of the time, we will want to use database sequencing for our table primary
    key. In order to do so, we know that we need to add the `generator` attribute
    in the `@GeneratedValue` annotation on our entity. The `@GeneratedValue` annotation
    allows us to define a strategy for our primary key.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the code snippet that we add in our entity to set database
    sequencing for our primary key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we thought that `accountSequence` was the database sequence name provided
    to the `generator`; however, when the application runs, it gives an exception.
    To solve this exception, we annotate our entity with `@SequenceGenerator` and
    give the name as `accountSequence`, and the database sequence name that Hibernate
    needs to use. The following shows how to set the `@SequenceGenerator` annotation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: We saw common problems faced during implementation. Now, let's see how to tune
    Hibernate to achieve high performance.
  prefs: []
  type: TYPE_NORMAL
- en: Hibernate performance tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the preceding section, we saw common Hibernate traps or issues. These issues
    don't necessarily mean faults in Hibernate; sometimes, they are from incorrect
    usage of the framework, and in some cases, limitations of the ORM framework itself.
    In the following sections, we will see how to improve performance in Hibernate.
  prefs: []
  type: TYPE_NORMAL
- en: Approaches to avoid the n + 1 problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We already saw the n + 1 problem in the *Hibernate n + 1 problem* section. Too
    many queries will slow down our application's overall performance. So, in order
    to avoid these additional queries with lazy loading, let's see what options are
    available.
  prefs: []
  type: TYPE_NORMAL
- en: Fetch join using JPQL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Normally, we call the `findById` method of DAO to fetch the outer or parent
    entity and then call the getter methods of associations. Doing so leads to n +
    1 queries because the framework will execute additional queries for each association.
    Instead, we can write a JPQL query using the `createQuery` method of `EntityManager`.
    In this query, we can join our associated entity, which we want to fetch along
    with the outer entity by using `JOIN FETCH`. The following is an example of how
    to get `JOIN FETCH` entities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the log that states that only one query is executed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '`JOIN FETCH` tells `entityManager` to load the selected entity, as well as
    the associated entity, in the same query.'
  prefs: []
  type: TYPE_NORMAL
- en: The advantage of this approach is that Hibernate fetches everything within one
    query. From a performance point of view, this option is good, because everything
    is fetched in a single query instead of multiple queries. This reduces the round-trips
    to the database for each separate query.
  prefs: []
  type: TYPE_NORMAL
- en: The disadvantage of this approach is that we need to write additional code to
    execute the query. It's not an issue until we have a few associations or relations
    to fetch. But, it gets worse if the entity has many associations and we need to
    fetch different associations for each different use case. So, in order to fulfill
    each different use case, we need to write different queries with required associations.
    Too many different queries for each use case would be quite messy, and also difficult
    to maintain.
  prefs: []
  type: TYPE_NORMAL
- en: This option would be a good approach if the number of queries requiring different
    join fetchcombinations was low.
  prefs: []
  type: TYPE_NORMAL
- en: Join fetch in Criteria API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This approach is the same as `JOIN FETCH` in JPQL; however, this time, we are
    using the Criteria API of Hibernate. The following is an example of how to use
    `JOIN FETCH` in the Criteria API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This option has the same advantages and disadvantages as JPQL. Most of the time,
    when we write a query using the Criteria API, it is use case-specific. So, this
    option might not be a huge problem in those cases, and it would be a good approach
    to reduce the amount of queries performed.
  prefs: []
  type: TYPE_NORMAL
- en: Named entity graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Then named entity graph is a new feature, introduced in JPA 2.1\. In this approach,
    we can define a graph of entities that need to be queried from the database. We
    can define the entity graph on our entity class by using the `@NamedEntityGraph`
    annotation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of how to define a graph using `@NamedEntityGraph`
    on the entity class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'An entity graph definition is independent of the query and defines which attributes
    to be fetched from the database. An entity graph can be used as a load or a fetch graph.
    If a load graph is used, all attributes that are not specified in the entity graph
    definition will keep following their default `FetchType.` If a fetch graph is
    used, only the attributes specified by the entity graph definition will be treated
    as `FetchType.EAGER`, and all other attributes will be treated as `LAZY`. The
    following is an example of how to use a named entity graph as a `fetchgraph`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We are not going to go into detail on named entity graphs in this book. This
    is one of the best approaches to resolve the n + 1 issue with Hibernate. This
    is an improved version of `JOIN FETCH`. An advantage on top of `JOIN FETCH` is
    that it will be reused for different use cases. The only disadvantage of this
    approach is that we must annotate the named entity graph for each combination
    of associations that we want to fetch in a single query. So, this can get quite
    messy if we have too many different combinations to set.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic entity graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A dynamic entity graph is similar to a named entity graph, with the difference
    that we can define it dynamically through the Java API. The following is an example
    of how to define an entity graph using the Java API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: So, if we have lots of use case-specific entity graphs, this approach will be
    an advantage over named entity graph where adding an annotation on our entity
    for each use case makes code unreadable. We can keep all use case-specific entity
    graphs in our business logic. With this approach, the disadvantage is that we
    need write more code and in order to make code reusable, we need to write more
    of the methods for each related business logic.
  prefs: []
  type: TYPE_NORMAL
- en: Finding performance issues with Hibernate statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most of the time, we face slow responses on the production system, while our
    local or test system works just fine. Most of these cases are because of slow
    database queries. In a local instance, we don't know the exact volume of requests
    and volume of data that we have in production. So, how do we find out which query
    is causing the problem, without adding logs to our application code? The answer
    is the Hibernate `generate_statistics` configuration.
  prefs: []
  type: TYPE_NORMAL
- en: We need to set the Hibernate property `generate_statistics` to true, as this
    property is false by default. This property impacts the overall performance, as
    it logs all database activities. So, enable this property only when you want to
    analyze slow queries. This property will generate summarized multiline logs, showing
    how much overall time is spent on database interaction.
  prefs: []
  type: TYPE_NORMAL
- en: If we want to log the execution of each query, we need to enable `org.hibernate.stat`
    to the `DEBUG` level in log configuration; similarly, if we want to log SQL queries
    (with times), we need to enable `org.hibernate.SQL` to the `DEBUG` level.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of a printed log:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b8713ce6-c5b1-47e8-bd83-65dc3a0024f0.png)'
  prefs: []
  type: TYPE_IMG
- en: Hibernate generate_statistics logs
  prefs: []
  type: TYPE_NORMAL
- en: An overall statistics information log shows the number of JDBC connections used,
    statements, caches, and performed flushes. We always need to check the number
    of statements first to see if there is an n + 1 issue.
  prefs: []
  type: TYPE_NORMAL
- en: Using query-specific fetching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is always recommended to select only those columns which are required for
    our use case. If you are using the `CriteriaQuery`, use projections to select
    required columns. Fetching the entire entity would degrade the application''s
    performance when the table has too many columns, so the database needs to go through
    each block of the stored page to retrieve them, and we might not even need all
    of those columns in our use case. Also, if we are using an entity instead of the
    DTO class, persistence context has to manage the entities and also fetches associated/child
    entities when required. This adds an overhead. Instead of fetching  the entire
    entity, fetch only the required columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Fetch a specific column as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The better way to use query-specific fetching is to use DTO projection. Our
    entities are managed by a persistence context. So, it would be easier to fetch
    `ResultSet` to the entity, in case we want to update it. We set the new values
    to the setter methods, and Hibernate will take care of the SQL statements to update
    it. This easiness comes with the price of performance since Hibernate needs to
    do dirty checks on all managed entities to find out if it needs to save any changes
    to the database. DTO are the POJO classes which are the same as our entities,
    however, it's not managed by persistence.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can fetch specific columns in JPQL by using the constructor expression,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, we can do the same thing by using `CriteriaQuery` and `JPAMetamodel`,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Caching and its best practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We already saw how caching works in Spring in [Chapter 3](6ad6974a-b108-4e80-b13c-cbc5916d1969.xhtml),
    *Tuning Aspect-Oriented Programming*. Here, we will see how caching works in Hibernate,
    and what different types of caching are available in Hibernate. In Hibernate,
    there are three different types of caching, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: First level cache
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second level cache
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Query cache
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's understand how each cache mechanism works in Hibernate.
  prefs: []
  type: TYPE_NORMAL
- en: First level cache
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the first level cache, Hibernate caches entities in session objects. The
    Hibernate first level cache is enabled by default, and we cannot disable it. Still,
    Hibernate provides methods through which we can delete particular objects from
    the cache, or completely clear the cache from a session object.
  prefs: []
  type: TYPE_NORMAL
- en: 'As Hibernate does a first level cache in a session object, any object cached
    will not be visible to another session. When the session is closed, the cache
    is cleared. We are not going to go into detail on this caching mechanism, as it
    is available by default, and there is no way to tune or disable it. There are
    certain methods to know for this level of cache, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Use the session's `evict()` method to delete a single object from the Hibernate
    first level cache
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the session's `clear()` method to clear the cache completely
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the session's `contains()` method to check whether an object is present
    in the Hibernate cache
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second level cache
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One benefit of database abstraction layers, such as ORM frameworks, is their
    ability to transparently cache data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2dae2d40-0d0d-4fef-b6dd-23bcd4e3a988.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Caching at the database and application level
  prefs: []
  type: TYPE_NORMAL
- en: The application cache is not an option for many large enterprise applications.
    With the application cache, we help to reduce many round-trips to get required
    data from the database cache. The application-level cache stores entire objects,
    which are retrieved based on hash table keys. Here, we are not going to talk about
    the application level cache; we are going to talk about the second level cache.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Hibernate, unlike with the first level cache, the second level cache is
    `SessionFactory` scoped; hence, it is shared by all sessions created within the
    same session factory. When the second level is enabled and the entity is looked
    up, the following applies:'
  prefs: []
  type: TYPE_NORMAL
- en: It will first be checked in the first level cache if the instance is available,
    and then returned.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the instance is not present in the first level, it will try to find it in
    the second level cache, and, if found, it is assembled and returned.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the instance is not found in the second level cache, it will make the trip
    to the database and fetch the data. The data is then assembled and returned.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Hibernate doesn''t do any caching by itself. It provides the interface `org.hibernate.cache.spi.RegionFactory`,
    and cache providers do the implementation of this interface. Here, we will talk
    about the Ehcache provider, which is mature and the most widely used cache. In
    order to enable second level caching, we need to add the following two lines to
    our persistence properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the level two cache is enabled, we need to define which entities we want
    to cache; we need to annotate those entities with `@org.hibernate.annotations.Cache`,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Hibernate uses a separate cache region to store the states of instances of
    an entity. The region name is the fully qualified class name. There are different
    concurrency strategies provided by Hibernate, which we can use based on our requirements.
    The following are the different concurrency strategies:'
  prefs: []
  type: TYPE_NORMAL
- en: '`READ_ONLY`: Used only for entities that are never modified; in the case of
    modification, an exception is thrown. It is used for some static reference data
    that doesn''t change.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`NONSTRICT_READ_WRITE`: The cache is updated when the transaction affecting
    the cached data is committed. While the cache is updated, there is a chance to
    obtain stale data from the cache. This strategy is suitable for those requirements
    that can tolerate eventual consistency. This strategy is useful for data that
    is rarely updated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`READ_WRITE`: To avoid obtaining stale data while the cache is updated, this
    strategy uses soft locks. When a cached entity is updated, the entity in the cache
    is locked and is released after the transaction is committed. All concurrent transactions
    will retrieve the corresponding data directly from the database.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TRANSACTIONAL`: The transaction strategy is mainly used in distributed caches
    in the JTA environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If there is no expiration and eviction policy defined, the cache could grow
    indefinitely and eventually consume all of the memory. We need to set these policies,
    and it depends on cache providers. Here, we are using Ehcache, and the following
    is the method to define expiration and eviction policies in `ehcache.xml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Many of us think that the cache stores entire objects. However, it doesn''t
    store entire objects, but rather, it stores them in a disassembled state:'
  prefs: []
  type: TYPE_NORMAL
- en: The primary key is not stored, because it is the cache key
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transient properties are not stored
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collection associations are not stored by default
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All property values, except for associations, are stored in their original forms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Foreign keys for `@ToOne` associations are stored only with IDs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Query cache
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The query cache can be enabled by adding the following Hibernate property:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the query cache is enabled, we can specify which query we want to cache,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'If we execute the same query again which is cached by query cache, the following
    is the log printed with `DEBUG` mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Performing updates and deletes in bulk
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we know, ORM frameworks, like Hibernate, execute two or more queries when
    we update or delete any entity. If we were updating or deleting a few entities,
    this would be fine, but think of a scenario where we want to update or delete
    100 entities. Hibernate will execute 100 `SELECT` queries to fetch the entities,
    and another 100 queries to update or delete the entities.
  prefs: []
  type: TYPE_NORMAL
- en: We know that in order to achieve better performance for any application, a lower
    number of database statements need to be executed. If we perform the same update
    or delete using JPQL or native SQL, it can be done in a single statement. Hibernate
    provides a lot of benefits as an ORM framework and can help us keep a focus on
    business logic, rather than database operations. In scenarios where Hibernate
    could be costly such as bulk update and delete, we should use the native database
    queries to avoid overhead and achieve better performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a way that we can execute the native query to `UPDATE` all
    of the user''s emails in the bank inbox as `read`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: We can measure the performance difference using the Hibernate method and native
    query to update bulk data, simply by logging `System.currentTimeMillis()`. There
    should be a significant increase in performance, with the native query 10 times
    faster than the Hibernate approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'The native query will definitely improve bulk operation performance, but at
    the same time, it comes with issues with the first level cache, and won''t trigger
    any entity life cycle events. As we know, Hibernate stores all entities that we
    use within a session in the first level cache. It has benefits for write-behind
    optimizations and avoids duplicate select statement executions for the same entity
    in the same session. But, with the native query, Hibernate doesn''t know which
    entities were updated or removed and updates the first level cache accordingly.
    It will keep using an outdated version of the entity in the cache if we fetch
    the entity before executing the native query in the same session. The following
    is an example of an issue with the first level cache, using the native query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'A solution to this problem is to update the first level cache manually, by
    detaching the entity before native query execution and attaching it back after
    native query execution. To do so, perform the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Call the `flush()` and `detach()` methods before performing the native query.
    The `flush()` method tells Hibernate to write the changed entities from the first
    level cache to the database. This is to make sure that we don't lose any updates.
  prefs: []
  type: TYPE_NORMAL
- en: Hibernate programming practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Until now, we saw problems with Hibernate when it is not used optimally, and
    how to use Hibernate to achieve better performance. The following are the best
    practices to follow (in terms of caching, and in general) to achieve better performance
    when using JPA and Hibernate.
  prefs: []
  type: TYPE_NORMAL
- en: Caching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are some programming tips in relation to the different caching
    levels in Hibernate:'
  prefs: []
  type: TYPE_NORMAL
- en: Make sure to use the same version of `hibernate-ehcache` as the version of Hibernate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since Hibernate caches all of the objects into the session first level cache,
    when running bulk queries or batch updates, it's necessary to clear the cache
    at certain intervals to avoid memory issues.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When caching an entity using the second level cache, collections inside of the
    entity are not cached by default. In order to cache the collections, annotate
    the collections within the entity with `@Cacheable` and `@org.hibernate.annotations.Cache(usage
    = CacheConcurrencyStrategy.READ_WRITE)`. Each collection is stored in a separate
    region in the second level cache, where the region name is the fully qualified
    name of the entity class, plus the name of the collection property. Define the
    expiration and eviction policy separately for each collection that's cached.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When DML statements are executed using JPQL, the cache for those entities will
    be updated/evicted by Hibernate; however, when using the native query, the entire
    second level cache will be evicted, unless the following detail is added to native
    query execution when using Hibernate with JPA:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: In the case of query caching, there will be one cache entry for each combination
    of query and parameter values, so queries, where different combinations of parameter
    values are expected, are not good for caching.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the case of query caching, a query that fetches the entity classes for which
    there are frequent changes in the database is not a good candidate for caching,
    because the cache will be invalidated when any entity involved in the query is changed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All query cache results are stored in the `org.hibernate.cache.internal.StandardQueryCache`
    region. We can specify the expiration and eviction policies for this region. Also,
    if required, we can set a different region for a particular query to cache by
    using the query hint `org.hibernate.cacheRegion`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hibernate keeps last update timestamps in a region named `org.hibernate.cache.spi.UpdateTimestampsCache`
    for all query cached tables. Hibernate uses this to verify that cached query results
    are not stale. It is best to turn off automatic eviction and expiration for this
    cache region, because entries in this cache must not be evicted/expired, as long
    as there are cached query results in cache results regions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Miscellaneous
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are general Hibernate best practices for achieving better performance
    in your application:'
  prefs: []
  type: TYPE_NORMAL
- en: Avoid enabling `generate_statistics` on the production system; rather, analyze
    issues by enabling `generate_statistics` on a staging or a replica of the production
    system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hibernate always updates all database columns, even though we update one or
    a few columns only. All of the columns in the `UPDATE` statement would take more
    time than a few columns. In order to achieve high performance and avoid using
    all of the columns in an `UPDATE` statement, only include the columns that are
    actually modified and use the `@DynamicUpdate` annotation on an entity. This annotation
    tells Hibernate to generate a new SQL statement for each update operation, with
    only modified columns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set the default `FetchType` as `LAZY` for all associations, and use query-specific
    fetching, using `JOIN FETCH`, named entity graphs, or dynamic entity graphs, to
    avoid the n + 1 issue and improve performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Always use bind parameters to avoid SQL injections and improve performance.
    When used with bind parameters, Hibernate and the database optimizes queries if
    the same query is executed multiple times.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform `UPDATE` or `DELETE` in a huge list in bulk, instead of performing them
    one-by-one. We already discussed this in the *Performing updates and deletes in
    bulk* section.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Never use entities for read-only operations; rather, use different projections
    provided by JPA and Hibernate. One that we already saw was the DTO projection.
    For read-only requirements, changing the entity to a constructor expression in
    `SELECT` is very easy, and high performance will be achieved.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With the introduction of the Stream API in Java 8.0, many people used its features
    to process huge data retrieved from a database. Stream is designed to work on
    huge data. But there are certain things that a database can do better than the
    Stream API. Don''t use the Stream API for the following requirements:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Filter data: The database can filter data more efficiently than the Stream
    API, which we can do using the `WHERE` clause'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Limiting data: The database provides more efficient results than the Stream
    API when we want to limit the number of data to be retrieved'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sort data: The database can sort more efficiently than the Stream API by using
    the `ORDER BY` clause'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Use order instead of sorting, especially for huge associated entities of data.
    Sorting is Hibernate-specific, and not a JPA specification:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hibernate sorts using the Java Comparator in memory. However, the same desired
    order of data can be retrieved from the database by using the `@OrderBy` annotation
    on associated entities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the column name is not specified, `@OrderBy` will be done on the primary
    key.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple columns can be specified in `@OrderBy`, comma-separated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The database handles `@OrderBy` more efficiently than implementing sorting
    in Java. The following is a code snippet, as an example:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Hibernate regularly performs dirty checks on all entities that are associated
    with the current `PersistenceContext`, to detect required database updates. For
    entities that never update, such as read-only database views or tables, performing
    dirty checks is an overhead. Annotate these entities with `@Immutable`, and Hibernate
    will ignore them in all dirty checks, improving performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Never define unidirectional one-to-many relationships; always define bidirectional
    relationships. If a unidirectional one-to-many relationship is defined, Hibernate
    will need an extra table to store the references of both of the tables, just like
    in many-to-many relationships. There would be many extra SQL statements executed
    in the case of a unidirectional approach, which would not be good for performance.
    For better performance, annotate `@JoinColumn` on the owning side of the entity,
    and use the `mappedby` attribute on the other side of the entity. This will reduce
    the number of SQL statements, improving performance. Adding and removing an entity
    from a relationship needs to be handled everywhere explicitly; hence, it is recommended
    to write helper methods in the parent entity, as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We started this chapter with a basic configuration of the ORM framework, Hibernate,
    using JPA and Spring Data. We focused on common ORM problems faced in production.
    In this chapter, we learned optimal solutions to the common problems faced while
    working on Hibernate for database operations and for achieving high performance.
     We learned useful tips for the best practices to follow when working on ORM-based
    frameworks to achieve high performance from the development stage, instead of
    resolving problems when facing them in the production system.
  prefs: []
  type: TYPE_NORMAL
- en: In line with optimization and high performance, the next chapter provides information
    on Spring messaging optimization. As you know, messaging framework enterprise
    applications connect multiple clients and provide reliability, asynchronous communications,
    and loose coupling. Frameworks are built to provide various benefits; however,
    we face issues if we don't use them optimally. Similarly, there are certain parameters
    related to queue configuration and scalability that will maximize throughput in
    the Spring messaging framework of our enterprise application if used effectively.
  prefs: []
  type: TYPE_NORMAL
