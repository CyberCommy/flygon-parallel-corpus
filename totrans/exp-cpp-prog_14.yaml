- en: Native C++ Threads and Primitives
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Starting with the 2011 revision of the C++ standard, a multithreading API is
    officially part of the C++ **Standard Template Library** (**STL**). This means
    that threads, thread primitives, and synchronization mechanisms are available
    to any new C++ application without the need to install a third-party library,
    or to rely on the operating system's APIs.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter looks at the multithreading features available in this native API
    up to the features added by the 2014 standard. A number of examples will be shown
    to use these features in detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'Topics in this chapter include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The features covered by the multithreading API in C++'s STL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detailed examples of the usage of each feature
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The STL threading API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 10](981efdf3-efa2-4e62-aba0-2d52ab80f3c8.xhtml), *C++ Multithreading
    APIs*, we looked at the various APIs that are available to us when developing
    a multithreaded C++ application. In [Chapter 11](3569125d-7316-4147-ba03-9c65cfd755d7.xhtml),
    *Thread Synchronization and Communication*, we implemented a multithreaded scheduler
    application using the native C++ threading API.
  prefs: []
  type: TYPE_NORMAL
- en: Boost.Thread API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By including the `<thread>` header from the STL, we gain access to the `std::thread`
    class with facilities for mutual exclusion (mutex, and so on) provided by further
    headers. This API is, essentially, the same as the multithreading API from `Boost.Thread`**,**
    the main differences being more control over threads (join with timeout, thread
    groups, and thread interruption), and a number of additional lock types implemented
    on top of primitives such as mutexes and condition variables.
  prefs: []
  type: TYPE_NORMAL
- en: In general, `Boost.Thread` should be used as a fall back for when C++11 support
    isn't present, or when these additional `Boost.Thread` features are a requirement
    of one's application, and not easily added otherwise. Since `Boost.Thread` builds
    upon the available (native) threading support, it's also likely to add overhead
    as compared to the C++11 STL implementation.
  prefs: []
  type: TYPE_NORMAL
- en: The 2011 standard
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The 2011 revision to the C++ standard (commonly referred to as C++11) adds a
    wide range of new features, the most crucial one being the addition of native
    multithreading support, which adds the ability to create, manage, and use threads
    within C++ without the use of third-party libraries.
  prefs: []
  type: TYPE_NORMAL
- en: This standard standardizes the memory model for the core language to allow multiple
    threads to coexist as well as enables features such as thread-local storage. Initial
    support was added in the C++03 standard, but the C++11 standard is the first to
    make full use of this.
  prefs: []
  type: TYPE_NORMAL
- en: As noted earlier, the actual threading API itself is implemented in the STL.
    One of the goals for the C++11 (C++0x) standard was to have as many of the new
    features as possible in the STL, and not as part of the core language. As a result,
    in order to use threads, mutexes, and kin, one has to first include the relevant
    STL header.
  prefs: []
  type: TYPE_NORMAL
- en: The standards committee which worked on the new multithreading API each had
    their own sets of goals, and as a result, a few features which were desired by
    some did not make it into the final standard. This includes features such as terminating
    another thread, or thread cancellation, which was strongly opposed by the POSIX
    representatives on account of canceling threads likely to cause issues with resource
    clean-up in the thread being destroyed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following are the features provided by this API implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '`std::thread`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`std::mutex`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`std::recursive_mutex`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`std::condition_variable`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`std::condition_variable_any`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`std::lock_guard`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`std::unique_lock`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`std::packaged_task`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`std::async`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`std::future`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a moment, we will look at detailed examples of each of these features. First
    we will see what the next revisions of the C++ standard have added to this initial
    set.
  prefs: []
  type: TYPE_NORMAL
- en: C++14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The 2014 standard adds the following features to the standard library:'
  prefs: []
  type: TYPE_NORMAL
- en: '`std::shared_lock`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`std::shared_timed_mutex`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both of these are defined in the `<shared_mutex>` STL header. Since locks are
    based on mutexes, a shared lock is, therefore, reliant on a shared mutex.
  prefs: []
  type: TYPE_NORMAL
- en: Thread class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `thread` class is the core of the entire threading API; it wraps the underlying
    operating system's threads, and provides the functionality we need to start and
    stop threads.
  prefs: []
  type: TYPE_NORMAL
- en: This functionality is made accessible by including the `<thread>` header.
  prefs: []
  type: TYPE_NORMAL
- en: Basic use
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Upon creating a thread it is started immediately:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This preceding code would start the thread to then immediately terminate the
    application, because we are not waiting for the new thread to finish executing.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this properly, we need to wait for the thread to finish, or rejoin as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This last code would execute, wait for the new thread to finish, and then return.
  prefs: []
  type: TYPE_NORMAL
- en: Passing parameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It''s also possible to pass parameters to a new thread. These parameter values
    have to be move constructible, which means that it''s a type which has a move
    or copy constructor (called for rvalue references). In practice, this is the case
    for all basic types and most (user-defined) classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In this preceding code, we pass an integer and string to the `thread` function.
    This function will receive copies of both variables. When passing references or
    pointers, things get more complicated with life cycle issues, data races, and
    such becoming a potential problem.
  prefs: []
  type: TYPE_NORMAL
- en: Return value
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Any value returned by the function passed to the `thread` class constructor
    is ignored. To return information to the thread which created the new thread,
    one has to use inter-thread synchronization mechanisms (like mutexes) and some
    kind of a shared variable.
  prefs: []
  type: TYPE_NORMAL
- en: Moving threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The 2011 standard adds `std::move` to the `<utility>` header. Using this template
    method, one can move resources between objects. This means that it can also move
    thread instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In this version of the code, we create a thread before moving it to another
    thread. Thread 0 thus ceases to exist (since it instantly finishes), and the execution
    of the `thread` function resumes in the new thread that we create.
  prefs: []
  type: TYPE_NORMAL
- en: As a result of this, we do not have to wait for the first thread to re join,
    but only for the second one.
  prefs: []
  type: TYPE_NORMAL
- en: Thread ID
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Each thread has an identifier associated with it. This ID, or handle, is a
    unique identifier provided by the STL implementation. It can be obtained by calling
    the `get_id()` function of the `thread` class instance, or by calling `std::this_thread::get_id()`
    to get the ID of the thread calling the function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This code would produce output similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Here, one sees that the internal thread ID is an integer (`std::thread::id`
    type), relative to the initial thread (ID 1). This is comparable to most native
    thread IDs such as those for POSIX. These can also be obtained using `native_handle()`.
    That function will return whatever is the underlying native thread handle. It
    is particularly useful when one wishes to use a very specific PThread or Win32
    thread functionality that's not available in the STL implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Sleeping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It''s possible to delay the execution of a thread (sleep) using either of two
    methods. One is `sleep_for()`, which delays execution by at least the specified
    duration, but possibly longer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This preceding code shows how to sleep for roughly 2 seconds, measuring the
    exact duration using a counter with the highest precision possible on the current
    OS.
  prefs: []
  type: TYPE_NORMAL
- en: Note that we are able to specify the number of seconds directly, with the seconds
    post-fix. This is a C++14 feature that got added to the `<chrono>` header. For
    the C++11 version, one has to create an instance of std::chrono::seconds and pass
    it to the `sleep_for()` function.
  prefs: []
  type: TYPE_NORMAL
- en: The other method is `sleep_until()`, which takes a single parameter of type
    `std::chrono::time_point<Clock, Duration>`. Using this function, one can set a
    thread to sleep until the specified time point has been reached. Due to the operating
    system's scheduling priorities, this wake-up time might not be the exact time
    as specified.
  prefs: []
  type: TYPE_NORMAL
- en: Yield
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One can indicate to the OS that the current thread can be rescheduled so that
    other threads can run instead. For this, one uses the `std::this_thread::yield()`
    function. The exact result of this function depends on the underlying OS implementation
    and its scheduler. In the case of a FIFO scheduler, it's likely that the calling
    thread will be put at the back of the queue.
  prefs: []
  type: TYPE_NORMAL
- en: This is a highly specialized function, with special use cases. It should not
    be used without first validating its effect on the application's performance.
  prefs: []
  type: TYPE_NORMAL
- en: Detach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After starting a thread, one can call `detach()` on the thread object. This
    effectively detaches the new thread from the calling thread, meaning that the
    former will continue executing even after the calling thread has exited.
  prefs: []
  type: TYPE_NORMAL
- en: Swap
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using `swap()`, either as a standalone method or as function of a thread instance,
    one can exchange the underlying thread handles of thread objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The possible output from this code might look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The effect of this is that the state of each thread is swapped with that of
    the other thread, essentially exchanging their identities.
  prefs: []
  type: TYPE_NORMAL
- en: Mutex
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `<mutex>` header contains multiple types of mutexes and locks. The mutex
    type is the most commonly used type, and provides the basic lock/unlock functionality
    without any further complications.
  prefs: []
  type: TYPE_NORMAL
- en: Basic use
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At its core, the goal of a mutex is to exclude the possibility of simultaneous
    access so as to prevent data corruption, and to prevent crashes due to the use
    of non-thread-safe routines.
  prefs: []
  type: TYPE_NORMAL
- en: 'An example of where one would need to use a mutex is the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: If one were to try and run this preceding code as-is, one would notice that
    the text output from both threads would be mashed together instead of being output
    one after the other. The reason for this is that the standard output (whether
    C or C++-style) is not thread-safe. Though the application will not crash, the
    output will be a jumble.
  prefs: []
  type: TYPE_NORMAL
- en: 'The fix for this is simple, and is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In this situation, each thread would first need to obtain access to the `mutex`
    object. Since only one thread can have access to the `mutex` object, the other
    thread will end up waiting for the first thread to finish writing to the standard
    output, and the two strings will appear one after the other, as intended.
  prefs: []
  type: TYPE_NORMAL
- en: Non-blocking locking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It''s possible to not want the thread to block and wait for the `mutex` object
    to become available: for example, when one just wants to know whether a request
    is already being handled by another thread, and there''s no use in waiting for
    it to finish.'
  prefs: []
  type: TYPE_NORMAL
- en: For this, a mutex comes with the `try_lock()` function which does exactly that.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we can see two threads trying to increment the same
    counter, but with one incrementing its own counter whenever it fails to immediately
    obtain access to the shared counter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Both threads in this preceding example run a different `worker` function, yet
    both have in common the fact that they sleep for a period of time, and try to
    acquire the mutex for the shared counter when they wake up. If they do, they'll
    increase the counter, but only the first worker will output this fact.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first worker also logs when it did not get the shared counter, but only
    increased its exclusive counter. The resulting output might look something like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Timed mutex
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A timed mutex is a regular mutex type, but with a number of added functions
    which give one control over the time period during which it should be attempted
    to obtain the lock, that is, `try_lock_for` and `try_lock_until`.
  prefs: []
  type: TYPE_NORMAL
- en: The former tries to obtain the lock during the specified time period (`std::chrono`
    object) before returning the result (true or false). The latter will wait until
    a specific point in the future before returning the result.
  prefs: []
  type: TYPE_NORMAL
- en: The use of these functions mostly lies in offering a middle path between the
    blocking (`lock`) and non-blocking (`try_lock`) methods of the regular mutex.
    One may want to wait for a number of tasks using only a single thread without
    knowing when a task will become available, or a task may expire at a certain point
    in time at which waiting for it makes no sense any more.
  prefs: []
  type: TYPE_NORMAL
- en: Lock guard
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A lock guard is a simple mutex wrapper, which handles the obtaining of a lock
    on the `mutex` object as well as its release when the lock guard goes out of scope.
    This is a helpful mechanism to ensure that one does not forget to release a mutex
    lock, and to help reduce clutter in one's code when one has to release the same
    mutex in multiple locations.
  prefs: []
  type: TYPE_NORMAL
- en: 'While refactoring of, for example, big if/else blocks can reduce the instances
    in which the release of a mutex lock is required, it''s much easier to just use
    this lock guard wrapper and not worry about such details:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we see that we have a small if/else block with one
    condition leading to the `worker` function immediately returning. Without a lock
    guard, we would have to make sure that we also unlocked the mutex in this condition
    before returning from the function.
  prefs: []
  type: TYPE_NORMAL
- en: With the lock guard, however, we do not have to worry about such details, which
    allows us to focus on the business logic instead of worrying about mutex management.
  prefs: []
  type: TYPE_NORMAL
- en: Unique lock
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The unique lock is a general-purpose mutex wrapper. It's similar to the timed
    mutex, but with additional features, primary of which is the concept of ownership.
    Unlike other lock types, a unique lock does not necessarily own the mutex it wraps
    if it contains any at all. Mutexes can be transferred between unique lock instances
    along with ownership of the said mutexes using the `swap()` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Whether a unique lock instance has ownership of its mutex, and whether it''s
    locked or not, is first determined when creating the lock, as can be seen with
    its constructors. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The first constructor in the last code does not lock the assigned mutex (defers).
    The second attempts to lock the mutex using `try_lock()`. Finally, the third constructor
    assumes that it already owns the provided mutex.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to these, other constructors allow the functionality of a timed
    mutex. That is, it will wait for a time period until a time point has been reached,
    or until the lock has been acquired.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the association between the lock and the mutex is broken by using the
    `release()` function, and a pointer is returned to the `mutex` object. The caller
    is then responsible for the releasing of any remaining locks on the mutex and
    for the further handling of it.
  prefs: []
  type: TYPE_NORMAL
- en: This type of lock isn't one which one will tend to use very often on its own,
    as it's extremely generic. Most of the other types of mutexes and locks are significantly
    less complex, and likely to fulfil all the needs in 99% of all cases. The complexity
    of a unique lock is, thus, both a benefit and a risk.
  prefs: []
  type: TYPE_NORMAL
- en: It is, however, commonly used by other parts of the C++11 threading API, such
    as condition variables, as we will see in a moment.
  prefs: []
  type: TYPE_NORMAL
- en: 'One area where a unique lock may be useful is as a scoped lock, allowing one
    to use scoped locks without having to rely on the native scoped locks in the C++17
    standard. See this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: As we enter the function, we create a new unique_lock with the global mutex
    instance. The mutex is locked at this point, after which we can perform any critical
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: When the function scope ends, the destructor of the unique_lock is called, which
    results in the mutex getting unlocked again.
  prefs: []
  type: TYPE_NORMAL
- en: Scoped lock
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First introduced in the 2017 standard, the scoped lock is a mutex wrapper which
    obtains access to (locks) the provided mutex, and ensures it is unlocked when
    the scoped lock goes out of scope. It differs from a lock guard in that it is
    a wrapper for not one, but multiple mutexes.
  prefs: []
  type: TYPE_NORMAL
- en: This can be useful when one deals with multiple mutexes in a single scope. One
    reason to use a scoped lock is to avoid accidentally introducing deadlocks and
    other unpleasant complications with, for example, one mutex being locked by the
    scoped lock, another lock still being waited upon, and another thread instance
    having the exactly opposite situation.
  prefs: []
  type: TYPE_NORMAL
- en: One property of a scoped lock is that it tries to avoid such a situation, theoretically
    making this type of lock deadlock-safe.
  prefs: []
  type: TYPE_NORMAL
- en: Recursive mutex
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The recursive mutex is another subtype of mutex. Even though it has exactly
    the same functions as a regular mutex, it allows the calling thread, which initially
    locked the mutex, to lock the same mutex repeatedly. By doing this, the mutex
    doesn't become available for other threads until the owning thread has unlocked
    the mutex as many times as it has locked it.
  prefs: []
  type: TYPE_NORMAL
- en: One good reason to use a recursive mutex is for example when using recursive
    functions. With a regular mutex one would need to invent some kind of entry point
    which would lock the mutex before entering the recursive function.
  prefs: []
  type: TYPE_NORMAL
- en: With a recursive mutex, each iteration of the recursive function would lock
    the recursive mutex again, and upon finishing one iteration, it would unlock the
    mutex. As a result the mutex would be unlocked and unlocked the same number of
    times.
  prefs: []
  type: TYPE_NORMAL
- en: A potential complication hereby is that the maximum number of times that a recursive
    mutex can be locked is not defined in the standard. When the implementation's
    limit has been reached, a `std::system_error` will be thrown if one tries to lock
    it, or false is returned when using the non-blocking `try_lock` function.
  prefs: []
  type: TYPE_NORMAL
- en: Recursive timed mutex
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The recursive timed mutex is, as the name suggests, an amalgamation of the functionality
    of the timed mutex and recursive mutex. As a result, it allows one to recursively
    lock the mutex using a timed conditional function.
  prefs: []
  type: TYPE_NORMAL
- en: Although this adds challenges to ensuring that the mutex is unlocked as many
    times as the thread locks it, it nevertheless offers possibilities for more complex
    algorithms such as the aforementioned task-handlers.
  prefs: []
  type: TYPE_NORMAL
- en: Shared mutex
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `<shared_mutex>` header was first added with the 2014 standard, by adding
    the `shared_timed_mutex` class. With the 2017 standard, the `shared_mutex` class
    was also added.
  prefs: []
  type: TYPE_NORMAL
- en: The shared mutex header has been present since C++17\. In addition to the usual
    mutual exclusive access, this `mutex` class adds the ability to provide shared
    access to the mutex. This allows one to, for example, provide read access to a
    resource by multiple threads, while a writing thread would still be able to gain
    exclusive access. This is similar to the read-write locks of Pthreads.
  prefs: []
  type: TYPE_NORMAL
- en: 'The functions added to this mutex type are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`lock_shared()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`try_lock_shared()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unlock_shared()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The use of this mutex's share functionality should be fairly self-explanatory.
    A theoretically infinite number of readers can gain read access to the mutex,
    while ensuring that only a single thread can write to the resource at any time.
  prefs: []
  type: TYPE_NORMAL
- en: Shared timed mutex
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This header has been present since C++14\. It adds shared locking functionality
    to the timed mutex with these functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`lock_shared()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`try_lock_shared()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`try_lock_shared_for()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`try_lock_shared_until()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unlock_shared()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This class is essentially an amalgamation of the shared mutex and timed mutex,
    as the name suggests. The interesting thing here is that it was added to the standard
    before the more basic shared mutex.
  prefs: []
  type: TYPE_NORMAL
- en: Condition variable
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In essence, a condition variable provides a mechanism through which a thread's
    execution can be controlled by another thread. This is done by having a shared
    variable which a thread will wait for until signaled by another thread. It is
    an essential part of the scheduler implementation we looked at in [Chapter 11](3569125d-7316-4147-ba03-9c65cfd755d7.xhtml),
    *Thread Synchronization and Communication*.
  prefs: []
  type: TYPE_NORMAL
- en: For the C++11 API, condition variables and their associated functionality are
    defined in the `<condition_variable>` header.
  prefs: []
  type: TYPE_NORMAL
- en: The basic usage of a condition variable can be summarized from that scheduler's
    code in [Chapter 11](3569125d-7316-4147-ba03-9c65cfd755d7.xhtml), *Thread Synchronization
    and Communication*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'In the constructor, as defined in the preceding `Worker` class declaration,
    we see the way a condition variable in the C++11 API is initialized. The steps
    are listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a `condition_variable` and `mutex` instance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assign the mutex to a new `unique_lock` instance. With the constructor we use
    here for the lock, the assigned mutex is also locked upon assignment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The condition variable is now ready for use:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Here, we use the `wait_for()` function of the condition variable, and pass both
    the unique lock instance we created earlier and the amount of time which we want
    to wait for. Here we wait for 1 second. If we time out on this wait, we are free
    to re-enter the wait (as is done here) in a continuous loop, or continue execution.
  prefs: []
  type: TYPE_NORMAL
- en: It's also possible to perform a blocking wait using the simple `wait()` function,
    or wait until a certain point in time with `wait_for()`.
  prefs: []
  type: TYPE_NORMAL
- en: As noted, when we first looked at this code, the reason why this worker's code
    uses the `ready` Boolean variable is to check that it was really another thread
    which signaled the condition variable, and not just a spurious wake-up. It's an
    unfortunate complication of most condition variable implementations--including
    the C++11 one--that they are susceptible to this.
  prefs: []
  type: TYPE_NORMAL
- en: As a result of these random wake-up events, it is necessary to have some way
    to ensure that we really did wake up intentionally. In the scheduler code, this
    is done by having the thread which wakes up the worker thread also set a `Boolean`
    value which the worker thread can wake up.
  prefs: []
  type: TYPE_NORMAL
- en: 'Whether we timed out, or were notified, or suffered a spurious wake-up can
    be checked with the `cv_status` enumeration. This enumeration knows these two
    possible conditions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`timeout`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`no_timeout`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The signaling, or notifying, itself is quite straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'In this preceding function from the `Dispatcher` class, we attempt to obtain
    an available worker thread instance. If found, we obtain a reference to the worker
    thread''s condition variable as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Setting the new request on the worker thread also changes the value of the `ready`
    variable to true, allowing the worker to check that it is indeed allowed to continue.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the condition variable is notified that any threads which are waiting
    on it can now continue using `notify_one()`. This particular function will signal
    the first thread in the FIFO queue for this condition variable to continue. Here,
    only one thread will ever be notified, but if there are multiple threads waiting
    for the same condition variable, the calling of `notify_all()` will allow all
    threads in the FIFO queue to continue.
  prefs: []
  type: TYPE_NORMAL
- en: Condition_variable_any
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `condition_variable_any` class is a generalization of the `condition_variable`
    class. It differs from the latter in that it allows for other mutual exclusion
    mechanisms to be used beyond `unique_lock<mutex>`. The only requirement is that
    the lock used meets the `BasicLockable` requirements, meaning that it provides
    a `lock()` and `unlock()` function.
  prefs: []
  type: TYPE_NORMAL
- en: Notify all at thread exit
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `std::notify_all_at_thread_exit()` function allows a (detached) thread to
    notify other threads that it has completely finished, and is in the process of
    having all objects within its scope (thread-local) destroyed. It functions by
    moving the provided lock to internal storage before signaling the provided condition
    variable.
  prefs: []
  type: TYPE_NORMAL
- en: The result is exactly as if the lock was unlocked and `notify_all()` was called
    on the condition variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'A basic (non-functional) example can be given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Here, the worker thread executes a method which creates thread-local objects.
    It's therefore essential that the main thread waits for the detached worker thread
    to finish first. If the latter isn't done yet when the main thread finishes its
    tasks, it will enter a wait using the global condition variable. In the worker
    thread, `std::notify_all_at_thread_exit()` is called after setting the `ready`
    Boolean.
  prefs: []
  type: TYPE_NORMAL
- en: What this accomplishes is twofold. After calling the function, no more threads
    are allowed to wait on the condition variable. It also allows the main thread
    to wait for the result of the detached worker thread to become available.
  prefs: []
  type: TYPE_NORMAL
- en: Future
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The last part of the C++11 thread support API is defined in `<future>`. It offers
    a range of classes, which implement more high-level multithreading concepts aimed
    more at easy asynchronous processing rather than the implementation of a multithreaded
    architecture.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we have to distinguish two concepts: that of a future and that of a promise.
    The former is the end result (the future product) that''ll be used by a reader/consumer.
    The latter is what the writer/producer uses.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A basic example of a future would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This code asynchronously calls a function, passing it a parameter (potential
    prime number). It then enters an active loop while it waits for the future it
    received from the asynchronous function call to finish. It sets a 100 ms timeout
    on its wait function.
  prefs: []
  type: TYPE_NORMAL
- en: Once the future finishes (not returning a timeout on the wait function), we
    obtain the resulting value, in this case telling us that the value we provided
    the function with is in fact a prime number.
  prefs: []
  type: TYPE_NORMAL
- en: In the *async* section of this chapter, we will look a bit more at asynchronous
    function calls.
  prefs: []
  type: TYPE_NORMAL
- en: Promise
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A `promise` allows one to transfer states between threads. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: This preceding code uses a `promise` instance passed to a worker thread to transfer
    a value to the other thread, in this case an integer. The new thread waits for
    the future we created from the promise, and which it received from the main thread
    to complete.
  prefs: []
  type: TYPE_NORMAL
- en: The promise is completed when we set the value on the promise. This completes
    the future and finishes the worker thread.
  prefs: []
  type: TYPE_NORMAL
- en: In this particular example, we use a blocking wait on the `future` object, but
    one can also use `wait_for()` and `wait_until()`, to wait for a time period or
    a point in time respectively, as we saw in the previous example for a future.
  prefs: []
  type: TYPE_NORMAL
- en: Shared future
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A `shared_future` is just like a regular `future` object, but can be copied,
    which allows multiple threads to read its results.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a `shared_future` is similar to a regular `future.`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The biggest difference is that the regular `future` is passed to its constructor.
  prefs: []
  type: TYPE_NORMAL
- en: After this, all threads which have access to the `future` object can wait for
    it, and obtain its value. This can also be used to signal threads in a way similar
    to condition variables.
  prefs: []
  type: TYPE_NORMAL
- en: Packaged_task
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A `packaged_task` is a wrapper for any callable target (function, bind, lambda,
    or other function object). It allows for asynchronous execution with the result
    available in a `future` object. It is similar to `std::function`, but automatically
    transfers its results to a `future` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This preceding code implements a simple countdown feature, counting down from
    10 to 0\. After creating the task and obtaining a reference to its `future` object,
    we push it onto a thread along with the parameters of the `worker` function.
  prefs: []
  type: TYPE_NORMAL
- en: The result from the countdown worker thread becomes available as soon as it
    finishes. We can use the `future` object's waiting functions here the same way
    as for a `promise`.
  prefs: []
  type: TYPE_NORMAL
- en: Async
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A more straightforward version of `promise` and `packaged_task` can be found
    in `std::async()`. This is a simple function, which takes a callable object (function,
    bind, lambda, and similar) along with any parameters for it, and returns a `future`
    object.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a basic example of the `async()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The `worker` function in the preceding code determines whether a provided integer
    is a prime number or not. As we can see, the resulting code is a lot more simple
    than with a `packaged_task` or `promise`.
  prefs: []
  type: TYPE_NORMAL
- en: Launch policy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In addition to the basic version of `std::async(),` there is a second version
    which allows one to specify the launch policy as its first argument. This is a
    bitmask value of type `std::launch` with the following possible values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The `async` flag means that a new thread and execution context for the `worker`
    function is created immediately. The `deferred` flag means that this is postponed
    until `wait()` or `get()` is called on the `future` object. Specifying both flags
    causes the function to choose the method automatically depending on the current
    system situation.
  prefs: []
  type: TYPE_NORMAL
- en: The `std::async()` version, without explicitly specified bitmask values, defaults
    to the latter, automatic method.
  prefs: []
  type: TYPE_NORMAL
- en: Atomics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With multithreading, the use of atomics is also very important. The C++11 STL
    offers an `<atomic>` header for this reason. This topic is covered extensively
    in [Chapter 15](fa81398a-9b4d-43c6-8ee5-cec7d6a6b6c1.xhtml), *Atomic Operations
    - Working with the Hardware*.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored the entirety of the multithreading support in the
    C++11 API, along with the features added in C++14 and C++17.
  prefs: []
  type: TYPE_NORMAL
- en: We saw how to use each feature using descriptions and example code. We can now
    use the native C++ multithreading API to implement multithreaded, thread-safe
    code as well as use the asynchronous execution features in order to speed up and
    execute functions in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will take a look at the inevitable next step in the
    implementation of multithreaded code: debugging and validating of the resulting
    application.'
  prefs: []
  type: TYPE_NORMAL
