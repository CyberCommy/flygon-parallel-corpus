- en: Introduction to Parallel Programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Parallel programming has been supported in .NET since the start and it has gained
    a strong footing since the introduction of the **Task Parallel Library** (**TPL**)
    from .NET framework 4.0 onward.
  prefs: []
  type: TYPE_NORMAL
- en: Multithreading is a subset of parallel programming and is one of the least understood
    aspects of programming; it's one that many new developers struggle to understand.
    C# has evolved significantly since its inception. It has very strong support,
    not only for multithreading but also for asynchronous programming. Multithreading
    in C# goes way back to C# version 1.0. C# is primarily synchronous, but with the
    strong async support that has been added from C# 5.0 onward, it has become the
    first choice for application programmers. Whereas multithreading only deals with
    how to parallelize within processes, parallel programming also deals with inter-process
    communication scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Prior to the introduction of the TPL, we relied on `Thread`, `BackgroundWorker`, and `ThreadPool` to
    provide us with multithreading capabilities. At the time of C# v1.0, it relied
    on threads to split up work and free up the **user interface** (**UI**), thereby
    allowing the user to develop responsive applications. This model is now referred
    to as classic threading. With time, this model made way for another model of programming,
    called TPL, which relies on tasks and still uses threads internally.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will learn about various concepts that will help you learn
    about writing multithreaded code from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Basic concepts of multi-core computing, starting with an introduction to the
    concepts and processes related to the **operating system** (**OS**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Threads and the difference between multithreading and multitasking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advantages and disadvantages of writing parallel code and scenarios in which
    parallel programming is useful
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the examples demonstrated in this book have been created in Visual Studio
    2019 using C# 8. All the source code can be found on GitHub at [https://github.com/PacktPublishing/Hands-On-Parallel-Programming-with-C-8-and-.NET-Core-3/tree/master/Chapter01](https://github.com/PacktPublishing/Hands-On-Parallel-Programming-with-C-8-and-.NET-Core-3/tree/master/Chapter01).
  prefs: []
  type: TYPE_NORMAL
- en: Preparing for multi-core computing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will introduce the core concepts of the OS, starting with
    the process, which is where threads live and run. Then, we will consider how multitasking
    evolved with the introduction of hardware capabilities, which make parallel programming
    possible. After that, we will try to understand the different ways of creating
    a thread with code.
  prefs: []
  type: TYPE_NORMAL
- en: Processes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In layman's terms, the word *process* refers to a program in execution. In terms
    of the OS, however, a process is an address space in the memory. Every application,
    whether it is a Windows, web, or mobile application, needs processes to run. Processes
    provide security for programs against other programs that run on the same system
    so that data that's allocated to one cannot be accidentally accessed by another.
    They also provide isolation so that programs can be started and stopped independently
    of each other and independently of the underlying OS.
  prefs: []
  type: TYPE_NORMAL
- en: Some more information about the OS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The performance of applications largely depends on the quality and configuration
    of the hardware. This includes the following:'
  prefs: []
  type: TYPE_NORMAL
- en: CPU speed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amount of RAM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hard disk speed (5400/7200 RPM)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disk type, that is, HDD or SSD
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Over the last few decades, we have seen huge jumps in hardware technology. For
    example, microprocessors used to have a single core, which is a chip with one
    **central processing unit** (**CPU**). By the turn of the century, we saw the
    advent of multi-core processors, which are chips with two or more processors,
    each with its own cache.
  prefs: []
  type: TYPE_NORMAL
- en: Multitasking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multitasking refers to the ability of a computer system to run more than one
    process (application) at a time. The number of processes that can be run by a
    system is directly proportional to the number of cores in that system. Therefore,
    a single-core processor can only run one task at a time, a dual-core processor
    can run two tasks at a time, and a quad-core processor can run four tasks at a
    time. If we add the concept of CPU scheduling to this, we can see that the CPU
    runs more applications at a time by scheduling or switching them based on CPU
    scheduling algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Hyper-threading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Hyper-threading** (**HT**) technology is a proprietary technology that was
    developed by Intel that improves the parallelization of computations that are
    performed on x86 processors. It was first introduced in Xeon server processors
    in 2002\. HT-enabled single-processor chips run with two virtual (logical) cores
    and are capable of executing two tasks at a time. The following diagram shows
    the difference between single- and multi-core chips:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0bf4dc71-2221-42f3-b90f-ffaccf0bbd82.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following are a few examples of processor configurations and the number
    of tasks that they can perform:'
  prefs: []
  type: TYPE_NORMAL
- en: '**A single processor with a single-core chip**: One task at a time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A single processor with an HT-enabled single-core chip**: Two tasks at a
    time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A single processor with a dual-core chip**: Two tasks at a time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A single processor with an HT-enabled dual-core chip**: Four tasks at a time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A single processor with a quad-core chip**: Four tasks at a time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A single processor with an HT-enabled quad-core chip**: Eight tasks at a
    time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is a screenshot of a CPU resource monitor for an HT-enabled quad-core
    processor system. On the right-hand side, you can see that there are eight available
    CPUs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/47af0d87-7dcb-4f51-843d-dcba28bb0ab6.png)'
  prefs: []
  type: TYPE_IMG
- en: You might be wondering how much you can improve the performance of your computer
    simply by moving from a single-core to a multi-core processor. At the time of
    writing, most of the fastest supercomputers are built on the **Multiple Instruction,
    Multiple Data** (**MIMD**) architecture, which was one of the classifications
    of computer architecture proposed by Michael J. Flynn in 1966.
  prefs: []
  type: TYPE_NORMAL
- en: Let's try to understand this classification.
  prefs: []
  type: TYPE_NORMAL
- en: Flynn's taxonomy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Flynn classified computer architectures into four categories based on the number
    of concurrent instruction (or control) streams and data streams:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Single Instruction, Single Data (SISD)**:In this model, there is a single
    control unit and a single instruction stream. These systems can only execute one
    instruction at a time without any parallel processing. All single-core processor
    machines are based on the SISD architecture.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Single Instruction, Multiple Data (SIMD)**:In this model, we have a single
    instruction stream and multiple data streams. The same instruction stream is applied
    to multiple data streams in parallel. This is handy in speculative-approach scenarios
    where we have multiple algorithms for data and we don''t know which one will be
    faster. It provides the same input to all the algorithms and runs them in parallel
    on multiple processors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multiple Instructions, Single Data (MISD)**:In this model, multiple instructions
    operate on one data stream. Therefore, multiple operations can be applied in parallel
    on the same data source. This is generally used for fault tolerance and in space
    shuttle flight control computers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multiple Instructions, Multiple Data (MIMD)**:In this model, as the name
    suggests, we have multiple instruction streams and multiple data streams. Due
    to this, we can achieve true parallelism, where each processor can run different
    instructions on different data streams. Nowadays, this architecture is used by
    most computer systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we've covered the basics, let's move our discussion to threads.
  prefs: []
  type: TYPE_NORMAL
- en: Threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A thread is a unit of execution inside a process. At any point, a program may
    consist of one or more threads for better performance. GUI-based Windows applications,
    such as legacy **Windows Forms** (**WinForms**) or **Windows Presentation Foundation**
    (**WPF**), have a dedicated thread for managing the UI and handling user actions.
    This thread is also called the UI thread, or the **foreground thread**. It owns
    all the controls that are created as part of the UI.
  prefs: []
  type: TYPE_NORMAL
- en: Types of threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two different types of managed threads, that is, a foreground thread
    and a background thread. The difference between these is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Foreground threads:** These have a direct impact on an application''s lifetime.
    The application keeps running until there is a foreground thread.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Background threads:** These have no impact on the application''s lifetime.
    When the application exits, all the background threads are killed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An application may comprise any number of foreground or background threads.
    While active, a foreground thread keeps the application running; that is, the
    application's lifetime depends on the foreground thread. The application stops
    completely when the last foreground thread is stopped or aborted. When the application
    exits, the system stops all the background threads.
  prefs: []
  type: TYPE_NORMAL
- en: Apartment state
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another important aspect of threads to understand is the apartment state. This
    is the area inside a thread where **Component Object Model** (**COM**) objects
    reside.
  prefs: []
  type: TYPE_NORMAL
- en: COM is an object-oriented system for creating binary software that the user
    can interact with and is distributed and cross-platform. COM has been used to
    create Microsoft OLE and ActiveX technologies.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you may be aware, all Windows forms controls are wrapped over COM objects.
    Whenever you create a .NET WinForms application, you are actually hosting COM
    components. A thread apartment is a distinct area inside the application process
    where COM objects are created. The following diagram demonstrates the relationship
    between the thread apartment and COM objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/91fa5328-4ca2-4cde-8046-b3246100b68a.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from the preceding diagram, every thread has thread apartments
    where COM objects reside.
  prefs: []
  type: TYPE_NORMAL
- en: 'A thread can belong to one of two apartment states:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Single-Threaded Apartment** (**STA**):The underlying COM object can be accessed
    via a single thread only'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multi-Threaded Apartment** (**MTA**):The underlying COM object can be accessed
    via multiple threads at a time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following list highlights some important points regarding thread apartment
    states:'
  prefs: []
  type: TYPE_NORMAL
- en: Processes can have multiple threads, either foreground or background.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each thread can have one apartment, either STA or MTA.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every apartment has a concurrency model, either single-threaded or multithreaded.
    We can change the thread state programmatically as well.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An application process may have more than one STA, but a maximum of one MTA.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An example of an STA application is a Windows application, and an example of
    an MTA application is a web application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: COM objects are created in apartments. One COM object can only lie in one thread
    apartment, and apartments cannot be shared.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An application can be forced to start in STA mode by using the `STAThread`
    attribute over the main methods. The following is an example of the `Main` method
    of a legacy WinForm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The `STAThread` attribute is also present in WPF but is hidden from users.
    The following is the code for the compiled `App.g.cs` class, which can be found
    in the `obj/Debug` directory of your WPF project after compilation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the `Main` method is decorated with the `STAThread` attribute.
  prefs: []
  type: TYPE_NORMAL
- en: Multithreading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Parallel execution of code in .NET is achieved through multithreading. A process
    (or application) can utilize any number of threads, depending on its hardware
    capabilities. Every application, including console, legacy WinForms, WPF, and
    even web applications, is started by a single thread by default. We can easily
    achieve multithreading by creating more threads programmatically as and when they
    are required.
  prefs: []
  type: TYPE_NORMAL
- en: 'Multithreading typically functions using a scheduling component known as a **thread
    scheduler**, which keeps track of when a thread should run out of active threads
    inside a process. Every thread that''s created is assigned a `System.Threading.ThreadPriority`,
    which can have one of the following valid values. `Normal` is the default priority
    that''s assigned to any thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Highest`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AboveNormal`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Normal`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BelowNormal`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Lowest`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Every thread that runs inside a process is assigned a time slice by the OS
    based on the thread priority scheduling algorithm. Every OS can have a different
    scheduling algorithm for running threads, so the order of execution may vary in
    different operating systems. This makes it more difficult to troubleshoot threading
    errors. The most common scheduling algorithm is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Find the threads with the highest priority and schedule them to run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If there is more than one thread with the highest priority, each thread is assigned
    a fixed time slices in which they can execute.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the highest-priority threads finish executing, the lower-priority threads
    start to be allocated to time slices in which it can begin executing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If a new highest-priority thread is created, low-priority threads are pushed
    back again.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Time slicing refers to switching the execution between the active threads. It
    can vary, depending on the hardware configuration. A single-core processor machine
    can only run one thread at a time, so the thread scheduler carries out the time
    slicing. The time slice largely depends on the clock speed of the CPU, but there still aren't
    many performance gains that can be achieved via multithreading in such systems.
    Moreover, context switching comes with performance overheads. If the work that's
    allocated to a thread spans multiple time slices, then the thread needs to be
    switched in and out of memory. Every time it switches out, it needs to bundle
    and save its state (data) and reload it when it switches back in.
  prefs: []
  type: TYPE_NORMAL
- en: '**Concurrency** is a concept that''s primarily used in the context of multi-core
    processors. A multi-core processor has a higher number of CPUs available, as we
    discussed previously, and therefore different threads can be run simultaneously
    on different CPUs. A higher number of processors means a higher degree of concurrency.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are multiple ways that threads can be created in programs. These include
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The `Thread` class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `ThreadPool` Class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `BackgroundWorker` Class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asynchronous delegates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TPL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will cover asynchronous delegates and TPL in depth during the course of this
    book, but in this chapter, we will provide an explanation of the remaining three
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: Thread class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The simplest and easiest way of creating threads is via the `Thread` class,
    which is defined in the `System.Threading` namespace. This approach has been used
    since the arrival of .NET version 1.0 and it works with .NET core as well. To
    create a thread, we need to pass a method that the thread needs to execute. The
    method can either be parameter-less or parameterized. There are two delegates
    that are provided by the framework to wrap these functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`System.Threading.ThreadStart`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`System.Threading.ParameterizedThreadStart`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will learn both of these through examples. Before showing you how to create
    a thread, I will try to explain how a synchronous program works. Later on, we
    will introduce multithreading so that we understand the asynchronous way of execution.
    An example of *how to create a thread* is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, everything runs in the main thread. We have called the
    `PrintNumber10Times` method from within the `Main` method, and since the `Main`
    method is invoked by the main GUI thread, the code runs synchronously. This can
    cause unresponsive behavior if the code runs for a long time as the main thread
    will be busy during execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of the code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/74b9065b-8199-44b6-85ed-09d87800ba86.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the following timeline, we can see that everything happens in the **Main
    Thread**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/850babff-8666-46f4-b77e-93d4daf8b18e.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding diagram shows sequential code execution on the `Main` thread.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can make the program multithreaded by creating a thread to do the printing.
    The main thread prints the statements that are written in the `Main` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we have delegated the execution of `PrintNumber10Times()`
    to a new thread that has been created via the `Thread` class. The `Console.WriteLine`
    statements in the `Main` method are still executed via the main thread, but `PrintNumber10Times`
    is not called via the child thread.
  prefs: []
  type: TYPE_NORMAL
- en: The output of the code is as follows**:**
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4d9fdc64-b6d5-4c8d-bb76-34205f269081.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The timeline for this process is as follows. You can see that `Console.WriteLine`
    executes on the **Main Thread** and that the loop executes on the **Child Thread**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bf617bfc-229f-469d-896c-c5b883ffd3c0.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding diagram is an example of multithreaded execution.
  prefs: []
  type: TYPE_NORMAL
- en: If we compare the outputs, we can see that the program finishes everything in
    the main thread and then starts to print the number 10 times. The operations in
    this example are very small and thus work in a deterministic manner. If there
    are time-consuming statements in the main thread before **Finish Execution** is
    printed, however, the results can vary. We will look at how multithreading works
    and how it is related to CPU speed and numbers later on in this chapter in order
    to fully understand this idea.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is another example to show you how to pass data to the thread using the `System.Threading.ParameterizedThreadStart` delegate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The output of the preceding code is as follows**:**
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ca3f74e9-6fa1-47f9-9920-7544030afeb1.png)'
  prefs: []
  type: TYPE_IMG
- en: Using the `Thread` class has some advantages and disadvantages. Let's try to
    understand them.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and disadvantages of threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `Thread` class has the following advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: Threads can be utilized to free up the main thread.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Threads can be used to break up a task into smaller units that can be executed
    concurrently.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `Thread` class has the following disadvantages:'
  prefs: []
  type: TYPE_NORMAL
- en: With more threads, the code becomes difficult to debug and maintain.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thread creation puts a load on the system in terms of memory and CPU resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We need to do exception handling inside the worker method as any unhandled exceptions
    can result in the program crashing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ThreadPool class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thread creation is an expensive operation in terms of both memory and CPU resources.
    On average, every thread consumes around 1 MB of memory and a few hundred microseconds
    of CPU time. Application performance is a relative concept, so it will not necessarily
    improve by creating a large number of threads. Conversely, creating a large number
    of threads can sometimes decrease application performance drastically. We should
    always aim to create an optimal number of threads, depending on the target system's
    CPU load, that is, other programs running on the system. This is because every
    program gets a time slice by the CPU, which is then distributed among the threads
    inside the application. If you create too many threads, they may not be able to
    do any constructive work before being swapped out of memory to give the time slice
    other similar-priority threads.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the optimal number of threads can be tricky as it can vary from one
    system to another, depending on the configuration and the number of applications
    that are running concurrently on the system. What may be an optimal number on
    one system may cause a negative impact on another. Rather than finding the optimal
    number of threads ourselves, we can leave it to the **Common Language Runtime**
    (**CLR**). The CLR has an algorithm to determine the optimal number based on the
    CPU load at any point in time. It maintains a pool of threads, known as the `ThreadPool`.
    The `ThreadPool` resides in a process and each application has its own pool of
    threads. The advantage of thread pooling is that it maintains an optimal number
    of threads and assigns them to a task. When the work is finished, the threads
    are returned to the pool, where they can be assigned to the next work item, thereby
    preventing the cost of creating and destroying threads.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a list of the optimal number of threads that can be created
    in different frameworks inside `ThreadPool`:'
  prefs: []
  type: TYPE_NORMAL
- en: 25 per core in .NET Framework 2.0
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 250 per core in .NET Framework 3.5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1,023 in .NET Framework 4.0 in a 32-bit environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 32,768 in .NET Framework 4.0 onward, as well as in .NET core in a 64-bit environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While working with an investment bank, we came across a scenario where a trade process
    was taking almost 1,800 seconds to book close to 1,000 trades synchronously. After
    trying various optimal numbers, we finally switched to `ThreadPool` and made the
    process multithreaded. With .NET Framework version 2.0, the application finished
    in close to 72 seconds. With version 3.5, the same application finished in just
    a few seconds. This is a typical example of using the framework that's been provided
    rather than reinventing the wheel. You can get much-needed performance gains just
    by updating the framework.
  prefs: []
  type: TYPE_NORMAL
- en: We can create a thread via `ThreadPool` by calling `ThreadPool.QueueUserWorkItem`,
    as shown in the following example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the method that we want to call in parallel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is how we can create a thread using `ThreadPool.QueueUserWorkItem` while
    passing the `WaitCallback` delegate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a call from the `Main` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e4f970e1-5ed9-4167-8849-cdd81c5faf05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Every thread pool maintains a minimum and a maximum number of threads. These
    values can be modified by calling the following static methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ThreadPool.SetMinThreads`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ThreadPool.SetMaxThreads`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A thread is created via `System.Threading`. The `Thread` class doesn't belong
    to the `ThreadPool`.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at the advantages and disadvantages associated with using
    the `ThreadPool` class and when to avoid using it.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages, disadvantages, and when to avoid using ThreadPool
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The advantages of the `ThreadPool` are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Threads can be utilized to free up the main thread.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Threads are created and maintained in an optimal way by CLR.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The disadvantages of the `ThreadPool` are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: With more threads, the code becomes difficult to debug and maintain.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We need to do exception handling inside the worker method as any unhandled exception
    can result in the program crashing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Progress reporting, cancellations, and completion logic need to be written from
    scratch.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following are the reasons when we should avoid `ThreadPool`:'
  prefs: []
  type: TYPE_NORMAL
- en: When we need a foreground thread.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we need to set an explicit priority to a thread.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we have long-running or blocking tasks. Having a large number of blocked
    threads in the pool will prevent new tasks from starting due to the limited number
    of threads that are available per process in `ThreadPool`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we need STA threads since `ThreadPool` threads are MTA by default.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we need to dedicate a thread to a task by providing it a distinct identity
    since we cannot name a `ThreadPool` thread.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BackgroundWorker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`BackgroundWorker` is a construct provided by .NET to create more manageable
    threads from a `ThreadPool`. When explaining  GUI-based applications, we saw that
    the `Main` method was decorated with the `STAThread` attribute. This attribute
    guarantees control safety as controls are created in the apartment owned by the
    thread and cannot be shared with other threads. In Windows applications, there
    is the main thread of execution that owns the UI and controls, which is created
    when the application starts. It is responsible for accepting user inputs and painting
    or repainting the UI based on the actions of the user. For a great user experience,
    we should try to make the UI as thread-free as possible and delegate all time-consuming
    tasks to worker threads. Some common tasks that are usually assigned to worker
    threads are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Downloading images from a server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interacting with a database
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interacting with a filesystem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interacting with web services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Complex local computations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, most of these are **input/output** (**I/O**) operations. I/O
    operations are carried out by the CPU. The moment we call a piece of code that
    encapsulates an I/O operation, the execution is passed from the thread to the
    CPU, which performs the task. When it is complete, the result of the operation
    is returned to the caller thread. This period from passing the baton and receiving
    results is a period of inactivity for the thread as it just has to wait for the
    operation to complete. If this occurs in the main thread, the application becomes
    unresponsive. For this reason, it makes sense to delegate these tasks to the worker
    threads. There are still several challenges to overcome with regard to responsive
    applications. Let's look at an example.
  prefs: []
  type: TYPE_NORMAL
- en: '**Case study**:'
  prefs: []
  type: TYPE_NORMAL
- en: We need to fetch data from a service that streams data. We would like to update
    the user with the percentage completion of work. Once the work is complete, we
    need to update the user with all the data.
  prefs: []
  type: TYPE_NORMAL
- en: '**Challenges**:'
  prefs: []
  type: TYPE_NORMAL
- en: The service call takes time, so we need to delegate the call in a worker thread
    to avoid UI freeze.
  prefs: []
  type: TYPE_NORMAL
- en: '**Solution**:'
  prefs: []
  type: TYPE_NORMAL
- en: '`BackgroundWorker` is a class provided in `System.ComponentModel` that can
    be used to create a worker thread utilizing `ThreadPool`, as we discussed previously.
    This means that it works in an efficient way. `BackgroundWorker` also supports
    progress reporting and cancellations, apart from notifying the result of the operation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This scenario can be further explained with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '`BackgroundWorker` provides an abstraction over raw threads, which gives more
    control and options to the user. The best part about using `BackgroundWorker`
    is that it uses an **Event-Based Asynchronous Pattern** (**EAP**), which means
    it is able to interact with the code more efficiently than raw threads. The code
    is more or less self-explanatory. In order to raise progress reporting and cancellation
    events, you need to set the following properties to `true`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'You need to subscribe to the `ProgressChanged` event to receive progress, the `DoWork`
    event to pass a method that needs to be invoked by the thread, and the `RunWorkerCompleted` event
    to receive either the final results or any error messages from the thread''s execution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Once this has been set up, you can invoke the worker by calling the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: At any point in time, you can cancel the execution of the thread by calling
    the `backgroundWorker.CancelAsync()` method, which sets the `CancellationPending`
    property on the worker thread. We need to write some code that keeps checking
    this flag and exits gracefully.
  prefs: []
  type: TYPE_NORMAL
- en: 'If there are no exceptions, the result of the thread''s execution can be returned
    to the caller by setting the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: If there are any unhandled exceptions in the program, they are returned to the
    caller gracefully. We can do this by wrapping it into `RunWorkerCompletedEventArgs`
    and passing it as a parameter to the `RunWorkerCompleted` event handler.
  prefs: []
  type: TYPE_NORMAL
- en: We will look at the advantages and disadvantages of using `BackgroundWorker`
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and disadvantages of using BackgroundWorker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The advantages of using `BackgroundWorker` are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Threads can be utilized to free up the main thread.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Threads are created and maintained in an optimal way by the `ThreadPool` class's
    CLR.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graceful and automatic exception handling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supports progress reporting, cancellation, and completion logic using events.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The disadvantage of using `BackgroundWorker` is that, with more threads, the
    code becomes difficult to debug and maintain.
  prefs: []
  type: TYPE_NORMAL
- en: Multithreading versus multitasking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have seen how both multithreading and multitasking work. Both have advantages
    and disadvantages and you can use either, depending on your specific use case.
    The following are some examples where multithreading can come in handy:'
  prefs: []
  type: TYPE_NORMAL
- en: '**If you need a system that is easy to set up and terminate**: Multithreading
    can be useful when you have a process that has a large overhead. With threads,
    all you need to do is copy the thread stack. Creating a duplicate process, however,
    means recreating the entire data process in a separate memory space.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**If you require fast task switching**: The CPU caches and program context
    can be easily maintained between threads in a process. If you have to switch the
    CPU to a different process, however, it has to be reloaded.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**If you need to share data with other threads**:All the threads inside a process
    share the same memory pool, which makes it easier for them to share data to compare
    processes. If processes want to share data, they need I/O operation and transport
    protocols, which is expensive.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we have discussed the basics of multithreading and multitasking,
    alongside various approaches that were used to create threads in older versions
    of .NET. In the next section, we will try to understand some scenarios where you
    can utilize parallel programming techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Scenarios where parallel programming can come in handy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the scenarios in which parallel programming can be useful:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Creating a responsive UI for GUI-based applications**:We can delegate all
    of the heavy lifting and time-consuming tasks to the worker thread, thereby allowing
    the UI thread to process user interactions and the UI repainting tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Processing simultaneous requests**:In server-side programming scenarios,
    we need to process a large number of concurrent users. We can create a separate
    thread to process each request. For example, we can use an ASP.NET request model,
    which makes use of `ThreadPool` and assigns a thread to every request that hits
    the server. Then, the thread takes care of processing the request and returning
    a response to the client. In a client-side scenario, we can call multiple mutually
    exclusive API calls via multithreading to save time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Making efficient use of CPU**:With multi-core processors, only one core is
    generally utilized without multithreading and is overburdened. We can make full
    use of CPU resources by creating multiple threads, each running on separate CPUs.
    Sharing the burden in this way results in improved performance. This is useful
    for long-running and complex calculations, which can be performed faster using
    a divide-and-conquer strategy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Speculative approaches**:Scenarios involving more than one algorithm, such
    as for an input set of numbers, where we want to get a sorted set as quickly as
    possible. The only way to do this is to pass the input to all the algorithms and
    run them in parallel, and whichever finishes first is accepted, while the rest
    are canceled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advantages and disadvantages of parallel programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multithreading leads to parallelism, which has its own programming and pitfalls.
    Now that we have grasped the basic concepts of parallel programming, it is important
    to understand its advantages and disadvantages.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the benefits of parallel programming:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Enhanced performance**: We can achieve better performance since tasks are
    distributed across threads that run in parallel.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Improved GUI responsiveness**: Since tasks perform non-blocking I/O, this
    means the GUI thread is always free to accept user inputs. This results in better
    responsiveness.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The simultaneous and parallelized occurrence of tasks**: Since tasks run
    in parallel, we can simultaneously run different programming logic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Better use of cache storage by utilizing resources and better use of CPU resources.
    Tasks can run on different cores, thereby ensuring maximizing throughput.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Parallel programming also has the following disadvantages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Complex debugging and testing processes**: It''s not easy to debug threads
    without good multithreading tool support as different threads runs in parallel.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Context switching overheads**: Every thread works on a slice of time that''s
    been allocated to it. Once the time slice expires, context switching happens,
    which also wastes resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**High chance of deadlock occurrence**: If multiple threads work on a shared
    resource, we need to apply locks to achieve thread-safety. This can lead to deadlocks
    if multiple threads are simultaneously locking and waiting for shared resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Difficult to program**: With code branching, parallel programs can be difficult
    to write compared to synchronous versions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unpredictable results**: Since parallel programming relies on CPU cores,
    we can get different results on different configuration machines.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We should always understand that parallel programming is a relative concept
    and that something that worked for others may or may not work for you. You are
    advised to implement this approach and validate it yourself.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed the scenarios, benefits, and pitfalls of parallel
    programming. Computer systems have evolved over the last few decades from single-core
    processors to multi-core processors. The hardware in chips has become HT-enabled,
    thereby increasing the performance of modern systems.
  prefs: []
  type: TYPE_NORMAL
- en: Before embarking on your journey in parallel programming, it's a good idea to
    understand the basic concepts related to the OS, such as processes, tasks, and
    the difference between multithreading and multitasking.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will focus our discussion entirely on the TPL and its
    associated implementations. In the real world, however, there is a lot of legacy
    code that still relies on older constructs, so knowledge of these will be handy.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multithreading is a superset of parallel programming.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'False'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How many cores will there be in a single-processor dual-core machine with hyper-threading
    enabled?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '2'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '4'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '8'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When an application exits, all the foreground threads are killed as well. There
    is no separate logic required to close foreground threads on an application's
    exit.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'False'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which exception is thrown when a thread has tried to access controls it has
    not owned/created?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`ObjectDisposedException`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`InvalidOperationException`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`CrossThreadException`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of these provides cancellation support and progress reporting?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Thread`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`BackgroundWorker`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`ThreadPool`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
