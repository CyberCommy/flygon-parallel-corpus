- en: Detecting Dark Matter - The Higgs-Boson Particle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: True or false? Positive or negative? Pass or no pass? User clicks on the ad
    versus not clicking the ad? If you've ever asked/encountered these questions before
    then you are already familiar with the concept of *binary classification.*
  prefs: []
  type: TYPE_NORMAL
- en: 'At it''s core, binary classification - also referred to as *binomial classification*
    - attempts to categorize a set of elements into two distinct groups using a classification
    rule, which in our case, can be a machine learning algorithm. This chapter shows
    how to deal with it in the context of Spark and big data. We are going to explain
    and demonstrate:'
  prefs: []
  type: TYPE_NORMAL
- en: Spark MLlib models for binary classification including decision trees, random
    forest, and the gradient boosted machine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Binary classification support in H2O
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Searching for the best model in a hyperspace of parameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluation metrics for binomial models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Type I versus type II error
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Binary classifiers have intuitive interpretation since they are trying to separate
    data points into two groups. This sounds simple, but we need to have some notion
    of measuring the quality of this separation. Furthermore, one important characteristic
    of a binary classification problem is that, often, the proportion of one group
    of labels versus the other can be disproportionate. That means the dataset may
    be imbalanced with respect to one label which necessitates careful interpretation
    by the data scientist.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose, for example, we are trying to detect the presence of a particular rare
    disease in a population of 15 million people and we discover that - using a large
    subset of the population - only 10,000 or 10 million individuals actually carry
    the disease. Without taking this huge disproportion into consideration, the most
    naive algorithm would guess "no presence of disease" on the remaining five million
    people simply because 0.1% of the subset carried the disease. Suppose that of
    the remaining five million people, the same proportion, 0.1%, carried the disease,
    then these 5,000 people would not be correctly diagnosed because the naive algorithm
    would simply guess no one carries the disease. Is this acceptable? In this situation,
    the *cost* of the errors posed by binary classification is an important factor
    to consider, which is relative to the question being asked.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given that we are only dealing with two outcomes for this type of problem,
    we can create a 2-D representation of the different types of errors that are possible.
    Keeping our preceding example of the people carrying / not carrying the disease,
    we can think about the outcome of our classification rule as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00014.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1 - Relation between predicted and actual values
  prefs: []
  type: TYPE_NORMAL
- en: 'From the preceding table, the green area represents where we are *correctly *predicting
    the presence / absence of disease in the individual whereas the white areas represent
    where our prediction was incorrect. These false predictions fall into two categories
    known as **Type I** and **Type II** errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Type I error**: When we reject the null hypothesis (that is, a person not
    carrying the disease) when in fact, it is true in actuality'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Type II error**: Where we predict the presence of the disease when the individual
    does *not* carry the disease'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clearly, both errors are not good but often, in practice, some errors are more
    acceptable than others.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the situation where our model makes significantly more Type II errors
    than Type I errors; in this case, our model would be predicting more people are
    carrying the disease than actually are - a conservative approach may be *more
    acceptable* than a Type II error where we are failing to identify the presence
    of the disease. Determining the *cost* of each type of error is a function of
    the question being asked and is something the data scientist must consider. We
    will revisit this topic of errors and some other metrics of model quality after
    we build our first binary classification model which tries to predict the presence
    / non-presence of the Higgs-Boson particle.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the Higgs-Boson particle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'On July 4, 2012, scientists from Europe''s CERN lab in Geneva, Switzerland,
    presented strong evidence of a particle they believe is the Higgs-Boson, sometimes
    referred to as the *God-particle*. Why is this discovery so meaningful and important?
    As popular physicist and author Michio Kaku wrote:'
  prefs: []
  type: TYPE_NORMAL
- en: '"In quantum physics, it was a Higgs-like particle that sparked the cosmic explosion
    (that is, the big bang). In other words, everything we see around us, including
    galaxies, stars, planets, and us, owes its existence to the Higgs-Boson."'
  prefs: []
  type: TYPE_NORMAL
- en: In layman's terms, the Higgs-Boson is the particle that gives mass to matter
    and offers a possible explanation for how the Earth was originally created and
    hence, its huge popularity in mainstream media channels.
  prefs: []
  type: TYPE_NORMAL
- en: The LHC and data creation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To test for the presence of the Higgs-Boson, scientists constructed the largest
    human-made machine called the **Large Hadron Collider** (**LHC**) near Geneva,
    close to the Franco-Swiss border. The LHC is a ring-shaped tunnel that runs 27
    kilometers long (equivalent to the Circle Line from London's Underground) and
    lies 100 meters underground.
  prefs: []
  type: TYPE_NORMAL
- en: Through this tunnel, subatomic particles are fired in opposite directions with
    the help of the aforementioned magnets with speeds approaching the speed of light.
    Once a critical speed is reached, the particles are put on a collision course
    where detectors monitor and record the collisions. There are literally millions
    upon millions of collisions and sub-collisions! - and the resultant *particle
    debris* give in hope of detecting the Higgs-Boson.
  prefs: []
  type: TYPE_NORMAL
- en: The theory behind the Higgs-Boson
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For quite some time, physicists have known that some fundamental particles have
    mass which contradicts the mathematics underlying the Standard Model which states
    these particles should be mass-less. In the 1960s, Peter Higgs and his colleagues
    challenged this mass conundrum by studying the universe after the big bang. At
    the time, it was largely believed that particles should be thought of as ripples
    in a quantum jelly as opposed to tiny billiard balls bouncing off one another.
    Higgs believed that during this early period, all particle jellies were runny
    with a consistency like water; but as the universe began to *cool down*, one particle
    jelly, known first as the *Higgs field*, began to condense and become thick. Consequently,
    other particle jellies, when interacting with the Higgs field, are drawn towards
    it thanks to inertia; and, according to Sir Isaac Newton, any particle with inertia
    should contain mass. This mechanism offers an explanation to how particles that
    makeup the Standard Model - born massless at first - may have acquired mass. It
    follows then that the amount of mass acquired by each particle is proportional
    to the strength with which it feels the effects of the Higgs field.
  prefs: []
  type: TYPE_NORMAL
- en: The article [https://plus.maths.org/content/particle-hunting-lhc-higgs-boson](https://plus.maths.org/content/particle-hunting-lhc-higgs-boson)
    is a great source of information for curious readers.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring for the Higgs-Boson
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Testing this theory goes back to the original notion of particle jelly ripples
    and in particular, the Higgs jelly which a) can ripple and b) would resemble a
    particle in an experiment: the infamous Higgs-Boson. So how do scientists detect
    this ripple using the LHC?'
  prefs: []
  type: TYPE_NORMAL
- en: To monitor the collisions and the resulting post-collisions, scientists set
    up detectors which act like three-dimensional digital cameras which measure the
    tracks of particles coming from the collisions. Properties from these tracks -
    that is, how much they curve in magnetic fields - are used to infer various properties
    of the particles that generated them; one extremely common property that can be
    measured is an electric charge where it is believed the Higgs exists somewhere
    between 120 and 125 giga-electronvolts. Meaning, if the detectors find an event
    with an electric charge that exists between these two ranges, this would indicate
    a new particle which may be indicative of the Higgs-Boson.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Upon releasing their findings to the scientific community in 2012, researchers
    later made the data public from the LHC experiments where they observed - and
    identified - a signal which is indicative of the Higgs-Boson particle. However,
    amidst the positive findings is a lot of background noise which causes an imbalance
    within the dataset. Our task as data scientist is to build a machine learning
    model which can accurately identify the Higgs-Boson particle from background noise.
    Already, you should be thinking about how this question is phrased which would
    be indicative of binary classification (that is, is this example the Higgs-Boson
    versus background noise?).
  prefs: []
  type: TYPE_NORMAL
- en: You can download the dataset from [https://archive.ics.uci.edu/ml/datasets/HIGGS](https://archive.ics.uci.edu/ml/datasets/HIGGS)
    or use the script `getdata.sh` located in the  `bin` folder of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'This file is 2.6 gigs (uncompressed) and contains 11 million examples that
    have been labeled as 0 - background noise and 1 - Higgs-Boson. First, you will
    need to uncompress this file and then we will begin loading the data into Spark
    for processing and analysis. There are 29 total fields which make up the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Field 1: Class label (1 = signal for Higgs-Boson, 2 = background noise)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fields 2-22: 21 "low-level" features that come from the collision detectors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fields 23-29: seven "high-level" features that have been hand-derived by particle
    physicists to help classify the particle into its appropriate class (Higgs or
    background noise)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Later in this chapter, we cover a **Deep Neural Network** (**DNN**) example
    that will attempt to *learn* these hand-derived features through layers of non-linear
    transformations to the input data.
  prefs: []
  type: TYPE_NORMAL
- en: Note that for the purposes of this chapter, we will work with a subset of the
    data, the first 100,000 rows, but all the code we show would also work on the
    original dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Spark start and data load
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now it''s time to fire up a Spark cluster which will give us all the functionality
    of Spark while simultaneously allowing us to use H2O algorithms and visualize
    our data. As always, we must download Spark 2.1 distribution from [http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html)
    and declare the execution environment beforehand. For example, if you download
    `spark-2.1.1-bin-hadoop2.6.tgz` from the Spark download page, you can prepare
    the environment in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'When the environment is ready, we can start the interactive Spark shell with
    Sparkling Water packages and this book package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: H2O.ai is constantly keeping up with the latest releases of the Spark project
    to match the version of Sparkling Water. The book is using Spark 2.1.1 distribution
    and Sparkling Water 2.1.12\. You can find the latest version of Sparkling Water
    for your version of Spark at [http://h2o.ai/download/](http://h2o.ai/download/)
  prefs: []
  type: TYPE_NORMAL
- en: This case is using the provided Spark shell which downloads and uses Spark packages
    of Sparkling Water version 2.1.12\. The packages are identified by Maven coordinates
    - in this case `ai.h2o` represents organization ID, `sparkling-water-core` identifies
    Sparkling Water implementation (for Scala 2.11, since Scala versions are not binary
    compatible), and, finally, `2.1.12` is a version of the package. Furthermore,
    we are using this book -specific package which provides handful utilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'The list of all published Sparkling Water versions is also available on Maven
    central: [http://search.maven.org](http://search.maven.org)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The command starts Spark in a local mode - that is, the Spark cluster has a
    single node running on your computer. Assuming you did all this successfully,
    you should see the standard Spark shell output like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00015.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2 - Notice how the shell starts up showing you the version of Spark you
    are using.
  prefs: []
  type: TYPE_NORMAL
- en: The provided book source code provides for each chapter the command starting
    the Spark environment; for this chapter, you can find it in the `chapter2/bin`
    folder.
  prefs: []
  type: TYPE_NORMAL
- en: The Spark shell is a Scala - based console application that accepts Scala code
    and executes it in an interactive way. The next step is to prepare the computation
    environment by importing packages which we are going to use during our example.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s first ingest the `.csv` file that you should have downloaded and do
    a quick count to see how much data is in our subset. Here, please notice, that
    the code expects the data folder "data" relative to the current process working
    directory or location specified:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00016.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: You can observe that execution of the command `sc.textFile(...)` took no time
    and returned instantly, while executing `rawData.count` took the majority amount
    of time. This exactly demonstrates the difference between Spark **transformations**
    and **actions**. By design, Spark adopts **lazy evaluation** - it means that if
    a transformation is invoked, Spark just records it directly into its so-called
    **execution graph/plan**. That perfectly fits into the big data world, since users
    can pile up transformations without waiting. On the other hand, an action evaluates
    the execution graph - Spark instantiates each recorded transformation and applies
    it onto the output of previous transformations. This concept also helps Spark
    to analyze and optimize an execution graph before its execution - for example,
    Spark can reorganize the order of transformations or can decide to run transformations
    in parallel if they are independent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Right now, we defined a transformation which loads data into the Spark data
    structure `RDD[String]` which contains all the lines of input data file. So, let''s
    look at the first two rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00017.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The first two lines contain raw data as loaded from the file. You can see that
    a row is composed of a response column having the value 0,1 (the first value of
    the row) and other columns having real values. However, the lines are still represented
    as strings and require parsing and transformation into regular rows. Hence, based
    on the knowledge of the input data format, we can define a simple parser which
    splits an input line into numbers based on a comma:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can extract a response column (the first column in the dataset) and
    the rest of data representing the input features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'After this transformation, we have two RDDs:'
  prefs: []
  type: TYPE_NORMAL
- en: One representing the response column
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another which contains dense vectors of numbers holding individual input features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, let''s look in more detail at the input features and perform some very
    rudimentary data analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We converted this vector into a distributed *RowMatrix*. This gives us the ability
    to perform simple summary statistics (for example, compute mean, variance, and
    so on:)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00018.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Take a look at following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00019.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the next step, let''s explore columns in more details. We can get directly
    the number of non-zeros in each column to figure out if the data is dense or sparse.
    Dense data contains mostly non-zeros, sparse data the opposite. The ratio between
    the number of non-zeros in the data and the number of all values represents the sparsity
    of data. The sparsity can drive our selection of the computation method, since
    for sparse data it is more efficient to iterate over non-zeros only:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00020.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'However, the call just gives us the number of non-zeros for all column, which
    is not so interesting. We are more curious about columns that contain some zero
    values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, we augmented the original vector of non-zeros by the index of
    each value and then filter out all the values which are equal to the number of
    rows in the original matrix. And we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00021.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We can see that columns 8, 12, 16, and 20 contain some zero numbers, but still
    not enough to consider the matrix as sparse. To confirm our observation, we can
    compute the overall sparsity of the matrix (remainder: the matrix does not include
    the response column):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00022.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: And the computed number confirms our former observation - the input matrix is
    dense.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now it is time to explore the response column in more detail. As the first
    step, we verify that the response contains only the values `0` and `1` by computing
    the unique values inside the response vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00023.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The next step is to explore the distribution of labels in the response vector.
    We can compute the rate directly via Spark:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00024.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: In this step, we simply transform each row into a tuple representing the row
    value and `1` expressing that the value occurs once in the row. Having RDDs of
    pairs, the Spark method `countByKey` aggregates pairs by a key and gives us a
    summary of the keys count. It shows that the data surprisingly contains slightly
    more cases which do represent Higgs-Boson but we can still consider the response
    nicely balanced.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also explore labels distribution visually with help of the H2O library.
    For that we need to start H2O services represented by `H2OContext`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The code initializes the H2O library and starts H2O services on each node of
    the Spark clusters. It also exposes an interactive environment called Flow, which
    is useful for data exploration and model building. In the console, `h2oContext`
    prints the location of the exposed UI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can directly open the Flow UI address and start exploring the data.
    However, before doing that, we need to publish the Spark data as an H2O frame
    called `response`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'If you import implicit conversions exposed by `H2OContext`, you will be able
    to invoke transformation transparently based on the defined type on the left-side
    of assignment:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Now it is time to open the Flow UI. You can open it directly by accessing the
    URL reported by `H2OContext` or by typing `h2oContext.openFlow` in the Spark shell.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00025.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3 - Interactive Flow UI
  prefs: []
  type: TYPE_NORMAL
- en: 'The Flow UI allows for interactive work with the stored data. Let,s look at
    which data is exposed for the Flow by typing `getFrames` into the highlighted
    cell:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00026.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4 - Get list of available H2O frames
  prefs: []
  type: TYPE_NORMAL
- en: 'By clicking on the response field or typing `getColumnSummary "response", "values"`,
    we can get visual confirmation about the distribution of values in the response
    column and see that the problem is slightly imbalanced:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00027.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5 - Statistical properties of column named "response".
  prefs: []
  type: TYPE_NORMAL
- en: Labeled point vector
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Prior to running any supervised machine learning algorithm using Spark MLlib,
    we must convert our dataset into a labeled point vector which maps features to
    a given label/response; labels are stored as doubles which facilitates their use
    for both classification and regression tasks. For all binary classification problems,
    labels should be stored as either `0` or `1`, which we confirmed from the preceding
    summary statistics holds true for our example.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'An example of a labeled point vector follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, all doubles inside the bracket are the features and
    the single number outside the bracket is our label. Note that we are yet to tell
    Spark that we are performing a classification task and not a regression task which
    will happen later.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, all input features contain only numeric values, but in many
    situations data that contains categorical values or string data. All this non-numeric
    representation needs to be converted into numbers, which we will show later in
    this book.
  prefs: []
  type: TYPE_NORMAL
- en: Data caching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many machine learning algorithms are iterative in nature and thus require multiple
    passes over the data. However, all data stored in Spark RDD are by default transient,
    since RDD just stores the transformation to be executed and not the actual data.
    That means each action would recompute data again and again by executing the transformation
    stored in RDD.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hence, Spark provides a way to persist the data in case we need to iterate
    over it. Spark also publishes several `StorageLevels` to allow storing data with
    various options:'
  prefs: []
  type: TYPE_NORMAL
- en: '`NONE`: No caching at all'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MEMORY_ONLY`: Caches RDD data only in memory'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DISK_ONLY`: Write cached RDD data to a disk and releases from memory'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MEMORY_AND_DISK`: Caches RDD in memory, if it''s not possible to offload data
    to a disk'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OFF_HEAP`: Use external memory storage which is not part of JVM heap'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Furthermore, Spark gives users the ability to cache data in two flavors: *raw*
    (for example, `MEMORY_ONLY`) and *serialized* (for example, `MEMORY_ONLY_SER`).
    The later uses large memory buffers to store serialized content of RDD directly.
    Which one to use is very task and resource dependent. A good rule of thumb is
    if the dataset you are working with is less than 10 gigs then raw caching is preferred
    to serialized caching. However, once you cross over the 10 gigs soft-threshold,
    raw caching imposes a greater memory footprint than serialized caching.'
  prefs: []
  type: TYPE_NORMAL
- en: Spark can be forced to cache by calling the `cache()` method on RDD or directly
    via calling the method persist with the desired persistent target - `persist(StorageLevels.MEMORY_ONLY_SER)`.
    It is useful to know that RDD allows us to set up the storage level only once.
  prefs: []
  type: TYPE_NORMAL
- en: 'The decision on what to cache and how to cache is part of the Spark magic;
    however, the golden rule is to use caching when we need to access RDD data several
    times and choose a destination based on the application preference respecting
    speed and storage. A great blogpost which goes into far more detail than what
    is given here is available at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://sujee.net/2015/01/22/understanding-spark-caching/#.VpU1nJMrLdc](http://sujee.net/2015/01/22/understanding-spark-caching/#.VpU1nJMrLdc)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Cached RDDs can be accessed as well from the H2O Flow UI by evaluating the
    cell with `getRDDs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00028.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Creating a training and testing set
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As with most supervised learning tasks, we will create a split in our dataset
    so that we *teach* a model on one subset and then test its ability to generalize
    on new data against the holdout set. For the purposes of this example, we split
    the data 80/20 but there is no hard rule on what the ratio for a split should
    be - or for that matter - how many splits there should be in the first place:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: By creating our 80/20 split on the dataset, we are taking a random sample of
    8.8 million examples as our training set and the remaining 2.2 million as our
    testing set. We could just as easily take another random 80/20 split and generate
    a new training set with the same number of examples (8.8 million) but with different
    data. Doing this type of *hard* splitting of our original dataset introduces a
    sampling bias, which basically means that our model will learn to fit the training
    data but the training data may not be representative of "reality". Given that
    we are working with 11 million examples already, this bias is not as prominent
    versus if our original dataset is 100 rows, for example. This is often referred
    to as the **holdout method** for model validation.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also use the H2O Flow to split the data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Publish the Higgs data as H2OFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Split data in the Flow UI using the command `splitFrame` (see *Figure 07*).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: And then publish the results back to RDD.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00029.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7 - Splitting Higgs dataset into two H2O frames representing 80 and 20
    percent of data.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast to Spark lazy evaluation, the H2O computation model is eager. That
    means the `splitFrame` invocation processes the data right away and creates two
    new frames, which can be directly accessed.
  prefs: []
  type: TYPE_NORMAL
- en: What about cross-validation?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Often, in the case of smaller datasets, data scientists employ a technique known
    as cross-validation, which is also available to you in Spark. The `CrossValidator`
    class starts by splitting the dataset into N-folds (user declared) - each fold
    is used N-1 times as part of the training set and once for model validation. For
    example, if we declare that we wish to use a **5-fold cross-validation**, the
    `CrossValidator` class will create five pairs (training and testing) of datasets
    using four-fifths  of the dataset to create the training set with the final fifth as
    the test set, as shown in the following figure.
  prefs: []
  type: TYPE_NORMAL
- en: The idea is that we would see the performance of our algorithm across different,
    randomly sampled datasets to account for the inherent sampling bias when we create
    our training/testing split on 80% of the data. An example of a model that does
    not generalize well would be one where the accuracy - as measured by overall error,
    for example - would be all over the map with wildly different error rates, which
    would suggest we need to rethink our model.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00030.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8 - Conceptual schema of 5-fold cross-validation.
  prefs: []
  type: TYPE_NORMAL
- en: There is no set rule on how many folds you should perform, as these questions
    are highly individual with respect to the type of data being used, the number
    of examples, and so on. In some cases, it makes sense to have extreme cross-validation
    where N is equal to the number of data points in the input dataset. In this case,
    the **Test** set contains only one row. This method is called as **Leave-One-Out**
    (**LOO**) validation and is more computationally expensive.
  prefs: []
  type: TYPE_NORMAL
- en: In general, it is recommended that you perform some cross-validation (often
    5-folds, or 10-folds cross-validation is recommended) during the model construction
    to validate the quality of a model - especially when the dataset is small.
  prefs: []
  type: TYPE_NORMAL
- en: Our first model – decision tree
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our first attempt at trying to classify the Higgs-Boson from background noise
    will use a decision tree algorithm. We purposely eschew from explaining the intuition
    behind this algorithm as this has already been well documented with plenty of
    supporting literature for the reader to consume ([http://www.saedsayad.com/decision_tree.htm](http://www.saedsayad.com/decision_tree.htm),
    http://spark.apache.org/docs/latest/mllib-decision-tree.html). Instead, we will
    focus on the hyper-parameters and how to interpret the model''s efficacy with
    respect to certain criteria / error measures. Let''s start with the basic parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we are explicitly telling Spark that we wish to build a decision tree classifier
    that looks to distinguish between two classes. Let''s take a closer look at some
    of the hyper-parameters for our decision tree and see what they mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '`numClasses`: How many classes are we trying to classify? In this example,
    we wish to distinguish between the Higgs-Boson particle and background noise and
    thus there are four classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`categoricalFeaturesInfo`: A specification whereby we declare what features
    are categorical features and should not be treated as numbers (for example, ZIP
    code is a popular example). There are no categorical features in this dataset
    that we need to worry about.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`impurity`: A measure of the homogeneity of the labels at the node. Currently
    in Spark, there are two measures of impurity with respect to classification: Gini
    and Entropy and one impurity for regression: variance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`maxDepth`: A stopping criterion which limits the depth of constructed trees.
    Generally, deeper trees lead to more accurate results but run the risk of overfitting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`maxBins`: Number of bins (think "values") for the tree to consider when making
    splits. Generally, increasing the number of bins allows the tree to consider more
    values but also increases computation time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gini versus Entropy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to determine which one of the impurity measures to use, it's important
    that we cover some foundational knowledge beginning with the concept of **information
    gain**.
  prefs: []
  type: TYPE_NORMAL
- en: 'At it''s core, information gain is as it sounds: the gain in information from
    moving between two states. More accurately, the information gain of a certain
    event is the difference between the amount of information known before and after
    the event takes place. One common measure of this information is looking at the
    **Entropy** which can be defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00031.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Where *p[j]* is the frequency of label *j* at a node.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you are familiar with the concept of information gain and Entropy,
    we can move on to what is meant by the **Gini Index** (there is no correlation
    whatsoever to the Gini coefficient).
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Gini Index**: is a measure of how often a randomly chosen element would
    be misclassified if it were randomly given a label according to the distribution
    of labels at a given node.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00032.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Compared with the equation for Entropy, the Gini Index should be computed slightly
    faster due to the absence of a log computation which may be why it is the **default** option
    for many other machine learning libraries including MLlib.
  prefs: []
  type: TYPE_NORMAL
- en: 'But does this make it a **better** measure for which to make splits for our
    decision tree? It turns out that the choice of impurity measure has little effect
    on performance with respect to single decision tree algorithms. The reason for
    this, according to Tan et. al, in the book *Introduction to Data Mining*, is that:'
  prefs: []
  type: TYPE_NORMAL
- en: '"...This is because impurity measures are quite consistent with each other
    [...]. Indeed, the strategy used to prune the tree has a greater impact on the
    final tree than the choice of impurity measure."'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now it''s time we train our decision tree classifier on the training data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'This should yield a final output which looks like this (note that your results
    will be slightly different due to the random split of the data):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00033.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The output shows that decision tree has depth `5` and `63` nodes organized
    in an hierarchical decision predicate. Let''s go ahead and interpret it looking
    at the first five *decisions*. The way it reads is: *"If feature 25''s value is
    less than or equal to 1.0559 AND is less than or equal to 0.61558 AND feature
    27''s value is less than or equal to 0.87310 AND feature 5''s value is less than
    or equal to 0.89683 AND finally, feature 22''s value is less than or equal to
    0.76688, then the prediction is 1.0 (the Higgs-Boson). BUT, these five conditions
    must be met in order for the prediction to hold."* Notice that if the last condition
    is not held (feature 22''s value is `> 0.76688`) but the previous four held conditions
    remain true, then the prediction changes from 1 to 0, indicating background noise.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s score the model on our test dataset and print the prediction error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00034.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'After some period of time, the model will score all of the test set data and
    then compute an error rate which we defined in the preceding code. Again, your
    error rate will be slightly different than ours but as we show, our simple decision
    tree model has an error rate of ~33%. However, as you know, there are different
    kinds of errors that we can possibly make and so it''s worth exploring what those
    types of error are by constructing a confusion matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code is using advanced the Spark method `combineByKey` which
    allows us to map each (K,V)-pair to a value, which is going to represent the output
    of the group by the key operation. In this case, the (K,V)-pair represents the
    actual value K and prediction V. We map each prediction to a tuple by creating
    a combiner (parameter `createCombiner`) - if the predicted values is `0`, then
    we map to `(1,0)`; otherwise, we map to `(0,1)`. Then we need to define how combiners
    accept a new value and how combiners are merged together. At the end, the method
    produces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The resulting array contains two tuples - one for the actual value `0` and another
    for the actual value `1`. Each tuple contains the number of predictions `0` and
    `1`. Hence, it is easy to extract all necessary to present a nice confusion matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The code extracts all true negatives and positives predictions and also missed
    predictions and outputs of the confusion matrix based on the template shown on
    *Figure 9*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00035.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the preceding code, we are using a powerful Scala feature, which is called
    *string interpolation*: `println(f"...")`. It allows for the easy construction
    of the desired output by combining a string output and actual Scala variables.
    Scala supports different string "interporlators", but the most used are *s* and
    *f*. The *s* interpolator allows for referencing any Scala variable or even code:
    `s"True negative: ${tn}"`. While, the *f* interpolator is type-safe - that means
    the user is required to specify the type of variable to show: `f"True negative:
    ${tn}%5d"` - and references the variable `tn` as decimal type and asks for printing
    on five decimal spaces.'
  prefs: []
  type: TYPE_NORMAL
- en: Going back to our first example in this chapter, we can see that our model is
    making most of the errors in detecting the actual Boson particle. In this case,
    all data points representing detection of Boson are wrongly missclassified as
    non-Boson. However, the overall error rate is pretty low! This is a nice example
    of how the overall error rate can be misleading for a dataset with an imbalanced
    response.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00036.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9 - Confusion matrix schema.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will consider another modeling metric used to judge classification
    models, called the **Area Under the** (Receiver Operating Characteristic) **Curve**
    (**AUC**) (see the following figure for an example). The **Receiver Operating
    Characteristic** (**ROC**) curve is a graphical representation of the **True Positive
    Rate** versus the **False Positive Rate**:'
  prefs: []
  type: TYPE_NORMAL
- en: '**True Positive Rate**: The total number of true positives divided by the sum
    of true positives and false negatives. Expressed differently, it is the ratio
    of the true signals for the Higgs-Boson particle (where the actual label was 1)
    to all the predicted signals for the Higgs-Boson (where our model predicted label
    is 1). The value is shown on the *y*-axis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False Positive Rate**: The total number of false positives divided by the
    sum of false positives and true negatives, which is plotted on the *x*-axis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more metrics, please see the figure for "Metrics derived from confusion
    matrix".
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/00037.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10 - Sample AUC Curve with an AUC value of 0.94
  prefs: []
  type: TYPE_NORMAL
- en: 'It follows that the ROC curve portrays our model''s tradeoff of TPR against
    FPR for a given decision threshold (the decision threshold is the cutoff point
    whereby we say it is label 0 or label 1). Therefore, the area under the ROC curve
    can be thought of as an *average model accuracy* whereby a value of 1.0 would
    represent perfect classification, 0.5 would be a coin-flip (meaning our model
    is doing a 50-50 job at guessing 1 or 0), and anything less than 0.5 would mean
    flipping a coin is more accurate than our model! This is an incredibly useful
    metric which we will see can be used to compare against different hyper-parameter
    tweaks and different models altogether! Let''s go ahead and create a function
    which will allow us to calculate the AUC for our decision tree model which we
    will use to compare against other models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00038.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Spark MLlib models do not share a common definition of interfaces; hence in
    the preceding example, we have to define the type `Predictor` exposing the method
    predict and use Scala structural typing in the definition of the method `computeMetrics`.
    Later in the book, we will show the Spark ML package, which is based on a unified
    pipeline-based API.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00039.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11 - Metrics derived from confusion matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Interested in a great read on this subject? There is no holy bible that is the
    be-all-end-all. The book, *The Elements of Statistical Learning,* by Trevor Hastie
    - renowned statistics professor from Stanford University - is a great source of
    information. This book offers useful nuggets for both beginners and advanced practitioners
    of machine learning and is highly recommended.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to keep in mind that results between runs can be slightly different,
    since the Spark decision tree implementation is using internally the `RandomForest`
    algorithm, which is non-deterministic if a seed for a random generator is not
    specified. The problem is that the MLLib API for Spark `DecisionTree` does not
    allow to pass a seed as a parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Next model – tree ensembles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Algorithms such as **Random Forest** (**RF**) or **Gradient Boosted Machine**
    (**GBM)** (also referred to as Gradient Boosted Trees) are two examples of ensemble
    tree-based models which are currently available in MLlib; you can think of an
    ensemble as an *uber-model* which represents a collection of base models. The
    best way to think about what an ensemble is doing behind the scenes is to consider
    a simple analogy:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Suppose that you are the head coach of a famous soccer club and you have
    heard rumors of an incredible athlete from Brazil and it may be advantageous to
    sign this young athlete to your club before the other teams do; but your schedule
    is incredibly busy and instead, you send 10 of your assistant coaches to assess
    the player. Each one of your assistant coaches grades the player based on his/her
    coaching philosophy - maybe one coach wants to measure how fast the player can
    run 40 yards while another coach thinks height and arm-reach are important. Regardless
    of how each coach defines "athlete potential" you, as head coach, just want to
    know if you should sign the player to a contract now or wait. And so it goes that
    your coaches fly down to Brazil and each coach makes an assessment; upon arrival
    you go up to each of your coaches and ask "should we draft this player now or
    wait?" and, based on a simple rule like majority vote, you can make your decision.
    This an example of what an ensemble is doing behind the scenes with respect to
    a classification task."*'
  prefs: []
  type: TYPE_NORMAL
- en: You can think of each coach as a decision tree and, therefore, you will have
    an ensemble of 10 trees (for 10 coaches). How each coach assesses the player is
    highly specific and this holds true for our trees as well; for each of the 10
    trees created features are selected randomly at each node (hence the random, in
    RF. Forest because there are many trees!). The reason for introducing this randomness
    and other base models is to prevent over-fitting the data. While RF and GBM are
    both tree-based ensembles, the manner in which they go about training is slightly
    different and deserves mention.
  prefs: []
  type: TYPE_NORMAL
- en: GBMs must be trained one tree at a time in order to minimize a `loss` function
    (for example, `log-loss`, squared error, and so on) and usually take longer to
    train than an RF which can generate multiple trees in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: However, when training a GBM, it is recommended to make shallow trees which
    in turn lends itself to faster training.
  prefs: []
  type: TYPE_NORMAL
- en: RFs generally do not overfit the data compared to a GBM; that is, we can add
    more trees to our forest and be less prone to over-fitting than if we added more
    trees to our GBM.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyper-parameter tuning for an RF is much simpler than GBM. In his paper, *Influence
    of Hyperparameters on Random Forest Accuracy*, Bernard et al. show via experimentation
    that the number of K random features to select at each node is a key influencer
    with respect to model accuracy ([https://hal.archives-ouvertes.fr/hal-00436358/document](https://hal.archives-ouvertes.fr/hal-00436358/document))
    Conversely, a GBM has much more hyper-parameters that must be considered, such
    as `loss` function, learning rate, number of iterations, and so on.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As with most *which is better* questions in data science, choosing between an
    RF and a GBM is open-ended and very task and dataset dependent.
  prefs: []
  type: TYPE_NORMAL
- en: Random forest model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, let's try building a random forest using 10 decision trees.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Just like our single decision tree model, we start by declaring the hyper-parameters,
    many of which should be familiar to you already from the decision tree example.
    In the preceding code, we will start by creating a random forest of 10 trees,
    solving a two-class problem. One key feature that is different is the feature
    subset strategy described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The `featureSubsetStrategy` object gives the number of features to use as candidates
    for making splits at each node. Can either be a fraction (for example, 0.5) or
    a function based on the number of features in your dataset. The setting `auto` allows
    the algorithm to choose this number for you but a common soft-rule states to use
    the square-root of the number of features you have.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have trained our model, let''s score it against our hold-out set
    and compute the total error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00040.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'And also compute AUC by using the already defined method `computeMetrics`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00041.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Our RF - where we hardcode the hyper-parameters - performs much better than
    our single decision tree with respect to the overall model error and AUC. In the
    next section, we will introduce the concept of a grid search and how we can try
    varying hyper-parameter values / combinations and measure the impact on the model
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: Again, results can slightly differ between runs. However, in contrast to the
    decision tree, it is possible to make a run deterministic by passing a seed as
    a parameter of the method `RandomForest.trainClassifier`.
  prefs: []
  type: TYPE_NORMAL
- en: Grid search
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As with most algorithms in MLlib and H2O, there are many hyper-parameters to
    choose from which can have a significant effect on the performance of the model.
    Given the endless amount of combinations that are possible, is there an intelligent
    way we can begin looking at what combinations look more promising than others?
    Thankfully, the answer is an emphatic "YES!" and the solution is known as a grid
    search, which is ML-speak for running many models that use different combinations
    of hyper-parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try running a simple grid search using the RF algorithm. In this case,
    the RF model builder is invoked for each combination of parameters from a defined
    hyper-space of parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'What we have just written is a `for`-loop that is going to try a number of
    different combinations with respect to the number of trees, impurity type, depth
    of the trees, and the bins (that is, values to try); And then, for each model
    created based on these hyper-parameter permutations, we are going to score the
    trained model against our hold-out set while computing the AUC metric and the
    overall error rate. In total we get *2*2*2*2=16* models. Again, your models will
    be slightly different than the ones we show here but your output should resemble
    something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00042.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Look at the first entry of our output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We can interpret this as follows: for the combination of 15 decision trees,
    using Entropy as our impurity measure, along with a tree depth of 20 (for each
    tree) and a bin value of 20, our AUC is `0.695`. Note that the results are shown
    in the order you wrote them initially. For our grid search using the RF algorithm,
    we can easily get a combination of hyper-parameters producing the highest AUC:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00043.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Gradient boosting machine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, the best AUC we are able to muster is a 15-decision tree RF that has
    an AUC value of `0.698`. Now, let's go through the same process of running a single
    gradient boosted machine with hardcoded hyper-parameters and then doing a grid
    search over these parameters to see if we can get a higher AUC using this algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall that a GBM is slightly different than an RF due to its iterative nature
    of trying to reduce an overall `loss` function that we declare beforehand. Within
    MLlib there are three different loss functions to choose from as of 1.6.0:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Log-loss**: Use this `loss` function for classification tasks (note that
    GBM only supports binary classification for Spark. If you wish to use a GBM for
    multi-class classification, please use H2O''s implementation, which we will show
    in the next chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Squared-error**: Use this `loss` function for regression tasks it is is the
    current default `loss` function for this type of problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Absolute-error**: Another `loss` function that is available to use for regression
    tasks. Given that this function takes the absolute difference between the predicted
    and actual value, it controls for outliers much better than the squared error.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Given our task of binary classification, we will employ the `log-loss` function
    and begin building a 10 tree GBM model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that we must declare a boosting strategy before we can build our model.
    The reason is that MLlib does not know what type of problem we are tackling beforehand:
    classification or regression? So this strategy is letting Spark know that this
    is a binary classification problem and to use the declared hyper-parameters to
    build our model.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Following are some hyper-parameters to keep in mind when training GBMs:'
  prefs: []
  type: TYPE_NORMAL
- en: '`numIterations`: By definition, a GBM builds trees one at a time in order to
    minimize a `loss` function we declare. This hyper-parameter controls the number
    of trees to build; be careful to not build too many trees as performance at test-time
    may not be ideal.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`loss`: Where you declare which `loss` function to use depends on the question
    being asked and the dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`learningRate`: Optimizes speed of learning. Lower values (< 0.1) means slower
    learning, and improved generalization. However, it also needs a higher number
    of iterations and hence a longer computation time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s score this model against the hold-out set and compute our AUC:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00044.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'As a final step, we will perform a grid-search over a few hyper-parameters
    and, similar to our previous RF grid-search example, output the combinations and
    their respective errors and AUC calculations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'We can print the first 10 lines of the result sorted by AUC:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00045.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'And we can easily get the model producing maximal AUC:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00046.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Last model - H2O deep learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far we used the Spark MLlib for building different models; however, we can
    use also H2O algorithms as well. So let's try them!
  prefs: []
  type: TYPE_NORMAL
- en: At first, we are going to transfer our training and testing datasets over to
    H2O and create a DNN for our binary classification problem. To reiterate, this
    is made possible because Spark and H2O are sharing the same JVM which facilitates
    passing Spark RDDs over to H2O hex frames and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: 'All the models that we have run up to now have been in MLlib but now we are
    going to use H2O to build a DNN using the same training and testing sets that
    we used, which means we need to send this data over to our H2O cloud as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: To verify that we have successfully transferred our training and testing RDDs
    (which we converted to DataFrames), we can execute this command in our Flow notebook
    (all commands are executed with *Shift+Enter*). Notice that we have two H2O frames
    now called `trainingRDD` and `testRDD` which you can see in our H2O notebook by
    running the command `getFrames.`
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00047.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12 - List of available H2O frames is available by typing "getFrames"
    into Flow UI.
  prefs: []
  type: TYPE_NORMAL
- en: We can easily explore frames to see their structure by typing `getFrameSummary
    "trainingHF"` into the Flow cell or just by clicking on the frame name (see *Figure
    13*).
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00048.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13 - Structure of training frame.
  prefs: []
  type: TYPE_NORMAL
- en: The preceding figure shows structure of the training frame - it has 80,491 rows
    and 29 columns; there are numeric columns named *features0*, *features1*, ...
    with real values and the first column label containing integer values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we would like to perform a binary classification, we need to transform
    the "label" column from the integer to categorical type. You can do that easily
    by clicking on the action *Convert to enum* in the Flow UI or in the Spark console
    by executing the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: The code replaces the first vector by a transformed vector and removes the original
    vector from memory. Furthermore, the call `update` propagates changes into the
    shared distributed store, so they become visible by all the nodes in the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Build a 3-layer DNN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'H2O exposes slightly different way of building models; however, it is unified
    among all H2O models. There are three basic building blocks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Model parameters**: Defines inputs and algorithm specific parameters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model builder**: Accepts model parameters and produces a model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model**: Contains model definition but also technical information about model
    building such as score times or error rates for each iteration'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Prior to building our model, we need to construct parameters for the DeepLearning
    algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s walk through the parameters and figure out the model we just initialized:'
  prefs: []
  type: TYPE_NORMAL
- en: '`train` and `valid`: Specifying the training and testing set that we created.
    Note that these RDDs are in fact, H2O frames.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`response_column`: Specifying the label that we use which we declared beforehand
    was the first element (indexes from 0) in each frame.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`epochs`: An extremely important parameter which specifies how many times the
    network should pass over the training data; generally, models that are trained
    with higher `epochs` allow the network to *learn* new features and produce better
    model results. The caveat to this, however, is that these networks that have been
    trained for a long time suffer from overfitting and may not generalize well on
    new data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`activation`: These are the various non-linear functions that will be applied
    to the input data. In H2O there are three primary activations from which to choose
    from:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Rectifier`: Sometimes referred to as **rectified linear unit** (**ReLU**),
    this is a function that has a lower limit of **0** but goes to positive infinity
    in a linear fashion. In terms of biology, these units are shown to be closer to
    actual neuron activations. Currently, this is the default activation function
    in H2O given its results for tasks such as image recognition and speed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/00049.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14 - Rectifier activation function
  prefs: []
  type: TYPE_NORMAL
- en: '`Tanh`: A modified logistic function that is bound between **-1** and **1**
    but goes through the origin at (0,0). Due to its symmetry around **0**, convergence
    is usually faster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/00050.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15 - Tanh activation function and Logistic function - note difference
    between Tanh.
  prefs: []
  type: TYPE_NORMAL
- en: '`Maxout`: A function whereby each neuron picks the largest value coming from
    k separate channels:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**hidden**: Another extremely important hyper-parameter, this is where we specify
    two things:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of layers (which you can create with additional commas). Note that
    in the GUI, the default parameter is a two-layers hidden network with 200 hidden
    neurons per layer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The number of neurons per layer. As with most things regarding machine learning,
    there is no set rule on what this number should be and experimentation is usually
    best. However, there are some additional tuning parameters we will cover in the
    next chapter that will help you think about this, namely: L1 and L2 regularization
    and dropout.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding more layers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The reason for adding more layers to the network comes from our understanding
    of how the visual cortex works for humans. This is a dedicated area in the rear
    part of your brain that is used for recognizing objects/patterns/numbers, and
    so on, and is composed of complex layers of neurons that work to encode visual
    information and classify them accordingly based on prior knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: Not surprisingly, there is no set rule on how many layers a network needs in
    order to produce good results and experimentation is highly recommended!
  prefs: []
  type: TYPE_NORMAL
- en: Building models and inspecting results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So now that you understand a little about the parameters and the model that
    we want to run, it''s time to go ahead and train and inspect our network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The code created the `DeepLearning` model builder and launched it. By default,
    the launch of `trainModel` is asynchronous (that is, it never blocks, but returns
    a job), but it is possible to wait until the end of computation by calling the
    method `get`. You can also explore the job progress in UI or even explore the
    unfinished model by typing `getJobs` into the Flow UI (see *Figure 18*).
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00051.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18 - The command getJobs provides a list of executed jobs with their
    status.
  prefs: []
  type: TYPE_NORMAL
- en: 'The result of the computation is a DeepLearning model - we can directly explore
    the model and its details from the Spark shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also obtain a frame of predictions for the test data directly by calling
    the `score` method of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The table contains three columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '`predict`: Predicted value based on default threshold'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`p0`: Probability of selecting class 0'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`p1`: Probability of selecting class 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can also get model metrics for the test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00052.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The output directly shows the AUC and accuracy (respective error rate). Please
    note that the model is really good at predicting Higgs-Boson; on the other hand,
    it has a high False Positive rate!
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let''s see how we can build a similar model using the GUI, only this
    time, we are going to exclude the physicist-hand-derived features from our model
    and use more neurons for inner layers:'
  prefs: []
  type: TYPE_NORMAL
- en: Select the model to use for TrainingHF.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As you can see, H2O and MLlib share many of the same algorithms with differing
    levels of functionality. Here we are going to select *Deep Learning* and then
    de-select the last eight hand-derived features.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00053.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 19- Selecting model algorithm
  prefs: []
  type: TYPE_NORMAL
- en: Build DNN and exclude hand-derived features.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Here we are manually choosing to ignore features 21-27, which represent physicist-derived
    features in the hope that our network will learn them. Note also the ability to
    perform k-folds cross - validation should you choose to go this route as well.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00054.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 20 - Selecting input features.
  prefs: []
  type: TYPE_NORMAL
- en: Specify the network topology.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As you can see, we are going to build a three-layer DNN using the rectifier
    activation function, where each layer will have 1,024 hidden neurons and this
    will run for 100 `epochs`.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00055.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 21 - Configuring network topology with 3 layers, 1024 neurons per layer.
  prefs: []
  type: TYPE_NORMAL
- en: Explore the model results.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After running this model, which takes some time, we can click on the View button
    to inspect the AUC for both the training and testing set:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00056.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 22 - AUC curve for validation data.
  prefs: []
  type: TYPE_NORMAL
- en: If you click your mouse and drag-and-drop on a section of the AUC curve, you
    can actually zoom in on that particular part of the curve and H2O gives summary
    statistics about the accuracy and precision at the various thresholds of the selected
    area.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00057.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 23 - ROC curve can be easily explored to find optimal threshold.
  prefs: []
  type: TYPE_NORMAL
- en: Also, there is a little button labeled Preview **Plain Old Java Object** (**POJO**),
    which we will explore in the latter chapters, which is how you will deploy your
    model into a production setting.
  prefs: []
  type: TYPE_NORMAL
- en: OK so we've built a few dozen models; it's time now to begin inspecting our
    results and figuring which one gives us the best results given the overall error
    and AUC metric. Interestingly, when we host the many meetups at our office and
    talk with top kagglers, these types of tables showing results are frequently constructed
    and it is a good way to keep track of a) what works and what doesn't and b) look
    back at what you have tried as a form of documentation.
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Error | AUC |'
  prefs: []
  type: TYPE_TB
- en: '| Decision Tree | 0.332 | 0.665 |'
  prefs: []
  type: TYPE_TB
- en: '| Grid-Search: Random Forest | 0.294 | 0.704 |'
  prefs: []
  type: TYPE_TB
- en: '| **Grid-Search: GBM** | **0.287** | **0.712** |'
  prefs: []
  type: TYPE_TB
- en: '| Deep Learning - all features | 0.376 | 0.705 |'
  prefs: []
  type: TYPE_TB
- en: '| Deep Learning - subset feat. | 0.301 | 0.716 |'
  prefs: []
  type: TYPE_TB
- en: So, which one do we go with? In this case, we like the the GBM model since it
    provides the second highest AUC value with the lowest accuracy. But always this
    decision is driven by the modeling goal - in this example, we were strictly motivated
    by accuracy of the model in finding Higgs-Bosons; however, in other cases, selection
    of the right model or models can be influenced by various aspects - for example,
    the time to find and build the best model.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter was all about the binary classification problem: true or false
    and, for our example, the signal indicative of the Higgs-Boson or background noise?
    We have explored four different algorithms: **single decision tree**, **random
    forest**, **gradient boosted machine**, and DNN. For this exact problem, DNNs
    are the current world-beaters as the models can continue to train for longer (that
    is, increase the number of `epochs`) and more layers can be added ([http://papers.nips.cc/paper/5351-searching-for-higgs-boson-decay-modes-with-deep-learning.pdf](http://papers.nips.cc/paper/5351-searching-for-higgs-boson-decay-modes-with-deep-learning.pdf))'
  prefs: []
  type: TYPE_NORMAL
- en: In addition to exploring four algorithms and how to perform a grid-search against
    many hyper-parameters, we also looked at some important model metrics to help
    you better differentiate between models and understand ways to define how *good* is
    good. Our goal for this chapter was to expose you to a variety of different algorithms
    and tweaks within Spark and H2O to solve binary classification problems. In the
    next chapter, we will explore multi-class classification and how to create ensembles
    of models (sometimes called super-learners) to arrive at a good solution for our
    real-world example.
  prefs: []
  type: TYPE_NORMAL
