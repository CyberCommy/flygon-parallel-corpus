- en: Local Development with Kubernetes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you'll learn how to define a cluster, deploying all the interacting
    microservices, and how to work locally for development purposes. We will build
    on the concepts introduced in the previous chapter and we will describe how to
    configure the whole system in Kubernetes in practical terms, deploying multiple
    microservices, and how to make it work as a whole on your own local computer.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we will introduce the other two microservices: the Frontend and the Users
    Backend. They were discussed in [Chapter 1](ddb0a00a-6c5b-4ffe-b403-0f5f9f7a7df2.xhtml), *Making
    the Move – Design, Plan, and Execute*, in the *Strategic planning to break the
    monolith* section. We will see in this chapter how they need to be configured
    to work in Kubernetes. This is in addition to the Thoughts Backend introduced
    in [Chapter 2](8f5b60ee-fa8e-42ff-aa6c-fb27d4bd574a.xhtml), *Creating a REST Service
    with Python;* [Chapter 3](05dd2141-e113-43a2-8bd9-26fb97057913.xhtml), *Build,
    Run, and Test Your Service Using Docker*, and [Chapter 4](872309f3-42ba-493c-8595-af1e610af61a.xhtml),
    *Creating a Pipeline and Workflow*. We will discuss how to configure the three
    of them properly and add some other options to ensure their smooth operation once
    they''re deployed in a production environment.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Implementing multiple services
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring the services
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying the full system locally
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of the chapter, you will have a working local Kubernetes system with
    the three microservices deployed and working as a whole. You will understand how
    the different elements work and how to configure and tweak them.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this chapter, you need to have a local Kubernetes instance running as described
    in the previous chapter. Remember to have the Ingress controller installed.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: You can check the full code that we are going to use in the GitHub repository
    ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter06](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter06)).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Implementing multiple services
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the GitHub repo, you can find the three microservices that we will be using
    in this chapter. They are based on the monolith introduced in [Chapter 1](ddb0a00a-6c5b-4ffe-b403-0f5f9f7a7df2.xhtml),
    *Making the Move – Design, Plan, and Execute*, and are split into three elements:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '**Thoughts Backend**: As described in the previous chapter, this handles the
    storage of thoughts and the search for them.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Users Backend**: This stores the users and allows them to log in. Based on
    the description of the authentication method, this creates a token that can be
    used to authenticate against other systems.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Frontend**: This comes from the monolith, but instead of accessing a database directly,
    it makes requests to the User and Thoughts Backends to replicate the functionality.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that the static files are still being served by the Frontend, even though
    we described the final stage of the cluster serving them independently. This is
    done for simplicity and to avoid having an extra service.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: The aforementioned services are Dockerized in similar ways to how the Thoughts
    Backend was in [Chapter 3](05dd2141-e113-43a2-8bd9-26fb97057913.xhtml), *Build,
    Run, and Test Your Service Using Docker*. Let's look at some of the details for
    the other microservices.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Describing the Users Backend microservice
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The code for the Users Backend can be found at [https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter06/users_backend](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter06/users_backend).
    The structure is very similar to the Thoughts Backend, a Flask-RESTPlus application
    that communicates to a PostgreSQL database.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: 'It has two endpoints, as seen in its Swagger interface:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b3fae995-d64e-42dd-90ab-e11643f75592.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
- en: 'The endpoints are as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Endpoint** | **Input** | **Returns** |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
- en: '| `POST` | `/api/login` | `{username: <username>, password: <password>}` |
    `{Authorized: <token header>}` |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
- en: '| `POST` | `/admin/users` | `{username: <username>, password: <password>}`
    | `<new_user>` |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
- en: The `admin` endpoint allows you to create new users, and the login API returns
    a valid header that can be used for the Thoughts Backend.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: 'The users are stored in the database with the following schema:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '| **Field** | **Format** | **Comments** |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
- en: '| `id` | `Integer` | Primary key |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
- en: '| `username` | `String (50)` | Username |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
- en: '| `password` | `String(50)` | Password stored in plain text, which is a bad
    idea, but simplifies the example |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
- en: '| `creation` | `Datetime` | The time of the creation of the user |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
- en: 'This schema, in SQLAlchemy model definition, is described using the following
    code:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note that the creation date gets stored automatically. Also, note that we store
    the password in plain text. This is a *terrible, terrible idea in a production
    service*. You can check out an article called *How to store a password in the
    database?* ([https://www.geeksforgeeks.org/store-password-database/](https://www.geeksforgeeks.org/store-password-database/))
    to get general ideas for encrypting passwords with a salt seed. You can use a
    package such as `pyscrypt` ([https://github.com/ricmoo/pyscrypt](https://github.com/ricmoo/pyscrypt))
    to implement this kind of structure in Python.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: The users *bruce* and *stephen *are added to the `db` example as a way of having
    example data.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Describing the Frontend microservice
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Frontend code is available in the GitHub repo. It is based on the Django
    monolith ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter01/Monolith](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter01/Monolith))
    introduced in [Chapter 1](ddb0a00a-6c5b-4ffe-b403-0f5f9f7a7df2.xhtml), *Making
    the Move – Design, Plan, and Execute*.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: The main difference from the monolith is that the database is not accessed.
    Therefore, there are no uses for the Django ORM. They are replaced with HTTP requests
    to the other backends. To make the requests, we use the fantastic `requests` library.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the `search.py` file gets converted into the following code, which
    delegates the search toward the Thoughts Backend microservice. Note how the request
    by the customer gets transformed into an internal API call to the `GET /api/thoughts`
    endpoint. The result is decoded in JSON and rendered in the template:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The monolith equivalent code can be compared in the `Chapter01` subdirectory
    of the repo ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter01/Monolith/mythoughts/thoughts/search.py](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter01/Monolith/mythoughts/thoughts/search.py)).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Note how we make a `get` request through the `requests` library to the defined
    search endpoint, which results in the `json` format being returned and rendered.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: The `THOUGTHS_BACKEND` root URL comes from the settings, in usual Django fashion.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: This example is a simple one because there's no authentication involved. The
    parameters are captured from the user interface, then routed toward the backend.
    The request gets properly formatted both toward the backend and once the result
    is obtained, and then rendered. This is the core of two microservices working
    together.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: 'A more interesting case is the `list_thought` ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter06/frontend/mythoughts/thoughts/thoughts.py#L18](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter06/frontend/mythoughts/thoughts/thoughts.py#L18))
    view. The following code lists the thoughts for the logged in user:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here, before doing anything, we need to check whether a user is logged in. This
    is done in the `get_username_from_session` call, which returns the `username`
    or `None`, if they're not logged in. If they're not logged in, the return gets
    redirected to the login screen.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: As this endpoint requires authentication, we need to add the session from the
    user in an `Authorization` header to our request. The session of the user can
    be obtained from the `request.COOKIES` dictionary.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: As a safeguard, we need to check whether the returning status code from the
    backend is correct. For this call, any resulting status code that's not a 200
    (HTTP call correct) will produce a redirection to the login page.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: For simplicity and clarity, our example services are not handling different
    error cases. In a production system, there should be a differentiation between
    errors where the issue is that either the user is not logged in or there's another
    kind of user error (a 400 error), or the backend service is not available (a 500
    status code).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Error handling, when done properly, is difficult, but worth doing well, especially
    if the error helps users to understand what happened.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: 'The `get_username_from_session` function encapsulates a call to `validate_token_header`,
    the same one as introduced in the previous chapter:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `settings` file contains the public key required to decode the token.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, for simplicity, we copied the key directly into the `settings`
    file. This is not the way to go for a production environment. Any secret should
    be obtained through the Kubernetes environment configuration. We will see how
    to do this in the following chapters.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: The environment file needs to specify where both the base URLs for the Users
    Backend and the Thoughts Backend are, to be able to connect to them.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Connecting the services
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It's possible to test the services working in unison only with `docker-compose`.
    Check that the `docker-compose.yaml` files in both the Users Backend and the Thoughts
    Backend expose different ports externally.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: 'The Thoughts Backend exposes port `8000` and the Users Backend exposes port
    `8001`. This allows the Frontend to connect to them (and expose port `8002`).
    This diagram shows how this system works:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1a463150-339d-4bf2-8a94-374bb6a34ec3.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
- en: You can see how the three services are isolated, as `docker-compose` will create
    its own network for them to connect. Both backends have their own container, which
    acts as the database.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: The Frontend service needs to connect to the others. The URL of the services
    should be added to the `environment.env` file and should indicate the service
    with the IP of the computer.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: An internal IP such as localhost or `127.0.0.1` does not work, as it gets interpreted
    **inside the container. **You can obtain the local IP by running `ifconfig`.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if your local IP is `10.0.10.3`, the `environment.env` file should
    contain the following:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: If you access the Frontend service in your browser, it should connect to the
    other services.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: A possibility could be to generate a bigger `docker-compose` file that includes
    everything. This could make sense if all the microservices are in the same Git
    repo, a technique known as **monorepo** ([https://gomonorepo.org/](https://gomonorepo.org/)).
    Possible problems include keeping both the internal `docker-compose` to work with
    a single system and the general one in sync so that the automated tests should
    detect any problems.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: This structure is a bit cumbersome, so we can transform it into a proper Kubernetes
    cluster, aiming at local development.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the services
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To configure the apps in Kubernetes, we need to define the following Kubernetes
    objects per app:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '**Deployment**: The deployment will control the creation of pods, so they will
    always be available. It will also create them based on the image and will add
    configuration, where needed. The pod runs the app.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service**: The service will make the RESTful requests available inside the
    cluster, with a short name. This routes the requests to any available pod.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ingress**: This makes the service available outside of the cluster, so we
    can access the app from outside the cluster.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we will look at the Thoughts Backend configuration in detail
    as an example. Later, we will see how the different parts connect. We created
    a Kubernetes sub-directory ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter06/thoughts_backend/kubernetes](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter06/thoughts_backend/kubernetes))
    to store the `.yaml` files with each of the definitions.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the `example` namespace, so be sure that it''s created:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Let's start with the first Kubernetes object.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the deployment
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the Thoughts Backend deployment, we will deploy a pod with two containers,
    one with the database, and another with the application. This configuration makes
    it easy to work locally but keep in mind that recreating the pod will restart
    both containers.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'The file for configuration is fully available here ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter06/thoughts_backend/kubernetes/deployment.yaml](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter06/thoughts_backend/kubernetes/deployment.yaml)),
    so let''s take a look at its different parts. The first element describes what
    it is and its name, as well as the namespace it lives at:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Then, we generate `spec`. It contains how many pods we should keep and the
    template for each pod. `selector` defines what labels are monitored, and it should
    match the `labels` in the template:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The `template` section defines the containers in its own `spec` section:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`thoughts-backend-db` is simpler. The only required element is to define the
    name of the container and the image. We need to define the pulling policy as `Never`
    to indicate that the image is available in the local Docker repo, and that it''s
    not necessary to pull it from a remote registry:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`thoughts-backend-service` needs to define the exposed port for the service
    as well as the environment variables. The variable values are the ones that we
    used previously when creating the database, except for `POSTGRES_HOST`, where
    we have the advantage that all containers in the same pod share the same IP:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To get the deployment in Kubernetes, you need to apply the file, as shown here:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The deployment is now created in the cluster:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This creates pods automatically. If the pod is deleted or crashes, the deployment
    will restart it with a different name:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The deployment is tracking the latest image, but it won''t create a new pod
    unless it''s deleted. To make changes, be sure to delete the pod manually, after
    which it will be recreated:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The application is still not discoverable inside the cluster, other than referring
    to it by its specific pod name, which can change, so we need to create a service
    for that.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the service
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We create a Kubernetes service to create a name for the application exposed
    by the created deployment. The service can be checked in the `service.yaml` file.
    Let''s take a look:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The initial data is similar to the deployment. The `spec` section defines the
    open ports, routing access to the service on port `80` to port `8000` in containers
    in `thoughts-backend`, the name of the deployment. The `selector` part routes
    all the requests to any pod that matches.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: 'The type is `NodePort` to allow access from outside the cluster. This allows
    us to check that it is working correctly, once we find the externally exposed
    IP:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We can access the Thoughts Backend by accessing localhost with the described
    pod. In this case, `http://127.0.0.1:31600`:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4281d880-2b90-4375-b757-16fca37b7c00.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
- en: The service gives us an internal name, but if we want to have control over how
    it is exposed externally, we need to configure an Ingress.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the Ingress
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Finally, we describe the Ingress in `ingress.yaml` ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter06/thoughts_backend/kubernetes/ingress.yaml](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter06/thoughts_backend/kubernetes/ingress.yaml)).
    The file is copied here. Note how we set up the metadata to live in the proper
    namespace:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This Ingress will make the service be exposed to the nodes on port `80`. As
    multiple services can be exposed on the same nodes, they get distinguished by
    their hostname, in this case, `thoughts.example.local`.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: The Ingress controller we are using only allows exposing ports `80` (HTTP) and
    `443` (HTTPS) in `servicePort`.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: 'After applying the service, we can try to access the page, but, unless we address
    the calls toward the proper host, we will get a 404 error:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We need to be able to point any request to `thoughts.example.local` to our
    localhost. In Linux and macOS, the easiest way is to change your `/etc/hosts`
    file to include the following line:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Then, we can use a browser to check our application, this time in `http://thoughts.example.local`
    (and port `80`):'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ce2705b4-0075-4086-9b08-df80806271e5.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
- en: Defining different host entries allows us to access all the services externally,
    to be able to tweak them and debug problems. We will define the rest of the Ingresses
    in the same way.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: If you get a `Connection refused` error and the word `localhost` does not appear
    when running `kubectl get ingress -n example`, your Kubernetes installation does
    not have the Ingress controller installed. Double-check the installation documentation
    at [https://github.com/kubernetes/ingress-nginx/blob/master/docs/deploy/index.md.](https://github.com/kubernetes/ingress-nginx/blob/master/docs/deploy/index.md)
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: So now we have a working application deployed in Kubernetes locally!
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the full system locally
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Each of our microservices works on its own, but to have the whole system working,
    we need to deploy the three of them (Thoughts Backend, Users Backend, and Frontend)
    and connect them to each other. The Frontend, in particular, requires the other
    two microservices to be up and running. With Kubernetes, we can deploy it locally.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: To deploy the full system, we need to deploy the Users Backend first, and then
    the Frontend. We will describe each of these systems, relating them to the already
    deployed Thoughts Backend, which we saw how to deploy before.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the Users Backend
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Users Backend files are very similar to the Thoughts Backend. You can check
    them in the GitHub repo ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter06/users_backend/kubernetes](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter06/users_backend/kubernetes)).
    Be sure that the environment settings in the `deployment.yaml` values are correct:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Remember to be sure to include the new hostname in `/etc/hosts`:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: You can access the Users Backend in `http://users.example.local`.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Adding the Frontend
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Frontend service and Ingress are very similar to the previous ones. The
    deployment is slightly different. Let''s take a look at the configuration, in
    three groups:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we add the metadata about the `namespace`, `name`, and the `kind` (deployment)
    as shown in the following code:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Then, we define the `spec` with the template and the number of `replicas`.
    Only one replica is fine for a local system:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Finally, we `spec` out the template with the container definition:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The main difference from the previously defined Thoughts Backend deployment
    is that there's a single container and that the environment on it is simpler.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: We define the backend URLs environments as the service endpoints. These endpoints
    are available inside the cluster, so they'll be directed to the proper containers.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Remember that the `*.example.local` addresses are only available in your computer,
    as they only live in `/etc/hosts`. Inside the container, they won't be available.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: This is suitable for local development, but an alternative is to have a DNS
    domain that can be redirected to `127.0.0.1` or similar.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 'We should add a new domain name in the `/etc/hosts` file:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Django requires you to set up the `ALLOWED_HOSTS` setting's value, to allow
    it to accept the hostname, as, by default, it only allows connections from localhost.
    See the Django documentation ([https://docs.djangoproject.com/en/2.2/ref/settings/#allowed-hosts](https://docs.djangoproject.com/en/2.2/ref/settings/#allowed-hosts))
    for more information. To simplify things, we can allow any host using `'*'`. Check
    out the code on GitHub ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter06/frontend/mythoughts/mythoughts/settings.py#L28](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter06/frontend/mythoughts/mythoughts/settings.py#L28)).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: In production, it's good practice to limit the hosts to the **Fully Qualified
    Domain Name** (**FQDN**), the full DNS name of a host, but the Kubernetes Ingress
    will check the host header and reject it if it's not correct.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: 'The Frontend application gets deployed as we''ve done before:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Then we can access the full system, login, search, and so on.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: Remember that there are two users, `bruce` and `stephen`. Their passwords are
    the same as their usernames. You don't need to be logged in to search.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: 'In your browser, go to `http://frontend.example.local/`:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b45ab968-9029-4a8b-9c2a-7571d2057c07.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
- en: Congratulations! You have a working Kubernetes system, including different deployed
    microservices. You can access each of the microservices independently to debug
    it or to carry out actions such as creating a new user, and so on.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: If you need to deploy a new version, build the proper containers using the `docker-compose`
    build and delete the pod to force the recreation of it.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we saw how to deploy our microservices in a Kubernetes local
    cluster to allow local development and testing. Having the whole system deployed
    on your local computer greatly simplifies developing new features or debugging
    the behavior of the system. The production environment will be very similar, so
    this also lays the foundation for it.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: We first described the two microservices that were missing. The Users Backend
    handles the authentication for users and Frontend is a modified version of the
    monolith presented in [Chapter 1](ddb0a00a-6c5b-4ffe-b403-0f5f9f7a7df2.xhtml),
    *Making the Move – Design, Plan, and Execute*, which connects to the two backends.
    We showed how to build and run them in a `docker-compose` way.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: After that, we described how to set up a combination of `.yaml` files to configure
    applications properly in Kubernetes. Each microservice has its own deployment
    to define the available pods, a service to define a stable access point, and an
    Ingress to allow external access. We described them in detail, and then applied
    them to all of the microservices.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will see how to move from local deployment and deploy
    a Kubernetes cluster ready for production.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What are the three microservices that we are deploying?
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which microservice requires the other two to be available?
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why do we need to use external IPs to connect the microservices while running
    in `docker-compose`?
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the main Kubernetes objects required for each application?
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Are any of the objects not required?
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Can you see any issues if we scale any of the microservices to more than one
    pod?
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why are we using the `/etc/hosts` file?
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can learn more about Kubernetes in the books *Kubernetes for Developers*
    ([https://www.packtpub.com/eu/virtualization-and-cloud/kubernetes-developers](https://www.packtpub.com/eu/virtualization-and-cloud/kubernetes-developers))
    and *Kubernetes Cookbook - Second Edition* ([https://www.packtpub.com/in/virtualization-and-cloud/kubernetes-cookbook-second-edition](https://www.packtpub.com/in/virtualization-and-cloud/kubernetes-cookbook-second-edition)).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在书籍《Kubernetes for Developers》（[https://www.packtpub.com/eu/virtualization-and-cloud/kubernetes-developers](https://www.packtpub.com/eu/virtualization-and-cloud/kubernetes-developers)）和《Kubernetes
    Cookbook - Second Edition》（[https://www.packtpub.com/in/virtualization-and-cloud/kubernetes-cookbook-second-edition](https://www.packtpub.com/in/virtualization-and-cloud/kubernetes-cookbook-second-edition)）中了解更多关于Kubernetes的信息。
