- en: Chapter 12. A Better lastlog with Awk
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have already seen in [Chapter 11](part0069_split_000.html#21PMQ1-747571d9b4814e1dbffcdef2eb0dec8d
    "Chapter 11. Summarizing Logs with Awk"), *Summarizing Logs with Awk*, how we
    can create complex reports from large amounts of data mined from purely text files.
    Similarly, we can create extensive reports using the output from standard command-line
    tools, such as the `lastlog` tool. In itself `lastlog` can report the last login
    time for all users. Often though, we may wish to filter the output from `lastlog`.
    Perhaps you need to exclude the user accounts that have never been used to login
    to the system. It may also be irrelevant to report on `root`, as the account may
    be predominately used for `sudo` only and not used to record regularly for standard
    logins.
  prefs: []
  type: TYPE_NORMAL
- en: 'In working through this chapter, we will work both with `lastlog` and formatting
    of XML data. As this is the last chapter in which we investigate awk, we will
    configure record separators. We have already seen the use of field separators
    in awk but we can change the default record separator from a newline to something
    more specific to our need. More specifically, within this chapter we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Using awk ranges to exclude data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conditions based on the number of fields in a row
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manipulating the awk record separator to report on XML data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using awk ranges to exclude data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this book, we have predominately looked at including data with ranges
    either for `sed` or for `awk`. With both of these tools, we can negate the range
    so that we exclude the specified rows. This suits the need that we have been using
    the output from `lastlog`. This will print all the login data for all the users,
    including accounts that have never been logged in. These accounts that have never
    been logged in might be service accounts or for new users that have not logged
    into the system so far.
  prefs: []
  type: TYPE_NORMAL
- en: The lastlog command
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If we look at the output from `lastlog`, when it is used without any options,
    we can begin to understand the issue. From the command line, we execute the command
    as a standard user. There is no requirement to run it as the root account. The
    command is shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The partial output is shown within the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The lastlog command](img/00118.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: We can see, even from this limited output that we have a cluttered output due
    to the virtual noise being created by the accounts that have not logged in. It
    is possible to alleviate this to some degree using the `lastlog` options but it
    may not entirely resolve the issue. To demonstrate this, we can add an option
    to `lastlog` that only users accounts usually used by standard accounts should
    be included. This may vary on your system but on the sample CentOS 6 host that
    I am using, the first user will be UID 500.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we use the `lastlog -u 500-5000` command, we will only print data for those
    users with a UID within this range. On the simple demonstration system, we have
    just three user accounts for which the output is acceptable. However, we can understand
    that we may still have some clutter die to these accounts that have not yet been
    used. This is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The lastlog command](img/00119.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: In addition to the superfluous data being printed from the **Never logged in**
    accounts, we may only be interested in the **Username** and **Latest** fields.
    This is another reason to support the need to use awk as our data filter. In this
    way, we can provide both horizontal and vertical data filtering, rows, and columns.
  prefs: []
  type: TYPE_NORMAL
- en: Horizontal filtering rows with awk
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To provide this filtering using awk, we will pipe the data from `lastlog` directly
    to `awk`. We will make use of a simple control file initially providing the horizontal
    filtering or reducing the rows that we see. First, the command pipeline will be
    as simple as the following command example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Of course, the complexity is abstracted from the command line and concealed
    within the control file that we use. Initially, the control file is kept simple
    and would read as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The range is setup as we have seen previously and precedes the main code block.
    Using the exclamation mark in front of the parentheses negates or reverses the
    selected range. The double vertical bar acts as a logical `OR`. We do not include
    lines that contain `Never logged in`, nor do we include lines that start with
    `Username`. This removes the header-line that is printed by `lastlog`. Finally,
    we exclude the root account from the display. This initiates the rows that we
    work with and the main code block will print those lines.
  prefs: []
  type: TYPE_NORMAL
- en: Counting matched rows
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We may also want to count the number of rows that are returned by the filter.
    For example, using the internal `NR` variable will show all rows and not just
    the matched rows; for us to be able to report the number of users that have logged
    in, we must use our own variable. The following code will maintain the count within
    the variable that we name `cnt`. We increment this using the C style `++` for
    each iteration of the main code block. We can use the `END` code block to display
    the closing value of this variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see from the following code and output how this appears on my system:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Counting matched rows](img/00120.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: From the display output, we can now see that we show only users that have logged
    in and in this case, it is just the single user. However, we may also decide that
    we want to abstract the data further and display only certain fields from the
    matched rows. This should be a simple task but it is complicated, as the number
    of fields will vary depending on how the login was executed.
  prefs: []
  type: TYPE_NORMAL
- en: Conditions based on the number of fields
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If a user logs onto the server's physical console directly rather than logging
    on through a remote or graphical pseudo-terminal, then the `lastlog` output will
    not display the host field. To demonstrate this, I have logged onto my CentOS
    host directly to the `tty1` console and avoided the GUI. The output from the previous
    awk control file shows that we now have the users **tux** and **bob**; **bob**
    though is lacking the host field as he is connected to a console.
  prefs: []
  type: TYPE_NORMAL
- en: '![Conditions based on the number of fields](img/00121.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Although in itself it's not an issue but it will be if we want to filter the
    fields and the two row's field numbers will vary where a field is omitted from
    some lines. For `lastlog` we will have `9` fields for most connections and only
    `8` fields for those that connect directly to the server console. The desire for
    the application is that we print the username and the date, but not the time of
    the last login. We will also print our own header in the `BEGIN` block. To ensure
    that we use the correct placements we will need to count the fields in each row
    using the `NF` internal variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the `8` fields lines we want to print fields `1`, `4`, `5`, and `8`; for
    the longer lines with additional host information, we will use fields `1`, `5`,
    `6` and `9`. We will also use `printf` so that we can align the column data correctly.
    The control file should be edited, as shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see the command and the output it produces in the following screenshot.
    We can see how we can create a more suitable display based on information that
    we want to focus on:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Conditions based on the number of fields](img/00122.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: If we look at the output, I have chosen to display the date before the month
    so we do not display the fields in the numeric order. This, of course, is a personal
    choice and customizable to suit the way you feel the data should be displayed.
  prefs: []
  type: TYPE_NORMAL
- en: We can use the principles of what we have seen in the `lastlog` control file
    with output from any command and you should practise with the commands that you
    want to filter the data from.
  prefs: []
  type: TYPE_NORMAL
- en: Manipulating the awk record separator to report on XML data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, while we have been working with awk we have limited ourselves to working
    with individual rows, with each new row representing a new record. Although this
    is often what we want, where we work with tagged data, such as XML where an individual
    record may span multiple lines. In this case, we may need to look at setting the
    `RS` or `record` separator internal variable.
  prefs: []
  type: TYPE_NORMAL
- en: Apache Virtual Hosts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In [Chapter 9](part0060_split_000.html#1P71O2-747571d9b4814e1dbffcdef2eb0dec8d
    "Chapter 9. Automating Apache Virtual Hosts"), *Automating Apache Virtual Hosts*
    we worked with **Apache Virtual Hosts**. This uses tagged data that defines the
    start and end of each Virtual Host. Even though we prefer to store each Virtual
    Host in their own file, they can be combined into a single file. Consider the
    following file that stores the possible Virtual Host definitions, this can be
    stored as the `virtualhost.conf` file, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We have the three Virtual Hosts within a single file. Each record is separated
    by an empty line, meaning that we have two new line characters that logically
    separate each entry. We will explain this to awk by setting the `RS` variable
    as follows: `RS="\n\n"`. With this in place, we can then print the required Virtual
    Host record. This will be set in the `BEGIN` code block of the control file.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will also need to dynamically search the command line for the desired host
    configuration. We build this into the control file. The control file should look
    similar to the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The `BEGIN` block sets the variable and then we move onto the range. The range
    is set so that the record (`$0`) matches (`~`) the `search` variable. We must
    set the variable when `awk` is executed. The following command demonstrates the
    command line execution where the control file and configuration file are located
    within our working directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see this more clearly by looking at the command and the output that
    is produced in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Apache Virtual Hosts](img/00123.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: XML catalog
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can extend this further into XML files where we may not want to display
    the complete record, but just certain fields. If we consider the following product
    `catalog`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Logically, each record is delimited as before with the empty line. Each field
    though is a little more detailed and we need to use the delimiter as follows:
    `FS="[><]"`. We define either the opening or closing angle bracket as the field
    delimiter.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To help analyze this, we can print a single record as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Each angle brace is a field separator, which means that we will have some empty
    fields. We could rewrite this line as a CSV file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We just replace each angle bracket with a comma, in this way it is more easily
    read by us. We can see that the content of field `5` is the `top` value.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, we will not edit the XML file, we will leave it in the XML format.
    The conversion here is just to highlight how the field separators can be read.
  prefs: []
  type: TYPE_NORMAL
- en: 'The control file that we use to extract data from the XML file is illustrated
    in the following code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Within the `BEGIN` code block, we set the `FS` and `RS` variables as we have
    discussed. We also set the `OFS` or **Output Field Separator** to a space. In
    this way, when we print the fields we separate the values with a space rather
    than leaving in the angle brackets. The ranch makes use of the same match as we
    used before when looking at the Virtual Hosts.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we need to search for the product drill from within the `catalog` we can
    use the command laid out in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the output in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '![XML catalog](img/00124.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: We have now been able to take a rather messy XML file and create readable reports
    from the catalog. The power of awk is highlighted again and for us, the last time
    within this book. By now, I hope you too can start to make use of this on a regular
    basis.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have had three Chapters where we have used awk. Starting with some basic
    usage statements in [Chapter 10](part0063_split_000.html#1S2JE1-747571d9b4814e1dbffcdef2eb0dec8d
    "Chapter 10. Awk Fundamentals"), *Awk Fundamentals* where we became comfortable.
    Within [Chapter 11](part0069_split_000.html#21PMQ1-747571d9b4814e1dbffcdef2eb0dec8d
    "Chapter 11. Summarizing Logs with Awk"), *Summarizing Logs with Awk* and this
    chapter we started building our bespoke applications.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, in this chapter we saw how we could create reports from the output
    of standard commands, such as `lastlog`. We saw that we could negate ranges and
    additionally make use of the `OR` statement. We then built the application that
    will allow us to query XML data.
  prefs: []
  type: TYPE_NORMAL
- en: For the next two chapters, we will move away from the shell scripts and look
    at scripts using perl and Python so we can compare the scripting languages and
    make appropriate choices.
  prefs: []
  type: TYPE_NORMAL
