- en: Chapter 8. The Itertools Module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Functional programming emphasizes stateless programming. In Python this leads
    us to work with generator expressions, generator functions, and iterables. In
    this chapter, we'll look at the itertools library with numerous functions to help
    us work with iterable collections.
  prefs: []
  type: TYPE_NORMAL
- en: We introduced iterator functions in [Chapter 3](ch03.html "Chapter 3. Functions,
    Iterators, and Generators"), *Functions, Iterators, and Generators*. In this chapter,
    we'll expand on that superficial introduction. We used some related functions
    in [Chapter 5](ch05.html "Chapter 5. Higher-order Functions"), *Higher-order Functions*.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some of the functions merely behave like they are proper, lazy Python iterables.
    It's important to look at the implementation details for each of these functions.
    Some of them create intermediate objects, leading to the potential of consuming
    a large amount of memory. Since implementations might change with Python releases,
    we can't provide function-by-function advice here. If you have performance or
    memory issues, ensure that you check the implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a large number of iterator functions in this module. We''ll examine
    some of the functions in the next chapter. In this chapter, we''ll look at three
    broad groupings of iterator functions. These are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Functions that work with infinite iterators. These can be applied to any iterable
    or an iterator over any collection; they will consume the entire source.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Functions that work with finite iterators. These can either accumulate a source
    multiple times, or they produce a reduction of the source.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The tee iterator function which clones an iterator into several copies that
    can each be used independently. This provides a way to overcome the primary limitation
    of Python iterators: they can be used once only.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We need to emphasize an important limitation of iterables that we've touched
    upon in other places.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Iterables can be used only once.
  prefs: []
  type: TYPE_NORMAL
- en: This can be astonishing because there's no error. Once exhausted, they appear
    to have no elements and will raise the `StopIteration` exception every time they're
    used.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are some other features of iterators that aren''t such profound limitations.
    They are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: There's no `len()` function for an iterable. In almost every other respect,
    they appear to be a container.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Iterables can do `next()` operations, unlike a container.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `for` statement makes the distinction between containers and iterables invisible;
    containers will produce an iterable via the `iter()` function. An iterable simply
    returns itself.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These points will provide some necessary background for this chapter. The idea
    of the `itertools` module is to leverage what iterables can do to create succinct,
    expressive applications without the complex-looking overheads associated with
    the details of managing the iterables.
  prefs: []
  type: TYPE_NORMAL
- en: Working with the infinite iterators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `itertools` module provides a number of functions that we can use to enhance
    or enrich an iterable source of data. We''ll look at the following three functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`count()`: This is an unlimited version of the `range()` function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cycle()`: This will reiterate a cycle of values'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`repeat()`: This can repeat a single value an indefinite number of times'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our goal is to understand how these various iterator functions can be used in
    generator expressions and with generator functions.
  prefs: []
  type: TYPE_NORMAL
- en: Counting with count()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The built-in `range()` function is defined by an upper limit: the lower limit
    and step values are optional. The `count()` function, on the other hand, has a
    start and optional step, but no upper limit.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This function can be thought of as the primitive basis for a function like
    `enumerate()`. We can define the `enumerate()` function in terms of `zip()` and
    `count()` functions, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `enumerate()` function behaves as if it's a `zip()` function that uses the
    `count()` function to generate the values associated with some iterator.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consequently, the following two commands are equivalent to each other:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Both will emit a sequence of numbers of two tuples paired with items from the
    iterator.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `zip()` function is made slightly simpler with the use of the `count()`
    function, as shown in the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This will provide values of 1, 4, 7, 10, and so on, as the identifiers for each
    value from the enumerator. This is a challenge because `enumerate` doesn't provide
    a way to change the step.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following command describes the `enumerate()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `count()` function permits non-integer values. We can use something like
    the `count(0.5, 0.1)` method to provide floating-point values. This will accumulate
    a substantial error if the increment value doesn't have an exact representation.
    It's generally better to use the `(0.5+x*.1 for x in count())` method to assure
    that representation errors don't accumulate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a way to examine the accumulating error. We''ll define a function,
    which will evaluate items from an iterator until some condition is met. Here''s
    how we can define the `until()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We'll get the next value from the iterator. If it passes the test, that's our
    value. Otherwise, we'll evaluate this function recursively to search for a value
    that passes the test.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll provide a source iterable and a comparison function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'When we evaluate the `until(neq, source)` method, we find the result is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: After 928 iterations, the sum of the error bits has accumulated to ![Counting
    with count()](graphics/B03652_08_01.jpg). Neither value has an exact binary representation.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `count()` function is close to the Python recursion limit. We'd need to
    rewrite our `until()` function to use tail-call optimization to locate counts
    with larger accumulated errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'The smallest detectible difference can be computed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: After just six steps, the `count(0, 0.1)` method has accumulated a measurable
    error of ![Counting with count()](graphics/B03652_08_02.jpg). Not a large error,
    but within 1000 steps, it will be considerably larger.
  prefs: []
  type: TYPE_NORMAL
- en: Reiterating a cycle with cycle()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `cycle()` function repeats a sequence of values. We can imagine using it
    to solve silly fizz-buzz problems.
  prefs: []
  type: TYPE_NORMAL
- en: Visit [http://rosettacode.org/wiki/FizzBuzz](http://rosettacode.org/wiki/FizzBuzz)
    for a comprehensive set of solutions to a fairly trivial programming problem.
    Also see [https://projecteuler.net/problem=1](https://projecteuler.net/problem=1)
    for an interesting variation on this theme.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the `cycle()` function to emit sequences of `True` and `False` values
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'If we zip together a finite collection of numbers, we''ll get a set of triples
    with a number, and two flags showing whether or not the number is a multiple of
    3 or a multiple of 5\. It''s important to introduce a finite iterable to create
    a proper upper bound on the volume of data being generated. Here''s a sequence
    of values and their multiplier flags:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now decompose the triples and use a filter to pass numbers which are
    multiples and reject all others:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This function has another, more valuable use for exploratory data analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'We often need to work with samples of large sets of data. The initial phases
    of cleansing and model creation are best developed with small sets of data and
    tested with larger and larger sets of data. We can use the `cycle()` function
    to fairly select rows from within a larger set. The population size, ![Reiterating
    a cycle with cycle()](graphics/B03652_08_03.jpg), and the desired sample size,
    ![Reiterating a cycle with cycle()](graphics/B03652_08_04.jpg), denotes how long
    we can use a cycle:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Reiterating a cycle with cycle()](graphics/B03652_08_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We''ll assume that the data can be parsed with the `csv` module. This leads
    to an elegant way to create subsets. We can create subsets using the following
    commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We created a `cycle()` function based on the selection factor, `c`. For example,
    we might have a population of 10 million records: a 1,000-record subset involves
    picking 1/10,000 of the records. We assumed that this snippet of code is nestled
    securely inside a `with` statement that opens the relevant files. We also avoided
    showing details of any dialect issues with the CSV format files.'
  prefs: []
  type: TYPE_NORMAL
- en: We can use a simple generator expression to filter the data using the `cycle()`
    function and the source data that's available from the CSV reader. Since the `chooser`
    expression and the expression used to write the rows are both non-strict, there's
    little memory overhead from this kind of processing.
  prefs: []
  type: TYPE_NORMAL
- en: We can—with a small change—use the `random.randrange(c)` method instead of the
    `cycle(c)` method to achieve a randomized selection of a similar sized subset.
  prefs: []
  type: TYPE_NORMAL
- en: We can also rewrite this method to use `compress()`, `filter()`, and `islice()`
    functions, as we'll see later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: This design will also reformat a file from any nonstandard CSV-like format into
    a standardized CSV format. As long as we define parser functions that return consistently
    defined tuples and write consumer functions that write tuples to the target files,
    we can do a great deal of cleansing and filtering with relatively short, clear
    scripts.
  prefs: []
  type: TYPE_NORMAL
- en: Repeating a single value with repeat()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `repeat()` function seems like an odd feature: it returns a single value
    over and over again. It can serve as a replacement for the `cycle()` function.
    We can extend our data subset selection function using the `repeat(0)` method
    instead of the `cycle(range(100))` method in an expression line, for example,`(x==0
    for x in some_function)`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can think of the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This allows us to make a simple parameter change, which will either pick all
    data or pick a subset of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can embed this in nested loops to create more complex structures. Here''s
    a simple example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: We created repeating sequences of numbers using the `times` parameter on the
    `repeat()` function.
  prefs: []
  type: TYPE_NORMAL
- en: Using the finite iterators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `itertools` module provides a number of functions that we can use to produce
    finite sequences of values. We''ll look at ten functions in this module, plus
    some related built-in functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`enumerate()`: This function is actually part of the `__builtins__` package,
    but it works with an iterator and is very similar to other functions in the `itertools`
    module.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`accumulate()`: This function returns a sequence of reductions of the input
    iterable. It''s a higher-order function and can do a variety of clever calculations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`chain()`: This function combines multiple iterables serially.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`groupby()`: This function uses a function to decompose a single iterable into
    a sequence of iterables over subsets of the input data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`zip_longest()`: This function combines elements from multiple iterables. The
    built-in `zip()` function truncates the sequence at the length of the shortest
    iterable. The `zip_longest()` function pads the shorter iterables with the given
    fillvalue.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`compress()`: This function filters one iterable based on a second iterable
    of `Boolean` values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`islice()`: This function is the equivalent of a slice of a sequence when applied
    to an iterable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dropwhile()` and `takewhile()`: Both of these functions use a `Boolean` function
    to filter items from an iterable. Unlike `filter()` or `filterfalse()`, these
    functions rely on a single `True` or `False` value to change their filter behavior
    for all subsequent values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`filterfalse()`: This function applies a filter function to an iterable. This
    complements the built-in `filter()` function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`starmap()`: This function maps a function to an iterable sequence of tuples
    using each iterable as an `*args` argument to the given function. The `map()`
    function does a similar thing using multiple parallel iterables.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We've grouped these functions into approximate categories. The categories are
    roughly related to concepts of restructuring an iterable, filtering, and mapping.
  prefs: []
  type: TYPE_NORMAL
- en: Assigning numbers with enumerate()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In [Chapter 7](ch07.html "Chapter 7. Additional Tuple Techniques"), *Additional
    Tuple Techniques*, we used the `enumerate()` function to make a naïve assignment
    of rank numbers to sorted data. We can do things like pairing up a value with
    its position in the original sequence, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This will sort the items in `raw_values` into order, create two tuples with
    an ascending sequence of numbers, and materialize an object we can use for further
    calculations. The command and the result are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: In [Chapter 7](ch07.html "Chapter 7. Additional Tuple Techniques"), *Additional
    Tuple Techniques* we implemented an alternative form of enumerate, `rank()` function,
    which would handle ties in a more statistically useful way.
  prefs: []
  type: TYPE_NORMAL
- en: This is a common feature that is added to a parser to record the source data
    row numbers. In many cases, we'll create some kind of `row_iter()` function to
    extract the string values from a source file. This might iterate over the `string`
    values in tags of an XML file or in columns of a CSV file. In some cases, we might
    even be parsing data presented in an HTML file parsed with Beautiful Soup.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 4](ch04.html "Chapter 4. Working with Collections"), *Working with
    Collections*, we parsed an XML to create a simple sequence of position tuples.
    We then created legs with a start, end, and distance. We did not, however, assign
    an explicit leg number. If we ever sorted the trip collection, we'd be unable
    to determine the original ordering of the legs.
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Chapter 7](ch07.html "Chapter 7. Additional Tuple Techniques"), *Additional
    Tuple Techniques*, we expanded on the basic parser to create namedtuples for each
    leg of the trip. The output from this enhanced parser looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The first `Leg` function is a short trip between two points on the Chesapeake
    Bay.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can add a function that will build a more complex tuple with the input order
    information as part of the tuple. First, we''ll define a slightly more complex
    version of the `Leg` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This is similar to the `Leg` instance shown in [Chapter 7](ch07.html "Chapter 7. Additional
    Tuple Techniques"), *Additional Tuple Techniques* but it includes the order as
    well as the other attributes. We''ll define a function that decomposes pairs and
    creates `Leg` instances as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We can use this function to enumerate each pair of starting and ending points.
    We'll decompose the pair and then reassemble the `order`, `start`, and `end` parameters
    and the `haversine(start,end)` parameter's value as a single `Leg` instance. This
    `generator` function will work with an iterable sequence of pairs.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the context of the preceding explanation, it is used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We've parsed the original file into the path points, created start-end pairs,
    and then created a trip that was built of individual `Leg` objects. The `enumerate()`
    function assures that each item in the iterable sequence is given a unique number
    that increments from the default starting value of 0\. A second argument value
    can be given to provide an alternate starting value.
  prefs: []
  type: TYPE_NORMAL
- en: Running totals with accumulate()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `accumulate()` function folds a given function into an iterable, accumulating
    a series of reductions. This will iterate over the running totals from another
    iterator; the default function is `operator.add()`. We can provide alternative
    functions to change the essential behavior from sum to product. The Python library
    documentation shows a particularly clever use of the `max()` function to create
    a sequence of maximum values so far.
  prefs: []
  type: TYPE_NORMAL
- en: One application of running totals is quartiling data. We can compute the running
    total for each sample and divide them into quarters with an `int(4*value/total)`
    calculation.
  prefs: []
  type: TYPE_NORMAL
- en: In the *Assigning numbers with enumerate()* section, we introduced a sequence
    of latitude-longitude coordinates that describe a sequence of legs on a voyage.
    We can use the distances as a basis for quartiling the waypoints. This allows
    us to determine the midpoint in the trip.
  prefs: []
  type: TYPE_NORMAL
- en: 'The value of the `trip` variable looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Each `Leg` object has a start point, an end point, and a distance. The calculation
    of quartiles looks like the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: We extracted the distance values and computed the accumulated distances for
    each leg. The last of the accumulated distances is the total. We've added `1.0`
    to the total to assure that `4*d/total` is 3.9983, which truncates to 3\. Without
    the `+1.0`, the final item would have a value of `4`, which is an impossible fifth
    quartile. For some kinds of data (with extremely large values) we might have to
    add a larger value.
  prefs: []
  type: TYPE_NORMAL
- en: 'The value of the `quartiles` variable is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We can use the `zip()` function to merge this sequence of quartile numbers with
    the original data points. We can also use functions like `groupby()` to create
    distinct collections of the legs in each quartile.
  prefs: []
  type: TYPE_NORMAL
- en: Combining iterators with chain()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can use the `chain()` function to combine a collection of iterators into
    a single, overall iterator. This can be helpful to combine data that was decomposed
    via the `groupby()` function. We can use this to process a number of collections
    as if they were a single collection.
  prefs: []
  type: TYPE_NORMAL
- en: 'In particular, we can combine the `chain()` function with the `contextlib.ExitStack()`
    method to process a collection of files as a single iterable sequence of values.
    We can do something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We've created an `ExitStack` object that can contain a number of individual
    contexts open. When the `with` statement finishes, all items in the `ExitStack`
    object will be closed properly. We created a simple sequence of open file objects;
    these objects were also entered into the `ExitStack` object.
  prefs: []
  type: TYPE_NORMAL
- en: Given the sequence of files in the `files` variable, we created a sequence of
    CSV readers in the `readers` variable. In this case, all of our files have a common
    tab-delimited format, which makes it very pleasant to open all of the files with
    a simple, consistent application of a function to the sequence of files.
  prefs: []
  type: TYPE_NORMAL
- en: 'We could also open the files using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we chained all of the readers into a single iterator with `chain(*readers)`.
    This was used to yield the sequence of rows from all of the files.
  prefs: []
  type: TYPE_NORMAL
- en: It's important to note that we can't return the `chain(*readers)` object. If
    we do, this would exit the `with` statement context, closing all the source files.
    Instead, we must yield individual rows so that the `with` statement context is
    kept active.
  prefs: []
  type: TYPE_NORMAL
- en: Partitioning an iterator with groupby()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can use the `groupby()` function to partition an iterator into smaller iterators.
    This works by evaluating the given `key()` function for each item in the given
    iterable. If the key value matches the previous item's key, the two items are
    part of the same partition. If the key does not match the previous item's key,
    the previous partition is ended and a new partition is started.
  prefs: []
  type: TYPE_NORMAL
- en: The output from the `groupby()` function is a sequence of two tuples. Each tuple
    has the group's key value and an iterable over the items in the group. Each group's
    iterator can be preserved as a tuple or processed to reduce it to some summary
    value. Because of the way the group iterators are created, they can't be preserved.
  prefs: []
  type: TYPE_NORMAL
- en: In the *Running totals with accumulate()* section, earlier in the chapter, we
    showed how to compute quartile values for an input sequence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given the `trip` variable with the raw data and the quartile variable with
    the quartile assignments, we can group the data using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: This will start by zipping the quartile numbers with the raw trip data, iterating
    over two tuples. The `groupby()` function will use the given `lambda` variable
    to group by the quartile number. We used a `for` loop to examine the results of
    the `groupby()` function. This shows how we get a group key value and an iterator
    over members of the group.
  prefs: []
  type: TYPE_NORMAL
- en: The input to the `groupby()` function must be sorted by the key values. This
    will assure that all of the items in a group will be adjacent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that we can also create groups using the `defaultdict(list)` method, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: We created a `defaultdict` class with a `list` object as the value associated
    with each key. Each item will have the given `key()` function applied to create
    a key value. The item is appended to the list in the `defaultdict` class with
    the given key.
  prefs: []
  type: TYPE_NORMAL
- en: Once all of the items are partitioned, we can then return each partition as
    an iterator over the items that share a common key. This is similar to the `groupby()`
    function because the input iterator to this function isn't necessarily sorted
    in precisely the same order; it's possible that the groups might have the same
    members, but the order might differ.
  prefs: []
  type: TYPE_NORMAL
- en: Merging iterables with zip_longest() and zip()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We saw the `zip()` function in [Chapter 4](ch04.html "Chapter 4. Working with
    Collections"), *Working with Collections*. The `zip_longest()` function differs
    from the `zip()` function in an important way: where the `zip()` function stops
    at the end of the shortest iterable, the `zip_longest()` function pads short iterables
    and stops at the end of the longest iterable.'
  prefs: []
  type: TYPE_NORMAL
- en: The `fillvalue` keyword parameter allows filling with a value other than the
    default value, `None`.
  prefs: []
  type: TYPE_NORMAL
- en: For most exploratory data analysis applications, padding with a default value
    is statistically difficult to justify. The **Python Standard Library** document
    shows a few clever things which can be done with the `zip_longest()` function.
    It's difficult to expand on these without drifting far from our focus on data
    analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Filtering with compress()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The built-in `filter()` function uses a predicate to determine if an item is
    passed or rejected. Instead of a function that calculates a value, we can use
    a second, parallel iterable to determine which items to pass and which to reject.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can think of the `filter()` function as having the following definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: We cloned the iterable using the `tee()` function. (We'll look at this function
    in detail later.) We evaluated the filter predicate for each value. Then we provided
    the original iterable and the filter function iterable to compress, pass, and
    reject values. This builds the features of the `filter()` function from the more
    primitive features of the `compress()` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the *Reiterating a cycle with cycle()* section of this chapter, we looked
    at data selection using a simple generator expression. Its essence was as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: We defined a function which would produce a value `1` followed by *c-1* zeroes.
    This cycle would be repeated, allowing to pick only *1/c* rows from the source.
  prefs: []
  type: TYPE_NORMAL
- en: We can replace the `cycle(range(c))` function with the `repeat(0)` function
    to select all rows. We can also replace it with the `random.randrange(c)` function
    to randomize the selection of rows.
  prefs: []
  type: TYPE_NORMAL
- en: 'The keep expression is really just a `compress(some_source, chooser)` method.
    If we make that change, the processing is simplified:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ve defined three alternative selection rules: `all`, `subset`, and `randomized`.
    The subset and randomized versions will pick *1/c* rows from the source. The `chooser`
    expression will build an iterable over `True` and `False` values based on one
    of the selection rules. The rows to be kept are selected by applying the source
    iterable to the row selection iterable.'
  prefs: []
  type: TYPE_NORMAL
- en: Since all of this is non-strict, rows are not read from the source until required.
    This allows us to process very large sets of data efficiently. Also, the relative
    simplicity of the Python code means that we don't really need a complex configuration
    file and an associated parser to make choices among the selection rules. We have
    the option to use this bit of Python code as the configuration for a larger data
    sampling application.
  prefs: []
  type: TYPE_NORMAL
- en: Picking subsets with islice()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In [Chapter 4](ch04.html "Chapter 4. Working with Collections"), *Working with
    Collections*, we looked at slice notation to select subsets from a collection.
    Our example was to pair up items sliced from a `list` object. The following is
    a simple list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'We can create pairs using list slices as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The `islice()` function gives us similar capabilities without the overhead
    of materializing a `list` object, and it looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: We created two independent iterators over a flat list of data points. These
    might be two separate iterators over an open file or a database result set. The
    two iterators need to be independent so that change in one `islice()` function
    doesn't interfere with the other `islice()` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The two sets of arguments to the `islice()` function are similar to the `flat[0::2]`
    and `flat[1::2]` methods. There''s no slice-like shorthand, so the start and stop
    argument values are required. The step can be omitted and the default value is
    1\. This will produce a sequence of two tuples from the original sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Since `islice()` works with an iterable, this kind of design will work with
    extremely large sets of data. We can use this to pick a subset out of a larger
    set of data. In addition to using the `filter()` or `compress()` functions, we
    can also use the `islice(source,0,None,c)` method to pick ![Picking subsets with
    islice()](graphics/B03652_08_06.jpg) items from a larger set of data.
  prefs: []
  type: TYPE_NORMAL
- en: Stateful filtering with dropwhile() and takewhile()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `dropwhile()` and `takewhile()` functions are stateful filter functions.
    They start in one mode; the given `predicate` function is a kind of flip-flop
    that switches the mode. The `dropwhile()` function starts in reject mode; when
    the function becomes `False`, it switches to pass mode. The `takewhile()` function
    starts in pass mode; when the given function becomes `False`, it switches into
    reject mode.
  prefs: []
  type: TYPE_NORMAL
- en: Since these are filters, both functions will consume the entire iterable. Given
    an infinite iterator like the `count()` function, it will continue indefinitely.
    Since there's no simple integer overflow in Python, an ill-considered use of `dropwhile()`
    or `takewhile()` functions won't crash after a few billion iterations with integer
    overflow. It really can run for a very, very long time.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use these with file parsing to skip headers or footers in the input.
    We use the `dropwhile()` function to reject header rows and pass the remaining
    data. We use the `takewhile()` function to pass data and reject trailer rows.
    We''ll return to the simple GPL file format shown in [Chapter 3](ch03.html "Chapter 3. Functions,
    Iterators, and Generators"), *Functions, Iterators, and Generators*. The file
    has a header that looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'This is followed by rows that look like the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'We can easily locate the final line of the headers—the `#` line—using a parser
    based on the `dropwhile()` function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: We created a CSV reader to parse the lines based on tab characters. This will
    neatly separate the `color` three tuple from the name. The three tuple will need
    further parsing. This will produce an iterator that starts with the `#` line and
    continues with the rest of the file.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the `islice()` function to discard the first item of an iterable.
    We can then parse the color details as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The `islice(rows, 1, None)` expression is similar to asking for a `rows[1:]`
    slice: the first item is quietly discarded. Once the last of the heading rows
    have been discarded, we can parse the color tuples and return more useful color
    objects.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For this particular file, we can also use the number of columns located by
    the CSV reader function. We can use the `dropwhile(lambda row: len(row) == 1,
    rdr)` method to discard header rows. This doesn''t always work out well in general.
    Locating the last line of the headers is often easier than trying to locate some
    general feature that distinguishes header (or trailer) lines from the meaningful
    file content.'
  prefs: []
  type: TYPE_NORMAL
- en: Two approaches to filtering with filterfalse() and filter()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In [Chapter 5](ch05.html "Chapter 5. Higher-order Functions"), *Higher-order
    Functions* we looked at the built-in `filter()` function. The `filterfalse()`
    function from the `itertools` module could be defined from the `filter()` function,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'As with the `filter()` function, the predicate function can be of `None` value.
    The value of the `filter(None, iterable)` method is all the `True` values in the
    iterable. The value of the `filterfalse(None, iterable)` method is all of the
    `False` values from the iterable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: The point of having the `filterfalse()` function is to promote reuse. If we
    have a succinct function that makes a filter decision, we should be able to use
    that function to partition input in to pass and reject groups without having to
    fiddle around with logical negation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The idea is to execute the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: This will obviously include all items from the source. The `test()` function
    is unchanged, and we can't introduce a subtle logic bug through improper use of
    `()`.
  prefs: []
  type: TYPE_NORMAL
- en: Applying a function to data via starmap() and map()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The built-in `map()` function is a higher-order function that applies a `map()`
    function to items from an iterable. We can think of the simple version of the
    `map()` function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'This works well when the `arg_iter` parameter is a list of individual values.
    The `starmap()` function in the `itertools` module is simply the `*a` version
    of the `map()` function, which is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: This reflects a small shift in the semantics of the `map()` function to properly
    handle a tuple-of-tuples structure.
  prefs: []
  type: TYPE_NORMAL
- en: The `map()` function can also accept multiple iterables; the values from these
    additional iterables are zipped and it behaves like the `starmap()` function.
    Each zipped item from the source iterables becomes multiple arguments to the given
    function.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can think of the `map(function, iter1, iter2, ..., itern)` method being
    defined as the following two commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Various iterator values are used to construct a tuple of arguments via the `*args`
    construct. In effect, `starmap()` function is like this more general case. We
    can build the simple `map()` function from the more general `starmap()` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we look at the trip data, from the preceding commands, we can redefine
    the construction of a `Leg` object based on the `starmap()` function. Prior to
    creating `Leg` objects, we created pairs of points. Each pair looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'We could use the `starmap()` function to assemble the `Leg` objects, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: The `legs()` function creates pairs of point objects that reflect the start
    and end of a leg of the voyage. Given these pairs, we can create a simple function,
    `make_leg`, which accepts a pair of `Points` object, and returns a `Leg` object
    with the start point, end point, and distance between the two points.
  prefs: []
  type: TYPE_NORMAL
- en: The benefit of the `starmap(function, some_list)` method is to replace a potentially
    wordy `(function(*args) for args in some_list)` generator expression.
  prefs: []
  type: TYPE_NORMAL
- en: Cloning iterators with tee()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `tee()` function gives us a way to circumvent one of the important Python
    rules for working with iterables. The rule is so important, we'll repeat it here.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Iterators can be used only once.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `tee()` function allows us to clone an iterator. This seems to free us
    from having to materialize a sequence so that we can make multiple passes over
    the data. For example, a simple average for an immense dataset could be written
    in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: This would compute an average without appearing to materialize the entire dataset
    in memory in any form.
  prefs: []
  type: TYPE_NORMAL
- en: While interesting in principle, the `tee()` function's implementation suffers
    from a severe limitation. In most Python implementations, the cloning is done
    by materializing a sequence. While this circumvents the "one time only" rule for
    small collections, it doesn't work out well for immense collections.
  prefs: []
  type: TYPE_NORMAL
- en: Also, the current implementation of the `tee()` function consumes the source
    iterator. It might be nice to create some syntactic sugar to allow unlimited use
    of an iterator. This is difficult to manage in practice. Instead, Python obliges
    us to optimize the `tee()` function carefully.
  prefs: []
  type: TYPE_NORMAL
- en: The itertools recipes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *itertools* chapter of the Python library documentation, *Itertools* *Recipes*,
    is outstanding. The basic definitions are followed by a series of recipes that
    are extremely clear and helpful. Since there's no reason to reproduce these, we'll
    reference them here. They should be considered as required reading on functional
    programming in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*10.1.2* section, *Itertools Recipes* of *Python Standard Library*, is a wonderful
    resource. See'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.python.org/3/library/itertools.html#itertools-recipes](https://docs.python.org/3/library/itertools.html#itertools-recipes).'
  prefs: []
  type: TYPE_NORMAL
- en: It's important to note that these aren't importable functions in the `itertools`
    modules. A recipe needs to be read and understood and then, perhaps, copied or
    modified before inclusion in an application.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table summarizes some of the recipes that show functional programming
    algorithms built from the itertools basics:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Function Name | Arguments | Results |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `take` | `(n, iterable)` | This returns the first n items of the iterable
    as a list. This wraps a use of `islice()` in a simple name. |'
  prefs: []
  type: TYPE_TB
- en: '| `tabulate` | `(function, start=0)` | This returns `function(0)` and `function(1)`.
    This is based on a `map(function, count())`. |'
  prefs: []
  type: TYPE_TB
- en: '| `consume` | `(iterator, n)` | This advances the iterator n steps ahead. If
    *n* is `None`, iterator consumes the steps entirely. |'
  prefs: []
  type: TYPE_TB
- en: '| `nth` | `(iterable, n, default=None)` | This returns the nth item or a default
    value. This wraps the use of `islice()` in a simple name. |'
  prefs: []
  type: TYPE_TB
- en: '| `quantify` | `(iterable, pred=bool)` | This counts how many times the predicate
    is true. This uses `sum()` and `map()`, and relies on the way a Boolean predicate
    is effectively 1 when converted to an integer value. |'
  prefs: []
  type: TYPE_TB
- en: '| `padnone` | `(iterable)` | This returns the sequence elements and then returns
    `None` indefinitely. This can create functions that behave like `zip_longest()
    or map()`. |'
  prefs: []
  type: TYPE_TB
- en: '| `ncycles` | `(iterable, n)` | This returns the sequence elements *n* times.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `dotproduct` | `(vec1, vec2)` | This is the essential definition of a dot
    product. Multiply two vectors and find the sum of the result. |'
  prefs: []
  type: TYPE_TB
- en: '| `flatten` | `(listOfLists)` | This flattens one level of nesting. This chains
    the various lists together into a single list. |'
  prefs: []
  type: TYPE_TB
- en: '| `repeatfunc` | `(func, times=None, *args)` | This calls to `func` repeatedly
    with specified arguments. |'
  prefs: []
  type: TYPE_TB
- en: '| `pairwise` | `(iterable):` | `s -> (s0,s1), (s1,s2), (s2, s3).` |'
  prefs: []
  type: TYPE_TB
- en: '| `grouper` | `(iterable, n, fillvalue=None)` | Collect data into fixed length
    chunks or blocks. |'
  prefs: []
  type: TYPE_TB
- en: '| `roundrobin` | `(*iterables)` | `roundrobin(''ABC'', ''D'', ''EF'') --> A
    D E B F C` |'
  prefs: []
  type: TYPE_TB
- en: '| `partition` | `(pred, iterable)` | This uses a predicate to partition entries
    into `False` entries and `True` entries. |'
  prefs: []
  type: TYPE_TB
- en: '| `unique_ everseen` | `(iterable, key=None)` | This lists unique elements,
    preserving order. Remembers all elements ever seen. `unique_ everseen(''AAAABBBCCDAABBB'')
    - -> A B C D.` |'
  prefs: []
  type: TYPE_TB
- en: '| `unique_ justseen` | `(iterable, key=None)` | This lists unique elements,
    preserving order. Remembers only the element just seen. `unique_justseen(''AAAABBBCCDAABBB'')
    - -> A B C D A B.` |'
  prefs: []
  type: TYPE_TB
- en: '| `iter_except` | `(func, exception, first=None)` | Call a function repeatedly
    until an exception is raised. This can be used to iterate until `KeyError` or
    `IndexError`. |'
  prefs: []
  type: TYPE_TB
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we've looked at a number of functions in the `itertools` module.
    This library module provides a number of functions that help us to work with iterators
    in sophisticated ways.
  prefs: []
  type: TYPE_NORMAL
- en: We've looked at the infinite iterators; these repeat without terminating. These
    include the `count()`, `cycle()`, and `repeat()` functions. Since they don't terminate,
    the consuming function must determine when to stop accepting values.
  prefs: []
  type: TYPE_NORMAL
- en: We've also looked at a number of finite iterators. Some of these are built-in
    and some of these are part of the `itertools` module. These work with a source
    iterable, so they terminate when that iterable is exhausted. These functions include
    `enumerate()`, `accumulate()` , `chain()` , `groupby()` , `zip_longest()`, `zip()`,
    `compress()`, `islice()`, `dropwhile()`, `takewhile()`, `filterfalse()`, `filter()`,
    `starmap()`, and `map()`. These functions allow us to replace possibly complex
    generator expressions with simpler-looking functions.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we looked at the recipes from the documentation, which provide
    yet more functions we can study and copy for our own applications. The recipes
    list shows a wealth of common design patterns.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 9](ch09.html "Chapter 9. More Itertools Techniques"), *More Itertools
    Techniques*, we'll continue our study of the `itertools` module. We'll look at
    the iterators focused on permutations and combinations. These don't apply to processing
    large sets of data. They're a different kind of iterator-based tool.
  prefs: []
  type: TYPE_NORMAL
