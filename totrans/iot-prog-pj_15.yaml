- en: Connecting Sensory Inputs from the Robot Car to the Web
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to make our robot car, T.A.R.A.S, a true IoT **thing**, we have to
    connect T.A.R.A.S to the internet. In this chapter, we will start the transformation
    from desktop robot to internet robot by connecting the distance sensor from T.A.R.A.S
    to the web.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Identifying the sensor on the robot car
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reading robot car sensory data with Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Publishing robot car sensory data to the cloud
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Knowledge required to complete this chapter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To complete this chapter, you should have built a T.A.R.A.S robot car, as described
    in detail in [Chapter 13](2289f7f6-874d-4a13-8e08-02fde93e6b18.xhtml), *Introducing
    the Raspberry Pi Robot Car*. As with the other chapters in this book, a working
    knowledge of Python is required, as well as a basic understanding of object-oriented
    programming.
  prefs: []
  type: TYPE_NORMAL
- en: Project overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The project in this chapter will involve sending sensory distance data from
    T.A.R.A.S to the internet. We will create an online dashboard using ThingsBoard,
    which will display this distance information on an analogue gauge.
  prefs: []
  type: TYPE_NORMAL
- en: This project should take a couple of hours to complete.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To complete this project, the following will be required:'
  prefs: []
  type: TYPE_NORMAL
- en: A Raspberry Pi Model 3 (2015 model or newer)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A USB power supply
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A computer monitor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A USB keyboard
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A USB mouse
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A completed T.A.R.A.S robot car kit (see [Chapter 13](2289f7f6-874d-4a13-8e08-02fde93e6b18.xhtml),
    *Introducing the Raspberry Pi Robot Car*)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying the sensor on the robot car
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Throughout the course of the book, we have used a few input sensors. We have
    also published data from these sensors to the web. T.A.R.A.S. uses a distance
    sensor to detect objects close by, as can be seen in the following picture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/da4160be-5fd9-49fa-bc1a-6c249107c6e1.png)'
  prefs: []
  type: TYPE_IMG
- en: Looking at T.A.R.A.S for the first time, you would be forgiven for not knowing
    where the distance sensor is located. On T.A.R.A.S, and many other robots, this
    sensor is located in the eyes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a photo of the HC-SR04 distance sensor—the one used on T.A.R.A.S:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/c6bd91ef-c524-41cc-9ea8-6b1127b72892.png)'
  prefs: []
  type: TYPE_IMG
- en: If you do a Google image search for HC-SR04 on robots, you will see many, many
    robots that use this sensor. It is a very popular choice due to its low cost and
    wide availability, as well as its handy resemblance to eyes.
  prefs: []
  type: TYPE_NORMAL
- en: Taking a closer look at the HC-SR04
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned, the HC-SR04 is a very popular sensor. It is easy to program, and
    is available from multiple vendors on [www.aliexpress.com](http://www.aliexpress.com).
    The HC-SR04 provides measurements from 2 cm to 400 cm, and is accurate to within
    3 mm.
  prefs: []
  type: TYPE_NORMAL
- en: 'The GPIO Zero library makes it easy to read data from the HC-SR04\. The following
    diagram is a wiring diagram for using this sensor with the Raspberry Pi:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/9fffe200-03b5-4702-b041-d246fb7dad48.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, the HC-SR04 has four pins, two of which are used for the signal
    input and output. The wiring diagram is a subdiagram of the one we used to wire
    up T.A.R.A.S in [Chapter 13](2289f7f6-874d-4a13-8e08-02fde93e6b18.xhtml), *Introducing
    the Raspberry Pi Robot Car*. The connections are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Trig from HC-SR04 (distance sensor) to pin 17 on the Raspberry Pi
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Echo from HC-SR04 (distance sensor) to the left side of the 330 Ohm resistor
    on the breadboard
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VCC from HC-SR04 (distance sensor) to 5V on the Raspberry Pi
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Output from voltage divider to pin 18 on the Raspberry Pi
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GND from HC-SR04 to the right side of the 470 Ohm resistor on the breadboard
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The trig, or trigger, is the input of the HC-SR04, and works with 5V or 3.3V.
    The Echo pin is the output, and is designed to work with 5V. Since this is a little
    too much for our Raspberry Pi to handle, we use a voltage divider circuit to reduce
    the voltage to 3.3V.
  prefs: []
  type: TYPE_NORMAL
- en: We could have added further sensors to T.A.R.A.S to make it more advanced, including
    line-tracking sensors, temperature sensors, light sensors, and PID sensors. The
    line-tracking sensor is of particular interest, as a simple line could provide
    T.A.R.A.S with a route to follow during its security patrol duties—a very useful
    addition. As the design is already complicated enough, I will leave it to you
    to add this functionality if you choose.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram outlines how a line-tracking sensor works:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/d0d5f0ff-d13f-4fbc-8061-5e8f133d8a90.png)'
  prefs: []
  type: TYPE_IMG
- en: In the diagram, you will see two sensors at the front of the robot car. When
    the robot car veers off to the side, one of the sensors picks it up. In the previous
    example, the car in position **B** has veered to the right. The left sensor picks
    this up, and the program makes corrections by turning the robot car to the left
    until it returns to position **A**.
  prefs: []
  type: TYPE_NORMAL
- en: Reading robot car sensory data with Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Although we have covered this before, it''s a good idea to familiarize (or
    re-familiarize) ourselves with the programming of the HC-SR04:'
  prefs: []
  type: TYPE_NORMAL
- en: Open up Thonny from Application Menu | Programming | Thonny Python IDE.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click New to create a new file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Save the file as `distance-sensor-test.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Place your hand in front of the distance sensor. You should see the following
    in the shell (depending on how far your hand is from the distance sensor):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As you move your hand closer to, or farther away from, the distance sensor,
    the value will change. This code is pretty self explanatory. The `distance_sensor
    = DistanceSensor(echo=18, trigger=17)` line sets up a `distance_sensor` object
    of class type `DistanceSensor`, with the appropriate pin definitions. We retrieve
    the distance an object is from the HC-SR04 every time we call the `distance` method
    of `distance_sensor`. To convert the value to centimeters, we multiply it by 100.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now that we are able to retrieve values from the distance sensor, let''s modify
    the code to make it more object-oriented friendly:'
  prefs: []
  type: TYPE_NORMAL
- en: Open up Thonny from Application Menu | Programming | Thonny Python IDE
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click New to create a new file
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Save the file as `RobotEyes.py`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the code
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The code should run in exactly the same way as before. The only thing we did
    was to wrap it up in a class in order to abstract it. This will make things easier
    as we write more code. We won't have to remember which pins the HC-SR04 is connected
    to, and we actually don't need to know that it is a distance sensor that we are
    getting data from. This code makes more sense visually than the previous code.
  prefs: []
  type: TYPE_NORMAL
- en: Publishing robot car sensory data to the cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 10](6c15e05d-c6f4-48b4-9279-704320035b8a.xhtml), *Publishing to
    Web Services*, we set up a ThingsBoard account for publishing sensory data. If
    you have not already done so, set up an account at [www.ThingsBoard.io](https://thingsboard.io/)
    (refer to [Chapter 10](6c15e05d-c6f4-48b4-9279-704320035b8a.xhtml), *Publishing
    to Web Services*, for instructions on how to do this).
  prefs: []
  type: TYPE_NORMAL
- en: Create a ThingsBoard device
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To publish our distance sensor data to ThingsBoard, we first need to create
    a ThingsBoard Device:'
  prefs: []
  type: TYPE_NORMAL
- en: Log in to your account at [https://demo.thingsboard.io/login](https://demo.thingsboard.io/login)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on Devices, and then the large orange + sign at the bottom-right corner
    of the screen:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/49e26edc-5be8-4ee2-b56b-49dc553774c9.png)'
  prefs: []
  type: TYPE_IMG
- en: Type in `RobotEyes` for the Name, leave the Device type as `default`, and put
    in a meaningful description under Description
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click ADD
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on `RobotEyes` to get a menu sliding out from the right
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click COPY ACCESS TOKEN to copy the token onto your clipboard
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Paste the token into a text file
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For our code, we will be using the MQTT protocol. If the Paho MQTT library
    has not been installed on your Raspberry Pi, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a Terminal application from the Raspberry Pi main toolbar
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Type `sudo pip3 install pho-mqtt`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You should see the library install.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now it''s time to write the code that will publish the sensory data of T.A.R.A.S
    to the web. We will modify our `RobotEyes` class:'
  prefs: []
  type: TYPE_NORMAL
- en: Open up Thonny from Application Menu | Programming | Thonny Python IDE
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click New to create a new file
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Be sure to paste the access token from the text file to the `access_token` variable
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save the file as `RobotEyesIOT.py`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the code
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should see the `distance` value in the shell, just as you did before. However,
    when you go to ThingsBoard and click on Latest Telemetry, you should see the same
    value, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/f43b0d47-2406-49cc-a3c7-b33bae6a940b.png)'
  prefs: []
  type: TYPE_IMG
- en: What we have accomplished here, just as in [Chapter 10](6c15e05d-c6f4-48b4-9279-704320035b8a.xhtml),
    *Publishing to Web Services*, is the successful transmission of our distance sensor
    information to the internet. We can now see how close an object is to our robot
    car from anywhere in the world. In the previous screenshot, we can see that there
    is *something* 3.801 cm away.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once again, we''ve written the code to be as self-explanatory as possible.
    However, we should point out the `publish_distance` method of the class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In this method, we start by creating a variable called `distance`, which we
    populate with the actual distance information from our class `get_distance` method.
    A Python dictionary object called `sensor_data` is created, and is used to store
    the `distance` value. From there, we create an MQTT client object called `client`.
    We set the password to the `access_token` we copied from ThingsBoard, and then
    connect using standard ThingsBoard boilerplate code.
  prefs: []
  type: TYPE_NORMAL
- en: The `client.publish` method sends our `sensor_data` to ThingsBoard through a
    `json.dumps` method. We then disconnect from `client` to close the connection.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s create a dashboard widget using our distance sensory data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In ThingsBoard, click Latest Telemetry, and check the box in the list next
    to the `distance` value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/12e05e33-6189-4eb6-8036-9ab7bfda79d1.png)'
  prefs: []
  type: TYPE_IMG
- en: Click SHOW ON WIDGET
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Under Current bundle, select `Analogue gauges` from the drop-down menu, as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/e77e038b-87ee-4f2c-bfe9-42eb23a9b346.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Select the last widget:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/e70c900d-55eb-4683-9354-4653ebf48dee.png)'
  prefs: []
  type: TYPE_IMG
- en: Click ADD TO DASHBOARD at the top
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a new dashboard called `RobotEyes`, and check the Open dashboard box:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/9107f1c7-f6fd-46ee-973e-29e398d856d8.png)'
  prefs: []
  type: TYPE_IMG
- en: Click ADD
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Congratulations! We now have created an IoT dashboard widget for the sensory
    distance information from T.A.R.A.S. With this, we can go fullscreen and view
    the information easily:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/5b607879-78ed-4afb-8320-f5a9b25d9a29.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we turned T.A.R.A.S into a true IoT thing by publishing the
    distance data—the distance from the eyes of T.A.R.A.S to any object within its
    view—to the internet. By encapsulating our code into a class called `RobotEyes`,
    we can forget that we are dealing with a distance sensor and just focus on the
    eyes of T.A.R.A.S as behaving sonar-like.
  prefs: []
  type: TYPE_NORMAL
- en: Through the use of the demo platform in ThingsBoard, we are able to write code
    that sends the distance information from T.A.R.A.S to a dashboard widget for display.
    If we really wanted to be creative, we could connect an actual analogue device
    via a servo and display the distance information that way (as we did in [Chapter
    6](f9133d23-c79a-4bf6-98f3-5405b8f0f5cf.xhtml), *Working with the Servo Control
    Code to Control an Analog Device*). In [Chapter 16](78ca846a-9f4b-47f7-b404-bb04366a9d9a.xhtml),
    *Controlling the Robot Car with Web Service Calls*, we will take things a step
    further and start to control T.A.R.A.S from the internet.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why do we use a voltage divider circuit when connecting the HC-SR04 to the Raspberry
    Pi?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: True or false? T.A.R.A.S has eyes that see through the use of sonar.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a device in ThingsBoard?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: True or false? Our class, `RobotEyes`, encapsulates the Raspberry Pi camera
    module used on T.A.R.A.S.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does the `RobotEyes.publish_distance` method do?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: True or false? The library that we require to work with MQTT comes pre-installed
    with Raspbian.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why do we name our class `RobotEyes`, and not `RobotDistanceSensor`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: True or false? Encapsulating boilerplate code in a class makes the code much
    more difficult to work with.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: True or false? The GPIO Zero library does not have support for distance sensors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between `RobotEyes.py` and `RobotEyesIOT.py`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A good source of guidance for the ThingsBoard platform is its own website. Go
    to [www.thingsboard.io/docs/guides](https://thingsboard.io/docs/guides/) to find
    more information.
  prefs: []
  type: TYPE_NORMAL
