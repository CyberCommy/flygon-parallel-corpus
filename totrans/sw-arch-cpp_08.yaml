- en: Design Patterns and C++
  prefs: []
  type: TYPE_NORMAL
- en: C++ is not just an object-oriented language, and it doesn't just offer dynamic
    polymorphism, so design in C++ is not just about the Gang of Four patterns. In
    this chapter, you will learn about the commonly used C++ idioms and design patterns
    and where to use them.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Writing idiomatic C++
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Curiously recurring template pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracking state and visiting objects in C++
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dealing with memory efficiently
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That's quite a list! Let's not waste time and jump right in.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The code from this chapter requires the following tools to build and run:'
  prefs: []
  type: TYPE_NORMAL
- en: A compiler supporting C++20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CMake 3.15+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The source code snippets from the chapter can be found at [https://github.com/PacktPublishing/Software-Architecture-with-Cpp/tree/master/Chapter06](https://github.com/PacktPublishing/Software-Architecture-with-Cpp/tree/master/Chapter06).
  prefs: []
  type: TYPE_NORMAL
- en: Writing idiomatic C++
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you're familiar with object-oriented programming languages, you must have
    heard of the Gang of Four's design patterns. While they can be implemented in
    C++ (and often are), this multi-paradigm language often takes a different approach
    for achieving the same goals. If you want to beat the performance of the so-called
    coffee-based languages such as Java or C#, sometimes paying the cost of virtual
    dispatch is too much. In many cases, you'll know upfront what types you'll deal
    with. If that happens, you can often write more performant code using the tools
    available both in the language and in the standard library. Out of many, there's
    a group that we will start this chapter with – the language idioms. Let's start
    our journey by looking at a few of them.
  prefs: []
  type: TYPE_NORMAL
- en: By definition, an idiom is a construct that recurs in a given language, an expression
    that's specific to the language. "Native speakers" of C++ should know its idioms
    by intuition. We already mentioned smart pointers, which are one of the most common
    ones. Let's now discuss a similar one.
  prefs: []
  type: TYPE_NORMAL
- en: Automating scope exit actions using RAII guards
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the most powerful expressions in C++ is the brace closing a scope. This
    is the place where destructors get called and the RAII magic happens. To tame
    this spell, you don't need to use smart pointers. All you need is an RAII guard
    – an object that, when constructed, will remember what it needs to do when destroyed.
    This way, regardless of whether the scope exits normally or by an exception, the
    work will happen automatically.
  prefs: []
  type: TYPE_NORMAL
- en: 'The best part – you don''t even need to write an RAII guard from scratch. Well-tested
    implementation already exists in various libraries. If you''re using GSL, which
    we mentioned in the previous chapter, you can use `gsl::finally()`. Consider the
    following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Here, we take a timestamp at the start of the function and another one at the
    end. Try running this example and see how uncommenting the `throw` statement affects
    the execution. In both cases, our RAII guard will properly print the execution
    time (assuming the exception is caught somewhere).
  prefs: []
  type: TYPE_NORMAL
- en: Let's now discuss a few more popular C++ idioms.
  prefs: []
  type: TYPE_NORMAL
- en: Managing copyability and movability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When designing a new type in C++, it's important to decide whether it should
    be copyable and movable. Even more important is implementing those semantics for
    a class correctly. Let's discuss those issues now.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing non-copyable types
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are cases when you don''t want your class to be copied. Classes that
    are very expensive to copy are one example. Another would be those subject to
    error due to slicing. In the past, a common way to prevent such objects from copying
    was by using the non-copyable idiom:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Note, however, that such a class is also not movable, although it''s easy to
    not notice it when reading the class definition. A better approach would be to
    just add the two missing members (the move constructor and move assignment operator)
    explicitly. As a rule of thumb, when declaring such special member functions,
    always declare all of them. This means that from C++11 onward, the preferred way
    would be to write the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This time, the members were defined directly in the target type without the
    helper `NonCopyable` type.
  prefs: []
  type: TYPE_NORMAL
- en: Adhering to the rules of three and five
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There''s one more thing to mention when discussing special member functions:
    if you don''t delete them and are providing your own implementations, most probably
    you need to define all of them, including the destructor, too. This was called
    the rule of three in C++98 (due to the need to define three functions: the copy
    constructor, the copy assignment operator, and the destructor) and since C++11''s
    move operations, it is now replaced by the rule of five (the two additional ones
    being the move constructor and the move assignment operator). Applying these rules
    can help you avoid resource management issues.'
  prefs: []
  type: TYPE_NORMAL
- en: Adhering to the rule of zero
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If, on the other hand, you''re good to go with just the default implementations
    of all special member functions, then just don''t declare them at all. This is
    a clear sign that you want the default behavior. It''s also the least confusing.
    Consider the following type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Even though we defaulted all the members, the class is still non-copyable.
    That''s because it has a `unique_ptr` member that is non-copyable itself. Fortunately,
    Clang will warn you about this, but GCC does not by default. A better approach
    would be to apply the rule of zero and instead write the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Now we have less boilerplate code and by looking at the members, it's easier
    to notice that it does not support copying.
  prefs: []
  type: TYPE_NORMAL
- en: There's one more important idiom to know about when it comes to copying that
    you'll get to know in a minute. Before that happens, we shall touch on yet another
    idiom, which can (and should) be used to implement the first one.
  prefs: []
  type: TYPE_NORMAL
- en: Using hidden friends
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In essence, hidden friends are non-member functions defined in the body of the
    type that declares them as a friend. This makes such functions impossible to call
    in ways other than by using **Argument-Dependent Lookup** (**ADL**), effectively
    making them hidden. Because they reduce the number of overloads a compiler considers,
    they also speed up compilation. A bonus of this is that they provide shorter error
    messages than their alternatives. Their last interesting property is that they
    cannot be called if an implicit conversion should happen first. This can help
    you avoid such accidental conversions.
  prefs: []
  type: TYPE_NORMAL
- en: Although friends in C++ are generally not recommended, things look differently
    for hidden friends; if the advantages from the previous paragraph don't convince
    you, you should also know that they should be the preferred way of implementing
    customization points. Now, you're probably wondering what those customization
    points are. Briefly speaking, they are callables used by the library code that
    the user can specialize in for their types. The standard library reserves quite
    a lot of names for those, such as `begin`, `end`, and their reverse and `const`
    variations, `swap`, `(s)size`, `(c)data`, and many operators, among others. If
    you decide to provide your own implementation for any of those customization points,
    it had better behave as the standard library expects.
  prefs: []
  type: TYPE_NORMAL
- en: 'Okay, enough theory for now. Let''s see how to provide a customization point
    specialization using a hidden friend in practice. For example, let''s create an
    oversimplified class to manage arrays of types:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we defined a destructor, which means we should provide other
    special member functions too. We implement them in the next section, using our
    hidden friend `swap`. Note that despite being declared in the body of our `Array`
    class, this `swap` function is still a non-member function. It accepts two `Array`
    instances and doesn't have access to this.
  prefs: []
  type: TYPE_NORMAL
- en: Using the `std::swap` line makes the compiler first look for `swap` functions
    in the namespaces of the swapped members. If not found, it will fall back to `std::swap`.
    This is called the *two-step ADL and fallback idiom*, or *two-step* for short,
    because we first make `std::swap` visible, and then call `swap`. The `noexcept`
    keyword tells the compiler that our `swap` function does not throw, which allows
    it to generate faster code in certain situations. Aside from `swap`, always mark
    your default and move constructors with this keyword too for the same reason.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a `swap` function, let's use it to apply another idiom to our
    `Array` class.
  prefs: []
  type: TYPE_NORMAL
- en: Providing exception safety using the copy-and-swap idiom
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we mentioned in the previous section, because our `Array` class defines a
    destructor, according to the rule of five, it should also define other special
    member functions. In this section, you'll learn about an idiom that lets us do
    this without boilerplate, while also adding strong exception safety as a bonus.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you''re not familiar with the exception safety levels, here''s a quick recap
    of the levels your functions and types can offer:'
  prefs: []
  type: TYPE_NORMAL
- en: '**No guarantee**: This is the most basic level. No guarantees are made about
    the state of your object after an exception is thrown while it''s being used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Basic exception safety**: Side effects are possible, but your object won''t
    leak any resources, will be in a valid state, and will contain valid data (not
    necessarily the same as before the operation). Your types should always offer
    at least this level.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Strong exception safety**: No side effects will happen. The object''s state
    will be the same as before the operation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**No-throw guarantee**: Operations will always succeed. If an exception is
    thrown during the operation, it will be caught and handled internally so the operation
    does not throw exceptions outside. Such operations can be marked as `noexcept`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, how can we kill these two birds with one stone and write no-boilerplate
    special members while also providing strong exception safety? It''s pretty easy,
    actually. As we have our `swap` function, let''s use it to implement the assignment
    operators:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In our case, a single operator suffices for both the copy and move assignments.
    In the copy case, we take the parameter by value, so this is where a temporary
    copy is being made. Then, all we need to do is swap the members. We have not only
    achieved strong exception safety but were also able to not throw from the assignment
    operator's body. However, an exception can still be thrown right before the function
    gets called, when the copy happens. In the case of the move assignment, no copy
    is made as taking by value will just take the moved object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s define the copy constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This guy can throw depending on `T` and because it allocates memory. Now, let''s
    define the move constructor too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Here, we use `std::exchange` so that our members get initialized and `other`'s
    members get cleaned up, all on the initialization list. The constructor is declared
    `noexcept` for performance reasons. For instance, `std::vector` can move their
    elements when they grow only if they're `noexcept` move-constructible, and will
    copy otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: That's it. We've created an `array` class providing strong exception safety
    with little effort and no code duplication.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now tackle yet another C++ idiom, which can be spotted in a few places
    in the standard library.
  prefs: []
  type: TYPE_NORMAL
- en: Writing niebloids
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Niebloids, named after Eric Niebler, are a type of function object that the
    standard uses for customization points from C++17 onward. With the introduction
    of standard ranges described in [Chapter 5](315eea2a-c029-4bc3-a159-4f897d393639.xhtml)*,
    Leveraging C++ Language Features*, their popularity started to grow, but they
    were first proposed by Niebler back in 2014\. **Their purpose is to disable ADL
    where it's not wanted so overloads from other namespaces are not considered by
    the compiler**. Remember the *two-step idiom* from the previous sections? Because
    it's inconvenient and easy to forget, the notion of *customization point objects*
    was introduced. In essence, these are function objects performing the *two-step*
    for you.
  prefs: []
  type: TYPE_NORMAL
- en: If your libraries should provide customization points, it's probably a good
    idea to implement them using niebloids. All the customization points in the standard
    library introduced in C++17 and later are implemented this way for a reason. Even
    if you just need to create a function object, still consider using niebloids.
    They offer all the good parts of ADL while reducing the drawbacks. They allow
    specialization and together with concepts they give you a way to customize the
    overload set of your callables. They also allow better customization of algorithms,
    all at the slight cost of writing a bit more verbose code than usual.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we''ll create a simple range algorithm that we''ll implement
    as a niebloid. Let''s call it `contains` as it will simply return a Boolean value
    denoting whether a given element is found in the range or not. First, let''s create
    the function object itself, starting with the declaration of its iterator-based
    call operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: It looks verbose, but all this code has a purpose. We make our struct `final`
    to aid the compiler in generating more efficient code. If you look at the template
    parameters, you'll see an iterator and a sentinel – the basic building blocks
    of each standard range. The sentinel is often an iterator, but it can be any semiregular
    type that can be compared with the iterator (a semiregular type is copyable and
    default-initializable). Next, `T` is the type of element to search for, while
    `Proj` denotes a projection – an operation to apply to each range element before
    comparison (the default of `std::identity` simply passes its input as output).
  prefs: []
  type: TYPE_NORMAL
- en: After the template parameters, there come the requirements for them; the operator
    requires that we can compare the projected value and the searched-for value for
    equality. After those constraints, we simply specify the function parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now see how it''s implemented:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Here, we simply iterate over the elements, invoking the projection on each element
    and comparing it with the searched-for value. We return `true` if found and `false`
    otherwise (when `first == last`).
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding function would work even if we didn''t use standard ranges; we
    also need an overload for ranges. Its declaration can be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This time, we take a type satisfying the `input_range` concept, the element
    value, and the type of projection as template parameters. We require that the
    range's iterator after calling the projection can be compared for equality with
    objects of type `T`, similarly as before. Finally, we use the range, the value,
    and the projection as our overload's parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'The body of this operator will be pretty straightforward, too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We simply call the previous overload using an iterator and sentinel from the
    given range, while passing the value and our projection unchanged. Now, for the
    last part, we need to provide a `contains` niebloid instead of just the `contains_fn`
    callable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'By declaring an inline variable named `contains` of type `contains_fn`, we
    allow anyone to call our niebloid using the variable name. Now, let''s call it
    ourselves to see whether it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: And that's it. Our ADL-inhibiting functor works as intended.
  prefs: []
  type: TYPE_NORMAL
- en: If you think all of this is a tad too verbose, then you might be interested
    in `tag_invoke`, which might become part of the standard at some point in the
    future. Refer to the *Further reading* section for a paper on this topic and a
    YouTube video that explains ADL, niebloids, hidden friends, and `tag_invoke` nicely.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now move on to yet another useful C++ idiom.
  prefs: []
  type: TYPE_NORMAL
- en: Policy-based design idiom
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Policy-based design was first introduced by Andrei Alexandrescu in his excellent
    *Modern C++ Design* book. Although published in 2001, many ideas showed in it
    are still used today. We recommend reading it; you can find it linked in the *Further
    reading* section at the end of this chapter. The policy idiom is basically a compile-time
    equivalent of the Gang of Four's Strategy pattern. If you need to write a class
    with customizable behavior, you can make it a template with the appropriate policies
    as template parameters. A real-world example of this could be standard allocators,
    passed as a policy to many C++ containers as the last template parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s return to our `Array` class and add a policy for debug printing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, we can use a default policy that won''t print anything. `NullPrintingPolicy`
    can be implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, regardless of the arguments given, it won't do anything. The
    compiler will completely optimize it out, so no overhead will be paid when the
    debug printing feature is not used.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want our class to be a bit more verbose, we can use a different policy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, we''ll simply print the text passed to the policy to `cout`. We
    also need to modify our class to actually use our policy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We simply call the policy's `operator()`, passing the text to be printed. Since
    our policies are stateless, we can instantiate it each time we need to use it
    without extra cost. An alternative could also be to just call a static function
    from it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, all we need to do is to instantiate our `Array` class with the desired
    policy and use it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: One drawback of using compile-timed policies is that the template instantiations
    using different policies are of different types. This means more work is required
    to, for instance, assign from a regular `Array` class to one with `CoutPrintingPolicy`.
    To do so, you would need to implement assignment operators as template functions
    with the policy as the template parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes an alternative to using policies is to use traits. As an example,
    take `std::iterator_traits`, which can be used to use various information about
    iterators when writing algorithms that use them. An example could be `std::iterator_traits<T>::value_type`,
    which can work for both custom iterators defining a `value_type` member, and simple
    ones such as pointers (in which case `value_type` would refer to the pointed-to
    type).
  prefs: []
  type: TYPE_NORMAL
- en: Enough about policy-based design. Next on our list is a powerful idiom that
    can be applied in multiple scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Curiously recurring template pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Despite having *pattern* in its name, the **Curiously Recurring Template Pattern**
    (**CRTP**) is an idiom in C++. It can be used to implement other idioms and design
    patterns and to apply static polymorphism, to name a few areas. Let's start with
    this last one as we'll cover the others later on.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing when to use dynamic versus static polymorphism
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When mentioning polymorphism, many programmers will think of dynamic polymorphism,
    where the information needed to perform a function call is gathered at runtime.
    In contrast to this, static polymorphism is about determining the calls at compile
    time. An advantage of the former is that you can modify the list of types at runtime,
    allowing extending your class hierarchies through plugins and libraries. The big
    advantage of the second is that it can get better performance if you know the
    types upfront. Sure, in the first case you can sometimes expect your compiler
    to devirtualize your calls, but you cannot always count on it doing so. However,
    in the second case, you can get longer compilation times.
  prefs: []
  type: TYPE_NORMAL
- en: Looks like you cannot win in all cases. Still, choosing the right type of polymorphism
    for your types can go a long way. If performance is at stake, we strongly suggest
    you consider static polymorphism. CRTP is an idiom that can be used to apply it.
  prefs: []
  type: TYPE_NORMAL
- en: Many design patterns can be implemented in one way or another. As the cost of
    dynamic polymorphism is not always worth it, the Gang of Four design patterns
    are often not the best solution in C++. If your type hierarchy should be extended
    at runtime, or compile times are a much bigger issue than performance for you
    (and you don't plan on using modules any time soon), then the classical implementations
    of the Gang of Four patterns may be a good fit. Otherwise, you can try to implement
    them using static polymorphism or by applying simpler C++-focused solutions, some
    of which we describe in this chapter. It's all about choosing the best tool for
    the job.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing static polymorphism
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s now implement our statically polymorphic class hierarchy. We''ll need
    a base template class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The template parameter for the base class is the derived class. This may seem
    odd at first, but it allows us to `static_cast` to the correct type in our interface
    function, in this case, named `appear_in_full_glory`. We then call the implementation
    of this function in a derived class. Derived classes could be implemented like
    so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Each of these classes derives from our `GlamorousItem` base class using itself
    as the template argument. Each also implements the required function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that, as opposed to dynamic polymorphism, the base class in CRTP is a
    template, so you''ll get a different base type for each of your derived classes.
    This means you can''t easily create a container of your `GlamorousItem` base class.
    What you can do, however, is several things:'
  prefs: []
  type: TYPE_NORMAL
- en: Store them in a tuple.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a `std::variant` of your derived classes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add one common class to wrap all instantiations of `Base`. You can use a variant
    for this one as well.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the first case, we could use the class as follows. First, create the tuple
    of instances of `base`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Our type-aliased tuple will be able to store any glamorous items. Now, all
    we need to do is to call the interesting function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Because we're trying to iterate a tuple, the easiest way to do so is to call
    `std::apply`, which invokes the given callable on all the elements of the given
    tuple. In our case, the callable is a lambda that accepts only `GlamorousItem`
    base class. We use fold expressions, introduced in C++17, to ensure our function
    will be called for all elements.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we were to use a variant instead of a tuple, we''d need to use `std::visit`,
    like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The `std::visit` function basically takes the variant and calls the passed lambda
    on the object stored in it. Here, we create an array of our glamorous variants,
    so we can just iterate over it like over any other container, visiting each variant
    with the appropriate lambda.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you find it not intuitive to write from the interface user''s perspective,
    consider this next approach, which wraps the variant into yet another class, in
    our case called `CommonGlamorousItem`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: To construct our wrapper, we use a forwarding constructor (`templated T&&` being
    its parameter). We then forward instead of moving to create the `item_` wrapped
    variant, as this way we only move r-value inputs. We also constrain the template
    parameters, so on one hand, we only wrap the `GlamorousItem` base class and on
    the other, our template is not used as a move or copy constructor.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also need to wrap our member function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, the `std::visit` call is an implementation detail. The user can
    use this wrapper class in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: This approach lets the user of the class write easy-to-understand code, but
    still keep the performance of static polymorphism.
  prefs: []
  type: TYPE_NORMAL
- en: To offer a similar user experience, albeit with worse performance, you can also
    use a technique called type erasure, which we'll discuss next.
  prefs: []
  type: TYPE_NORMAL
- en: Interlude – using type erasure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although type erasure isn't related to CRTP, it fits in nicely with our current
    example, which is why we're showing it here.
  prefs: []
  type: TYPE_NORMAL
- en: The type erasure idiom is about hiding the concrete type under a polymorphic
    interface. A great example of this approach can be found in Sean Parent's talk
    *Inheritance Is The Base Class of Evil* from the *GoingNative 2013* conference.
    We highly recommend you watch it in your spare time; you can find a link to it
    in the *Further reading* section. In the standard library, you can find it in
    `std::function`, `std::shared_ptr's deleter`, or `std::any`, among others.
  prefs: []
  type: TYPE_NORMAL
- en: The convenience of use and flexibility comes at a price – this idiom needs to
    use pointers and virtual dispatch, which makes the mentioned utilities from the
    standard library bad to use in performance-oriented use cases. Beware.
  prefs: []
  type: TYPE_NORMAL
- en: 'To introduce type erasure to our example, we no longer need CRTP. This time,
    our `GlamorousItem` class will wrap dynamically polymorphic objects in a smart
    pointer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, we store a pointer to base (`TypeErasedItemBase`), which will point
    to derived wrappers for our items (`TypeErasedItem<T>s`). The base class can be
    defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Each derived wrapper needs to implement this interface, too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The base class's interface is implemented by calling the function from the wrapped
    object. Note that the idiom is called "type erasure" because the `GlamorousItem`
    class doesn't know what `T` it is actually wrapping. The `information` type gets
    erased when the item gets constructed, but it all works because `T` implements
    the required methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'The concrete items can be implemented in a simpler manner, as shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This time, they don't need to inherit from any base. All we need is duck typing
    – if it quacks like a duck, it's probably a duck. And if it can appear in full
    glory, it's probably glamorous.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our type-erased API can be used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: We just create an array of our wrappers and iterate over it, all using simple,
    value-based semantics. We find it the most pleasant to use, as the polymorphism
    is hidden from the caller as an implementation detail.
  prefs: []
  type: TYPE_NORMAL
- en: However, a big drawback of this approach is, as we mentioned before, poor performance.
    Type erasure comes at a price, so it should be used sparingly and definitely not
    in the hot path.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've described how to wrap and erase types, let's switch to discussing
    how to create them.
  prefs: []
  type: TYPE_NORMAL
- en: Creating objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we'll discuss common solutions to problems related to object
    creation. We'll discuss various types of object factories, go through builders,
    and touch on composites and prototypes. However, we'll take a slightly different
    approach than the Gang of Four when describing their solutions. They proposed
    complex, dynamically polymorphic class hierarchies as proper implementations of
    their patterns. In the C++ world, many patterns can be applied to real-world problems
    without introducing as many classes and the overhead of dynamic dispatch. That's
    why in our case, the implementations will be different and in many cases simpler
    or more performant (although more specialized and less "generic" in the Gang of
    Four sense). Let's dive right in.
  prefs: []
  type: TYPE_NORMAL
- en: Using factories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first type of creational patterns we'll discuss here are factories. They're
    useful when the object construction can be done in a single step (a pattern useful
    if it cannot be covered right after factories), but when the constructor just
    isn't good enough on its own. There are three types of factories – factory methods,
    factory functions, and factory classes. Let's introduce them one by one.
  prefs: []
  type: TYPE_NORMAL
- en: Using factory methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Factory methods, also called the *named constructor idiom*, are basically member
    functions that call a private constructor for you. When do we use them? Here are
    a few scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '**When there are many different ways to construct an object, which would make
    errors likely**. For example, imagine constructing a class for storing different
    color channels for a given pixel; each channel is represented by a one-byte value.
    Using just a constructor would make it too easy to pass the wrong order of channels,
    or values meant for a different color palette entirely. Also, switching the pixel''s
    internal representation of colors would get tricky pretty fast. You could argue
    that we should have different types representing colors in those different formats,
    but often, using a factory method is a valid approach as well.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**When you want to force the object to be created on the heap or in another
    specific memory area**. If your object takes up loads of space on the stack and
    you''re afraid you''ll run out of stack memory, using a factory method is a solution.
    The same if you require all instances to be created in some area of memory on
    a device, for instance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**When constructing your object can fail, but you cannot throw exceptions**.
    You should use exceptions instead of other methods of error handling. When used
    properly, they can yield cleaner and better-performing code. However, some projects
    or environments require that exceptions are disabled. In such cases, using a factory
    method will allow you to report errors happening during construction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A factory method for the first case we described could look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'This class has two factory methods (actually, the C++ standard doesn''t recognize
    the term *method*, calling them *member functions* instead): `fromRgba` and `fromBgra`.
    Now it''s harder to make a mistake and initialize the channels in the wrong order.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that having a private constructor effectively inhibits any class from inheriting
    from your type, as without access to its constructor, no instances can be created.
    If that's your goal and not a side effect, however, you should prefer to just
    mark your class as final.
  prefs: []
  type: TYPE_NORMAL
- en: Using factory functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As opposed to using factory member functions, we can also implement them using
    non-member ones. This way, we can provide better encapsulation, as described by
    Scott Meyers in his article linked in the *Further reading* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of our `Pixel`, we could also create a free function to fabricate
    its instances. This way, our type could have simpler code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Using this approach makes our design conform to the open-closed principle described
    in [Chapter 1](475bdf95-9ad0-4bdc-9e5d-5083405fe48a.xhtml)*, Importance of Software
    Architecture and Principles of Great Design*. It's easy to add more factory functions
    for other color palettes without the need to modify the `Pixel` struct itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'This implementation of `Pixel` allows the user to initialize it by hand instead
    of using one of our provided functions. If we want, we can inhibit this behavior
    by changing the class declaration. Here''s how it could look after the fix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: This time, our factory functions are friends of our class. However, the type
    is no longer an aggregate, so we can no longer use aggregate initialization (`Pixel{}`),
    including designated initializers. Also, we gave up on the open-closed principle.
    The two approaches offer different trade-offs, so choose wisely.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the return type of a factory
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Yet another thing you should choose when implementing an object factory is the
    actual type it should return. Let's discuss the various approaches.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of `Pixel`, which is a value type and not a polymorphic one, the
    simplest approach works the best – we simply return by value. If you produce a
    polymorphic type, return it by a smart pointer (**never** use a naked pointer
    for this as this will yield memory leaks at some point). If the caller should
    own the created object, usually returning it in `unique_ptr` to the base class
    is the best approach. In the not-so-common cases where your factory and the caller
    must both own the object, use `shared_ptr` or another reference-counted alternative.
    Sometimes it's enough that the factory keeps track of the object but doesn't store
    it. In such cases, store `weak_ptr` inside the factory and return `shared_ptr`
    outside.
  prefs: []
  type: TYPE_NORMAL
- en: Some C++ programmers would argue that you should return specific types using
    an out parameter, but that's not the best approach in most cases. In the case
    of performance, returning by value is usually the best choice, as compilers will
    not make extra copies of your object. If the issue is with the type being non-copyable,
    from C++17 onward, the standard specifies where copy elision is mandatory, so
    returning such types by value is usually not an issue. If your function returns
    multiple objects, use a pair, tuple, struct, or container.
  prefs: []
  type: TYPE_NORMAL
- en: 'If something goes wrong during construction, you have several choices:'
  prefs: []
  type: TYPE_NORMAL
- en: Return `std::optional` of your type if there's no need to provide error messages
    to the caller.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Throw an exception if errors during construction are rare and should be propagated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Return `absl::StatusOr` of your type if errors during construction are common
    (see Abseil's documentation for this template in the *Further reading* section).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that you know what to return, let's discuss our last type of factories.
  prefs: []
  type: TYPE_NORMAL
- en: Using factory classes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Factory classes are types that can fabricate objects for us. They can help
    decouple polymorphic object types from their callers. They can allow for using
    object pools (in which reusable objects are kept so that you don''t need to constantly
    allocate and free them) or other allocation schemes. Those are just a few examples
    of how they can be useful. Let''s take a closer look at yet another one. Imagine
    you need to create different polymorphic types based on input parameters. In some
    cases, a polymorphic factory function such as the one shown next is not enough:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'What if we wanted to open other kinds of documents as well, such as OpenDocument
    text files? It may be ironic to discover that the preceding open factory is not
    open for extension. It might not be a big issue if we own the codebase, but if
    the consumers of our library need to register their own types, this can be an
    issue. To solve it, let''s use a factory class that will allow registering functions
    to open different kinds of documents, as shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The class doesn''t do much yet, but it has a map from extensions to functions
    that should be called to open files of given types. Now we''ll add two public
    member functions. The first one will register new file types:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we have a way of filling the map. The second new public function will open
    the documents using an appropriate opener:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Basically, we extract the extension from the file path, throw an exception if
    it's empty, and if not, we look for an opener in our map. If found, we use it
    to open the given file, and if not, the map will throw another exception for us.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can instantiate our factory and register custom file types such as the
    OpenDocument text format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we're registering a lambda because it can be converted to our `ConcreteOpener`
    type, which is a function pointer. However, if our lambda had state, this wouldn't
    be the case. In such a situation, we would need to use something to wrap us up.
    One such thing could be `std::function`, but the drawback of this would be the
    need to pay the cost of type erasure each time we would want to run the function.
    In the case of opening files, that's probably okay. If you need better performance,
    however, consider using a type such as `function_ref`.
  prefs: []
  type: TYPE_NORMAL
- en: An example implementation of this utility proposed to the C++ standard (not
    yet accepted) can be found on Sy Brand's GitHub repo referred to in the *Further
    reading* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Okay, now that we have our opener registered in the factory, let''s use it
    to open a file and extract some text out of it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: And that's all! If you want to provide the consumers of your library with a
    way to register their own types, they must have access to your map at runtime.
    You can either provide them with an API to reach it or make the factory static
    and allow them to register from anywhere in the code.
  prefs: []
  type: TYPE_NORMAL
- en: That does it for factories and building objects in a single step. Let's discuss
    another popular pattern to be used if factorys aren't a good fit.
  prefs: []
  type: TYPE_NORMAL
- en: Using builders
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Builders are similar to factories, a creational pattern coming from the Gang
    of Four. Unlike factories, they can help you build more complex objects: those
    that cannot be built in a single step, such as types assembled from many separate
    parts. They also provide you with a way to customize the construction of objects.
    In our case, we''ll skip designing complex hierarchies of builders. Instead, we''ll
    show how a builder can help. We''ll leave implementing hierarchies to you, as
    an exercise.'
  prefs: []
  type: TYPE_NORMAL
- en: Builders are needed when an object cannot be produced in a single step, but
    having a fluent interface can just make them pleasant to use if the single step
    is not trivial. Let's demonstrate creating fluent builder hierarchies using CRTP.
  prefs: []
  type: TYPE_NORMAL
- en: In our case, we'll create a CRTP, `GenericItemBuilder`, that we'll use as our
    base builder, and `FetchingItemBuilder`, which will be a more specialized one
    that can fetches data using a remote address if that's a supported feature. Such
    specializations can even live in different libraries, for instance, consuming
    different APIs that may or may not be available at build time.
  prefs: []
  type: TYPE_NORMAL
- en: 'For demo purposes, we''ll build instances of our `Item` struct from [Chapter
    5](315eea2a-c029-4bc3-a159-4f897d393639.xhtml)*, Leveraging C++ Language Features*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want, you can enforce that `Item` instances are built using a builder
    by making the default constructor private and making the builders friends:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Our builder''s implementation can be started as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Although it's generally not recommended to create protected members, we want
    our descendant builders to be able to reach our item. An alternative would be
    to use just the public methods of our base builder in derived ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'We take the name in the builder''s constructor, as it''s a single input coming
    from the user that needs to be set when we create our item. This way, we make
    sure that it will be set. An alternative would be to check whether it''s okay
    at the final stage of building, when the object is being released to the user.
    In our case, the build step can be implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: We enforce that the builder is "consumed" when this method is called; it must
    be an r-value. This means we can either use the builder in one line or move it
    in the last step to mark its end of work. We then set the creation time for our
    item and move it outside of the builder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our builder''s API could offer functions such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Each of them returns the concrete (derived) builder object as an r-value reference.
    Perhaps counterintuitively, this time such a return type should be preferred to
    returning by value. This is to avoid unnecessary copies of `item_` when building.
    On the other hand, returning by an l-value reference could lead to dangling references
    and would make calling `build()` harder because the returned l-value reference
    wouldn't match the expected r-value one.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final builder type could look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s just a class that reuses the constructors from our generic builder. It
    can be used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the final interface can be called using function chaining and
    the method names make the whole invocation fluent to read, hence the name *fluent
    interfaces*.
  prefs: []
  type: TYPE_NORMAL
- en: 'What if we were to not load each item directly, but rather use a more specialized
    builder that could load parts of the data from a remote endpoint? We could define
    it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'We also use CRTP to inherit from our generic builder and also enforce giving
    us a name. This time, however, we extend the base builder with our own function
    to fetch the contents and put them in the item we''re building. Thanks to CRTP,
    when we call a function from our base builder, we''ll get the derived one returned,
    which makes the interface much easier to use. It can be called in the following
    manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: All nice and dandy!
  prefs: []
  type: TYPE_NORMAL
- en: Builders can also come in handy if you need to always create immutable objects.
    As the builder has access to private members of the class, it can modify them,
    even if the class doesn't provide any setters for them. That's of course not the
    only case when you can benefit from using them.
  prefs: []
  type: TYPE_NORMAL
- en: Building with composites and prototypes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A case where you would need to use a builder is when creating a composite. A
    composite is a design pattern in which a group of objects is treated as one, all
    sharing the same interface (or the same base type). An example would be a graph,
    which you could compose out of subgraphs, or a document, which could nest other
    documents. When you would call `print()` on such an object, all its sub-objects
    would get their `print()` functions called in order to print the whole composite.
    The builder pattern can be useful for creating each sub-object and composing them
    all together.
  prefs: []
  type: TYPE_NORMAL
- en: 'Prototype is yet another pattern that can be used for object construction.
    If your type is very costly to create anew, or you just want to have a base object
    to build upon, you might want to use this pattern. It boils down to providing
    a way to clone your object, which you could later either use on its own or modify
    so it becomes what it should be. In the case of a polymorphic hierarchy, just
    add `clone()` like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Our `MapWithPointsOfInterests` object could clone the points too, so we don't
    need to re-add each of them manually. This way, we can have some default provided
    to the end user when they create their own map. Note also that in some cases,
    instead of using a prototype, a simple copy constructor would suffice.
  prefs: []
  type: TYPE_NORMAL
- en: We have now covered object creation. We touched on variants along the way, so
    why not revisit them (pun intended) to see how else they can help us?
  prefs: []
  type: TYPE_NORMAL
- en: Tracking state and visiting objects in C++
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: State is a design pattern meant to help change the behavior of an object when
    its internal state changes. The behavior for different states should be independent
    of each other so that adding new states doesn't affect the current ones. The simple
    approach of implementing all the behavior in the stateful object doesn't scale
    and is not open for extension. Using the state pattern, new behavior can be added
    by introducing new state classes and defining the transitions between them. In
    this section, we'll show a way to implement states and a state machine leveraging
    `std::variant` and statically polymorphic double dispatch. In other words, we'll
    build a finite state machine by joining the state and visitor patterns in a C++
    way.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s define our states. In our example, let''s model the states of
    a product in a store. They can be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Our states can have properties of their own, such as the count of items left.
    Also, as opposed to dynamically polymorphic ones, they don''t need to inherit
    from a common base. Instead, they are all stored in one variant, as shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Aside from states, we also need events for state transitions. Check the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, our events can also have properties and don''t inherit from
    a common base. Now, we need to implement the transitions between the states. This
    can be done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'If a purchase is made, the state can change, but it can also stay the same.
    We can also use templates to handle several states at once:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'If an item gets discontinued, it doesn''t matter what state it was in. Okay,
    let''s now implement the last supported transition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'The next piece of the puzzle we need is a way to define multiple call operators
    in one object generically so that the best matching overload can be called. We''ll
    use it later to call the transitions we just defined. Our helper can look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: We create an `overload` struct that will provide all the call operators passed
    to it during construction, using variable templates, a fold expression, and a
    class template argument deduction guide. For a more in-depth explanation of this,
    along with an alternative way of implementing visitation, refer to Bartłomiej
    Filipek's blog post in the *Further reading* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now start implementing the state machine itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Our `process_event` function will accept any of our defined events. It will
    call an appropriate `on_event` function using the current state and the passed
    event and switch to the new state. If an `on_event` overload is found for the
    given state and event, the first lambda will get called. Otherwise, the constraint
    won't be satisfied and the second, more generic overload will get called. This
    means if there's an unsupported state transition, we'll just throw an exception.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s provide a way to report the current state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Here, we use our overload to pass three lambdas, each returning a report string
    generated by visiting our state object.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now call our solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Upon running, this will yield the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: That is, unless you uncomment the last line with the unsupported transition,
    in which case an exception will be thrown at the end.
  prefs: []
  type: TYPE_NORMAL
- en: Our solution is much more performant than dynamic polymorphism-based ones, although
    the list of supported states and events is constrained to those provided at compile
    time. For more information on states, variants, and the various ways of visitations,
    see Mateusz Pusz's talk from CppCon 2018, also listed in the *Further reading*
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Before we close this chapter, one last thing we'd like for you to learn about
    is handling memory. Let's begin our last section.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with memory efficiently
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even if you don't have very limited memory, it's a good idea to look at how
    you use it. Usually, memory throughput is the performance bottleneck of modern-day
    systems, so it's always important to make good use of it. Performing too many
    dynamic allocations can slow down your program and lead to memory fragmentation.
    Let's learn a few ways to mitigate those issues.
  prefs: []
  type: TYPE_NORMAL
- en: Reducing dynamic allocations using SSO/SOO
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Dynamic allocations can sometimes cause you other trouble than just throwing
    when you construct objects despite not having enough memory. They often cost you
    CPU cycles and can cause memory fragmentation. Fortunately, there is a way to
    protect against it. If you''ve ever used `std::string` (post GCC 5.0), you most
    probably used an optimization called **Small String Optimization** (**SSO**).
    This is one example of a more general optimization named **Small Object Optimization**
    (**SSO**), which can be spotted in types such as Abseil''s InlinedVector. The
    main idea is pretty straightforward: if the dynamically allocated object is small
    enough, it should be stored inside the class that owns it instead of being dynamically
    allocated. In `std::string`''s case, usually, there''s a capacity, length, and
    the actual string to store. If the string is short enough (in GCC''s case, on
    64-bit platforms, it''s 15 bytes), it will be stored in some of those members.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Storing objects in place instead of allocating them somewhere else and storing
    just the pointer has one more benefit: less pointer chasing. Each time you need
    to reach to data stored behind a pointer, you increase the pressure on the CPU
    caches and risk needing to fetch data from the main memory. If this is a common
    pattern, it can influence the overall performance of your app, especially if the
    pointed-to addresses aren''t guessed by the CPU''s prefetcher. Using techniques
    such as SSO and SOO are invaluable in reducing those issues.'
  prefs: []
  type: TYPE_NORMAL
- en: Saving memory by herding COWs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you used GCC's `std::string` before GCC 5.0, you might have used a different
    optimization called **Copy-On-Write** (**COW**). The COW string implementation,
    when it had multiple instances created with the same underlying character array,
    was actually sharing the same memory address for it. When the string was written
    to, the underlying storage was copied — hence the name.
  prefs: []
  type: TYPE_NORMAL
- en: This technique helped save memory and keep the caches hot, and often offered
    solid performance on a single thread. Beware of using it in multi-threaded contexts,
    though. The need for using locks can be a real performance killer. As with any
    performance-related topic, it's best to just measure whether in your case it's
    the best tool for the job.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now discuss a feature of C++17 that can help you achieve good performance
    with dynamic allocations.
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging polymorphic allocators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The feature we're talking about is polymorphic allocators. To be specific, the
    `std::pmr::polymorphic_allocator` and the polymorphic `std::pmr::memory_resource`
    class that the allocator uses to allocate memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'In essence, it allows you to easily chain memory resources to make the best
    use of your memory. Chains can be as simple as one resource that reserves a big
    chunk and distributes it, falling back to another that simply calls `new` and
    `delete` if it depletes memory. They can also be much more complex: you can build
    a long chain of memory resources that handle pools of different sizes, offer thread-safety
    only when needed, bypass the heap and go for the system''s memory directly, return
    you the last freed chunk of memory to provide cache hotness, and do other fancy
    stuff. Not all of these capabilities are offered by the standard polymorphic memory
    resources, but thanks to their design, it''s easy to extend them.'
  prefs: []
  type: TYPE_NORMAL
- en: Let's first tackle the topic of memory arenas.
  prefs: []
  type: TYPE_NORMAL
- en: Using memory arenas
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A memory arena, also called a region, is just a large chunk of memory that exists
    for a limited time. You can use it to allocate smaller objects that you use for
    the lifetime of the arena. Objects in the arena can be either deallocated as usual
    or erased all at once in a process called *winking out*. We'll describe it later
    on.
  prefs: []
  type: TYPE_NORMAL
- en: Arenas have several great advantages over the usual allocations and deallocations
    – they increase performance because they limit the memory allocations that need
    to grab upstream resources. They also reduce fragmentation of memory, because
    any fragmentation that would happen will happen inside the arena. Once an arena's
    memory is released, the fragmentation is no more as well. A great idea is to create
    separate arenas per thread. If only a single thread uses an arena, it doesn't
    need to use any locking or other thread-safety mechanisms, reducing thread contention
    and giving you a nice boost in performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'If your program is single-threaded, a low-cost solution to increase its performance
    could be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: The default resource if you won't set any explicitly will be `new_delete_resource`,
    which calls `new` and `delete` each time just like regular `std::allocator` does,
    and with all the thread-safety it provides (and costs).
  prefs: []
  type: TYPE_NORMAL
- en: 'If you use the preceding code snippet, all the allocations done using `pmr`
    allocators would be done with no locks. You still need to actually use the `pmr`
    types, though. To do so with standard containers, for instance, you need to simply
    pass `std::pmr::polymorphic_allocator<T>` as the allocator template parameter.
    Many standard containers have `pmr`-enabled type aliases. The two variables created
    next are of the same type and both will use the default memory resource:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: The first one gets the resource passed explicitly, though. Let's now go through
    the resources available in `pmr`.
  prefs: []
  type: TYPE_NORMAL
- en: Using the monotonic memory resource
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first one we'll discuss is `std::pmr::monotonic_buffer_resource`. It's a
    resource that only allocates memory and doesn't do anything on deallocation. It
    will only deallocate memory when the resource is destructed or on an explicit
    call to `release()`. This, connected with no thread safety, makes this type extremely
    performant. If your application occasionally needs to perform a task that does
    lots of allocations on a given thread, then releases all the objects used at once
    afterward, using monotonic resources will yield great gains. It's also a great
    base building block for chains of resources.
  prefs: []
  type: TYPE_NORMAL
- en: Using pool resources
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A common combo of two resources is to use a pool resource on top of a monotonic
    buffer resource. The standard pool resources create pools of different-sized chunks.
    There are two types in `std::pmr`, `unsynchronized_pool_resource` for use when
    only one thread allocates and deallocates from it and `synchronized_pool_resource`
    for multi-threaded use. Both should provide you with much better performance compared
    to the global allocator, especially when using the monotonic buffer as their upstream
    resource. If you wonder how to chain them, here''s how:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: We create a 1 MB buffer for the arena to reuse. We pass it to a monotonic resource,
    which is then passed to an unsynchronized pool resource, creating a simple yet
    efficient chain of allocators that won't call new until all the initial buffer
    is used up.
  prefs: []
  type: TYPE_NORMAL
- en: You can pass a `std::pmr::pool_options` object to both the pool types to limit
    the max count of blocks of a given size (`max_blocks_per_chunk`) or the size of
    the largest block (`largest_required_pool_block`). Passing 0 causes the implementation's
    default to be used. In the case of GCC's library, the actual blocks per chunk
    differ depending on the block size. If the max size is exceeded, the pool resource
    will allocate directly from its upstream resource. It also goes to the upstream
    resource if the initial memory was depleted. In this case, it allocates geometrically
    growing chunks of memory.
  prefs: []
  type: TYPE_NORMAL
- en: Writing your own memory resource
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If the standard memory resources don't suit all your needs, you can always create
    a custom one quite simply. For instance, a good optimization that not all standard
    library implementations offer is to keep track of the last chunks of a given size
    that were released and return them back on the next allocations of given sizes.
    This `Most Recently Used` cache can help you increase the hotness of data caches,
    which should help your app's performance. You can think of it as a set of LIFO
    queues for chunks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes you might also want to debug allocations and deallocations. In the
    following snippet, I have written a simple resource that can help you with this
    task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Our verbose resource inherits from the polymorphic base resource. It also accepts
    an upstream resource, which it will use for actual allocations. It has to implement
    three private functions – one for allocating, one for deallocating, and one for
    comparing instances of the resource itself. Here''s the first one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'All it does is print the allocation size on the standard output and then use
    the upstream resource to allocate memory. The next one will be similar:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'We log how much memory we deallocate and use the upstream to perform the task.
    Now the last required function is stated next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: We simply compare the addresses of the instances to know whether they're equal.
    The `[[nodiscard]]` attribute helps us be sure that the caller actually consumes
    the returned value, which can help us avoid accidental misuse of our function.
  prefs: []
  type: TYPE_NORMAL
- en: That's it. For a powerful feature such as the `pmr` allocators, the API isn't
    that complex now, isn't it?
  prefs: []
  type: TYPE_NORMAL
- en: Aside from tracking allocations, we can also use `pmr` to guard us against allocating
    when we shouldn't.
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring there are no unexpected allocations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The special `std::pmr::null_memory_resource()` will throw an exception when
    anyone tries to allocate memory using it. You can safeguard from performing any
    allocations using `pmr` by setting it as the default resource as shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also use it to limit allocation from the upstream when it shouldn''t
    happen. Check the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: If anybody tries to allocate more than the buffer size we set, `std::bad_alloc`
    would be thrown.
  prefs: []
  type: TYPE_NORMAL
- en: Let's move on to our last item in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Winking out memory
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sometimes not having to deallocate the memory, as the monotonic buffer resource
    does, is still not enough for performance. A special technique called *winking*
    out can help here. Winking out objects means that they're not only not deallocated
    one by one, but their constructors aren't called too. The objects simply evaporate,
    saving time that would normally be spent calling destructors for each object and
    their members (and their members...) in the arena.
  prefs: []
  type: TYPE_NORMAL
- en: 'NOTE: This is an advanced topic. Be careful when using this technique, and
    only use it if the possible gain is worth it.'
  prefs: []
  type: TYPE_NORMAL
- en: This technique can save your precious CPU cycles, but it's not always possible
    to use it. Avoid winking out memory if your objects handle resources other than
    memory. Otherwise, you will get resource leaks. The same goes if you depend on
    any side effects the destructors of your objects would have.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now see winking out in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: Here, we created a polymorphic allocator by hand that'll use our default resource
    – a monotonic one that logs each time it reaches upstream. To create objects,
    we'll use a C++20 addition to `pmr`, the `new_object` function. We create a vector
    of strings. We can pass the first one using `push_back`, because it's small enough
    to fit into the small-string buffer we have thanks to SSO. The second string would
    need to allocate a string using the default resource and only then pass it to
    our vector if we used `push_back`. Emplacing it causes the string to be constructed
    inside the vector's functions (not before the call), so it will use the vector's
    allocator. Finally, we don't call the destructors of allocated objects anywhere,
    and just deallocate everything at once, when we exit the scope. This should give
    us hard-to-beat performance.
  prefs: []
  type: TYPE_NORMAL
- en: That was the last item on our list for this chapter. Let's summarize what we've
    learned.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we went through various idioms and patterns used in the C++
    world. You should now be able to write fluent, idiomatic C++. We've demystified
    how to perform automatic cleanup. You can now write safer types that properly
    move, copy, and swap. You learned how to use ADL to your advantage both with compilation
    times and writing customization points. We discussed how to choose between static
    and dynamic polymorphism. We also learned how to introduce policies to your types,
    when to use type erasure, and when not.
  prefs: []
  type: TYPE_NORMAL
- en: What's more, we discussed how to create objects using factories and fluent builders.
    Moreover, using memory arenas for this is also no longer arcane magic. So is writing
    state machines using tools such as variants.
  prefs: []
  type: TYPE_NORMAL
- en: We did all that as well as touching on extra topics down the road. Phew! The
    next stop on our journey will be about building your software and packaging it.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What are the rules of three, five, and zero?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When do we use niebloids versus hidden friends?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can arrays interfaces be improved to be more production-ready?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are fold expressions?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When shouldn't you use static polymorphism?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can we save on one more allocation in the winking out example?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*tag_invoke: A general pattern for supporting customisable functions*, Lewis
    Baker, Eric Niebler, Kirk Shoop, ISO C++ proposal, [https://wg21.link/p1895](https://wg21.link/p1895)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*tag_invoke :: niebloids evolved*, Gašper Ažman for the Core C++ Conference,
    YouTube video, [https://www.youtube.com/watch?v=oQ26YL0J6DU](https://www.youtube.com/watch?v=oQ26YL0J6DU)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Inheritance Is The Base Class of Evil*, Sean Parent for the GoingNative 2013
    Conference, Channel9 video, [https://channel9.msdn.com/Events/GoingNative/2013/Inheritance-Is-The-Base-Class-of-Evil](https://channel9.msdn.com/Events/GoingNative/2013/Inheritance-Is-The-Base-Class-of-Evil)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Modern C++ Design*, Andrei Alexandrescu, Addison-Wesley, 2001'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*How Non-Member Functions Improve Encapsulation*, Scott Meyers, Dr. Dobbs article,
    [https://www.drdobbs.com/cpp/how-non-member-functions-improve-encapsu/184401197](https://www.drdobbs.com/cpp/how-non-member-functions-improve-encapsu/184401197)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Returning a Status or a Value*, Status User Guide, Abseil documentation, [https://abseil.io/docs/cpp/guides/status#returning-a-status-or-a-value](https://abseil.io/docs/cpp/guides/status#returning-a-status-or-a-value)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`function_ref`, GitHub repository, [https://github.com/TartanLlama/function_ref](https://github.com/TartanLlama/function_ref)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*How To Use std::visit With Multiple Variants*, Bartłomiej Filipek, post on
    Bartek''s coding blog, [https://www.bfilipek.com/2018/09/visit-variants.html](https://www.bfilipek.com/2018/09/visit-variants.html)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'CppCon 2018: Mateusz Pusz, *Effective replacement of dynamic polymorphism with
    std::variant*, YouTube video, [https://www.youtube.com/watch?v=gKbORJtnVu8](https://www.youtube.com/watch?v=gKbORJtnVu8)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
