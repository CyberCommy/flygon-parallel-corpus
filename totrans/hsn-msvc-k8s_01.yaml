- en: Introduction to Kubernetes for Developers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will introduce you to Kubernetes. Kubernetes is a big platform
    and it''s difficult to do justice to it in just one chapter. Luckily, we have
    a whole book to explore it. Don''t worry if you feel a little overwhelmed. I''ll
    mention many concepts and capabilities briefly. In later chapters, we will cover
    many of these in detail, as well as the connections and interactions between those
    Kubernetes concepts. To spice things up and get hands-on early, you will also
    create a local Kubernetes cluster (Minikube) on your machine. This chapter will
    cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes in a nutshell
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Kubernetes architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes and microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a local cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, you will need the following tools:'
  prefs: []
  type: TYPE_NORMAL
- en: Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubectl
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minikube
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To install Docker, follow the instructions here: [https://docs.docker.com/install/#supported-platforms](https://docs.docker.com/install/#supported-platforms). I
    will use Docker for macOS.
  prefs: []
  type: TYPE_NORMAL
- en: Installing kubectl
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To install kubectl, follow the instructions here: [https://kubernetes.io/docs/tasks/tools/install-kubectl/](https://kubernetes.io/docs/tasks/tools/install-kubectl/).'
  prefs: []
  type: TYPE_NORMAL
- en: Kubectl is the Kubernetes CLI and we will use it extensively throughout the
    book.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Minikube
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To install Minikube, follow the instructions here: [https://kubernetes.io/docs/tasks/tools/install-minikube/](https://kubernetes.io/docs/tasks/tools/install-minikube/).'
  prefs: []
  type: TYPE_NORMAL
- en: Note that you need to install a hypervisor too. For the macOS, I find VirtualBox
    the most reliable. You may prefer another hypervisor, such as HyperKit. There
    will be more detailed instructions later when you get to play with Minikube.
  prefs: []
  type: TYPE_NORMAL
- en: The code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The code for the chapter is available here: [https://github.com/PacktPublishing/Hands-On-Microservices-with-Kubernetes/tree/master/Chapter01](https://github.com/PacktPublishing/Hands-On-Microservices-with-Kubernetes/tree/master/Chapter01)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is another Git repository for the Delinkcious sample application that
    we will build together: [https://github.com/the-gigi/delinkcious](https://github.com/the-gigi/delinkcious)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes in a nutshell
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, you'll get a sense of what Kubernetes is all about, its history,
    and how it became so popular.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes – the container orchestration platform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The primary function of Kubernetes is deploying and managing a large number
    of container-based workloads on a fleet of machines (physical or virtual). This
    means that Kubernetes provides the means to deploy containers to the cluster.
    It makes sure to comply with various scheduling constraints and pack the containers
    efficiently into the cluster nodes. In addition, Kubernetes automatically watches
    your containers and restarts them if they fail. Kubernetes will also relocate
    workloads off problematic nodes to other nodes. Kubernetes is an extremely flexible
    platform. It relies on a provisioned infrastructure layer of compute, memory,
    storage, and networking, and, with these resources, it works its magic.
  prefs: []
  type: TYPE_NORMAL
- en: The history of Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes and the entire cloud-native scene is moving at breakneck speed, but
    let's take a moment to reflect on how we got here. It will be a very short journey
    because Kubernetes came out of Google in June 2014, just a few years ago. When
    Docker became popular, it changed how people package, distribute, and deploy software.
    But, it soon became apparent that Docker doesn't scale on its own for large distributed
    systems. A few orchestration solutions became available, such as Apache Mesos,
    and later, Docker's own swarm. But, they never measured up to Kubernetes. Kubernetes
    was conceptually based on Google's Borg system. It brought together the design
    and technical excellence of a decade of Google engineering, but it was a new open
    source project. At OSCON 2015, Kubernetes 1.0 was released and the floodgates
    opened. The growth of Kubernetes, its ecosystem, and the community behind it,
    was as impressive as its technical excellence.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes means helmsman in Greek. You'll notice many nautical terms in the
    names of Kubernetes-related projects.
  prefs: []
  type: TYPE_NORMAL
- en: The state of Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes is now a household name. The DevOps world pretty much equates container
    orchestration with Kubernetes. All major cloud providers offer managed Kubernetes
    solutions. It is ubiquitous in enterprise and in startup companies. While Kubernetes
    is still young and innovation keeps happening, it is all happening in a very healthy
    way. The core is rock solid, battle tested, and used in production across lots
    and lots of companies. There are very big players collaborating and pushing Kubernetes
    forward, such as Google (obviously), Microsoft, Amazon, IBM, and VMware.
  prefs: []
  type: TYPE_NORMAL
- en: The **Cloud Native Computing Foundation** (**CNCF**) open source organization
    offers certification. Every 3 months, a new Kubernetes release comes out, which
    is the result of a collaboration between hundreds of volunteers and paid engineers.
    There is a large ecosystem surrounding the main project of both commercial and
    open source projects. You will see later how Kubernetes' flexible and extensible
    design encourages this ecosystem and helps in integrating Kubernetes into any
    cloud platform.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the Kubernetes architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes is a marvel of software engineering. The architecture and design
    of Kubernetes are a big part in its success. Each cluster has a control plane
    and data plane. The control plane consists of several components, such as an API
    server, a metadata store for keeping the state of a cluster, and multiple controllers
    that are responsible for managing the nodes in the data plane and providing access
    to users. The control plane in production will be distributed across multiple
    machines for high availability and robustness. The data plane consists of multiple
    nodes, or workers. The control plane will deploy and run your pods (groups of
    containers) on these nodes, and then watch for changes and respond.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a diagram that illustrates the overall architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/f4c49543-afdd-4a9f-98df-ec49113430c1.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's review in detail the control plane and the data plane, as well as kubectl,
    which is the command-line tool you use to interact with the Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: The control plane
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The control plane consists of several components:'
  prefs: []
  type: TYPE_NORMAL
- en: API server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The etcd metadata store
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scheduler
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Controller manager
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud controller manager
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's examine the role of each component.
  prefs: []
  type: TYPE_NORMAL
- en: The API server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **kube-api-server** is a massive REST server that exposes the Kubernetes
    API to the world. You can have multiple instances of the API server in your control
    plane for high-availability. The API server keeps the cluster state in etcd.
  prefs: []
  type: TYPE_NORMAL
- en: The etcd store
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The complete cluster is stored in etcd ([https://coreos.com/etcd/](https://coreos.com/etcd/)),
    a consistent and reliable, distributed key-value store. The **etcd store** is
    an open source project (developed by CoreOS, originally).
  prefs: []
  type: TYPE_NORMAL
- en: It is common to have three or five instances of etcd for redundancy. If you
    lose the data in your etcd store, you lose your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: The scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **kube-scheduler** is responsible for scheduling pods to worker nodes. It
    implements a sophisticated scheduling algorithm that takes a lot of information
    into account, such as resource availability on each node, various constraints
    specified by the user, types of available nodes, resource limits and quotas, and
    other factors, such as affinity, anti-affinity, tolerations, and taints.
  prefs: []
  type: TYPE_NORMAL
- en: The controller manager
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **kube-controller manager** is a single process that contains multiple
    controllers for simplicity. These controllers watch for events and changes to
    the cluster and respond accordingly:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Node controller**: Responsible for noticing and responding when nodes go
    down.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Replication controller**: This makes sure that there is the correct number
    of pods for each replica set or replication controller object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Endpoints controller**: This assigns for each service an endpoints object
    that lists the service''s pods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service account and token controllers**: These initialize new namespaces
    with default service accounts and corresponding API access tokens.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The data plane
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The data plane is the collection of the nodes in the cluster that run your
    containerized workloads as pods. The data plane and control plane can share physical
    or virtual machines. This happens, of course, when you run a single node cluster,
    such as Minikube. But, typically, in a production-ready deployment, the data plane
    will have its own nodes. There are several components that Kubernetes installs
    on each node in order to communicate, watch, and schedule pods: kubelet, kube-proxy,
    and the container runtime (for example, the Docker daemon).'
  prefs: []
  type: TYPE_NORMAL
- en: The kubelet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **kubelet** is a Kubernetes agent. It''s responsible for talking to the
    API server and for running and managing the pods on the node. Here are some of
    the responsibilities of the kubelet:'
  prefs: []
  type: TYPE_NORMAL
- en: Downloading pod secrets from the API server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mounting volumes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running the pod container via the **Container Runtime Interface** (**CRI**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reporting the status of the node and each pod
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Probe container liveness
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The kube proxy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The kube proxy is responsible for the networking aspects of the node. It operates
    as a local front for services and can forward TCP and UDP packets. It discovers
    the IP addresses of services via DNS or environment variables.
  prefs: []
  type: TYPE_NORMAL
- en: The container runtime
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes eventually runs containers, even if they are organized in pods. Kubernetes
    supports different container runtimes. Originally, only Docker was supported.
    Now, Kubernetes runs containers through an interface called **CRI**, which is
    based on **gRPC**.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/b7e399a7-6d2c-4e1b-b8d3-6393bb8136c0.png)'
  prefs: []
  type: TYPE_IMG
- en: Each container runtime that implements CRI can be used on a node controlled
    by the **kubelet**, as shown in the preceding diagram.
  prefs: []
  type: TYPE_NORMAL
- en: Kubectl
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Kubectl** is a tool you should get very comfortable with. It is your **command-line
    interface** (**CLI**) to your Kubernetes cluster. We will use kubectl extensively
    throughout the book to manage and operate Kubernetes. Here is a short list of
    the capabilities kubectl puts literally at your fingertips:'
  prefs: []
  type: TYPE_NORMAL
- en: Cluster management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Troubleshooting and debugging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resource management (Kubernetes objects)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuration and metadata
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Just type `kubectl` to get a complete list of all the commands and `kubectl
    <command> --help` for more detailed info on specific commands.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes and microservices – a perfect match
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes is a fantastic platform with amazing capabilities and a wonderful
    ecosystem. How does it help you with your system? As you'll see, there is a very
    good alignment between Kubernetes and microservices. The building blocks of Kubernetes,
    such as namespaces, pods, deployments, and services, map directly to important
    microservices concepts and an agile **software development life cycle** (**SDLC**).
    Let's dive in.
  prefs: []
  type: TYPE_NORMAL
- en: Packaging and deploying microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you employ a microservice-based architecture, you'll have lots of microservices.
    Those microservices, in general, may be developed independently, and deployed
    independently. The packaging mechanism is simply containers. Every microservice
    you develop will have a Dockerfile. The resulting image represents the deployment
    unit for that microservice. In Kubernetes, your microservice image will run inside
    a pod (possibly alongside other containers). But an isolated pod, running on a
    node, is not very resilient. The kubelet on the node will restart the pod's container
    if it crashes, but if something happens to the node itself, the pod is gone. Kubernetes
    has abstractions and resources that build on the pod.
  prefs: []
  type: TYPE_NORMAL
- en: '**ReplicaSets** are sets of pods with a certain number of replicas. When you
    create a ReplicaSet, Kubernetes will make sure that the correct number of pods
    you specify always run in the cluster. The deployment resource takes it a step
    further and provides an abstraction that exactly aligns with the way you consider
    and think about microservices. When you have a new version of a microservice ready,
    you will want to deploy it. Here is a Kubernetes deployment manifest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The file can be found at [https://github.com/the-gigi/hands-on-microservices-with-kubernetes-code/blob/master/ch1/nginx-deployment.yaml.](https://github.com/the-gigi/hands-on-microservices-with-kubernetes-code/blob/master/ch1/nginx-deployment.yaml)
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a YAML file ([https://yaml.org/](https://yaml.org/)) that has some
    fields that are common to all Kubernetes resources, and some fields that are specific
    to deployments. Let''s break this down piece by piece. Almost everything you learn
    here will apply to other resources:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `apiVersion` field marks the Kubernetes resources version. A specific version
    of the Kubernetes API server (for example, V1.13.0) can work with different versions
    of different resources. Resource versions have two parts: an API group (in this
    case, `apps`) and a version number (`v1`). The version number may include **alpha**
    or **beta** designations:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The `kind` field specifies what resource or API object we are dealing with.
    You will meet many kinds of resources in this chapter and later:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The `metadata` section contains the name of the resource (`nginx`) and a set
    of labels, which are just key-value string pairs. The name is used to refer to
    this particular resource. The labels allow for operating on a set of resources
    that share the same label. Labels are very useful and flexible. In this case,
    there is just one label (`app: nginx`):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we have a `spec` field. This is a ReplicaSet `spec`. You could create
    a ReplicaSet directly, but it would be static. The whole purpose of deployments
    is to manage its set of replicas. What''s in a ReplicaSet spec? Obviously, it
    contains the number of `replicas` (`3`). It has a selector with a set of `matchLabels`
    (also `app: nginx`), and it has a pod template. The ReplicaSet will manage pods
    that have labels that match `matchLabels`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s have a look at the pod template. The template has two parts: `metadata`
    and a `spec`. The `metadata` is where you specify the labels. The `spec` describes
    the `containers` in the pod. There may be one or more containers in a pod. In
    this case, there is just one container. The key field for a container is the image
    (often a Docker image), where you packaged your microservice. That''s the code
    we want to run. There is also a name (`nginx`) and a set of ports:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: There are more fields that are optional. If you want to dive in deeper, check
    out the API reference for the deployment resource at [https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.13/#deployment-v1-apps](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.13/#deployment-v1-apps).
  prefs: []
  type: TYPE_NORMAL
- en: Exposing and discovering microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We deployed our microservice with a deployment. Now, we need to expose it,
    so that it can be used by other services in the cluster and possibly also make
    it visible outside the cluster. Kubernetes provides the `Service` resource for
    that purpose. Kubernetes services are backed up by pods, identified by labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Services discover each other inside the cluster, using DNS or environment variables.
    This is the default behavior. But, if you want to make a service accessible to
    the world, you will normally set an ingress object or a load balancer. We will
    explore this topic in detail later.
  prefs: []
  type: TYPE_NORMAL
- en: Securing microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes was designed for running large-scale critical systems, where security
    is of paramount concern. Microservices are often more challenging to secure than
    monolithic systems because there is so much internal communication across many
    boundaries. Also, microservices encourage agile development, which leads to a
    constantly changing system. There is no steady state you can secure once and be
    done with it. You must constantly adapt the security of the system to the changes.
    Kubernetes comes pre-packed with several concepts and mechanisms for secure development,
    deployment, and operation of your microservices. You still need to employ best
    practices, such as principle of least privilege, security in depth, and minimizing
    blast radius. Here are some of the security features of Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Namespaces
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Namespaces let you isolate different parts of your cluster from each other.
    You can create as many namespaces as you want and scope many resources and operations
    to their namespace, including limits, and quotas. Pods running in a namespace
    can only access directly their own namespace. To access other namespaces, they
    must go through public APIs.
  prefs: []
  type: TYPE_NORMAL
- en: Service accounts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Service accounts provide identity to your microservices. Each service account
    will have certain privileges and access rights associated with its account. Service
    accounts are pretty simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: You can associate service accounts with a pod (for example, in the pod `spec`
    of a deployment) and the microservices that run inside the pod will have that
    identity and all the privileges and restrictions associated with that account.
    If you don't assign a service account, then the pod will get the default service
    account of its namespace. Each service account is associated with a secret used
    to authenticate it.
  prefs: []
  type: TYPE_NORMAL
- en: Secrets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes provides secret management capabilities to all microservices. The
    secrets can be encrypted at rest on etcd (since Kubernetes 1.7), and are always
    encrypted on the wire (over HTTPS). Secrets are managed per namespace. Secrets
    are mounted in pods as either files (secret volumes) or environment variables.
    There are multiple ways to create secrets. Secrets can contain two maps: `data`
    and `stringData`. The type of values in the data map can be arbitrary, but must
    be base64-encoded. Refer to the following, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is how a pod can load secrets as a volume:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The end result is that the DB credentials secrets that are managed outside the
    pod by Kubernetes show up as a regular file inside the pod accessible through
    the path `/etc/db_creds`.
  prefs: []
  type: TYPE_NORMAL
- en: Secure communication
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes utilizes client-side certificates to fully authenticate both sides
    of any external communication (for example, kubectl). All communication to the
    Kubernetes API from outside should be over HTTP. Internal cluster communication
    between the API server and the kubelet on the node is over HTTPS too (the kubelet
    endpoint). But, it doesn't use a client certificate by default (you can enable
    it).
  prefs: []
  type: TYPE_NORMAL
- en: Communication between the API server and nodes, pods, and services is, by default,
    over HTTP and is not authenticated. You can upgrade them to HTTPS, but note that
    the client certificate is checked, so don't run your worker nodes on public networks.
  prefs: []
  type: TYPE_NORMAL
- en: Network policies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a distributed system, beyond securing each container, pod, and node, it is
    critical to also control communication over the network. Kubernetes supports network
    policies, which give you full flexibility to define and shape the traffic and
    access across the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Authenticating and authorizing microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Authentication and authorization are also related to security, by limiting access
    to trusted users and to limited aspects of Kubernetes. Organizations have a variety
    of ways to authenticate their users. Kubernetes supports many of the common authentication
    schemes, such as X.509 certificates, and HTTP basic authentication (not very secure),
    as well as an external authentication server via webhook that gives you ultimate
    control over the authentication process. The authentication process just matches
    the credentials of a request with an identity (either the original or an impersonated
    user). What that user is allowed to do is controlled by the authorization process.
    Enter RBAC.
  prefs: []
  type: TYPE_NORMAL
- en: Role-based access control
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Role-based access control** (**RBAC**) is not required! You can perform authorization
    using other mechanisms in Kubernetes. However, it is a best practice. RBAC is
    based on two concepts: role and binding. A role is a set of permissions on resources
    defined as rules. There are two types of roles: `Role`, which applies to a single
    namespace, and `ClusterRole`, which applies to all namespaces in a cluster.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a role in the default namespace that allows the getting, watching,
    and listing of all pods. Each role has three components: API groups, resources,
    and verbs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Cluster roles are very similar, except there is no namespace field because they
    apply to all namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: A binding is associating a list of subjects (users, user groups, or service
    accounts) with a role. There are two types of binding, `RoleBinding` and `ClusterRoleBinding`,
    which correspond to `Role` and `ClusterRole`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: It's interesting that you can bind a `ClusterRole` to a subject in a single
    namespace. This is convenient for defining roles that should be used in multiple
    namespaces, once as a cluster role, and then binding them to specific subjects
    in specific namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: The cluster role binding is similar, but must bind a cluster role and always
    applies to the whole cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Note that RBAC is used to grant access to Kubernetes resources. It can regulate
    access to your service endpoints, but you may still need fine-grained authorization
    in your microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Upgrading microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deploying and securing microservices is just the beginning. As you develop and
    evolve your system, you'll need to upgrade your microservices. There are many
    important considerations regarding how to go about it that we will discuss later
    (versioning, rolling updates, blue-green, and canary). Kubernetes provides direct
    support for many of these concepts out of the box and the ecosystem built on top
    of it to provide many flavors and opinionated solutions.
  prefs: []
  type: TYPE_NORMAL
- en: The goal is often zero downtime and safe rollback if a problem occurs. Kubernetes
    deployments provide the primitives, such as updating a deployment, pausing a roll-out,
    and rolling back a deployment. Specific workflows are built on these solid foundations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The mechanics of upgrading a service typically involve upgrading its image
    to a new version and sometimes changes to its support resources and access: volumes,
    roles, quotas, limits, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: Scaling microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are two aspects to scaling a microservice with Kubernetes. The first aspect
    is scaling the number of pods backing up a particular microservice. The second
    aspect is the total capacity of the cluster. You can easily scale a microservice
    explicitly by updating the number of replicas of a deployment, but that requires
    constant vigilance on your part. For services that have large variations in the
    volume of requests they handle over long periods (for example, business hours
    versus off hours or week days versus weekends), it might take a lot of effort.
    Kubernetes provides horizontal pod autoscaling, which is based on CPU, memory,
    or custom metrics, and can scale your service up and down automatically.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how to scale our `nginx` deployment that is currently fixed at three
    replicas to go between `2` and `5`, depending on the average CPU usage across
    all instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The outcome is that Kubernetes will watch CPU utilization of the pods that belong
    to the `nginx` deployment. When the average CPU over a certain period of time
    (5 minutes, by default) exceeds 90%, it will add more replicas until the maximum
    of 5, or until utilization drops below 90%. The HPA can scale down too, but will
    always maintain a minimum of two replicas, even if the CPU utilization is zero.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Your microservices are deployed and running on Kubernetes. You can update the
    version of your microservices whenever it is needed. Kubernetes takes care of
    healing and scaling automatically. However, you still need to monitor your system
    and keep track of errors and performance. This is important for addressing problems,
    but also for informing you on potential improvements, optimizations, and cost
    cutting.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several categories of information that are relevant and that you
    should monitor:'
  prefs: []
  type: TYPE_NORMAL
- en: Third-party logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application errors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes events
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When considering a system composed of multiple microservices and multiple supporting
    components, the number of logs will be substantial. The solution is central logging,
    where all the logs go to a single place where you can slice and dice at your will.
    Errors can be logged, of course, but often it is useful to report errors with
    additional metadata, such as stack trace, and review them in their own dedicated
    environment (for example, sentry or rollbar). Metrics are useful for detecting
    performance and system health problems or trends over time.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes provides several mechanisms and abstractions for monitoring your
    microservices. The ecosystem provides a number of useful projects too.
  prefs: []
  type: TYPE_NORMAL
- en: Logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are several ways to implement central logging with Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: Have a logging agent that runs on every node
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inject a logging sidecar container to every application pod
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have your application send its logs directly to a central logging service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are pros and cons to each approach. But, the main thing is that Kubernetes
    supports all approaches and makes container and pod logs available for consumption.
  prefs: []
  type: TYPE_NORMAL
- en: Refer to [https://kubernetes.io/docs/concepts/cluster-administration/logging/#cluster-level-logging-architectures](https://kubernetes.io/docs/concepts/cluster-administration/logging/#cluster-level-logging-architectures)
    for an in-depth discussion.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes comes with cAdvisor ([https://github.com/google/cadvisor](https://github.com/google/cadvisor)),
    which is a tool for collecting container metrics integrated into the kubelet binary.
    Kubernetes used to provide a metrics server called **heapster** that required
    additional backends and a UI. But, these days, the best in class metrics server
    is the open source Prometheus project. If you run Kubernetes on Google's GKE,
    then Google Cloud Monitoring is a great option that doesn't require additional
    components to be installed in your cluster. Other cloud providers also have integration
    with their monitoring solutions (for example, CloudWatch on EKS).
  prefs: []
  type: TYPE_NORMAL
- en: Creating a local cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the strengths of Kubernetes as a deployment platform is that you can
    create a local cluster and, with relatively little effort, have a realistic environment
    that is very close to your production environment. The main benefit is that developers
    can test their microservices locally and collaborate with the rest of the services
    in the cluster. When your system is comprised of many microservices, the more
    significant tests are often integration tests and even configuration and infrastructure
    tests, as opposed to unit tests. Kubernetes makes that kind of testing much easier
    and requires much less brittle mocking.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you will install a local Kubernetes cluster and some additional
    projects, and then have some fun exploring it using the invaluable kubectl command-line
    tool.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Minikube
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Minikube is a single node Kubernetes cluster that you can install anywhere.
    I used macOS here, but, in the past, I used it successfully on Windows too. Before
    installing Minikube itself, you must install a hypervisor. I prefer HyperKit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'But, I''ve run into trouble with HyperKit from time to time. If you can''t
    overcome the issues, I suggest using VirtualBox as the hypervisor instead. Run
    the following command to install VirtualBox via Homebrew:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, you can install Minikube itself. Homebrew is the best way to go again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'If you''re not on macOS, follow the official instructions here: [https://kubernetes.io/docs/tasks/tools/install-minikube/](https://kubernetes.io/docs/tasks/tools/install-minikube/).'
  prefs: []
  type: TYPE_NORMAL
- en: You must turn off any VPN before starting Minikube with HyperKit. You can restart
    your VPN after Minikube has started.
  prefs: []
  type: TYPE_NORMAL
- en: 'Minikube supports multiple versions of Kubernetes. At the moment, the default
    version is 1.10.0, but 1.13.0 is already out and supported, so let''s use that
    version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'If you''re using VirtualBox as your hypervisor, you don''t need to specify `--vm-driver`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Minikube will automatically download the Minikube VM (178.88 MB) if it's the
    first time you are starting your Minikube cluster.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, your Minikube cluster is ready to go.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting Minikube
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you run into some trouble (for example, if you forgot to turn off your VPN),
    try to delete your Minikube installation and restart it with verbose logging:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'If your Minikube installation just hangs (maybe waiting for SSH), you might
    have to reboot to unstick it. If that doesn''t help, try the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Then, reboot again.
  prefs: []
  type: TYPE_NORMAL
- en: Verifying your cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If everything is OK, you can check your Minikube version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Minikube has many other useful commands. Just type `minikube` to see the list
    of commands and flags.
  prefs: []
  type: TYPE_NORMAL
- en: Playing with your cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Minikube is running, so let''s have some fun. Your kubectl is going to serve
    you well in this section. Let''s start by examining our node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Your cluster already has some pods and services running. It turns out that
    Kubernetes is dogfooding and many of its own services are plain services and pods.
    But, those pods and services run in namespaces. Here are all the namespaces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'To see all the services in all the namespaces, you can use the `--all-namespaces`
    flag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The Kubernetes API server, itself, is running as a service in the default namespace
    and then we have `kube-dns` and the `kubernetes-dashboard` running in the `kube-system`
    namespace.
  prefs: []
  type: TYPE_NORMAL
- en: 'To explore the dashboard, you can run the dedicated Minikube command, `minikube
    dashboard`. You can also use `kubectl`, which is more universal and will work
    on any Kubernetes cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, browse to `http://localhost:9090` and you will see the following dashboard:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/48590ed9-0382-4c6e-8f48-180a7b2403e5.png)'
  prefs: []
  type: TYPE_IMG
- en: Installing Helm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Helm is the Kubernetes package manager. It doesn''t come with Kubernetes, so
    you have to install it. Helm has two components: a server-side component called
    `tiller`, and a CLI called `helm`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s install `helm` locally first, using Homebrew:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, properly initialize both the server and client type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'With Helm in place, you can easily install all kinds of goodies in your Kubernetes
    cluster. There are currently `275` chars (the Helm term for a package) in the
    stable chart repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'For example, check out all the releases tagged with the `db` type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: We will use Helm a lot throughout the book.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you received a whirlwind tour of Kubernetes and got an idea
    of how well it aligns with microservices. The extensible architecture of Kubernetes
    empowers a large community of enterprise organizations, startup companies, and
    open source organizations to collaborate and create an ecosystem around Kubernetes
    that multiplies its benefits and ensures its staying power. The concepts and abstractions
    built into Kubernetes are very well suited for microservice-based systems. They
    support every phase of the SDLC, from development, through testing, and deployments,
    and all the way to monitoring and troubleshooting. The Minikube project lets every
    developer run a local Kubernetes cluster, which is great for experimenting with
    Kubernetes itself, as well as testing locally in an environment that is very similar
    to the production environment. The Helm project is a fantastic addition to Kubernetes
    and provides great value as the de facto package management solution. In the next
    chapter, we will dive into the world of microservices and learn why they are the
    best approach for developing complex and fast-moving distributed systems that
    run in the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you want to learn more about Kubernetes, I recommend my book, *Mastering
    Kubernetes – Second Edition*, published by Packt: [https://www.packtpub.com/application-development/mastering-kubernetes-second-edition](https://www.packtpub.com/application-development/mastering-kubernetes-second-edition)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
