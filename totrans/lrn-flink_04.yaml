- en: Chapter 4.  Data Processing Using the Table API
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the earlier chapters, we talked about batch and stream data processing APIs
    provided by Apache Flink. In this chapter, we are going to talk about Table API
    which is a SQL interface for data processing in Flink. Table API operates on a
    table interface which can be created from a dataset and datastream. Once the dataset/datastream
    is registered as a table, we are free to apply relational operations such as aggregations,
    joins, and selections.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: Tables can also be queried like regular SQL queries. Once the operations are
    performed, we need to convert the table back to either a dataset or datastream.
    Apache Flink internally uses another open source project called Apache Calcite
    [https://calcite.apache.org/](https://calcite.apache.org/) for optimizing these
    query transformations.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Registering tables
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accessing the registered table
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operators
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data types
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SQL
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now let's get started.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to use Table API, the very first thing we need to do is to create
    a Java Maven project and add the following dependency in it:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This dependency will download all the required JARs in your class path. Once
    the download is complete, we are all good to use Table API.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Registering tables
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to operate on datasets/datastreams, first we need to register a table
    in `TableEnvironment`. Once the table is registered with a unique name, it can
    be easily accessed from `TableEnvironment`.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '`TableEnvironment` maintains an internal table catalogue for table registration.
    The following diagram shows the details:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '![Registering tables](img/B05653_image1.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
- en: It is very important to have unique table names, otherwise you will get an exception.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Registering a dataset
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to perform SQL operations on a dataset, we need to register it as a
    table in `BatchTableEnvironment`. We need to define a Java POJO class while registering
    the table.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, let''s say we need to register a dataset called Word Count. Each
    record in this table will have word and frequency attributes. The Java POJO for
    the same would look like the following:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The same class in Scala can be defined as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now we can register this table.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In Scala:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Please make a note that the name of the dataset table must not match the `^_DataSetTable_[0-9]+`
    pattern as it is reserved for internal memory use.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Registering a datastream
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Similar to a dataset, we can also register a datastream in `StreamTableEnvironment`.
    We need to define a Java POJO class while registering the table.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, let''s say we need to register a datastream called Word Count.
    Each record in this table will have a word and frequency attributes. The Java
    POJO for the same would look as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The same class in Scala can be defined as shown here:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now we can register this table.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In Scala:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Please make a note that the name of the datastream table must not match the
    `^_DataStreamTable_[0-9]+` pattern as it is reserved for internal memory use.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Registering a table
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Similar to a dataset and a datastream, we can also register a table originating
    from Table API.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In Scala:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Registering external table sources
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Flink allows us to register an external table from sources using a `TableSource`.
    A table source can allow us to access data stored in databases such as MySQL and
    Hbase, in. filesystems such as CSVs, Parquet, and ORC, or you can also read messaging
    systems such as RabbitMQ and Kafka.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Currently, Flink allows reading data from CSV files using CSV sources and JSON
    data from Kafka topics using Kafka sources.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: CSV table source
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now let's look at how to directly read data using a CSV source and then register
    the source in a table environment.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: 'A CSV source is by default available in the `flink-table` API JAR so there
    is no need to add any other extra Maven dependency. The following dependency is
    good enough:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The following code snippet shows how to read CSV files and register the table
    source.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In Scala:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Kafka JSON table source
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can also register the Kafka JSON table source in the table environment.
    In order to use this API we need to add the following two dependencies:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: 'The first one is for Table API:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The second dependency would be for the Kafka Flink connector:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using Kafka 0.8, apply:'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'If you are using Kafka 0.9, apply:'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now we need to write the code as shown in the following code snippet:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In the preceding code, we define the Kafka source for Kafka 0.8 and then register
    the source in the table environment.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Accessing the registered table
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once the table is registered, we can access it very easily from `TableEnvironment`
    as shown here:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The preceding statement scans the table registered with the name `"tableName"`
    in `BatchTableEnvironment`:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The preceding statement ingests the table registered with the name `"tableName"`
    in `StreamTableEnvironment`:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Operators
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Flink's Table API provides various operators as part of its domain-specific
    language. Most of the operators are available in Java and Scala APIs. Let's look
    at those operators one by one.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: The select operator
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `select` operator is like a SQL select operator which allows you to select
    various attributes/columns in a table.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'In Scala:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The where operator
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `where` operator is used for filtering out results.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'In Scala:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The filter operator
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `filter` operator can be used as a replacement for the `where` operator.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In Scala:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The as operator
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `as` operator is used for renaming fields:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'In Scala:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The groupBy operator
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is similar to SQL `groupBy` operations which aggregate the results according
    to a given attribute.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'In Scala:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The join operator
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `join` operator is used to join tables. It is compulsory that we specify
    at least one equality joining condition.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'In Scala:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The leftOuterJoin operator
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `leftOuterJoin` operator joins two tables by getting all the values from
    the table specified on the left side and selects only the matching values from
    the right side table. It is compulsory that we specify at least one equality joining
    condition.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'In Scala:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The rightOuterJoin operator
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `rightOuterJoin` operator joins two tables by getting all values from the
    table specified on the right side and selects only matching values from the left
    side table. It is compulsory that we specify at least one equality joining condition.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'In Scala:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The fullOuterJoin operator
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `fullOuterJoin` operator joins two tables by getting all the values from
    both tables. It is compulsory that we specify at least one equality joining condition.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'In Scala:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The union operator
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `union` operator merges two similar tables. It removes duplicate values
    in the resulting table.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'In Scala:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The unionAll operator
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `unionAll` operator merges two similar tables.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'In Scala:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The intersect operator
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `intersect` operator returns matching values from both tables. It makes
    sure that the resultant table does have any duplicates.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'In Scala:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The intersectAll operator
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `intersectAll` operator returns matching values from both tables. The resultant
    table might have duplicate records.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'In Scala:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The minus operator
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `minus` operator returns records from the left table which do not exist
    in the right table. It makes sure that the resultant table does not have any duplicates.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'In Scala:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: The minusAll operator
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `minusAll` operator returns records from the left table which do not exist
    in the right table. The resultant table might have duplicate records.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'In Scala:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The distinct operator
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `distinct` operator returns only unique value records from the table.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'In Scala:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The orderBy operator
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `orderBy` operator returns records sorted across globally parallel partitions.
    You can choose the order as ascending or descending.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'In Scala:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: The limit operator
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `limit` operator limits records sorted across globally parallel partitions
    from a given offset.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'In Scala:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Data types
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Table API supports common SQL data types which can be used easily. Internally,
    it uses `TypeInformation` to identify various data types. It currently does not
    support all Flink data types:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '| Table API | SQL | Java type |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
- en: '| `Types.STRING` | `VARCHAR` | `java.lang.String` |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
- en: '| `Types.BOOLEAN` | `BOOLEAN` | `java.lang.Boolean` |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
- en: '| `Types.BYTE` | `TINYINT` | `java.lang.Byte` |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
- en: '| `Types.SHORT` | `SMALLINT` | `java.lang.Short` |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
- en: '| `Types.INT` | `INTEGER`, `INT` | `java.lang.Integer` |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
- en: '| `Types.LONG` | `BIGINT` | `java.lang.Long` |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
- en: '| `Types.FLOAT` | `REAL`, `FLOAT` | `java.lang.Float` |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
- en: '| `Types.DOUBLE` | `DOUBLE` | `java.lang.Double` |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
- en: '| `Types.DECIMAL` | `DECIMAL` | `java.math.BigDecimal` |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
- en: '| `Types.DATE` | `DATE` | `java.sql.Date` |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
- en: '| `Types.TIME` | `TIME` | `java.sql.Time` |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
- en: '| `Types.TIMESTAMP` | `TIMESTAMP(3)` | `java.sql.Timestamp` |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
- en: '| `Types.INTERVAL_MONTHS` | INTERVAL YEAR TO MONTH | `java.lang.Integer` |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
- en: '| `Types.INTERVAL_MILLIS` | INTERVAL DAY TO SECOND(3) | `java.lang.Long` |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
- en: With continuous development and support from the community, more data types
    will be supported soon.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: SQL
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Table API also allows us to write free form SQL queries using the `sql()` method.
    The method internally also uses Apache Calcite for SQL syntax verification and
    optimization. It executes the query and returns results in the table format. Later
    the table can be again transformed into either a dataset or datastream or `TableSink`
    for further processing.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: One thing to note here is that, for the SQL method to access the tables, they
    must be registered with `TableEnvironment`.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: More support is being added to the SQL method continuously so if any syntax
    is not supported, it will error out with `TableException`.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Now let's look at how to use the SQL method on a dataset and datastream.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: SQL on datastream
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'SQL queries can be executed on datastreams registered with `TableEnvironment`
    using the `SELECT STREAM` keyword. Most of the SQL syntax is common between datasets
    and datastreams. To know more about stream syntax, the Apache Calcite''s Streams
    documentation would be helpful. It can be found at: [https://calcite.apache.org/docs/stream.html](https://calcite.apache.org/docs/stream.html).'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Let's say we want to analyze the product schema defined as (`id`, `name`, `stock`).
    The following code needs to be written using the `sql()` method.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'In Scala:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Table API uses a lexical policy similar to Java in order to define queries properly.
    This means the case of the identifiers is preserved and they are matched case
    sensitively. If any of your identifiers contain non-alpha numeric characters then
    you can quote those using back ticks.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, if you want to define a column with the name `''my col''` then
    you need to use back ticks as shown here:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Supported SQL syntax
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As stated earlier, Flink uses Apache Calcite for validating and optimizing
    SQL queries. With the current version, the following **Backus Naur Form** (**BNF**)
    is supported:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Scalar functions
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Table API and SQL support various built-in scalar functions. Let's try to understand
    those one by one.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Scalar functions in the table API
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following is the list of supported scalar functions in the table API:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '| **Java function** | **Scala function** | **Description** |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
- en: '| `ANY.isNull` | `ANY.isNull` | Returns `true` if the given expression is null.
    |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
- en: '| `ANY.isNotNull` | `ANY.isNotNull` | Returns `true` if the given expression
    is not null. |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
- en: '| `BOOLEAN.isTrue` | `BOOLEAN.isTrue` | Returns `true` if the given Boolean
    expression is `true`. `False` otherwise. |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
- en: '| `BOOLEAN.isFalse` | `BOOLEAN.isFalse` | Returns `true` if given Boolean expression
    is false. `False` otherwise. |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
- en: '| `NUMERIC.log10()` | `NUMERIC.log10()` | Calculates the base 10 logarithm
    of given value. |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
- en: '| `NUMERIC.ln()` | `NUMERIC.ln()` | Calculates the natural logarithm of given
    value. |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
- en: '| `NUMERIC.power(NUMERIC)` | `NUMERIC.power(NUMERIC)` | Calculates the given
    number raised to the power of the other value. |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
- en: '| `NUMERIC.abs()` | `NUMERIC.abs()` | Calculates the absolute value of given
    value. |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
- en: '| `NUMERIC.floor()` | `NUMERIC.floor()` | Calculates the largest integer less
    than or equal to a given number. |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
- en: '| `NUMERIC.ceil()` | `NUMERIC.ceil()` | Calculates the smallest integer greater
    than or equal to a given number. |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
- en: '| `STRING.substring(INT, INT)` | `STRING.substring(INT, INT)` | Creates a substring
    of the given string at the given index for the given length |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
- en: '| `STRING.substring(INT)` | `STRING.substring(INT)` | Creates a substring of
    the given string beginning at the given index to the end. The start index starts
    at 1 and is inclusive. |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
- en: '| `STRING.trim(LEADING, STRING)` `STRING.trim(TRAILING, STRING)` `STRING.trim(BOTH,
    STRING)` `STRING.trim(BOTH)` `STRING.trim()` | `STRING.trim(leading = true, trailing
    = true, character = " ")` | Removes leading and/or trailing characters from the
    given string. By default, whitespaces at both sides are removed. |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
- en: '| `STRING.charLength()` | `STRING.charLength()` | Returns the length of a string.
    |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
- en: '| `STRING.upperCase()` | `STRING.upperCase()` | Returns all of the characters
    in a string in upper case using the rules of the default locale. |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
- en: '| `STRING.lowerCase()` | `STRING.lowerCase()` | Returns all of the characters
    in a string in lower case using the rules of the default locale. |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
- en: '| `STRING.initCap()` | `STRING.initCap()` | Converts the initial letter of
    each word in a string to uppercase. Assumes a string containing only `[A-Za-z0-9]`,
    everything else is treated as whitespace. |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
- en: '| `STRING.like(STRING)` | `STRING.like(STRING)` | Returns true, if a string
    matches the specified LIKE pattern. For example, `"Jo_n%"` matches all strings
    that start with `"Jo(arbitrary letter)n"`. |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
- en: '| `STRING.similar(STRING)` | `STRING.similar(STRING)` | Returns `true`, if
    a string matches the specified SQL regex pattern. For example, `"A+"` matches
    all strings that consist of at least one `"A"`. |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
- en: '| `STRING.toDate()` | `STRING.toDate` | Parses a date string in the form `"yy-mm-dd"`
    to a SQL date. |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
- en: '| `STRING.toTime()` | `STRING.toTime` | Parses a time string in the form `"hh:mm:ss"`
    to a SQL time. |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
- en: '| `STRING.toTimestamp()` | `STRING.toTimestamp` | Parses a timestamp string
    in the form `"yy-mm-dd hh:mm:ss.fff"` to a SQL timestamp. |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
- en: '| `TEMPORAL.extract(TIMEINTERVALUNIT)` | NA | Extracts parts of a time point
    or time interval. Returns the part as a long value. For example, `2006-06-05 .toDate.extract(DAY)`
    leads to `5`. |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
- en: '| `TIMEPOINT.floor(TIMEINTERVALUNIT)` | `TIMEPOINT.floor(TimeIntervalUnit)`
    | Rounds a time point down to the given unit. For example, `"12:44:31".toDate.floor(MINUTE)`
    leads to `12:44:00`. |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
- en: '| `TIMEPOINT.ceil(TIMEINTERVALUNIT)` | `TIMEPOINT.ceil(TimeIntervalUnit)` |
    Rounds a time point up to the given unit. For example, `"12:44:31".toTime.floor(MINUTE)`
    leads to `12:45:00`. |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
- en: '| `currentDate()` | `currentDate()` | Returns the current SQL date in UTC time
    zone. |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
- en: '| `currentTime()` | `currentTime()` | Returns the current SQL time in UTC time
    zone. |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
- en: '| `currentTimestamp()` | `currentTimestamp()` | Returns the current SQL timestamp
    in UTC time zone. |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
- en: '| `localTime()` | `localTime()` | Returns the current SQL time in local time
    zone. |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
- en: '| `localTimestamp()` | `localTimestamp()` | Returns the current SQL timestamp
    in local time zone. |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
- en: Scala functions in SQL
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following is the list of supported scalar functions in the `sql()` method:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '| Function | Description |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
- en: '| `EXP(NUMERIC)` | Calculates the Euler''s number raised to the given power.
    |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
- en: '| `LOG10(NUMERIC)` | Calculates the base 10 logarithm of the given value. |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
- en: '| `LN(NUMERIC)` | Calculates the natural logarithm of the given value. |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
- en: '| `POWER(NUMERIC, NUMERIC)` | Calculates the given number raised to the power
    of the other value. |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
- en: '| `ABS(NUMERIC)` | Calculates the absolute value of the given value. |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
- en: '| `FLOOR(NUMERIC)` | Calculates the largest integer less than or equal to a
    given number. |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
- en: '| `CEIL(NUMERIC)` | Calculates the smallest integer greater than or equal to
    a given number. |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
- en: '| `SUBSTRING(VARCHAR, INT, INT) SUBSTRING(VARCHAR FROM INT FOR INT)` | Creates
    a substring of the given string at the given index for the given length. The index
    starts at 1 and is inclusive, that is, the character at the index is included
    in the substring. The substring has the specified length or less. |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
- en: '| `SUBSTRING(VARCHAR, INT)``SUBSTRING(VARCHAR FROM INT)` | Creates a substring
    of the given string beginning at the given index to the end. The start index starts
    at 1 and is inclusive. |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
- en: '| `TRIM(LEADING VARCHAR FROM VARCHAR) TRIM(TRAILING VARCHAR FROM VARCHAR) TRIM(BOTH
    VARCHAR FROM VARCHAR) TRIM(VARCHAR)` | Removes leading and/or trailing characters
    from the given string. By default, whitespaces at both sides are removed. |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
- en: '| `CHAR_LENGTH(VARCHAR)` | Returns the length of a string. |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
- en: '| `UPPER(VARCHAR)` | Returns all of the characters in a string in upper case
    using the rules of the default locale. |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
- en: '| `LOWER(VARCHAR)` | Returns all of the characters in a string in lower case
    using the rules of the default locale. |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
- en: '| `INITCAP(VARCHAR)` | Converts the initial letter of each word in a string
    to uppercase. Assumes a string containing only `[A-Za-z0-9]`, everything else
    is treated as whitespace. |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
- en: '| `VARCHAR LIKE VARCHAR` | Returns true if a string matches the specified LIKE
    pattern. For example, `"Jo_n%"` matches all strings that start with `"Jo(arbitrary
    letter)n"`. |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
- en: '| `VARCHAR SIMILAR TO VARCHAR` | Returns true if a string matches the specified
    SQL regex pattern. For example, `"A+"` matches all strings that consist of at
    least one `"A"`. |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
- en: '| `DATE VARCHAR` | Parses a date string in the form `"yy-mm-dd"` to a SQL date.
    |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
- en: '| `TIME VARCHAR` | Parses a time string in the form `"hh:mm:ss"` to a SQL time.
    |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
- en: '| `TIMESTAMP VARCHAR` | Parses a timestamp string in the form `"yy-mm-dd hh:mm:ss.fff"`
    to a SQL timestamp. |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
- en: '| `EXTRACT(TIMEINTERVALUNIT FROM TEMPORAL)` | Extracts parts of a time point
    or time interval. Returns the part as a long value. For example, `EXTRACT(DAY
    FROM DATE ''2006-06-05'')` leads to `5`. |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
- en: '| `FLOOR(TIMEPOINT TO TIMEINTERVALUNIT)` | Rounds a time point down to the
    given unit. For example, `FLOOR(TIME ''12:44:31'' TO MINUTE)` leads to `12:44:00`.
    |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
- en: '| `CEIL(TIMEPOINT TO TIMEINTERVALUNIT)` | Rounds a time point up to the given
    unit. For example, `CEIL(TIME ''12:44:31'' TO MINUTE)` leads to `12:45:00`. |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
- en: '| `CURRENT_DATE` | Returns the current SQL date in UTC timezone. |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
- en: '| `CURRENT_TIME` | Returns the current SQL time in UTC timezone. |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
- en: '| `CURRENT_TIMESTAMP` | Returns the current SQL timestamp in UTC timezone.
    |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
- en: '| `LOCALTIME` | Returns the current SQL time in local timezone. |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
- en: '| `LOCALTIMESTAMP` | Returns the current SQL timestamp in local timezone. |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
- en: Use case - Athletes data insights using Flink Table API
  id: totrans-292
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have learnt details of Table API, let's try to apply this knowledge
    to a real life use case. Consider we have a dataset with us, which has information
    about the Olympic athletes and their performance in various games.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 'The sample data looks like that shown in the following table:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: '| **Player** | **Country** | **Year** | **Game** | **Gold** | **Silver** |
    **Bronze** | **Total** |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
- en: '| Yang Yilin | China | 2008 | Gymnastics | 1 | 0 | 2 | 3 |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
- en: '| Leisel Jones | Australia | 2000 | Swimming | 0 | 2 | 0 | 2 |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
- en: '| Go Gi-Hyeon | South Korea | 2002 | Short-Track Speed Skating | 1 | 1 | 0
    | 2 |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
- en: '| Chen Ruolin | China | 2008 | Diving | 2 | 0 | 0 | 2 |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
- en: '| Katie Ledecky | United States | 2012 | Swimming | 1 | 0 | 0 | 1 |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
- en: '| Ruta Meilutyte | Lithuania | 2012 | Swimming | 1 | 0 | 0 | 1 |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
- en: "| DÃ\x83Â¡niel Gyurta | Hungary | 2004 | Swimming | 0 | 1 | 0 | 1 |"
  id: totrans-302
  prefs: []
  type: TYPE_TB
- en: '| Arianna Fontana | Italy | 2006 | Short-Track Speed Skating | 0 | 0 | 1 |
    1 |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
- en: '| Olga Glatskikh | Russia | 2004 | Rhythmic Gymnastics | 1 | 0 | 0 | 1 |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
- en: '| Kharikleia Pantazi | Greece | 2000 | Rhythmic Gymnastics | 0 | 0 | 1 | 1
    |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| Kharikleia Pantazi | 希腊 | 2000 | 韵律体操 | 0 | 0 | 1 | 1 |'
- en: '| Kim Martin | Sweden | 2002 | Ice Hockey | 0 | 0 | 1 | 1 |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| Kim Martin | 瑞典 | 2002 | 冰球 | 0 | 0 | 1 | 1 |'
- en: '| Kyla Ross | United States | 2012 | Gymnastics | 1 | 0 | 0 | 1 |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '| Kyla Ross | 美国 | 2012 | 体操 | 1 | 0 | 0 | 1 |'
- en: '| Gabriela Dragoi | Romania | 2008 | Gymnastics | 0 | 0 | 1 | 1 |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '| Gabriela Dragoi | 罗马尼亚 | 2008 | 体操 | 0 | 0 | 1 | 1 |'
- en: '| Tasha Schwikert-Warren | United States | 2000 | Gymnastics | 0 | 0 | 1 |
    1 |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| Tasha Schwikert-Warren | 美国 | 2000 | 体操 | 0 | 0 | 1 | 1 |'
- en: Now we want to get answers to the questions like, how many medals were won by
    country or by game. As the data we have in structured data, we can use Table API
    to query data in a SQL way. So let's get started.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们想要得到答案，比如，每个国家或每个比赛赢得了多少枚奖牌。由于我们的数据是结构化数据，我们可以使用Table API以SQL方式查询数据。所以让我们开始吧。
- en: 'The data available is in the CSV format. So we will be using a CSV reader provided
    by Flink API as shown in the following code snippet:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的数据是以CSV格式提供的。因此，我们将使用Flink API提供的CSV阅读器，如下面的代码片段所示：
- en: '[PRE60]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Next we need to create a Table with this dataset and register it in Table Environment
    for further processing:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要使用这个数据集创建一个表，并在Table Environment中注册它以进行进一步处理：
- en: '[PRE61]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Next we can write a regular SQL query to get more insights from the data. Or
    else we can use Table API operators to manipulate the data, as shown in the following
    code snippet:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以编写常规的SQL查询，以从数据中获取更多见解。或者我们可以使用Table API操作符来操作数据，如下面的代码片段所示：
- en: '[PRE62]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: This way we can analyse such data in a much more simpler way using Table API.
    The complete code for this use case is available on GitHub at [https://github.com/deshpandetanmay/mastering-flink/tree/master/chapter04/flink-table](https://github.com/deshpandetanmay/mastering-flink/tree/master/chapter04/flink-table).
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 通过Table API，我们可以以更简单的方式分析这样的数据。这个用例的完整代码可以在GitHub上找到：[https://github.com/deshpandetanmay/mastering-flink/tree/master/chapter04/flink-table](https://github.com/deshpandetanmay/mastering-flink/tree/master/chapter04/flink-table)。
- en: Summary
  id: totrans-318
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about a SQL-based API supported by Flink called
    Table API. We also learned how to transform a dataset/stream into a table, registering
    a table, datasets, and datastreams with `TableEnvironment` and then using the
    registered tables to perform various operations. For people coming from a SQL
    databases background, this API is bliss.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了Flink支持的基于SQL的API，称为Table API。我们还学习了如何将数据集/流转换为表，使用`TableEnvironment`注册表、数据集和数据流，然后使用注册的表执行各种操作。对于来自SQL数据库背景的人来说，这个API是一种福音。
- en: In the next chapter, we are going to talk about a very interesting library called
    **Complex Event Processing** and how to use it for solving various business use
    cases.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论一个非常有趣的库，叫做**复杂事件处理**，以及如何将其用于解决各种业务用例。
