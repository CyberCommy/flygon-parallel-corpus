- en: Deploying Your First Application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we covered Kubernetes key operation principles and
    deployment strategies for Windows/Linux hybrid clusters. Now it is time to focus
    more on deploying and working with Kubernetes applications. To demonstrate the
    essential operations for Kubernetes applications, we will use the AKS Engine hybrid
    Kubernetes cluster that we created in [Chapter 8](ab695a0d-05dc-48f8-8c41-bbd167cfbfa6.xhtml), *Deploying
    Hybrid Azure Kubernetes Service Engine Cluster*. You can use the on-premises hybrid
    cluster as well, but you should expect limited functionality; for example, services
    of the LoadBalancer type will not be available.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Imperatively deploying an application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Kubernetes manifest files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scheduling Pods on Windows nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accessing your application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling the application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you will need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Windows 10 Pro, Enterprise, or Education (version 1903 or later, 64-bit) installed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An Azure account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Windows/Linux Kubernetes cluster deployed using AKS Engine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To follow along, you will need your own Azure account to create Azure resources
    for the Kubernetes cluster. If you haven't already created the account for the
    previous chapters, you can read more about how to obtain a limited free account
    for personal use here: [https://azure.microsoft.com/en-us/free/](https://azure.microsoft.com/en-us/free/).
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a Kubernetes cluster using AKS Engine has been covered in [Chapter
    8](ab695a0d-05dc-48f8-8c41-bbd167cfbfa6.xhtml), *Deploying Hybrid Azure Kubernetes
    Service Engine Cluster*.
  prefs: []
  type: TYPE_NORMAL
- en: You can download the latest code samples for this chapter from the official
    GitHub repository: [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter09](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter09).
  prefs: []
  type: TYPE_NORMAL
- en: Imperatively deploying an application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the Kubernetes world, you can choose from two approaches when managing your
    applications: imperative management and declarative management. The imperative
    approach consists of executing imperative kubectl commands, such as `kubectl run`
    or `kubectl expose`, and imperative object configuration management, where you
    use commands such as `kubectl create` or `kubectl replace`. In short, you manage
    the cluster by executing ad-hoc commands that modify the Kubernetes objects and
    result in a changed desired state for the cluster—sometimes, you may not even
    know how the desired state has exactly changed after an imperative command. By
    contrast, in the declarative approach, you modify object configurations (manifest
    files) and create or update them in the cluster using the `kubectl apply` command
    (alternatively, you can use Kustomization files).'
  prefs: []
  type: TYPE_NORMAL
- en: Using declarative management is, in general, more close to the spirit of Kubernetes—the
    whole architecture is focused on persisting the desired cluster state and constantly
    performing operations that change the current cluster state to the desired state.
    A general rule of thumb is that in production environments, you should always
    use declarative management, either using standard manifest files or Kustomization
    files. You can easily provide source control for your object configurations and
    integrate this into continuous integration/deployment pipelines. Imperative management
    is useful for development and proof-of-concept scenarios—the operations are performed
    directly on a live cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that, for this approach, you will not have an easy way of knowing the
    history of the previous configurations!
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s first try the imperative approach for deploying a simple web application.
    We will perform the following operations:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a single bare Pod or a ReplicationController.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Expose it using a Service (LoadBalancer type).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To create imperatively a pod or a ReplicationController, we will use the `kubectl
    run` command. This command allows you to create different container-management
    objects using generators. You can find the complete list of generators in the
    official documentation: [https://kubernetes.io/docs/reference/kubectl/conventions/#generators](https://kubernetes.io/docs/reference/kubectl/conventions/#generators)—since
    Kubernetes 1.12, all generators apart from `run-pod/v1` are deprecated. The main
    reason for this is the relatively high complexity of the `kubectl run` command
    and the encouragement of a proper, declarative approach for advanced scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: 'To deploy a sample application based on the `mcr.microsoft.com/dotnet/core/samples:aspnetapp`
    Docker image, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a PowerShell window and ensure that you are using the `kubeconfig` file,
    which allows you to connect to your AKS Engine hybrid cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Determine which version of the Windows Server operating system is available
    on the nodes in your cluster.For example, for Windows Server 2019 Datacenter nodes,
    you need to use container images that have base layer version 1809\. This means
    that we have to use the `mcr.microsoft.com/dotnet/core/samples:aspnetapp-nanoserver-1809` Docker
    image in our example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Execute the `kubectl run` command with the `run-pod/v1` generator to run a
    single pod, `windows-example`, for the sample application with `nodeSelector`
    set to nodes and the OS type,and `windows`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The pod will be scheduled on one of the Windows nodes, and you can monitor
    the progress of pod creation using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'When the pod changes its status to `Running`, you can continue with exposing
    the pod using  the LoadBalancer Service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Wait for `EXTERNAL-IP` of the service to be available:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Now you can use the external IP of the service and port `8080` to access the
    application running in the pod. For example, in the web browser, navigate to `http://213.199.135.14:8080/`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Alternatively, the preceding procedure can be performed in only one `kubectl
    run` command, which will create the pod and expose it immediately using the LoadBalancer
    Service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Note that this command exposes the service using port `80`, not `8080`. Using
    service port `80` and target port `8080` requires another layer of complexity
    in the `--service-overrides` flag.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the sake of completeness, let''s run our `mcr.microsoft.com/dotnet/core/samples:aspnetapp-nanoserver-1809`
    container behind a Kubernetes ReplicationController object. You can learn more
    about ReplicationControllers, ReplicaSets, and Deployments in [Chapter 4](118e3c89-786e-4718-ba67-6c38928e2a42.xhtml), *Kubernetes
    Concepts and Windows Support*—in general, it is not advisable to run bare Pods
    in your cluster; you should always manage Pods using at least ReplicaSets or,
    preferably, Deployments. In Kubernetes 1.17, it is still possible to create a
    ReplicationController using `kubectl run`—the generator is deprecated but not
    removed yet. Creating a ReplicationController imperatively requires using a different
    `--generator` flag with the value `run/v1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Even if this approach is quick and does not require any configuration files,
    you can clearly see that using `kubectl run` for anything else than simple operations
    is getting complex and error-prone. In most cases, you will be using imperative
    commands for the following operations:'
  prefs: []
  type: TYPE_NORMAL
- en: Quickly creating Pods in your development clusters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating ad hoc interactive Pods for debugging purposes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predictably deleting Kubernetes resources—more on this in the next section
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's now perform similar Deployment by using Kubernetes manifest files and
    the declarative management approach.
  prefs: []
  type: TYPE_NORMAL
- en: Using Kubernetes manifest files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Declarative management of Kubernetes objects is much closer to the spirit of
    Kubernetes—you focus on telling Kubernetes what you want (describing the desired
    state) instead of directly telling it what to do. As your application grows and
    has more components, managing the cluster using imperative commands becomes impossible.
    It is a much better idea to use imperative commands for read-only operations,
    such as `kubectl describe`, `kubectl get`, and `kubectl logs`, and perform all
    modifications to the clusters desired state using the `kubectl apply` command
    and Kubernetes object configuration files (also known as manifest files).
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a couple of recommended practices when using manifest files:'
  prefs: []
  type: TYPE_NORMAL
- en: It's preferable to use YAML manifest files over JSON manifest files. YAML is
    easier to manage and more commonly used by Kubernetes community.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Store your manifest files in source control such as Git. Before applying any
    configuration changes to the cluster, push the changes to the source control first—this
    will make rollbacks and configuration restoration much easier. Eventually, you
    should automate this process as part of your CI/CD pipeline.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grouping multiple manifest files into a single file is recommended, whenever
    it makes sense. The official Kubernetes examples repository provides a good demonstration
    of this approach: [https://github.com/kubernetes/examples/blob/master/guestbook/all-in-one/guestbook-all-in-one.yaml](https://github.com/kubernetes/examples/blob/master/guestbook/all-in-one/guestbook-all-in-one.yaml).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you have multiple manifest files for your cluster, you can use `kubectl apply`
    to recursively apply all manifest files in a given directory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use `kubectl diff` to understand what changes will be applied to the current
    cluster configuration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When deleting Kubernetes objects, use the imperative `kubectl delete` command
    as it gives predictable results. You can learn more about the declarative deleting
    of resources in the official documentation but in practice, it is a more risky
    approach: [https://kubernetes.io/docs/tasks/manage-kubernetes-objects/declarative-config/#how-to-delete-objects](https://kubernetes.io/docs/tasks/manage-kubernetes-objects/declarative-config/#how-to-delete-objects.).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use labels whenever possible to semantically describe your components: [https://kubernetes.io/docs/concepts/configuration/overview/#using-labels](https://kubernetes.io/docs/concepts/configuration/overview/#using-labels.).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More best practices regarding manifest files can be found in the official documentation: [https://kubernetes.io/docs/concepts/configuration/overview/](https://kubernetes.io/docs/concepts/configuration/overview/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s try demonstrating this approach by deploying an application similar
    to the one in the last section. This time, we will use Deployment and service
    objects, which will be defined in separate manifest files—in a real-world scenario,
    you would group these two manifest files into a single file, but for demonstration
    purposes, it makes sense to separate them. Follow these steps to deploy the application:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a PowerShell window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure that your cluster is not running resources from the previous section—you
    can check that using the `kubectl get all` command and delete them using the `kubectl
    delete` command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a directory for your manifest files, for example, `declarative-demo`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the `windows-example-deployment.yaml` manifest file, which contains
    the Deployment definition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the `windows-example-service.yaml` manifest file, which contains the
    LoadBalancer Service definition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the manifest files in the current directory using the `kubectl apply`
    command. Note that if you had a multi-level directory hierarchy, you could use
    the `-R` flag for recursive processing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the following command to wait for the service''s external IP to be available:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Use your web browser to navigate to the external IP and port `8080`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, let''s see how you can apply a simple change to your application using
    the declarative approach—we would like to change the LoadBalancer port to `9090`:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the `windows-example-service.yaml` manifest file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Modify the `spec.ports[0].port` value to `9090`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save the manifest file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(Optional but recommended) Verify your changes using the `kubectl diff` command.
    Remember that you need to have an appropriate *diff* tool installed and defined
    in the `$env:KUBECTL_EXTERNAL_DIFF` environment variable; you can learn more about
    this in [Chapter 6](791e78c0-f625-4232-9907-36e25ec2767d.xhtml), *Interacting
    with Kubernetes Clusters*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the manifest files again:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Notice that only `service/windows-example` has been detected as changed in the
    desired configuration.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, you can navigate in the web browser to the external IP address and port
    `9090` to verify the changes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you want to delete all of the resources that have been created by manifest
    files in the current directory, you can use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: That's it! As you can see, declarative management may require a bit more of
    boilerplate configuration but, in the end, managing the applications using this
    approach is much more predictable and easier to track.
  prefs: []
  type: TYPE_NORMAL
- en: When managing complex applications running in multiple environments, consider
    using Kustomization files (which can be used with the `kubectl apply` command)
    or Helm Charts. For example, with Kustomization files, you can organize the configuration
    files in a convention-friendly directory structure: [https://kubectl.docs.kubernetes.io/pages/app_composition_and_deployment/structure_directories.html](https://kubectl.docs.kubernetes.io/pages/app_composition_and_deployment/structure_directories.html).
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will take a quick look at the recommended practices
    regarding scheduling Pods on Windows nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Scheduling Pods on Windows nodes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To schedule Pods on nodes with specific properties, Kubernetes gives you a
    few possible options:'
  prefs: []
  type: TYPE_NORMAL
- en: Using `nodeName` in the Pod specification. This is the simplest form of statically
    scheduling Pods on a given node and is generally not recommended.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using `nodeSelector` in the pod specification. This gives you the possibility
    to schedule your pod only on nodes that have certain label values. We have been
    already using this approach in the previous section.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Node affinity and anti-affinity: These concepts expand the `nodeSelector` approach
    and provide a richer language of defining which nodes are preferred or avoided
    for your pod. You can read more about the possibilities in the official documentation: [https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity](https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Node taints and pod tolerations: They provide an opposite functionality to
    node affinity—you apply a taint to a given node (which describes some kind of
    limitation) and the pod must have a specific toleration defined to be schedulable
    on the tainted node.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Scheduling Pods in hybrid Windows/Linux clusters requires at least using `nodeSelector`
    or a combination of node taints with `nodeSelector`. Every Kubernetes node comes
    by default with a set of labels, which include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kubernetes.io/arch`, which describes the node''s processor architecture, for
    example, `amd64` or `arm`: This is also defined as `beta.kubernetes.io/arch`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kubernetes.io/os`, which has a value of `linux` or `windows`: This is also
    defined as `beta.kubernetes.io/os`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can check the default labels for your Windows node (for example, `7001k8s011`)
    in your AKS Engine cluster using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'If your pod does not contain `nodeSelector` in the specification, it can be
    scheduled on both Windows and Linux nodes— this is a problem as Windows containers
    will not start on Linux nodes and vice versa. The recommended practice is using
    `nodeSelector` for the predictable scheduling of your Pods for both Windows and
    Linux containers. For example, in the Deployment definition, the pod template
    may contain the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, you can use, in the latest versions of Kubernetes, the `"kubernetes.io/os":
    windows` selector. For Linux containers, you need to specify `"beta.kubernetes.io/os":
    linux` or `"kubernetes.io/os": linux`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This approach may cause problems when you are adding Windows nodes to existing
    large, Linux-only clusters, using Helm Charts or Kubernetes Operators—such workloads
    may not have the Linux node selector specified out of the box. To solve this issue,
    you can use taints and tolerations: mark your Windows nodes with a specific `NoSchedule`
    taints and use matching toleration for your Pods. We will use taint with the `os` key and
    a value of `Win1809`  for this purpose.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To taint Windows nodes, you have two possibilities:'
  prefs: []
  type: TYPE_NORMAL
- en: Taint the node at registration level using the `--register-with-taints='os=Win1809:NoSchedule'`
    flag for kubelet. Note that this approach is currently not available in AKS Engine
    as `--register-with-taints` is not user-configurable—you can read more in the
    documentation: [https://github.com/Azure/aks-engine/blob/master/docs/topics/clusterdefinitions.md#kubeletconfig](https://github.com/Azure/aks-engine/blob/master/docs/topics/clusterdefinitions.md#kubeletconfig).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Taint the node using kubectl. You can add a taint using the following command: `kubectl
    taint nodes <nodeName> os=Win1809:NoSchedule` and remove it using `kubectl taint
    nodes 7001k8s011 os:NoSchedule-`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, your Deployment definition would have to specify the appropriate pod
    node selector for Windows and taint toleration, which allows scheduling on Windows
    nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In this approach, for Linux containers, you do not need to specify any node
    selector or taint toleration. However, if possible, it is recommended to use the
    node selector approach without node taints, especially if you are building a new
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will take a look at how you can access your application.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing your application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For accessing your application running in a pod, you have a few possibilities
    depending on your scenario. In debugging and testing scenarios, you can access
    your application in the following simple ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Use `kubectl exec` to create an ad hoc, interactive pod. We used this approach
    in the previous chapters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use `kubectl proxy` to access any service type. This approach works only for
    HTTP(S) endpoints as it uses proxy functionality provided by Kubernetes API Server.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use `kubectl port-forward`. You can use this approach to access individual Pods
    or Pods running in a Deployment or behind a service.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you would like to expose the application for end users in production, you
    can use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A service object with the LoadBalancer or NodePort type: We have already demonstrated
    how to use the LoadBalancer Service in the previous section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using an Ingress Controller together with a service of the ClusterIP type:
    This approach reduces the number of cloud load balancers used (resulting in reduced
    operational costs) and performs load balancing and routing inside the Kubernetes
    cluster. Note that this approach uses L7 load balancing so it can be used for
    exposing HTTP(S) endpoints only.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can learn in detail about services and Ingress Controllers in [Chapter 5](da2ee6af-a754-4fc8-ae62-86d8e68f0bd0.xhtml), *Kubernetes
    Networking*. Later in this section, we will demonstrate how to use an Ingress
    Controller for the demo application.
  prefs: []
  type: TYPE_NORMAL
- en: You can read more about accessing applications running in the cluster in various
    scenarios in the official documentation: [https://kubernetes.io/docs/tasks/administer-cluster/access-cluster-services/#accessing-services-running-on-the-cluster](https://kubernetes.io/docs/tasks/administer-cluster/access-cluster-services/#accessing-services-running-on-the-cluster).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s first demonstrate how to use `kubectl proxy` and `kubectl port-forward`.
    Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a Powershell window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure that the demonstration application from the previous sections is deployed
    and has a `windows-example` service with port `8080` deployed in the cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Run the `kubectl proxy` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This will expose a simple proxy server on your localhost machine on port `8001`
    to the remote Kubernetes API Server. You can freely use the API using this endpoint,
    without additional authentication. Note that using a raw API without a proxy is
    also possible but then you have to handle the authentication yourself ([https://kubernetes.io/docs/tasks/administer-cluster/access-cluster-api/](https://kubernetes.io/docs/tasks/administer-cluster/access-cluster-api/)).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Your service will be available at `http://<proxyEndpoint>/api/v1/namespaces/<namespaceName>/services/[https:]<serviceName>[:portName]/proxy`.
    In our case, navigate to `http://127.0.0.1:8001/api/v1/namespaces/default/services/windows-example/proxy/`.
    This approach works for any service type, including just internal ClusterIPs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Terminate the `kubectl proxy` process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, execute the following `kubectl port-forward` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This will forward any network traffic from your localhost `5000` port to `8080`
    on the `windows-example` service. For example, you can navigate to `http://127.0.0.1:5000/`
    in your web browser. Note that this approach will also work for different protocols
    than HTTP(S).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Terminate the `kubectl port-forward` process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, let''s see how to use Ingress Controller to access the demo application.
    Using Ingress is highly customizable and there are multiple Ingress Controllers
    available—we will demonstrate the quickest way to get up and running on AKS Engine
    hybrid cluster using `ingress-nginx` ([https://www.nginx.com/products/nginx/kubernetes-ingress-controller](https://www.nginx.com/products/nginx/kubernetes-ingress-controller)).
    Please note that this approach limits the Deployment of Ingress Controllers to
    Linux nodes only—you will be able to create Ingress objects for services running
    on Windows nodes but all of the load balancing will be performed on Linux nodes.
    Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Modify the `windows-example-service.yaml` manifest file so that it has `type:
    ClusterIP`, `port: 80`, and no `targetPort`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply your modifications to the cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the official generic manifest file for ingress-nginx, which creates a
    Deployment with one replica running on Linux nodes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the official cloud-specific manifest file for ingress-nginx. This will
    create a service of the LoadBalancer type, which will be used for the Ingress
    Controller:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Wait for the Ingress Controller service to receive an external IP address.The
    external IP address `104.40.133.125` will be used for all services that are configured
    to run behind this Ingress Controller:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the `windows-example-ingress.yaml` manifest file and define the Ingress
    object. The `windows-example` service for our application will be registered under
    the `<ingressLoadBalancerIp>/windows-example` path:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the changes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Navigate to `http://104.40.133.125/windows-example` to test the Ingress definition.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Of course, you can create multiple Ingress objects with complex rules for different
    services. A general rule of thumb is that you should use an Ingress Controller
    to expose your HTTP(S) endpoints whenever possible and use dedicated LoadBalancer
    services for other protocols.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's take a look at how you can scale your application!
  prefs: []
  type: TYPE_NORMAL
- en: Scaling the application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In production scenarios, you will definitely need to scale your application—this
    is where Kubernetes is powerful; you can either manually scale your application
    or use autoscaling. Let''s first take a look at how to perform the manual scaling
    of your Deployment. You can do it either imperatively or declaratively. To perform
    scaling by using an imperative command in PowerShell, perform these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Execute the `kubectl scale` command, which will scale the `windows-example` Deployment
    to three replicas:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Now watch how the Pods are being added to your Deployment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'You can perform a similar operation in a declarative manner, which is generally
    recommended. Let''s scale the application further to four replicas:'
  prefs: []
  type: TYPE_NORMAL
- en: Edit the `windows-example-deployment.yaml` manifest file and modify `replicas`
    to `4`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Save the manifest file and apply the changes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Again, use the `kubectl get pods -w` command to observe how the application
    is scaled up.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The true power of Kubernetes comes with autoscaling. We will cover autoscaling
    in more detail in [Chapter 11](9ad8c38e-6d0d-435b-a46c-82a468f18007.xhtml), *Configuring
    Applications to Use Kubernetes Features*, so in this section, we will give only
    a short overview of how to do it using an imperative command:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you need to configure the CPU resource limits for the pod template in
    the Deployment—set this to a small value, for example, `100m`. Without CPU resource
    limits, autoscaling will be not able to apply the scaling policy properly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the modifications:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Execute the following `kubectl autoscale` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This will create a **Horizontal Pod Autoscaler** (**HPA**) object in the cluster
    with the default algorithm, a minimum of 1 replica, a maximum of 5 replicas, and
    configuration based on a target CPU usage of 15% of the limit.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the following command to check the state of the HPA:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: You can try to add some CPU load to your Pods by frequently refreshing the application
    web page. Note that if you are using Ingress, you will hit the cache at the Ingress
    Controller so the CPU usage may not increase in such a scenario.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After some time, you will see that autoscaling kicks in and adds more replicas.
    When you decrease the load, the Deployment will be scaled down. You can check
    the timeline using the `kubectl describe` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Delete the HPA object to turn off autoscaling using this command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: For managed AKS instances, it is possible to leverage the **node-level** autoscaling
    feature ([https://docs.microsoft.com/en-us/azure/aks/cluster-autoscaler](https://docs.microsoft.com/en-us/azure/aks/cluster-autoscaler)),
    which brings another dimension of scalability for your workloads. Additionally,
    you can consider using AKS workloads with Azure Container Instances ([https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/scale-using-aks-with-aci](https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/scale-using-aks-with-aci)).
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You have successfully deployed and autoscaled your first application
    on an AKS Engine hybrid Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has given a brief introduction to how to deploy and manage Windows
    container applications running on an AKS Engine hybrid cluster. You learned  the
    differences between imperative and declarative management of cluster configuration
    and when to use each of them. We have used both approaches to deploy a demonstration
    application—now you know that the recommended declarative approach is easier and
    less error-prone than using imperative commands. Next, you learned how to predictably
    schedule Pods on Windows nodes and how to approach adding Windows container workloads
    to existing Kubernetes clusters. And lastly, we have shown how to access applications
    running in Kubernetes both for end users and developers and how to scale applications
    manually and automatically.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will utilize all of this new knowledge to deploy a real
    .NET Framework application to our Kubernetes cluster!
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is the difference between imperative and declarative management for Kubernetes
    objects?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When is using imperative commands  recommended?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do you see the changes between local manifest files and the current cluster
    state?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the recommended practice to schedule Pods in hybrid clusters?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between the `kubectl proxy` and `kubectl port-forward`
    commands?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When can you use an Ingress Controller?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do you scale a deployment manually?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can find answers to these questions in *Assessments* of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information about Kubernetes applications management, please refer
    to the following Packt books:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*The Complete Kubernetes Guide* ([https://www.packtpub.com/virtualization-and-cloud/complete-kubernetes-guide](https://www.packtpub.com/virtualization-and-cloud/complete-kubernetes-guide))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Getting Started with Kubernetes -Third Editi*on ([https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition](https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Kubernetes for Developers* ([https://www.packtpub.com/virtualization-and-cloud/kubernetes-developers](https://www.packtpub.com/virtualization-and-cloud/kubernetes-developers))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Currently, most of the resources regarding hybrid Windows/Linux clusters running
    on AKS Engine are available online. Please check the official documentation on
    GitHub for more details:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://github.com/Azure/aks-engine/blob/master/docs/topics/windows.md](https://github.com/Azure/aks-engine/blob/master/docs/topics/windows.md)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://github.com/Azure/aks-engine/blob/master/docs/topics/windows-and-kubernetes.md](https://github.com/Azure/aks-engine/blob/master/docs/topics/windows-and-kubernetes.md)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In general, many of the topics concerning AKS (the managed Kubernetes Azure
    offering, not AKS Engine itself) are useful, as they touch on how to integrate
    Kubernetes with the Azure ecosystem. You can find more about AKS itself in the
    following Packt book:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*DevOps with Kubernetes – Second Edition* ([https://www.packtpub.com/virtualization-and-cloud/devops-kubernetes-second-edition](https://www.packtpub.com/virtualization-and-cloud/devops-kubernetes-second-edition))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
