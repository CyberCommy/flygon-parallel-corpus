- en: An Introduction to Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As mentioned at the end of the previous chapter, in this chapter we are going
    to look at Kubernetes. We will discuss:'
  prefs: []
  type: TYPE_NORMAL
- en: A brief history of Kubernetes—where did it come from?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How does it operate?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the use cases for Kubernetes and who is using it?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why would you run serverless on servers?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A brief history of Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we discuss where Kubernetes came from, we should quickly discuss what
    Kubernetes is. It is pronounced **koo-ber-net****-eez** and sometimes referred
    to as **K8s**. **Kubernetes** is the Greek name for a helmsman or pilot of a ship,
    which is apt when you consider what Kubernetes is designed to do. The project''s
    website, which you can find at [https://kubernetes.io/](https://kubernetes.io/),
    describes it as:'
  prefs: []
  type: TYPE_NORMAL
- en: '"An open-source system for automating deployment, scaling, and management of
    containerized applications."'
  prefs: []
  type: TYPE_NORMAL
- en: The project has its roots in an internal project at Google called **Borg**.
    Google has been a longtime user of container technology, long before Docker made
    a splash.
  prefs: []
  type: TYPE_NORMAL
- en: Control groups
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Google's own container journey started in 2006 when two of their engineers made
    a start on the **control groups** (**cgroups**)project. This is the Linux kernel
    feature which makes it possible to isolate resources such as RAM, CPU, networking,
    and disk I/O for a collection of processes. cgroups was initially released in
    2007, and in early 2008 the functionality was merged into the Linux kernel mainline
    version 2.6.24.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the release notes for version 2.6.24 of the Linux kernel at [https://kernelnewbies.org/Linux_2_6_24](https://kernelnewbies.org/Linux_2_6_24).
    You can find information about the introduction of cgroups at *point 10* in the
    *Important things* list where it discusses the framework that allows cgroups to
    hook into the kernel.
  prefs: []
  type: TYPE_NORMAL
- en: lmctfy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A few years later, in October 2013, Google released an open source version of
    their own container system called **lmctfy**, which is actually short for **Let
    Me Contain That For You**. This tool is actually what they used on their own servers
    to enable them to run Linux application containers, and it was designed as an
    alternative to LXC.
  prefs: []
  type: TYPE_NORMAL
- en: lmctfy, LXC, and Docker all occupy the same space. To this end, Google actually
    stopped all development on lmctfy in 2015\. The project's GitHub page has an announcement
    that states that Google has been collaborating with Docker and they are porting
    the core concepts of lmctfy to libcontainer.
  prefs: []
  type: TYPE_NORMAL
- en: Borg
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is where the Borg project comes in. Google uses containers a lot, and
    when I say a lot I mean *a lot*. In May 2014, Joe Beda from Google gave a presentation
    at Gluecon entitled *Containers At Scale*. There were a few takeaway quotes from
    the presentation such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '"Everything at Google runs in a container."'
  prefs: []
  type: TYPE_NORMAL
- en: 'And the one that gets talked about the most is:'
  prefs: []
  type: TYPE_NORMAL
- en: '"We start over 2 billion containers per week."'
  prefs: []
  type: TYPE_NORMAL
- en: This works out at around 3,000 per second and, during the talk, it was mentioned
    that the number didn't include any long-running containers.
  prefs: []
  type: TYPE_NORMAL
- en: While Joe went into some detail about how Google was using containers at that
    time, he did not mention anything directly about the Borg project; instead, it
    was simply referred to as a cluster scheduler.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final takeaway from the presentation was the slide entitled *Declarative
    Over Imperative*, which introduced the following concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Imperative**: Start this container on that server'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Declarative**: Run 100 copies of this container with a target of <= 2 tasks
    down at any time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This concept explains how Google was able to launch those 2 billion containers
    per week without having to really manage well over 2 billion containers.
  prefs: []
  type: TYPE_NORMAL
- en: It wasn't until Google published a paper entitled *Large-scale cluster management
    at Google with Borg* in 2015 that we really got an insight into the practices
    and design decisions that went into the cluster scheduler mentioned by Joe Beda
    the previous year.
  prefs: []
  type: TYPE_NORMAL
- en: The paper talks about how Google's internal tooling, called Borg, runs thousands
    of jobs, which go to make up pretty much all of Google's applications across clusters
    made up of tens of thousands of machines.
  prefs: []
  type: TYPE_NORMAL
- en: It then goes on to reveal that customer-facing services such as Google Mail,
    Google Docs, and Google Search are all served from Borg-managed clusters as well
    as their own internal tools. It details the job specification language that users
    can use to declare their desired state, making it easy for users to deploy their
    applications without having to worry about all of the steps needed to deploy their
    application in a highly available configuration across Google's infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: I would recommend reading through the paper as it gives an excellent overview
    of how Google approaches its own container services.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, in case you are wondering, Borg was named after the alien race from the
    *Star Trek: The Next Generation* TV show.'
  prefs: []
  type: TYPE_NORMAL
- en: Project Seven
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In 2014 Joe Beda, Brendan Burns, and Craig McLuckie were joined by Brian Grant
    and Tim Hockin on Project Seven.
  prefs: []
  type: TYPE_NORMAL
- en: This project, named after the *Star Trek* character *Seven of Nine*, aimed to
    make a friendlier version of Borg. By the time of the first commit, the project
    had an external name, Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: You can see the first commit at [https://github.com/kubernetes/kubernetes/commit/2c4b3a562ce34cddc3f8218a2c4d11c7310e6d56](https://github.com/kubernetes/kubernetes/commit/2c4b3a562ce34cddc3f8218a2c4d11c7310e6d56)
    and the first really stable release, which came four months later, can be found
    at [https://github.com/kubernetes/kubernetes/releases/tag/v0.4](https://github.com/kubernetes/kubernetes/releases/tag/v0.4).
  prefs: []
  type: TYPE_NORMAL
- en: Initially, the aim of Kubernetes was to take everything Google had learned from
    Borg and running its large container clusters and open source it as a way of attracting
    customers to Google's own public Cloud Platform—which is why you may still find
    reference to the project's original GitHub page at [https://github.com/GoogleCloudPlatform/kubernetes/](https://github.com/GoogleCloudPlatform/kubernetes/).
  prefs: []
  type: TYPE_NORMAL
- en: However, by the time of its 1.0 release in July 2015, Google had seen that it
    had quickly become much more than that and they joined the Linux Foundation, Twitter,
    Intel, Docker, and VMware (to name a few) in forming the Cloud Native Computing
    Foundation. As part of this new partnership, Google donated the Kubernetes project
    as the foundation of the new group.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since then, other projects have joined Kubernetes, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Prometheus ([https://prometheus.io/](https://prometheus.io/)), originally developed
    by SoundCloud, is a time series database that can be used to store metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fluentd ([https://www.fluentd.org/](https://www.fluentd.org/)) is a data collector
    that allows you to take data from many different sources, filter or normalize
    it, and then route it to a storage engine such as Elasticsearch, MongoDB or Hadoop
    (to name a few)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: containerd ([http://containerd.io/](http://containerd.io/)) is an open-source
    container runtime originally developed by Docker to implement Open Container Initiative
    standards
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CoreDNS ([https://coredns.io/](https://coredns.io/)) is a DNS service built
    entirely on plugins, meaning that you can create DNS services that traditionally
    would be extremely complex to configure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As well as this, new members such as AWS, Microsoft, Red Hat, and Oracle are
    all lending their support and resources to the foundation's projects.
  prefs: []
  type: TYPE_NORMAL
- en: An overview of Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have an idea of how Kubernetes came to be, we should walk through
    all of the different components that go to make up a typical Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes itself is written in Go. While the project's GitHub page shows that
    the project is currently 84.9% Go, the rest, 5.8% HTML, 4.7% Python, and 3.3%
    Shell (with the remainder being configuration/spec files, and so on), are all
    documentation and helper scripts.
  prefs: []
  type: TYPE_NORMAL
- en: Go is a programming language developed and open sourced by Google who describes
    it as *A fast, statically typed, compiled language that feels like a dynamically
    typed, interpreted language.* For more information, see [https://golang.org/](https://golang.org/).
  prefs: []
  type: TYPE_NORMAL
- en: Components
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two main server roles with Kubernetes: masters and nodes; each of
    these roles is made up of several components.'
  prefs: []
  type: TYPE_NORMAL
- en: Master servers are the brains of the cluster and they make decisions on where
    pods (more on those in the next section) are deployed within the cluster, as well
    as acting on and looking at the health of not only the cluster, but also the pods
    themselves.
  prefs: []
  type: TYPE_NORMAL
- en: 'The core components of a master server are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kube-apiserver`: This is the frontend to your Kubernetes control panel; no
    matter what you use to manage your cluster it will be talking directly to this
    API service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`etcd`: `etcd` is a distributed key-value store that Kubernetes uses to store
    the state of your cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kube-controller-manager`: This service does behind-the-scenes work to maintain
    your cluster. It looks for nodes joining and leaving the cluster, ensuring that
    the correct number of pods are running, and that they are healthy and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cloud-controller-manager`: This service is new to Kubernetes. It works alongside
    `kube-controller-manager` and its purpose is to interact with the APIs of cloud
    providers such as AWS, Google Cloud, and Microsoft Azure. An example of the tasks
    it performs would be that, if a node was to be removed from the cluster, it would
    check your cloud services API to see if the node still exists. If it does then
    there could be a problem; if not, then more than likely the node has been removed
    because of a scaling event.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kube-scheduler`: This chooses where pods should be launched based on a series
    of rules, utilization, and availability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next up we have nodes. Once deployed, the master interacts with components which
    are installed on the nodes to effect change within the cluster; these are where
    your pods run.
  prefs: []
  type: TYPE_NORMAL
- en: 'The components that go to make up the nodes are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kubelet`: This is the main component that runs on the node. It is responsible
    for accepting instructions from and reporting back to the master servers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kube-proxy`: This service helps the cluster communicate. It acts as a basic
    proxy for all network traffic on the nodes, and is capable of configuring TCP/UDP
    forwarding or acting as a TCP/UDP round-robin load balancer to a number of backends.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker` or `rkt`: These are the actual container engines on the nodes. The
    `kubelet` service interacts with these to launch and manage the containers running
    on each of your cluster nodes. Throughout the following chapters, we will look
    at launching nodes running both.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`supervisord`: This process manager and monitor maintains the availability
    of other services such as `kubelet`, `docker`, and `rkt` on the nodes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fluentd`: This service helps with cluster-level logging.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You may have noticed that the only mention of containers in these services was
    `docker` and `rkt`. Kubernetes does not actually directly interact with your containers;
    instead, it communicates with a pod.
  prefs: []
  type: TYPE_NORMAL
- en: Pods and services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As already mentioned, Kubernetes does not deploy containers; instead, it launches
    pods. In its most simple form, a pod can actually be a single container; however,
    typically a pod is made up of several containers, storage, and networking.
  prefs: []
  type: TYPE_NORMAL
- en: The following is meant to be illustrative and not a practical example; we will
    be working through a practical example in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Think of a pod as a complete application; for example, if you were running
    a simple web application it would probably be running a single NGINX container—the
    pod definition file for this would look something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we are providing some simple metadata about our pod, which in
    this case is just the name so we can identify it. We then have a single container
    defined, which is running the latest NGINX image from the Docker hub and port
    `8080` is exposed.
  prefs: []
  type: TYPE_NORMAL
- en: 'As it stands, this pod is quite useless as we are only going to display a Welcome
    to nginx! page. Next up, we need to add a volume to store our website data in.
    To do this, our pod definition file would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we are now creating a volume called `web-data` and mounting
    it read-only at `/srv/www`, which is the default web root on our NGINX container.
    It is still a little pointless as our volume is empty, meaning that all our visitors
    will see is a 404 page.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s add a second container, which will sync our website''s HTML from an
    Amazon S3 bucket:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we have two containers: the NGINX one and now a container running the `s3
    sync` command ([https://github.com/ocastastudios/docker-sync-s3/](https://github.com/ocastastudios/docker-sync-s3/)).
    This will copy all of our website data from the Amazon S3 bucket called `my-awesome-website`
    to the volume that is also being shared with the NGINX container. This means we
    now have a website; note that this time, as we want to write to the volume, we
    are not mounting it read-only.'
  prefs: []
  type: TYPE_NORMAL
- en: So far, so good, you might be thinking to yourself; we have a pod serving our
    website that is being deployed from an Amazon S3 bucket, which is all true. However,
    we have not quite finished. We have a pod running, but we need to expose that
    pod to the network to be able to access it in a browser.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, we need to launch a service. For our example, the service file
    would look something like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the service definition looks similar to the pod one. We are
    setting a name using the metadata section. We are then selecting our NGINX pod
    and mapping port `80` to port `8080`, which is what our pod is listening on.
  prefs: []
  type: TYPE_NORMAL
- en: As already mentioned, we will look at this in more detail in the next chapter
    when we launch our first Kubernetes cluster, but for now, this should give you
    a good idea of how Kubernetes hangs together.
  prefs: []
  type: TYPE_NORMAL
- en: Workloads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we looked at pods and services. While these can be
    launched manually, you also can use controllers to manage your pods. These controllers
    allow for different types of workload to be executed. We are going to take a quick
    look at the different types of controller and also discuss when you would use
    them.
  prefs: []
  type: TYPE_NORMAL
- en: ReplicaSet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A ReplicaSet can be used to launch and maintain a number of copies of the the
    same pod. For example, using the NGINX pod we discussed in the previous section,
    we could create a ReplicaSet that launches three copies of the same pod. Traffic
    could then be load-balanced between the three pods.
  prefs: []
  type: TYPE_NORMAL
- en: Our three pods can be spread across multiple hosts, meaning that, if a host
    wants to disappear for any reason, taking one of our pods out of service, it will
    automatically be replaced on a healthy node. You can also use a ReplicaSet to
    both automatically and manually add and remove pods.
  prefs: []
  type: TYPE_NORMAL
- en: Deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One thing you may be thinking you will be able to do with a ReplicaSet is rolling
    upgrades and rollbacks. Unfortunately, ReplicaSets can only replicate the same
    version of a pod; luckily, this is where deployments come in.
  prefs: []
  type: TYPE_NORMAL
- en: 'A deployment controller is designed to update a ReplicaSet or pod. Lets use
    NGINX as an example. As you can see from the following definition, we have `3`
    replicas all running NGINX version `1.9.14`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '`kubectl` is the command-line client for Kubernetes; we will be looking at
    this in more detail in our next chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We could deploy this using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now say we want to update the version of the NGINX image used. We simply need
    to run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This will update each pod in turn until all of the pods are running the new
    version of NGINX.
  prefs: []
  type: TYPE_NORMAL
- en: StatefulSets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This controller is new to Kubernetes and has been designed to replace PetSets.
    As you may have guessed by the name, pods maintain their state as part of a deployment.
    They are designed to have:'
  prefs: []
  type: TYPE_NORMAL
- en: Consistent unique network identifiers throughout the pod's life cycle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Persistent storage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graceful deployment and scaling executed in the order you define
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User-defined and controlled automated rolling updates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So while there is a change in name, you should think of StatefulSets as pets
    and ReplicaSets as cattle.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes use cases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have already touched upon in this chapter, Kubernetes can run pretty much
    anywhere, from just your local machine (which we will cover in our next chapter),
    from your on-premise hardware of virtual machine infrastructure to potential spanning
    hundreds of public cloud instances in AWS, Microsoft Azure, or Google Cloud. In
    fact, you could even span multiple environments with your Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: This means that you get a consistent experience no matter where you are running
    your application, but also get to take advantage of your underlying platform's
    features, such as load balancing, persistent storage, and auto scaling, without
    have to really design your application to be aware it is running on, say, AWS
    or Microsoft Azure.
  prefs: []
  type: TYPE_NORMAL
- en: One of the common threads you will notice when reading through success stories
    is that people are talking about not being locked into one particular vendor.
    As Kubernetes is open source, they are not locked into any licensing costs. If
    they have a problem or want to add functionality, they are able to dive straight
    into the source code and make changes; they can also contribute any changes they
    make back to the project via a pull request.
  prefs: []
  type: TYPE_NORMAL
- en: Also, as already discussed, using Kubernetes allows them to not get locked into
    any one particular platform vendor or architecture. This is because it is reasonable
    to assume Kubernetes will perform in exactly the same way when installed on other
    platforms. Because of this, all of a sudden you are able to take your application
    and move it between providers with relative ease.
  prefs: []
  type: TYPE_NORMAL
- en: Another common use case is operations teams using Kubernetes as an **Infrastructure
    as a Service** (**IaaS**) platform. This allows them to offer their developers
    resources they can consume via APIs, the web, and CLIs, meaning that they can
    easily hook into their own workflows. It also provides a consistent environment
    for local development, all the way from staging or **user acceptance testing**
    (**UAT**) to eventually running their applications in production.
  prefs: []
  type: TYPE_NORMAL
- en: This is part of the reason why using Kubernetes to execute your serverless workloads
    is a good idea. You are not locked in by any one provider, such as AWS or Microsoft
    Azure. In fact, you should think of Kubernetes as a cloud platform like the ones
    we looked at in [Chapter 1](37d92482-56fd-4329-8b81-01acc97e9c0c.xhtml), *The
    Serverless Landscape*; it has a web-based console, an API, and a command-line
    client.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are several case studies about Kubernetes where users go into detail
    on their journey with using Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Wink**: [https://kubernetes.io/case-studies/wink/](https://kubernetes.io/case-studies/wink/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Buffer**: [https://kubernetes.io/case-studies/buffer/](https://kubernetes.io/case-studies/buffer/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ancestry**: [https://kubernetes.io/case-studies/ancestry/](https://kubernetes.io/case-studies/ancestry/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Wikimedia Foundation**: [https://kubernetes.io/case-studies/wikimedia/](https://kubernetes.io/case-studies/wikimedia/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are also talks, interviews, and presentations from the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The New Times**: [https://www.youtube.com/watch?v=P5qfyv_zGcU](https://www.youtube.com/watch?v=P5qfyv_zGcU)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monzo**: [https://www.youtube.com/watch?v=YkOY7DgXKyw](https://www.youtube.com/watch?v=YkOY7DgXKyw)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Goldman Sachs**: [https://blogs.wsj.com/cio/2016/02/24/big-changes-in-goldmans-software-emerge-from-small-containers/](https://blogs.wsj.com/cio/2016/02/24/big-changes-in-goldmans-software-emerge-from-small-containers/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, you can read more about the Cloud Native Computing Foundation at  [https://www.cncf.io/](https://www.cncf.io/).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we spoke a lot about where Kubernetes came from and we also  covered
    some of its use cases. We also looked at some of the basic functionality.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to get hands-on with Kubernetes by installing
    Minikube locally. Once we have our local Kubernetes installation, we will be ready
    to proceed to [Chapter 4](f1b36345-157f-4e54-970c-5f948110ad0f.xhtml), *Introducing
    Kubeless Functioning*, where we will start to deploy our first serverless functions
    on Kubernetes.
  prefs: []
  type: TYPE_NORMAL
