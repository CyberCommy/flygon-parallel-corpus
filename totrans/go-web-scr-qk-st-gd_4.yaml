- en: Parsing HTML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we have dealt with whole web pages, which is not really
    practical for most web scrapers. Although it is nice to have all of the content
    from a web page, most of the time, you will only need small pieces of information
    from each page. In order to extract this information, you must learn to parse
    the standard formats of the web, the most common of these being HTML.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is the HTML format
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Searching using the strings package
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Searching using the regexp package
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Searching using XPath queries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Searching using Cascading Style Sheets selectors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the HTML format?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'HTML is the standard format used to provide web page context. An HTML page
    defines which elements a browser should draw, the content and style of the elements,
    and how the page should respond to interactions from the user. Looking back at
    our [http://example.com/index.html](http://example.com/index.html) response, you
    can see the following, which is what an HTML document looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Files that adhere to the HTML specification follow a strict set of rules that
    define the syntax and structure of the document. By learning these rules, you
    can quickly and easily retrieve any information from any web page.
  prefs: []
  type: TYPE_NORMAL
- en: Syntax
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: HTML documents define elements of a web page by using tags with element names.
    Tags are always surrounded by angle brackets, such as the `<body>` tag. Each element
    defines the end of a tag set by using a forward slash before the tag name, such
    as `</body>`. The contents of the element lie between a set of opening and closing
    tags. For example, everything between the `<body>`, and matching `</body>` tag,
    defines the content of the body element.
  prefs: []
  type: TYPE_NORMAL
- en: Some tags also have extra properties defined in key-value pairs called attributes.
    These are used to describe extra information about the element. In the example
    shown, there is an `<a>` tag that has an attribute called `href`, whose value
    is [https://www.iana.org/domains/example](https://www.iana.org/domains/example).
    In this case, the `href` is a property of the `<a>` tag and tells the browser
    that this element links to the URL provided. We'll look deeper into navigating
    these links in a later chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Each HTML document has a specific layout starting with the `<!doctype>` tag.
    This tag is used to define the version of the HTML specification used to validate
    this specific document. In our case, the `<!doctype html>` refers to the HTML
    5 specification. You may sometimes see tags such as this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This would describe an `HTML 4.01` (strict) web page that follows definitions
    provided at the URL provided. We will not go into using the provided definition
    to validate the page in this book, as it is usually not necessary to do so.
  prefs: []
  type: TYPE_NORMAL
- en: Following the `<!doctype>` tag is the `<html>` tag, which holds the actual content
    of the web page. Inside the `<html>` tag, you will find the `<head>` and `<body>`
    tags for the document. The `<head>` tag contains metadata about the page itself,
    such as the title, as well as external files to include for building the web page.
    These files may be for styling, or for describing how elements react to user interactions.
  prefs: []
  type: TYPE_NORMAL
- en: On the actual web page at [http://example.com/index.html](http://example.com/index.html),
    you can see the `<style>` tag used to describe the sizes, colors, fonts, and spacing
    for various types of elements on the web page. This information was removed from
    the HTML document in this book to preserve space.
  prefs: []
  type: TYPE_NORMAL
- en: The `<body>` tag contains the bulk of the data that you will be interested in
    scraping. Inside the `<body>` element, you will find all of the text, images,
    videos, and links containing information for your web scraping needs. Collecting
    the data you need from the web page can be done in many different ways; you will
    see some of the common ways in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Searching using the strings package
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most basic way to search for content is to use the `strings` package from
    the Go standard library. The `strings` package allows you to perform various operations
    on String objects, including searching for matches, counting occurrences, and
    splitting strings into arrays. The utility of this package can cover some use
    cases that you may run into.
  prefs: []
  type: TYPE_NORMAL
- en: Example – Counting links
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One quick and easy piece of information that we could extract using the `strings`
    package is to count the number of links that are contained in a web page. The
    `strings` package has a function called `Count()`, which returns the number of
    times a substring occurs in a string. As we have seen before, links are contained
    in `<a>` tags. By counting the number of occurrences of `"<a"`, we can get a general
    idea of the number of links in a page. An example would look like the one given
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the `Count()` function is used to find the number of occurrences
    of `"<a"` in the home page for the Packt Publishing website.
  prefs: []
  type: TYPE_NORMAL
- en: Example – Doctype check
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another useful method in the `strings` package is the `Contains()` method.
    This is used to check for the existence of a substring in a string. For example,
    you could check for the HTML Version used to build a web page similar to the one
    given here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This example looks for information contained in a `<!doctype>` tag to check
    if it contains certain indicators for the HTML Version. Running this code will
    show you that the home page for Packt Publishing is built to the HTML 5 specification.
  prefs: []
  type: TYPE_NORMAL
- en: Relying on the `strings` package can reveal some very light information about
    a web page, but it does have its shortcomings. In both of the previous examples,
    the matches could be misleading if there are sentences in the document that contain
    the strings in unexpected places. Over generalizing a string search can lead to
    misinformation that can be avoided using more robust tools.
  prefs: []
  type: TYPE_NORMAL
- en: Searching using the regexp package
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `regexp` package in the Go standard library provides a deeper level of search
    by using regular expressions. This defines a syntax that allows you to search
    for strings in more complex terms, as well as retrieving strings from a document.
    By using capture groups in regular expressions, you can extract data matching
    a query from the web page. Here are a few useful tasks that the `regexp` package
    can help you achieve.
  prefs: []
  type: TYPE_NORMAL
- en: Example – Finding links
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous section, we used the `strings` package to count the number
    of links on a page. By using the `regexp` package, we can take this example further
    and retrieve the actual links with the following regular expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This query should match any string that looks like a URL, inside an `href` attribute,
    inside of `<a>` tags.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following program prints all of the links on the Packt Publishing home
    page. This same technique could be used to collect all of the images using querying
    for the `src` attributes of `<img>` tags:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Example – Finding prices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Regular expressions can also be used to find content displayed on the web page
    itself. For example, you may be trying to find the price of an item. Let''s look
    at the following example that shows the price of the *Hands-On Go Programming*
    book from Packt Publishing''s website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This program looks for a text string matching `main-book-price`, then looks
    for a USD-formatted decimal on the following line.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see that regular expressions can be used to extract strings in a document
    where the `strings` package is used mostly for discovering strings. Both of these
    techniques suffer from the same issue: you might match strings in unexpected places.
    In order to have a more fine-grained approach, the search needs to be more structured.'
  prefs: []
  type: TYPE_NORMAL
- en: Searching using XPath queries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous examples for parsing HTML documents, we treated HTML simply
    as searchable text, where you can discover information by looking for specific
    strings. Fortunately, HTML documents actually have a structure. You can see that
    each set of tags can be viewed as some object, called a node, which can, in turn,
    contain more nodes. This creates a hierarchy of root, parent, and child nodes,
    providing a structured document. In particular, HTML documents are very similar
    to XML documents, although they are not fully XML-compliant. Because of this XML-like
    structure, we can search for content in the pages using XPath queries.
  prefs: []
  type: TYPE_NORMAL
- en: XPath queries define a way to traverse the hierarchy of nodes in an XML document,
    and return matching elements. In our previous examples, where we were looking
    for `<a>` tags in order to count and retrieve links, we needed to search for the
    tags by string. This method can be problematic if similar matching strings are
    found in unexpected places in an HTML document, such as in a code comment or escaped
    text. If we use XPath queries such as `//a/@href`, we can traverse the HTML document
    structure for the actual `<a>` tag node and retrieve the `href` attribute.
  prefs: []
  type: TYPE_NORMAL
- en: Example – Daily deals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using a structured querying language like XPath, you can easily collect unformatted
    data as well. In our previous examples, we've mostly looked at the prices of products.
    Prices are simpler to deal with because they generally follow a specific format.
    For example, you can use regular expressions to look for a dollar sign, followed
    by a one or more digits, a period, and two more digits. On the other hand, if
    you wanted to retrieve a block or multiple blocks of text where the content had
    no format, it would become more difficult to do so with basic string searches.
    XPath simplifies this by allowing you to retrieve all of the text content inside
    of a node.
  prefs: []
  type: TYPE_NORMAL
- en: The Go standard library has basic support for the handling of XML documents
    and elements; unfortunately, there is no XPath support. However, the open source
    community has built various XPath libraries for Go. The one I would recommend
    is `htmlquery` by GitHub user `antchfx`.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can obtain this library by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The following example demonstrates how you can scrape daily deals using an
    XPath query to discover some basic product information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This program selects any `text()` found in the `div` element containing a `class`
    attribute, with the matching value of `dotd-main-book-summary`. This query also
    returns the names of the nodes that are children of targeted `div` elements, for
    example, `div` and `h2`, as well as empty text nodes. For this reason, we drop
    any known HTML tags (using a regular expression) and only print the remaining
    text nodes that are not empty strings.
  prefs: []
  type: TYPE_NORMAL
- en: Example – Collecting products
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this example, we will use an XPath query to retrieve the latest releases
    from the Packt Publishing website. On this web page, there are a series of `<div>`
    tags that contain more `<div>` tags, which will eventually lead to our information.
    Each of these `<div>` tags hold an attribute called `class`, which describes what
    the purpose of the node is. In particular, we are concerned with the `landing-page-row` class.
    The book-related `<div>` tags within the `landing-page-row` class have an attribute
    called `itemtype`, which tells us that the `div` is for a book and should contain
    other attributes holding the names and prices. It would not be possible to achieve
    this with the `strings` package, and a regular expression would be very laborious
    to design.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Using an XPath query that directly targets the elements in the document directly,
    we are able to navigate to the exact attribute of the exact node to retrieve the
    name and price of each of the books.
  prefs: []
  type: TYPE_NORMAL
- en: Searching using Cascading Style Sheets selectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can see how using a structured query language makes searching for, and retrieving,
    information much easier than basic string searches. However, XPath was designed
    for generic XML documents, not HTML. There is another structured query language
    that is made specifically for HTML. **Cascading Style Sheets** (**CSS**) were
    created to provide a way to add stylistic elements to HTML pages. In a CSS file,
    you would define a path to an element or multiple elements, and what describes
    the appearance. The definitions for the path to the element are called CSS selectors
    and are written specifically for HTML documents.
  prefs: []
  type: TYPE_NORMAL
- en: CSS selectors understand common attributes that we could use in searching HTML
    documents. In the previous XPath examples, we often used a query such as `div[@class="some-class"]`
    in order to search for elements with the class name `some-class`. CSS selectors
    offer a shorthand for `class` attributes by simply using a `.`. The same XPath
    query would look like `div.some-class` as a CSS query. Another common shorthand
    used here is searching elements with an `id` attribute, which is represented in
    CSS as a `#` symbol. In order to find an element with the `id` of `main-body`,
    you would use `div#main-body` as a CSS selector. There are many other niceties
    in the CSS selector specification that expand what can be done via XPath, as well
    as simplifying common queries.
  prefs: []
  type: TYPE_NORMAL
- en: Although there is no support for CSS selectors in the Go standard library, once
    again, the open source community has many tools that provide this functionality,
    the best of which is `goquery` by GitHub user `PuerkitoBio`.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can obtain the library by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Example – Daily deals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following examples will refine the XPath example, using `goquery` in place
    of `htmlquery`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Using `goquery`, the search for the daily deals becomes much more succinct.
    In this query, we use one of the helper features that CSS selectors offer by using
    the `$=` operator. Instead of looking for the `itemtype` attribute, matching the
    exact string `http://schema.org/Product`, we can simply match the string that
    *ends with* `/Product`. We also use the `.` operator to look for the `landing-page-row`
    class. One key difference to note between this example and the XPath example is
    that you do not need to match the entire value of the class attribute. When we
    were searching with XPath, we had to use `@class="landing-page-row cf"` as a query.
    In CSS, is it not necessary to have exact matches for classes. As long as the
    element contains the `landing-page-row class`, it matches.
  prefs: []
  type: TYPE_NORMAL
- en: Example – Collecting products
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the code given here, you can see the CSS selector version of the collecting
    products example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In this example, you can use CSS queries to return all of the text from all
    of the child elements as well. We use the `:not()` operator to exclude the countdown
    timer, and finally, to process the lines of text to ignore spaces and blank lines.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can see that there are various ways of extracting data from HTML pages using
    different tools. Basic string searches and `regex` searches can collect information
    using very simple techniques, but there are cases where more structured query
    languages are needed. XPath provides great searching capabilities by assuming
    the document is XML-formatted and can cover generic searches. CSS selectors are
    the simplest way to search for and extract data from HTML documents and provide
    many helpful features that are HTML-specific.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 5](a4a15c5d-908d-4a1c-bce4-0bf2181c80e3.xhtml), *Web Scraping Navigation*,
    we will look at the best ways to crawl the internet efficiently and safely.
  prefs: []
  type: TYPE_NORMAL
