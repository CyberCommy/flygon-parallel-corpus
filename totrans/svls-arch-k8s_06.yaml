- en: 6\. Upcoming Serverless Features in Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Learning Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will be able to:'
  prefs: []
  type: TYPE_NORMAL
- en: Utilize the concepts and components of Knative to deploy applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set up Knative on a GKE cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploy applications on Knative and configure autoscaling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploy applications on Google Cloud Run
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set up Virtual Kubelet on Azure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploy applications with Virtual Kubelet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter covers Knative, Google Cloud Run, and Virtual Kubelet, which offers
    the advantages of serverless on top of a Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Serverless with Kubernetes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous chapter, we extensively studied the various setup options and
    platforms used in Kubernetes. We also covered the autoscaling feature of Kubernetes
    and implemented it in an application deployed on a cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes and serverless are two of the trending topics in the IT industry,
    but these two topics are often discussed independently of each other. Kubernetes
    is a platform for managing containerized applications, and serverless is an execution
    model that abstracts away the infrastructure so software developers can focus
    on their application logic. However, a combination of these two concepts will
    achieve the same goal of making the software developer's life much easier.
  prefs: []
  type: TYPE_NORMAL
- en: A few platforms have emerged recently that bring serverless features to containers
    by abstracting away the complexities of managing containers and any underlying
    infrastructure. These platforms run serverless workloads on Kubernetes clusters
    and provide many benefits, including autoscaling, scale to zero, per-usage billing,
    event-driven capabilities, integrated monitoring, and integrated logging features.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will be discussing three technologies that offer the benefits
    of serverless on top of a Kubernetes cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: Knative
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Cloud Run
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Virtual Kubelet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to Knative
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Knative is an open source project started by Google with contributions from
    over 50 other companies, including Pivotal, Red Hat, IBM, and SAP. Knative extends
    Kubernetes by introducing a set of components to build and run serverless applications
    on top of it. This framework is great for application developers who are already
    using Kubernetes. Knative provides tools for them to focus on their code without
    worrying about the underlying architecture of Kubernetes. It introduces features
    such as automated container builds, autoscaling, scale to zero, and an eventing
    framework, which allows developers to get the benefits of serverless on top of
    Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: The Knative framework is described as a "*Kubernetes-based platform to deploy
    and manage modern serverless workloads*" on the Knative website. The framework
    helps to bridge the gap between containerized applications and serverless applications
    by introducing serverless features such as autoscaling and scale to zero to the
    Kubernetes platform.
  prefs: []
  type: TYPE_NORMAL
- en: 'Knative consists of three main components:'
  prefs: []
  type: TYPE_NORMAL
- en: Build
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serving
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eventing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The Build component has been deprecated in favor of Tekton Pipelines in the
    latest version of Knative. The final release of the Knative Build component is
    available in version 0.7.
  prefs: []
  type: TYPE_NORMAL
- en: Build is the process of building the container images from the source code and
    running them on a Kubernetes cluster. The Knative Serving component allows the
    deployment of serverless applications and functions. This enables serving traffic
    to containers and autoscaling based on the number of requests. The serving component
    is also responsible for taking snapshots of the code and configurations whenever
    a change is made to them. The Knative Eventing component helps us to build event-driven
    applications. This component allows the applications to produce events for and
    consume events from event streams.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates a Knative framework with its dependencies
    and the stakeholders of each component:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1: Knative dependencies and stakeholders'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.1: Knative dependencies and stakeholders'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The bottom layer represents the Kubernetes framework, which is used as the container
    orchestration layer by the Knative framework. Kubernetes can be deployed on any
    infrastructure, such as Google Cloud Platform or an on-premises system. Next,
    we have the **Istio** service mesh layer, which manages network routing within
    the cluster. This layer provides many benefits, including traffic management,
    observability, and security. At the top layer, Knative runs on top of a Kubernetes
    cluster with **Istio**. In the Knative layer, at one end we can see contributors
    who contribute code to the Knative framework through the GitHub project, and at
    the other end we can see the application developers who build and deploy applications
    on top of the Knative framework.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For more information on Istio, please refer to [https://istio.io/](https://istio.io/).
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have this understanding of Knative, let's look at how to install
    Knative on a Kubernetes cluster in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Getting Started with Knative on GKE
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will take you through the process of installing Knative
    on a Kubernetes cluster. We will be using Google Kubernetes Engine (GKE) to set
    up a Kubernetes cluster. GKE is the managed Kubernetes cluster service in the
    Google cloud. It allows us to run Kubernetes clusters without the burden of installing,
    managing and operating our own clusters.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to have the following prerequisites installed and configured to continue
    with this section:'
  prefs: []
  type: TYPE_NORMAL
- en: A Google Cloud account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The gcloud CLI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The kubectl CLI (v1.10 or newer)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'First, we need to set a few environment variables that we will be using with
    the **gcloud** CLI. You should update `<your-gcp-project-name>` with the name
    of your GCP project. We will be using `us-central1-a` as the GCP zone. Execute
    the following commands in your terminal window to set the required environment
    variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2: Setting environment variables'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.2: Setting environment variables'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Set our GCP project as the default project to be used by the `gcloud` CLI commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3: Setting the default GCP project'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.3: Setting the default GCP project'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now we can create the GKE cluster using the `gcloud` command. Knative requires
    a Kubernetes cluster with version 1.11 or newer. We will be using the **Istio**
    plugin provided by GKE for this cluster. The following is the recommended configuration
    for a Kubernetes cluster to run Knative components:'
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes version 1.11 or newer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes nodes with four vCPUs (n1-standard-4)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Node autoscaling enabled for up to 10 nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: API scopes for `cloud-platform`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Execute the following command to create a GKE cluster compatible with these
    requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.4: Creating a GKE cluster'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.4: Creating a GKE cluster'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'It may take a few minutes to set up the Kubernetes cluster. Once the cluster
    is ready, we will use the command `gcloud container clusters get-credentials`
    to fetch the credentials of the new cluster and configure the **kubectl** CLI
    as you can see in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.5: Fetching credentials for the GKE cluster'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.5: Fetching credentials for the GKE cluster'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Now you have successfully created the GKE cluster with **Istio** and configured
    `kubectl` to access the newly created cluster. We can now proceed with the next
    step of installing Knative. We will be installing Knative version 0.8, which is
    the latest available version at the time of writing this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the `kubectl` CLI to apply the Knative components to the Kubernetes
    cluster. First, run the `kubectl apply` command with the `-l knative.dev/crd-install=true`
    flag to prevent race conditions during the installation process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, run the command again without the `-l knative.dev/crd-install=true` flag
    to complete the installation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the command is completed, execute the following commands to check the
    status of the installation. Make sure that all pods have a status of **Running**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image/C12607_06_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.6: Verifying Knative installation'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: At this stage, you have set up a Kubernetes cluster on GKE and installed Knative.
    Now we are ready to deploy our first application on Knative.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 16: Deploying a Sample Application on Knative'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the previous section, we successfully deployed Knative on top of Kubernetes
    and **Istio**. In this exercise, we will deploy our first application on the Knative
    framework. For this deployment, we are going to use a sample web application written
    with Node.js. A Docker image of this application is available in Google Container
    Registry at `gcr.io/knative-samples/helloworld-nodejs`. These steps can be adapted
    to deploy our own Docker image on Docker Hub or any other container registry.
  prefs: []
  type: TYPE_NORMAL
- en: This sample "hello world" application will read an environment variable named
    `TARGET` and print `Hello <VALUE_OF_TARGET>!` as the output. It will print `NOT
    SPECIFIED` as the output if no value is defined for the `TARGET` environment variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by creating the service definition file for our application. This
    file defines application-related information including the application name and
    the application Docker image:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Knative service objects and Kubernetes Service objects are two different types.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a file named `hello-world.yaml` with the following content. This Knative
    service object defines values such as the namespace to deploy this service in,
    the Docker image to use for the container, and any environment variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the `hello-world.yaml` file is ready, we can deploy our application with
    the `kubectl apply` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ Figure 6.7: Deploying the helloworld-nodejs application'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.7: Deploying the helloworld-nodejs application'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The previous command will create multiple objects, including the Knative service,
    configuration, revision, route, and Kubernetes Deployment. We can verify the application
    by listing the newly created objects as in the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8: Verifying helloworld-nodejs application deployment'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.8: Verifying helloworld-nodejs application deployment'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Once our application is deployed successfully, we can invoke this application
    using an HTTP request. For this, we need to identify the external IP address of
    the Kubernetes cluster. Execute the following command to export the value of `EXTERNAL-IP`
    into an environment variable named `EXTERNAL_IP`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.9: Exporting the external IP of the istio-ingressgateway service'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.9: Exporting the external IP of the istio-ingressgateway service'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Next, we need to find the host URL of the `helloworld-nodejs` application. Execute
    the following command and take note of the value of the **URL** column. This URL
    takes the form `http://<application-name>.<namespace>.example.com:`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.10: Listing the helloworld-nodejs route'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.10: Listing the helloworld-nodejs route'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now we can invoke our application using the `EXTERNAL_IP` and `URL` values
    that we noted in the earlier steps. Let''s make a `curl` request with the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.11: Invoking the helloworld-nodejs application'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.11: Invoking the helloworld-nodejs application'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You should receive the expected output as **Hello Knative NodeJS App!**. This
    indicates that we have successfully deployed and invoked our first application
    on the Knative platform.
  prefs: []
  type: TYPE_NORMAL
- en: Knative Serving Component
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous section, we deployed our first Knative application using a
    YAML file of the service type. When deploying the service, it created multiple
    other objects, including configuration, revision, and route objects. In this section,
    let''s discuss each of these objects:'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are four resource types in the Knative Serving component:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Configuration**: Defines the desired state of the application'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Revision**: Read-only snapshots that track the changes in configurations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Route**: Provides traffic routing to revisions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service**: Top-level container for routes and configurations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the relationship between each of these components:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.12: Relationship between Knative services, routes, configurations,
    and revisions'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.12: Relationship between Knative services, routes, configurations,
    and revisions'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The **configuration** is used to define the desired state of the application.
    This will define the container image used for the application and any other configuration
    parameters that are required. A new **Revision** will be created each time a **Configuration**
    is updated. **Revision** refers to a snapshot of the code and the **Configuration**.
    This is used to record the history of **Configuration** changes. A **Route** is
    used to define the traffic routing policy of the application and provides an HTTP
    endpoint for the application. By default, the **Route** will send traffic to the
    latest **Revision** created by the **Configuration**. The **Route** can also be
    configured for more advanced scenarios, including sending traffic to a specific
    **Revision** or splitting traffic to different revisions based on defined percentages.
    **Service** objects are used to manage the whole life cycle of the application.
    While deploying a new application, it is required to create **Configuration**
    and **Route** objects manually, but the **Service** can be used to simplify this
    by creating and managing **Configuration** and **Route** objects automatically.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will be using canary deployment to deploy applications
    with Knative. Let's first understand what exactly canary deployment is.
  prefs: []
  type: TYPE_NORMAL
- en: Canary Deployment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Canary deployment is a deployment strategy used when rolling out a new version
    of code to a production environment. This is a fail-safe process of deploying
    a new version of code into a production environment and switching a small percentage
    of traffic to the new version. This way, the development and deployment teams
    can verify the new version of the code with minimal impact on production traffic.
    Once the verifications are done, all traffic will be switched to the new version.
    In addition to canary deployments, there are several other deployment types, such
    as big bang deployments, rolling deployments, and blue-green deployments.
  prefs: []
  type: TYPE_NORMAL
- en: In the `helloworld-nodejs` application that we deployed in *Exercise 16*, *Deploying
    a Sample App on Knative,* we used the Service object with the `spec.runLatest`
    field, which directs all traffic to the latest available revision. In the following
    exercise, we will be using separate configuration and route objects instead of
    the service object.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For more information on canary deployment technique, refer to [https://dev.to/mostlyjason/intro-to-deployment-strategies-blue-green-canary-and-more-3a3](https://dev.to/mostlyjason/intro-to-deployment-strategies-blue-green-canary-and-more-3a3).
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 17: Canary Deployment with Knative'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will be implementing a canary deployment strategy to deploy
    applications with Knative. First, we will deploy an initial version (version 1)
    of an application and route 100% traffic to that version. Next, we will create
    version 2 of the application and route 50% of traffic to version 1 and the remaining
    50% to version 2\. Finally, we will update the routes to send 100% of traffic
    to version 2.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps will help you complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, start by creating the initial version (`v1`) of the application. Create
    a file named `canary-deployment.yaml` with the following content. This application
    uses the same Docker image (`gcr.io/knative-samples/helloworld-nodejs`) that we
    used previously and sets the `TARGET` environment variable as `This is the first
    version - v1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Deploy the first version of the application with the `kubectl apply` command
    using the YAML file created in the previous step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.13: Creating canary-deployment'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.13: Creating canary-deployment'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let''s get the revision name created by this configuration as we need this
    value in the next step. Execute the `kubectl get configurations` command and retrieve
    the value of the `latestCreatedRevisionName` field:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.14: Getting the latest revision of the canary-deployment configuration'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_14.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.14: Getting the latest revision of the canary-deployment configuration'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: For me, the value returned from the preceding command is `canary-deployment-xgvl8`.
    Note that your value will be different.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is to create the route object. Let''s create a file named `canary-deployment-route.yaml`
    with the following content (please remember to replace `canary-deployment-xgvl8`
    with the revision name that you noted in the previous step). Under the `spec.traffic`
    section, you can see that 100% of traffic is routed to the revision that we created
    previously:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the route object with the `kubectl apply` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.15: Creating the canary-deployment route'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.15: Creating the canary-deployment route'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Make a request to the application and observe the expected output of `Hello
    This is the first version - v1!`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.16: Invoking canary-deployment'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_16.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.16: Invoking canary-deployment'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Once the application is successfully invoked, we can deploy version 2 of the
    application. Update `canary-deployment.yaml` with the following content. In version
    2 of the application, we only need to update the value of the `TARGET` environment
    variable from `This is the first version - v1` to `This is the second version
    - v2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the updated configuration with `kubectl apply`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.17: Updating canary-deployment to version 2'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_17.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.17: Updating canary-deployment to version 2'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now we can check the revisions created, while updating the configuration, using
    the `kubectl get revisions` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.18: Getting the revisions of canary-deployment'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_18.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.18: Getting the revisions of canary-deployment'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let''s get the latest revision created by the `canary-deployment` configuration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.19: Getting the latest revision of the canary-deployment configuration'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_19.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.19: Getting the latest revision of the canary-deployment configuration'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now it''s time to send some traffic to our new version of the application.
    Update the `spec.traffic` section of `canary-deployment-route.yaml` to send 50%
    of the traffic to the old revision and 50% to the new revision:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply changes to the route using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.20: Updating the canary-deployment route'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_20.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.20: Updating the canary-deployment route'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now we can invoke the application multiple times to observe how traffic splits
    between two revisions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we verify version 2 of the application successfully, we can update `canary-deployment-route.yaml`
    to route 100% of the traffic to the latest revision:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the changes to the route using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.21: Updating the canary-deployment route'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_21.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.21: Updating the canary-deployment route'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now invoke the application multiple times to verify that all traffic goes to
    version 2 of the application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: In this exercise, we have successfully used configuration and route objects
    to perform a canary deployment with Knative.
  prefs: []
  type: TYPE_NORMAL
- en: Knative Monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Knative comes with Grafana pre-installed, which is an open source metric analytics
    and visualization tool. The Grafana pod is available in the `knative-monitoring`
    namespace and can be listed with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.22: Listing the Grafana pod'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_22.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.22: Listing the Grafana pod'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We can expose the Grafana UI with the `kubectl port-forward` command, which
    will forward local port `3000` to the port `3000` of the Grafana pod. Open a new
    terminal and execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image/C12607_06_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.23: Port forwarding to the Grafana pod'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Now we can navigate the Grafana UI from our web browser on `http://127.0.0.1:3000`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.24: The Grafana UI'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_24.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.24: The Grafana UI'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Knative''s Grafana dashboard comes with multiple dashboards, including the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.25: Dashboards'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_25.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.25: Dashboards'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Knative Autoscaler
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Knative has a built-in autoscaling feature that automatically scales the application
    pods based on the number of HTTP requests it receives. This will increase the
    pod count when there is increased demand and decrease the pod count when the demand
    decreases. The pod count will scale to zero when pods are idle and there are no
    incoming requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Knative uses two components, the autoscaler, and the activator, to achieve
    the previously mentioned functionality. These components are deployed as pods
    in the `knative-serving` namespace, as you can see in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The activator component is responsible for collecting information about the
    number of concurrent requests to a revision and reporting these values to the
    autoscaler. The autoscaler component will increase or decrease the number of pods
    based on the metrics reported by the activator. By default, the autoscaler will
    try to maintain 100 concurrent requests per pod by scaling pods up or down. All
    Knative autoscaler-related configurations are stored in a configuration map named
    `config-autoscaler` in the `knative-serving` namespace. Knative can also be configured
    to use the **Horizontal Pod Autoscaler** (**HPA**), which is provided by Kubernetes.
    HPA will autoscale pods based on CPU usage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 18: Autoscaling with Knative'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will perform Knative pod autoscaling by deploying a sample
    application:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create an `autoscale-app.yaml` service definition file with the following content.
    This file defines a service named `autoscale-app`, which will use the `gcr.io/knative-samples/autoscale-go:0.1`
    sample Docker image. `autoscaling.knative.dev/target` is used to configure the
    target number of concurrent requests per pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the service definition with the `kubectl apply` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.26: Creating autoscale-app'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_26.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.26: Creating autoscale-app'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Once the application is ready, we can generate a load to the **autoscale-app**
    application to observe the autoscaling. For this, we will use a load generator
    named `hey`. Download the `hey` binary using the following `curl` command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.27: Installing hey'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_27.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.27: Installing hey'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Add execution permission to the `hey` binary and move it into the `/usr/local/bin/`
    path:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.28: Moving hey to /usr/local/bin'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_28.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.28: Moving hey to /usr/local/bin'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now we are ready to generate a load with the `hey` tool. The `hey` tool supports
    multiple options when generating a load. For this scenario, we will use a load
    with a concurrency of 50 (with the `-c flag`) for a duration of 60 seconds (with
    the `-z flag`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'In a separate terminal, watch for the number of pods created during the load:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Open the **Knative Serving - Scaling Debugging** dashboard from Grafana to
    observe how autoscaling increased the pod count during the load and decreased
    the pod count back to zero once the load stopped, as you can see in the following
    screenshots:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.29: Revision pod count metrics'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_29.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.29: Revision pod count metrics'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Figure 6.30: Observed concurrency metrics'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_30.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.30: Observed concurrency metrics'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We have successfully configured Knative's autoscaler and observed autoscaling
    with the Grafana dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud Run
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the previous sections, we discussed Knative. We learned how to install Istio
    and Knative on top of a Kubernetes cluster and how to run Docker images with Knative.
    But the advantages of the Knative platform come with the operational overhead
    of managing the underlying Kubernetes cluster with Istio. GKE, which is the managed
    Kubernetes service from Google Cloud, will help us manage the Kubernetes master
    components, but still, we have to manage all the Kubernetes nodes ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: In order to abstract away all the infrastructure management tasks from the developer,
    Google introduced a new service named Cloud Run. This is a fully managed platform,
    built on the Knative project, to run stateless HTTP-driven containers. Cloud Run
    offers the same set of features as Knative, including autoscaling, scale to zero,
    versioning, and events. Cloud Run was introduced in the Google Cloud Next '19
    conference as the newest member of Google Cloud's serverless compute stack. At
    the time of writing this book, the Cloud Run service is still in beta and only
    available in a limited number of regions.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now perform an exercise to deploy containers on Google Cloud Run.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 19: Deploying Containers on Google Cloud Run'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will be deploying a pre-built Docker image on the Google
    Cloud Run platform.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps will help you complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to your GCP console from your browser and select **Cloud Run** from
    the menu (in the **Compute** category) as shown in the following figure:![Figure
    6.31: GCP menu for Cloud Run'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](image/C12607_06_31.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.31: GCP menu for Cloud Run'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Click on the **CREATE SERVICE** button to create a new service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Fill the create service form with the following values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Container Image URL: [gcr.io/knative-samples/helloworld-nodejs](http://gcr.io/knative-samples/helloworld-nodejs)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Deployment platform: **Cloud Run** (fully managed)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Location: Select any region you prefer from the options'
  prefs: []
  type: TYPE_NORMAL
- en: 'Service name: **hello-world**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Authentication: **Allow unauthenticated invocations**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.32: Cloud Run create service form'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_32.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.32: Cloud Run create service form'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Click on the **CREATE** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now we will be redirected to the deployed service page, which includes details
    about the newly deployed **hello-world** service. We can see that a revision has
    been created called **hello-world-00001**, as shown in the following figure:![Figure
    6.33: Service details page'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](image/C12607_06_33.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.33: Service details page'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Click on the URL link displayed to run the container. Note that the URL will
    be different for every new instance:![Figure 6.34: Invoking the hello-world app'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](image/C12607_06_34.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.34: Invoking the hello-world app'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Next, we are going to deploy a new revision of the application by updating the
    **TARGET** environment variable. Navigate back to the **GCP** console and click
    on the **DEPLOY NEW REVISION** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'From the **Deploy revision to hello-world (us-central1)** form, click on the
    **SHOW OPTIONAL REVISION SETTINGS** link, which will point us to the additional
    setting section:![Figure 6.35: Optional revision settings'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](image/C12607_06_35.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.35: Optional revision settings'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Under the environment variables section, create a new environment variable
    named `TARGET` with the value `Cloud Run Deployment`:![Figure 6.36: Setting the
    TARGET environment variable'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](image/C12607_06_36.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.36: Setting the TARGET environment variable'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Click on the **DEPLOY** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now we can see the new revision of the **hello-world** application called `hello-world-00002`
    with 100% of traffic being routed to the latest revision:![Figure 6.37: The hello-world
    app''s new revision'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](image/C12607_06_37.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.37: The hello-world app''s new revision'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Click on the URL again to run the updated revision:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.38: Invoking the hello-world app'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_38.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.38: Invoking the hello-world app'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We have successfully deployed a pre-built Docker image on the Google Cloud Run
    platform.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Virtual Kubelet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Virtual Kubelet is an open source implementation of Kubernetes' kubelet that
    acts as a kubelet. This is a sandbox project from the **Cloud Native Computing
    Foundation** (**CNCF**), and the first major version (v 1.0) of Virtual Kubelet
    was released on July 8, 2019.
  prefs: []
  type: TYPE_NORMAL
- en: Before diving further into Virtual Kubelet, let's recap what a kubelet is in
    the Kubernetes architecture. A kubelet is an agent that runs on each node in a
    Kubernetes cluster and is responsible for managing pods within the nodes. A kubelet
    takes instructions from the Kubernetes API to identify the pods to be scheduled
    on the node and interacts with the underlying container runtime (for example,
    Docker) of the nodes to ensure that the desired number of pods are running and
    that they are healthy.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to managing pods, the kubelet performs several other tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Updating the Kubernetes API with the current status of the pods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring and reporting node health metrics such as CPU, memory, and disk utilization
    to the Kubernetes master
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pulling Docker images from the Docker registry for the assigned pods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating and mounting volumes for pods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Providing an interface for the API server to execute commands such as `kubectl
    logs`, `kubectl exec`, and `kubectl attach` for the pods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following figure displays a Kubernetes cluster with standard and virtual
    kubelets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.39: Kubernetes cluster with standard kubelets and Virtual Kubelets'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_39.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.39: Kubernetes cluster with standard kubelets and Virtual Kubelets'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Virtual Kubelet will appear as a traditional kubelet from the viewpoint of
    the Kubernetes API. This will run in the existing Kubernetes cluster and register
    itself as a node within the Kubernetes API. Virtual Kubelet will run and manage
    the pods in the same way a kubelet does. But in contrast to the kubelet, which
    runs pods within the nodes, Virtual Kubelet will utilize external services to
    run the pods. This connects the Kubernetes cluster to other services such as serverless
    container platforms. Virtual Kubelet supports a growing number of providers, including
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Alibaba Cloud **Elastic Container Instance** (**ECI**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS Fargate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Batch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Container Instances** (**ACI**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes **Container Runtime Interface** (**CRI**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huawei **Cloud Container Instance** (**CCI**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HashiCorp Nomad
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenStack Zun
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running pods on these platforms come with the benefits of the serverless world.
    We do not have to worry about the infrastructure as it is managed by the cloud
    provider. Pods will scale up and down automatically based on the number of requests
    received. Also, we have to pay only for the utilized resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 20: Deploying Virtual Kubelet on AKS'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we are going to configure Virtual Kubelet on **Azure Kubernetes
    Service** (**AKS**) with the ACI provider. For this exercise, we will be using
    the following services available in Azure.
  prefs: []
  type: TYPE_NORMAL
- en: 'AKS: AKS is a managed Kubernetes service on Azure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'ACI: ACI provides a managed service for running containers on Azure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Azure Cloud Shell: An interactive, browser-based shell that supports both Bash
    and PowerShell.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You need to have the following prerequisites for this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: A Microsoft Azure account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Azure CLI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The kubectl CLI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Helm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will be using Azure Cloud Shell, which has all the previously mentioned
    CLIs pre-installed:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to [https://shell.azure.com/](https://shell.azure.com/) to open Cloud
    Shell in a browser window. Select **Bash** from the **Welcome to Azure Cloud Shell**
    window:![Figure 6.40: The Welcome to Azure Cloud Shell window'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](image/C12607_06_40.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.40: The Welcome to Azure Cloud Shell window'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Click on the **Create storage** button to create a storage account for Cloud
    Shell. Note that this is a one-time task purely for when we are using Cloud Shell
    for the first time:![Figure 6.41: Mounting storage for Cloud Shell'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](image/C12607_06_41.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.41: Mounting storage for Cloud Shell'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The Cloud Shell window will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.42: Cloud Shell window'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_42.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.42: Cloud Shell window'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Once Cloud Shell is ready, we can start creating the AKS cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, we need to create an Azure resource group that allows us to group related
    Azure resources logically. Execute the following command to create a resource
    group named `serverless-kubernetes-group` in the West US (`westus`) region:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.43: Creating an Azure resource group'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_43.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.43: Creating an Azure resource group'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Register your subscription to use the `Microsoft.Network` namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.44: Registering the subscription'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_44.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.44: Registering the subscription'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Next, we will create an Azure Kubernetes cluster. The following command will
    create an AKS cluster named `virtual-kubelet-cluster` with one node. This command
    will take a few minutes to execute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Once AKS cluster creation is successful, the preceding command will return
    some JSON output with the details of the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.45: Creating the AKS cluster'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_45.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.45: Creating the AKS cluster'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Next, we need to configure the kubectl CLI to communicate with the newly created
    AKS cluster. Execute the `az aks get-credentials` command to download the credentials
    and configure the kubectl CLI to work with the `virtual-kubelet-cluster` cluster
    with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We are not required to install the kubectl CLI because Cloud Shell comes with
    kubectl pre-installed.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.46: Configuring kubectl'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_46.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.46: Configuring kubectl'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now we can verify the connection to the cluster from Cloud Shell by executing
    the `kubectl get nodes` command, which will list the nodes available in the AKS
    cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.47: Listing Kubernetes nodes'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_47.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.47: Listing Kubernetes nodes'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'If this is the first time you are using the ACI service, you need to register
    the `Microsoft.ContainerInstance` provider with your subscription. We can check
    the registration state of the `Microsoft.ContainerInstance` provider with the
    following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.48: Checking the registration status of the Microsoft.ContainerInstace
    provider'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_48.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.48: Checking the registration status of the Microsoft.ContainerInstace
    provider'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'If the **RegistrationStatus** column contains a value of **NotRegistered**,
    execute the `az provider register` command to register the `Microsoft.ContainerInstance`
    provider. If the **RegistrationStatus** column contains a value of **Registered**,
    you can continue to the next step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.49: Registering for Microsoft.ContainerInstance provider'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_49.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.49: Registering for Microsoft.ContainerInstance provider'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The next step is to create the necessary `ServiceAccount` and `ServiceAccount`
    objects for the tiller. Create a file named `tiller-rbac.yaml` with the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Then execute the `kubectl apply` command to create the necessary `ServiceAccount`
    and `ClusterRoleBinding` objects:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.50: Creating the ServiceAccount and ClusterRoleBinding objects'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_50.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.50: Creating the ServiceAccount and ClusterRoleBinding objects'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now we can configure Helm to use the tiller service account that we created
    in the previous step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.51: Configuring tiller'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_51.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.51: Configuring tiller'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Once all configurations are done, we can install Virtual Kubelet using the
    `az aks install-connector` command. We will be deploying both Linux and Windows
    connectors with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.52: Installing Virtual Kubelet'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_52.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.52: Installing Virtual Kubelet'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Once the installation is complete, we can verify it by listing the Kubernetes
    nodes. There will be two new nodes, one for Windows and one for Linux:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.53: Listing Kubernetes nodes'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_53.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.53: Listing Kubernetes nodes'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Now we have Virtual Kubelet installed in the AKS cluster. We can deploy an application
    to a new node introduced by Virtual Kubelet. We will be creating a Kubernetes
    Deployment named `hello-world` with the `microsoft/aci-helloworld` Docker image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We need to add a **nodeSelector** to assign this pod specifically to the Virtual
    Kubelet node. Note that Virtual Kubelet nodes are tainted by default to prevent
    unexpected pods from being run on them. We need to add tolerations to the pods
    to allow them to be scheduled for these nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a file named `hello-world.yaml` with the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Deploy the `hello-world` application with the `kubectl apply` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.54: Creating the hello-world deployment'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_54.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.54: Creating the hello-world deployment'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Execute the `kubectl get pods` command with the `-o wide` flag to output a
    list of pods and their respective nodes. Note that the `hello-world-57f597bc59-q9w9k`
    pod has been scheduled on the `virtual-kubelet-virtual-kubelet-linux-westus` node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.55: Listing all pods with the -o wide flag'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_55.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.55: Listing all pods with the -o wide flag'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Thus, we have successfully configured Virtual Kubelet on AKS with ACI and have
    deployed a pod in the Virtual Kubelet node.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now complete an activity where we will be deploying a containerized application
    in a serverless environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 6: Deploy a Containerized Application in a Serverless Environment'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Imagine that you are working for a start-up company and your manager wants you
    to create an application that can return the current date and time for a given
    timezone. This application is expected to receive only a few requests during the
    initial phase but will receive millions of requests in the long run. The application
    should be able to scale automatically based on the number of requests received
    without any modifications. Also, your manager does not want to have the burden
    of managing the infrastructure and expects this application to run with the lowest
    possible cost.
  prefs: []
  type: TYPE_NORMAL
- en: 'Execute the following steps to complete this activity:'
  prefs: []
  type: TYPE_NORMAL
- en: Create an application (in any language you want) that can provide the current
    date and time based on the given `timezone` value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following is some sample application code written in PHP:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Containerize the application according to the guidelines provided by Google
    Cloud Run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following is the content of a sample Dockerfile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: Push the Docker image to a Docker registry.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the application with Cloud Run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.56: Deployment of the application in a serverless environment'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/C12607_06_56.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.56: Deployment of the application in a serverless environment'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution to the activity can be found on page 417.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we discussed the advantages of using serverless on Kubernetes.
    We discussed three technologies that offer the benefits of serverless on top of
    a Kubernetes cluster. These are Knative, Google Cloud Run, and Virtual Kubelet.
  prefs: []
  type: TYPE_NORMAL
- en: First, we created a GKE cluster with Istio and deployed Knative on top of it.
    Then we learned how to deploy an application on Knative. Next, we discussed the
    serving component of Knative and how to perform a canary deployment with configuration
    and route objects. Then we discussed monitoring on Knative and observed how Knative
    autoscaling works based on the number of requests received.
  prefs: []
  type: TYPE_NORMAL
- en: We also discussed Google Cloud Run, which is a fully managed platform, built
    on the Knative project, to run stateless HTTP-driven containers. Then we learned
    how to deploy an application with the Cloud Run service.
  prefs: []
  type: TYPE_NORMAL
- en: In the final section, we studied Virtual Kubelet, which is an open source implementation
    of Kubernetes' kubelet. We learned the differences between normal kubelets and
    Virtual Kubelet. Finally, we deployed Virtual Kubelet on an AKS cluster and deployed
    an application to a Virtual Kubelet node.
  prefs: []
  type: TYPE_NORMAL
- en: In the next three chapters, we will be focusing on three different Kubernetes
    serverless frameworks, namely Kubeless, OpenWhisk, and OpenFaaS.
  prefs: []
  type: TYPE_NORMAL
