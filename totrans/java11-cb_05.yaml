- en: Streams and Pipelines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In Java 8 and 9, the collections API got a major facelift with the introduction
    of streams and internal iteration by leveraging lambda expressions. In Java 10
    (JDK 18.3), new methods—`List.copyOf`, `Set.copyOf`, and `Map.copyOf`—were added
    that allow us to create a new immutable collection from existing instances. Also,
    new methods—  `toUnmodifiableList`, `toUnmodifiableSet`, and `toUnmodifiableMap`—were
    added to the `Collectors` class in the `java.util.stream` package, allowing the
    elements of `Stream` to be collected into an immutable collection. This chapter
    shows you how to use the streams and chain multiple operations to create a pipeline.
    Also, the reader will learn how these operations can be done in parallel. The
    list of recipes includes the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Create immutable collections using the `of()` and `copyOf()` factory methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create and operating on streams
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use numeric streams for arithmetic operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Complete streams by producing collections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Complete streams by producing maps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Complete streams by grouping stream elements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a stream operation pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processing a stream in parallel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lambda expressions described and demonstrated in the previous chapter were introduced
    in Java 8\. Together with functional interfaces, they added the functional programming
    capability to Java, allowing the passing of behavior (functions) as parameters
    to the libraries optimized for the performance of data processing. This way, an
    application programmer can concentrate on the business aspects of the developed
    system, leaving performance aspects to the specialists—the authors of the library.
  prefs: []
  type: TYPE_NORMAL
- en: One example of such a library is the `java.util.stream` package, which is going
    to be the focus of this chapter. This package allows you to have a declarative
    presentation of the procedures that can be subsequently applied to the data, also
    in parallel; these procedures are presented as streams, which are objects of the `Stream` interface. For
    a better transition from the traditional collections to streams, two default methods
    (`stream()` and `parallelStream()`) were added to the `java.util.Collection` interface,
    along with the addition of new factory methods of the stream generation to the `Stream` interface.
  prefs: []
  type: TYPE_NORMAL
- en: This approach takes advantage of the power of aggregation, as discussed in [Chapter
    2](db468cc9-60fa-4966-890a-872bef36ff01.xhtml), *Fast Track to OOP - Classes and
    Interfaces*. Together with other design principles—encapsulation, interface, and
    polymorphism—it facilitates a highly extensible and flexible design, while lambda
    expressions allow you to implement it in a concise and succinct manner.
  prefs: []
  type: TYPE_NORMAL
- en: Today, when the machine learning requirements of massive data processing and
    the fine-tuning of operations have become ubiquitous, these new features reinforce
    the position of Java among a few modern programming languages of choice.
  prefs: []
  type: TYPE_NORMAL
- en: Creating immutable collections using the of() and copyOf() factory methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will revisit traditional methods of creating collections
    and compare them with the `List.of()`, `Set.of()`, `Map.of()`, and `Map.ofEntries()` factory
    methods that came with Java 9, and the `List.copyOf()`, `Set.copyOf()`, and `Map.copyOf()` methods
    that came with Java 10.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before Java 9, there were several ways to create collections. Here is the most
    popular way that was used to create a `List`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run the preceding code, we get this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/97a3612f-48c9-423e-9155-16cc369dc50d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The shorter way of creating the `List` collection is by starting with an array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/378ce09a-1858-4ddb-9424-44f2f1179348.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `Set` collection used to be created similarly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, we can build `Set` by starting with an array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s an illustration of the results of the last two examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0e8f0748-76b5-43bf-ab84-a53ada4ad9bc.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice that, unlike `List`, the order of elements in `Set` is not preserved.
    It depends on the hash code implementation and can change from computer to computer.
    But the order remains the same between the runs on the same computer. Please take
    note of this last fact, because we will come back to it later.
  prefs: []
  type: TYPE_NORMAL
- en: 'And this is how we used to create `Map` before Java 9:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/069d62ab-e65a-4550-a366-cafb7e8d7fbf.png)'
  prefs: []
  type: TYPE_IMG
- en: Although the preceding output preserves the order of the elements, it is not
    guaranteed for `Map` since it is based on the keys that are collected in `Set`.
  prefs: []
  type: TYPE_NORMAL
- en: Those who had to create collections that way often appreciated the JDK enhancement-Proposal
    269 *Convenience Factory Methods for Collections* (JEP 269) that stated,
  prefs: []
  type: TYPE_NORMAL
- en: '"*Java is often criticized for its verbosity*" and its goal was to "*Provide
    static factory methods on the collection interfaces that will create compact,
    unmodifiable collection instances*."'
  prefs: []
  type: TYPE_NORMAL
- en: 'In response to the criticism and the proposal, Java 9 introduced 12 `of()` static
    factory methods for each of the 3 interfaces—`List`, `Set`, and `Map`. The following
    are the factory methods of `List`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 10 overloaded factory methods with a fixed number of elements are optimized
    for performance, and as stated in JEP 269 ([http://openjdk.java.net/jeps/269](http://openjdk.java.net/jeps/269)),
    these methods
  prefs: []
  type: TYPE_NORMAL
- en: '"*avoid array allocation, initialization, and garbage collection overhead that
    is incurred by* *varargs calls.**"*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `of()` factory methods makes the code much more compact:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The `System.out.println()` statement was added to inject a line break between
    the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d60ff266-9bf0-4ad4-bcc0-dba9c10badb5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'One of the 12 static factory methods in the `Map` interface is different from
    the other `of()` methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is an example of its usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'It produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5541fd5e-21ac-4d8c-97fb-9a1d9bcdc4d1.png)'
  prefs: []
  type: TYPE_IMG
- en: And there is no `Map.of()` factory method for an unlimited number of elements.
    One has to use `Map.ofEntries()` when creating a map with more than 10 elements.
  prefs: []
  type: TYPE_NORMAL
- en: In Java 10, the `List.copyOf()`, `Set.copyOf()`, and `Map.copyOf()` methods
    were introduced. They allow us to convert any collection into an immutable collection
    of the corresponding type.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have mentioned already, the `Set.of()`, `Map.of()`, and `Map.ofEntries()`
    methods do not preserve the order of the collection elements. This is different
    from the previous (before Java 9) instances of the `Set` and `Map` behavior of
    preserving the same order while running on the same computer. The `Set.of()`, `Map.of()`,
    and `Map.ofEntries()` methods change the elements' order between runs even on
    the same computer. The order remains the same only during the same run, no matter
    how many times the collection is iterated. Changing the elements' order from one
    run to another on the same computer helps programmers avoid the unwarranted reliance
    on a certain order.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another feature of the collections generated by the `of()` static method of
    the `List`, `Set`, and `Map` interfaces is their immutability. What does this
    mean? Consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, any attempt to add a new element or modify an existing element
    of a collection created using the `List.of()` method results in a `java.lang.UnsupportedOperationException` runtime
    exception.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, the `List.of()` method does not accept a `null` element, so the
    following code throws a `java.lang.NullPointerException` runtime exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The collections created by `Set.of()` and  `Map.of()` have the same behavior
    as the method `List.of()` described earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The `List.copyOf()`, `Set.copyOf()`, and `Map.copyOf()` methods provide another
    way to create an immutable collection based on another collection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that the input parameter can be any collection that has elements of
    the same type or the type that extends the type of the elements of the passed-in
    collection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is not an accident that non-null values and immutability were enforced soon
    after lambda expressions and streams were introduced. As you will see in subsequent
    recipes, functional programming and stream pipelines encourage a fluent style
    of coding (using method chaining, as well as using the `forEach()` method in the
    examples of this recipe). Fluent style provides more compact and readable code.
    Removing the need for the check for the `null` value helps to keep it this way—compact
    and focused on the main processing procedures.
  prefs: []
  type: TYPE_NORMAL
- en: 'The immutability feature, in turn, aligns well with the *effectively final*
    concept for the variables used by lambda expressions. For example, a mutable collection
    allows us to work around this limitation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, the lambda expression used by the second `forEach()`
    operation maintains state in the third (with index 2) element of the original
    list. It makes it possible—intentionally or not—to introduce a state in a lambda
    expression and cause different outcomes of the same function in different contexts.
    This is especially dangerous in parallel processing because one cannot predict
    the state of each possible context. This is why immutability of a collection is
    a helpful addition that makes the code more robust and reliable.
  prefs: []
  type: TYPE_NORMAL
- en: Creating and operating on streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will describe how streams can be created and how the operations
    can be applied to the elements emitted by the streams. The discussion and examples
    are applicable for a stream of any type, including the specialized numeric streams:  `IntStream`, `LongStream`,
    and `DoubleStream`. The behavior specific to the numeric streams is not presented
    because it is described in the next recipe, *Using numeric streams for arithmetic
    operations*.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are many ways to create a stream:'
  prefs: []
  type: TYPE_NORMAL
- en: The `stream()` and `parallelStream()` methods of the `java.util.Collection` 
    interface—this means that all the sub-interfaces, including `Set` and `List`,
    have these methods too
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Two overloaded `stream()` methods of the `java.util.Arrays` class, which convert
    arrays and subarrays to streams
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `of()`, `generate()`, and `iterate()` methods of the `java.util.stream.Stream` interface
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Stream<Path> list()`, `Stream<String> lines()`, and `Stream<Path> find()` methods
    of the `java.nio.file.Files` class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Stream<String> lines()` method of the `java.io.BufferedReader` class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After a stream is created, various methods (called operations) can be applied
    to its elements. A stream itself does not store data. Instead, it acquires data
    from the source (and provides or emits it to the operations) as needed. The operations
    can form a pipeline using the fluent style since many intermediate operations
    can return a stream too. Such operations are called *intermediate* operations.
    Examples of intermediate operations include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`map()`: Transforms elements according to a function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`flatMap()`: Transforms each element into a stream according to a function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`filter()`: Selects only elements matching a criterion'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`limit()`: Limits a stream to the specified number of elements'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sorted()`: Transforms an unsorted stream into a sorted one'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`distinct()`: Removes duplicates'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other methods of the `Stream` interface that return `Stream` too
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The pipeline ends with a **terminal operation**. The processing of the stream
    elements actually begins only when a terminal operation is being executed. Then,
    all the intermediate operations (if present) start processing and the stream closes
    and cannot be reopened until the terminal operation is finished with the execution.
    Examples of terminal operations are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`forEach()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`findFirst()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reduce()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`collect()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other methods of the `Stream` interface that do not return `Stream`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Terminal operations return a result or produce a side effect, but they do not
    return the `Stream` object.
  prefs: []
  type: TYPE_NORMAL
- en: All the `Stream` operations support parallel processing, which is especially
    helpful in the case of a large amount of data processed on a multicore computer. All
    the Java Stream API interfaces and classes are in the `java.util.stream` package.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we are going to demonstrate sequential streams. Parallel-streams
    processing is not much different. One just has to watch that the processing pipeline
    does not use a context state that can vary across different processing environments. We
    will discuss parallel processing in another recipe later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section of the recipe, we will present methods to create a stream.
    Each class that implements the `Set` interface or the `List` interface has the `stream()` method
    and the `parallelStream()` method, which returns an instance of the `Stream` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following examples of stream creation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: We used the fluent style to make the code more compact and interjected `System.out.println()`
    in order to start a new line in the output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the preceding example and you should see the following result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/936e8f84-eacb-4d72-b5bc-04e165a78f25.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice that, `List` preserves the order of the elements, while the order of
    the `Set` elements changes at every run. The latter helps to uncover the defects
    based on the reliance on a certain order when the order is not guaranteed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Look at the Javadoc of the `Arrays` class. It has two `stream()` overloaded
    static methods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Write an example of the usage of the last two methods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Run it and see the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3c9d5ca8-f851-446c-a7e2-8f4eb2260372.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice that in the second example, only the first two elements—with indexes
    `0` and `1`—were selected to be included in the stream, as it was intended.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the Javadoc of the `Stream` interface and see the `of()`, `generate()`,
    and `iterate()` static factory methods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The first two methods are simple, so we skip their demo and start with the third
    method,  `of()`. It can accept either an array or comma-delimited elements.
  prefs: []
  type: TYPE_NORMAL
- en: 'Write the example as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Run it and observe the output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/89515668-5eb9-44d4-a2be-a3abf325b39c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Write the examples of the usage of the `generate()` and `iterate()` methods
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: We had to put a limit on the size of the streams generated by the first two
    examples. Otherwise, they would be infinite. The third example accepts a predicate
    that provides the criterion for when the iteration has to stop.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the examples and observe the results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/64c9332d-924f-46c9-a8f6-ff57b57517c9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s look at the example of the `Files.list(Path dir)` method, which returns
    `Stream<Path>` of all the entries of the directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is from the JDK API:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"This method must be used within a try-with-resources statement or similar
    control structure to ensure that the stream''s open directory is closed promptly
    after the stream''s operations are completed*."'
  prefs: []
  type: TYPE_NORMAL
- en: And this is what we did; we used a try-with-resources statement. Alternatively,
    we could use a try-catch-finally construct, close the stream in the finally block,
    and the result would not change.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the preceding examples and observe the output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/9faf4c8d-cc86-43ce-9bcc-d116b5953269.png)'
  prefs: []
  type: TYPE_IMG
- en: Not all streams have to be closed explicitly, although the `Stream` interface
    extends `AutoCloseable` and one would expect that all streams have to be closed
    automatically using the try-with-resources statement. But that is not the case.
    The Javadoc for the `Stream` interface ([https://docs.oracle.com/javase/8/docs/api/java/util/stream/Stream.html](https://docs.oracle.com/javase/8/docs/api/java/util/stream/Stream.html)) says,
  prefs: []
  type: TYPE_NORMAL
- en: '"Streams have a `BaseStream.close()` method and implement `AutoCloseable`.
    Most stream instances do not actually need to be closed after use, as they are
    backed by collections, arrays, or generating functions, which require no special
    resource management. Generally, only streams whose source is an I/O channel, such
    as those returned by `Files.lines(Path)`, will require closing."'
  prefs: []
  type: TYPE_NORMAL
- en: This means that a programmer has to know the source of the stream, so make sure
    that the stream is closed if the API for the source requires it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Write an example of the `Files.lines()` method''s usage:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The intent of the preceding example was to read the first three lines of the
    specified file and print non-empty lines with an indentation of three spaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the preceding example and see the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/05f2f40a-65c6-48cf-9e2f-7d674d05efda.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Write the code that uses the `Files.find()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to the previous case, a stream generated by the `Files.find()` method
    has to be closed explicitly too. The `Files.find()` method walks the file tree
    rooted at a given starting file and at the requested depth and returns the paths
    to the files that match the predicate (which includes file attributes). Write
    the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the preceding example and you''ll get the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/186d2a93-23ed-480f-b4e7-37fa6bbc3e44.png)'
  prefs: []
  type: TYPE_IMG
- en: If necessary, `FileVisitorOption.FOLLOW_LINKS` could be included as the last
    parameter of the `Files.find()` method if we need to perform a search that would
    follow all symbolic links it might encounter.
  prefs: []
  type: TYPE_NORMAL
- en: The requirements for using the `BufferedReader.lines()` method, which returns
    `Stream<String>` of lines read from a file, is a little bit different. According to
    Javadoc ([https://docs.oracle.com/javase/8/docs/api/java/io/BufferedReader.html](https://docs.oracle.com/javase/8/docs/api/java/io/BufferedReader.html)),
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '"The reader must not be operated on during the execution of the terminal stream
    operation. Otherwise, the result of the terminal stream operation is undefined."'
  prefs: []
  type: TYPE_NORMAL
- en: There are many other methods in the JDK that produce streams. But they are more
    specialized, and we will not demonstrate them here because of the shortage of
    space.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout the preceding examples, we have demonstrated several stream operations
    already—methods of the `Stream` interface. We used `forEach()` most often and `limit()`
    a few times. The first one is a terminal operation and the second one is an intermediate
    one. Let's look at other methods of the `Stream` interface now.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the intermediate operations—methods that return `Stream` and can be
    connected in a fluent style:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The signatures of the preceding methods typically include `"? super T"` for
    an input parameter and `"? extends R"` for the result (see the Javadoc for the
    formal definition). We simplified them by removing these notations in order to
    provide a better overview of the variety and commonality of the methods. To compensate,
    we would like to recap the meaning of the related generic notations since they
    are used extensively in the Stream API and might be the source of confusion.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at the formal definition of the `flatMap()` method because it has
    all of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The `<R>` symbol in front of the method indicates to the compiler that it is
    a generic method (the one with its own type parameters). Without it, the compiler
    would be looking for the definition of the `R` type. The `T` type is not listed
    in front of the method because it is included in the `Stream<T>` interface definition
    (look at the top of the page where the interface is declared). The `? super T`
    notation means that the `T` type or its superclass is allowed here. The `? extends
    R` notation means that the `R` type or its subclass is allowed here. The same
    applies to `? extends Stream<...>`: the `Stream` type or its subclass is allowed
    here.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s get back to our (simplified) list of intermediate operations. We
    have broken them into several groups by similarity:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first group contains only one `peek()` method, which allows you to apply
    the `Consumer` function to each of the stream elements without affecting the element
    because the `Consumer` function does not return anything. It is typically used
    for debugging:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'If you execute the preceding code, the result will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c805401d-0eff-4b09-b9e4-cadfb5c23d9a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the second group of intermediate operations listed above, the first three—`distinct()`, 
    `skip()`, `limit()`—are self-explanatory. The `filter(Predicate p)` method is
    one of the most often used. It does what its name suggests—it removes from the
    stream those elements that do not match the criterion passed in as the `Predicate`
    function. We saw an example of its usage in the previous snippet of code: only
    the odd numbers were allowed to flow through the filter. The `dropWhile()` method
    discards the elements as long as the criterion is met (then allows the rest of
    the stream elements to flow to the next operation). The `takeWhile()` method does
    the opposite—it allows the elements to flow as long as the criterion is met (then
    discards the rest of the elements). Here is an example of these operations'' usage:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: This code reads the file where the preceding code is stored. We want it to print
    `"Files.lines().dropWhile().takeWhile():"` first, then print all the preceding
    lines except the last three. So, the preceding code discards all the first lines
    of the file that do not have the `dropWhile().takeWhile()` substring, then allows
    all the lines to flow until the `} catch` substring is found.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that we had to write `"} catc" + "h"` instead of  `"} catch"`. Otherwise,
    the code would find `contains(" catch")` and would not go further.
  prefs: []
  type: TYPE_NORMAL
- en: 'The result of the preceding code in as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/31315eab-c83a-4822-a762-baadf73b4b4e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The group of `map()` operations is pretty straightforward too. Such an operation
    transforms each element of the stream by applying to it a function that was passed
    in as a parameter. We have already seen an example of the usage of the `mapToInt()`
    method. Here is another example of the `map()` operation:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, we transform `String` literals into `boolean`. The result
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/514474c8-0a6c-4f97-9c78-74174d928e3b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The next group of intermediate operations, called `flatMap()`, provides more
    complex processing. A `flatMap()` operation applies the passed-in function (which
    returns a stream) to each of the elements so that the operation can produce a
    stream composed of the streams extracted from each of the elements. Here''s an
    example of `flatMap()` usage:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code selects from the stream elements only literals that contain
    `Th` and converts them into a stream of characters, which are then printed out
    by `forEach()`. The result of this is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d98ba1f7-0686-4ad3-8ac5-15eb4f80b2f7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `concat()` method creates a stream from two input streams so that all the
    elements of the first stream are followed by all the elements of the second stream.
    Here''s an example of this functionality:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a374487c-d5a2-4ee3-86cc-54f05d75f8c1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the case there are more than two stream concatenations, one can write the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b4687d8d-f14e-49b3-896c-7736483e1d18.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice that, in the preceding code, `Function.identity()` is a function that
    returns its input argument. We use it because we do not need to transform the
    input streams but just pass them as is to the resulting stream. Without using
    this `flatMap()` operation, the stream would consist of the `Stream` objects,
    not of their elements, and the output would show `java.util.stream.ReferencePipeline$Head@548b7f67java.util.stream.ReferencePipeline$Head@7ac7a4e4
    java.util.stream.ReferencePipeline$Head@6d78f375`.
  prefs: []
  type: TYPE_NORMAL
- en: The last group of intermediate operations is composed of the `sorted()` methods
    that sort the stream elements in a natural order (if they are of the `Comparable` type)
    or according to the passed-in `Comparator` object. It is a stateful operation
    (as well as `distinct()`, `limit()`, and `skip()`) that yields a non-deterministic
    result in the case of parallel processing (that is the topic of the recipe *Processing
    stream in parallel* below).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let''s look at terminal operations (we simplified their signature too
    by removing `? super T` and `? extends R`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The first four groups are self-explanatory, but we need to say a few words about `Optional`.
    The Javadoc ([https://docs.oracle.com/javase/8/docs/api/java/util/Optional.html](https://docs.oracle.com/javase/8/docs/api/java/util/Optional.html))
    defines it as,
  prefs: []
  type: TYPE_NORMAL
- en: '"A container object which may or may not contain a non-null value. If a value
    is present, `isPresent()` returns `true` and `get()` returns the value."'
  prefs: []
  type: TYPE_NORMAL
- en: 'It allows you to avoid `NullPointerException` or check for `null` (well, you
    have to call `isPresent()` instead anyway). It has its own methods—`map()`, `filter()`,
    and `flatMap()`. In addition, `Optional` has methods that include the `isPresent()`
    check implicitly:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ifPresent(Consumer<T> action)`: Performs the action with the value if present,
    otherwise does nothing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ifPresentOrElse(Consumer<T> action, Runnable emptyAction)`: Performs the provided
    action with the value if present, otherwise performs the provided empty-based
    action'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`or(Supplier<Optional<T>> supplier)`: Returns an `Optional` class describing
    the value if present, otherwise returns an `Optional` class produced by the provided
    function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`orElse(T other)`: Returns the value if present, otherwise returns the provided `other` object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`orElseGet(Supplier<T> supplier)`: Returns the value if present, otherwise
    returns the result produced by the provided function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`orElseThrow(Supplier<X> exceptionSupplier)`: Returns the value if present,
    otherwise throws an exception produced by the provided function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Note that `Optional` is used as a return value in cases when `null` is a possible
    result. Here is an example of its usage. We reimplemented the stream-concatenating
    code using the `reduce()` operation that returns `Optional`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is the same as in the previous implementation with the `flatMap()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ca8a1a49-61ac-43cd-94b1-2385161bf443.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The next group of terminal operations is referred to as `forEach()`. These
    operations guarantee that the given function will be applied to each element of
    the stream. But `forEach()` does not say anything about the order, which might
    be changed for better performance. By contrast, `forEachOrdered()` guarantees not
    only the processing of all the elements of the stream, but also doing this in
    the order specified by its source, regardless of whether the stream is sequential
    or parallel. Here are a couple of examples of this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/62fc8016-1719-485e-9767-68ada906d7f5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, in the case of parallel processing, `forEach()` does not guarantee
    the order, while `forEachOrdered()` does. Here is another example of using both `Optional`
    and `forEach()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'We could not use `Optional.of()` and used `Optional.ofNullable()` instead because
    `Optional.of()` would throw `NullPointerException` on `null`. In such a case, `Optional.ofNullable()`
    just returns `Optional` empty. The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/062c4c7d-21e1-4ad9-8e69-c21ec4476bb5.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, let's talk about the next group of terminal operations, called `reduce()`.
    Each of the three overloaded methods returns a single value after processing all
    the stream elements. Among the most simple examples are finding a sum of the stream
    elements in case they are numbers, or max, min, and similar. But a more complex
    result can be constructed for a stream of objects of any type.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first method, `Optional<T> reduce(BinaryOperator<T> accumulator)`, returns
    the `Optional<T>` object because it is the responsibility of the provided accumulator
    function to calculate the result, and the authors of the JDK implementation cannot
    guarantee that it will always contain a non-null value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The passed-in function receives the result of the previous execution of the
    same function (as the first parameter, `p`) and the next element of the stream
    (as the second parameter, `e`). For the very first element, `p` gets its value,
    while `e` is the second element. You can print the `p` value as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/51f1c284-f957-449d-af72-1eae5e35d77c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To avoid the extra step with `Optional`, the second method, `T reduce(T identity,
    BinaryOperator<T> accumulator)`, returns the value provided as the first parameter, `identity`,
    of the `T` type (which is the type of the elements of `Stream<T>`) in case the
    stream is empty. This parameter has to comply with the for all `t`, as `accumulator.apply(identity,
    t)` is equal to the `t` requirement (from Javadoc). In our case, it has to be
    `0` for it to comply with `0 + e == e`. Here is an example of how to use the second
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: The result is the same as with the first `reduce()` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'The third method, `U reduce(U identity, BiFunction<U,T,U> accumulator, BinaryOperator<U>
    combiner)`, converts the value of the `T` type into a value of the `U` type with
    the help of the `BiFunction<U,T,U>` function. `BiFunction<U,T,U>` is used as an
    accumulator so that the result (the `U` type) of its application to the previous
    element (the `T` type) becomes an input into the function along with the current
    element of the stream. Here is a code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'One naturally expects to see the result as `1,2,3`. Instead, we see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/64da187d-c5b8-4c95-9ac9-d47990d7dd77.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The reason for the preceding result is that the combiner was used because the
    stream was sequential. But let''s make the stream parallel now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The result of the preceding code execution will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/012b5675-5bff-4cec-ac3d-9f36597dde57.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This means that the combiner is called only for parallel processing in order
    to assemble (combine) the results of different sub-streams processed in parallel.
    This is the only deviation we have noticed so far from the declared intent of
    providing the same behavior for sequential and parallel streams. But there are
    many ways to accomplish the same result without using this third version of `reduce()`.
    For example, consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'It produces the same result as the previous example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2619716a-1f9f-4782-8a21-9e330b1f5494.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now let''s change it to a parallel stream:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: The result remains the same: `1,2,3`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next group of intermediate operations, called `collect()`, consists of
    two methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The first one accepts `Collector<T,A,R>` as a parameter. It is much more popular
    than the second one because it is backed up by the `Collectors` class, which provides
    a wide variety of implementations of the `Collector` interface. We encourage you
    to go through the Javadoc of the `Collectors` class and see what it offers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s discuss a few examples of using the `Collectors` class. First, we''ll
    create a small demo class called `Thing`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can use it to demonstrate a few collectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The result will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c86fc553-23f1-4679-aa5e-e41571816ee9.png)'
  prefs: []
  type: TYPE_IMG
- en: The joining collector is a source of joy for any programmer who has ever had
    to write code that checks whether the added element is the first, the last, or
    removes the last character (like we did in the example of the `reduce()` operation).
    The collector produced by the `joining()` method does this behind the scenes.
    All the programmer has to provide is the delimiter, prefix, and suffix.
  prefs: []
  type: TYPE_NORMAL
- en: Most programmers will never need to write a customs collector. But in the case
    there is a need, one can use the second method, `collect()`, of `Stream`, and
    provide the functions that compose the collector or use one of the two `Collector.of()` static
    methods that generate a collector that can be reused.
  prefs: []
  type: TYPE_NORMAL
- en: If you compare the `reduce()` and `collect()` operations, you'll notice that
    the primary purpose of `reduce()` is to operate on immutable objects and primitives.
    The result of `reduce()` is one value that is typically (but not exclusively)
    of the same type as the elements of the stream. `collect()`, by contrast, produces
    the result of a different type wrapped in a mutable container. The most popular
    usage of `collect()` is centered around producing `List`, `Set`, or `Map` objects
    using the corresponding `Collectors.toList()`, `Collectors.toSet()`, or `Collectors.toMap()` collector.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last group of terminal operations consists of two `toArray()` methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The first returns `Object[]`, the second, an array of the specified type. Let''s
    look at the examples of their usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of these examples is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fa432b46-098d-4fbe-b97d-1646a94aafbe.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The first example is quite straightforward. It is worth noting that we cannot
    write the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: This is because `toArray()` is a terminal operation and the stream is closed
    automatically after it. That's why we have to open a new stream in the second
    line of our preceding code example.
  prefs: []
  type: TYPE_NORMAL
- en: The second example—with the overloaded `A[] toArray(IntFunction<A[]> generator)`
    method—is more complicated. The Javadoc ([https://docs.oracle.com/javase/8/docs/api/java/util/stream/Stream.html](https://docs.oracle.com/javase/8/docs/api/java/util/stream/Stream.html))
    says,
  prefs: []
  type: TYPE_NORMAL
- en: '"The generator function takes an integer, which is the size of the desired
    array, and produces an array of the desired size."'
  prefs: []
  type: TYPE_NORMAL
- en: This means that the method reference to a `toArray(String[]::new)` constructor
    in the last example is a shorter version of `toArray(size -> new String[size])`.
  prefs: []
  type: TYPE_NORMAL
- en: Using numeric streams for arithmetic operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In addition to the `Stream` interface, the `java.util.stream` package also provides
    specialized interfaces—`IntStream`, `DoubleStream`, and `LongStream`—that are
    optimized for processing streams of corresponding primitive types. They are very
    convenient to use, and have numeric operations, such as `max()`, `min()`, `average()`, `sum()`.
  prefs: []
  type: TYPE_NORMAL
- en: The numeric interfaces have methods similar to the methods of the Stream interface,
    which means that everything we have talked about in the previous recipe, *Creating
    and operating on streams*, applies to numeric streams too. That is why, in this
    section, we will only talk about the methods that are not present in the `Stream` interface.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In addition to the methods described in the *Creating and operating on streams* recipe,
    the following methods can be used to create a numeric stream:'
  prefs: []
  type: TYPE_NORMAL
- en: The `range(int startInclusive, int endInclusive)` and `rangeClosed(int startInclusive,
    int endInclusive)` methods of the `IntStream` and `LongStream` interfaces
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Six overloaded `stream()` methods of the `java.util.Arrays` class, which convert
    arrays and subarrays to numeric streams
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The list of intermediate operations specific to numeric streams includes the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`boxed()`: Converts a numeric stream of a primitive type to a stream of the
    corresponding wrapping type'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mapToObj(mapper)`: Converts a numeric stream of a primitive type to a stream
    of objects using the provided function mapper'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`asDoubleStream()` of the `LongStream` interface: Converts `LongStream` to
    `DoubleStream`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`asLongStream()` and `asDoubleStream()` of the `IntStream` interface: Converts `IntStream`
    to the corresponding numeric stream'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The list of terminal arithmetic operations specific to numeric streams includes
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`sum()`: Calculates a sum of the numeric stream elements'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`average()`: Calculates an average of the numeric stream elements'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`summaryStatistics()`: Creates an object with various summary data about the
    elements of the stream'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Experiment with the `range(int startInclusive, int endInclusive)` and `rangeClosed(int
    startInclusive, int endInclusive)` methods of the  `IntStream` and `LongStream` interfaces:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the difference between the `range()` and `rangeClosed()` methods
    is the exclusion or inclusion of the value passed in as the second parameter.
    This also leads to the following results in the case where both parameters have
    the same value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding examples, the `range()` method does not emit any element, while
    the `rangeClosed()` method emits only one element.
  prefs: []
  type: TYPE_NORMAL
- en: 'Please notice that neither of these methods generates an error when the first
    parameter is bigger than the second parameter. They just emit nothing and the
    following statements produce no output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'If you do not need the values of stream elements to be sequential, you can
    create an array of the values first and then generate a stream using one of six
    overloaded `stream()` static methods of the `java.util.Arrays` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are the examples of the usage of the `Arrays.stream()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'The last two pipelines can be improved to print out the elements of `DoubleStream` in
    a more human-friendly format by using the joining collector we discussed in the
    previous recipe, *Creating and operating on streams*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: Since the `Collector<CharSequence, ?, String>` joining collector accepts `CharSequence`
    as an input type, we had to convert the number into `String` using an intermediate
    operation, `mapToObj()`.
  prefs: []
  type: TYPE_NORMAL
- en: Use the `mapToObj(mapper)` intermediate operation to convert a primitive type
    element to a reference type. We saw an example of its usage in step 2\. The mapper
    function can be as simple or as complex as it needs to be in order to achieve
    the necessary transformation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'There is also a specialized operation, `boxed()`, without parameters that convert
    elements of a primitive numeric type to the corresponding wrapping type—`int`
    value to `Integer` value, `long` value to `Long` value, and `double` value to
    `Double` value. We can use it, for example, to achieve the same results as the
    last two examples of the usage of the `mapToObj(mapper)` operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'There are also intermediate operations that convert an element of a numeric
    stream from one primitive type to another numeric primitive type: `asLongStream()` and `asDoubleStream()` in
    the `IntStream` interface, and `asDoubleStream()` in the `LongStream` interface.
    Let''s look at examples of their usage:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'You may have noticed that these operations are possible only for the widening
    primitive conversion: from the `int` type to `long` and `double`, and from `long`
    to `double`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The terminal arithmetic operations specific to numeric streams are pretty straightforward.
    Here are examples of the `sum()` and `average()` operations with `IntStream`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the `average()` operation returns `OptionalDouble`. It is interesting
    to consider why the authors decided to return `OptionalDouble` for `average()`
    but not for `sum()`. This decision was probably made to map an empty stream to
    an empty `OptionalDouble`, but then the decision to return `0` when `sum()` applies
    to an empty stream seems inconsistent.
  prefs: []
  type: TYPE_NORMAL
- en: 'These operations behave the same way for `LongStream` and `DoubleStream`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The `summaryStatistics()` terminal operation collects various summary data
    about the elements of the stream:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: The printouts added as comments to the preceding printing lines come from the `toString()`
    method of the `IntSummaryStatistics`, `LongSummaryStatistics`, or `DoubleSummaryStatistics` objects, correspondingly.
    Other methods of these objects include `getCount()`, `getSum()`, `getMin()`, `getAverage()`,
    and `getMax()`, which allow access to a particular aspect of the collected statistics.
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice that in the case of an empty stream, the min (max) value is the smallest
    (biggest) possible value of the corresponding Java type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Only `DoubleSummaryStatistics` shows `Infinity` and `-Infinity` as min and max
    values, instead of the actual numbers shown here. According to the Javadoc of
    these methods, `getMax()` returns "the maximum recorded value, `Double.NaN` if
    any recorded value was `NaN` or `Double.NEGATIVE_INFINITY` if no values were recorded"
    and `getMin()` returns "the minimum recorded value, `Double.NaN` if any recorded
    value was `NaN` or `Double.POSITIVE_INFINITY` if no values were recorded."
  prefs: []
  type: TYPE_NORMAL
- en: Also, please notice that in contrast with the `average()` terminal stream operation,
    the `getAverage()` method of any of the preceding summary statistics returns the
    arithmetic mean of streamed values, or zero if there were no values emitted from
    the stream, not the `Optional` object.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `IntSummaryStatistics`, `LongSummaryStatistics`, and `DoubleSummaryStatistics` objects
    can be created not only by the `summaryStatistics()` numeric stream terminal operation.
    Such an object can also be created by the `collect()` terminal operation applied
    to any `Stream` object, not just `IntStream`, `LongStream`, or `DoubleStream`.
  prefs: []
  type: TYPE_NORMAL
- en: Each of the summary statistics objects has the `accept()` and `combine()` methods,
    which allow us to create a `Collector` object that can be passed into the `collect()` operation
    and produce the corresponding summary statistics object. We will demonstrate this
    possibility by creating the `IntSummaryStatistics` object. The `LongSummaryStatistics` and `DoubleSummaryStatistics` objects
    can be created similarly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `IntSummaryStatistics` class has the following two methods:'
  prefs: []
  type: TYPE_NORMAL
- en: 'void accept (int value): Includes a new value into statistics summary'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'void combine (`IntSummaryStatistics` other): Adds the collected statistics
    of the provided `other` object to the current one'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These methods allow us to use the overloaded version of the `R collect(Supplier<R>
    supplier, BiConsumer<R,? super T> accumulator, BiConsumer<R,R> combiner)` operation
    on any `Stream` object, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the stream is not one of the specialized numeric streams. It
    just has numeric elements of the same type as the created summary statistics object.
    Nevertheless, we were able to create an object of the `IntSummaryStatistics` class.
    Similarly, it is possible to create objects of the `LongSummaryStatistics` and `DoubleSummaryStatistics` classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Please notice that the third parameter, `combiner`, is used only for parallel
    stream processing—it combines the results of sub-streams that are processed in
    parallel. To demonstrate this, we can change the preceding example as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Combining...` line is not printing. Let''s change the stream to a parallel
    one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: If you run the preceding code now, you will see the `Combining...` line.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another way to collect statistics is to use a `Collector` object created by
    one of the following methods of the `Collectors` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, we will use the first of the preceding methods to create the `IntSummaryStatistics`
    object. Let''s assume we have the following `Person` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'If there is a stream of `Person` class objects, we can collect statistics of
    the age of the persons (stream elements) as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we were able to collect statistics only on the field of an object
    that matches the type of the collected statistics. Neither the stream nor its
    elements are numeric.
  prefs: []
  type: TYPE_NORMAL
- en: Look in the Javadoc of the `java.util.stream.Collectors` class to see what other
    functionality it provides before trying to create a custom `Collector` object.
  prefs: []
  type: TYPE_NORMAL
- en: Completing streams by producing collections
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will learn and practice how to use the `collect()` terminal operation to
    repackage stream elements to a target collection structure.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two overloaded versions of the `collect()` terminal operation that
    allow us to create a collection of the stream elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '`R collect(Supplier<R> supplier, BiConsumer<R,T> accumulator, BiConsumer<R,R>
    combiner)`: Produces the `R` result using the passed-in functions applied to the
    stream elements of the `T` type. The provided supplier and accumulator work together
    as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: The provided combiner is used only for the processing of a parallel stream.
    It combines the results of the sub-streams processed in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: '`R collect(Collector<T, A, R> collector)`: Produces the `R` result using the
    passed-in `Collector` object applied to the stream elements of the `T` type. The `A` type
    is an intermediate accumulation type of `Collector`. The `Collector` object can
    be built using the `Collector.of()` factory method, but we are not going to discuss
    it in this recipe because there are many factory methods available in the `java.util.stream.Collectors` class
    that cover the majority of the needs. Besides, after you learn how to use the `Collectors`
    class, you will be able to use the `Collector.of()` method too.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In this recipe, we are going to demonstrate how to use the following methods
    of the `Collectors` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Collector<T, ?, List<T>> toList()`: Creates a `Collector` object that collects
    the stream elements of the `T` type into a `List<T>` object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Collector<T, ?, Set<T>> toSet()`: Creates a `Collector` object that collects
    the stream elements of the `T` type into a `Set<T>` object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Collector<T, ?, C> toCollection(Supplier<C> collectionFactory)`: Creates a `Collector` object
    that collects the stream elements of the `T` type into a `Collection` of the C
    type produced by the `collectionFactor` supplier'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Collector<T, ?, List<T>> toUnmodifiableList()`: Creates a `Collector` object
    that collects the stream elements of the `T` type into an immutable `List<T>` object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Collector<T, ?, Set<T>> toUnmodifiableSet()`: Creates a `Collector` object
    that collects the stream elements of the `T` type into an immutable `Set<T>` object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For our demonstrations, we are going to use the following `Person` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will walk you through the sequence of practical steps that demonstrate how
    to use the preceding methods and classes:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Write an example of the usage of the `R collect(Supplier<R> supplier, BiConsumer<R,T>
    accumulator, BiConsumer<R,R> combiner)` operation of the `Stream<T>` interface
    that produces the `List<T>` object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, the comments to the accumulator and the combiner demonstrate
    how these functions can be presented as lambda expressions instead of just method
    references.
  prefs: []
  type: TYPE_NORMAL
- en: The first parameter, `Supplier<R>`, returns the container for the result. In
    our case, we have defined it as a constructor of the `ArrayList<Person>` class
    because it implements the `List<Person>` interface—the type of the object we would
    like to construct.
  prefs: []
  type: TYPE_NORMAL
- en: The accumulator takes the current result, `a` (which is going to be of the `List<Person>` type
    in our case), and adds to it the next stream element, `p` (the `Person` object
    in our case). The output of the example is shown as the last comment line.
  prefs: []
  type: TYPE_NORMAL
- en: 'The combiner combines the results of the sub-streams processed in parallel. It
    takes the first result, `r` (of any sub-stream that has finished processing first),
    and adds to it another result, `r1`, and so on. This means that the combiner is
    used for parallel processing only. To demonstrate this, let''s modify the preceding
    code as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: If you run the preceding example, you will not see the `Combining...` line printed
    out because `combiner` is not used for sequential stream processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s convert the stream into a parallel one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: If you run the preceding code, the `Combining...` line will be displayed.
  prefs: []
  type: TYPE_NORMAL
- en: Nothing prevents you from modifying the provided functions any way you need
    to, as long as the input and return types of each function remain the same.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Set<Person>` object can be created the same way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'The created `List` or a `Set` object can be modified at any time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: We have mentioned it to contrast this behavior with the behavior of immutable
    collections, which we are going to discuss shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Write an example of the usage of the `R collect(Collector<T, A, R> collector)` operation
    of the `Stream<T>` interface with the collector created by the `Collector<T, ?,
    List<T>> Collectors.toList()` and  `Collector<T, ?, Set<T>> Collectors.toSet()` methods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: As was expected, `Set` does not allow duplicate elements defined by the `equals()` method
    implementation. In the case of the `Person` class, the `equals()` method compares
    both age and name, so a difference in any of these properties makes two `Person`
    objects not equal.
  prefs: []
  type: TYPE_NORMAL
- en: 'Write an example of the usage of the `R collect(Collector<T, A, R> collector)` operation
    of the `Stream<T>` interface with the collector created by the `Collector<T, ?,
    C> Collectors.toCollection(Supplier<C> collectionFactory)` method. The advantage
    of this collector is that it collects stream elements not just in `List` or `Set`,
    but in any object that implements a `Collection` interface. The target object
    that collects the stream elements of the `T` type is produced by the `collectionFactor` supplier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Write an example of the usage of the `R collect(Collector<T, A, R> collector)` operation
    of the `Stream<T>` interface with the collector created by the `Collector<T, ?,
    List<T>> Collectors.toUnmodifiableList()` and  `Collector<T, ?, Set<T>> Collectors.toUnmodifiableSet()` methods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from the comments in the preceding code, the objects created
    using collectors generated by the `Collector<T, ?, List<T>> Collectors.toUnmodifiableList()` and  `Collector<T,
    ?, Set<T>> Collectors.toUnmodifiableSet()` methods create immutable objects. Such
    objects are very helpful when used in lambda expressions because this way we are
    guaranteed that they cannot be modified, so the same the expression—even if passed
    around and executed in different contexts—will produce the result that depends
    only on its input parameters and will not have unexpected side-effects caused
    by the modification of the `List` or `Set` object it uses.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: The filter we have created in the preceding example can be used anywhere to
    select `Person` objects that belong to the provided set.
  prefs: []
  type: TYPE_NORMAL
- en: Completing streams by producing maps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will learn and practice how to use the `collect()` terminal operation to
    repackage stream elements to target the `Map` structure. While discussing collectors,
    we will not include collectors that use grouping because they will be presented
    in the next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we mentioned in the previous recipe, there are two overloaded versions of
    the `collect()` terminal operation, which allow us to create a collection of the
    stream elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '`R collect(Supplier<R> supplier, BiConsumer<R,T> accumulator, BiConsumer<R,R>
    combiner)`: Produces the `R` result using the passed-in functions applied to the
    stream elements of the `T` type'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`R collect(Collector<T, A, R> collector)`: Produces the `R` result using the
    passed-in `Collector` object applied to the stream elements of the `T` type'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These operations can be also used to create a `Map` object, and in this recipe,
    we are going to demonstrate how to do so.
  prefs: []
  type: TYPE_NORMAL
- en: 'In support of the second of the preceding versions of the `collect()` operation,
    the `Collectors` class provides four groups of factory methods that create the `Collector`
    object. The first group includes the factory methods very similar to those that
    create the `Collector` object for collecting stream elements into `List` or `Set` discussed
    and demonstrated in the previous recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Collector<T,?,Map<K,U>> toMap(Function<T,K> keyMapper, Function<T,U> valueMapper)`:
    Creates a `Collector` object that collects the stream elements of the `T` type
    into a `Map<K,U>` object using the provided functions (mappers) that produce a
    key and value from a stream element as an input parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Collector<T,?,Map<K,U>> toMap(Function<T,K> keyMapper, Function<T,U> valueMapper,
    BinaryOperator<U> mergeFunction)`: Creates a `Collector` object that collects
    the stream elements of the `T` type into a `Map<K,U>` object using the provided
    functions (mappers) that produce a key and value from a stream element as an input
    parameter. The provided `mergeFunction` is used only for parallel stream processing;
    it merges the results of the sub-streams into the one final result—the `Map<K,U>`
    object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Collector<T,?,M> toMap(Function<T,K> keyMapper, Function<T,U> valueMapper,
    BinaryOperator<U> mergeFunction, Supplier<M> mapFactory)`: Creates a `Collector` object
    that collects the stream elements of the `T` type into a `Map<K,U>` object using
    the provided functions (mappers) that produce a key and value from a stream element
    as an input parameter. The provided `mergeFunction` is used only for parallel
    stream processing; it merges the results of the sub-streams into the one final
    result—the `Map<K,U>` object. The provided `mapFactory` supplier creates an empty `Map<K,U>` object
    into which the results will be inserted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Collector<T,?,Map<K,U>> toUnmodifiableMap(Function<T,K> keyMapper, Function<T,U>
    valueMapper)`: Creates a `Collector` object that collects the stream elements
    of the `T` type into an *immutable* `Map<K,U>` object using the provided functions
    (mappers) that produce a key and value from a stream element as an input parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Collector<T,?,Map<K,U>> toUnmodifiableMap(Function<T,K> keyMapper, Function<T,U>
    valueMapper, BinaryOperator<U> mergeFunction)`: Creates a `Collector` object that
    collects the stream elements of the `T` type into an *immutable* `Map<K,U>` object
    using the provided functions (mappers) that produce a key and value from a stream
    element as an input parameter. The provided `mergeFunction` is used only for parallel
    stream processing; it merges the results of the sub-streams into the one final
    result—an immutable `Map<K,U>` object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The second group includes three factory methods similar to the three `toMap()` methods
    we just listed. The only difference is that the collectors created by the `toConcurrentMap()` methods
    collect stream elements in a `ConcurrentMap` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Collector<T,?,ConcurrentMap<K,U>> toConcurrentMap(Function<T,K> keyMapper,
    Function<T,U> valueMapper)`: Creates a `Collector` object that collects the stream
    elements of the `T` type into a `ConcurrentMap<K,U>` object using the provided
    functions (mappers) that produce a key and value from a stream element as an input
    parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Collector<T,?,ConcurrentMap<K,U>> toConcurrentMap(Function<T,K> keyMapper,
    Function<T,U> valueMapper, BinaryOperator<U> mergeFunction)`: Creates a `Collector` object
    that collects the stream elements of the `T` type into a `ConcurrentMap<K,U>` object
    using the provided functions (mappers) that produce a key and value from a stream
    element as an input parameter. The provided `mergeFunction` is used only for parallel
    stream processing; it merges the results of the sub-streams into the one final
    result—the `ConcurrentMap<K,U>` object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Collector<T,?,M> toConcurrentMap(Function<T,K> keyMapper, Function<T,U> valueMapper,
    BinaryOperator<U> mergeFunction, Supplier<M> mapFactory)`: Creates a `Collector` object
    that collects the stream elements of the `T` type into a `ConcurrentMap<K,U>` object
    using the provided functions (mappers) that produce a key and value from a stream
    element as an input parameter. The provided `mergeFunction` is used only for parallel
    stream processing; it merges the results of the sub-streams into the one final
    result—the  `ConcurrentMap<K,U>` object. The provided `mapFactory` supplier creates
    an empty `ConcurrentMap<K,U>` object into which the results will be inserted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The need for this second group of factory methods arises from the fact that, for
    a parallel stream, the merging results of different sub-streams is an expensive
    operation. It is especially heavy when the results have to be merged into the
    resulting `Map` in the encountered order—that is what the collectors created by
    the `toMap()` factory methods do. These collectors create multiple intermediate
    results and then merge them by calling the collector's supplier and combiner multiple
    times.
  prefs: []
  type: TYPE_NORMAL
- en: When the order of the results-merging is not important, the collectors created by
    the `toConcurrentMap()` methods can be used as less heavy because they call the
    supplier only once, insert the elements in the *shared* resulting container, and
    never call the combiner.
  prefs: []
  type: TYPE_NORMAL
- en: So, the difference between the `toMap()` and `toConcurrentMap()` collectors
    manifest only during parallel stream processing. That's why it is often recommended
    to use the `toMap()` collectors for serial stream processing, and the `toConcurrentMap()`
    collectors for parallel stream processing (if the order of collecting the stream
    elements is not important).
  prefs: []
  type: TYPE_NORMAL
- en: The third group includes three `groupingBy()` factory methods, which we are
    going to discuss in the next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: The fourth group includes three `groupingByConcurrent()` factory methods, which
    we are going to discuss in the next recipe, too.
  prefs: []
  type: TYPE_NORMAL
- en: 'For our demonstrations, we are going to use the same `Person` class we used
    to create collections in the previous recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will walk you through the sequence of practical steps that demonstrate how
    to use the preceding methods and classes:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Write an example of the usage of the `R collect(Supplier<R> supplier, BiConsumer<R,T>
    accumulator, BiConsumer<R,R> combiner)` operation of the `Stream<T>` interface
    that produces the `Map` object. Create `Map<String, Person>` with a person''s
    name as the key:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Or, to avoid redundant data in the resulting `Map`, we can use age field as
    the `Map` value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'The combiner is called only for a parallel stream, as it is used to combine
    the results of different sub-stream processing. To prove it, we have replaced
    the method reference `Map::putAll` with the code block that prints the message `Combining...`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: The `Combining...` message will be displayed only if the conversion to a parallel
    stream is not commented out.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we add another `Person` object with the same name, one of them is going
    to be overwritten in the resulting `Map`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'If such a behavior is not desirable and we need to see all the values of all
    duplicate keys, we can change the resulting `Map` to have a `List` object as a
    value, so that in this list we can collect all the values that have the same key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we did not inline the `BiConsumer` function in the `collect()` operation
    as a parameter because it is a multiline code now and is easier to read this way.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another way to collect multiple values for the same key, in this case, would
    be to create `Map` with a `String` value as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'Write an example of the usage of the `R collect(Collector<T, A, R> collector)` operation
    of the `Stream<T>` interface with the collector created by the `Collector<T, ?,
    Map<K,U>> Collectors.toMap(Function<T,K> keyMapper, Function<T,U> valueMapper)` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding solution works fine as long as there is no duplicate key encountered,
    as in the following case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code throws `IllegalStateException` with the `Duplicate key John`
    (attempted merging values 30 and 15) message and there is no way for us to add
    a check for a duplicate key, as we have done before. So, if there is a chance
    for a duplicate key, one has to use the overloaded version of the `toMap()` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Write an example of the usage of the `R collect(Collector<T, A, R> collector)` operation
    of the `Stream<T>` interface with the collector created by the `Collector<T, ?,
    Map<K,U>> Collectors.toMap(Function<T,K> keyMapper, Function<T,U> valueMapper,
    BinaryOperator<U> mergeFunction)` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'That is the purpose of the `mergeFunction`—to combine values for a duplicate
    key. Instead of `List<Integer>`, we can also collect the values of a duplicate
    key in a `String` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'Write an example of the usage of the `R collect(Collector<T, A, R> collector)` operation
    of the `Stream<T>` interface with the collector created by the `Collector<T, ?,
    M> Collectors.toMap(Function<T,K> keyMapper, Function<T,U> valueMapper, BinaryOperator<U>
    mergeFunction, Supplier<M> mapFactory)` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, this version of the `toMap()` method allows us to specify the
    desired `Map` interface implementation (the `LinkedHashMap` class, in this case)
    instead of using the default one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Write an example of the usage of the `R collect(Collector<T, A, R> collector)` operation
    of the `Stream<T>` interface with the collector created by the `Collector<T, ?,
    Map<K,U>> Collectors.toUnmodifiableMap(Function<T,K> keyMapper, Function<T,U> valueMapper)` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the collector created by the `toUnmpdifiableMap()` method behaves
    the same as the collector created by the `Collector<T, ?, Map<K,U>> Collectors.toMap(Function<T,K>
    keyMapper, Function<T,U> valueMapper)` method, except that it produces an immutable
    `Map` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Write an example of the usage of the `R collect(Collector<T, A, R> collector)` operation
    of the `Stream<T>` interface with the collector created by the `Collector<T, ?,
    Map<K,U>> Collectors.toUnmodifiableMap(Function<T,K> keyMapper, Function<T,U>
    valueMapper, BinaryOperator<U> mergeFunction)` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'The collector created by the `toUnmpdifiableMap()` method behaves the same
    as the collector created by the  `Collector<T, ?, Map<K,U>> Collectors.toMap(Function<T,K>
    keyMapper, Function<T,U> valueMapper, BinaryOperator<U> mergeFunction)` method,
    except that it produces an immutable `Map` object. Its purpose is to handle the
    case of duplicate keys. The following is another way to combine the values of
    duplicate keys:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'Write an example of the usage of the `R collect(Collector<T, A, R> collector)` operation
    of the `Stream<T>` interface with the collector created by the `Collector<T, ?
    ,ConcurrentMap<K,U>> Collectors.toConcurrentMap(Function<T,K> keyMapper, Function<T,U>
    valueMapper)` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the collector created by the `toConcurrentMap()` method behaves
    the same as the collector created by the `Collector<T, ?, Map<K,U>> Collectors.toMap(Function<T,K>
    keyMapper, Function<T,U> valueMapper)` and `Collector<T, ?, Map<K,U>> Collectors.toUnmodifiableMap(Function<T,K>
    keyMapper, Function<T,U> valueMapper)` methods, except that it produces a mutable `Map` object
    and, when the stream is parallel, shares between sub-streams the resulting `Map`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Write an example of the usage of the `R collect(Collector<T, A, R> collector)` operation
    of the `Stream<T>` interface with the collector created by the `Collector<T, ?,
    ConcurrentMap<K,U>> Collectors.toConcurrentMap(Function<T,K> keyMapper, Function<T,U>
    valueMapper, BinaryOperator<U> mergeFunction)` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the collector created by the `toConcurrentMap()` method behaves
    the same as the collector created by the `Collector<T, ?, Map<K,U>> Collectors.toMap(Function<T,K>
    keyMapper, Function<T,U> valueMapper, BinaryOperator<U> mergeFunction)` and `Collector<T,
    ?, Map<K,U>> Collectors.toUnmodifiableMap(Function<T,K> keyMapper, Function<T,U> valueMapper,
    BinaryOperator<U> mergeFunction)` methods, except that it produces a mutable `Map` object
    and, when the stream is parallel, shares the resulting `Map` between sub-streams. The
    following is another way to combine the values of duplicate keys:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'Write an example of the usage of the `R collect(Collector<T, A, R> collector)` operation
    of the `Stream<T>` interface with the collector created by the `Collector<T, ?,
    M> Collectors.toConcurrentMap(Function<T,K> keyMapper, Function<T,U> valueMapper,
    BinaryOperator<U> mergeFunction, Supplier<M> mapFactory)` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, this version of the `toConcurrentMap()` method allows us to
    specify the desired `Map` interface implementation (the `ConcurrentSkipListMap` class,
    in this case) instead of using the default one.
  prefs: []
  type: TYPE_NORMAL
- en: The collector created by the `toConcurrentMap()` method behaves the same as
    the collector created by the `Collector<T, ?, Map<K,U>> Collectors.toMap(Function<T,K>
    keyMapper, Function<T,U> valueMapper, BinaryOperator<U> mergeFunction, Supplier<M>
    mapFactory)` method, but when the stream is parallel, it shares between sub-streams
    the resulting `Map`.
  prefs: []
  type: TYPE_NORMAL
- en: Completing streams by producing maps using grouping collectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will learn about and practice how to use the `collect()` terminal
    operation to group elements by a property and store the result in a `Map` instance
    using a collector.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two sets of collectors that use grouping—similar to the *group by* functionality
    of SQL statements—to present stream data as a `Map` object. The first set includes
    three overloaded `groupingBy()` factory methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Collector<T, ?, Map<K,List<T>>> groupingBy(Function<T,K> classifier)`: Creates
    a `Collector` object that collects the stream elements of the `T` type into a `Map<K,List<T>>` object
    using the provided `classifier` function to map the current element to the key
    in the resulting map.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Collector<T,?,Map<K,D>> groupingBy(Function<T,K> classifier, Collector<T,A,D>
    downstream)`: Creates a `Collector` object that collects the stream elements of
    the `T` type into a `Map<K,D>` object using the provided `classifier` function
    to map the current element to the key in the intermediate map `Map<K,List<T>>`.
    It then uses the `downstream` collector to convert the values of the intermediate
    map into the values of the resulting map, `Map<K,D`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Collector<T, ?, M> groupingBy(Function<T,K> classifier, Supplier<M> mapFactory,
    Collector<T,A,D> downstream)`: Creates a `Collector` object that collects the
    stream elements of the `T` type into the `M` map object using the provided `classifier` function
    to map the current element to the key in the `Map<K,List<T>>` intermediate map.
    It then uses the `downstream` collector to convert the values of the intermediate
    map into the values of the resulting map of the type provided by the `mapFactory`
    supplier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The second set of collectors includes three `groupingByConcurrent()` factory
    methods, which are created for concurrency handling during parallel stream processing.
    These collectors take the same arguments as the corresponding overloaded versions
    of the `groupingBy()` collectors listed earlier. The only difference is that the
    return type of the `groupingByConcurrent()` collectors are the instances of the
    `ConcurrentHashMap` class or its subclass:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Collector<T, ?, ConcurrentMap<K,List<T>>> groupingByConcurrent(Function<T,K>
    classifier)` : Creates a `Collector` object that collects the stream elements
    of the `T` type into a `ConcurrentMap<K,List<T>>` object using the provided `classifier` function
    to map the current element to the key in the resulting map.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Collector<T, ?, ConcurrentMap<K,D>> groupingByConcurrent(Function<T,K> classifier,
    Collector<T,A,D> downstream)`: Creates a `Collector` object that collects the
    stream elements of the `T` type into a `ConcurrentMap<K,D>` object using the provided `classifier` function
    to map the current element to the key in the `ConcurrentMap<K,List<T>>` intermediate
    map. It then uses the `downstream` collector to convert the values of the intermediate
    map into the values of the resulting map, `ConcurrentMap<K,D>`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Collector<T, ?, M> groupingByConcurrent(Function<T,K> classifier, Supplier<M>
    mapFactory, Collector<T,A,D> downstream)`: Creates a `Collector` object that collects
    the stream elements of the `T` type into the `M` map object using the provided `classifier` function
    to map the current element to the key in the `ConcurrentMap<K,List<T>>` intermediate
    map. It then uses the `downstream` collector to convert the values of the intermediate
    map into the values of the resulting map of the type provided by the `mapFactory`
    supplier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For our demonstrations, we are going to use the same `Person` class we used
    to create maps in the previous recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'We will also use the `Person2` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Person2` class is different from the `Person` class as it has an additional
    field—city. It will be used to demonstrate the power of the grouping functionality.
    And the `Person2` class variation—the `Person3` class—will be used to demonstrate
    how to create the `EnumMap` object. The `Person3` class uses `enum City` as the
    value type for its `city` property:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'To make the examples less verbose, we are going to use the following methods
    to generate test streams:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will walk you through the sequence of practical steps that demonstrate how
    to use the preceding methods and classes:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Write an example of the usage of the `R collect(Collector<T, A, R> collector)` operation
    of the `Stream<T>` interface with the collector created by the `Collector<T, ?,
    Map<K,List<T>>> groupingBy(Function<T,K> classifier)` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: This is the simplest version of the `Collector` object. You just define what
    is going to be the key of the resulting map, and the collector will add all the
    stream elements that have the same key value to the list of elements associated
    with that key in the resulting map.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is another example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: 'If the stream elements have to be grouped by a combination of properties, you
    can create a class that can contain the necessary combination. The object of this
    class will serve as a complex key. For example, let''s read the stream of the `Person2`
    elements and group them by age and name. This means that need a class that can
    carry two values. For example, here is such a class, called `TwoStrings`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: 'We had to implement the `equals()` and `hashCode()` methods because an object
    of the `TwoStrings` class will be used as a key and its value has to be specific
    for each combination of the two values. We can use it now as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: 'Write an example of the usage of the `R collect(Collector<T, A, R> collector)` operations
    of the `Stream<T>` interface with the collector created by the `Collector<T,?,Map<K,D>> groupingBy(Function<T,K>
    classifier, Collector<T,A,D> downstream)` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the `List<Person>` values of the map produced by the `Collectors.groupingBy(Person::getName)` collector
    were later (downstream) changed to a set by the `Collectors.toSet()` collector.
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, each `List<Person>` value can be converted to just a count of
    the list elements, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'To count how many of the same `Person` objects (those that are equal according
    to the `equals()` method) are in the stream, we can use the identity function,
    which is defined as returning the input unchanged. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: 'Using this function, we can count the number of same persons, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also calculate an average age in each group of persons (a group is defined
    as having the same the resulting key value):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: 'To list all the values of the age of the persons with the same name, we can
    use the downstream collector created by the `Collector<T, ?, R> Collectors.mapping
    (Function<T,U> mapper, Collector<U,A,R> downstream)` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: 'Another variation of this solution is the following example, where for each
    age, a comma-delimited list of names is created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: 'And, finally, to demonstrate another technique, we can use the nested `groupingBy()`
    collectors to create a map that contains age as a key and a map of person''s names
    to their cities as values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: Please note that we used the `Person2` stream in the preceding example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Write an example of the usage of the `R collect(Collector<T, A, R> collector)` operation
    of the `Stream<T>` interface with the collector created by the `Collector<T, ?,
    M> groupingBy(Function<T,K> classifier, Supplier<M> mapFactory, Collector<T,A,D>
    downstream)` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: The code in the preceding example counts how many times each name is encountered
    in the stream of the `Person` objects and places the result in the container (`LinkedHashMap`
    in this case) defined by the `mapFactory` function (the second parameter of the
    `groupingBy()` method).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following examples demonstrate how to tell the collector to use `EnumMap` based
    on `enum City` as a container of the final result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: 'Please notice that we used the `Person3` stream in the preceding examples.
    To simplify the result (to avoid displaying a city twice for the same result)
    and to group the persons by age (for each city), we can use the nested `groupingBy()`
    collector again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: 'As examples of the second set of collectors, those created by the `groupingByConcurrent()` methods, all
    the preceding code snippets (except the last two with `EnumMap`) can be used by
    just replacing `groupingBy()` with `groupingByConcurrent()`  and the resulting  `Map` with
    the `ConcurrentMap` class or its subclass. For example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: As we have mentioned before, the `groupingByConcurrent()` collectors can process
    sequential streams too, but they are designed to be used to process parallel stream
    data, so we have converted the preceding streams to parallel ones. The returned
    result is of the `ConcurrentHashMap` type or a subclass of it.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `Collectors` class also provides two collectors generated by the `partitioningBy()` method,
    which are specialized versions of the `groupingBy()` collectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Collector<T, ?, Map<Boolean,List<T>>> partitioningBy(Predicate<T> predicate)`:
    Creates a `Collector` object that collects the stream elements of the `T` type
    into a `Map<Boolean,List<T>>` object using the provided `predicate` function to
    map the current element to the key in the resulting map.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Collector<T, ?, Map<Boolean,D>> partitioningBy(Predicate<T> predicate, Collector<T,A,D>
    downstream)` : Creates a `Collector` object that collects the stream elements
    of the `T` type into a `Map<Boolean,D>` object using the provided `predicate` function
    to map the current element to the key in the `Map<K,List<T>>` intermediate map.
    It then uses the `downstream` collector to convert the values of the intermediate
    map into the values of the resulting map, `Map<Boolean,D>`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s look at some examples. Here is how the first of the preceding methods
    can be used to collect the `Person` stream elements into two groups—one with names
    that contain the letter `i` and another with names that don''t contain the letter
    `i`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: 'To demonstrate the usage of the second method, we can convert each `List<Person>` value
    of the map created in the preceding example to the list size:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: 'The same result can be achieved using collectors created by the `groupingBy()` methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: The collectors created by the `partitioningBy()` methods are considered a specialization
    of the collectors created by the `groupingBy()` methods, and are expected to allow
    us to write less code when stream elements are broken into two groups and stored
    in a map with Boolean keys. But, as you can see from the preceding code, that's
    not always the case. The `partitioningBy()` collectors in our examples require
    us to write exactly the same amount of code as the `groupingBy()` collectors.
  prefs: []
  type: TYPE_NORMAL
- en: Creating stream operation pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will learn how to build a pipeline from the `Stream` operations.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous chapter, [Chapter 4](69c0640b-9b2e-4515-bda6-8a481206da19.xhtml),
    *Going Functional*, while creating a lambda-friendly API, we ended up with the
    following API method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: The specified number of `TrafficUnit` instances were produced inside the `speedAfterStart()`
    method. They were limited by the `limitTrafficAndSpeed` function and were processed
    according to the `speedModel` function inside the `speedAfterStart()` method.
    The results were formatted by the `printResults` function.
  prefs: []
  type: TYPE_NORMAL
- en: It is a very flexible design that allows for quite a range of experimentation
    via the modification of functions that are passed to the API. In reality, though,
    especially during the early stages of data analysis, creating an API requires
    more code writing. It pays back only in the long run and only if the design flexibility
    allows us to accommodate new requirements with zero or very few code changes.
  prefs: []
  type: TYPE_NORMAL
- en: The situation radically changes during the research phase. When new algorithms
    are developed or when the need for processing a large amount of data presents
    its own challenges, transparency across all the layers of the developed system
    becomes a foundational requirement. Without it, many of today's successes in the
    analysis of big data would be impossible.
  prefs: []
  type: TYPE_NORMAL
- en: Streams and the pipelines address the problem of transparency and minimize the overhead
    of writing infrastructural code.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s recall how a user called the lambda-friendly API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: As we have already noticed, such an API may not cover all the possible ways
    the model can evolve, but it is a good starting point that allows us to construct
    the stream and the pipeline of operations with more transparency and flexibility
    of experimentation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s look at the API''s implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: 'We can convert the `for` loop into a stream of traffic units and apply the
    same functions directly to the elements of the stream. But first, we can request
    the traffic-generating system to supply us with a `Stream` instead of a `List`
    of data. It allows us to avoid storing all the data in memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: We can now process an endless number of traffic units without storing in the
    memory more than one unit at a time. In the demo code, we still use `List`, so
    the streaming does not save us memory. But in real systems, such as those that
    collect data from various sensors, using streams helps to decrease or completely
    avoid memory-usage concerns.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will also create a convenience method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE125]'
  prefs: []
  type: TYPE_PRE
- en: 'With this, we can write the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: 'We mapped (transform) `TrafficUnit` to `Vehicle`, then mapped `Vehicle` to
    `speed`, and then used the current `TrafficUnit` instance and the calculated `speed`
    to limit the traffic and print results. If you have this code in a modern editor,
    you will notice that it does not compile because, after the first map, the current
    `TrafficUnit` element is not accessible anymore—it is replaced by `Vehicle`. This
    means we need to carry the original elements and add new values along the way.
    To accomplish this, we need a container—some kind of traffic-unit wrapper. Let''s
    create one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can build a pipeline that works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: 'The code looks a bit verbose, especially the `Vehicle` and `SpeedModel` settings.
    We can hide this plumbing by moving them to the `TrafficUntiWrapper` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice how we return `this` from the `setSpeedModel()` and `setSpeed()` methods.
    This allows us to preserve the fluent style. Now, the pipeline looks much cleaner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs: []
  type: TYPE_PRE
- en: 'If there is no need to keep the formula for the speed calculations easily accessible,
    we can move it to the `TrafficUnitWrapper` class by changing the `setSpeed()`
    method to `calcSpeed()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE131]'
  prefs: []
  type: TYPE_PRE
- en: 'So, the pipeline becomes even less verbose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: 'Based on this technique, we can now create a method that calculates traffic
    density—the count of vehicles in each lane of a multilane road for the given speed
    limit in each of the lanes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE133]'
  prefs: []
  type: TYPE_PRE
- en: 'The private `CountByLane` class used by the preceding method looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: 'And here is how the private `TrafficUnitWrapper` class looks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: 'The code of the `countByLane()` private method is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: In [Chapter 14](402d6438-f308-4ae7-b637-8e60a1215bc4.xhtml), *Testing*, we will
    discuss this method of the `TrafficDensity` class in more detail and revisit this
    implementation to allow for better unit testing. This is why writing a unit test
    parallel to the code development brings higher productivity; it eliminates the
    need to change the code afterward. It also results in more testable (better-quality)
    code.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The pipeline allows the easy addition of another filter, or any other operation
    for that matter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs: []
  type: TYPE_PRE
- en: It is especially important when many types of data have to be processed. It's
    worth mentioning that having a filter before the calculations are the best way
    to improve performance because it allows you to avoid unnecessary calculations.
  prefs: []
  type: TYPE_NORMAL
- en: Another major advantage of using a stream is that the process can be made parallel
    without extra coding. All you need to do is change the first line of the pipeline
    to `getTrafficUnitStream(trafficUnitsNumber).parallel()` (assuming the source
    does not generate the parallel stream, which can be identified by the `.isParallel()`
    operation). We will talk about parallel processing in more detail in the next
    recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Processing streams in parallel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous recipes, we demonstrated some of the techniques of parallel
    stream-processing. In this recipe, we will discuss processing in greater detail,
    and share the best practices and solutions for common problems.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is tempting to just set up all the streams to be parallel and not think about
    it again. Unfortunately, parallelism does not always provide an advantage. In
    fact, it incurs an overhead because of the worker threads' coordination. Besides,
    some stream sources are sequential in nature and some operations may share the
    same (synchronized) resource. Even worse, the usage of a stateful operation in
    parallel processing can lead to an unpredictable result. It does not mean one
    cannot use a stateful operation for a parallel stream, but it requires careful
    planning and a clear understanding of how the state is shared between the sub-streams
    of parallel processing.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As was mentioned in the previous recipe, a parallel stream can be created by
    the `parallelStream()` method of a collection or the `parallel()` method applied
    to a stream. Conversely, the existing parallel stream can be converted into a
    sequential one by using the `sequential()` method.
  prefs: []
  type: TYPE_NORMAL
- en: As the first best practice, one should use a sequential stream by default and
    start thinking about the parallel one only if necessary and possible. The need
    usually comes up if the performance is not good enough and a large amount of data
    has to be processed. The possibilities are limited by the nature of the stream
    source and operations. For example, reading from a file is sequential and a file-based
    stream does not perform better in parallel. Any blocking operation also negates
    performance improvement in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the areas where sequential and parallel streams are different is ordering.
    Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f3c994e3-4ae8-4123-b7d8-8c13afe401a2.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, `List` preserves the order of the elements but does not keep
    it in the case of parallel processing.
  prefs: []
  type: TYPE_NORMAL
- en: In the *Creating and operating on streams* recipe, we demonstrated that with
    the `reduce()` and `collect()` operations, a combiner is called only for a parallel
    stream. So, the combiner is not needed for a sequential stream processing, but
    it must be present while operating on a parallel one. Without it, the results
    of multiple workers are not correctly aggregated.
  prefs: []
  type: TYPE_NORMAL
- en: We have also demonstrated that the `sorted()`, `distinct()`, `limit()`, and
    `skip()` stateful operations yield non-deterministic results in the case of parallel
    processing.
  prefs: []
  type: TYPE_NORMAL
- en: If the order is important, we have shown that you can rely on the `forEachOrdered()` 
    operation. It guarantees not only the processing of all the elements of the stream
    but also doing it in the order specified by its source, regardless of whether
    the stream is sequential or parallel.
  prefs: []
  type: TYPE_NORMAL
- en: 'A parallel stream can be created by the `parallelStream()` method or by the `parallel()` method.
    Once created, it uses a `ForkJoin` framework during processing: the original stream
    is broken into segments (sub-streams) that are then given to different worker
    threads for processing, then all the results (of each sub-stream processing) are
    aggregated and presented as the final results of the original stream processing.
    On a computer with only one processor, such an implementation does not have an
    advantage because the processor is shared. But on a multicore computer, worker
    threads can be executed by different processors. Even more, if one worker becomes
    idle, it can *steal* a part of the job from a busy one. The results are then collected
    from all the workers and aggregated for the terminal operation completion (that
    is when a combiner of a collect operation becomes busy).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally speaking, if there is a resource that is not safe for concurrent
    access, it is not safe to use during parallel stream-processing either. Consider
    these two examples (`ArrayList` is not known to be thread-safe):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE139]'
  prefs: []
  type: TYPE_PRE
- en: 'If run several times, this code may produce the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/85352637-6444-46ab-a438-087e3d601812.png)'
  prefs: []
  type: TYPE_IMG
- en: The `Collectors.toList()` method always generates the same list, which consists
    of `is` and `Stream.of(literals)`, while `forEach()` misses either `is` or `Stream.of(literals)`
    once in a while.
  prefs: []
  type: TYPE_NORMAL
- en: If possible, try using collectors constructed by the `Collectors` class first
    and avoid shared resource during parallel computations.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, using stateless functions is your best bet for parallel stream pipelines.
    If in doubt, test your code and, most importantly, run the same test many times
    to check whether the result is stable.
  prefs: []
  type: TYPE_NORMAL
