- en: '*Chapter 4*: Exploiting S3 Buckets'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: S3 buckets are one of the primary resources that AWS uses to hold data. S3 buckets
    are great ways to hold objects such as data and metadata. However, much like other
    file storage solutions, S3 buckets can be easily exploited through simple misconfigurations.
    These misconfigurations can lead to data leaks and other serious security issues.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we are going to take a dive into S3 buckets, their functionality,
    and how to exploit issues with public buckets and misconfigured buckets. We will
    also discuss real-world scenarios and how vulnerabilities in S3 buckets have become
    a common global issue for many corporations.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: AWS Regions and Availability Zones
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manipulating S3 buckets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: S3 bucket policies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding public buckets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scripts to find private buckets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A goal-based pentesting scenario
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discovering buckets with Grayhat Warfare
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a local S3 environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To follow along with the instructions in this chapter, you will need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The AWS CLI (covered in [*Chapter 1*](B15630_01_Final_ASB_ePub.xhtml#_idTextAnchor025)*,
    Building Your AWS Environment*)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bash
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code used in this chapter is available at the following links:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/AWS-Penetration-Testing/tree/master/Chapter%204:%20Exploiting%20S3](https://github.com/PacktPublishing/AWS-Penetration-Testing/tree/master/Chapter%204:%20Exploiting%20S3)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://github.com/sa7mon/S3Scanner](https://github.com/sa7mon/S3Scanner)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://github.com/kromtech/s3-inspector](https://github.com/kromtech/s3-inspector)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://github.com/minio/minio](https://github.com/minio/minio)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://realpython.com/python-boto3-aws-s3/](https://realpython.com/python-boto3-aws-s3/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action: [https://bit.ly/3mJdY89](https://bit.ly/3mJdY89)'
  prefs: []
  type: TYPE_NORMAL
- en: AWS Regions and Availability Zones
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a few things we should discuss before getting started with S3\. It
    is essential to understand how AWS houses data because knowing the how and why
    helps us to understand the fundamentals a little better. Having a fundamental
    understanding allows us to further understand what we already know and go from
    there. To help us understand this a little better, let's discuss the infrastructure
    a bit before diving into S3\.
  prefs: []
  type: TYPE_NORMAL
- en: 'Just like local servers are typically stored on-premises, near your business
    or organization, it''s prudent to host information held in AWS as close to you
    as possible. What I mean is using systems that are geographically located near
    you to help support your mission with cloud-based resources. Well, this is where
    AWS Regions come into play in allowing you to geographically allocate resources
    based on your needs and locations. These geographically located areas known as
    **Regions** can be found in AWS. You can look at the regions by selecting them
    in the top-right corner of the AWS console. The current region that we are using
    throughout this book is **Oregon**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – List of AWS Regions'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_4.01_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.1 – List of AWS Regions
  prefs: []
  type: TYPE_NORMAL
- en: 'AWS Regions are various geographical locations that AWS uses to host its data,
    and its infrastructure. Thankfully, they are hosted globally with regions in major
    countries, allowing you to select a region that is closest to you. Choosing an
    infrastructure close to you means less latency for yourself or your end users.
    Currently, there are a few regions you can select from. The following screenshot
    was pulled directly from Amazon and highlights all the regions and the local zones
    that you can select:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2 – Longer list of AWS Regions'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_4.02_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.2 – Longer list of AWS Regions
  prefs: []
  type: TYPE_NORMAL
- en: You can see that there are numerous regions you can choose from here. As has
    already been said, ensure you select the one closest to you. This will ensure
    the best use of resources since they will be located nearest to you.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have learned about AWS Regions, let's look at some best practices.
  prefs: []
  type: TYPE_NORMAL
- en: AWS Region best practices
  prefs: []
  type: TYPE_NORMAL
- en: 'When looking at regions, there are a few housekeeping tips you will need to
    remember. These housekeeping tips help you to maintain better use of your cloud
    systems and to optimize speed. These best practices apply more on an enterprise-level
    but are still essential to understand:'
  prefs: []
  type: TYPE_NORMAL
- en: Choose the closest region to you to minimize latency.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some newer services may not be able to host the services you need, so ensure
    that the region you select has the services you desire. If not, choose the next
    closest region that supports the services required.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I can't stress this one enough – *compliance*! Ensure that, whatever you're
    doing, it is compliant with your region. Different countries have different laws,
    so ensure you're up to date on protocols within that region.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we understand what regions are, let's take a look at the services hosted
    inside regions. These services are known as **Availability Zones**.
  prefs: []
  type: TYPE_NORMAL
- en: Availability Zones
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Availability Zones are fantastic for minimizing redundancy and downtime if an
    EC2 Instance were to go offline. Availability Zones are created to allow you to
    distribute an EC2 instance across multiple zones so that if your instance fails
    in one zone, it can still be accessed in another. Of course, this all happens
    in the background, and you, the user, don't notice it! If you need a quick refresher
    on EC2 instances, head back to [*Chapter 1*](B15630_01_Final_ASB_ePub.xhtml#_idTextAnchor025)*,
    Building Your AWS Environment*, and give it a quick review.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moving forward, let''s look at the next diagram. The diagram illustrates how
    AWS utilizes Availability Zones within each region. Throughout this book, we will
    be using the Oregon `us-west-2` **Availability Zone**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3 – Redundancy with Availability Zones'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_4.03_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.3 – Redundancy with Availability Zones
  prefs: []
  type: TYPE_NORMAL
- en: It's extremely important that you take redundancy into account because when
    a service goes down, redundancy is a fault check that ensures that those services
    stay up. In a production or business case, a system going down can mean millions,
    or sometimes billions, of dollars lost!
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find more information about Availability Zones here: [https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions)'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a better idea of how our resources can be spread out over Availability
    Zones, let's start looking at services that may use these zones. The first service
    that we are going to discuss is S3 and its storage solution, S3 buckets.
  prefs: []
  type: TYPE_NORMAL
- en: Connecting and manipulating S3 buckets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Central file storage is conventional for organizations to secure and store data.
    If you have worked in IT, chances are you have had your fair share of run-ins
    with setting up **Server Message Block** (**SMB**) shares over Windows to allow
    file sharing between multiple hosts. Allowing files to be centrally resourced
    is a great way to collaborate and share information, as well as allowing personnel
    to access data remotely from another system. Setting up a file server, where data
    is stored – and retrieved – is nothing new. What is new is how we can store data
    in this same method, only now we can store it in the cloud using technology known
    as **S3** – or **Simple Storage Service** if you want to spell it out.
  prefs: []
  type: TYPE_NORMAL
- en: So, what is S3? S3 is a simple storage system (as the name implies) and allows
    users to store data in the cloud. Just like how we store data on a file server,
    we can store data in what is known as an S3 bucket, which will hold the contents
    of our data. You can store copious amounts of data in these buckets and retrieve
    it any time you like.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will be learning about S3 buckets, their usage, and how
    to create and upload files to S3\. Let's first understand what S3 stands for.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding S3 buckets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As mentioned, S3 is a simple storage service that allows users to store their
    data in the cloud. The storage solution is secure by default; however, users and
    administrators put policies around the storage that makes it vulnerable to attacks.
    We aren''t going to worry about attacks and vulnerabilities on S3 buckets just
    yet, because we need to understand the basics first. Before we dive into attacking,
    let''s break down some questions about the storage solution:'
  prefs: []
  type: TYPE_NORMAL
- en: How is information stored?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where does it go?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How much can we store, and how durable is it?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'S3 stores your data in what''s called an **object**, also known as **object
    storage**. Object storage allows you to store data such as pictures, videos, files,
    and any data associated with them in the form of an object. There are various
    storage classes we aren''t going to go over, but you can find out more about them
    here: https://aws.amazon.com/s3/features/.'
  prefs: []
  type: TYPE_NORMAL
- en: S3 is designed for the "11 9's" model, meaning it takes data durability and
    it automatically creates and stores copies of all S3 objects across multiple systems.
    However, this does not imply that S3 objects will be stored in an operating system.
    S3 is not like EC2 instances and is unable to host operating systems such as Windows
    or Linux.
  prefs: []
  type: TYPE_NORMAL
- en: S3 is also highly scalable and allows you to store what would seem like an infinite
    amount of storage; however, nothing is infinite, right? Making S3 storage unlimited
    adds on to the "11 9's!" model, driving success for safe and reliable storage.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's begin to take a look the usage of S3 and its real-world principles
    in an enterprise.
  prefs: []
  type: TYPE_NORMAL
- en: Using S3 buckets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It''s important that we understand the reasons why we use cloud storage. It
    provides a critical service for companies to store data and be able to access
    it. As mentioned, S3 stores the following types of data:'
  prefs: []
  type: TYPE_NORMAL
- en: Pictures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Videos
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Documents containing sensitive data, and so on
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While we understand the types of data that can be stored, how is S3 used? It's
    more than loading up a new text document – it's about redundancy and backing up
    data!
  prefs: []
  type: TYPE_NORMAL
- en: One of the primary reasons for S3 solutions in an enterprise is to back up and
    archive data that would otherwise be stored in backup locations such as hot sites,
    warm sites, and cold sites. S3 is like a hot site because the data is readily
    available and accessible at any time. Having S3 as a backup storage solution is
    also an excellent implementation of disaster recovery. If your primary filesystem
    goes down unexpectedly, your data will still be available in the cloud with S3\.
  prefs: []
  type: TYPE_NORMAL
- en: 'S3 can also act as a central location to store and distribute data amongst
    users in a business. Remember: S3 is about scaling and storing, so being able
    to access data globally is extremely important for productivity.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a better understanding of S3 and all it entails, it is time
    that we started looking at S3 buckets and how we can possibly exploit them.
  prefs: []
  type: TYPE_NORMAL
- en: S3 buckets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We now have a good grasp of what S3 is and how it works concerning storing information
    and backing up data for an enterprise. As stated previously, S3 is a simple storage
    service that stores data as objects. These **objects** are stored in what is known
    as a **bucket**. Simply put, a bucket is a basic container that is hosted in S3
    and stores your data objects. Let's take a brief look at what all this means,
    then set up a bucket of our very own.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Remember, S3 is a local filesystem in the cloud!
  prefs: []
  type: TYPE_NORMAL
- en: As stated before, S3 buckets essentially act similar to a simple file server
    that you would find within a local filesystem but are stored in the cloud instead
    of locally. A bucket stores objects that can be uploaded and downloaded at any
    time. Some resources will be stored in public buckets, while others will be stored
    internally and be available only to users that have access to them.
  prefs: []
  type: TYPE_NORMAL
- en: 'To give brevity to S3 attributes, here is a list of things to keep in mind
    with S3:'
  prefs: []
  type: TYPE_NORMAL
- en: S3 bucket names are unique and cannot be the same as someone else's. These names
    are specific to a particular bucket within a certain area. We'll take a look at
    that in just a bit.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can create up to 100 buckets! This will give you plenty of practice and
    storage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Buckets are assigned by region. It's important to remember what regions you
    store your buckets in – that's how you access them!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They are reliable and sufficient for all your storage needs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: S3 has a universal namespace where buckets are created.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They can be accessed virtually or via a path – we will talk about this once
    we have created a bucket.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now you should have a good grasp of what S3 is and how it works. However, don't
    fret if you're still unsure – more understanding will arise as we move through
    this chapter and we will apply more theory with hands-on practice as we move further
    through the book.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's build an S3 bucket and then look at some common security issues
    and how to exploit them. We will be using Kali Linux as our host operating system
    to interact with S3 – ensure that you have your local AWS Kali Linux image up
    to date and the AWS CLI installed, as mentioned in the *Technical requirements*
    section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Creating S3 buckets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's begin applying all our theory of S3 by putting it to practical use and
    start by logging into the AWS console. Once logged in, let's pin the S3 service
    icon to our main page. We are going to be using it quite a bit, so it's good practice
    to keep it on the main page.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go ahead and create a bucket by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: To begin, click on the thumbtack icon toward the top of the screen. Once you
    click on it, an extensive list of resources is displayed to you. Click and drag
    the **S3** icon to the top:![Figure 4.4 – List of AWS services
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_4.04_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.4 – List of AWS services
  prefs: []
  type: TYPE_NORMAL
- en: You'll have something that looks like the following. Notice the **S3** icon
    at the top of your screen:![Figure 4.5 – S3 icon added as a service shortcut
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_4.05_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.5 – S3 icon added as a service shortcut
  prefs: []
  type: TYPE_NORMAL
- en: Now you can click on the S3 icon and be directed to the S3 buckets page. This
    is where we will begin creating our buckets! Click on the icon that says **Create
    bucket** to start:![Figure 4.6 – S3 buckets dashboard
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_4.06_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.6 – S3 buckets dashboard
  prefs: []
  type: TYPE_NORMAL
- en: 'On the next screen, you''ll need to enter a name and a region for the bucket:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Use the region closest to you. Make sure your bucket uses a globally unique
    name. For example, you can't have two buckets named `AWSBucket`.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.7 – S3 buckets dashboard (creation and naming)'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_4.07_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.7 – S3 buckets dashboard (creation and naming)
  prefs: []
  type: TYPE_NORMAL
- en: The next screen will display the **Configure options**. In an enterprise environment,
    this is the start of where you will want to begin thinking about securing your
    buckets by assigning encryption and logging. However, for this, we will just leave
    everything unchecked:![Figure 4.8 – S3 bucket configuration options
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_4.08_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.8 – S3 bucket configuration options
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will want to make the bucket public. If this were a real-world scenario,
    we would stray away from setting up a bucket like this; however, we want to make
    sure the bucket is public for our lab purposes. Public buckets are what lead to
    the majority of attacks where S3 is the primary vulnerability. By unchecking **Block
    all public access**, you'll be making the bucket public for anyone to access:![Figure
    4.9 – S3 bucket configuration options
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_4.09_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.9 – S3 bucket configuration options
  prefs: []
  type: TYPE_NORMAL
- en: 'Check all your configurations and click **Create bucket**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 4.10 – S3 bucket review'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_4.10_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.10 – S3 bucket review
  prefs: []
  type: TYPE_NORMAL
- en: Great job! You just created your first S3 bucket! This bucket will act as a
    vulnerable storage solution throughout this book, so make sure that you don't
    delete it.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's look at ways to upload data and see how the methods for pentesting
    S3 buckets can retrieve information. Before we get started, let's make an admin
    user that will give us an access ID and a secret that we can use to connect to
    our AWS S3 environment.
  prefs: []
  type: TYPE_NORMAL
- en: Quick detour – making IAM users
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It''s essential to have a user to access S3, so head over to the following
    area in the AWS console and get started: https://console.aws.amazon.com/iam/home?#/users.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you get to the **Identity and Access Management (IAM)** page, follow the
    next steps to create a user that we can use to access our S3 bucket:'
  prefs: []
  type: TYPE_NORMAL
- en: Click **Add User** in the top-left corner.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Give your user a name.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Check off the following options:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: --**AWS Management Console access**
  prefs: []
  type: TYPE_NORMAL
- en: '**--Programmatic access**'
  prefs: []
  type: TYPE_NORMAL
- en: Click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Skip adding tags.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review and create a **User**!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After that, you will get an **Access key ID**, **Secret access key**, and **Password**.
    Save these and store them in a secure place:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.11 – Successful IAM user creation'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_4.11_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.11 – Successful IAM user creation
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand how users are created, let's look at how we can configure
    them for our AWS environment and copy and upload data to S3 buckets.
  prefs: []
  type: TYPE_NORMAL
- en: Copying and uploading to S3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Great – now we have a user that we can use to access our S3 bucket. Uploading
    files to S3 buckets is the most essential use for handling S3 buckets. It is how
    we get our information into the cloud safely and securely.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two ways that data can be uploaded to S3:'
  prefs: []
  type: TYPE_NORMAL
- en: Using a web browser
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using the AWS CLI
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We are going to use both, but rely on the CLI for our pentesting methods. While
    having a **graphical user interface** (**GUI**) is a great option to have, it''s
    always better to use a CLI when available – this typically allows you more options
    and will be stable if and when a GUI fails. This user has administrator permissions,
    meaning it has **read** and **write** access. Let''s take a look at how we can
    upload a file to S3 via the CLI:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Connect to your AWS environment with the **Access key ID** and **Secret access
    key** from the user you created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Enter the ID and secret from your user. When prompted, leave the region and
    output format blank. You should now be all set and connected. Now let''s check
    out the buckets and verify the contents by listing out the contents of the S3
    bucket:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you should be able to see the bucket that you created listed out in a Linux-type
    format. Before we move forward, let''s break down the command, so we understand
    what each parameter does:'
  prefs: []
  type: TYPE_NORMAL
- en: '`aws`: This command allows you to interact with your AWS environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`s3`: This parameter will enable you to access your `s3` buckets. There are
    other commands that we can put here that we will discover later.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ls`: We mentioned this before. `ls` allows the user to list out the contents
    of a filesystem. We can use this in various operating systems, and with `s3` filesystems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`s3://`: Simply put, this allows you to access the filesystem via `s3`. This
    syntax is similar to other syntax to access local filesystem, such as SMB or FTP.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that you understand what the command is doing, let's keep moving forward
    and create a file that we can upload to the bucket. We found the directory that
    we created; the next move is to list out any contents that could be in the directory.
    In this case, we won't have any.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following will allow us to make a file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Type in the following command to list out the contents of the target bucket:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we create a file in the Terminal that can later be uploaded:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Make sure that contents were written to the file correctly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now upload the contents of the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Verify the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Congrats, you successfully uploaded a file from the AWS command line! You can
    also check for your file in the AWS web console, which should have the contents
    look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.12 – Text file view from the AWS console'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_4.12_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.12 – Text file view from the AWS console
  prefs: []
  type: TYPE_NORMAL
- en: 'To recap, here are the steps we went through to get our S3 bucket live:'
  prefs: []
  type: TYPE_NORMAL
- en: Created an IAM user
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configured and connected to your AWS environment
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Listed out the contents of the S3 bucket
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Created a file and copied it to the bucket
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we have created a bucket, let's look at some common misconfigurations
    that are seen when pentesting S3.
  prefs: []
  type: TYPE_NORMAL
- en: Bucket policies and ACLs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bucket policies and **access control lists** (**ACLs**) are used for access
    control – acting as the front line to allow and deny access to S3 resources in
    your AWS environment. Both ACL and buckets use JSON or YAML to write out their
    policies, which can make things difficult or easy, depending on how you look at
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's move forward as we take a look at how these policies are created!
  prefs: []
  type: TYPE_NORMAL
- en: Public bucket policies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When pentesting S3, one of the first things you'll want to do is look and see
    what the policies are for an S3 bucket. The following takes a look at a simple
    bucket policy that we'll create and how we can start interacting with buckets
    based on that policy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these steps to create a bucket and then list out its policy:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to the S3 bucket page and click on the bucket that we created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, click on the **Permissions** tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure that you have everything unchecked on **Block all public access**:![Figure
    4.13 – S3 bucket access view
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_4.13_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.13 – S3 bucket access view
  prefs: []
  type: TYPE_NORMAL
- en: Next, go to the **Bucket Policy** section and click **Policy Generator**, located
    near the bottom left of the page.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'From here, you''ll want the following parameters to be set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '--**Select Type of Policy**: **S3 Bucket Policy**'
  prefs: []
  type: TYPE_NORMAL
- en: '--**Effect**: **Allow**'
  prefs: []
  type: TYPE_NORMAL
- en: '--**Principal**: ***** – Putting *** annotates that we are selecting "all"'
  prefs: []
  type: TYPE_NORMAL
- en: '--**AWS Service**: **Amazon S3**'
  prefs: []
  type: TYPE_NORMAL
- en: '--**Actions**: **All Actions**'
  prefs: []
  type: TYPE_NORMAL
- en: '--**ARN**: **The ARN of your bucket**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You''ll be able to create a policy and upload it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 4.14 – S3 bucket policy'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_4.14_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.14 – S3 bucket policy
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have updated the policy, let''s take a look at how we can read
    it from the AWS CLI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give us the results of the bucket policy; however, we can make the
    format a little more legible using the following command, which `json tool` to
    output the information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the output of the preceding command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.15 – Getting an S3 bucket policy via the Terminal'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_4.15_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.15 – Getting an S3 bucket policy via the Terminal
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, we have successfully listed out the policy of our bucket in
    a more legible format.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding policy attributes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It''s essential to understand what each portion of the policy means and what
    it is doing. You don''t need to understand JSON to know what the policy is doing.
    Let''s dissect the policy we just made and look at what each attribute means.
    Let''s take a look at what some of the basic attributes that we will take a look
    at are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ID`: Used as a reference number.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Version`: Tells the users what version of the policy is being used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Action`: This tells you what type of resource is being used. In our case for
    this chapter, we are using S3\.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Effect`: This portion of the policy will either "deny" or "allow" access to
    the resource.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Resource`: ARN is placed here and tells the policy what resource the policy
    is being applied to.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing bucket policies for policy bypassing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now let's take a look at writing a new bucket policy. For this exercise, use
    the policy generator built into the AWS console. For this, we will make a new
    bucket; only this time, we'll create a bucket with more strict policies. It should
    have `Effect` set to `Deny` instead of `Allow`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is what the policy of your new bucket should look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Moving forward, let''s take a look at how we can upload files to our S3 bucket:'
  prefs: []
  type: TYPE_NORMAL
- en: 'List out the contents of the bucket:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we know which buckets to target, let''s make a file and upload it
    to the bucket:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.16 – Listing out the contents of the bucket and copying the file
    to the bucket'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_4.16_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.16 – Listing out the contents of the bucket and copying the file to
    the bucket
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we''ve confirmed that we can upload files to the bucket, this gives us
    a hint that we should be able to upload just about any file to the bucket. Next,
    let''s take our policy and change one line that will allow us to make any action
    on the S3 bucket:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s as simple as that. We now need to upload this to our bucket. Save the
    new policy as `policy.json`, and upload it using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Now you'll have a more **overly** permissive policy put in place that allows
    you much more control. This can be dangerous on an enterprise-level – it will
    enable users to change policies as they wish without proper authorization.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand how to make a bucket policy, let's keep moving forward
    and start to look at the dangers of public buckets.
  prefs: []
  type: TYPE_NORMAL
- en: Public buckets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Public buckets are one of the largest health risks to AWS and S3\. Large amounts
    of data leaks have been reported due to misconfigurations in S3 due to a poor
    security posture. Some of the issues that have been reported are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A lack of monitoring of S3 buckets. Without monitoring, there really isn't a
    stable way to check access to your S3 environments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A lack of testing and auditing of S3 environments proves to be a security issue.
    Something as simple as a vulnerability assessment or even a simple pentest would
    help highlight issues that can be easily fixed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Relaxed policies are another issue. If policies let too many users access S3
    resources, issues could arise if those accounts become compromised.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Popular opinions revolving around the security of S3 highlights that monitoring
    will heighten the security posture of S3; however, monitoring is only half the
    battle. As we saw, having an overly permissive policy can also allow users to
    make changes that would be thought of as "unauthorized." The word unauthorized
    is used lightly because the policy technically says it's allowed, but good practices
    advise against it.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's start to move forward and look at a public misconfiguration within
    a bucket.
  prefs: []
  type: TYPE_NORMAL
- en: Bucket misconfigurations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Just like local filesystems, misconfigurations can be the be-all and end-all
    for guarding networks. It's essential to look for simple and tiny details that
    could be used as leverage. S3 comes "preconditioned" with security in mind, meaning
    it is secured by default. The misconfigurations that you will see in this book
    and in the real world typically involve having misconfigured policies that allow
    too much access to a particular resource, or permissions that can easily be bypassed.
  prefs: []
  type: TYPE_NORMAL
- en: While we do create vulnerable buckets in this chapter and look at weak issues
    overall throughout this entire book, it's essential to make sure that you secure
    all your resources so that they aren't able to be exploited.
  prefs: []
  type: TYPE_NORMAL
- en: We've already discussed how to look for misconfigured policies, in the *Writing
    Bucket Policies for Policy Bypassing* section. Now let's take a look at how we
    would search for data in a public bucket within our AWS environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started, let''s go ahead and authenticate using our **Access key ID**
    and **Secret access key**.Once authenticated to the environment, let''s use the
    following steps to find a public bucket:'
  prefs: []
  type: TYPE_NORMAL
- en: 'List out the buckets within the AWS environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The next command will show us whether there is any public access allowed to
    the bucket:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'After running the command, we will see some output that will list out all the
    access control lists set to false. Having the ACL set to false means that all
    access is public, and the bucket has no authorization controls placed around it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.17 – Output from the public bucket, awspublicpackt'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_4.17_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.17 – Output from the public bucket, awspublicpackt
  prefs: []
  type: TYPE_NORMAL
- en: As we can see from the command's output, we can confirm that the bucket is public.
    If we were to discover this during a pentest, it would need to be logged and we
    would need to advise the client that public access should be denied, unless the
    bucket is public for a business reason. Additionally, if the bucket needed to
    remain public, users would need to be advised not to store any information in
    the bucket deemed sensitive.
  prefs: []
  type: TYPE_NORMAL
- en: In this next section, we are going to go onto a slightly different topic. We
    are going to discuss scripting and using scripting for security regarding S3 buckets.
  prefs: []
  type: TYPE_NORMAL
- en: Scripts to find private buckets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Scripting is a highly sought-after skill when it comes to cybersecurity because
    having the knowledge and ability to script tasks allows you to automate and provide
    results at a much more efficient rate while also executing another task. Scripting
    is also a great way to solve problems that may be unique – in this case, finding
    buckets that may not have a common name. Buckets can only have one unique name
    and no bucket is the same, so having a dictionary list of known buckets won't
    assist you directly. What that means is you'll need to make a modified version
    of the bucket names and place those in a text file that can be used to discover
    bucket names.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have a vast amount of knowledge on S3, let''s take a look at a
    couple of scripts that you could use on your next pentest engagement. We will
    look at two popular languages: Python and Bash.'
  prefs: []
  type: TYPE_NORMAL
- en: Python scripting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Python is a standard programming language in the security community due to its
    simplicity and usability. Lots of security engineers use it because it allows
    you to create, automate, and monitor everything on the fly! Recall that we set
    up PyCharm in [*Chapter 2*](B15630_02_Final_ASB_ePub.xhtml#_idTextAnchor056)*,
    Pentesting and Ethical Hacking*, and wrote a simple program to get an overview
    of how Python works.
  prefs: []
  type: TYPE_NORMAL
- en: Note that this is not a Python course, so we will not be going over the internal
    workings of Python; however, there are copious amounts of Python books offered
    by **Packt Publishing**. It is always encouraged to go out and read more about
    the material not covered in this book.
  prefs: []
  type: TYPE_NORMAL
- en: We need to install the Boto3 SDK for AWS. **SDK** is the acronym for **Software
    Development Kit** and, in this case, you can use Boto3 to allow you to directly
    create, update, and delete AWS resources from your Python scripts.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Boto3 is an AWS **Software Development Kit** (**SDK**) that is used for Python
    and allows developers to write code that can make use of services such as S3 and
    EC2\.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps will assist you in executing this correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open up a Terminal and type the following command to install `boto3`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you have the SDK that will allow you to build S3 buckets using Python!
    Let''s create a file that we can store our credentials in:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This will create a file that you can store your credentials in. Open the file
    using a file editor and input the following parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Now you are all set to use `boto3` and Python to interact with your S3 buckets!
  prefs: []
  type: TYPE_NORMAL
- en: There are lots of ways to interact with S3 and Python – this book's intention
    is to show the basics of doing that, however, please use this book as a primer
    and "stay curious" and look at more resources for scripting with Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a great resource to use now that you have boto3 set up: https://docs.ceph.com/docs/master/radosgw/s3/python/'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s create a script that can help us find buckets that will allow us
    to look for buckets in an S3 environment. You can use the Python Terminal to write
    the following script:'
  prefs: []
  type: TYPE_NORMAL
- en: We create a file with the `.py` extension at the end – for example, `myBucket.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Whichever way you choose to use it, the following script will help you find
    buckets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: It's highly recommended to place this script in PyCharm, where you can use it
    later – or expand it with more capabilities. Placing it within PyCharm also allows
    you to edit the file in PyCharm by default, making PyCharm your primary workspace.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've seen how we can make a simple script to find buckets, let's take
    a look at some **Bash** scripting.
  prefs: []
  type: TYPE_NORMAL
- en: Bash scripting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Bash** is a scripting language that supports automating a task, and in our
    case, helps us reach our goals with testing S3\. The **Bourne Again SHell**, or
    **Bash** for short, is a shell process that often comes built into operating systems
    – like our Kali Linux distro that we are using throughout this book.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To ensure you have **Bash** set up in your environment, type out the following
    command in your Kali Linux Terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that you have verified that you have **Bash** set up on your machine, let''s
    create a script that can be used to find buckets that may not have such a common
    name. Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a new file using the `vi` text editor:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: You should have the `vi` editor open. Now, input the following text in the Terminal.
    You'll need to press *Shift* **+** *I*together to begin typing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following script is written to discover potential buckets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.18 – Bash script'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_4.18_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.18 – Bash script
  prefs: []
  type: TYPE_NORMAL
- en: When you're finished, hit *Esc* and then type `:wq` to save and close the Terminal.
    That command will allow you to save and quit the program.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to verify that the script saved correctly, you can `cat` out of
    the file and should see the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Once you have the script ready to go, use the ARN of your bucket and scan the
    bucket.
  prefs: []
  type: TYPE_NORMAL
- en: Now we are going to take all the knowledge that we have learned so far and do
    something very important with it – use it in a pentest scenario that you can walk
    through. This walk-through helps aid and highlight real potential ways a pentest
    with AWS could be executed.
  prefs: []
  type: TYPE_NORMAL
- en: Goal-based pentesting scenarios
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now let's start to move forward and look at some real scenarios that are relatively
    common when pentesting S3 in a real-life environment. While it may not seem like
    typical "pentesting," because AWS pentesting does not use a typical pentesting
    methodology, it does still serve the mission of finding issues and leveraging
    them to your advantage. Goal-based pentesting entails testing a target with a
    "goal" in mind. In this case, we are looking for issues and mishaps that may be
    in an S3 bucket. Oftentimes, organizations will want to know how vulnerable a
    specific resource is, and how the path that leads to the vulnerability could be
    exploited.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this example, we will look at how an unsecured bucket leads us to delete
    an important document and then upload a document with the same name. We will be
    using an "assumed model," meaning that we already have some type of access to
    the system. Before we walk through the exercise, let''s take a look at what we
    will be doing:'
  prefs: []
  type: TYPE_NORMAL
- en: We will need to access the S3 environment – we will use our credentials. Since
    we are acting on an assumed model, this means we will be operating as a near-sider.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we will pull information about the objects in the bucket.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then we will delete the object and make our own object to upload – then upload
    the object to the bucket.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now that we have what we need, let''s execute this plan and move forward. The
    following is the step-by-step process of how to execute this properly:'
  prefs: []
  type: TYPE_NORMAL
- en: Use `AWS configure` to enter your environment. Remember, because we are using
    an "assumed" model, we are acting like someone who already has access to the environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once you''re configured and connected, the next move is to list out the contents
    of the buckets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we see the buckets, let''s take a look at the `test` bucket:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Hmm, it looks like we have a secret file that someone must have left behind.
    Unfortunately, the bucket was made public and made quickly, so security was an
    afterthought. Next, let''s go and grab the secret file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Great, now we have the file! Using our Kali Linux machine, let''s take a look
    at the contents of the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 4.19 – Listing out files of the bucket'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_4.19_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.19 – Listing out files of the bucket
  prefs: []
  type: TYPE_NORMAL
- en: 'We can take a deeper look and see who owns the object. In a real pentest, this
    could be useful information for spoofing or social engineering attacks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 4.20 – Listing out the contents of the object'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_4.20_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.20 – Listing out the contents of the object
  prefs: []
  type: TYPE_NORMAL
- en: It looks like this wasn't meant for us; however, because we are pentesting,
    it's crucial that we illustrate to clients the importance of security. In order
    for us to do that, we will need to remove the file and upload a new artifact.
    Ensure that you keep the original so that the client can have the file returned.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: If this were a real pentest and the file contained sensitive data, then you
    would immediately stop the pentest and inform your client before continuing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moving forward with our testing, let''s see if we can delete the file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, we have our file, now let''s delete that file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a new file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Upload the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: We have successfully removed the old file and uploaded a new file of our very
    own! As you can see, leaving public buckets open is a massive issue that can be
    easily mitigated by setting proper access controls that deny unauthorized users
    access to files containing data not meant for them.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand a little better how to find buckets in a real-life penetration
    test situation, let's look at another tool that you can use through a browser
    of your choice. The web tool called **Grayhat Warfare** allows you to discover
    buckets by making queries through its search engine.
  prefs: []
  type: TYPE_NORMAL
- en: Discovering buckets with Grayhat Warfare
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The next tool we are going to mention in this chapter is a personal favorite
    of mine. It makes discovering open S3 buckets easy and efficient. The web-based
    tool **Grayhat Warfare** allows users to find open buckets quickly with a simple
    query, and it also allows us to find other documents quickly by searching various
    file types.
  prefs: []
  type: TYPE_NORMAL
- en: Let's go over a quick example that will look for files under the `packtpub.com`
    domain.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start, first, open your web browser and go to [https://buckets.grayhatwarfare.com/](https://buckets.grayhatwarfare.com/):'
  prefs: []
  type: TYPE_NORMAL
- en: Next, search [packtpub.com](http://packtpub.com) in the **Keywords** section
    of the tool. Once you have the name in the **Keywords** box, click **Search**:![Figure
    4.21 – Searching packtpub.com with Grayhat Warfare
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_4.21_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.21 – Searching packtpub.com with Grayhat Warfare
  prefs: []
  type: TYPE_NORMAL
- en: You'll see a banner saying **Results for "packtpub com"**. Under the banner,
    you will see a list of buckets. In our case, with this example, we only discovered
    one bucket, however, that may change over time and by the time you complete this
    exercise:![Figure 4.22 – Discovering packtpub.com buckets with Grayhat Warfare
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_4.22_B15630.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.22 – Discovering packtpub.com buckets with Grayhat Warfare
  prefs: []
  type: TYPE_NORMAL
- en: From here, you can click on the buckets and download the objects within the
    bucket if you choose to. This example focuses more on the methodology rather than
    executing the full tool.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When using **Grayhat Warfare**, ensure that you are using best practices and
    only use the tool for ethical purposes. What does that mean? It means that while
    using the tool is 100% legal, you should advise any company if you discover a
    leaky bucket associated with their domain.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: A leaky bucket is an S3 bucket that is open to the internet and is leaking sensitive
    information. If you discover a leaky bucket, contact the owner and notify them
    immediately!
  prefs: []
  type: TYPE_NORMAL
- en: It also means not using the tool for unethical reasons such as using discovered
    data to harm an organization.
  prefs: []
  type: TYPE_NORMAL
- en: Moving forward, let's start to wrap up this chapter. We have learned a great
    deal about S3 environments and how to manipulate and exploit S3 buckets. Next,
    let's discuss a couple of extras about S3 and then start wrapping up.
  prefs: []
  type: TYPE_NORMAL
- en: S3 Burp Suite extensions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Burp Suite is a tool commonly used for web application testing. We aren''t
    going to get deep into the details of how Burp Suite works, however, please stop
    by the PortSwigger website for more details: https://portswigger.net/burp.'
  prefs: []
  type: TYPE_NORMAL
- en: With an enormous amount of available extensions, `aws-extender`. The extension
    allows you to scan for misconfigurations in S3 buckets.
  prefs: []
  type: TYPE_NORMAL
- en: Before we begin, we need to ensure we have the most up-to-date Python package
    installed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Download it here: [https://github.com/jythontools/jython](https://github.com/jythontools/jython).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s move forward and retrieve a copy of the tool:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by retrieving a copy of the package:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Follow the instructions provided on the website and continue once complete.
  prefs: []
  type: TYPE_NORMAL
- en: 'After installing the new `jython` package, go ahead and clone the tool to your
    machine from this repository: [https://github.com/VirtueSecurity/aws-extender.git](https://github.com/VirtueSecurity/aws-extender.git):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you''re done, you''ll need to move onto the extensions and use `pip` to
    install the requirements:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This portion may take a moment, so give it some time.
  prefs: []
  type: TYPE_NORMAL
- en: Now you'll need to load the extension into Burp Suite. You can find `burpsuite`
    into a Terminal and the application will start up. Once you have the application
    started, go to the `aws-extender` Python program directory.
  prefs: []
  type: TYPE_NORMAL
- en: We are going to move in a different direction really quickly and look at something
    really interesting – creating a local S3 lab that you can use for practice!
  prefs: []
  type: TYPE_NORMAL
- en: Creating a local S3 lab
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There will be times where you may want to test S3 without having to set up a
    filesystem in the cloud. Due to S3 only allowing unique names, finding "test"
    names can become cumbersome, and creating a test environment can be tedious. However,
    that shouldn't hinder you from being able to set up a local lab where you can
    learn more about S3\.
  prefs: []
  type: TYPE_NORMAL
- en: '**MinIO** is a local storage system that can be used to house data that you
    would want in the cloud. The reason we mention it here in the book is because
    it is a great way to learn about S3 storage on your local network, without being
    restricted to only using names available in AWS. However, one of the drawbacks
    of MinIO is that policy setup can be a little bit of a learning curve or odd if
    you''re used to typical policy generation with AWS.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now you can do just that – set up a local S3 lab that you can use at your disposal
    with a program called **MinIO**, as per their statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '*MinIO is High-Performance Object Storage released under Apache License v2.0\.
    It is API compatible with Amazon S3 cloud storage service. Using MinIO build high-performance
    infrastructure for machine learning, analytics and application data workloads.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*- MinIO*'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can locate more about the MinIO project here: [https://github.com/minio/minio](https://github.com/minio/minio).'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find a full walk-through on how to set up MinIO here: [https://medium.com/@jonathanchelmus/creating-an-s3-lab-on-an-ec2-instance-95ffd8ac6c1](mailto:https://medium.com/@jonathanchelmus/creating-an-s3-lab-on-an-ec2-instance-95ffd8ac6c1).'
  prefs: []
  type: TYPE_NORMAL
- en: I highly suggest looking through the documentation and setting up a local lab
    that you can use for testing and building your S3 skill sets, with the ease of
    using your local lab.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned quite a bit about S3 buckets and some ways to exploit
    common public bucket issues. We also learned more about AWS Regions and Availability
    Zones and what they are in relation to S3 buckets and AWS in general. The chapter
    also went over various scripting languages such as Python and Bash, and how we
    can use Python and Bash to scan S3 buckets.
  prefs: []
  type: TYPE_NORMAL
- en: To finish off, we took a look at a "real-world" scenario by applying proof of
    concept to a public S3 bucket that we made. It's encouraged that you create your
    own scenarios and execute them – while staying within the legal bounds of AWS
    practices and policies.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we took a look at some other projects that can help us dive more into
    S3, without having to use AWS. Technology such as MinIO is a great resource to
    use if you're looking to set up a local S3 bucket lab.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will go over what RDS is by discussing some key points
    and setting up an RDS database using MySQL.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Public bucket tool: [https://github.com/Moos1e/Recon-Public-Buckets/tree/master](https://github.com/Moos1e/Recon-Public-Buckets/tree/master)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'MinIO setup in EC2: [https://medium.com/@jonathanchelmus/creating-an-s3-lab-on-an-ec2-instance-95ffd8ac6c1](mailto:https://medium.com/@jonathanchelmus/creating-an-s3-lab-on-an-ec2-instance-95ffd8ac6c1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'More about S3: [https://aws.amazon.com/s3/features/](https://aws.amazon.com/s3/features/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Creating buckets: [https://docs.aws.amazon.com/AmazonS3/latest/gsg/CreatingABucket.html](https://docs.aws.amazon.com/AmazonS3/latest/gsg/CreatingABucket.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'More about boto3: [https://realpython.com/python-boto3-aws-s3/](https://realpython.com/python-boto3-aws-s3/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
