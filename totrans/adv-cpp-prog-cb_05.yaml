- en: Concurrency and Synchronization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will learn how to properly handle concurrency, synchronization,
    and parallelism in C++. Here, it is essential that you have a general knowledge
    of C++ and C++ threads. This chapter is important because working with C++ typically
    requires the use of shared resources, which can easily become corrupt if thread-safety
    is not implemented properly. We will start with an extensive overview of `std::mutexes`,
    which provides a means to synchronizing C++ threads. We will then look at atomic
    data types, which provide another mechanism for handling parallelism safely.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter has recipes that demonstrate how to handle different scenarios
    while working with C++ threads, including handling `const &`, thread-safety wrapping,
    blocking versus asynchronous programming, and C++ promises and futures. This is
    important, as this knowledge is critical when working with multiple threads of
    execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following recipes are covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Working with mutexes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using atomic data types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding what `const &` mutable mean in the context of multiple threads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making a class thread-safe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synchronization wrappers and how to implement them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blocking operations versus asynchronous programming
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with promises and futures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To compile and run the examples in this chapter, you must have administrative
    access to a computer running Ubuntu 18.04 with a functional internet connection.
    Prior to running these examples, you must install the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: If this is installed on any operating system other than Ubuntu 18.04, then GCC
    7.4 or higher and CMake 3.6 or higher will be required.
  prefs: []
  type: TYPE_NORMAL
- en: Working with mutexes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will learn why and how to use a mutex in C++. When working
    with multiple threads in C++, it is common to establish resources that are shared
    between threads. As we will demonstrate in this recipe, attempting to use these
    shared resources simultaneously leads to race conditions that are capable of corrupting
    the resource.
  prefs: []
  type: TYPE_NORMAL
- en: A mutex (in C++, this is written as `std::mutex`) is an object that is used
    to guard a shared resource, ensuring that more than one thread can access a shared
    resource in a controlled manner. This prevents it from becoming corrupt.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we begin, please ensure that all of the technical requirements are met,
    including installing Ubuntu 18.04 or higher and running the following in a terminal
    window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This will ensure your operating system has the proper tools to compile and execute
    the examples in this recipe. Once this is complete, open a new terminal. We will
    use this terminal to download, compile, and run our examples.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You need to perform the following steps to try this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'From a new terminal, run the following to download the source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'To compile the source code, run the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the source code is compiled, you can execute each example in this recipe
    by running the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we will step through each of these examples and explain
    what each example program does and how it relates to the lessons being taught
    in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we will learn how to use `std::mutex` to protect a shared resource
    from becoming corrupt. To start, let''s first review how a resource could become
    corrupt when more than one thread is accessing it at the same time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'When executed, we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/01192c95-b3c1-4df5-a5a4-b94be4b18090.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding example, we create a function that outputs to `stdout` in an
    endless loop. We then create two threads, with each thread executing the previously
    defined function. As you can see, when both threads execute, the resulting output
    becomes corrupt. This is because while one thread is in the middle of outputting
    its text to `stdout`, the other thread outputs to `stdout` at the same time, resulting
    in the output from one thread being mixed with the output of the other thread.
  prefs: []
  type: TYPE_NORMAL
- en: To deal with this issue, we must ensure that, once one of the threads attempts
    to output its text to `stdout`, it should be allowed to finish its output before
    the other thread is able to output. In other words, each thread must take turns
    outputting to `stdout`. While one thread is outputting, the other thread must
    wait its turn. To do this, we will leverage an `std::mutex` object.
  prefs: []
  type: TYPE_NORMAL
- en: std::mutex
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A mutex is an object that is used to guard a shared resource to ensure the use
    of the shared resource does not result in corruption. To accomplish this, `std::mutex`
    has a `lock()` function and an `unlock()` function. The lock function *acquires*
    access to a shared resource (sometimes referred to as a critical section). `unlock()` *releases*
    this previously acquired access. Any attempt to execute the `lock()` function
    after another thread has already executed `lock()` will result in the thread having
    to wait until the `unlock()` function is executed.
  prefs: []
  type: TYPE_NORMAL
- en: How `std::mutex` is implemented depends on the CPU's architecture and the operating
    system; however, in general, a mutex can be implemented with a simple integer.
    If the integer is `0`, the `lock()` function will set the integer to `1` and return,
    which tells the mutex that it is acquired. If the integer is `1`, meaning the
    mutex is already acquired, the `lock()` function will wait (that is, block) until
    the integer becomes `0`, and then it will set the integer to `1` and return. How
    this wait is implemented depends on the operating system. For example, the `wait()`
    function can loop forever until the integer becomes `0`, which is called a **spinlock**,
    or it can execute a `sleep()` function and wait for a period of time, allowing
    other threads and processes to execute while the mutex is locked. The release
    function always sets the integer to `0`, meaning the mutex is no longer acquired.
    The trick to ensuring the mutex works properly is to ensure the integer is read/written
    using atomic operations. If non-atomic operations are used, the integer itself
    would suffer the same shared resource corruption the mutex is trying to prevent.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This example, when run, outputs the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a74a32c8-e166-46cc-b84f-774e905f34cb.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding example, we create the same function that outputs to `stdout`.
    The difference is, before we output to `stdout`, we acquire `std::mutex` by executing
    the `lock()` function. Once we are done outputting to `stdout`, we release the
    mutex by executing the `unlock()` function. The code in between the `lock()` and
    `unlock()` functions is called the **critical region**. Any code in the critical
    region can only be executed by one thread at any given time, ensuring our use
    of `stdout` does not become corrupt.
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring shared resources do not become corrupt by controlling access to the
    shared resource (for example, using a mutex) is called **synchronization**. Although
    the majority of scenarios where thread synchronization is needed are not complicated,
    some scenarios can result in thread synchronization schemes that require an entire
    college course to cover. For this reason, thread synchronization is considered
    an extremely difficult paradigm in computer science to program correctly.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this recipe, we will cover some of these scenarios. To start, let''s discuss
    something called a **deadlock**. A deadlock occurs when a thread enters an endless
    wait state when calling the `lock()` function. A deadlock is often extremely difficult
    to debug and is the result of several reasons, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A thread never calling `unlock()` due to programmer error or the thread that
    acquired the mutex crashing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The same thread calling the `lock()` function more than once before it calls
    `unlock()`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each thread locking more than one mutex in a different order
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To demonstrate this, let''s look at the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we create two threads, both of which attempt to lock
    the mutex but never call `unlock()`. As a result, the first thread acquires the
    mutex and then returns without releasing it. When the second thread attempts to
    acquire the mutex, it is forced to wait for the first thread to execute `unlock()`,
    which it never does, resulting in a deadlock (that is, the program never returns).
  prefs: []
  type: TYPE_NORMAL
- en: 'Deadlock, in this example, is simple to identify and correct; however, in real-world
    scenarios, identifying deadlock is a lot more complicated. Let''s look at the
    following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we wrote a function that returns an element in an
    array, given an index. In addition, we acquire a mutex that guards the array and
    releases the mutex just before returning. The challenge here is that we have to
    `unlock()` the mutex where the function can return, which includes not only every
    possible branch that returns from the function, but all possible scenarios where
    an exception could be thrown. In the preceding example, if the index that is provided
    is larger than the array, the `std::array` object will throw an exception, resulting
    in the function returning before the function has a chance to call `unlock()`,
    which would result in deadlock if another thread is sharing this array.
  prefs: []
  type: TYPE_NORMAL
- en: std::lock_guard
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Instead of littering your code with `try`/`catch` blocks to prevent deadlock,
    which assumes the programmer is even capable of determining every possible scenario
    where this could occur without making a mistake, C++ provides an `std::lock_guard` object
    to simplify the use of the `std::mutex` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'When executed, we see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/948ff65e-fbca-4f22-98f2-85b33fe28cea.png)'
  prefs: []
  type: TYPE_IMG
- en: As shown in the preceding example, `std::lock_guard` is used when we would normally
    call `lock()` on the mutex. `std::lock_guard` calls the `lock()` function on the
    mutex when it is created and then calls `unlock()` on the mutex when it is destroyed
    (an idiom called **Resource Acquisition Is Initialization** or **RAII**). No matter
    how the function returns (either from a normal return or an exception), the mutex
    will always be released, ensuring deadlock is not possible, preventing the programmer
    from having to accurately determine every possible scenario where the function
    could return.
  prefs: []
  type: TYPE_NORMAL
- en: Although `std::lock_guard` is capable of preventing deadlock in cases where
    `unlock()` is never called, it is not capable of preventing deadlock from occurring
    in cases where `lock()` is called by the same thread more than once prior to `unlock()`
    being called. To handle this scenario, C++ provides `std::recursive_mutex`.
  prefs: []
  type: TYPE_NORMAL
- en: std::recursive_mutex
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A recursive mutex increments the integer stored inside the mutex each time the
    same thread calls the `lock()` function without causing the `lock()` function
    to wait. For example, if the mutex is released (that is, the integer in the mutex
    is `0`), when thread `#1` calls the `lock()` function, the integer in the mutex
    is set to `1`. Normally, if thread `#1` calls the `lock()` function again, the
    `lock()` function would see that the integer is `1` and enter a wait state until
    the integer is set to `0`. Instead, a recursive mutex will determine which thread
    is calling the `lock()` function, and, if the thread that acquired the mutex is
    the same thread calling the `lock()` function, the integer in the mutex is incremented
    again (now resulting in `2`) using an atomic operation. For the mutex to be released,
    the thread must call `unlock()`, which decrements the integer using an atomic
    operation, until the integer in the mutex is `0`.
  prefs: []
  type: TYPE_NORMAL
- en: The recursive mutex allows the same thread to call the `lock()` function as
    many times as it wants, preventing multiple calls to the `lock()` function and
    resulting in deadlock at the expense that the `lock()` and `unlock()` functions
    must include an added function call to get the thread's `id()` instance, so that
    the mutex can determine which thread is calling `lock()` and `unlock()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, consider the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding example results in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fef09e3b-fb6a-479b-a600-6c482d4c8b94.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding example, we define a function that calls the `lock()` function
    for a recursive mutex twice, outputs to `stdout`, and then calls the `unlock()`
    function twice. We then create two threads that execute this function, resulting
    in no corruption to `stdout` and no deadlock.
  prefs: []
  type: TYPE_NORMAL
- en: std::shared_mutex
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up until this point, our synchronization primitives have serialized access to
    our shared resource. That is, each thread must execute one at a time when accessing
    the critical region. Although this ensures corruption is not possible, it is inefficient
    for certain types of scenarios. To better understand this, we must examine what
    causes corruption in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider an integer variable that is incremented by two threads simultaneously.
    The process for incrementing an integer variable is as follows: `i = i + 1`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s write this as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'To prevent corruption, we use a mutex to ensure that if two threads increment
    the integer, they do so synchronously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Corruption occurs when these operations mix (that is, when both operations
    execute simultaneously in different threads). For example, consider this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Instead of the integer being `2`, it is `1`, because the integer is read before
    the first increment is allowed to finish. This scenario is possible because both
    threads are attempting to write to the same shared resource. We call these types
    of threads **producers**.
  prefs: []
  type: TYPE_NORMAL
- en: What if, however, we create a million threads that read the shared resource
    simultaneously. Since the integer never changes, no matter what order the threads
    execute in, they will all read the same value, and therefore corruption is not
    possible. We call these threads **consumers**. If we only ever have consumers,
    we do not need thread synchronization as corruption is not possible.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, what happens if we have the same 1 million consumers, but we add a
    single producer to the mix? Now, we must use thread synchronization because it
    is possible that while the producer is in the middle of attempting to write a
    value to the integer that a consumer attempts to read, it will result in a corrupt
    result. To prevent this, we must use a mutex to guard the integer. If we use `std::mutex`,
    however, all 1 million consumers would have to wait on each other, even though
    the consumers themselves can safely execute simultaneously without the fear of
    corruption. It is only when the producer attempts to execute that we must be worried.
  prefs: []
  type: TYPE_NORMAL
- en: 'To handle this obvious performance problem, C++ provides the `std::shared_mutex`
    object. For example, consider this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we create a producer function (called the `reader`
    function) and a consumer function (called the `writer` function). The producer
    locks the mutex using `std::unique_lock()`, while the consumer locks the mutex
    using `std::shared_lock()`. Whenever the mutex is locked using `std::unique_lock()`,
    all other threads must wait (producer and consumer alike). If, however, the mutex
    is locked using `std::shared_lock()`, additional attempts to lock the mutex using
    `std::shared_lock()` do not result in the thread waiting.
  prefs: []
  type: TYPE_NORMAL
- en: It's only when `std::unique_lock()` is called that a wait must occur. This allows
    the consumers to execute without waiting on each other. It's only when the producer
    attempts to execute that the consumers must wait, preventing the consumers from
    serializing each other, ultimately resulting in better performance (especially
    if the number of consumers is 1 million).
  prefs: []
  type: TYPE_NORMAL
- en: It should be noted that we use the `const` keyword to ensure that a consumer
    is not a producer. This simple trick ensures that the programmer doesn't accidentally
    think they have programmed a consumer when, in fact, they have created a producer,
    as the compiler would warn the programmer if this occurred.
  prefs: []
  type: TYPE_NORMAL
- en: std::timed_mutex
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finally, we have not dealt with the scenario where a thread that acquired a
    mutex crashed. In this scenario, any thread that attempts to acquire the same
    mutex would enter a deadlock state as the thread that crashed never gets a chance
    to call `unlock()`. One way to prevent this issue is to use `std::timed_mutex`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'When this is executed, we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a606b9bb-6ef7-4885-93e6-344fc3bc06e7.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding example, we tell C++ that the thread is only allowed to wait
    for 1 second. If the mutex is already acquired and it is not released after 1
    second, the `try_lock_for()` function will exit and return false, allowing the
    thread to gracefully exit and handle the error without entering a deadlock.
  prefs: []
  type: TYPE_NORMAL
- en: Using atomic data types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to use atomic data types in C++. Atomic data
    types provide the ability to read and write simple data types (that is, a Boolean
    or integer) without the need for thread synchronization (that is, the use of `std::mutex`
    and friends). To accomplish this, atomic data types are implemented using special
    CPU instructions that ensure when an operation is executed, it is done so as a
    single, atomic operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, incrementing an integer can be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: An atomic data type ensures that this increment is executed such that no other
    attempts to increment the integer simultaneously can interleave, and therefore result
    in corruption. How this is done by the CPU is out of the scope of this book. That's
    because this is extremely complicated in modern, super-scalar, pipelined CPUs
    that support the execution of instructions in parallel, out-of-order, and speculatively
    on multiple cores and sockets.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we begin, please ensure that all of the technical requirements are met,
    including installing Ubuntu 18.04 or higher and running the following in a terminal
    window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This will ensure your operating system has the proper tools to compile and execute
    the examples in this recipe. Once this is complete, open a new terminal. We will
    use this terminal to download, compile, and run our examples.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You need to perform the following steps to try this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'From a new terminal, run the following to download the source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'To compile the source code, run the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the source code is compiled, you can execute each example in this recipe
    by running the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we will step through each of these examples and explain
    what each example program does and how it relates to the lessons being taught
    in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to use C++'s atomic data types. Atomic data
    types are limited to simple data types such as integers, and since these data
    types are extremely complicated to implement, the only operations that are supported
    are simple operations such as add, subtract, increment, and decrement.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at a simple example that not only demonstrates how to use
    an atomic data type in C++, but also demonstrates why atomic data types are so
    important:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'When this code is executed, we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/216f9a16-1893-4c5f-b259-da1e2d0b4bc0.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding example, we have two integers. The first integer is a normal
    C/C++ integer type, while the second is an atomic data type (of type integer).
    We then define a function that loops until the atomic data type is `1000`. Finally,
    we execute this function from two threads, which means our global integers are
    incremented by two threads simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the output of this simple test shows that the simple C/C++
    integer data type is not the same value as the atomic data type, yet both are
    incremented the same number of times. The reason for this can be seen in the assembly
    of this function (on an Intel CPU), as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b1e3de9e-b754-49b6-a53a-d4e0bfd9cc2f.png)'
  prefs: []
  type: TYPE_IMG
- en: To increment an integer (without optimizations enabled), the compiler must move
    the contents of memory into a register, add `1` to the register, and then write
    the results of the register back to memory. Since this code is executing simultaneously
    in two different threads, this code interleaves, resulting in corruption. The
    atomic data type does not suffer this same problem. This is because the process
    of incrementing the atomic data type occurs in a single, special instruction that
    the CPU ensures to execute, without interleaving its internal state with the same
    internal state of other instructions, on other CPUs.
  prefs: []
  type: TYPE_NORMAL
- en: Atomic data types are typically used to implement synchronization primitives
    such as `std::mutex` (although, in practice, `std::mutex` is implemented using
    test and set instructions, which use a similar principle but oftentimes execute
    faster than atomic instructions). These data types can also be used to implement
    special data structures called lock-free data structures, which are capable of
    operating in multithreaded environments without the need for `std::mutex`. The
    benefit of lockless data structures is that there are no wait states when dealing
    with thread synchronization at the expense of more complicated CPU hardware and
    other types of performance penalties (most CPU optimizations provided by the hardware
    have to be temporarily disabled when the CPU encounters an atomic instruction).
    So, like anything in computer science, they have their time and place.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding what const & mutable mean in the context of multiple threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to deal with objects that are labeled `const`,
    but contain `std::mutex` that must be used to ensure thread synchronization. This
    recipe is important because it is useful to store `std::mutex` as a private member
    of a class, but, as soon as you do this, passing an instance of this object as
    a constant reference (that is, `const &`) will result in a compiler error. In
    this recipe, we will demonstrate why this occurs and how to overcome it.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we begin, please ensure that all of the technical requirements are met,
    including installing Ubuntu 18.04 or higher and running the following in a terminal
    window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: This will ensure your operating system has the proper tools to compile and execute
    the examples in this recipe. Once this is complete, open a new terminal. We will
    use this terminal to download, compile, and run our examples.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You need to perform the following steps to try this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'From a new terminal, run the following to download the source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'To compile the source code, run the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the source code is compiled, you can execute each example in this recipe
    by running the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we will step through each of these examples and explain
    what each example program does and how it relates to the lessons being taught
    in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to add `std::mutex` to a class's private members
    while still being able to handle `const` scenarios. Generally speaking, there
    are two ways to ensure an object is thread-safe. The first method is to place
    `std::mutex` at the global level. Doing this ensures an object can be passed as
    a constant reference or the object itself can have a function marked as `const`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this, consider the following code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we create an object that outputs to `stdout` when
    the `print()` function is executed. The `print()` function is labeled as `const`,
    which tells the compiler that the `print()` function will not modify any class
    members (that is, the function is read-only). Since `std::mutex` is global, the
    const-qualifier of the object is maintained and the code compiles and executes
    without an issue.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with a global `std::mutex` object is that every instance of the
    object must use the same `std::mutex` object. This is fine if the user intends
    this, but what if you want each instance of the object to have its own `std::mutex` object
    (for example, when the same instance of the object might be executed by more than
    one thread)?
  prefs: []
  type: TYPE_NORMAL
- en: 'For this, let''s take a look at how that happens using the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'If we attempt to compile this, we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/944a6bd9-fba1-4f70-b061-5dc7c7c4afba.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding example, all we did was take the previous example and move
    `std::mutex` inside the class as a private member. As a result, when we attempt
    to compile the class, we get a compiler error. This is because the `print()` function
    is marked as `const`, which tells the compiler that the `print()` function will
    not modify any of the class's members. The problem is that when you attempt to
    lock `std::mutex`, you must modify it, resulting in a compiler error.
  prefs: []
  type: TYPE_NORMAL
- en: To overcome this, we must tell the compiler to ignore this error by marking
    `std::mutex` as mutable. Marking a member as mutable tells the compiler that the
    member is allowed to be modified, even when the object is passed as a constant
    reference or when the object defines a constant function.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, this is how the code appears on `const` marked as `mutable`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: As you can see in the preceding example, once we mark `std::mutex` as mutable,
    the code compiles and executes as we would expect. It should be noted that `std::mutex`
    is one of the few examples for which the use of mutable is acceptable. The mutable
    keyword can easily be abused, resulting in code that doesn't compile or operate
    as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Making a class thread-safe
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we will learn how to make a class thread-safe (that is, how
    to ensure a class''s public member functions can be called at any time, by any
    number of threads simultaneously). Most classes, especially those provided by
    the C++ standard library are not thread-safe and, instead, assume the user will
    add thread-synchronization primitives such as an `std::mutex` object as needed.
    The problem with this approach is that every object has two instances that must
    be tracked in code: the class itself and its `std::mutex`. The user must also
    wrap each of the object''s functions with custom versions that protect the class
    using `std::mutex`, resulting in not only two objects that must be managed, but
    also a bunch of C-style wrapper functions.'
  prefs: []
  type: TYPE_NORMAL
- en: This recipe is important because it will demonstrate how to address these issues
    in your code by making a thread-safe class, which combines everything into a single
    class.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we begin, please ensure that all of the technical requirements are met,
    including installing Ubuntu 18.04 or higher and running the following in a terminal
    window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: This will ensure your operating system has the proper tools to compile and execute
    the examples in this recipe. Once this is complete, open a new terminal. We will
    use this terminal to download, compile, and run our examples.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You need to perform the following steps to try this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'From a new terminal, run the following to download the source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'To compile the source code, run the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the source code is compiled, you can execute each example in this recipe
    by running the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we will step through each of these examples and explain
    what each example program does and how it relates to the lessons being taught
    in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to make a thread-safe class by implementing
    our own thread-safe stack. The C++ standard library does not provide thread-safe
    data structures, and, as a result, if you wish to use a data structure as a global
    resource across multiple threads, you add thread-safety manually. This can be
    done by implementing wrapper functions, or by creating a wrapper class.
  prefs: []
  type: TYPE_NORMAL
- en: The advantage of creating wrapper functions is that, for global objects, the
    amount of code that is needed is oftentimes smaller and easier to understand,
    while the advantage of a thread-safe class is that you can create multiple instances
    of the class, as `std::mutex` is self-contained.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be tried with the following code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we implement our own stack. This stack has `std::stack`
    and `std::mutex` as member variables. We then reimplement some of the functions
    the `std::stack` provides. Each of these functions first attempts to acquire `std::mutex`
    and then calls the associated function in `std::stack`. In the case of the `push()`
    function, we leverage `std::forward` to ensure the arguments passed to the `push()`
    function are preserved.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can use our custom stack the same way we would use `std::stack`.
    For example, take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the only difference between `std::stack` and our custom stack
    is that our stack is thread-safe.
  prefs: []
  type: TYPE_NORMAL
- en: Synchronization wrappers and how to implement them
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to make thread-safe synchronization wrappers.
    By default, the C++ standard library is not thread-safe as not all applications
    will need this functionality. One mechanism to ensure the C++ standard library
    is thread-safe is to create a thread-safe class, which adds the data structure
    you wish to use as well as `std::mutex` to the class as private members, and then
    reimplements the data structure's functions to first acquire `std::mutex` and
    then forward the function call to the data structure. The problem with this approach
    is there is a lot of extra code that is added to your program if the data structure
    is a global resource, making the resulting code hard to read and maintain.
  prefs: []
  type: TYPE_NORMAL
- en: This recipe is important because it will demonstrate how to address these issues
    in your code by making thread-safe synchronization wrappers.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we begin, please ensure that all of the technical requirements are met,
    including installing Ubuntu 18.04 or higher and running the following in a terminal
    window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: This will ensure your operating system has the proper tools to compile and execute
    the examples in this recipe. Once this is complete, open a new terminal. We will
    use this terminal to download, compile, and run our examples.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You need to perform the following steps to try this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'From a new terminal, run the following to download the source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'To compile the source code, run the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the source code is compiled, you can execute each example in this recipe
    by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we will step through each of these examples and explain
    what each example program does and how it relates to the lessons being taught
    in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to create thread-safe synchronization wrappers,
    which allow us to add thread-safety to the C++ standard library data structures,
    which, by default, are not thread-safe.
  prefs: []
  type: TYPE_NORMAL
- en: To do this, we will create wrapper functions for each function in the C++ standard
    library that we intend to use. These wrapper functions will first attempt to acquire
    `std::mutex`, before forwarding the same function call to the C++ standard library
    data structure.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, consider the following code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we have created a wrapper function for the `push()`,
    `pop()`, and `empty()` functions. These functions attempt to acquire our global
    `std::mutex` object before calling the data structure, which, in this case, is
    a template. The use of a template creates what is called a concept. Our wrapper
    functions can be used by any data structure that implements `push()`, `pop()`,
    and `empty()`. Also, note that we use `std::forward` in our `push()` function
    to ensure the l-valueness and CV qualifiers of the argument being pushed remain
    unchanged.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can use our wrappers the same way we would use the data structure''s
    functions, with the slight difference being that the data structure is passed
    as the first argument. For example, take a look at the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: As you can see in the preceding example, the use of our synchronization wrappers
    is simple, while ensuring the stack that we created is now thread-safe.
  prefs: []
  type: TYPE_NORMAL
- en: Blocking operations versus asynchronous programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will learn the difference between a blocking operation and
    an asynchronous operation. This recipe is important because blocking operations
    serialize the execution of each operation on a single CPU. This is typically fine
    if the execution of each operation must be executed in serial order; however,
    if these operations can be executed in parallel, asynchronous programming can
    be a useful optimization, ensuring that, while an operation is waiting, others
    can still execute on the same CPU.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we begin, please ensure that all of the technical requirements are met,
    including installing Ubuntu 18.04 or higher and running the following in a terminal
    window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: This will ensure that your operating system has the proper tools to compile
    and execute the examples in this recipe. Once this is complete, open a new terminal.
    We will use this terminal to download, compile, and run our examples.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You need to perform the following steps to try this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'From a new terminal, run the following to download the source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'To compile the source code, run the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the source code is compiled, you can execute each example in this recipe
    by running the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we will step through each of these examples and explain
    what each example program does and how it relates to the lessons being taught
    in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A blocking operation is an operation that must be completed before the next
    operation can take place. Most programs are written serially, meaning each instruction
    must execute before the next instruction. The problem, however, is that some operations
    can be executed in parallel (that is, either concurrently or asynchronously).
    Serializing these operations can, in the best case, lead to poor performance and,
    in some cases, can actually lead to deadlock (the program entering an endless
    wait state) if the operation that is blocking is waiting on another operation
    that is never given a chance to execute.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate a blocking operation, let''s examine the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code creates a main function with four `std::vector` objects
    of the `int` type. In the following steps, we will use these vectors to demonstrate
    a blocking operation:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we create four vectors that we can store integers in:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we fill each array with random numbers using `std::generate`, which results
    in an array with numbers and a random order:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we sort the array of integers, which is the main goal of this example,
    as this operation takes a while to execute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we output the last entry in each array, which will usually be `999999`
    (but doesn't have to be since the numbers were generated using a random number
    generator).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The problem with the preceding example is that the operations could be executed
    in parallel because each array is independent. To address this, we can execute
    these operations asynchronously, meaning the arrays will be created, filled, sorted,
    and outputted in parallel. For example, consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The first thing we do is implement a function called `foo()` that creates our
    vector, fills it with random numbers, sorts the list, and returns the last entry
    in the array (which is identical to the preceding example with the exception that
    we only work with one array at a time and not `4`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: We then use `std::async` to execute this `foo()` function four times, resulting
    in the same four arrays, just like our previous example. The `std::async()` function
    in this example does the same thing as executing four threads manually. The result
    of `std::aync()` is a `std::future` object, which stores the result of the function
    once it has finished executing. The last thing we do in this example is use the
    `get()` function to return the value of the function once it is ready.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we time the results of these functions, we can see that the asynchronous
    version is faster than the blocking version. The following code shows this (the
    `real` time is the time to look for):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/46ef0e32-b06c-4bc6-9b92-5984d00d7432.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `std::async()` function can also be used to execute our array function
    asynchronously in the same thread. For example, consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: As you can see in the preceding example, we changed the operation from `std::launch::async`
    to `std::launch::deferred`, which results in each function executing once the
    result of the function is needed (that is, when the `get()` function is called).
    This is useful if you are not sure whether the function needs to execute in the
    first place (that is, only execute the function when needed), with the downside
    being that the execution of the program is slower, as threads are not typically
    used as an optimization method.
  prefs: []
  type: TYPE_NORMAL
- en: Working with promises and futures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to use C++ promises and futures. C++ `promise`
    is an argument to a C++ thread, while C++ `future` is the return value of the
    thread, and can be used to manually implement the same functionality of an `std::async`
    call. This recipe is important because a call to `std::aync` requires that each
    thread stops execution to get its result, while manually implementing a C++ `promise`
    and **`future`** allows the user to get the return value of a thread while the
    thread is still executing.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we begin, please ensure that all of the technical requirements are met,
    including installing Ubuntu 18.04 or higher and running the following in a terminal
    window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: This will ensure your operating system has the proper tools to compile and execute
    the examples in this recipe. Once this is complete, open a new terminal. We will
    use this terminal to download, compile, and run our examples.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You need to perform the following steps to try this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'From a new terminal, run the following to download the source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'To compile the source code, run the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the source code is compiled, you can execute each example in this recipe
    by running the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we will step through each of these examples and explain
    what each example program does and how it relates to the lessons being taught
    in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we will learn how to manually use a C++ `promise` and `future`
    to provide a function that is executed in parallel with an argument, as well as
    get the function''s return value. To start, let''s demonstrate how this is done
    in its most simplistic form, with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding example results in the following when executed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5313a9ee-d6f1-449f-90df-069c182a2a80.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see in the preceding code, the C++ `promise` is an argument to the
    function that is threaded. The thread returns its value by setting the `promise`
    argument, which, in turn, sets a C++ `future` that the user can get from the `promise` argument
    it provides to the thread. It should be noted that we use `std::move()` to prevent
    the `promise` argument from being copied (which the compiler will prohibit as
    the C++ `promise` is a move-only class). Finally, we use the `get()` function
    to get the result of the thread, the same way you would get the result of a thread
    executed using `std::async`.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the benefits of using `promise` and `future` manually is that you can
    get the result of the thread before it completes, allowing the thread to continue
    to do work. For example, take a look at the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following when executed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/af9f0ada-0fe3-4d17-9c75-52f61975d425.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding example, we created the same thread, but we looped forever
    in the thread, meaning the thread will never return. We then created the thread
    the same way, but outputted the result of the C++ `future` as soon as it was ready,
    which we can determine using the `wait()` function.
  prefs: []
  type: TYPE_NORMAL
