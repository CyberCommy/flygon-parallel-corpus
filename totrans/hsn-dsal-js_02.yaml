- en: Creating Queues for In-Order Executions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A queue is a programming construct that bears a heavy resemblance to real-world
    queues, for example, a queue at the movie theater, ATMs, or the bank. Queues,
    as opposed to stacks, are **first-in first-out **(**FIFO**), so whatever goes
    in first comes out first as well. This is especially helpful when you would like
    to maintain data in the same sequence in which it flows in.
  prefs: []
  type: TYPE_NORMAL
- en: 'A more computer/scientific definition of a queue would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <q>An abstract data collection in which the elements can be added to the back
    called enqueue and removed from the front called dequeue which makes it a FIFO
    data structure.</q>
  prefs: []
  type: TYPE_NORMAL
- en: Of course, having only *enqueue* and *dequeue* operations may be enough for
    the majority of cases to cover a wider spectrum of issues that we may encounter;
    however, we can expand the API and make our queue future-proof.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will discuss the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Types of queue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementation of different types of queue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use cases showing the usefulness of queues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performance of queues as compared to other native data structures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Types of queue
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we begin understanding queues, let''s quickly take a look at the types
    of queues that we may want to use in our applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Simple queue**: In a simple FIFO queue, the order is retained and data leaves
    in the same order in which it comes in'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Priority queue**: A queue in which the elements are given a predefined priority'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Circular queue**: Similar to a simple queue, except that the back of the
    queue is followed by the front of the queue'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Double ended queue** (**Dequeue**): Similar to the simple queue but can add
    or remove elements from either the front or the back of the queue'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing APIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Implementing an API is never as easy as it seems, as discussed earlier. When
    making generic classes, we can never predict what kinds of a situation our queue
    is going to be used in. With that in mind, let''s create a very generic API for
    our queue and expand it in future as we see fit. Some of the most common operations
    that we can add to the queue are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`add()`: Pushes an item to the back of the queue'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`remove()`: Removes an item from the start of the queue'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`peek()`: Shows the last item added to the queue'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`front()`: Returns the item at the front of the queue'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clear()`: Empties the queue'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`size()`: Gets the current size of the queue'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a queue
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Of the four types of the queue that we have discussed earlier, first, we will
    implement a simple queueand then move on to modify it for each type of the subsequent
    queue*.*
  prefs: []
  type: TYPE_NORMAL
- en: A simple queue
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Similar to a stack, we will create a queue using the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define a `constructor()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We will be using `WeakMap()` for in-memory data storage just like we did for
    stacks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the methods described previously in the API:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We have again wrapped the entire class inside an IIFE because we don''t want
    to make ;`Queue` items accessible from the outside:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/602f7738-6cd0-40f4-8fe3-b9ba8a960396.png)'
  prefs: []
  type: TYPE_IMG
- en: Testing the queue
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To test this queue, you can simply instantiate it and add/remove some items
    to/from the queue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can note from the preceding code, all elements are treated the same.
    Irrespective of the data that they contain, elements are always treated in a FIFO
    fashion. Although that is a good approach, sometimes we may need something more:
    the ability to prioritize elements that are coming in and leaving the queue*,*
    as we can note in the next section.'
  prefs: []
  type: TYPE_NORMAL
- en: Priority Queue
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A priority queue is operationally similar the simple queues, that is, they support
    the same API, but there is a small addition to the data that they hold. Along
    with the element (your data), they can also persist a priority, which is just
    a numerical value indicating the priority of your element in the queue.
  prefs: []
  type: TYPE_NORMAL
- en: 'Addition or removal of these elements from the queue is based on priority.
    You can either have a minimum priority queue or a maximum priority queue, to help
    establish whether you are adding elements based on increasing priority or decreasing
    priority. We will take a look at how the `add()` method can substitute the `add()`
    method of the simple queue that we defined earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Since we are accounting for the priority of the elements while they are being
    inserted into the stack, we do not have to concern ourselves with priority while
    we removeelements from the queue, so the `remove()`method is the same for both
    simple and priority queues. Other utility methods, such as `front()`, `clear()`,
    `peek()`, and `size()`, have no correlation with the type of data that is being
    saved in the queue, so they remain unchanged as well.
  prefs: []
  type: TYPE_NORMAL
- en: A smart move while creating a priority queue would be to optimize your code
    and decide whether you would like to determine the priority at the time of addition or
    removal. That way, you are not overcalculating or analyzing your dataset at each
    step.
  prefs: []
  type: TYPE_NORMAL
- en: Testing a priority queue
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s first set up the data for testing the queue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Visually, the preceding steps would generate a queue that looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/8c841da0-1359-4cb8-bf55-731f3ac619a0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'From the preceding figure, we can note how when we add an element with a priority
    **2** it gets placed ahead of all the elements with priority **1**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'And when we add an element with priority 1 (lowest) it gets added to the end
    of the queue:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ff347fa9-6abe-441c-94d7-26e1e3f7571b.png)'
  prefs: []
  type: TYPE_IMG
- en: The last element that we add here happens to be the one with the lowest priority
    as well, which makes it the last element of the queue, thus keeping all the elements
    ordered based on priority.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s remove elements from the queue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'There we have it: the creation of simple and priority queues in JavaScript
    using `WeakMap()`. Let''s now take a look at some of the practical applications
    of these queues.'
  prefs: []
  type: TYPE_NORMAL
- en: Use cases for queues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we start off with use cases, we will need a base starting point in the
    form of a Node.js application. To create one, ensure that you have the latest
    Node.js installed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This should show you your currently installed Node.js version; if it does not,
    then download and install the latest version of Node.js from [https://nodejs.org/en](https://nodejs.org/en/).
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Node.js application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To start off a sample Node.js project, simply create a project folder first
    and then run the following command from that folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'On running this command, Node will prompt you with a series of questions, which
    you can either fill or leave blank:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aa9bf36c-0a1d-443a-9483-d94608efff14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once the blank application is created, all you see is a file called `package.json`*. *You
    can now add the dependencies that are needed to create the Node.js application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The `body-parser` modulehelps with parsing of the POST request body, whereas
    the `express`module helps with the creation of the Node.js server.
  prefs: []
  type: TYPE_NORMAL
- en: Starting the Node.js server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once we have the application shell created, create a file called `index.js`,
    which will be the main file of your application; you can call it anything you
    like, but make sure that you update the `main` property accordingly in your `package.json`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s add some code to the `index.js` file to start an express server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'That''s it! The server is now up-and-running on the `3000` port. To test it,
    just add an empty route to tell you whether your application is up or not:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: You can go to your browser and navigate to `localhost:3000`*, *and that should
    show you the server status as `OK!` or give you an error if your server is down.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a chat endpoint
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have the server up and running, we can create an in-memory chat
    endpoint, which would accept a message from two users and forward it to its intended
    recipient using a queue while retaining the order.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we add the logic, we will need to do some groundwork to set up the application
    in a modular way. First, let''s include the `body-parser`and use it in an express
    middlewareso that we can access the `body` of requests easily. So, the updated
    `index.js` file looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, to add the endpoint for the message, we can create a new file called `messages.js`
    under the `routes` folder to which we can add the basic `post`request:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can inject it in our `index.js` and make it a part of our application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, to test this, we can start our server and post a message to `localhost:3000/message`
    using Postman; then we can see the response posted, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/10ca44ce-3541-493d-a17d-6233240f53c8.png)Figure: Sample post message'
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can go ahead and start adding the logic to send messages between two
    users. We are going to abstract, mock, and simplify the chat part of the application
    and focus more on queue applicationsin such complex applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'The workflow itself is relatively straightforward: user A sends a message to
    user B,which our server tries to forward to user B. If it goes through without
    any issue, then everything is good, and the message is delivered to user B;but
    if it fails, then we invoke our `FailureProtocol()`,which retries to send the
    last failed message per-conversation. For simplicity, we will assume that there
    is only one channel right now, that is, between user A and user B*. *'
  prefs: []
  type: TYPE_NORMAL
- en: The production counterpart of this would be capable of handling multiple channels
    simultaneously by creating a new `FailureProtocol()` handler for a particular
    channel when a message fails on a channel and would have the flexibility of deferring
    the job over to multiple threads.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now mock out the `sendMessage()` and `getUniqueFailureQueue()` methods
    in a file called `messaging-utils.js` which will be our wrapper so that we can
    move them into their own module, as their internal workings are not really important
    to understand queuesin this scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, when we receive a new message, we try to send it to the intended end user:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: If the message is sent successfully, we will need to immediately acknowledge
    that and send a success message—otherwise, we will get a unique `failedMessageQueue`
    between the two users—and then add the message to it, which is then followed by
    triggering the failure protocol.
  prefs: []
  type: TYPE_NORMAL
- en: 'A failure protocol can mean anything to different applications. While some applications
    choose to just show a failed message, applications such as ours will retry to
    send the message until it is sent successfully:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We can use the methods available in our `Queue` to pick the top message and
    then try to send it. If successful in doing so, then remove it; otherwise, retry.
    As you can see, using queues greatly simplifies and abstracts the logic of the
    actual queuing of failed messages and what is even better is that you can upgrade
    and enhance the queue at any time without having to think twice about what other
    components would get affected by that change.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have the API call ready to parse the incoming request, send it
    to the intended recipient and trigger our custom failure protocol. When we combine
    all of this logic together, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Implementing logging using priority queues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Endpoints fail, it's inevitable. Although we can try to resend failed messages,
    we need to realize at some point that there is an issue on our end and stop bombarding
    the server with requests to forward the messages. This is where priority queues
    can come in handy.
  prefs: []
  type: TYPE_NORMAL
- en: We will replace the existing logic to use a priority queue so that we detect
    when to stop trying to resend the message and notify the support team instead.
  prefs: []
  type: TYPE_NORMAL
- en: The biggest change is in the `triggerFailureProtocol()` method where we check
    whether the message has failed more times than the preset `retryThreshold`; if
    it has, then we add the message to the queue with critical priority, which we
    later use to prevent subsequent bombardment of the server until the support team
    resolves the issue. This solution although rather naive is very efficient when
    it comes to preserving server resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, the updated code with the priority queue is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we wrapped the same login in an `if-else`block to be
    able to retry sending the message or create a critical error and stop our retry
    efforts.
  prefs: []
  type: TYPE_NORMAL
- en: So, the next time a new message for that channel comes in, you can verify that
    there already exists a critical error and reject the request directly rather than
    going through the hassle of trying to send the messages and failing, which keeps
    bloating the failure queue.
  prefs: []
  type: TYPE_NORMAL
- en: This is certainly one approach to solving this problem, but a more suitable
    approach, which is outside the scope of this example, is to notify the user of
    any critical errors when the user tries to access the channel rather than doing
    it when the users posts a message to it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the complete code including the priority queue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Comparing performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Earlier, we saw how we can simply swap out a simple queue for a priority queue
    and not worry about the functional change that it might cause; similarly, we can
    swap out priority queues for a higher-performant variant of them: circular dequeues*.*'
  prefs: []
  type: TYPE_NORMAL
- en: Before we start working on a comparison, we will need to discuss circular queues
    and why we need them.
  prefs: []
  type: TYPE_NORMAL
- en: The difference between a circular queue and a simple queue is that the back
    of the queue is followed by the front of the queue. That being said, they are
    not functionally different. They still perform the same operations, and produce
    the same results; you might be wondering where exactly they differ and what's
    the point if the end result is the same.
  prefs: []
  type: TYPE_NORMAL
- en: In JavaScript arrays, memory locations are contiguous. So, when creating a queue
    and performing operations such as `remove()`, we will need to worry about moving
    the remaining elements to point to the updated *front* instead of *null*, thus
    increasing the number of operations; it is a memory hit too, unless your queue
    has an unlimited/dynamic number of slots.
  prefs: []
  type: TYPE_NORMAL
- en: Now, imagine a circular queue—because of its circular nature, this queue has
    a fixed number of memory locations, and when an element is removed or added, you
    get to reuse memory locations and reduce the number of operations that are performed,
    which makes it faster than a regular queue.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we can make a similar judgment over the performance of this queue against
    native arrays in JavaScript, let''s take a look under the hood of Chrome''s JavaScript
    engine V8 and check whether it really matters in our case. The reason why we are
    considering this is because of the frequently overlooked concept of sparse and
    dense arrays in JavaScript, although this is an under-the-hood implementation
    and could keep changing every now and then. Most of the time, JavaScript arrays
    are dense and can easily become sparse if not handled properly. A simple way to
    test this is to create an array, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider example 1:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'When you log it, you see the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, create an array like this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider example 2:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'When you log it, you get the same result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: This is interesting, as it shows the difference between the dense (example 1)
    and sparse (example 2) behavior of JavaScript arrays. When you create these dense
    arrays, the elements of the array are known to be of specific values, and these
    values are known at the time of initialization, which gives JavaScript the option
    of keeping these values in contiguous memory.
  prefs: []
  type: TYPE_NORMAL
- en: The V8 code for the JavaScript array implementation has the following comment,
    which makes for another interesting observation that is in line with what we have
    discussed so far
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: So, arrays internally are treated differently based on the type and size of
    data that is being saved in the array. As a rule of thumb, always create an empty
    array using an array literal and incrementally assign values to elements starting
    from the 0 index while leaving no gaps or holes in the array. This keeps the array
    fast, and it does not go into the dictionary mode unless the sheer size of the
    data demands it.
  prefs: []
  type: TYPE_NORMAL
- en: A double-ended circular queue, also known as circular dequeue, is also similar
    to a simple queue, except that the `add()` and `remove()` can be done from either
    the front or the back of the queue.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is basically the same API as your array, and we can build an example of
    the class that would provide this functionality, but let''s go one better and
    take a look at how we can implement everything we discussed previously using a
    circular queue and make it as performant as possible:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/96b70c36-8796-4a30-9ebb-b82c590024e5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'First, we will make an assumption that this queue has a limited size; it can
    be extended later to be of a dynamic nature, but that''s not a concern right now.
    Until now, `WeakMap()` has been used as the in-memory data store in which we persisted
    the data necessary for the queue, but when it comes to performance it just adds
    another layer of retrieval to our data structure, so we will move over to a standard
    array in this case, as that is what we will be comparing against in our benchmark
    tests anyway. Translating this into some code, we can get our `CircularDequeue`,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Of course, this is only one way of implementing a circular dequeue; you can
    get better performance by adding the properties to the class's constructor itself
    instead of wrapping them inside an IIFE (that is, avoid scope chain lookups )
    and also further simplify the code if you are using TypeScript, which allows private
    class members as discussed with stacks.
  prefs: []
  type: TYPE_NORMAL
- en: Running benchmark tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we run the benchmark, it is important to understand our intention of
    comparing our queue with native arrays. We are not trying to prove that the queue
    is faster than arrays and that's why we should be using them. At the same time,
    we do not want to use something, that is ridiculously slow. The goal of these
    tests is to help us understand where queues lie with respect to native data structures
    and whether we can rely on them to provide a performant custom data structure
    if needed.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's run some benchmark tests to compare a circular dequeue and an array*. *We
    will use `benchmark.js` to set up and run our benchmark tests. The setup is pretty
    straightforward; we will be comparing the circular dequeue API with a regular
    array's native operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start with the testing, let''s first include the benchmark node module in
    our project. To install it, run the following command on your Terminal in the
    project root:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Once it is installed, we are ready to create our test suite. Create a `tests` folder and
    add a file called `benchmark.js` under it. To create a test suite, we will first
    set up the data. As discussed earlier, we will compare our `CircularDequeue` against
    an array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Here, we start off with a small dataset in both the circular dequeue and array.
    This will allow the arrays to be dense and thus allow V8 engine will run in fast
    mode and apply internal optimizations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can go ahead and add tests to our testing suite:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'One thing to note in the previous tests is that we always couple two operations
    together, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'If we do not do a `shift()` method before doing the `push()` method and push
    a number instead, for example, `1` or `2`, then we will quickly run into an `out
    of memory` error, as the number of iterations of the tests internally is too large
    for the arrays to handle; circular queues, on the other hand, will be fine because
    of their circular nature: they would just overwrite the previous values.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, add the test to your `package.json` scripts for an easier access:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'To run the benchmark test suite, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The result will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/4ff62d71-59e1-4930-b5f4-a9cbf6bcebd6.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can note from the preceding screenshot, the push and the unshift for
    the circular queues are much faster than the native push and unshift operations,
    whereas the pop and shift operations are almost 30% slower.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s make the arrays sparse so that we force V8 to run the array methods
    in dictionary mode (this can be a real use case for some and also a possibility
    sometimes when dealing with arrays of mixed data types):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'When we run similar tests but with sparse arrays, the results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/8c009c93-8f99-491a-9b10-9c4123d53985.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see that the performance greatly varies from that of the fast mode for
    the `push()` operation, whereas the other pretty much remains the same. This is
    a great way to understand the consequences of adopting a particular coding practice.
    You will need to understand the requirements of your application and pick the
    right tool for the right job accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, when memory is a priority, we will use the simple queue instead,
    which works with `WeakMap()`, instead of regular array. We can create two new
    tests, which we can run separately to track their individual memory usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'It produces the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/6ac6574f-7e19-48e9-b6f6-3c4319db9981.png)'
  prefs: []
  type: TYPE_IMG
- en: We can note from the preceding screenshot that it logs the result of our test
    run, which is the ops/sec, and also logs the total memory usage of that cycle.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, we can run the benchmark for a `remove` operation on the simple
    queue, which is very similar to what we did with the shift operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/6dc01644-a555-4d2a-92ea-3cdb3c8776c0.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see that the simple queue is obviously slower than the array by a factor
    of `4`, but what is important here is to note that the `heapUsed` for both scenarios.
    This is another factor that lets you decide when and how to pick a particular
    type of data structure.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With that, we conclude this chapter on queues. We learned about simple, priority,
    and circular queues and it's double-ended variant. We also learned when to apply
    them based on use cases and we saw with example, how we can leverage the power
    of benchmarking any algorithm or data structure as needed. In the next chapter,
    we will be putting sets, maps, and hashes under the microscope to understand their
    internal workings and see what situations they can be useful in.
  prefs: []
  type: TYPE_NORMAL
