- en: Chapter 6. C10K – A Non-blocking Web Server in Go
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up to this point, we've built a few usable applications; things we can start
    with and leapfrog into real systems for everyday use. By doing so, we've been
    able to demonstrate the basic and intermediate-level patterns involved in Go's
    concurrent syntax and methodology.
  prefs: []
  type: TYPE_NORMAL
- en: However, it's about time we take on a real-world problem—one that has vexed
    developers (and their managers and VPs) for a great deal of the early history
    of the Web.
  prefs: []
  type: TYPE_NORMAL
- en: In addressing and, hopefully, solving this problem, we'll be able to develop
    a high-performance web server that can handle a very large volume of live, active
    traffic.
  prefs: []
  type: TYPE_NORMAL
- en: For many years, the solution to this problem was solely to throw hardware or
    intrusive caching systems at the problem; so, alternately, solving it with programming
    methodology should excite any programmer.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll be using every technique and language construct we''ve learned so far,
    but we''ll do so in a more structured and deliberate way than we have up to now.
    Everything we''ve explored so far will come into play, including the following
    points:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a visual representation of our concurrent application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Utilizing goroutines to handle requests in a way that will scale
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building robust channels to manage communication between goroutines and the
    loop that will manage them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Profiling and benchmarking tools (JMeter, ab) to examine the way our event loop
    actually works
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Timeouts and concurrency controls—when necessary—to ensure data and request
    consistency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attacking the C10K problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The genesis of the C10K problem is rooted in serial, blocking programming, which
    makes it ideal to demonstrate the strength of concurrent programming, especially
    in Go.
  prefs: []
  type: TYPE_NORMAL
- en: 'The proposed problem came from developer Dan Kegel, who famously asked:'
  prefs: []
  type: TYPE_NORMAL
- en: '|   | *It''s time for web servers to handle ten thousand clients simultaneously,
    don''t you think? After all, the web is a big place now.* |   |'
  prefs: []
  type: TYPE_TB
- en: '|   | --*Dan Kegel ([http://www.kegel.com/c10k.html](http://www.kegel.com/c10k.html))*
    |'
  prefs: []
  type: TYPE_TB
- en: When he asked this in 1999, for many server admins and engineers, serving 10,000
    concurrent visitors was something that would be solved with hardware. The notion
    that a single server on common hardware could handle this type of CPU and network
    bandwidth without falling over seemed foreign to most.
  prefs: []
  type: TYPE_NORMAL
- en: The crux of his proposed solutions relied on producing non-blocking code. Of
    course, in 1999, concurrency patterns and libraries were not widespread. C++ had
    some polling and queuing options available via some third-party libraries and
    the earliest predecessor to multithreaded syntaxes, later available through Boost
    and then C++11.
  prefs: []
  type: TYPE_NORMAL
- en: Over the coming years, solutions to the problem began pouring in across various
    flavors of languages, programming design, and general approaches. At the time
    of publishing this book, the C10K problem is not one without solutions, but it
    is still an excellent platform to conduct a very real-world challenge to high-performance
    Go.
  prefs: []
  type: TYPE_NORMAL
- en: Any performance and scalability problem will ultimately be bound to the underlying
    hardware, so as always, your mileage may vary. Squeezing 10,000 concurrent connections
    on a 486 processor with 500 MB of RAM will certainly be more challenging than
    doing so on a barebones Linux server stacked with memory and multiple cores.
  prefs: []
  type: TYPE_NORMAL
- en: It's also worth noting that a simple echo server would obviously be able to
    assume more cores than a functional web server that returns larger amounts of
    data and accepts greater complexity in requests, sessions, and so on, as we'll
    be dealing with here.
  prefs: []
  type: TYPE_NORMAL
- en: Failing of servers at 10,000 concurrent connections
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you may recall, when we discussed concurrent strategies back in [Chapter
    3](part0032_split_000.html#page "Chapter 3. Developing a Concurrent Strategy"),
    *Developing a Concurrent Strategy*, we talked a bit about Apache and its load-balancing
    tools.
  prefs: []
  type: TYPE_NORMAL
- en: When the Web was born and the Internet commercialized, the level of interactivity
    was pretty minimal. If you're a graybeard, you may recall the transition from
    NNTP/IRC and the like and how extraordinarily rudimentary the Web was.
  prefs: []
  type: TYPE_NORMAL
- en: To address the basic proposition of [page request] → [HTTP response], the requirements
    on a web server in the early 1990s were pretty lenient. Ignoring all of the error
    responses, header readings and settings, and other essential (but unrelated to
    the in → out mechanism) functions, the essence of the early servers was shockingly
    simple, at least compared to the modern web servers.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first web server was developed by the father of the Web, Tim Berners-Lee.
  prefs: []
  type: TYPE_NORMAL
- en: Developed at CERN (such as WWW/HTTP itself), CERN httpd handled many of the
    things you would expect in a web server today—hunting through the code, you'll
    find a lot of notation that will remind you that the very core of the HTTP protocol
    is largely unchanged. Unlike most technologies, HTTP has had an extraordinarily
    long shelf life.
  prefs: []
  type: TYPE_NORMAL
- en: Written in C in 1990, it was unable to utilize a lot of concurrency strategies
    available in languages such as Erlang. Frankly, doing so was probably unnecessary—the
    majority of web traffic was a matter of basic file retrieval and protocol. The
    meat and potatoes of a web server were not dealing with traffic, but rather dealing
    with the rules surrounding the protocol itself.
  prefs: []
  type: TYPE_NORMAL
- en: You can still access the original CERN httpd site and download the source code
    for yourself from [http://www.w3.org/Daemon/](http://www.w3.org/Daemon/). I highly
    recommend that you do so as both a history lesson and a way to look at the way
    the earliest web server addressed some of the earliest problems.
  prefs: []
  type: TYPE_NORMAL
- en: However, the Web in 1990 and the Web when the C10K question was first posed
    were two very different environments.
  prefs: []
  type: TYPE_NORMAL
- en: By 1999, most sites had some level of secondary or tertiary latency provided
    by third-party software, CGI, databases, and so on, all of which further complicated
    the matter. The notion of serving 10,000 flat files concurrently is a challenge
    in itself, but try doing so by running them on top of a Perl script that accesses
    a MySQL database without any caching layer; the challenge is immediately exacerbated.
  prefs: []
  type: TYPE_NORMAL
- en: By the mid 1990s, the Apache web server had taken hold and largely controlled
    the market (by 2009, it had become the first server software to serve more than
    100 million websites).
  prefs: []
  type: TYPE_NORMAL
- en: 'Apache''s approach was rooted heavily in the earliest days of the Internet.
    At its launch, connections were initially handled first in, first out. Soon, each
    connection was assigned a thread from the thread pool. There are two problems
    with the Apache server. They are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Blocking connections can lead to a domino effect, wherein one or more slowly
    resolved connections could avalanche into inaccessibility
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache had hard limits on the number of threads/workers you could utilize, irrespective
    of hardware constraints
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's easy to see the opportunity here, at least in retrospect. A concurrent
    server that utilizes actors (Erlang), agents (Clojure), or goroutines (Go) seems
    to fit the bill perfectly. Concurrency does not *solve* the C10k problem in itself,
    but it absolutely provides a methodology to facilitate it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most notable and visible example of an approach to the C10K problem today
    is Nginx, which was developed using concurrency patterns, widely available in
    C by 2002 to address—and ultimately solve—the C10k problem. Nginx, today, represents
    either the #2 or #3 web server in the world, depending on the source.'
  prefs: []
  type: TYPE_NORMAL
- en: Using concurrency to attack C10K
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are two primary approaches to handle a large volume of concurrent requests.
    The first involves allocating threads per connection. This is what Apache (and
    a few others) do.
  prefs: []
  type: TYPE_NORMAL
- en: On the one hand, allocating a thread to a connection makes a lot of sense—it's
    isolated, controllable via the application's and kernel's context switching, and
    can scale with increased hardware.
  prefs: []
  type: TYPE_NORMAL
- en: One problem for Linux servers—on which the majority of the Web lives—is that
    each allocated thread reserves 8 MB of memory for its stack by default. This can
    (and should) be redefined, but this imposes a largely unattainable amount of memory
    required for a single server. Even if you set the default stack size to 1 MB,
    we're dealing with a minimum of 10 GB of memory just to handle the overhead.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is an extreme example that''s unlikely to be a real issue for a couple
    of reasons: first, because you can dictate the maximum amount of resources available
    to each thread, and second, because you can just as easily load balance across
    a few servers and instances rather than add 10 GB to 80 GB of RAM.'
  prefs: []
  type: TYPE_NORMAL
- en: Even in a threaded server environment, we're fundamentally bound to the issue
    that can lead to performance decreases (to the point of a crash).
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s look at a server with connections bound to threads (as shown
    in the following diagram), and visualize how this can lead to logjams and, eventually,
    crashes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using concurrency to attack C10K](img/00027.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: This is obviously what we want to avoid. Any I/O, network, or external process
    that can impose some slowdown can bring about that avalanche effect we talked
    about, such that our available threads are taken (or backlogged) and incoming
    requests begin to stack up.
  prefs: []
  type: TYPE_NORMAL
- en: We can spawn more threads in this model, but as mentioned earlier, there are
    potential risks there too, and even this will fail to mitigate the underlying
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: Taking another approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In an attempt to create our web server that can handle 10,000 concurrent connections,
    we'll obviously leverage our goroutine/channel mechanism to put an event loop
    in front of our content delivery to keep new channels recycled or created constantly.
  prefs: []
  type: TYPE_NORMAL
- en: For this example, we'll assume we're building a corporate website and infrastructure
    for a rapidly expanding company. To do this, we'll need to be able to serve both
    static and dynamic content.
  prefs: []
  type: TYPE_NORMAL
- en: The reason we want to introduce dynamic content is not just for the purposes
    of demonstration—we want to challenge ourselves to show 10,000 true concurrent
    connections even when a secondary process gets in the way.
  prefs: []
  type: TYPE_NORMAL
- en: As always, we'll attempt to map our concurrency strategy directly to goroutines
    and channels. In a lot of other languages and applications, this is directly analogous
    to an event loop, and we'll approach it as such. Within our loop, we'll manage
    the available goroutines, expire or reuse completed ones, and spawn new ones where
    necessary.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example visualization, we show how an event loop (and corresponding
    goroutines) can allow us to scale our connections without employing too many *hard*
    resources such as CPU threads or RAM:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Taking another approach](img/00028.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The most important step for us here is to manage that event loop. We'll want
    to create an open, infinite loop to manage the creation and expiration of our
    goroutines and respective channels.
  prefs: []
  type: TYPE_NORMAL
- en: As part of this, we will also want to do some internal logging of what's happening,
    both for benchmarking and debugging our application.
  prefs: []
  type: TYPE_NORMAL
- en: Building our C10K web server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our web server will be responsible for taking requests, routing them, and serving
    either flat files or dynamic files with templates parsed against a few different
    data sources.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned earlier, if we exclusively serve flat files and remove much of
    the processing and network latency, we'd have a much easier time with handling
    10,000 concurrent connections.
  prefs: []
  type: TYPE_NORMAL
- en: Our goal is to approach as much of a real-world scenario as we can—very little
    of the Web operates on a single server in a static fashion. Most websites and
    applications utilize databases, **CDNs** (**Content Delivery Networks**), dynamic
    and uncached template parsing, and so on. We need to replicate them whenever possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the sake of simplicity, we''ll separate our content by type and filter
    them through URL routing, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`/static/[request]`: This will serve `request.html` directly'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/template/[request]`: This will serve `request.tpl` after its been parsed
    through Go'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/dynamic/[request][number]`: This will also serve `request.tpl` and parse
    it against a database source''s record'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By doing this, we should get a better mixture of possible HTTP request types
    that could impede the ability to serve large numbers of users simultaneously,
    especially in a blocking web server environment.
  prefs: []
  type: TYPE_NORMAL
- en: We'll utilize the `html/template` package to do parsing—we've briefly looked
    at the syntax before, and going any deeper is not necessarily part of the goals
    of this book. However, you should look into it if you're going to parlay this
    example into something you use in your environment or have any interest in building
    a framework.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can find Go's exceptional library to generate safe data-driven templating
    at [http://golang.org/pkg/html/template/](http://golang.org/pkg/html/template/).
  prefs: []
  type: TYPE_NORMAL
- en: By safe, we're largely referring to the ability to accept data and move it directly
    into templates without worrying about the sort of injection issues that are behind
    a large amount of malware and cross-site scripting.
  prefs: []
  type: TYPE_NORMAL
- en: For the database source, we'll use MySQL here, but feel free to experiment with
    other databases if you're more comfortable with them. Like the `html/template`
    package, we're not going to put a lot of time into outlining MySQL and/or its
    variants.
  prefs: []
  type: TYPE_NORMAL
- en: Benchmarking against a blocking web server
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It's only fair to add some starting benchmarks against a blocking web server
    first so that we can measure the effect of concurrent versus nonconcurrent architecture.
  prefs: []
  type: TYPE_NORMAL
- en: For our starting benchmarks, we'll eschew any framework, and we'll go with our
    old stalwart, Apache.
  prefs: []
  type: TYPE_NORMAL
- en: For the sake of completeness here, we'll be using an Intel i5 3GHz machine with
    8 GB of RAM. While we'll benchmark our final product on Ubuntu, Windows, and OS
    X here, we'll focus on Ubuntu for our example.
  prefs: []
  type: TYPE_NORMAL
- en: Our localhost domain will have three plain HTML files in `/static`, each trimmed
    to 80 KB. As we're not using a framework, we don't need to worry about raw dynamic
    requests, but only about static and dynamic requests in addition to data source
    requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'For all examples, we''ll use a MySQL database (named `master`) with a table
    called `articles` that will contain 10,000 duplicate entries. Our structure is
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: With ID indexes ranging sequentially from 0-10,000, we'll be able to generate
    random number requests, but for now, we just want to see what kind of basic response
    we can get out of Apache serving static pages with this machine.
  prefs: []
  type: TYPE_NORMAL
- en: For this test, we'll use Apache's ab tool and then gnuplot to sequentially map
    the request time as the number of concurrent requests and pages; we'll do this
    for our final product as well, but we'll also go through a few other benchmarking
    tools for it to get some better details.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Apache's AB comes with the Apache web server itself. You can read more about
    it at [http://httpd.apache.org/docs/2.2/programs/ab.html](http://httpd.apache.org/docs/2.2/programs/ab.html).
  prefs: []
  type: TYPE_NORMAL
- en: You can download it for Linux, Windows, OS X, and more from [http://httpd.apache.org/download.cgi](http://httpd.apache.org/download.cgi).
  prefs: []
  type: TYPE_NORMAL
- en: The gnuplot utility is available for the same operating systems at [http://www.gnuplot.info/](http://www.gnuplot.info/).
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let''s see how we did it. Have a look at the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Benchmarking against a blocking web server](img/00029.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Ouch! Not even close. There are things we can do to tune the connections available
    (and respective threads/workers) within Apache, but this is not really our goal.
    Mostly, we want to know what happens with an out-of-the-box Apache server. In
    these benchmarks, we start to drop or refuse connections at around 800 concurrent
    connections.
  prefs: []
  type: TYPE_NORMAL
- en: More troubling is that as these requests start stacking up, we see some that
    exceed 20 seconds or more. When this happens in a blocking server, each request
    behind it is queued; requests behind that are similarly queued and the entire
    thing starts to fall apart.
  prefs: []
  type: TYPE_NORMAL
- en: Even if we cannot hit 10,000 concurrent connections, there's a lot of room for
    improvement. While a single server of any capacity is no longer the way we expect
    a web server environment to be designed, being able to squeeze as much performance
    as possible out of that server, ostensibly with our concurrent, event-driven approach,
    should be our goal.
  prefs: []
  type: TYPE_NORMAL
- en: Handling requests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In an earlier chapter, we handled URL routing with Gorilla, a compact but feature-full
    framework. The Gorilla toolkit certainly makes this easier, but we should also
    know how to intercept the functionality to impose our own custom handler.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a simple web router wherein we handle and direct requests using a custom
    `http.Server` struct, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Here, instead of using a built-in URL routing muxer and dispatcher, we're creating
    a custom server and custom handler type to accept URLs and route requests. This
    allows us to be a little more robust with our URL handling.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, we created a basic, empty struct called `customRouter` and passed
    it to our custom server creation call.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can add more elements to our `customRouter` type, but we really don''t need
    to for this simple example. All we need to do is to be able to access the URLs
    and pass them along to a handler function. We''ll have three: one for static content,
    one for dynamic content, and one for dynamic content from a database.'
  prefs: []
  type: TYPE_NORMAL
- en: Before we go so far though, we should probably see what our absolute barebones
    HTTP server written in Go does when presented with the same traffic that we sent
    Apache's way.
  prefs: []
  type: TYPE_NORMAL
- en: By old school, we mean that the server will simply accept a request and pass
    along a static, flat file. You could do this using a custom router as we did earlier,
    taking requests, opening files, and then serving them, but Go provides a much
    simpler mode to handle this basic task in the `http.FileServer` method.
  prefs: []
  type: TYPE_NORMAL
- en: So, to get some benchmarks for the most basic of Go servers against Apache,
    we'll utilize a simple FileServer and test it against a `test.html` page (which
    contains the same 80 KB file that we had with Apache).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As our goal with this test is to improve our performance in serving flat and
    dynamic pages, the actual specs for the test suite are somewhat immaterial. We'd
    expect that while the metrics will not match from environment to environment,
    we should see a similar trajectory. That said, it's only fair we supply the environment
    used for these tests; in this case, we used a MacBook Air with a 1.4 GHz i5 processor
    and 4 GB of memory.
  prefs: []
  type: TYPE_NORMAL
- en: First, we'll do this with our absolute best performance out of the box with
    Apache, which had 850 concurrent connections and 900 total requests.
  prefs: []
  type: TYPE_NORMAL
- en: '![Handling requests](img/00030.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The results are certainly encouraging as compared to Apache. Neither of our
    test systems were tweaked much (Apache as installed and basic FileServer in Go),
    but Go's FileServer handles 1,000 concurrent connections without so much as a
    blip, with the slowest clocking in at 411 ms.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Apache has made a great number of strides pertaining to concurrency and performance
    options in the last five years, but to get there does require a bit of tuning
    and testing. The intent of this experiment is not intended to denigrate Apache,
    which is well tested and established. Instead, it's to compare the out-of-the-box
    performance of the world's number 1 web server against what we can do with Go.
  prefs: []
  type: TYPE_NORMAL
- en: 'To really get a baseline of what we can achieve in Go, let''s see if Go''s
    FileServer can hit 10,000 connections on a single, modest machine out of the box:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Handling requests](img/00031.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Success! Go's FileServer by itself will easily handle 10,000 concurrent connections,
    serving flat, static content.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, this is not the goal of this particular project—we'll be implementing
    real-world obstacles such as template parsing and database access, but this alone
    should show you the kind of starting point that Go provides for anyone who needs
    a responsive server that can handle a large quantity of basic web traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Routing requests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So, let's take a step back and look again at routing our traffic through a traditional
    web server to include not only our static content, but also the dynamic content.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll want to create three functions that will route traffic from our `customRouter:serveStatic()::
    read` function and serve a flat file `serveRendered():`, parse a template to display
    `serveDynamic():`, connect to MySQL, apply data to a struct, and parse a template.'
  prefs: []
  type: TYPE_NORMAL
- en: To take our requests and reroute, we'll change the `ServeHTTP` method for our
    `customRouter` struct to handle three regular expressions.
  prefs: []
  type: TYPE_NORMAL
- en: For the sake of brevity and clarity, we'll only be returning data on our three
    possible requests. Anything else will be ignored.
  prefs: []
  type: TYPE_NORMAL
- en: In a real-world scenario, we can take this approach to aggressively and proactively
    reject connections for requests we think are invalid. This would include spiders
    and nefarious bots and processes, which offer no real value as nonusers.
  prefs: []
  type: TYPE_NORMAL
- en: Serving pages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First up are our static pages. While we handled this the idiomatic way earlier,
    there exists the ability to rewrite our requests, better handle specific 404 error
    pages, and so on by using the `http.ServeFile` function, as shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Here, we simply relegate all requests starting with `/static/(.*)` to match
    the request in addition to the `.html` extension. In our case, we've named our
    test file (the 80 KB example file) `test.html`, so all requests to it will go
    to `/static/test`.
  prefs: []
  type: TYPE_NORMAL
- en: We've prepended this with `staticPath`, a constant defined upcode. In our case,
    it's `/var/www/`, but you'll want to modify it as necessary.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let''s see what kind of overhead is imposed by introducing some regular
    expressions, as shown in the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Serving pages](img/00032.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How about that? Not only is there no overhead imposed, it appears that the FileServer
    functionality itself is heavier and slower than a distinct `FileServe()` call.
    Why is that? Among other reasons, not explicitly calling the file to open and
    serve imposes an additional OS call, one which can cascade as requests mount up
    at the expense of concurrency and performance.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Sometimes it''s the little things**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Other than strictly serving flat pages here, we''re actually doing one other
    task per request using the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: While this ultimately may have no impact on your final performance, we should
    take care to avoid unnecessary logging or related activities that may impart seemingly
    minimal performance obstacles that become much larger ones at scale.
  prefs: []
  type: TYPE_NORMAL
- en: Parsing our template
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In our next phase, we'll measure the impact of reading and parsing a template.
    To effectively match the previous tests, we'll take our HTML static file and impose
    some variables on it.
  prefs: []
  type: TYPE_NORMAL
- en: If you recall, our goal here is to mimic real-world scenarios as closely as
    possible. A real-world web server will certainly handle a lot of static file serving,
    but today, dynamic calls make up the vast bulk of web traffic.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our data structure will resemble the simplest of data tables without having
    access to an actual database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We'll want to take any data of this form and render a template with it. Remember
    that Go creates the notion of public or private variables through the syntactical
    sugar of capitalized (public) or lowercase (private) values.
  prefs: []
  type: TYPE_NORMAL
- en: If you find that the template fails to render but you're not given explicit
    errors in the console, check your variable naming. A private value that is called
    from an HTML (or text) template will cause rendering to stop at that point.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we''ll take that data and apply it to a template for any calls to a URL
    that begins with the `/(.*)` template. We could certainly do something more useful
    with the wildcard portion of that regular expression, so let''s make it part of
    the title using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Hitting `localhost:9000/template/hello` should render a template with a primary
    body of the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We will do this with the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Parsing our template](img/00033.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: One thing to note about templates is that they are not compiled; they remain
    dynamic. That is to say, if you create a renderable template and start your server,
    the template can be modified and the results are reflected.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is noteworthy as a potential performance factor. Let''s run our benchmarks
    again, with template rendering as the added complexity to our application and
    its architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Parsing our template](img/00034.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Yikes! What happened? We've gone from easily hitting 10,000 concurrent requests
    to barely handling 200.
  prefs: []
  type: TYPE_NORMAL
- en: To be fair, we introduced an intentional stumbling block, one not all that uncommon
    in the design of any given CMS.
  prefs: []
  type: TYPE_NORMAL
- en: You'll notice that we're calling the `template.ParseFiles()` method on every
    request. This is the sort of seemingly cheap call that can really add up when
    you start stacking the requests.
  prefs: []
  type: TYPE_NORMAL
- en: It may then make sense to move the file operations outside of the request handler,
    but we'll need to do more than that—to eliminate overhead and a blocking call,
    we need to set an internal cache for the requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most importantly, all of our template creation and parsing should happen outside
    the actual request handler if you want to keep your server non-blocking, fast,
    and responsive. Here''s another take:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Even though we're using the `Parse()` function prior to our request, we can
    still modify our URL-specific variables using the `Execute()` method, which does
    not carry the same overhead as `Parse()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we move this outside of the `customRouter` struct''s `ServeHTTP()` method,
    we''re back in business. This is the kind of response we''ll get with these changes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Parsing our template](img/00035.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: External dependencies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, we need to bring in our biggest potential bottleneck, which is the
    database. As mentioned earlier, we'll simulate random traffic by generating a
    random integer between 1 and 10,000 to specify the article we want.
  prefs: []
  type: TYPE_NORMAL
- en: Randomization isn't just useful on the frontend—we'll want to work around any
    query caching within MySQL itself to limit nonserver optimizations.
  prefs: []
  type: TYPE_NORMAL
- en: Connecting to MySQL
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can route our way through a custom connection to MySQL using native Go, but
    as is often the case, there are a few third-party packages that make this process
    far less painful. Given that the database here (and associated libraries) is tertiary
    to the primary exercise, we'll not be too concerned about the particulars here.
  prefs: []
  type: TYPE_NORMAL
- en: 'The two mature MySQL driver libraries are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Go-MySQL-Driver** ([https://github.com/go-sql-driver/mysql](https://github.com/go-sql-driver/mysql))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MyMySQL** ([https://github.com/ziutek/mymysql](https://github.com/ziutek/mymysql))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For this example, we''ll go with the Go-MySQL-Driver. We''ll quickly install
    it using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Both of these implement the core SQL database connectivity package in Go, which
    provides a standardized method to connect to a SQL source and iterate over rows.
  prefs: []
  type: TYPE_NORMAL
- en: One caveat is if you've never used the SQL package in Go but have in other languages—typically,
    in other languages, the notion of an `Open()` method implies an open connection.
    In Go, this simply creates the struct and relevant implemented methods for a database.
    This means that simply calling `Open()` on `sql.database` may not give you relevant
    connection errors such as username/password issues and so on.
  prefs: []
  type: TYPE_NORMAL
- en: One advantage of this (or disadvantage depending on your vantage point) is that
    connections to your database may not be left open between requests to your web
    server. The impact of opening and reopening connections is negligible in the grand
    scheme.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we''re utilizing a pseudo-random article request, we''ll build a MySQL piggyback
    function to get an article by ID, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We will then call the function directly from our `ServeHTTP()` method, as shown
    in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'How did we do here? Take a look at the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Connecting to MySQL](img/00036.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Slower, no doubt, but we held up to all 10,000 concurrent requests, entirely
    from uncached MySQL calls.
  prefs: []
  type: TYPE_NORMAL
- en: Given that we couldn't hit 1,000 concurrent requests with a default installation
    of Apache, this is nothing to sneeze at.
  prefs: []
  type: TYPE_NORMAL
- en: Multithreading and leveraging multiple cores
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You may be wondering how performance may vary when invoking additional processor
    cores—as mentioned earlier, this can sometimes have an unexpected effect.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, we should expect only improved performance in our dynamic requests
    and static requests. Any time the cost of context switching in the OS might outweigh
    the performance advantages of additional cores, we can see paradoxical performance
    degradation. In this case, we do not see this effect and instead see a relatively
    similar line, as shown in the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Multithreading and leveraging multiple cores](img/00037.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Exploring our web server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our final web server is capable of serving static, template-rendered, and dynamic
    content well within the confines of the goal of 10,000 concurrent connections
    on even the most modest of hardware.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code—much like the code in this book—can be considered a jumping-off point
    and will need refinement if put into production. This server lacks anything in
    the form of error handling but can ably serve valid requests without any issue.
    Let''s take a look at the following server''s code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Most of our imports here are fairly standard, but note the MySQL line that
    is called solely for its side effects as a database/SQL driver:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The relative `static/` path is where we''ll look for any file requests—as mentioned
    earlier, this does no additional error handling, but the `net/http` package itself
    will deliver 404 errors should a request to a nonexistent file hit it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Our `WebPage` type represents the final output page before template rendering.
    It can be filled with static content or populated by data source, as shown in
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Use these if you choose to extend the web app—this makes the code cleaner and
    removes a lot of the cruft in the `ServeHTTP` section, as shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'All of our routing here is based on regular expression pattern matching. There
    are a lot of ways you can do this, but `regexp` gives us a lot of flexibility.
    The only time you may consider simplifying this is if you have so many potential
    patterns that it could cause a performance hit—and this means thousands. The popular
    web servers, Nginx and Apache, handle a lot of their configurable routing through
    regular expressions, so it''s fairly safe territory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Go is notoriously cranky about unused variables, and while this isn't always
    the best practice, you will end up, at some point, with a function that does nothing
    specific with data but keeps the compiler happy. For production, this is not the
    way you'd want to handle such data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Our `getArticle` function demonstrates how you can interact with the `database/sql`
    package at a very basic level. Here, we open a connection and query a single row
    with the `QueryRow()` function. There also exists the `Query` command, which is
    also usually a `SELECT` command but one that could return more than a single row.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Our main function sets up the server, builds a default `WebPage` and `customRouter`,
    and starts listening on port `9000`.
  prefs: []
  type: TYPE_NORMAL
- en: Timing out and moving on
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One thing we did not focus on in our server is the notion of lingering connection
    mitigation. The reason we didn't worry much about it is because we were able to
    hit 10,000 concurrent connections in all three approaches without too much issue,
    strictly by utilizing Go's powerful built-in concurrency features.
  prefs: []
  type: TYPE_NORMAL
- en: Particularly when working with third-party or external applications and services,
    it's important to know that we can and should be prepared to call it quits on
    a connection (if our application design permits it).
  prefs: []
  type: TYPE_NORMAL
- en: 'Note the custom server implementation and two notes-specific properties: `ReadTimeout`
    and `WriteTimeout`. These allow us to handle this use case precisely.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, this is set to an absurdly high 10 seconds. For a request to
    be received, processed, and sent, up to 20 seconds can transpire. This is an eternity
    in the Web world and has the potential to cripple our application. So, what does
    our C10K look like with 1 second on each end? Let''s take a look at the following
    graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Timing out and moving on](img/00038.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Here, we've saved nearly 5 seconds off the tail end of our highest volume of
    concurrent requests, almost certainly at the expense of complete responses to
    each.
  prefs: []
  type: TYPE_NORMAL
- en: It's up to you to decide how long it's acceptable to keep slow-running connections,
    but it's another tool in the arsenal to keep your server swift and responsive.
  prefs: []
  type: TYPE_NORMAL
- en: There will always be a tradeoff when you decide to kill a connection—too early
    and you'll have a bevy of complaints about a nonresponsive or error-prone server;
    too late and you'll be unable to cope with the connection volume programmatically.
    This is one of those considerations that will require QA and hard data.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The C10K problem may seem like a relic today, but the call to action was symptomatic
    of the type of approaches to systems' applications that were primarily employed
    prior to the rapid expansion of concurrent languages and application design.
  prefs: []
  type: TYPE_NORMAL
- en: Just 15 years ago, this seemed a largely insurmountable problem facing systems
    and server developers worldwide; now, it's handled with only minor tweaking and
    consideration by a server designer.
  prefs: []
  type: TYPE_NORMAL
- en: Go makes it easy to get there (with a little effort), but reaching 10,000 (or
    100,000 or even 1,000,000) concurrent connections is only half the battle. We
    must know what to do when problems arise, how to seek out maximum performance
    and responsiveness out of our servers, and how to structure our external dependencies
    such that they do not create roadblocks.
  prefs: []
  type: TYPE_NORMAL
- en: In our next chapter, we'll look at squeezing even more performance out of our
    concurrent applications by testing some distributed computing patterns and best
    utilizing memory management.
  prefs: []
  type: TYPE_NORMAL
