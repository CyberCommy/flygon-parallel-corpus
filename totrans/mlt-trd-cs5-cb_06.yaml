- en: Chapter 6. Using Concurrent Collections
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will look through the different data structures for concurrent
    programming included in the .NET Framework base class library. You will learn
    about:'
  prefs: []
  type: TYPE_NORMAL
- en: Using a concurrent dictionary
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing asynchronous processing using the concurrent queue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changing asynchronous processing order with the concurrent stack
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a scalable crawler with the concurrent bag
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generalizing asynchronous processing with the blocking collection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Programming requires understanding and knowledge of basic data structures and
    algorithms. To choose the best-suited data structure for a concurrent situation,
    a programmer has to know about many things, such as algorithm time, space complexity,
    and big O notation. In different well-known scenarios, we always know which data
    structures are more efficient.
  prefs: []
  type: TYPE_NORMAL
- en: For concurrent computations, we need to have appropriate data structures. These
    data structures have to be scalable, avoid locks when possible, and at the same
    time provide thread-safe access. The .NET framework, since Version 4, has the
    `System.Collections.Concurrent` namespace with several data structures in it.
    In this chapter, we will cover several data structures and show very simple examples
    of how to use them.
  prefs: []
  type: TYPE_NORMAL
- en: Let us start with `ConcurrentQueue`. This collection uses atomic **Compare and
    Swap** (**CAS**) operations and `SpinWait` to ensure thread safety. It implements
    a **First In First Out** (**FIFO**) collection, which means that the items go
    out of the queue in the same order in which they were added to the queue. To add
    an item to a queue you call the `Enqueue` method. The `TryDequeue` method tries
    to take the first item from the queue, and the `TryPeek` method tries to get the
    first item without removing it from the queue.
  prefs: []
  type: TYPE_NORMAL
- en: '`ConcurrentStack` is also implemented without using any locks with only CAS
    operations. It is a **Last In First Out** (**LIFO**) collection, which means that
    the most recently added item will be returned first. To add items you use the
    `Push` and `PushRange` methods, to retrieve you use `TryPop` and `TryPopRange`,
    and to inspect you use the `TryPeek` method.'
  prefs: []
  type: TYPE_NORMAL
- en: '`ConcurrentBag` is an unordered collection that supports duplicate items. It
    is optimized for a scenario where multiple threads partition their work in such
    a way that each thread produces and consumes its own tasks, dealing with other
    threads'' tasks very rarely (in which case it uses locks). You add items to a
    bag with the `Add` method, inspect with `TryPeek`, and take with the `TryTake`
    method.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Please avoid using the `Count` property on the collections mentioned. They are
    implemented using linked lists, while `Count` is an `O(N)` operation. If you need
    to check whether the collection is empty, use the `IsEmpty` property, which is
    an `O(1)` operation.
  prefs: []
  type: TYPE_NORMAL
- en: '`ConcurrentDictionary` is a thread-safe dictionary collection implementation.
    It is lock free for read operations. However, it requires locking for write operations.
    The concurrent dictionary uses multiple locks, implementing a fine-grained locking
    model over the dictionary buckets. The number of locks could be defined by using
    a constructor with the parameter `concurrencyLevel`, which means that an estimated
    number of threads will update the dictionary concurrently.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Since a concurrent dictionary uses locking, there are a number of operations
    that require acquiring all the locks inside the dictionary. Please avoid using
    these operations without need. They are: `Count`, `IsEmpty`, `Keys`, `Values`,
    `CopyTo`, and `ToArray`.'
  prefs: []
  type: TYPE_NORMAL
- en: '`BlockingCollection` is an advanced wrapper over the `IProducerConsumerCollection`
    generic interface implementation. It has many features that are more advanced
    and is very useful to implement pipeline scenarios when you have some steps that
    use the results from processing the previous steps. The `BlockingCollection` class
    supports such features as blocking, bounding inner collections capacity, cancelling
    collection operations, and retrieving values from multiple blocking collections.'
  prefs: []
  type: TYPE_NORMAL
- en: The concurrent algorithms can be very complicated, and covering all the concurrent
    collections—whether more or less advanced— would require writing a separate book.
    Here we illustrate only the simplest examples of using concurrent collections.
  prefs: []
  type: TYPE_NORMAL
- en: Using ConcurrentDictionary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe shows a very simple scenario, comparing the performance of a usual
    dictionary collection with the concurrent dictionary in a single-threaded environment.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To work through this recipe, you will need Visual Studio 2012\. There are no
    other prerequisites. The source code for this recipe can be found at `BookSamples\Chapter6\Recipe1`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand the difference between performance of a usual dictionary collection
    with the concurrent dictionary, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Start Visual Studio 2012\. Create a new C# **Console Application** project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `Program.cs` file add the following `using` directives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following code snippet below the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following code snippet inside the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Run the program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When the program starts, we create two collections. One of them is a standard
    dictionary collection and the other is a new concurrent dictionary. Then we start
    adding to it, using a standard dictionary with a lock and measuring the time it
    takes for one million iterations to complete. Then we measure the `ConcurrentDictionary`
    performance in the same scenario, and we finally compare the performance of retrieving
    values from both collections.
  prefs: []
  type: TYPE_NORMAL
- en: In this very simple scenario, we find that `ConcurrentDictionary` is significantly
    slower on write operations than a usual dictionary with a lock but is faster on
    retrieval operations. Therefore, if we need many thread-safe reads from a dictionary,
    the `ConcurrendDictionary` collection is the best choice.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you need just read-only, multithreaded access to the dictionary, it may not
    be necessary to perform thread-safe reads. In this scenario, it is much better
    to use just a regular dictionary or the `ReadOnlyDictionary` collections.
  prefs: []
  type: TYPE_NORMAL
- en: '`ConcurrentDictionary` is implemented using the **fine-grained locking** technique,
    and this allows it to scale better on multiple writes than using a regular dictionary
    with a lock (which is called **coarse-grained locking**). As we saw in this example,
    when we use just one thread, a concurrent dictionary is much slower, but when
    we scale this up to five-six threads (if we have enough CPU cores that could run
    them simultaneously), the concurrent dictionary will actually perform better.'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing asynchronous processing using ConcurrentQueue
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe will show an example of creating a set of tasks to be processed
    asynchronously by multiple workers.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To step through this recipe, you will need Visual Studio 2012\. There are no
    other prerequisites. The source code for this recipe can be found in `BookSamples\Chapter6\Recipe2`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand the working of creating a set of tasks to be processed asynchronously
    by multiple workers, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Start Visual Studio 2012\. Create a new C# **Console Application** project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `Program.cs` file add the following `using` directives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following code snippet below the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following code snippet inside the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Run the program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When the program runs, we create a queue of tasks with an instance of the `ConcurrentQueue`
    collection. Then we create a cancellation token, which will be used to stop work
    after we are done posting tasks to the queue. Next, we start a separate worker
    thread that will be posting tasks to the tasks queue. This part produces a workload
    for our asynchronous processing.
  prefs: []
  type: TYPE_NORMAL
- en: Now let us define a task-consuming part of the program. We create four workers
    that will wait a random time, then get a task from the task queue, process it,
    and repeat the whole process until we signal the cancellation token. Finally,
    we start the task-producing thread, wait for its completion, and then signal to
    the consumers that we finished work with the cancellation token. The last step
    will be to wait for all our consumers to complete.
  prefs: []
  type: TYPE_NORMAL
- en: We see that we have tasks processing from start to end, but it is possible that
    a later task will be processed before an earlier one because we have four workers
    running independently and the task processing time is not constant. We see that
    the access to the queue is thread-safe; no work item was taken twice.
  prefs: []
  type: TYPE_NORMAL
- en: Changing asynchronous processing order ConcurrentStack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe is a slight modification of the previous one. We will once again
    create a set of tasks to be processed asynchronously by multiple workers, but
    this time we implement it with `ConcurrentStack` and see the differences.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To step through this recipe, you will need Visual Studio 2012\. There are no
    other prerequisites. The source code for this recipe can be found in `BookSamples\Chapter6\Recipe3`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand the processing of a set of tasks implemented with `ConcurrentStack`,
    perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Start Visual Studio 2012\. Create a new C# **Console Application** project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `Program.cs` file add the following `using` directives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following code snippet below the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following code snippet inside the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Run the program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When the program runs, we now create an instance of the `ConcurrentStack` collection.
    The rest is almost like in the previous recipe, except instead of using the `Push`
    and `TryPop` methods on the concurrent stack, we use `Enqueue` and `TryDequeue`
    on a concurrent queue.
  prefs: []
  type: TYPE_NORMAL
- en: We now see that the task processing order has been changed. The stack is a LIFO
    collection and workers process the later tasks first. In case of a concurrent
    queue, tasks were processed in almost the same order in which they were added.
    This means that by depending on the number of workers, we will surely process
    the task that was created first in a given time frame. In case of a stack, the
    tasks that were created earlier will have lower priority and may be not processed
    until a producer stops putting more tasks to the stack. This behavior is very
    specific and it is much better to use a queue in this scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a scalable crawler with ConcurrentBag
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe shows how to scale workload between a number of independent workers
    that both produce work and process it.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To step through this recipe, you will need Visual Studio 2012\. There are no
    other prerequisites. The source code for this recipe can be found in `BookSamples`
    `\Chapter6\Recipe4`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps demonstrate how to scale workload between a number of independent
    workers that both produce work and process it:'
  prefs: []
  type: TYPE_NORMAL
- en: Start Visual Studio 2012\. Create a new C# **Console Application** project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `Program.cs` file add the following `using` directives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following code snippet below the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following code snippet inside the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Run the program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The program simulates web-page indexing with multiple web crawlers. A web crawler
    is a program that opens a web page by its address, indexes the content, and tries
    to visit all the links that this page contains and index these linked pages as
    well. At the beginning, we define a dictionary containing different web-page URLs.
    This dictionary simulates web pages containing links to other pages. The implementation
    is very naive; it does not care about indexing already visited pages, but it is
    simple and allows us to focus on the concurrent workload.
  prefs: []
  type: TYPE_NORMAL
- en: Then we create a concurrent bag, containing crawling tasks. We create four crawlers
    and provide a different site root URL to each of them. Then we wait for all crawlers
    to compete. Now, each crawler starts to index the site URL it was given. We simulate
    the network I/O process by waiting for some random amount of time; then if the
    page contains more URLs, the crawler posts more crawling tasks to the bag. Then,
    it checks whether there are any tasks left to crawl in the bag. If not, the crawler
    completes.
  prefs: []
  type: TYPE_NORMAL
- en: If we check the output in the first lines below the first four, which were root
    URLs, we will see that usually a task posted by crawler number *N* is processed
    by the same crawler. However, the later lines will be different. This happens
    because internally `ConcurrentBag` is optimized for exactly this scenario where
    there are multiple threads that both add items and remove them. This is achieved
    by letting each thread work with its own local queue of items, and thus, we do
    not need any locks while this queue is occupied. Only when we have no items left
    in the local queue will we perform some locking and try to "steal" the work from
    another thread's local queue. This behavior helps to distribute the work between
    all workers and avoid locking.
  prefs: []
  type: TYPE_NORMAL
- en: Generalizing asynchronous processing with BlockingCollection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe will describe how to use `BlockingCollection` to simplify implementation
    of workload asynchronous processing.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To step through this recipe, you will need Visual Studio 2012\. No other prerequisites
    are required. The source code for this recipe can be found in `BookSamples\Chapter6\Recipe5`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand how `BlockingCollection` simplifies the implementation of workload
    asynchronous processing, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Start Visual Studio 2012\. Create a new C# **Console Application** project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `Program.cs` file add the following `using` directives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following code snippet below the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following code snippet inside the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Run the program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here we take exactly the first scenario, but now we use a `BlockingCollection`
    class that provides many useful benefits. First of all, we are able to change
    the way the tasks are stored inside the blocking collection. By default, it uses
    a `ConcurrentQueue` container, but we are able to use any collection that implements
    the `IProducerConsumerCollection` generic interface. To illustrate this, we run
    the program twice, using `ConcurrentStack` as the underlying collection the second
    time.
  prefs: []
  type: TYPE_NORMAL
- en: Workers get work items by iterating over the `GetConsumingEnumerable` method
    call result on a blocking collection. If there are no items inside the collection,
    the iterator will just block the worker thread until an item is posted to the
    collection. The cycle ends when the producer calls the `CompleteAdding` method
    on the collection. It signals that the work is done.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is very easy to make a mistake and just iterate over `BlockingCollection`
    as it implements `IEnumerable` itself. Do not forget to use `GetConsumingEnumerable`,
    or else you will just iterate over a "snapshot" of a collection and get completely
    unexpected program behavior.
  prefs: []
  type: TYPE_NORMAL
- en: The workload producer inserts the tasks into `BlockingCollection` and then calls
    the `CompleteAdding` method, which causes all the workers to complete. Now in
    the program output we see two result sequences illustrating the difference between
    the concurrent queue and stack collections.
  prefs: []
  type: TYPE_NORMAL
