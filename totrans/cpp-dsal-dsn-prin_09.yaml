- en: 9\. Dynamic Programming II
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Learning Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will be able to:'
  prefs: []
  type: TYPE_NORMAL
- en: Describe how problems can be solved in polynomial versus non-deterministic polynomial
    time and the effect this has on our ability to develop efficient algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement solutions for both the 0-1 and unbounded variants of the knapsack
    problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apply the concept of state space reduction to dynamic programming problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determine every shortest path in a weighted graph using approaches that have
    been optimized by the dynamic programming paradigm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will build upon our understanding of the dynamic programming
    approach and examine how it can be used to optimize the problems we discussed
    in the previous chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: From the previous chapter, you should have a basic understanding of dynamic
    programming, as well as an effective set of strategies for finding a dynamic programming
    (DP) solution for an unfamiliar problem. In this chapter, we will develop this
    understanding further by exploring relationships between problems, particularly
    in terms of how the basic DP logic for one problem can be modified to find the
    approach to another. We will also discuss the concept of state space reduction,
    which allows us to exploit certain aspects of a problem to further optimize a
    working DP solution by decreasing the number of dimensions and/or operations required
    to find the result. We will conclude this chapter by revisiting the topic of graphs
    to demonstrate how the DP approach can be applied to the shortest-path problem.
  prefs: []
  type: TYPE_NORMAL
- en: An Overview of P versus NP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In *Chapter 8*, *Dynamic Programming I,* we demonstrated the significant gains
    in efficiency that dynamic programming can offer over other approaches, but it
    may not yet be clear how dramatic the difference can be. It is important to appreciate
    the extent to which the complexity of certain problems will scale as the input
    bounds increase because then we can understand the situations in which DP is not
    just preferable, but necessary.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Given the terms and operators of a Boolean formula, determine whether or
    not it evaluates to TRUE."*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This problem is conceptually very simple to solve. All that is required to
    get the correct result is a linear evaluation of the given formula. However, imagine
    that, instead, the problem was stated this way:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Given the variables and operators of a Boolean formula, determine whether
    there exists an assignment of TRUE/FALSE to each variable so that the formula
    will evaluate to TRUE."*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Note:'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If you are unfamiliar with logic symbols, `¬` denotes `NOT`, hence `(1 ¬ 1)
    = FALSE`, and `(1 ¬ 0) = TRUE`. Also, `∧` denotes `AND`, while `∨` denotes `OR`.
  prefs: []
  type: TYPE_NORMAL
- en: The basic underlying concept remains the same, but the difference between these
    two problems is immense. In the original problem, the complexity of finding the
    result was dependent only on one factor—the length of the formula—but stated this
    way, there seems to be no obvious approach to solving it that does not require
    searching every possible binary subset of variable assignments until a solution
    is found.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s consider another problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Given a graph where every vertex is assigned one of three possible colors,
    determine whether no two adjacent vertices are the same color."*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Like our first example, this is quite simple to implement—traverse every vertex
    of the graph, compare its color to each of its neighbors, and return false only
    if a matching pair of adjacent colors is found. But now, imagine that the problem
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Given a graph where every vertex is assigned one of three possible colors,
    determine whether it is possible to color its vertices so that no two neighbors
    share the same color."*'
  prefs: []
  type: TYPE_NORMAL
- en: Again, this is a very different scenario.
  prefs: []
  type: TYPE_NORMAL
- en: The first versions of these problems are commonly classified as **P**, which
    simply means that there's a way to solve them in **polynomial time**. When we
    describe a problem as having a time complexity of *O(n)*, *O(n**2**)*, *O(log
    n)*, and so on, we are describing a problem within the *P* class. However, the
    restated forms—at least as far as anyone has currently been able to prove—have
    no existing methods for finding a solution that are not essentially exponential
    in their worst-case complexity. Therefore, we classify their complexity as **NP**,
    or **non-deterministic polynomial time**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The relationship between these classes of problems is a subject of considerable
    debate. The particular matter of interest is that the complexity of computation
    that''s required to *verify* their solutions is "easy," whereas the complexity
    of *producing* solutions is "hard". This demonstrates one of the most widely discussed
    unsolved problems in programming: does the fact that the verification of solutions
    is in class *P* imply that there is also an approach for producing solutions in
    polynomial time? In other words, does *P = NP*? While the generally postulated
    answer to this question is no (*P ≠ NP*), this has yet to be proven, and doing
    so (regardless of what the answer actually is) would be a truly revolutionary
    advance in the study of algorithms and computation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Arguably the most interesting group of problems in NP are known as **NP-complete**
    because they share a remarkable trait: should a solution be discovered that solves
    any one of these problems efficiently (that is, in polynomial time), that solution
    can, in fact, be modified to solve all of the other problems in *NP* efficiently.
    In other words, if a polynomial solution for the first example (known as the **Boolean
    satisfiability problem**, or **SAT**) was found, some variant of the same logic
    could also be used to solve the second example (known as the **graph-coloring
    problem**), and vice versa.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Keep in mind that not every exponentially complex problem fits into this classification.
    Consider the problem of determining the next best move in a chess game. You may
    describe the recursive logic as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The complexity of finding solutions is unquestionably exponential. However,
    this problem does not meet the criteria of *NP*-completeness because the basic
    act of verifying whether a certain move is the best requires the same degree of
    complexity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Compare this example to the problem of solving a Sudoku puzzle:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1: A solved Sudoku puzzle](img/C14498_09_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.1: A solved Sudoku puzzle'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Verification requires scanning each row and column of the matrix and determining
    that each of the nine outlined 3 x 3 squares contains every digit from 1 – 9,
    and that no row or column contains the same number more than once. A straightforward
    implementation of this could use three collections of nine sets, each containing
    `{ 1, 2, 3, 4, 5, 6, 7, 8, 9 }`, the first of these collections representing the
    numbers in each row, the second representing the numbers in each column, and the
    third representing the numbers in each 3 x 3 square. As each cell is scanned,
    we would check that the number it contains is in each set that corresponds to
    that cell; if it is, it is removed from the set. Otherwise, the result is *FALSE*.
    Once every cell has been considered, the result equals *TRUE* if every set is
    empty. Since this approach only requires us to iterate through the matrix once,
    we can conclude that it can be solved in polynomial time. However, assuming the
    puzzle that's provided is incomplete and the task is to determine whether a solution
    exists, we would have to recursively consider each combination of digits for each
    cell until a valid solution is found, leading to a worst-case complexity of *O(9**n**)*,
    with *n* equal to the number of empty squares in the original grid; thus, we can
    conclude that solving a Sudoku puzzle is in *NP*.
  prefs: []
  type: TYPE_NORMAL
- en: Reconsidering the Subset Sum Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous chapter, we discussed the subset sum problem, which we saw possessed
    exponential complexity in the worst cases. Let's consider the two ways this problem
    can be expressed – in terms of the relative difficulty of finding a solution and
    verifying the validity of a solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider the problem of verifying the validity of a solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: There's no question that the complexity of verification is linear regarding
    the length of each subset—add up all the numbers and compare the sum to the target—which
    puts it squarely in the P class. We found some seemingly efficient methods for
    handling the complexity of finding solutions that we may assume to have a polynomial-time
    complexity of *O(N × M)*, where *N* is the size of the set and *M* is the target
    sum. This would appear to disqualify this problem as being *NP*-complete. However,
    this is actually not the case because *M* is not the size of the input, but rather
    its magnitude. Remember that computers represent integers in binary, and integers
    requiring a greater number of bits to represent them will also require a greater
    amount of time to process. Thus, every time the maximum value of M is doubled,
    it will essentially require twice the amount of time to compute.
  prefs: []
  type: TYPE_NORMAL
- en: So, unfortunately, our DP solution does not qualify as having polynomial complexity.
    We, therefore, define our approach to this problem as running in `pseudo-polynomial
    time`, and we can conclude that the subset sum problem is in fact *NP*-complete.
  prefs: []
  type: TYPE_NORMAL
- en: The Knapsack Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let''s reconsider the knapsack problem we looked at in *Chapter 5*, *Greedy
    Algorithms*, which we could describe as the subset sum problem''s "big brother."
    It asks the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Given a knapsack of limited capacity and a collection of weighted items of
    different values, what set of items can be contained within the knapsack that
    produces the greatest combined value without exceeding the capacity?"*'
  prefs: []
  type: TYPE_NORMAL
- en: This problem is also a characteristic example of *NP*-completeness, and as such,
    it shares many close ties to the other problems in this class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'With this data, we can produce the following subsets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.2: All possible subsets for the given 0-1 knapsack problem](img/C14498_09_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.2: All possible subsets for the given 0-1 knapsack problem'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This definitely appears to be familiar territory. Could this require little
    more than a slight modification to the subset sum algorithm?
  prefs: []
  type: TYPE_NORMAL
- en: 0-1 Knapsack – Extending the Subset Sum Algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You may recall from our discussions in *Chapter 6*, *Graph Algorithms I*, that
    the previous example is that of the 0-1 knapsack problem. Here, we noticed another
    clear parallel between the current algorithm and the state logic we used to solve
    the subset sum problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the subset sum problem, we concluded that for every element, `x`, at index
    `i` in `set`, we can do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Add the value of `x` to a previously found subset sum.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Leave the subset sum as is.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This implies that a DP table entry for a new sum, `y`, at index `i + 1` can
    be marked `TRUE` if it is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: An existing sum, `x`, in the previous row of the table, that is, `DP(i, x)`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The combined sum of `x` with the current element at `set[i]`, that is, `DP(i,
    x + set[i])`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In other words, whether or not a sum could be formed with a subset spanning
    the first `i` elements in the set was dependent on whether it had already been
    found earlier, or whether it could be found by adding the value of the current
    element to another previously found sum.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the current problem, we can observe that for every item, `x`, at index `i`
    in `set` with weight `w`, we can do either of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Add the value of `x` to a previously found subset sum of the item values, as
    long as the combined total of the corresponding items' weights with `w` is less
    than or equal to the maximum capacity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Leave the subset sum as is.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This, in turn, implies that the maximum value sum, `y`, that can be found at
    index `i + 1` of the set of items with a combined weight `W` can be either of
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: An existing maximum value sum, `x`, that had been found within the previous
    `i` items and had a combined weight of `w`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The combined sum of `x` with the value of the item at index `i`, assuming the
    weight of the item does not exceed capacity when added to `w`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Stated differently, the maximum value sum that can be formed with a subset of
    items spanning the first `i` items and having a combined weight of `w` is either
    equal to the maximum sum corresponding to weight `w` for the previous `i – 1`
    items or the sum produced by adding the current item's value to the total value
    of a previously found subset.
  prefs: []
  type: TYPE_NORMAL
- en: 'In pseudocode, we expressed the table-filling scheme for the subset sum problem
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The equivalent logic for the 0-1 knapsack problem would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see that the general algorithmic concepts are practically identical:
    we are traversing a two-dimensional search space bounded by the size of the set
    and the maximum sum of the set''s elements and determining whether new subset
    sums can be found. The difference is that we are not merely recording whether
    or not a certain subset sum exists, but rather, we are collecting the maximum
    corresponding value sums associated with each subset of items and organizing them
    according to their total combined weights. We''ll take a look at its implementation
    in the following exercise.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 41: 0-1 Knapsack Problem'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will now implement the preceding logic using the tabulated bottom-up approach.
    Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will begin by including the following headers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Our first step will be to handle the input. We will need to declare two integers,
    `items` and `capacity`, which represent the total number of items to choose from
    and the weight limit of the knapsack. We will also need two arrays, `value` and
    `weight`, where we will store the data corresponding to each item:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will define the function `Knapsack_01()`, which has parameters corresponding
    to the input and returns an integer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Our DP table will be two-dimensional and will correspond quite closely to the
    table we used in the subset sum problem. In the subset sum table, the first dimension''s
    size was initialized to one greater than the length of the set, while the second
    dimension''s size was initialized to one greater than the maximum sum of all the
    elements in the set. Here, our first dimension''s size will equivalently be initialized
    to `items + 1`; likewise, the second dimension''s size will be initialized to
    `capacity + 1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We will need to iterate across the length of both dimensions starting from
    `1`. At the beginning of each iteration of the outer loop, we will define two
    variables, `currentWeight` and `currentValue`, that correspond to the elements
    in `weight[i-1]` and `values[i-1]`, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will implement our tabulation scheme:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'At the end of our function, we return the final element of the table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we add a call to `main()` and print the output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s try running our program using the following input:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, a relatively efficient DP solution to the knapsack problem is
    little more than a slight modification of the same algorithm we used to solve
    the subset sum problem.
  prefs: []
  type: TYPE_NORMAL
- en: Unbounded Knapsack
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The implementation we explored regarding the knapsack problem is the most traditional
    version, but as we mentioned earlier in this chapter, there are actually many
    varieties of this problem that can apply to different scenarios. We will now consider
    the case where we have unlimited amounts of each item in the set.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider an example where we find the solution by brute force:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: From a brute-force perspective, this problem seems to be significantly more
    complex. Let's restate our pseudocode logic from the 0-1 knapsack implementation
    to handle this extra stipulation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The maximum value sum, `y`, that can be found at index `i` of the set of items
    with a combined weight `total_weight` can be either of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: An existing maximum value sum, `x`, that had been found within the previous
    `i - 1` items and also had a combined weight equal to `total_weight`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Assuming `total_weight` can be formed by adding `current_weight` to some other
    subset''s total weight found within the previous `i – 1` items:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) The sum of the current item's value with the maximum value sum for subsets
    spanning the previous `i - 1` items and having a combined weight of `total_weight
    – current_weight`
  prefs: []
  type: TYPE_NORMAL
- en: b) The sum of the current item's value with some previous `y` found in the recent
    iteration having a combined weight of `total_weight – current_weight`
  prefs: []
  type: TYPE_NORMAL
- en: 'In terms of the DP table, we can represent the new logic as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We can implement this like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Logically, this approach will work, but it turns out that this is actually not
    the most efficient implementation. Let's understand its limitations and how to
    overcome them in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: State Space Reduction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One rather tricky aspect of using DP effectively is the concept of **state space
    reduction**, which is the act of reformulating a working DP algorithm to use the
    minimal amount of space required to represent a state. This often comes down to
    exploiting some pattern or symmetry inherent to the nature of the problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate this concept, let''s consider the problem of finding the value
    in the *n**th* row and *m**th* column of **Pascal''s triangle**, which can be
    represented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C14498_09_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.3: Pascal''s triangle'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Pascal''s triangle is built according to the following logic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'In other words, the first value in every row is `1`, and each subsequent column
    value is equal to the sum of the current and previous columns of the previous
    row. As you can see from the following figure, in the second column of the second
    row, we get `2` by adding the elements in the second (`1`) and the first column
    (`1`) from the previous row:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4: Getting the next values in Pascal’s triangle](img/C14498_09_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.4: Getting the next values in Pascal''s triangle'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Solving the problem of finding the value in the *n**th* row and *m**th* column
    using tabulation could be done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The DP table that was built in the preceding code would look like this for
    `N = 7`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.5: Pascal’s triangle represented as an N × N DP table](img/C14498_09_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.5: Pascal''s triangle represented as an N × N DP table'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'As we can see, this algorithm is quite wasteful both in terms of memory usage
    and redundant calculations. The immediately apparent problem is the fact that
    the table has *N + 1* columns, despite the fact that only one row ever contains
    that many values. We could easily reduce space complexity by initializing each
    row as needed, sized according to the number of elements it requires, which reduces
    the space required by the table from *N**2* to *N × (N + 1) / 2*. Let''s modify
    our implementation as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We may further observe that there is a symmetrical relationship between the
    first and second half of each row, which means that we really only need to calculate
    the values for the first (n/2) columns. Therefore, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'We could state this in a generalized way like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Considering this, we could modify our implementation as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, assuming we were able to receive input queries in advance and precompute
    the results, we could abandon storing the full table entirely since only the previous
    row is needed to produce results for the current row. Hence, we could further
    modify our implementation as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s get back to the unbounded knapsack problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The DP table that was constructed by our proposed solution in the previous
    section would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.6: Two-dimensional DP table constructed by the proposed algorithm](img/C14498_09_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.6: Two-dimensional DP table constructed by the proposed algorithm'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The logic that we used to produce the preceding table was based on the approach
    we used to solve the 0-1 form of the knapsack problem, and thus, we assumed that
    the maximum value sum for a given `weight` and `i` types of items, that is, `DP(i,
    weight)`, could be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The maximum value sum for the same weight and `i - 1` types of items, without
    including the current item, that is, `DP(i - 1, weight)`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The sum of the current item's `value` with the maximum sum for `i - 1` types
    of items, that is, `DP(i - 1, weight - w) + value`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The sum of the current item's `value` with the maximum sum for `i` types of
    items if the item is to be included more than once, that is, `DP(i, weight - w)
    + value`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The first two conditions correspond to the logic of the 0-1 knapsack problem.
    However, considering them within the context of the unbounded knapsack and checking
    them against the table that was produced by our algorithm, we can actually conclude
    that the first two conditions are essentially irrelevant.
  prefs: []
  type: TYPE_NORMAL
- en: In the original problem, we were concerned about the values for `i - 1` items
    because we needed to decide whether to include or exclude item `i`, but in this
    problem, we have no reason to exclude any of the items as long as their weight
    doesn't exceed the knapsack's capacity. In other words, the conditions dictating
    each state transition are bounded only by the `weight` and are therefore representable
    in one dimension!
  prefs: []
  type: TYPE_NORMAL
- en: 'This leads to an important distinction that must be made: the dimensions required
    to *simulate* a state are not necessarily the same as the dimensions required
    to *describe* a state. Until now, every DP problem we have examined, when cached,
    results in a form that was essentially equivalent to the state itself. However,
    in the unbounded knapsack problem, we can describe each state as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"For each item of weight w and value v, the maximum value of a knapsack of
    capacity C is equal to v plus the maximum value of a knapsack of capacity C –
    w."*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following input data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following table, each row represents a weight, `w`, from `0` to the
    maximum capacity, and each column represents the index, `i`, of an item. The number
    in every cell represents the maximum value sum for each weight after the item
    at index `i` has been considered:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.7: Subproblem results for each weight-index pair ](img/C14498_09_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.7: Subproblem results for each weight-index pair'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As demonstrated in the preceding table, the allowance of duplicates means that
    no item needs to be excluded as long as its inclusion fits within the maximum
    capacity. Therefore, whether or not the weight sum could be found at index *0*
    or index *1,000* of the collection is irrelevant because we are never going to
    leave a previously found subset sum as is unless adding to it exceeds the defined
    bounds of the knapsack. This means that there is no advantage to maintaining a
    record of the item's index, which allows us to cache our subproblems in a single
    dimension – the combined weight of any number of items encountered. We'll look
    at its implementation in the following exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 42: Unbounded Knapsack'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we shall apply the concept of state space reduction to the
    unbounded knapsack problem by representing our DP table in one dimension. Let''s
    get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use the same headers and input that we used in the previous exercise:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will implement a function called `UnboundedKnapsack()` that returns
    an integer. Its parameters will be identical to the input:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Our DP table will be represented as an integer vector with size equal to `capacity
    + 1`, with each index initialized to `0`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Like the 0-1 knapsack problem, our state logic will be contained in two nested
    loops; however, in this variation of the problem, we will invert the nesting of
    the loops so that the outer loop iterates from `0` to `capacity` (inclusive),
    and the inner loop iterates through the item indices:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we must decide on how to cache our states. Our only concern is that the
    capacity is not exceeded by the weights of the chosen items. Since our table is
    only large enough to represent weight values from `0` to `capacity`, we only need
    to make sure that the difference between `w` and `weight[i]` is non-negative.
    Thus, all of the assignment logic can be contained within a single `if` statement:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s return to `main()`, add a call to `UnboundedKnapsack()`, and output
    the results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Try running your program with the following input:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Your output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: As demonstrated by the preceding implementation, it is often worth it to consider
    less costly ways to cache solutions in a DP algorithm. Problems that seem to require
    complex state representations can often be simplified significantly after closer
    examination.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 22: Maximizing Profit'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You are working for a large chain of department stores. Like any retail business,
    your company purchases items from wholesale distributors in large quantities and
    then sells them at a higher price to gain profit. Certain types of products that
    are being sold in your store can be purchased from multiple different distributors,
    but the quality and price of the products can vary considerably, which naturally
    has an effect on its corresponding retail value. Once factors such as exchange
    rates and public demand are taken into account, products from certain distributors
    can often be bought at a much lower price per unit than what they can ultimately
    be sold for. You have been tasked with designing a system that calculates the
    maximum profit you can gain with an allotted budget.
  prefs: []
  type: TYPE_NORMAL
- en: 'You have been provided with a catalog of similar products. Each listed product
    has the following information:'
  prefs: []
  type: TYPE_NORMAL
- en: The wholesale price of the product
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The amount of profit that can be made by selling the same product after markup
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The quantity of the product sold per unit by the distributor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given that the distributor will only sell the product in the exact quantity
    specified, your task is to determine the maximum amount of money that can be made
    by purchasing some subset of the listed products. To ensure that the store offers
    a variety of choices, each item that's listed can only be purchased once.
  prefs: []
  type: TYPE_NORMAL
- en: Since you only have a limited amount of warehouse space and don't want to overstock
    a particular type of item, you are also given a restriction on the maximum number
    of individual units that can be purchased. Therefore, your program should also
    ensure that the combined number of products that are bought does not exceed this
    limit.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Say five items are listed in the catalog with the following information:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C14498_09_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.8: Sample values for profit optimization'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'You have a budget of $100 and a warehouse capacity of 20 units. The following
    sets of purchases would be valid:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Thus, the program should output `160`.
  prefs: []
  type: TYPE_NORMAL
- en: '**Input**'
  prefs: []
  type: TYPE_NORMAL
- en: The first line contains three integers, `N` as the number of distributors, `budget`
    as the maximum amount of money that can be spent, and `capacity` as the maximum
    number of units that can be purchased.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next `N` lines should contain three space-separated integers:'
  prefs: []
  type: TYPE_NORMAL
- en: '`quantity`: The quantity per unit offered by the distributor'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cost`: The price of the item'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`value`: The amount of profit that can be gained after selling the product'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output**'
  prefs: []
  type: TYPE_NORMAL
- en: A single integer representing the maximum amount of profit that can be made
    by choosing some subset of items from the catalog.
  prefs: []
  type: TYPE_NORMAL
- en: '**Test cases**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following set of test cases should help you understand this problem better:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.9: Activity 22 test case 1'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14498_09_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.9: Activity 22 test case 1'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Figure 9.10: Activity 22 test case 2'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14498_09_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.10: Activity 22 test case 2'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Figure 9.11: Activity 22 test case 3'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14498_09_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.11: Activity 22 test case 3'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Figure 9.12: Activity 22 test case 4'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14498_09_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.12: Activity 22 test case 4'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Activity Guidelines**'
  prefs: []
  type: TYPE_NORMAL
- en: The implementation that's required is very similar to the 0-1 knapsack problem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since there are two constraints (capacity and budget), the DP table will require
    three dimensions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution to this activity can be found on page 581.
  prefs: []
  type: TYPE_NORMAL
- en: Graphs and Dynamic Programming
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we have discussed advanced graph algorithms and DP as distinctly
    different topics, but as is often the case, they can be used concurrently depending
    on the type of problem we are trying to solve and the nature of the graph. Several
    problems commonly associated with graphs are identified as *NP*-complete (graph
    coloring and the vertex cover problem, to name two examples) and can, under the
    right circumstances, be solved with dynamic programming. However, most of these
    topics are outside the scope of this book (and are actually worthy of having entire
    books dedicated specifically to their analysis).
  prefs: []
  type: TYPE_NORMAL
- en: 'However, one problem in graph theory is particularly well suited to the DP
    approach, and fortunately, it is one we are already very familiar with: the shortest-path
    problem. In fact, in *Chapter 7*, *Graph Algorithms II*, we actually discussed
    an algorithm that''s commonly categorized under the DP umbrella, despite the fact
    that we never identified it as such.'
  prefs: []
  type: TYPE_NORMAL
- en: Reconsidering the Bellman-Ford Algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In our exploration of the Bellman-Ford algorithm, we were viewing it in light
    of our previous discussions of Dijkstra's algorithm, with which it certainly shares
    some similarities. But now that we have a solid grasp of the concepts underlying
    the dynamic programming paradigm, let's reconsider Bellman-Ford according to our
    new understanding.
  prefs: []
  type: TYPE_NORMAL
- en: 'In brief, the approach that''s used by Bellman-Ford can be described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Given a source node called `start`, the number of vertices, `V`, and the edges,
    `E`, of a graph, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Mark distances of each node from `0` to `V – 1` (inclusive) as `UNKNOWN`, except
    for `start`, which is `0`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Iterate from `1` to `V – 1` (inclusive).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On each iteration, consider every edge in `E` and check to see whether the source
    node's respective distance value is `UNKNOWN`. If not, then compare the neighboring
    node's currently stored distance to the sum of the source node's distance with
    the edge weight between them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the sum of the source node's distance with the edge weight is less than the
    destination node's distance, update the destination node's distance to the lesser
    value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After `V – 1` iterations, either the shortest path has been found or the graph
    has a negative weight cycle, which can be determined with an additional iteration
    through the edges.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The success of this algorithm is clearly dependent on the fact that the problem
    exhibits an optimal substructure. We can illustrate the recursive logic behind
    this concept as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.13: Visualizing the Bellman-Ford algorithm](img/C14498_09_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.13: Visualizing the Bellman-Ford algorithm'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Expressing this as pseudocode would look something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Clearly, the shortest-path problem also possesses the overlapping subproblems
    property. Bellman-Ford effectively avoids recomputation due to two key observations:'
  prefs: []
  type: TYPE_NORMAL
- en: The maximum number of moves that can be made in a non-cyclic traversal between
    any two nodes in a graph is `| V – 1 |` (that is, every node in the graph minus
    the starting node).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The shortest path between a source node and every reachable node after N iterations
    is equivalent to the shortest paths to every node that's reachable after `| N
    – 1 |` iterations, plus the edge weights to each of their neighbors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following set of figures should help you better visualize the steps in
    the Bellman-Ford algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.14: Bellman-Ford Step 1](img/C14498_09_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.14: Bellman-Ford Step 1'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Figure 9.15: Bellman-Ford Step 2](img/C14498_09_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.15: Bellman-Ford Step 2'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Figure 9.16: Bellman-Ford Step 3](img/C14498_09_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.16: Bellman-Ford Step 3'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The specific problem that Bellman-Ford is said to solve is known as the **single-source
    shortest path problem** because it is used to find the shortest paths for a single
    node. In *Chapter 7*, *Graph Algorithms II*, we discussed Johnson's algorithm,
    which solves what is known as the **all-pairs shortest path problem** because
    it finds the shortest paths between every pair of vertices in the graph.
  prefs: []
  type: TYPE_NORMAL
- en: Johnson's algorithm combined the DP approach seen in the Bellman-Ford algorithm
    with the greedy approach seen in Dijkstra's. In this section, we will explore
    a complete DP implementation of the all-pairs shortest path problem. However,
    let's consider the nature of the problem a bit deeper by implementing a top-down
    solution.
  prefs: []
  type: TYPE_NORMAL
- en: Approaching the Shortest Path Problem as a DP Problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One way to better understand the logic behind Bellman-Ford is to transform it
    into a top-down solution. To do this, let's start by considering our base cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Bellman-Ford performs `V – 1` iterations through the edges of the graph, typically
    by way of a `for` loop. Since our previous implementations have iterated from
    `1` to `V – 1` inclusive, let''s have our top-down solution begin at `V – 1` and
    decrement to `0`. In terms of our recurrence structure, let''s say that every
    state can be described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Therefore, our first base case can be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: In other words, if `depth` has been decremented to `0`, we can conclude that
    no path exists and terminate our search.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second base case we need to handle is, of course, the point where we find
    a path from the source to the target. In this case, the depth of the search is
    irrelevant; the shortest distance from the target to itself will always be `0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s define our intermediate states. Let''s review what the iterative
    approach that''s used by Bellman-Ford looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'In terms of a recursive traversal, this can be restated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Since every state can be uniquely described according to these two dimensions
    and the possible existence of cycles means that we are likely to encounter the
    same states more than once, we can conclude that caching according to node-depth
    pairs is both valid and useful for memoization purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'These states are illustrated in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.17: All the states for the shortest-path problem ](img/C14498_09_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.17: All the states for the shortest-path problem'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We'll look at the implementation of this approach in the following exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 43: Single-Source Shortest Paths (Memoization)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we shall take the top-down DP approach to finding a solution
    to the single-source shortest path problem. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s begin by including the following headers and the `std` namespace, as
    well as defining an `UNKNOWN` constant:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s also declare `V` and `E` (the number of vertices and the number of edges,
    respectively), as well as two two-dimensional integer vectors, `adj` (an adjacency
    list of our graph) and `weight` (a matrix of edge weight values). Finally, we
    will define a memoization table called `memo`. This time, we will use `std::map`
    to simplify the differentiation between checking whether a key exists in the cache
    versus whether its value is unknown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `main()` function, we should handle input so that we receive the graph
    we wish to apply the algorithm to. The first line of input will contain `V` and
    `E`, and the following `E` lines will contain three integers: `u`, `v`, and `w`
    (the source, destination, and weight of each edge, respectively):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now define a function called `SingleSourceShortestPaths()` that will
    take one argument—`source`, which is the index of the source vertex—and will return
    an integer vector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we will need to make some preliminary modifications to our graph. As opposed
    to traversing from the source node to all the other nodes in the graph, we will
    instead begin each traversal from the other nodes and calculate the shortest path
    from the source in reverse. Since our graph is directed, we will have to use its
    transpose to accomplish this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Here, we defined two new two-dimensional integer vectors, `adj_t` and `weight_t`,
    which will correspond to the adjacency list and weight matrix for the transpose
    graph. We then used a nested loop to create our modified graph, as well as initialized
    the values in our `memo` table.
  prefs: []
  type: TYPE_NORMAL
- en: 'We should now define the `ShortestPath_Memoization()` function with four parameters:
    two integers, `depth` and `node`, and `adj` and `weight` (which, in this case,
    will be references to the transpose graph):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Our algorithm will essentially be a standard depth-first search, except we
    will cache the results for each `{ node, depth }` pair at the end of each function
    call. At the top of the function, we will check for a cached result and return
    it if the key exists in the map:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Back in the `SingleSourceShortestPaths()` function, we will define an integer
    vector called `distance` of size `V` and fill it through successive calls to `ShortestPath_Memoization()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Back in `main()`, we will define a two-dimensional integer matrix called `paths`,
    which will store the distances returned from `SingleSourceShortestPaths()` for
    each node index from `0` to `V`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now use the `paths` table to print the distance values for every pair
    of nodes in the graph:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, run your code with the following input:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Unsurprisingly, this is not the preferred way of handling this particular problem,
    but as with the previous exercises, we can learn quite a bit about how the optimal
    substructure is formed by implementing recursive solutions like this one. With
    these insights, we are now equipped to fully understand how the shortest distances
    between every pair of nodes can be found simultaneously using tabulation.
  prefs: []
  type: TYPE_NORMAL
- en: All-Pairs Shortest Path
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our program from the previous exercise does print the shortest paths for every
    vertex pair, but its efficiency is roughly equivalent to performing `V` calls
    to Bellman-Ford, with the added memory-related disadvantages associated with recursive
    algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Thankfully, there is a very useful bottom-up algorithm for this problem that
    is equipped to handle everything that the others can in *O(V**3**)* time and *O(V**2**)*
    space. It is also quite intuitive, particularly after having implemented the other
    shortest path algorithms in this book.
  prefs: []
  type: TYPE_NORMAL
- en: The Floyd-Warshall Algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By now, we should have a fairly clear grasp of how the Bellman-Ford algorithm
    exploits the optimal substructure that's exhibited in the shortest path problem.
    The key takeaway is that any shortest path between two graph vertices is going
    to be a combination of some other shortest path beginning from the source and
    the edge connecting the path's endpoint to the destination vertex.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Floyd-Warshall algorithm** uses this same concept to great effect by
    making an even broader generalization:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"If the shortest distance between Node A and Node B is AB, and the shortest
    distance between Node B and Node C is BC, then the shortest distance between Node
    A and Node C is AB + BC."*'
  prefs: []
  type: TYPE_NORMAL
- en: This logic certainly isn't groundbreaking in and of itself; however, combined
    with the insight demonstrated by Bellman-Ford—that *V* iterations across the edges
    of a graph is sufficient to determine the shortest path from a source node and
    every other node in a graph—we can use this idea to successively generate the
    shortest paths between pairs of nodes with `Node A` as the source, and then use
    those results to generate potential shortest paths for `Node B`, `C`, `D`, and
    so on.
  prefs: []
  type: TYPE_NORMAL
- en: Floyd-Warshall accomplishes this by performing *V**3* iterations across the
    vertices. The first dimension represents a potential midpoint, *B*, between every
    possible pair of vertices *A* and *C*. The algorithm then checks whether the currently
    known distance value from *A* to *C* is greater than the sum of the shortest known
    distances from *A* to *B* and *B* to *C*. If so, it determines that that sum is
    at least closer to the optimal shortest distance value for *A* and *C*, and caches
    it in a table. Floyd-Warshall makes these sets of comparisons using every node
    in the graph as a midpoint, continuously improving the accuracy of its results.
    After every possible start and end point pair has been tested against every possible
    midpoint, the results in the table contain the correct shortest distance values
    for every pair of vertices.
  prefs: []
  type: TYPE_NORMAL
- en: Just like any graph-related algorithm, Floyd-Warshall is not guaranteed to be
    the best choice in every given circumstance, and comparative complexity between
    Floyd-Warshall and other alternatives should always be considered. A good rule
    of thumb is to use Floyd-Warshall for dense graphs (that is, graphs containing
    a large number of edges). Imagine, for example, that you have a graph with 100
    vertices and 500 edges. Running the Bellman-Ford algorithm (with a worst-case
    complexity of *O(V×E)*) on each starting vertex successively could potentially
    lead to a total complexity of 500×100×100 (or 5,000,000) operations, whereas Floyd-Warshall
    would require 100×100×100 (or 1,000,000) operations. Dijkstra's algorithm is usually
    more efficient than Bellman-Ford and may also be a viable alternative. Nevertheless,
    one distinct advantage of Floyd-Warshall is the fact that the overall complexity
    of the algorithm is always exactly *O(V**3**)*, regardless of the other properties
    of the input graph. So, we do not need to know any details about the graph we
    are using other than the number of vertices to be able to determine exactly how
    efficient (or inefficient) Floyd-Warshall will be.
  prefs: []
  type: TYPE_NORMAL
- en: A final point to consider is the fact that, like Bellman-Ford (and unlike Dijkstra's
    algorithm), Floyd-Warshall is equipped to handle graphs with negative edge weights
    but will also be thwarted by negative edge weight cycles without explicit handling.
  prefs: []
  type: TYPE_NORMAL
- en: We'll implement the Floyd-Warshall algorithm in the following exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 44: Implementing the Floyd-Warshall Algorithm'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we shall find the shortest distance between every pair of
    vertices using the Floyd-Warshall algorithm. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will begin by including the following headers and defining an `UNKNOWN`
    constant:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s begin by handling the input almost exactly like we did in the previous
    exercise. This time, however, we have no need for an adjacency list representation
    of the graph:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Our `FloydWarshall()` function will take two arguments—`V` and `weight`—and
    will return a two-dimensional integer vector of shortest-path distances:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s define a two-dimensional DP table with the name `distance` and with
    every value initialized to `UNKNOWN`. Then, we need to assign the initially known
    shortest distance "estimates" for each pair of nodes (that is, the values in the
    `weight` matrix), as well as the base case values (that is, the shortest distance
    from every node to itself, `0`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now perform three nested `for` loops from `0` to `V – 1` (inclusive),
    with the outer loop representing the current intermediate vertex, `mid`, the middle
    loop representing the source vertex, `start`, and the innermost loop representing
    the destination vertex, `end`. We will then compare distance values between every
    combination of vertices and reassign the distance value from start to end whenever
    a shorter path is found:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Similar to Bellman-Ford, we will need to check for negative cycles if our input
    is expected to contain negative edge weights. Thankfully, this can be accomplished
    with great ease using the distance table.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Consider the fact that a graph cycle is a path that has a length greater than
    zero and is where the start and end vertices are the same. In a table representing
    distances between each pair of nodes, the shortest path between a node and itself
    will be contained in `distance[node][node]`. In a graph containing only positive
    edge weights, the value contained in `distance[node][node]` can clearly only ever
    be equal to `0`; however, if the graph contains a negative weight cycle, `distance[node][node]`
    will be negative. Thus, we can test for negative cycles like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have finished writing the algorithm, we can perform a call to `FloydWarshall()`
    in `main()` and output the results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s run our program on the following set of input:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s try another set of input:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, Floyd-Warshall is an incredibly useful algorithm that is not
    only effective but quite easy to implement. In terms of efficiency, whether we
    should choose Floyd-Warshall or Johnson's algorithm depends entirely on the structure
    of the graph. But strictly in terms of ease of implementation, Floyd-Warshall
    is the clear winner.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 23: Residential Roads'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You are the head of a real estate development project that is planning on constructing
    a number of high-end residential communities. You've been given a variety of information
    about the various properties where developments will be built and are currently
    tasked with designing a system of roads as cheaply as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Many of the communities are set to be built in areas replete with lakes, forests,
    and mountains. In these areas, the terrain is often quite rugged, which can make
    construction much more complicated. You have been warned that the cost of building
    increases based on the ruggedness of the terrain. For your first drafts, you are
    told to consider the increase in cost linearly, relative to the ruggedness value
    of each coordinate where a road may be built.
  prefs: []
  type: TYPE_NORMAL
- en: 'You''ve been given the following information:'
  prefs: []
  type: TYPE_NORMAL
- en: Maps of the properties
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The coordinates where properties can be built
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ruggedness of the terrain at each coordinate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You have also been given the following guidelines for determining how roads
    should be built:'
  prefs: []
  type: TYPE_NORMAL
- en: Points on the map where a road may be built will be marked with "`.`" characters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Roads may only be built between two houses that have a direct vertical, horizontal,
    or diagonal path between them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All the houses in the community should be reachable from every other house.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Roads may not be built across bodies of water, mountains, forests, and so on.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The cost of building a road between two houses is equal to the sum of ruggedness
    values on the path between them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A road between two houses should be built only if it is on the path with the
    lowest possible cost to the designated entry point of the property.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The entrance point is always the highest indexed house in the input.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once the positions of the houses and roads have been determined, you should
    produce a new version of the original map according to the following legend:'
  prefs: []
  type: TYPE_NORMAL
- en: Houses should be labeled with uppercase letters corresponding to the order they
    were given in input (that is, 0 = `A`, 1 = `B`, 2 = `C` and so on).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Roads should be indicated with the characters `|`, `-`, `\`, and `/`, depending
    on their orientation. If two roads with different orientations intersect, this
    should be indicated with the `+` character.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Everything else on the map should be displayed as it was originally given in
    the input.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Input Format**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The program should take an input in the following format:'
  prefs: []
  type: TYPE_NORMAL
- en: The first line contains two space-separated integers, `H` and `W`, representing
    the height and width of the map.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second contains a single integer, `N`, which is the number of houses to
    be built.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next `H` lines each contain a string of length `W`, representing a row on
    the grid. Valid locations for building roads will be marked with the "`.`" character.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next `N` lines contain two integers, `x` and `y`, which are the coordinates
    of the houses. The final index (that is, `N - 1`) always represents the entry
    point to the community.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output Format**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The program should output the same map given in the input, with the following
    additions:'
  prefs: []
  type: TYPE_NORMAL
- en: The positions of each house should be labeled with uppercase letters corresponding
    to their zero-based index, with the origin on the top left, relative to `N` (that
    is, 0 = `A`, 1 = `B`, 2 = `C`, and so on).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The roads connecting each pair of houses should be indicated as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-` if the road''s orientation is horizontal'
  prefs: []
  type: TYPE_NORMAL
- en: '`|` if the road''s orientation is vertical'
  prefs: []
  type: TYPE_NORMAL
- en: '`/` or `\` if the road''s orientation is diagonal'
  prefs: []
  type: TYPE_NORMAL
- en: '`+` if any number of roads with different orientations intersect at the same
    point'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hints/Guidelines**'
  prefs: []
  type: TYPE_NORMAL
- en: To produce the final result, a number of distinct steps are required. It is
    recommended that you outline the necessary steps prior to their implementation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It may be quite helpful to devise some scheme for debugging and producing test
    output for each individual part of the program. A mistake early on in the process
    is likely to cause subsequent steps to fail.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Study the simpler input and output samples if you are having trouble understanding
    what needs to be done.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Start by implementing the algorithms you know you will need, particularly the
    ones we discussed in the previous chapter. There may be multiple ways to accomplish
    each part of this task—be creative!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test Cases**'
  prefs: []
  type: TYPE_NORMAL
- en: 'These test cases should help you understand how you need to proceed. Let''s
    begin by taking a simple example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.18: Activity 23, test cases 1 (left) and 2 (right)'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14498_09_18.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.18: Activity 23, test cases 1 (left) and 2 (right)'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let''s consider the sample output on the right side of the previous figure.
    In that example, a path from `E(0,4)` to `C(5,4)` cannot be built as impassable
    obstacles, `#`, exist. Let''s consider a few more samples with more complexity:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.19: Activity 23, test cases 3 (left) and 4 (right)'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14498_09_19.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.19: Activity 23, test cases 3 (left) and 4 (right)'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Note that the different symbols are used to represent different types of obstacles.
    Though the effect of any obstacle is the same, we cannot build a road there. Finally,
    let''s step up the complexity in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.20: Activity 23, test case 5'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14498_09_20.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.20: Activity 23, test case 5'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution to this activity can be found on page 585.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that you have completed this chapter, you should have a fairly high appreciation
    for the value of dynamic programming. If you initially found this topic to be
    somewhat anxiety-provoking, you have hopefully come to realize that it is not
    as complicated as it may have first appeared. Viewing familiar problems through
    the dynamic programming lens, as we did in this chapter, can certainly help us
    understand the core ideas that are needed to arrive at a working DP solution.
    To that end, we encourage you to investigate other variants of the knapsack problem
    and attempt to implement them using the strategies provided.
  prefs: []
  type: TYPE_NORMAL
- en: And with that, your tour through the vast world of algorithms and data structures
    in C++ has reached its conclusion. Having arrived at the end of this book, you
    should have a markedly deepened understanding of how and when to use some of the
    most useful tools of our trade. Hopefully, you have developed a better sense of
    the practical applications of the structures and techniques that were covered
    in this book, as well as an expanded knowledge of the C++ language and its vast
    collection of features.
  prefs: []
  type: TYPE_NORMAL
- en: It should be noted that the appropriate occasions to use many of these techniques
    in practice are not necessarily obvious, which is why it is immensely beneficial
    to apply what you have learned to a range of different contexts. We have endeavored
    to provide a variety of interesting activities for practicing the concepts in
    this book, but it is highly recommended that you also try to use these skills
    in other situations. There are a plethora of online resources offering unique
    and engaging programming challenges for developers of all levels, which can be
    invaluable if you wish to train yourself to recognize how certain techniques can
    be utilized in a variety of circumstances.
  prefs: []
  type: TYPE_NORMAL
- en: Certainly, every topic that we've discussed in this book deserves much deeper
    study than what can be covered in any single book, and we hope that the information
    we have provided has made these topics accessible enough to encourage you to explore
    them deeper. Regardless of whether you are a student, looking for a development
    job, or already working in the field professionally, you are likely to encounter
    a use for at least one (and likely many) of the subjects that were covered in
    this book; and with any luck, you will know exactly what to do when that time
    comes!
  prefs: []
  type: TYPE_NORMAL
