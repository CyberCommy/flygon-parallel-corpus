- en: Phishing Domain Detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Social engineering is one of the most dangerous threats facing every individual
    and modern organization. Phishing is a well-known, computer-based, social engineering
    technique. Attackers use disguised email addresses as a weapon to target large
    companies. With the huge number of phishing emails received every day, companies
    are not able to detect all of them. That is why new techniques and safeguards
    are needed to defend against phishing. This chapter will present the steps required
    to build three different machine learning-based projects to detect phishing attempts,
    using cutting-edge Python machine learning libraries.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: A social engineering overview
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The steps for social engineering penetration testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Building a real-time phishing attack detector using different machine learning
    models:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Phishing detection with logistic regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Phishing detection with decision trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spam email detection with **natural language processing** (**NLP**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to use the following Python libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: scikit-learn Python (≥ 2.7 or ≥ 3.3)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NumPy  (≥ 1.8.2)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NLTK
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you have not installed them yet, please make sure that they are installed
    before moving forward with this chapter. You can find the code files at [https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/tree/master/Chapter02](https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/tree/master/Chapter02).
  prefs: []
  type: TYPE_NORMAL
- en: Social engineering overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Social engineering, by definition, is the psychological manipulation of a person
    to get useful and sensitive information from them, which can later be used to
    compromise a system. In other words, criminals use social engineering to gain
    confidential information from people, by taking advantage of human behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Social Engineering Engagement Framework
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **Social Engineering Engagement Framework** (**SEEF**) is a framework developed
    by Dominique C. Brack and Alexander Bahmram. It summarizes years of experience
    in information security and defending against social engineering. The stakeholders
    of the framework are organizations, governments, and individuals (personals). Social
    engineering engagement management goes through three steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pre-engagement process**: Preparing the social engineering operation'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**During-engagement process**: The engagement occurs'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Post-engagement process**:Delivering a report'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'There are many social engineering techniques used by criminals:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Baiting**: Convincing the victim to reveal information, promising him a reward
    or a gift.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Impersonation**: Pretending to be someone else.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dumpster diving**: Collecting valuable information (papers with addresses,
    emails, and so on) from dumpsters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Shoulder surfing**: Spying on other peoples'' machines from behind them,
    while they are typing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Phishing**: This is the most often used technique; it occurs when an attacker,
    masquerading as a trusted entity, dupes a victim into opening an email, instant
    message, or text message.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Steps of social engineering penetration testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Penetration testing simulates a black hat hacker attack in order to evaluate
    the security posture of a company for deploying the required safeguard. Penetration
    testing is a methodological process, and it goes through well-defined steps. There
    are many types of penetration testing:'
  prefs: []
  type: TYPE_NORMAL
- en: White box pentesting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Black box pentesting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grey box pentesting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To perform a social engineering penetration test, you need to follow the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00049.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Building real-time phishing attack detectors using different machine learning
    models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the next sections, we are going to learn how to build machine learning phishing
    detectors. We will cover the following two methods:'
  prefs: []
  type: TYPE_NORMAL
- en: Phishing detection with logistic regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Phishing detection with decision trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Phishing detection with logistic regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to build a phishing detector from scratch with
    a logistic regression algorithm. Logistic regression is a well-known statistical
    technique used to make binomial predictions (two classes).
  prefs: []
  type: TYPE_NORMAL
- en: 'Like in every machine learning project, we will need data to feed our machine
    learning model. For our model, we are going to use the UCI Machine Learning Repository
    (Phishing Websites Data Set). You can check it out at [https://archive.ics.uci.edu/ml/datasets/Phishing+Websites](https://archive.ics.uci.edu/ml/datasets/Phishing+Websites):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00050.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The dataset is provided as an `arff` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00051.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following is a snapshot from the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00052.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'For better manipulation, we have organized the dataset into a `csv` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00053.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'As you probably noticed from the attributes, each line of the dataset is represented
    in the following format – *{30 Attributes (having_IP_Address URL_Length, abnormal_URL
    and so on)} + {1 Attribute (Result)}*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00054.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: For our model, we are going to import two machine learning libraries, NumPy
    and scikit-learn, which we already installed in [Chapter 1](part0021.html#K0RQ0-49a67f1d6e7843d3b2296f38e3fe05f5), *Introduction
    to Machine Learning in Pentesting*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s open the Python environment and load the required libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, load the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Identify the `inputs` (all of the attributes, except for the last one) and
    the `outputs` (the last attribute):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In the previous chapter, we discussed how we need to divide the dataset into
    training data and testing data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00055.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'Create the scikit-learn logistic regression classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Train the classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Make predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s print out the accuracy of our phishing detector model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00056.gif)'
  prefs: []
  type: TYPE_IMG
- en: The accuracy of our model is approximately 85%. This is a good accuracy, since
    our model detected 85 phishing URLs out of 100\. But let's try to make an even
    better model with decision trees, using the same data.
  prefs: []
  type: TYPE_NORMAL
- en: Phishing detection with decision trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To build the second model, we are going to use the same machine learning libraries,
    so there is no need to import them again. However, we are going to import the
    decision tree classifier from `sklearn`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the `tree.DecisionTreeClassifier()` scikit-learn classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Train the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Compute the predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Calculate the accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, print out the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00057.gif)'
  prefs: []
  type: TYPE_IMG
- en: The accuracy of the second model is approximately 90.4%, which is a great result,
    compared to the first model. We have now learned how to build two phishing detectors,
    using two machine learning techniques.
  prefs: []
  type: TYPE_NORMAL
- en: NLP in-depth overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'NLP is the art of analyzing and understanding human languages by machines.
    According to many studies, more than 75% of the used data is unstructured. Unstructured
    data does not have a predefined data model or not organized in a predefined manner.
    Emails, tweets, daily messages and even our recorded speeches are forms of unstructured
    data. NLP is a way for machines to analyze, understand, and derive meaning from
    natural language. NLP is widely used in many fields and applications, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Real-time translation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatic summarization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sentiment analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Speech recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build chatbots
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Generally, there are two different components of NLP:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Natural Language Understanding (NLU)**: This refers to mapping input into
    a useful representation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Natural Language Generation (NLG)**: This refers to transforming internal
    representations into useful representations. In other words, it is transforming
    data into written or spoken narrative. Written analysis for business intelligence
    dashboards is one of NLG applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every NLP project goes through five steps. To build an NLP project the first
    step is identifying and analyzing the structure of words. This step involves dividing
    the data into paragraphs, sentences, and words. Later we analyze the words in
    the sentences and relationships among them. The third step involves checking the
    text for  meaningfulness. Then, analyzing the meaning of consecutive sentences.
    Finally, we finish the project by the pragmatic analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00058.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Open source NLP libraries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are many open source Python libraries that provide the structures required
    to build real-world NLP applications, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Apache OpenNLP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GATE NLP library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stanford NLP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And, of course, **Natural Language Toolkit** (**NLTK**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the previous chapter, we learned how to install many open source machine
    learning Python libraries, including the NLTK. Let's fire up our Linux machine
    and try some hands-on techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the Python terminal and import `nltk`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Download a book type, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00059.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'If you want to list the available resources that we already downloaded in the
    previous chapter, type `l`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00060.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'You can also type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00061.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'To get text from a link, it is recommended to use the `urllib` module to crawl
    a website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'As a demonstration, we are going to load a text called `Security.in.Wireless.Ad.Hoc.and.Sensor.Networks`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00062.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We crawled the text file, and used `len` to check its length and `raw[:50]`
    to display some content. As you can see from the screenshot, the text contains
    a lot of symbols that are useless for our projects. To get only what we need,
    we use **tokenization**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: To summarize what we learned in the previous section, we saw how to download
    a web page, tokenize the text, and normalize the words.
  prefs: []
  type: TYPE_NORMAL
- en: Spam detection with NLTK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now it is time to build our spam detector using the NLTK. The principle of
    this type of classifier is simple; we need to detect the words used by spammers.
    We are going to build a spam/non-spam binary classifier using Python and the `nltk`
    library, to detect whether or not an email is spam. First, we need to import the
    library as usual:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to load data and feed our model with an emails dataset. To achieve
    that, we can use the dataset delivered by the **Internet CONtent FIltering Group**.
    You can visit the website at [https://labs-repos.iit.demokritos.gr/skel/i-config/](https://labs-repos.iit.demokritos.gr/skel/i-config/):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00063.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Basically, the website provides four datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: Ling-spam
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PU1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PU123A
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enron-spam
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For our project, we are going to use the Enron-spam dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00064.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s download the dataset using the `wget` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00065.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Extract the `tar.gz` file by using the `tar -xzf enron1.tar.gz` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00066.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Shuffle the `cp spam/* emails && cp ham/* emails` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00067.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'To shuffle the emails, let''s write a small Python script, `Shuffle.py`, to
    do the job:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Just change the directory variable, and it will shuffle the files:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00068.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'After preparing the dataset, you should be aware that, as we learned previously,
    we need to `tokenize` the emails:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00069.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Also, we need to perform another step, called lemmatizing. Lemmatizing connects
    words that have different forms, like hacker/hackers and is/are. We need to import
    `WordNetLemmatizer`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a sentence for the demonstration, and print out the result of the lemmatizer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00070.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, we need to remove `stopwords`, such as `of`, `is`, `the`, and so on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'To process the email, a function called `Process` must be created, to `lemmatize`
    and `tokenize` our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The second step is feature extraction, by reading the emails'' words:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Extract the features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s define training the model Python function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'As a classification algorithm, we are going to use `NaiveBayesClassifier`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we define the evaluation Python function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00071.gif)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned to detect phishing attempts by building three different
    projects from scratch. First, we discovered how to develop a phishing detector
    using two different machine learning techniques, thanks to cutting-edge Python
    machine learning libraries. The third project was a spam filter, based on NLP
    and Naive Bayes classification. In the next chapter, we will build various projects
    to detect malware, using different techniques and Python machine learning libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We hope it was easy to go through this chapter. Now, as usual, it is practice
    time. Your job is to try building your own spam detection system. We will guide
    you through the questions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter''s GitHub repository, you will find a dataset collected from
    research done by Androutsopoulos, J. Koutsias, K.V. Chandrinos, George Paliouras,
    and C.D. Spyropoulos: *An Evaluation of Naive Bayesian Anti-Spam Filtering*. *Proceedings
    of the workshop on Machine Learning in the New Information Age, G. Potamias, V.
    Moustakis and **M. van Someren (eds.), 11th European Conference on Machine Learning,
    Barcelona, Spain, pp. 9-17, 2000*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can now prepare the data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some text-cleaning tasks to perform:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Clean your texts of stopwords, digits, and punctuation marks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform lemmatization.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a word dictionary, including their frequencies.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In email texts, you will notice that the first line is the subject of the email
    and the third line is the body of the email (we only need the email bodies).
  prefs: []
  type: TYPE_NORMAL
- en: Remove the non-words from the dictionary.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extract the features from the data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Prepare the feature vectors and their labels.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the model with a linear support vector machine classifier.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Print out the confusion matrix of your model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
