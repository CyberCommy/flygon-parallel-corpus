- en: Chapter 6. Graph-based Storage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Processing with Apache Spark and especially GraphX provides the ability to
    use in memory cluster-based, real-time processing for graphs. However, Apache
    Spark does not provide storage; the graph-based data must come from somewhere
    and after processing, probably there will be a need for storage. In this chapter,
    I will examine graph-based storage using the Titan graph database as an example.
    This chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: An overview of Titan
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An overview of TinkerPop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing Titan
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Titan with HBase
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Titan with Cassandra
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Titan with Spark
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The young age of this field of processing means that the storage integration
    between Apache Spark, and the graph-based storage system Titan is not yet mature.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, the Neo4j Mazerunner architecture was examined, which
    showed how the Spark-based transactions could be replicated to Neo4j. This chapter
    deals with Titan not because of the functionality that it shows today, but due
    to the future promise that it offers for the field of the graph-based storage
    when used with Apache Spark.
  prefs: []
  type: TYPE_NORMAL
- en: Titan
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Titan is a graph database that was developed by Aurelius ([http://thinkaurelius.com/](http://thinkaurelius.com/)).
    The application source and binaries can be downloaded from GitHub ([http://thinkaurelius.github.io/titan/](http://thinkaurelius.github.io/titan/)),
    and this location also contains the Titan documentation. Titan has been released
    as an open source application under an Apache 2 license. At the time of writing
    this book, Aurelius has been acquired by DataStax, although Titan releases should
    go ahead.
  prefs: []
  type: TYPE_NORMAL
- en: Titan offers a number of storage options, but I will concentrate only on two,
    HBase—the Hadoop NoSQL database, and Cassandra—the non-Hadoop NoSQL database.
    Using these underlying storage mechanisms, Titan is able to provide a graph-based
    storage in the big data range.
  prefs: []
  type: TYPE_NORMAL
- en: The TinkerPop3-based Titan release 0.9.0-M2 was released in June 2015, which
    will enable greater integration with Apache Spark (TinkerPop will be explained
    in the next section). It is this release that I will use in this chapter. It is
    TinkerPop that the Titan database now uses for graph manipulation. This Titan
    release is an experimental development release but hopefully, future releases
    should consolidate Titan functionality.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter concentrates on the Titan database rather than an alternative graph
    database, such as Neo4j, because Titan can use Hadoop-based storage. Also, Titan
    offers the future promise of integration with Apache Spark for a big data scale,
    in memory graph-based processing. The following diagram shows the architecture
    being discussed in this chapter. The dotted line shows direct Spark database access,
    whereas the solid lines represent Spark access to the data through Titan classes.
  prefs: []
  type: TYPE_NORMAL
- en: '![Titan](img/B01989_06_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The Spark interface doesn't officially exist yet (it is only available in the
    M2 development release), but it is just added for reference. Although Titan offers
    the option of using Oracle for storage, it will not be covered in this chapter.
    I will initially examine the Titan to the HBase and Cassandra architectures, and
    consider the Apache Spark integration later. When considering (distributed) HBase,
    ZooKeeper is required as well for integration. Given that I am using an existing
    CDH5 cluster, HBase and ZooKeeper are already installed.
  prefs: []
  type: TYPE_NORMAL
- en: TinkerPop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TinkerPop, currently at version 3 as of July 2015, is an Apache incubator project,
    and can be found at [http://tinkerpop.incubator.apache.org/](http://tinkerpop.incubator.apache.org/).
    It enables both graph databases ( like Titan ) and graph analytic systems ( like
    Giraph ) to use it as a sub system for graph processing rather than creating their
    own graph processing modules.
  prefs: []
  type: TYPE_NORMAL
- en: '![TinkerPop](img/B01989_06_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The previous figure (borrowed from the TinkerPop website) shows the TinkerPop
    architecture. The blue layer shows the Core TinkerPop API, which offers the graph
    processing API for graph, vertex, and edge processing. The **Vendor API** boxes
    show the APIs that the vendors will implement to integrate their systems. The
    diagram shows that there are two possible APIs: one for the **OLTP** database
    systems, and another for the **OLAP** analytics systems.'
  prefs: []
  type: TYPE_NORMAL
- en: The diagram also shows that the **Gremlin** language is used to create and manage
    graphs for TinkerPop, and so for Titan. Finally, the Gremlin server sits at the
    top of the architecture, and allows integration to monitoring systems like Ganglia.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Titan
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As Titan is required throughout this chapter, I will install it now, and show
    how it can be acquired, installed, and configured. I have downloaded the latest
    prebuilt version (0.9.0-M2) of Titan at: [s3.thinkaurelius.com/downloads/titan/titan-0.9.0-M2-hadoop1.zip](http://s3.thinkaurelius.com/downloads/titan/titan-0.9.0-M2-hadoop1.zip).'
  prefs: []
  type: TYPE_NORMAL
- en: 'I have downloaded the zipped release to a temporary directory, as shown next.
    Carry out the following steps to ensure that Titan is installed on each node in
    the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the Linux unzip command, unpack the zipped Titan release file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, use the Linux `su` (switch user) command to change to the `root` account,
    and move the install to the `/usr/local/` location. Change the file and group
    membership of the install to the `hadoop` user, and create a symbolic link called
    `titan` so that the current Titan release can be referred to as the simplified
    path called `/usr/local/titan`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Using a Titan Gremlin shell that will be demonstrated later, Titan is now available
    for use. This version of Titan needs Java 8; make sure that you have it installed.
  prefs: []
  type: TYPE_NORMAL
- en: Titan with HBase
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As the previous diagram shows, HBase depends upon ZooKeeper. Given that I have
    a working ZooKeeper quorum on my CDH5 cluster (running on the `hc2r1m2`, `hc2r1m3`,
    and `hc2r1m4` nodes), I only need to ensure that HBase is installed and working
    on my Hadoop cluster.
  prefs: []
  type: TYPE_NORMAL
- en: The HBase cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I will install a distributed version of HBase using the Cloudera CDH cluster
    manager. Using the manager console, it is a simple task to install HBase. The
    only decision required is where to locate the HBase servers on the cluster. The
    following figure shows the **View By Host** form from the CDH HBase installation.
    The HBase components are shown to the right as **Added Roles**.
  prefs: []
  type: TYPE_NORMAL
- en: I have chosen to add the HBase region servers (RS) to the `hc2r1m2`, `hc2r1m3`,
    and `hc2r1m4` nodes. I have installed the HBase master (M), the HBase REST server
    (HBREST), and HBase Thrift server (HBTS) on the `hc2r1m1` host.
  prefs: []
  type: TYPE_NORMAL
- en: '![The HBase cluster](img/B01989_06_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: I have manually installed and configured many Hadoop-based components in the
    past, and I find that this simple manager-based installation and configuration
    of components is both quick and reliable. It saves me time so that I can concentrate
    on other systems, such as Titan.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once HBase is installed, and has been started from the CDH manager console,
    it needs to be checked to ensure that it is working. I will do this using the
    HBase shell command shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from the previous commands, I run the HBase shell as the Linux
    user `hadoop`. The HBase version 0.98.6 has been installed; this version number
    will become important later when we start using Titan:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'I have created a simple table called `table2` with a column family of `cf1`.
    I have then added two rows with two different values. This table has been created
    from the `hc2r1m2` node, and will now be checked from an alternate node called
    `hc2r1m4` in the HBase cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the two data rows are visible in `table2` from a different host,
    so HBase is installed and working. It is now time to try and create a graph in
    Titan using HBase and the Titan Gremlin shell.
  prefs: []
  type: TYPE_NORMAL
- en: The Gremlin HBase script
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I have checked my Java version to make sure that I am on version 8, otherwise
    Titan 0.9.0-M2 will not work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'If you do not set your Java version correctly, you will get errors like this,
    which don''t seem to be meaningful until you Google them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The interactive Titan Gremlin shell can be found within the bin directory of
    the Titan install, as shown here. Once started, it offers a Gremlin prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The following script will be entered using the Gremlin shell. The first section
    of the script defines the configuration in terms of the storage (HBase), the ZooKeeper
    servers used, the ZooKeeper port number, and the HBase table name that is to be
    used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The next section defines the generic vertex properties'' name and age for the
    graph to be created using the Management System. It then commits the management
    system changes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, six vertices are added to the graph. Each one is given a numeric label
    to represent its identity. Each vertex is given an age and name value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the graph edges are added to join the vertices together. Each edge
    has a relationship value. Once created, the changes are committed to store them
    to Titan, and therefore HBase:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in a simple person-based graph, shown in the following figure,
    which was also used in the previous chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Gremlin HBase script](img/B01989_06_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'This graph can then be tested in Titan via the Gremlin shell using a similar
    script to the previous one. Just enter the following script at the `gremlin>`
    prompt, as was shown previously. It uses the same initial six lines to create
    the `titanGraph` configuration, but it then creates a graph traversal variable
    `g`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the graph traversal variable can be used to check the graph contents.
    Using the `ValueMap` option, it is possible to search for the graph nodes called
    `Mike` and `Flo`. They have been successfully found here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'So, the graph has been created and checked in Titan using the Gremlin shell,
    but we can also check the storage in HBase using the HBase shell, and check the
    contents of the Titan table. The following scan shows that the table exists, and
    contains `72` rows of the data for this small graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Now that the graph has been created, and I am confident that it has been stored
    in HBase, I will attempt to access the data using apache Spark. I have already
    started Apache Spark on all the nodes as shown in the previous chapter. This will
    be a direct access from Apache Spark 1.3 to the HBase storage. I won't at this
    stage be attempting to use Titan to interpret the HBase stored graph.
  prefs: []
  type: TYPE_NORMAL
- en: Spark on HBase
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to access HBase from Spark, I will be using Cloudera's `SparkOnHBase`
    module, which can be downloaded from [https://github.com/cloudera-labs/SparkOnHBase](https://github.com/cloudera-labs/SparkOnHBase).
  prefs: []
  type: TYPE_NORMAL
- en: 'The downloaded file is in a zipped format, and needs to be unzipped. I have
    done this using the Linux unzip command in a temporary directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'I have then moved into the unpacked module, and used the Maven command `mvn`
    to build the JAR file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, I moved the built component to my development area to keep things
    tidy, so that I could use this module in my Spark HBase code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Accessing HBase with Spark
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As in previous chapters, I will be using SBT and Scala to compile my Spark-based
    scripts into applications. Then, I will use spark-submit to run these applications
    on the Spark cluster. My SBT configuration file looks like this. It contains the
    Hadoop, Spark, and HBase libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that I am running this application on the `hc2r1m2` server, using the
    Linux `hadoop` account, under the directory `/home/hadoop/spark/titan_hbase`.
    I have created a Bash shell script called `run_titan.bash.hbase`, which allows
    me to run any application that is created and compiled under the `src/main/scala`
    subdirectory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The Bash script is held within the same `titan_hbase` directory, and takes
    a single parameter of the application class name. The parameters to the `spark-submit`
    call are the same as the previous examples. In this case, there is only a single
    script under `src/main/scala`, called `spark3_hbase2.scala`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The Scala script starts by defining the package name to which the application
    class will belong. It then imports the Spark, Hadoop, and HBase classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The application class name is defined as well as the main method. A configuration
    object is then created in terms of the application name, and the Spark URL. Finally,
    a Spark context is created from the configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, an HBase configuration object is created, and a Cloudera CDH `hbase-site.xml`
    file-based resource is added:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'An HBase context object is created using the Spark context and the HBase configuration
    object. The scan and cache configurations are also defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the data from the HBase `Titan` table is retrieved using the `hbaseRDD`
    HBase context method, and the scan object. The RDD count is printed, and then
    the script closes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: I am only printing the count of the data retrieved because Titan compresses
    the data in GZ format. So, it would make little sense in trying to manipulate
    it directly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `run_titan.bash.hbase` script, the Spark application called `spark3_hbase2`
    is run. It outputs an RDD row count of `72`, matching the Titan table row count
    that was previously found. This proves that Apache Spark has been able to access
    the raw Titan HBase stored graph data, but Spark has not yet used the Titan libraries
    to access the Titan data as a graph. This will be discussed later. And here is
    the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Titan with Cassandra
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, the Cassandra NoSQL database will be used as a storage mechanism
    for Titan. Although it does not use Hadoop, it is a large-scale, cluster-based
    database in its own right, and can scale to very large cluster sizes. This section
    will follow the same process. As for HBase, a graph will be created, and stored
    in Cassandra using the Titan Gremlin shell. It will then be checked using Gremlin,
    and the stored data will be checked in Cassandra. The raw Titan Cassandra graph-based
    data will then be accessed from Spark. The first step then will be to install
    Cassandra on each node in the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Cassandra
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Create a repo file that will allow the community version of DataStax Cassandra
    to be installed using the Linux `yum` command. Root access will be required for
    this, so the `su` command has been used to switch the user to the root. Install
    Cassandra on all the nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, install Cassandra on each node in the cluster using the Linux `yum` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Set up the Cassandra configuration under `/etc/cassandra/conf` by altering
    the `cassandra.yaml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'I have made the following changes to specify my cluster name, the server seed
    IP addresses, the RPC address, and the snitch value. Seed nodes are the nodes
    that the other nodes will try to connect to first. In this case, the NameNode
    (`103`), and node2 (`108`) have been used as `seeds`. The snitch method manages
    network topology and routing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Cassandra can now be started on each node as root using the service command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Log files can be found under `/var/log/cassandra`, and the data is stored under
    `/var/lib/cassandra`. The `nodetool` command can be used on any Cassandra node
    to check the status of the Cassandra cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The Cassandra CQL shell command called `cqlsh` can be used to access the cluster,
    and create objects. The shell is invoked next, and it shows that Cassandra version
    2.0.13 is installed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The Cassandra query language next shows a key space called `keyspace1` that
    is being created and used via the CQL shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Since Cassandra is installed and working, it is now time to create a Titan graph
    using Cassandra for storage. This will be tackled in the next section using the
    Titan Gremlin shell. It will follow the same format as the HBase section previously.
  prefs: []
  type: TYPE_NORMAL
- en: The Gremlin Cassandra script
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As with the previous Gremlin script, this Cassandra version creates the same
    simple graph. The difference with this script is in the configuration. The backend
    storage type is defined as Cassandra, and the hostnames are defined to be the
    Cassandra seed nodes. The key space and the port number are specified and finally,
    the graph is created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'From this point, the script is the same as the previous HBase example, so I
    will not repeat it. This script will be available in the download package as `cassandra_create.bash`.
    The same checks, using the previous configuration, can be carried out in the Gremlin
    shell to check the data. This returns the same results as the previous checks,
    and so proves that the graph has been stored:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the Cassandra CQL shell, and the Titan `keyspace`, it can be seen that
    a number of Titan tables have been created in Cassandra:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'It can also be seen that the data exists in the `edgestore` table within Cassandra:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: This assures me that a Titan graph has been created in the Gremlin shell, and
    is stored in Cassandra. Now, I will try to access the data from Spark.
  prefs: []
  type: TYPE_NORMAL
- en: The Spark Cassandra connector
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to access Cassandra from Spark, I will download the DataStax Spark
    Cassandra connector and driver libraries. Information and version matching on
    this can be found at [http://mvnrepository.com/artifact/com.datastax.spark/](http://mvnrepository.com/artifact/com.datastax.spark/).
  prefs: []
  type: TYPE_NORMAL
- en: The version compatibility section of this URL shows the Cassandra connector
    version that should be used with each Cassandra and Spark version. The version
    table shows that the connector version should match the Spark version that is
    being used. The next URL allows the libraries to be sourced at [http://mvnrepository.com/artifact/com.datastax.spark/spark-cassandra-connector_2.10](http://mvnrepository.com/artifact/com.datastax.spark/spark-cassandra-connector_2.10).
  prefs: []
  type: TYPE_NORMAL
- en: 'By following the previous URL, and selecting a library version, you will see
    a compile dependencies table associated with the library, which indicates all
    of the other dependent libraries, and their versions that you will need. The following
    libraries are those that are needed for use with Spark 1.3.1\. If you use the
    previous URLs, you will see which version of the Cassandra connector library to
    use with each version of Spark. You will also see the libraries that the Cassandra
    connector depends upon. Be careful to choose just (and all of) those library versions
    that are required:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Accessing Cassandra with Spark
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that I have the Cassandra connector library and all of it''s dependencies
    in place, I can begin to think about the Scala code, required to connect to Cassandra.
    The first thing to do, given that I am using SBT as a development tool, is to
    set up the SBT build configuration file. Mine looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The Scala script for the Cassandra connector example, called `spark3_cass.scala`,
    now looks like the following code. First, the package name is defined. Then, the
    classes are imported for Spark, and the Cassandra connector. Next, the object
    application class `spark3_cass` ID is defined, and so is the main method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'A Spark configuration object is created using a Spark URL and application name.
    The Cassandra connection host is added to the configuration. Then, the Spark context
    is created using the configuration object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The Cassandra `keyspace`, and table names that are to be checked are defined.
    Then, the Spark context method called `cassandraTable` is used to connect to Cassandra,
    and obtain the contents of the `edgestore` table as an RDD. The size of this RDD
    is then printed, and the script exits. We won''t look at this data at this time,
    because all that was needed was to prove that a connection to Cassandra could
    be made:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'As in the previous examples, the Spark `submit` command has been placed in
    a Bash script called `run_titan.bash.cass`. This script, shown next, looks similar
    to many others used already. The point to note here is that there is a JARs option,
    which lists all of the JAR files used so that they are available at run time.
    The order of JAR files in this option has been determined to avoid the class exception
    errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: This application is invoked using the previous Bash script. It connects to Cassandra,
    selects the data, and returns a Cassandra table data-based count of `218` rows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: This proves that the raw Cassandra-based Titan table data can be accessed from
    Apache Spark. However, as in the HBase example, this is raw table-based Titan
    data, and not the data in Titan graph form. The next step will be to use Apache
    Spark as a processing engine for the Titan database. This will be examined in
    the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing Titan with Spark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this chapter, Titan 0.9.0-M2 has been installed, and the graphs have
    successfully been created using both HBase and Cassandra as backend storage options.
    These graphs have been created using Gremlin-based scripts. In this section, a
    properties file will be used via a Gremlin script to process a Titan-based graph
    using Apache Spark. The same two backend storage options, HBase and Cassandra,
    will be used with Titan.
  prefs: []
  type: TYPE_NORMAL
- en: The following figure, based on the TinkerPop3 diagram earlier in this chapter,
    shows the architecture used in this section. I have simplified the diagram, but
    it is basically the same as the previous TinkerPop version. I have just added
    the link to Apache Spark via the Graph Computer API. I have also added both HBase
    and Cassandra storage via the Titan vendor API. Of course, a distributed installation
    of HBase uses both Zookeeper for configuration, and HDFS for storage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Titan uses TinkerPop''s Hadoop-Gremlin package for graph processing OLAP processes.
    The link to the documentation section can be found at: [http://s3.thinkaurelius.com/docs/titan/0.9.0-M2/titan-hadoop-tp3.html](http://s3.thinkaurelius.com/docs/titan/0.9.0-M2/titan-hadoop-tp3.html).'
  prefs: []
  type: TYPE_NORMAL
- en: This section will show how the Bash shell, Groovy, and properties files can
    be used to configure, and run a Titan Spark-based job. It will show different
    methods for configuring the job, and it will also show methods for managing logging
    to enable error tracking. Also, different configurations of the property file
    will be described to give access to HBase, Cassandra, and the Linux file system.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that the Titan release 0.9.0-M2, that this chapter is based on, is
    a development release. It is a prototype release, and is not yet ready for production.
    I assume that as the future Titan releases become available, the link between
    Titan and Spark will be more developed and stable. Currently, the work in this
    section is for demonstration purposes only, given the nature of the Titan release.
  prefs: []
  type: TYPE_NORMAL
- en: '![Accessing Titan with Spark](img/B01989_06_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the next section, I will explain the use of Gremlin, and Groovy scripts before
    moving onto connecting Titan to Spark using Cassandra and HBase as storage options.
  prefs: []
  type: TYPE_NORMAL
- en: Gremlin and Groovy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Gremlin shell, which is used to execute Groovy commands against Titan,
    can be used in a number of ways. The first method of use just involves starting
    a Gremlin shell for use as an interactive session. Just execute the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'This starts the session, and automatically sets up required plug-ins such as
    TinkerPop and Titan (see next). Obviously, the previous `TITAN_HOME` variable
    is used to indicate that the bin directory in question is located within your
    Titan install (`TITAN_HOME`) directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: It then provides you with a Gremlin shell prompt where you can interactively
    execute your shell commands against your Titan database. This shell is useful
    for testing scripts and running ad hoc commands against your Titan database.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'A second method is to embed your Groovy commands inline in a script when you
    call the `gremlin.sh` command. In this example, the Groovy commands between the
    EOF markers are piped into the Gremlin shell. When the last Groovy command has
    executed, the Gremlin shell will terminate. This is useful when you still want
    to use the automated environment setup of the Gremlin shell, but you still want
    to be able to quickly re-execute a script. This code snippet has been executed
    from a Bash shell script, as can be seen in the next example. The following script
    uses the `titan.sh` script to manage the Gremlin server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'A third method involves moving the Groovy commands into a separate Groovy file,
    and using the `–e` option with the Gremlin shell to execute the file. This method
    offers extra logging options for error tracking, but means that extra steps need
    to be taken when setting up the Gremlin environment for a Groovy script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: So, this script defines a Gremlin log level, which can be set to different logging
    levels to obtain extra information about a problem, that is, INFO, WARN, and DEBUG.
    It also redirects the script output to a log file (`GREMLIN_LOG_FILE`), and redirects
    errors to the same log file (`2>&1`). This has the benefit of allowing the log
    file to be continuously monitored, and provides a permanent record of the session.
    The Groovy script name that is to be executed is then passed to the encasing Bash
    shell script as a parameter (`$1`).
  prefs: []
  type: TYPE_NORMAL
- en: 'As I already mentioned, the Groovy scripts invoked in this way need extra environment
    configuration to set up the Gremlin session when compared to the previous Gremlin
    session options. For instance, it is necessary to import the necessary TinkerPop
    and Aurelius classes that will be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Having described the script and configuration options necessary to start a Gremlin
    shell session, and run a Groovy script, from this point onwards I will concentrate
    on Groovy scripts, and the property files necessary to configure the Gremlin session.
  prefs: []
  type: TYPE_NORMAL
- en: TinkerPop's Hadoop Gremlin
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As already mentioned previously in this section, it is the TinkerPop Hadoop
    Gremlin package within Titan that will be used to call Apache Spark as a processing
    engine (Hadoop Giraph can be used for processing as well). The link available
    at [http://s3.thinkaurelius.com/docs/titan/0.9.0-M2/titan-hadoop-tp3.html](http://s3.thinkaurelius.com/docs/titan/0.9.0-M2/titan-hadoop-tp3.html)
    provides documentation for Hadoop Gremlin; remember that this TinkerPop package
    is still being developed and is subject to change.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, I will examine a properties file that can be used to connect
    to Cassandra as a storage backend for Titan. It contains sections for Cassandra,
    Apache Spark, and the Hadoop Gremlin configuration. My Cassandra properties file
    is called `cassandra.properties`, and it looks like this (lines beginning with
    a hash character (`#`) are comments):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'The previous Cassandra-based properties describe the Cassandra host and port.
    This is why the storage backend type is Cassandra, the Cassandra `keyspace` that
    is to be used is called `dead` (short for grateful dead—the data that will be
    used in this example). Remember that the Cassandra tables are grouped within keyspaces.
    The previous `partitioner` class defines the Cassandra class that will be used
    to partition the Cassandra data. The Apache Spark configuration section contains
    the master URL, executor memory, and the data `serializer` class that is to be
    used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the Hadoop Gremlin section of the properties file, which defines the
    classes to be used for graph and non-graph input and output is shown here. It
    also defines the data input and output locations, as well as the flags for caching
    JAR files, and deriving memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Blueprints is the TinkerPop property graph model interface. Titan releases
    it''s own implementation of blueprints, so instead of seeing `blueprints.graph`
    in the preceding properties, you see `gremlin.graph`. This defines the class,
    used to define the graph that is supposed to be used. If this option were omitted,
    then the graph type would default to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: The `CassandraInputFormat` class defines that the data is being retrieved from
    the Cassandra database. The graph output serialization class is defined to be
    `GryoOutputFormat`. The memory output format class is defined to use the Hadoop
    Map Reduce class `SequenceFileOutputFormat`.
  prefs: []
  type: TYPE_NORMAL
- en: The `jarsInDistributedCache` value has been defined to be true so that the JAR
    files are copied to the memory, enabling Apache Spark to source them. Given more
    time, I would investigate ways to make the Titan classes visible to Spark, on
    the class path, to avoid excessive memory usage.
  prefs: []
  type: TYPE_NORMAL
- en: Given that the TinkerPop Hadoop Gremlin module is only available as a development
    prototype release, currently the documentation is minimal. There are very limited
    coding examples, and there does not seem to be documentation available describing
    each of the previous properties.
  prefs: []
  type: TYPE_NORMAL
- en: Before I delve into the examples of Groovy scripts, I thought that I would show
    you an alternative method for configuring your Groovy jobs using a configuration
    object.
  prefs: []
  type: TYPE_NORMAL
- en: Alternative Groovy configuration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A configuration object can be created using the `BaseConfiguration` method.
    In this example, I have created a Cassandra configuration called `cassConf`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: The `setProperty` method is then used to define Cassandra connection properties,
    such as backend type, host, port, and `keyspace`. Finally, a Titan graph is created
    called `titanGraph` using the open method. As will be shown later, a Titan graph
    can be created using a configuration object or a path to a properties file. The
    properties that have been set match those that were defined in the Cassandra properties
    file described previously.
  prefs: []
  type: TYPE_NORMAL
- en: The next few sections will show how graphs can be created, and traversed. They
    will show how Cassandra, HBase, and the file system can be used for storage. Given
    that I have gone to such lengths to describe the Bash scripts, and the properties
    files, I will just describe those properties that need to be changed in each instance.
    I will also provide simple Groovy script snippets in each instance.
  prefs: []
  type: TYPE_NORMAL
- en: Using Cassandra
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Cassandra-based properties file called `cassandra.properties` has already
    been described, so I will not repeat the details here. This example Groovy script
    creates a sample graph, and stores it in Cassandra. It has been executed using
    the **end of file markers** (**EOF**) to pipe the script to the Gremlin shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'A Titan graph has been created using the `TitanFactory.open` method and the
    Cassandra properties file. It is called `t1`. The graph of the Gods, an example
    graph provided with Titan, has been loaded into the graph `t1` using the method
    `GraphOfTheGodsFactory.load`. A count of vertices (`V()`) has then been generated
    along with a `ValueMap` to display the contents of the graph. The output looks
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'So, there are 12 vertices in the graph, each has a name and age element shown
    in the previous data. Having successfully created a graph, it is now possible
    to configure the previous graph traversal Gremlin command to use Apache Spark
    for processing. This is simply achieved by specifying the `SparkGraphComputer`
    in the traversal command. See the full *TinkerPop* diagram at the top of this
    chapter for architectural details. When this command is executed, you will see
    the task appear on the Spark cluster user interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Using HBase
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When using HBase, the properties file needs to change. The following values
    have been taken from my `hbase.properties` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Remember that HBase uses Zookeeper for configuration purposes. So, the port
    number, and server for connection now becomes a `zookeeper` server, and `zookeeper`
    master port 2181\. The `znode` parent value in Zookeeper is also defined as the
    top level node `/hbase`. Of course, the backend type is now defined to be `hbase`.
  prefs: []
  type: TYPE_NORMAL
- en: Also, the `GraphInputFormat` class has been changed to `HBaseInputFormat` to
    describe HBase as an input source. A Titan graph can now be created using this
    properties file, as shown in the last section. I won't repeat the graph creation
    here, as it will be the same as the last section. Next, I will move on to filesystem
    storage.
  prefs: []
  type: TYPE_NORMAL
- en: Using the filesystem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to run this example, I used a basic Gremlin shell (`bin/gremlin.sh`).
    Within the data directory of the Titan release, there are many example data file
    formats that can be loaded to create graphs. In this example, I will use the file
    called `grateful-dead.kryo`. So this time, the data will be loaded straight from
    the file to a graph without specifying a storage backend, such as Cassandra. The
    properties file that I will use only contains the following entries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, it uses the Hadoop Gremlin package but this time the graph input and
    output formats are defined as `GryoInputFormat` and `GryoOutputFormat`. The input
    location is specified to be the actual `kyro`-based file. So, the source for input
    and output is the file. So now, the Groovy script looks like this. First, the
    graph is created using the properties file. Then, a graph traversal is created,
    so that we can count vertices and see the structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, a vertex count is executed, which shows that there are over 800 vertices;
    and finally, a value map shows the structure of the data, which I have obviously
    clipped to save the space. But you can see the song name, type, and the performance
    details:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives you a basic idea of the available functionality. I am sure that
    if you search the web, you will find more complex ways of using Spark with Titan.
    Take this for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: The previous example specifies the use of the `SparkGraphComputer` class using
    the compute method. It also shows how the page rank vertex program, supplied with
    Titan, can be executed using the program method. This would modify your graph
    by adding page ranks to each vertex. I provide this as an example, as I am not
    convinced that it will work with Spark at this time.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has introduced the Titan graph database from Aurelius. It has shown
    how it can be installed and configured on a Linux cluster. Using a Titan Gremlin
    shell example, the graphs have been created, and stored in both HBase and Cassandra
    NoSQL databases. The choice of Titan storage option required will depend upon
    your project requirements; HBase HDFS based storage or Cassandra non HDFS based
    storage. This chapter has also shown that you can use the Gremlin shell both interactively
    to develop the graph scripts, and with Bash shell scripts so that you can run
    scheduled jobs with associated logging.
  prefs: []
  type: TYPE_NORMAL
- en: Simple Spark Scala code has been provided, which shows that Apache Spark can
    access the underlying tables that Titan creates on both HBase and Cassandra. This
    has been achieved by using the database connector modules provided by Cloudera
    (for HBase), and DataStax (for Cassandra). All example code and build scripts
    have been described along with the example output. I have included this Scala-based
    section to show you that the graph-based data can be accessed in Scala. The previous
    section processed data from the Gremlin shell, and used Spark as a processing
    backend. This section uses Spark as the main processing engine, and accesses Titan
    data from Spark. If the Gremlin shell was not suitable for your requirements,
    you might consider this approach. As Titan matures, so will the ways in which
    you can integrate Titan with Spark via Scala.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, Titan's Gremlin shell has been used along with Apache Spark to demonstrate
    simple methods for creating, and accessing Titan-based graphs. Data has been stored
    on the file system, Cassandra, and HBase to do this.
  prefs: []
  type: TYPE_NORMAL
- en: Google groups are available for Aurelius and Gremlin users via the URLs at [https://groups.google.com/forum/#!forum/aureliusgraphs](https://groups.google.com/forum/#!forum/aureliusgraphs)
    and [https://groups.google.com/forum/#!forum/gremlin-users](https://groups.google.com/forum/#!forum/gremlin-users).
  prefs: []
  type: TYPE_NORMAL
- en: Although the community seems smaller than other Apache projects, posting volume
    can be somewhat light, and it can be difficult to get a response to posts.
  prefs: []
  type: TYPE_NORMAL
- en: DataStax, the people who created Cassandra, acquired Aurelius, the creators
    of Titan this year. The creators of Titan are now involved in the development
    of DataStax's DSE graph database, which may have a knock-on effect on Titan's
    development. Having said that, the 0.9.x Titan release has been created, and a
    1.0 release is expected.
  prefs: []
  type: TYPE_NORMAL
- en: So, having shown some of the Titan functionality with the help of an example
    with both Scala and Gremlin, I will close the chapter here. I wanted to show the
    pairing of Spark-based graph processing, and a graph storage system. I like open
    source systems for their speed of development and accessibility. I am not saying
    that Titan is the database for you, but it is a good example. If its future can
    be assured, and its community grows, then as it matures, it could offer a valuable
    resource.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that two versions of Spark have been used in this chapter: 1.3 and 1.2.1\.
    The earlier version was required, because it was apparently the only version that
    would work with Titan''s `SparkGraphComputer`, and so avoids Kyro serialization
    errors.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, extensions to the Apache Spark MLlib machine learning library
    will be examined in terms of the [http://h2o.ai/](http://h2o.ai/) H2O product.
    A neural-based deep learning example will be developed in Scala to demonstrate
    its potential functionality.
  prefs: []
  type: TYPE_NORMAL
