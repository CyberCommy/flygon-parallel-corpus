- en: Just Enough Linear Algebra for Machine Learning with Spark
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习与Spark的线性代数基础
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容：
- en: Package imports and initial setup for vectors and matrices
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量和矩阵的包导入和初始设置
- en: Creating DenseVector and setup with Spark 2.0
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建DenseVector并在Spark 2.0中设置
- en: Creating SparseVector and setup with Spark 2.0
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建SparseVector并在Spark 2.0中设置
- en: Creating DenseMatrix and setup with Spark 2.0
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建DenseMatrix并在Spark 2.0中设置
- en: Using sparse local matrices with Spark 2.0
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Spark 2.0的稀疏本地矩阵
- en: Performing vector arithmetic using Spark 2.0
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Spark 2.0进行向量运算
- en: Performing matrix arithmetic with Spark 2.0
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Spark 2.0进行矩阵运算
- en: Distributed matrices in Spark 2.0 ML library
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spark 2.0 ML库中的分布式矩阵
- en: Exploring RowMatrix in Spark 2.0
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中探索RowMatrix
- en: Exploring distributed IndexedRowMatrix in Spark 2.0
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中探索分布式IndexedRowMatrix
- en: Exploring distributed CoordinateMatrix in Spark 2.0
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中探索分布式CoordinateMatrix
- en: Exploring distributed BlockMatrix in Spark 2.0
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中探索分布式BlockMatrix
- en: Introduction
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Linear algebra is the cornerstone of **machine learning** (**ML**) and **mathematical**
    **programming** (**MP**). When dealing with Spark's machine library, one must
    understand that the Vector/Matrix structures provided by Scala (imported by default)
    are different from the Spark ML, MLlib Vector, Matrix facilities provided by Spark.
    The latter, powered by RDDs, is the desired data structure if you are going to
    use Spark (that is, parallelism) out of the box for large-scale matrix/vector
    computation (for example, SVD implementation alternatives with more numerical
    accuracy, desired in some cases for derivatives pricing and risk analytics). The
    Scala Vector/Matrix libraries provide a rich set of linear algebra operations
    such as dot product, additions, and so on, that still have their own place in
    an ML pipeline. In summary, the key difference between using Scala Breeze and
    Spark or Spark ML is that the Spark facility is backed by RDDs which allows for
    simultaneous distributed, concurrent computing, and resiliency without requiring
    any additional concurrency module or extra effort (for example, Akka + Breeze).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 线性代数是**机器学习**（**ML**）和**数学** **编程**（**MP**）的基石。在处理Spark的机器库时，必须了解Scala提供的Vector/Matrix结构（默认导入）与Spark提供的ML、MLlib
    Vector、Matrix设施有所不同。后者由RDD支持，是所需的数据结构，如果要使用Spark（即并行性）进行大规模矩阵/向量计算（例如，某些情况下用于衍生定价和风险分析的SVD实现替代方案，具有更高的数值精度）。Scala
    Vector/Matrix库提供了丰富的线性代数操作，如点积、加法等，在ML管道中仍然有其自己的位置。总之，使用Scala Breeze和Spark或Spark
    ML之间的关键区别在于，Spark设施由RDD支持，允许同时分布式、并发计算和容错，而无需任何额外的并发模块或额外的工作（例如，Akka + Breeze）。
- en: Almost all machine learning algorithms use some form of classification or regression
    mechanism (not necessarily linear) to train a model and then proceed to minimize
    errors by comparing the training output to the actual output. For example, any
    implementation of a recommendation system in Spark will heavily rely on matrix
    decomposition, factorization, approximation, or **Single Value Decomposition**
    (**SVD**). Another machine learning area of interest dealing with dimensionality
    reduction for big datasets is **Principal Component Analysis** (**PCA**), which
    relies heavily on linear algebra, factorization, and matrix manipulation.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有的机器学习算法都使用某种形式的分类或回归机制（不一定是线性的）来训练模型，然后通过比较训练输出和实际输出来最小化错误。例如，在Spark中任何推荐系统的实现都会严重依赖于矩阵分解、因子分解、近似或**单值分解**（**SVD**）。另一个与处理大型数据集的维度约简有关的机器学习领域是**主成分分析**（**PCA**），它严重依赖于线性代数、因子分解和矩阵操作。
- en: When we examined the Spark ML and MLlib algorithms' source code for the first
    time in Spark 1.x.x, we quickly noticed that Vectors and Matrices use RDDs as
    the base for many prominent algorithms.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们第一次在Spark 1.x.x中检查Spark ML和MLlib算法的源代码时，我们很快注意到向量和矩阵使用RDD作为许多重要算法的基础。
- en: 'When we revisited the source code for Spark 2.0 and machine learning libraries,
    we noticed some interesting changes that need to be considered going forward.
    Here is an example of such changes from Spark 1.6.2 to Spark 2.0.0 that impacted
    some of our linear algebra code with Spark:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们重新审视Spark 2.0和机器学习库的源代码时，我们注意到一些有趣的变化需要在以后考虑。以下是从Spark 1.6.2到Spark 2.0.0的一些变化的示例，这些变化影响了我们在Spark中的一些线性代数代码：
- en: 'In the previous version (Spark 1.6.x), you can convert the `DenseVector` or
    `SparseVector` (refer to [https://spark.apache.org/docs/1.5.2/api/java/org/apache/spark/mllib/linalg/Vectors.html](https://spark.apache.org/docs/1.5.2/api/java/org/apache/spark/mllib/linalg/Vectors.html))
    directly by using the `toBreeze()` function, as shown in the following code base:'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在之前的版本（Spark 1.6.x）中，您可以通过使用`toBreeze()`函数直接将`DenseVector`或`SparseVector`（参见[https://spark.apache.org/docs/1.5.2/api/java/org/apache/spark/mllib/linalg/Vectors.html](https://spark.apache.org/docs/1.5.2/api/java/org/apache/spark/mllib/linalg/Vectors.html)）转换为`BreezeVector`实例，如下面的代码所示：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In Spark 2.0, the `toBreeze()` function has not only been changed to `asBreeze()`,
    but it has also been demoted to a private function
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中，`toBreeze()`函数不仅已更改为`asBreeze()`，而且还已降级为私有函数
- en: 'To remedy this, use one of the following code snippets to convert the preceding
    vector to the commonly used `BreezeVector` instance:'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了解决这个问题，可以使用以下代码片段之一将前面的向量转换为常用的`BreezeVector`实例：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Scala is a concise language in which both object-oriented and functional programming
    paradigms can coexist without conflict. While in the machine learning paradigm,
    functional programming is preferred, there is nothing wrong with using the object-oriented
    approach for initial data collection and presentation at a later stage.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Scala是一种简洁的语言，对象导向和函数式编程范式可以在其中共存而不冲突。虽然在机器学习范式中，函数式编程更受青睐，但在初始数据收集和稍后的展示阶段使用面向对象的方法也没有问题。
- en: In terms of large-scale distributed matrices, our experience shows that when
    approaching large matrix sets 10⁹ to 10^(13) to 10^(27), and so on, you have to
    take a deeper look at the resulting network operation and shuffling that are inherent
    in a distributed operation. Based on our experience, the combination of local
    and distributed matrix/vector operations (for example, dot product, multiplication,
    and so on) work best when you operate at scale.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure depicts the categorization of available Spark vectors
    and matrices:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00044.jpeg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
- en: Package imports and initial setup for vectors and matrices
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we can program in Spark or use vector and matrix artifacts, we need to
    first import the right packages and then set up `SparkSession` so we can gain
    access to the cluster handle.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: In this short recipe, we highlight a comprehensive number of packages that can
    cover most of the linear algebra operations in Spark. The individual recipes that
    follow will include the exact subset required for the specific program.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Set up the package location where the program will reside:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Import the packages for setting up the logging level for `log4j`. This step
    is optional, but we highly recommend it (change the level appropriately as you
    move through the development cycle):'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Set up the logging level to warning and error to cut down on output. See the
    previous step for the package requirement:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Set up the Spark context and application parameters so Spark can run:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: There's more...
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Prior to Spark 2.0, the SparkContext and SQLContext had to be initialized separately.
    Refer to the following code snippet if you plan to run the code in previous versions
    of Spark.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: 'Set up the application parameters so Spark can run (using Spark 1.5.2 or Spark
    1.6.1):'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: See also
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: SparkSession is the new entry point into the cluster in Spark 2.x.x and above.
    SparkSession unifies access entry to the cluster and all things data. It unifies
    access to SparkContext, SQLContext, or HiveContext, while making it easier to
    work with the DataFrame and Dataset APIs. We will revisit the SparkSession with
    a dedicated recipe in [Chapter 4](part0200.html#5UNGG0-4d291c9fed174a6992fd24938c2f9c77),
    *Common Recipes for Implementing a Robust Machine Learning System*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: 'See the following figure for reference:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00045.jpeg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: The documentation for method calls can be seen at [https://spark.apache.org/docs/2.0.0/api/scala/#org.apache.spark.sql.SparkSession](https://spark.apache.org/docs/2.0.0/api/scala/#org.apache.spark.sql.SparkSession).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Creating DenseVector and setup with Spark 2.0
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we explore `DenseVectors` using the Spark 2.0 machine library.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Spark provides two distinct types of vector facilities (dense and sparse) for
    storing and manipulating feature vectors that are going to be used in machine
    learning or optimization algorithms.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we examine `DenseVector` examples that you would most likely
    use for implementing/augmenting existing machine learning programs. These examples
    also help to better understand Spark ML or MLlib source code and the underlying
    implementation (for example, Single Value Decomposition).
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here we look at creating an ML vector feature (with independent variables)
    from arrays, which is a common use case. In this case, we have three almost fully
    populated Scala arrays corresponding to customer and product feature sets. We
    convert these arrays to the corresponding `DenseVectors` in Scala:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Set the variables to create the vectors from the array. Convert from the array
    to the `DenseVector`:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The next step is to create a `DenseVector` and to assign values via initialization.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This is the most cited case and is often used in class constructors that deal
    with batch input:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following is another example to show on-the-fly conversion from a string
    to a double during the initialization. Here we start with a string and invoke
    `toDouble` inline:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下是另一个示例，展示了在初始化期间从字符串转换为双精度的即时转换。在这里，我们从一个字符串开始，并在内联中调用`toDouble`：
- en: '[PRE11]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output is as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE12]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: How it works...
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The signature for this method constructor is:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该方法构造函数的签名为：
- en: '[PRE13]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The method inherits from the following which makes its concrete methods available
    to all routines:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该方法继承自以下内容，使其具体方法对所有例程可用：
- en: '[PRE14]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'There are several method calls that are of interest:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有几个感兴趣的方法调用：
- en: 'Make a deep copy of the vector:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 制作向量的深拷贝：
- en: '[PRE15]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Convert to the `SparseVector`. You will do this if your vector is long and
    the density decreases after a number of operations (for example, zero out non-contributing
    members):'
  id: totrans-76
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转换为`SparseVector`。如果您的向量很长，并且在进行了一定数量的操作后密度减小（例如，将不贡献的成员归零），则会执行此操作：
- en: '[PRE16]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Find the number of non-zero elements. This is useful so you can convert on-the-fly
    to the SparseVector if the density ID is low:'
  id: totrans-78
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找非零元素的数量。如果密度ID较低，则这很有用，因此您可以即时转换为SparseVector：
- en: '[PRE17]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Convert the vector to the array. This is often necessary when dealing with
    distributed operations that require close interactions with RDDs or proprietary
    algorithms that use Spark ML as a subsystem:'
  id: totrans-80
  prefs:
  - PREF_UL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将向量转换为数组。在处理需要与RDD或使用Spark ML作为子系统的专有算法进行紧密交互的分布式操作时，这通常是必要的：
- en: '[PRE18]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: There's more...
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: One must be careful not to mix vector facilities provided by the `Breeze` library
    with Spark ML vectors. To work with ML library algorithms, you are required to
    use its native data structures, but you can always convert from ML vectors to
    `Breeze`, do all your math operations, and then convert to Spark's desired data
    structure when using the ML library algorithms (for example, ALS or SVD).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 必须小心，不要将`Breeze`库提供的向量功能与Spark ML向量混合使用。要使用ML库算法，您需要使用其本机数据结构，但您始终可以从ML向量转换为`Breeze`，进行所有数学运算，然后在使用ML库算法（例如ALS或SVD）时转换为Spark所需的数据结构。
- en: We need the vector and matrix import statements so we can work with the ML library
    itself, otherwise the Scala vector and matrix will be used by default. This is
    the source of much confusion when the programs fail to scale on cluster.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要向量和矩阵导入语句，这样我们才能使用ML库本身，否则Scala向量和矩阵将默认使用。当程序无法在集群上扩展时，这是导致许多混乱的根源。
- en: 'The following figure depicts a pictorial view which should help clarify the
    subject:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示了一个图解视图，这应该有助于澄清主题：
- en: '![](img/00046.jpeg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00046.jpeg)'
- en: See also
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation for constructor is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseVector.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseVector.html#constructor_summary)
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseVector.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseVector.html#constructor_summary)找到
- en: Documentation for method calls is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseVector.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseVector.html#method_summary)
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方法调用的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseVector.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseVector.html#method_summary)找到
- en: Creating SparseVector and setup with Spark
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建SparseVector并使用Spark进行设置
- en: In this recipe, we examine several types of `SparseVector` creation. As the
    length of the vector increases (millions) and the density remains low (few non-zero
    members), then sparse representation becomes more and more advantageous over the
    `DenseVector`.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们检查了几种`SparseVector`的创建类型。当向量的长度增加（百万级）且密度保持较低（非零成员较少）时，稀疏表示变得越来越有利于`DenseVector`。
- en: How to do it...
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入向量和矩阵操作所需的必要包：
- en: '[PRE19]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Set up the Spark context and application parameters so Spark can run. See the
    first recipe in this chapter for more details and variations:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置Spark上下文和应用程序参数，以便Spark可以运行。有关更多详细信息和变体，请参见本章的第一个示例：
- en: '[PRE20]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Here we look at creating a ML SparseVector that corresponds to its equivalent
    DenseVector. The call consists of three parameters: Size of the vector, indexes
    to non-zero data, and finally, the data itself.'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们看一下创建与其等效的DenseVector相对应的ML SparseVector。调用包括三个参数：向量的大小，非零数据的索引，最后是数据本身。
- en: 'In the following example, we can compare the dense versus SparseVector creation.
    As you can see, the four elements that are non-zero (5, 3, 8, 9) correspond to
    locations (0, 2, 18, 19) while the number 20 indicates the total size:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们可以比较密集与SparseVector的创建。如您所见，四个非零元素（5、3、8、9）对应于位置（0、2、18、19），而数字20表示总大小：
- en: '[PRE21]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: To understand the data structure better, we compare the output and some of the
    important attributes that help us, especially with dynamic programming using vectors.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了更好地理解数据结构，我们比较输出和一些重要属性，这些属性对我们有所帮助，特别是在使用向量进行动态编程时。
- en: 'First we take a look at the printout for the DenseVector to see its representation:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们看一下DenseVector的打印输出，以查看其表示：
- en: '[PRE22]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output is as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE23]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Next, we take a look at the printout for the SparseVector to see its internal
    representation:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们看一下SparseVector的打印输出，以查看其内部表示：
- en: '[PRE24]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: If we compare and contrast the internal representation and the number of elements
    versus active and non-zero, you will see that the SparseVector only stores non-zero
    elements and indexes to reduce storage requirement.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们比较内部表示和元素数量与活跃和非零元素的对比，您会发现SparseVector只存储非零元素和索引以减少存储需求。
- en: 'The output is as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE25]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We can convert back and forth between sparse and DenseVectors as needed. The
    reason that you might want to do this is that external math and linear algebra
    do not conform to Spark''s internal representation. We made the variable type
    explicit to make the point, but you can eliminate that extra declaration in actual
    practice:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以根据需要在稀疏向量和密集向量之间进行转换。您可能想这样做的原因是，外部数学和线性代数不符合Spark的内部表示。我们明确指定了变量类型以阐明观点，但在实际操作中可以消除该额外声明：
- en: '[PRE26]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The output is as follows:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE27]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: How it works...
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'The signature for this method constructor is:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此方法构造函数的签名为：
- en: '[PRE28]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The method inherits from the following which makes its concrete methods available
    to all routines:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法继承自以下内容，使其具体方法对所有例程可用：
- en: '[PRE29]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'There are several method calls related to vectors that are of interest:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个与向量相关的方法调用是有趣的：
- en: 'Make a deep copy of the vector:'
  id: totrans-121
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对向量进行深拷贝：
- en: '[PRE30]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Convert to the `SparseVector`. You will do this if your vector is long and
    the density decreases after a number of operations (for example, zero out non-contributing
    members):'
  id: totrans-123
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转换为`SparseVector`。如果您的向量很长，并且密度在多次操作后减少（例如，将不贡献的成员归零），则会执行此操作：
- en: '[PRE31]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Find the number of non-zero elements. This is useful so you can convert on-the-fly
    to the SparseVector if the density ID is low.
  id: totrans-125
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找非零元素的数量。这很有用，因此您可以在需要时将其转换为稀疏向量，如果密度ID较低。
- en: '[PRE32]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Convert the vector to an array. This is often necessary when dealing with distributed
    operations that require 1:1 interactions with RDDs or proprietary algorithms that
    use Spark ML as a subsystem:'
  id: totrans-127
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将向量转换为数组。在处理需要与RDD或使用Spark ML作为子系统的专有算法进行1:1交互的分布式操作时，通常需要这样做：
- en: '[PRE33]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: There's more...
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: One must remember that the dense and SparseVectors are local vectors and they
    must not be confused with the distributed facilities (for example, distributed
    matrices such as the RowMatrix class).
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 必须记住，密集向量和稀疏向量是本地向量，不得与分布式设施混淆（例如，分布式矩阵，如RowMatrix类）。
- en: 'The underlying math operations for the vectors on a local machine will be provided
    by two libraries:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本地机器上向量的基本数学运算将由两个库提供：
- en: '**Breeze**: [http://www.scalanlp.org/](http://www.scalanlp.org/)'
  id: totrans-132
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Breeze**：[http://www.scalanlp.org/](http://www.scalanlp.org/)'
- en: '**JBLAS**: [http://jblas.org/](http://jblas.org/)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**JBLAS**：[http://jblas.org/](http://jblas.org/)'
- en: 'There is another data structure related directly to Vectors called LabeledPoint,
    which we covered in [Chapter 4](part0200.html#5UNGG0-4d291c9fed174a6992fd24938c2f9c77), *Common
    Recipes for Implementing a Robust Machine Learning System*. In short, it is a
    data structure corresponding to `LIBSVM` and `LIBLINEAR` formats for storing ML
    data consisting of a feature vector plus a label (for example, independent and
    dependent variables in a regression):'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个与向量直接相关的数据结构，称为LabeledPoint，我们在[第4章](part0200.html#5UNGG0-4d291c9fed174a6992fd24938c2f9c77)中介绍过，*实现强大的机器学习系统的常见配方*。简而言之，它是一种数据结构，用于存储ML数据，包括特征向量和标签（例如，回归中的自变量和因变量）。
- en: '**LIBSVM**: [http://www.csie.ntu.edu.tw/~cjlin/libsvm/](http://www.csie.ntu.edu.tw/~cjlin/libsvm/)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LIBSVM**：[http://www.csie.ntu.edu.tw/~cjlin/libsvm/](http://www.csie.ntu.edu.tw/~cjlin/libsvm/)'
- en: '**LIBLINEAR**: [http://www.csie.ntu.edu.tw/~cjlin/liblinear/](http://www.csie.ntu.edu.tw/~cjlin/liblinear/)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LIBLINEAR**：[http://www.csie.ntu.edu.tw/~cjlin/liblinear/](http://www.csie.ntu.edu.tw/~cjlin/liblinear/)'
- en: See also
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation for constructor is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseVector.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseVector.html#constructor_summary)
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseVector.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseVector.html#constructor_summary)找到
- en: Documentation for method calls is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseVector.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseVector.html#method_summary)
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方法调用的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseVector.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseVector.html#method_summary)找到
- en: Creating dense matrix and setup with Spark 2.0
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建密集矩阵并使用Spark 2.0进行设置
- en: In this recipe, we explore matrix creation examples that you most likely would
    need in your Scala programming and while reading the source code for many of the
    open source libraries for machine learning.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们探讨了您在Scala编程中可能需要的矩阵创建示例，以及在阅读许多用于机器学习的开源库的源代码时可能需要的示例。
- en: Spark provides two distinct types of local matrix facilities (dense and sparse)
    for storage and manipulation of data at a local level. For simplicity, one way
    to think of a matrix is to visualize it as columns of Vectors.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Spark提供了两种不同类型的本地矩阵设施（密集和稀疏），用于在本地级别存储和操作数据。简单来说，将矩阵视为向量的列是一种思考方式。
- en: Getting ready
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The key to remember here is that the recipe covers local matrices stored on
    one machine. We will use another recipe, *D**istributed matrices in the Spark2.0
    ML library*, covered in this chapter, for storing and manipulating distributed
    matrices.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里要记住的关键是，该配方涵盖了存储在一台机器上的本地矩阵。我们将在本章中介绍的另一个配方*Spark2.0 ML库中的分布式矩阵*，用于存储和操作分布式矩阵。
- en: How to do it...
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入向量和矩阵操作所需的包：
- en: '[PRE34]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Set up the Spark session and application parameters so Spark can run:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置Spark会话和应用程序参数，以便Spark可以运行：
- en: '[PRE35]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Here we look at creating an ML vector feature from Scala arrays. Let us define
    a 2x2 dense matrix and instantiate it with an array:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们将从Scala数组创建ML向量特征。让我们定义一个2x2的密集矩阵，并用数组实例化它：
- en: '[PRE36]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The output is as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE37]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Constructing a dense matrix and assigning values via initialization in a single
    step:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 通过初始化一步构建密集矩阵并分配值：
- en: 'Construct a dense local matrix directly by defining the array inline. This
    is an array of 3x3 and has nine members. You can think of it as three columns
    of three vectors (3x3):'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 通过内联定义数组直接构造密集本地矩阵。这是一个3x3的数组，有九个成员。您可以将其视为三列三个向量（3x3）：
- en: '[PRE38]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The output is as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE39]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: This is another example to show inline instantiation of a dense local matrix
    with vectors. This is a common case in which you collect vectors into a matrix
    (column order) and then perform an operation on the entire set. The most common
    case is to collect the vectors and then use a distributed matrix to do distributed
    parallel operation.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一个示例，展示了使用向量内联实例化密集本地矩阵。这是一个常见情况，您将向量收集到矩阵（列顺序）中，然后对整个集合执行操作。最常见的情况是收集向量，然后使用分布式矩阵执行分布式并行操作。
- en: 'In Scala, we use the `++` operator with arrays to achieve concatenation:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在Scala中，我们使用`++`运算符与数组实现连接：
- en: '[PRE40]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The output is as follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE41]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: How it works...
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The signatures for this method constructor are (Column-major dense matrix):'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此方法构造函数的签名为（按列主要密集矩阵）：
- en: '[PRE42]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The method inherits from the following which makes their concrete methods available
    to all routines:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该方法继承自以下内容，使其具体方法对所有例程可用：
- en: interface class java.lang.Object
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接口类java.lang.Object
- en: java.io.Serializable
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: java.io.Serializable
- en: Matrix
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩阵
- en: 'There are several method calls that are of interest:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有几个感兴趣的方法调用：
- en: 'Generate the diagonal matrix from the supplied values in the vector:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从向量中提供的值生成对角矩阵：
- en: '[PRE43]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Create an identity matrix. An identity matrix is a matrix that has diagonals
    as 1 and any other element as 0:'
  id: totrans-175
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个单位矩阵。单位矩阵是对角线为1，其他元素为0的矩阵：
- en: '[PRE44]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Keep track of whether the matrix is transposed:'
  id: totrans-177
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 跟踪矩阵是否被转置：
- en: '[PRE45]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Create a matrix with a set of random numbers - drawn from uniform distribution:'
  id: totrans-179
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含一组随机数的矩阵-从均匀分布中抽取：
- en: '[PRE46]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Create a matrix with a set of random numbers - drawn from gaussian distribution:'
  id: totrans-181
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含一组随机数的矩阵-从高斯分布中抽取：
- en: '[PRE47]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Transpose the matrix:'
  id: totrans-183
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转置矩阵：
- en: '[PRE48]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Make a deep copy of the vector:'
  id: totrans-185
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对向量进行深拷贝：
- en: '[PRE49]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Convert to a SparseVector. You will do this if your vector is long and the
    density decreases after a number of operations (for example, zero out non-contributing
    members):'
  id: totrans-187
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转换为稀疏向量。如果您的向量很长，并且密度在一系列操作后减少（例如，将不贡献的成员归零），则会执行此操作：
- en: '[PRE50]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Find the number of non-zero elements. This is useful so you can convert on-the-fly
    to a SparseVector if the density ID is low:'
  id: totrans-189
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找非零元素的数量。这很有用，因此您可以根据需要将其转换为稀疏向量，如果密度ID较低：
- en: '[PRE51]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Get all the values stored in Matrix:'
  id: totrans-191
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取矩阵中存储的所有值：
- en: '[PRE52]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: There's more...
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'The most difficult part of working with matrices in Spark is to getting used
    to column order versus row order. It is key to remember that Spark ML uses underlying
    libraries that work better with column stored mechanisms. Here is an example to
    demonstrate:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark中处理矩阵最困难的部分是习惯于列顺序与行顺序。要记住的关键是，Spark ML使用的底层库更适合使用列存储机制。以下是一个示例：
- en: 'Given a matrix definition which defines a 2x2 matrix:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给定定义2x2矩阵的矩阵：
- en: '[PRE53]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The matrix is actually stored as :'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 矩阵实际上存储为：
- en: '[PRE54]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: You move from left to right in the value set and then from column to column
    for the placement in the Matrix.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 您从值集合的左侧移动到右侧，然后从列到列进行矩阵的放置。
- en: 'As you can see, the assumption that the matrix is stored row wise is not in
    alignment with the Spark approach. The following order is not correct from Spark''s
    perspective:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如您所见，矩阵按行存储的假设与Spark方法不一致。从Spark的角度来看，以下顺序是不正确的：
- en: '[PRE55]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: See also
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation for constructor is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseMatrix.html#constructor_summary)
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseMatrix.html#constructor_summary)找到
- en: Documentation For method calls is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseMatrix.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseMatrix.html#method_summary)
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方法调用的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseMatrix.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/DenseMatrix.html#method_summary)找到
- en: Using sparse local matrices with Spark 2.0
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spark 2.0的稀疏本地矩阵
- en: In this recipe, we concentrate on SparseMatrix creation. In the previous recipe,
    we saw how a local dense matrix is declared and stored. A good number of machine
    learning problem domains can be represented as a set of features and labels within
    the matrix. In large-scale machine learning problems (for example, progression
    of a disease through large population centers, security fraud, political movement
    modeling, and so on), a good portion of the cells will be 0 or null (for example,
    the current number of people with a given disease versus the healthy population).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们专注于稀疏矩阵的创建。在上一个示例中，我们看到了如何声明和存储本地密集矩阵。许多机器学习问题领域可以表示为矩阵中的一组特征和标签。在大规模机器学习问题中（例如，疾病在大型人口中的传播，安全欺诈，政治运动建模等），许多单元格将为0或null（例如，患有某种疾病的人数与健康人口的当前数量）。
- en: To help with storage and efficient operation in real time, sparse local matrices
    specialize in storing the cells efficiently as a list plus an index, which leads
    to faster loading and real time operations.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助存储和实时操作的高效性，稀疏本地矩阵专门用于以列表加索引的方式高效存储单元格，从而实现更快的加载和实时操作。
- en: How to do it...
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动新项目。确保包含必要的JAR文件。
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Set up the Spark context and application parameters so Spark can run - See
    the first recipe in this chapter for more details and variations:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: The creation of a SparseMatrix is a little bit more complicated due to the way
    we store the sparse presentation as Compressed Column Storage (CCS), also referred
    to as the Harwell-Boeing SparseMatrix format. Please see, *How it works...* for
    a detailed explanation.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We declare and create a local 3x2 SparseMatrix with only three non-zero members:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Let''s examine the output so we fully understand what is happening at a lower
    level. The three values will be placed at (0,0),(1,1),(2,1):'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The output is as follows:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'To clarify further, here is the code for the SparseMatrix that is illustrated
    on Spark''s documentation pages of the SparseMatrix (see following section titled
    *See also*). This is a 3x3 Matrix with six non-zero values. Note that the order
    of the declaration is: Matrix Size, Column Pointers, Row Indexes, and the Value
    as the last member:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The output is as follows:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Column Pointers = [0,2,3,6]
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Row Indexes = [0,2,1,0,1,2]
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Non-Zero Values = [1.0,2.0,3.0,4.0,5.0,6.0]
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How it works...
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our experience, most of the difficulties with SparseMatrices come from a
    lack of understanding of the difference between **Compressed Row Storage** (**CRS**)
    and **Compressed Column Storage** (**CCS**). We highly recommend that the reader
    researches this topic in depth to clearly understand the differences.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: 'In short, the CCS format is used by Spark for the transposed target matrix:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two distinct signatures for this method call constructor:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`SparseMatrix (int numRows, int numCols, int[] colPtrs, int[] rowIndices, double[]
    values)`'
  id: totrans-232
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SparseMatrix(int numRows, int numCols, int[] colPtrs, int[] rowIndices, double[]
    values, boolean isTransposed)`'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In option number two, we are indicating that the matrix is declared as transposed
    already, so the matrix will be treated differently.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: 'The method inherits from the following which makes their concrete methods available
    to all routines:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: interface class java.lang.Object
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: java.io.Serializable
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrix
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are several method calls that are of interest:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Generate the diagonal matrix from the supplied values in the vector:'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE63]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Create an identity matrix. An identity matrix is a matrix that has diagonals
    as 1 and any other element as 0:'
  id: totrans-242
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE64]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Keep track of whether the matrix is transposed:'
  id: totrans-244
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE65]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Create a matrix with a set of random numbers - drawn from uniform distribution:'
  id: totrans-246
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE66]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Create a matrix with a set of random numbers - drawn from gaussian distribution:'
  id: totrans-248
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE67]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Transpose the matrix:'
  id: totrans-250
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE68]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Make a deep copy of the vector
  id: totrans-252
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE69]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Convert to a SparseVector. You will do this if your vector is long and the
    density decreases after a number of operations (for example, zero out non-contributing
    members):'
  id: totrans-254
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE70]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Find the number of non-zero elements. This is useful so you can convert on-the-fly
    to the SparseVector if the density ID is low:'
  id: totrans-256
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE71]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Get all the values stored in the Matrix:'
  id: totrans-258
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE72]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'There are other calls corresponding to the specific operation for the SparseMatrix.
    The following is a sample, but we strongly recommend that you familiarize yourself
    with the manual pages (see the *There''s more...* section):'
  id: totrans-260
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Get Row Indexes: `int rowIndices()`'
  id: totrans-261
  prefs:
  - PREF_OL
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Check for transposition: `booleanisTransposed()`'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Get Column pointers: `int[]colPtrs()`
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There's more...
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To reiterate, in a lot of machine learning applications, you end up dealing
    with sparsity due to the large dimensional nature of the feature space that is
    not linearly distributed. To illustrate, we take the simplest case in which we
    have 10 customers indicating their affinity for four themes in the product line:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Theme 1** | **Theme 2** | **Theme 3** | **Theme 4** |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
- en: '| **Cust 1** | 1 | 0 | 0 | 0 |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
- en: '| **Cust 2** | 0 | 0 | 0 | 1 |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
- en: '| **Cust 3** | 0 | 0 | 0 | 0 |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
- en: '| **Cust 4** | 0 | 1 | 0 | 0 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
- en: '| **Cust 5** | 1 | 1 | 1 | 0 |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
- en: '| **Cust 6** | 0 | 0 | 0 | 0 |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
- en: '| **Cust 7** | 0 | 0 | 1 | 0 |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
- en: '| **Cust 8** | 0 | 0 | 0 | 0 |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
- en: '| **Cust 9** | 1 | 0 | 1 | 1 |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| **客户9** | 1 | 0 | 1 | 1 |'
- en: '| **Cust 10** | 0 | 0 | 0 | 0 |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| **客户10** | 0 | 0 | 0 | 0 |'
- en: As you can see, most of the elements are 0 and storing them as a dense matrix
    is not desirable while we increase the number of customers and themes to tens
    of millions (M x N). The SparseVector and matrix help with the storage and operation
    of these sparse structures in an efficient way.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，大部分元素都是0，当我们增加客户和主题的数量到数千万（M x N）时，将它们存储为密集矩阵是不可取的。SparseVector和矩阵有助于以高效的方式存储和操作这些稀疏结构。
- en: See also
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation for constructor is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseMatrix.html#constructor_summary)
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseMatrix.html#constructor_summary)找到
- en: Documentation for method calls is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseMatrix.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseMatrix.html#method_summary)
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方法调用的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseMatrix.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/SparseMatrix.html#method_summary)找到
- en: Performing vector arithmetic using Spark 2.0
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spark 2.0进行向量运算
- en: In this recipe, we explore vector addition in the Spark environment using the
    `Breeze` library for underlying operations. Vectors allow us to collect features
    and then manipulate them via linear algebra operations such as add, subtract,
    transpose, dot product, and so on.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们使用`Breeze`库进行底层操作，探索了在Spark环境中进行向量加法的方法。向量允许我们收集特征，然后通过线性代数运算（如加法、减法、转置、点积等）对其进行操作。
- en: How to do it...
  id: totrans-283
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作步骤...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入向量和矩阵操作所需的包：
- en: '[PRE73]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Set up the Spark session and application parameters so Spark can run:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置Spark会话和应用程序参数，以便Spark可以运行：
- en: '[PRE74]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'We create the Vectors:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建向量：
- en: '[PRE75]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'We convert the vectors from the Spark public interface to a `Breeze` (library)
    artifact so we can use a rich set of operators provided for Vector manipulation:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将向量从Spark公共接口转换为`Breeze`（库）工件，以便使用丰富的向量操作符：
- en: '[PRE76]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Let's look at the output and understand the results. For an operational understanding
    of vector addition, subtraction, and multiplication, see the *How it works...*
    section in this recipe.
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看一下输出并理解结果。要了解向量加法、减法和乘法的操作原理，请参阅本教程中的*How it works...*部分。
- en: 'The output is as follows:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE77]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Vector operations using both sparse and dense vectors with the Breeze library
    conversion are:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Breeze库转换的稀疏和密集向量的向量操作包括：
- en: '[PRE78]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'This is an alternate way, but it has the drawback of using a private function
    (see the actual source code for Spark 2.x.x itself). We recommend the method presented
    previously:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种替代方法，但它的缺点是使用了一个私有函数（请参阅Spark 2.x.x的实际源代码）。我们建议使用之前介绍的方法：
- en: '[PRE79]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'We take a look at the output:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看一下输出：
- en: '[PRE80]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: How it works...
  id: totrans-302
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作原理...
- en: Vectors are mathematical artifacts that allow us to express magnitude and direction.
    In machine learning, we collect object/user preferences into vectors and matrices
    in order to take advantage of distributed operations at scale.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 向量是数学工件，允许我们表达大小和方向。在机器学习中，我们将对象/用户的偏好收集到向量和矩阵中，以便利用分布式操作规模化。
- en: Vectors are tuples of numbers usually corresponding to some attributes collected
    for machine learning algorithms. The vectors are usually real numbers (measured
    values), but many times we use binary values to show the presence or absence of
    a preference or bias for a particular topic.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 向量通常是一些属性的元组，通常用于机器学习算法。这些向量通常是实数（测量值），但很多时候我们使用二进制值来表示对特定主题的偏好或偏见的存在或不存在。
- en: 'A vector can be thought of as either a row vector or a column vector. The column
    vector presentation is more suitable for ML thinking. The column vector is represented
    as follows:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 向量可以被看作是行向量或列向量。列向量的表示更适合于机器学习思维。列向量表示如下：
- en: '![](img/00047.jpeg)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00047.jpeg)'
- en: 'The row vector is represented as follows:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 行向量表示如下：
- en: '![](img/00048.jpeg)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00048.jpeg)'
- en: 'Vector addition is represented as follows:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 向量加法表示如下：
- en: '![](img/00049.gif)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00049.gif)'
- en: 'Vector subtraction is represented as follows:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 向量减法表示如下：
- en: '![](img/00050.gif)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00050.gif)'
- en: 'Vector multiplication or "dot" product is represented as follows:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 向量乘法或“点”积表示如下：
- en: '![](img/00051.jpeg)![](img/00052.gif)'
  id: totrans-314
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00051.jpeg)![](img/00052.gif)'
- en: There's more...
  id: totrans-315
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The public interfaces offered by the Spark ML and MLlib library, whether used
    for sparse or dense vectors, currently lacks the necessary operators to do full
    vector arithmetic. We must convert our local vectors to the `Breeze` library vector
    to have the operators available for linear algebra.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: Spark ML和MLlib库提供的公共接口，无论是用于稀疏向量还是密集向量，目前都缺少进行完整向量运算所需的运算符。我们必须将我们的本地向量转换为`Breeze`库向量，以便使用线性代数运算符。
- en: Prior to Spark 2.0, the method for conversion to `Breeze` (`toBreeze`) was available
    to use, but now the method has changed to `asBreeze()` and made private! A quick
    read of the source code is necessary to understand the new paradigm. Perhaps the
    change reflects Spark's core developers' desire to have less dependency on an
    underlying `Breeze` library.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark 2.0之前，转换为`Breeze`（`toBreeze`）的方法是可用的，但现在该方法已更改为`asBreeze()`并且变为私有！需要快速阅读源代码以了解新的范式。也许这种变化反映了Spark核心开发人员希望减少对底层`Breeze`库的依赖。
- en: If you are using any version of Spark prior to Spark 2.0 (Spark 1.5.1 or 1.6.1),
    use the following code snippets for conversion.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用的是Spark 2.0之前的任何版本（Spark 1.5.1或1.6.1），请使用以下代码片段进行转换。
- en: 'Pre-Spark 2.0 example 1:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 2.0之前的示例1：
- en: '[PRE81]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Pre-spark 2.0 example 2:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 2.0之前的示例2：
- en: '[PRE82]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: See also
  id: totrans-323
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: '`Breeze` library documentation is available at [http://www.scalanlp.org/api/breeze/#breeze.package](http://www.scalanlp.org/api/breeze/#breeze.package)'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Breeze`库文档可在[http://www.scalanlp.org/api/breeze/#breeze.package](http://www.scalanlp.org/api/breeze/#breeze.package)找到'
- en: '`Linalg` library documentation is available at [https://spark.apache.org/docs/latest/api/java/allclasses-noframe.html](https://spark.apache.org/docs/latest/api/java/allclasses-noframe.html)'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Linalg`库文档可在[https://spark.apache.org/docs/latest/api/java/allclasses-noframe.html](https://spark.apache.org/docs/latest/api/java/allclasses-noframe.html)找到'
- en: Performing matrix arithmetic using Spark 2.0
  id: totrans-326
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spark 2.0执行矩阵运算
- en: In this recipe, we explore matrix operations such as addition, transpose, and
    multiplication in Spark. The more complex operations such as inverse, SVD, and
    so on, will be covered in future sections. The native sparse and dense matrices
    for the Spark ML library provide multiplication operators so there is no need
    to convert to `Breeze` explicitly.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们探讨了Spark中的矩阵操作，如加法、转置和乘法。更复杂的操作，如逆、SVD等，将在未来的章节中介绍。Spark ML库的本机稀疏和密集矩阵提供了乘法运算符，因此不需要显式转换为`Breeze`。
- en: Matrices are the workhorses of distributed computing. ML features that are collected
    can be arranged in a matrix configuration and operated at scale. Many of the ML
    methods such as **ALS** (**Alternating Least Square**) and **SVD** (**Singular
    Value Decomposition**) rely on efficient matrix and vector operations to achieve
    large-scale machine learning and training.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵是分布式计算的工作马。收集的ML特征可以以矩阵配置的形式进行排列，并在规模上进行操作。许多ML方法，如**ALS**（**交替最小二乘法**）和**SVD**（**奇异值分解**），依赖于高效的矩阵和向量操作来实现大规模机器学习和训练。
- en: How to do it...
  id: totrans-329
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的包进行向量和矩阵操作：
- en: '[PRE83]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Set up the Spark session and application parameters so Spark can run:'
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置Spark会话和应用程序参数，以便Spark可以运行：
- en: '[PRE84]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'We create the matrices:'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建了矩阵：
- en: '[PRE85]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Multiply the matrix and vector and print the results. This is an extremely
    useful operation which becomes a common theme in most Spark ML cases. We use a
    `SparseMatrix` to demonstrate the fact that the Dense, Sparse, and Matrix are
    interchangeable and only the density (for example, the percent of non-zero elements)
    and performance should be the criteria for selection:'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将矩阵和向量相乘并打印结果。这是一个非常有用的操作，在大多数Spark ML案例中都是一个常见主题。我们使用`SparseMatrix`来演示密集、稀疏和矩阵是可互换的，只有密度（例如非零元素的百分比）和性能应该是选择的标准：
- en: '[PRE86]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'The output is as follows:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE87]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: Multiplying a `DenseMatrix` with `DenseVector`.
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`DenseMatrix`与`DenseVector`相乘。
- en: 'This is provided for completeness and will help the user to follow the matrix
    and vector multiplication more easily without worrying about sparsity:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 这是为了完整性考虑，将帮助用户更轻松地跟随矩阵和向量乘法，而不用担心稀疏性：
- en: '[PRE88]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'The output is as follows:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE89]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: We demonstrate the transposing of a Matrix, which is an operation to swap rows
    with columns. It is an important operation and used almost on a daily basis if
    you are involved in Spark ML or data engineering.
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们演示了矩阵的转置，这是一种交换行和列的操作。如果你参与Spark ML或数据工程，这是一个重要的操作，几乎每天都会用到。
- en: 'Here we demonstrate two steps:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们演示了两个步骤：
- en: 'Transposing a `SparseMatrix` and examining the new resulting matrix via the
    output:'
  id: totrans-348
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将稀疏矩阵转置并通过输出检查新的结果矩阵：
- en: '[PRE90]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'The output is as follows:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE91]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'Demonstrating that the transpose of a transpose yields the original matrix:'
  id: totrans-352
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 演示转置的转置产生原始矩阵：
- en: '[PRE92]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'The output is as follows:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE93]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'Transposing a dense matrix and examining the new resulting matrix via the output:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 转置密集矩阵并通过输出检查新的结果矩阵：
- en: 'This makes it easier to see how row and column indexes are swapped:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 这样更容易看到行和列索引是如何交换的：
- en: '[PRE94]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: We now look at matrix multiplication and how it would look in code.
  id: totrans-359
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们来看矩阵乘法以及在代码中的表现。
- en: 'We declare two 2x2 Dense Matrices:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 我们声明了两个2x2的密集矩阵：
- en: '[PRE95]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'The output is as follows:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE96]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: How it works...
  id: totrans-364
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: A matrix can be thought of as columns of vectors. Matrices are the power tools
    for distributed computation involving linear algebra transformation. A variety
    of attributes or feature representation can be collected and operated upon via
    matrices.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵可以被看作是向量的列。矩阵是涉及线性代数变换的分布式计算的强大工具。可以通过矩阵收集和操作各种属性或特征表示。
- en: 'In short, matrices are two-dimensional *m x n* arrays of numbers (usually real
    numbers) whose elements can be referenced using a two-element subscript, *i* and
    *j*:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，矩阵是二维*m x n*数组，其中元素可以使用两个元素的下标*i*和*j*来引用（通常是实数）：
- en: 'A matrix is represented as follows:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵表示如下：
- en: '![](img/00053.gif)'
  id: totrans-368
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00053.gif)'
- en: 'A matrix transpose is represented as follows:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵转置表示如下：
- en: '![](img/00054.jpeg)'
  id: totrans-370
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00054.jpeg)'
- en: 'Matrix multiplication is represented as follows:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵乘法表示如下：
- en: '![](img/00055.gif)'
  id: totrans-372
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00055.gif)'
- en: 'Vector matrix multiplication or "dot" product is represented as follows:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 向量矩阵乘法或“点”积表示如下：
- en: '![](img/00056.gif)![](img/00057.gif)'
  id: totrans-374
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00056.gif)![](img/00057.gif)'
- en: '*Distributed matrices in the Spark 2.0 ML library*: In the next four recipes,
    we will cover the four types of distributed matrices in Spark. Spark provides
    full support for distributed matrices baked by RDDs right out of the box. The
    fact that Spark supports distributed computing does not relieve the developer
    from planning their algorithms with parallelism in mind.'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: The underlying RDDs provide full parallelism and fault tolerance over the underlying
    data that is stored in the matrix. Spark is bundled with MLLIB and LINALG, which
    jointly provide a public interface and support for matrices that are not local
    and need full cluster support due to their size or complexity of chained operations.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: 'Spark ML provides four types of distributed matrices to support parallelism:
    `RowMatrix`, `IndexedRowMatrix`, `CoordinateMatrix`, and `BlockMatrix`:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: '`RowMatrix`: Represents a row-oriented distributed matrix compatible with ML
    library'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`IndexedRowMatrix`: Similar to `RowMatrix` with one additional benefit of indexing
    the rows. This is a specialized version of `RowMatrix` in which the matrix itself
    is created from the RDD of `IndexedRow` (Index, Vector) data structure. To visualize
    it, imagine a matrix where each row is a pair (long, RDD) and the work of pairing
    them (`zip` function) is done for you. This will allow you to carry the Index
    together with the RDD along its computational path in a given algorithm (matrix
    operations at scale)'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CoordinateMatrix`: A very useful format which is used for coordinates (for
    example, *x*, *y*, *z* coordinates in a projection space)'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BlockMatrix`: A distributed matrix made of blocks of locally maintained matrices'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We cover the creation of the four types in a brief recipe and then quickly move
    to a more complicated (code and concept) use case involving `RowMatrix` which
    is a typical ML use case involving a massively parallel distributed matrix operation
    (for example, multiplication) with a local matrix.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: If you plan to code or design large matrix operations, you must dig into the
    Spark internals such as core Spark and how staging, pipelining, and shuffling
    works in each version of Spark (continuous improvement and optimization in each
    version).
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: 'We also recommend the following before embarking on a large-scale matrix and
    optimization journey:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: The source for matrix computations and optimization in Apache Spark is available
    at [http://www.kdd.org/kdd2016/papers/files/adf0163-bosagh-zadehAdoi.pdf](http://www.kdd.org/kdd2016/papers/files/adf0163-bosagh-zadehAdoi.pdf)
    and [https://pdfs.semanticscholar.org/a684/fc37c79a3276af12a21c1af1ebd8d47f2d6a.pdf](https://pdfs.semanticscholar.org/a684/fc37c79a3276af12a21c1af1ebd8d47f2d6a.pdf).
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: The source for efficient large scale distributed matrix computation with Spark
    is available at [https://www.computer.org/csdl/proceedings/big-data/2015/9926/00/07364023.pdf](https://www.computer.org/csdl/proceedings/big-data/2015/9926/00/07364023.pdf)
    and [http://dl.acm.org/citation.cfm?id=2878336&preflayout=flat](http://dl.acm.org/citation.cfm?id=2878336&preflayout=flat)
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: The source for exploring matrix dependency for efficient distributed matrix
    computation is available at [http://net.pku.edu.cn/~cuibin/Papers/2015-SIGMOD-DMac.pdf](http://net.pku.edu.cn/~cuibin/Papers/2015-SIGMOD-DMac.pdf)
    and [http://dl.acm.org/citation.cfm?id=2723712](http://dl.acm.org/citation.cfm?id=2723712)
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: Exploring RowMatrix in Spark 2.0
  id: totrans-388
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we explore the `RowMatrix` facility that is provided by Spark.
    `RowMatrix`, as the name implies, is a row-oriented matrix with the catch being
    the lack of an index that can be defined and carried through the computational
    life cycle of a `RowMatrix`. The rows are RDDs which provide distributed computing
    and resiliency with fault tolerance.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: The matrix is made of rows of local vectors that are parallelized and distributed
    via RDDs. In short, each row will be an RDD, but the total number of columns will
    be limited by the maximum size of a local vector. This is not an issue in most
    cases, but we felt we should mention it for completion.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-391
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'Set up the Spark context and application parameters so Spark can run. See the
    first recipe in the chapter for more details and variations:'
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE98]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'The amount and timing of warning statements returned as output varies due to
    the nature of distributed computing (non-sequential) with distributed matrices.
    The interlacing of messages with actual output varies depending on the execution
    path and that results in hard to read output. In the following statements, we
    elevate the `log4j` messages from warning (WARN - out of the box) to errors (ERROR)
    for clarity. We suggest that the developer follows the warning messages in detail
    to grasp the parallel nature of these operations and to fully understand the concept
    of an RDD:'
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE99]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'Set the level to error:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: Originally comes out the box like this
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: We define two sequence data structures of dense vectors.
  id: totrans-403
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A Scala sequence of dense local vectors which will be the data for the distributed
    `RowMatrix`:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'A Scala sequence of dense local vectors which will be the data for the local
    identity matrix. A quick check of linear algebra shows that any matrix multiplied
    by an identity matrix will yield the same original matrix (that is, *A x I = A*).
    We like to use the identity matrix to prove that the multiplication worked and
    the original statistic computed over the original matrix is the same as the original
    *x* identity:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: Create our first distributed matrix by parallelizing the underlying dense vectors
    to RDDs.
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Going forward, our dense vectors are now rows in the new distributed vectors
    backed by RDD (that is, all RDD operations are fully supported!).
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: 'Take the original Sequences (made of vectors) and turn them into RDDs. We will
    cover RDDs in detail in the next chapter. In this single statement, we have turned
    a local data structure to a distributed artifact:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: 'We calculate some basic statistics to verify that the `RowMatrix` is constructed
    properly. The point to remember is that the dense vectors are now rows and not
    columns (which is the source of much confusion):'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  id: totrans-413
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'The output is as follows:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: The statistics calculated (mean, variance, min, max, and so on) are for each
    column and not the entire matrix. This is the reason you see three numbers for
    mean and variance which corresponds to each column.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: 'In this step, we create our local matrix from the identity vector''s data structure.
    The point to remember is that the multiplication requires a local matrix and not
    a distributed one. Please see the call signature for verification. We use the
    `map`, `toArray`, and `flatten` operators to create a Scala flattened array data
    structure that can be used as one of the parameters to create a local matrix as
    shown in the next step:'
  id: totrans-417
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE107]'
  id: totrans-418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'We create the local matrix as an identity matrix so we can verify the multiplication
    *A * I = A*:'
  id: totrans-419
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE108]'
  id: totrans-420
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: 'We multiply the distributed matrix by the local one and create a new distributed
    matrix. This is a typical use case in which you end up multiplying a tall and
    skinny local matrix with a large-scale distributed matrix to achieve scale and
    the inherited dimensionality reduction of the resulting matrix:'
  id: totrans-421
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE109]'
  id: totrans-422
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: Comparing step 7 and 8, we see that in fact the operation proceeded correctly
    and we can verify via descriptive statistics and the co-variance matrix that *A
    x I = A* using a distributed and local matrix.
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The output is as follows:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  id: totrans-425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: How it works...
  id: totrans-426
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The signatures for this method constructor are:'
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`RowMatrix(RDD<Vector> rows)`'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RowMatrix(RDD<Vector>, long nRows, Int nCols)`'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The method inherits from the following which makes their concrete methods available
    to all routines:'
  id: totrans-430
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: interface class java.lang.Object
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Implements the following interfaces:'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Distributed matrix
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are several method calls that are of interest:'
  id: totrans-435
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Calculate descriptive statistics such as mean, min, max, variance, and so on:'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MultivariateStatisticalSummary`'
  id: totrans-437
  prefs:
  - PREF_OL
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: '`computeColumnSummaryStatistics()`'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Compute the co-variance matrix from the original:'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Matrix computeCovariance()`'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compute the Gramian matrix, also referred to as the Gram Matrix
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(*A^TA* ):'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: '``Matrix computeGramianMatrix()``'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Calculate the PCA components:'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Matrix computePrincipalComponents(int k)`'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*k* is the number of principal components'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculate the SVD decomposition of the original matrix:'
  id: totrans-447
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SingularValueDecomposition<RowMatrix, Matrix> computeSVD(int k, boolean compute,
    double rCond)`'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*k* is the number of leading singular values to keep (*0<k<=n*).'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: 'Multiply:'
  id: totrans-450
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RowMatrix Multiply(Matrix B)`'
  id: totrans-451
  prefs:
  - PREF_OL
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rows:'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RDD<Vector> rows()`'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Calculate the QR decomposition:'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`QRDecomposition<RowMatrix, Matrix> tallSkinnyQR(boolean computeQ))`'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Find the number of non-zero elements. This is useful so you can convert on-the-fly
    to the SparseVector if the density ID is low:'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Int numNonzeros()`'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Get all the values stored in the matrix:'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Double[] Values()`'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Others:'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculate the column similarities (very useful in document analysis). There
    are two methods available which are covered in the [Chapter 12](part0512.html#F89000-4d291c9fed174a6992fd24938c2f9c77), *Implementing
    Text Analytics with Spark 2.0 ML Library*
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of columns and number of rows which we find useful for dynamic programming
  id: totrans-462
  prefs:
  - PREF_OL
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: There's more...
  id: totrans-463
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are some additional factors to consider when you use sparse or dense elements
    (vectors or block matrices). Multiplying by a local matrix is usually preferable
    since it doesn't require expensive shuffling.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: 'While simplicity and control is preferred when dealing with large matrices,
    the four types of distributed matrices simplify the setup and operation. Each
    of the four types has advantages and disadvantages that have to be considered
    and weighed against these three criteria:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
- en: Sparsity or Density of underlying data
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shuffling that will take place when using these facilities.
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network capacity utilization when dealing with edge cases
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the reasons mentioned, and especially to reduce the shuffling (that is,
    a network bottleneck) required during a distributed matrix operation (for example,
    multiplication of two RowMatrixes), we prefer multiplication with a local matrix
    to reduce shuffle noticeably. While this seems a bit counter-intuitive at first,
    in practice it is fine for the cases we have encountered. The reason for this
    is because when we multiply a large matrix with a vector or tall and skinny matrix,
    the resulting matrix is small enough that fits into the memory.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
- en: The other point of caution will be that the returning information (a row or
    local matrix) has to be small enough so it can be returned to the driver.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
- en: For imports, we need both local and distributed vector and matrix imports so
    we can work with the ML library. Otherwise, the Scala vector and matrix will be
    used by default.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
- en: See also
  id: totrans-472
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Documentation for constructor is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/RowMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/RowMatrix.html#constructor_summary)
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Documentation for method calls is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/RowMatrix.html#method_summary](https://spark.apache.org/docs/1.5.2/api/java/org/apache/spark/mllib/linalg/distributed/RowMatrix.html#method_summary)
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring Distributed IndexedRowMatrix in Spark 2.0
  id: totrans-475
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we cover the `IndexRowMatrix`, which is the first specialized
    distributed matrix that we cover in this chapter. The primary advantage of `IndexedRowMatrix`
    is that the index can be carried along with the row (RDD), which is the data itself.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
- en: In the case of `IndexRowMatrix`, we have an index defined by the developer which
    is permanently paired with a given row that is very useful for random access cases.
    The index not only helps with random access, but is also used for identifying
    the row itself when performing `join()` operations.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-478
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-479
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-480
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE111]'
  id: totrans-481
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: 'Set up the Spark context and application parameters so Spark can run. See the
    first recipe in the chapter for more details and variations:'
  id: totrans-482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE112]'
  id: totrans-483
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: We start with our original data vectors and then proceed to construct an appropriate
    data structure (that is, RowIndex) to house the index and vector.
  id: totrans-484
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We then proceed to construct the `IndexedRowMatrix` and show the access. For
    those of you who have worked with LIBSVM, this format is close to label and vector
    artifacts with a twist that labels are now indexes (that is, long).
  id: totrans-485
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Start with a sequence of vectors as the base data structure for `IndexedRowMatrix`:'
  id: totrans-486
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE113]'
  id: totrans-487
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: 'Start with a sequence of vectors as the base data structure for `IndexedRowMatrix`:'
  id: totrans-488
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE114]'
  id: totrans-489
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: 'The output is as follows:'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  id: totrans-491
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: How it works...
  id: totrans-492
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The index is a long data structure which provides a meaningful row index corresponding
    to each row of the `IndexedRowMatrix`. The horsepower underneath the implementation
    are the RDDs which offer all the advantages of a distributed resilient data structure
    in a parallel environment from the get go.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
- en: The primary advantage of `IndexedRowMatrix` is that the index can be carried
    along with the row (RDD) which is the data itself. The fact that we can define
    and carry along the index with the data (the actual row of matrix) is very useful
    when we have the `join()` operation that needs a key to select a specific row
    of data.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows a pictorial view of the `IndexedRowMatrix` which
    should help clarify the subject:'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00058.jpeg)'
  id: totrans-496
  prefs: []
  type: TYPE_IMG
- en: 'The definition may be unclear as you are required to repeatedly define the
    index and the data to compose the original matrix. The following code snippet
    shows the inner list with (index, Data) repetition for reference:'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  id: totrans-498
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: The other operations are similar to the `IndexRow` matrix that was covered in
    the previous recipe.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
- en: See also
  id: totrans-500
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Documentation for constructor is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#constructor_summary)
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Documentation for method calls is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#method_summary)
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring distributed CoordinateMatrix in Spark 2.0
  id: totrans-503
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we cover the second form of specialized distributed matrix.
    This is very handy when dealing with ML implementations that need to deal with
    often large 3D coordinate systems (x, y, z). It is a convenient way to package
    the coordinate data structure into a distributed matrix.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-505
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  id: totrans-506
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-507
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE117]'
  id: totrans-508
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: 'Set up the Spark context and application parameters so Spark can run. See the
    first recipe in the chapter for more details and variations:'
  id: totrans-509
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE118]'
  id: totrans-510
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'We start with a SEQ of `MatrixEntry`, which corresponds to each coordinate
    and will be placed in the `CoordinateMatrix`. Note that the entries cannot be
    real numbers any more (they are x, y, z coordinates after all):'
  id: totrans-511
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE119]'
  id: totrans-512
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: 'We instantiate the call and construct the `CoordinateMatrix`. We need an additional
    step to create RDDs which we have shown in the constructor by using the Spark
    context for parallelization (that is, `sc.parallelize`):'
  id: totrans-513
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE120]'
  id: totrans-514
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: 'We print the first `MatrixEntry` to verify the matrix elements. We will address
    RDDs in the next chapter, but note that `count()` is an action by itself and using
    `collect()` will be redundant:'
  id: totrans-515
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE121]'
  id: totrans-516
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: 'The output is as follows:'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  id: totrans-518
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: How it works...
  id: totrans-519
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`CoordinateMatrix` is a specialized matrix in which each entry is a coordinate
    system or a tuple of three numbers (long, long, long corresponding to *x*, *y*,
    *z* coordinates). A related data structure is `MatrixEntry`, in which coordinates
    will be stored and then placed at a location in the `CoordinateMatrix`. The following
    code snippet demonstrates the use of `MaxEntry`, which seems to be a source of
    confusion in itself.'
  id: totrans-520
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following figure shows a pictorial view of the `CoordinateMatrix`, which
    should help clarify the subject:'
  id: totrans-521
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00059.jpeg)'
  id: totrans-522
  prefs: []
  type: TYPE_IMG
- en: 'The code snippet which holds three coordinates is:'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE123]'
  id: totrans-524
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: '`MaxEntry` is nothing but a required structure to hold the coordinate. Unless
    you need to modify the source code supplied by Spark (see GitHub `CoordinateMatrix.scala`)
    to define a more specialized container (compressed), there is no need to understand
    it any further:'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
- en: The `CoordinateMatrix` is also backed by RDDs which lets you leverage parallelism
    from the get go.
  id: totrans-526
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
- en: You need to import `IndexedRow` as well so you can define the row with its index
    prior to instantiating the `IndexedRowMatrix`.
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This matrix can be converted to `RowMatrix`, `IndexedRowMatrix`, and `BlockMatrix`.
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is also an added benefit of efficient storage, retrieval, and operation
    that comes with a sparse coordinate system (for example, security threat matrix
    of all devices versus location).
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
- en: See also
  id: totrans-530
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Documentation for constructor is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#constructor_summary)
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Documentation for method calls is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#method_summary)
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Documentation for MaxEntry is available at [http://spark.apache.org/docs/latest/api/java/index.html](http://spark.apache.org/docs/latest/api/java/index.html)
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring distributed BlockMatrix in Spark 2.0
  id: totrans-534
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we explore `BlockMatrix`, which is a nice abstraction and a
    placeholder for the block of other matrices. In short, it is a matrix of other
    matrices (matrix blocks) which can be accessed as a cell.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE124]'
  id: totrans-536
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: How to do it...
  id: totrans-537
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Start a new project in IntelliJ or in an editor of your choice and make sure
    all the necessary JAR files (Scala and Spark) are available to your application.
  id: totrans-538
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the necessary packages for vector and matrix manipulation:'
  id: totrans-539
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE125]'
  id: totrans-540
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: 'Set up the Spark context and application parameters so Spark can run. See the
    first recipe in this chapter for more details and variations:'
  id: totrans-541
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE126]'
  id: totrans-542
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: 'Create a `CoordinateMatrix` quickly to use as a base for conversion:'
  id: totrans-543
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE127]'
  id: totrans-544
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: 'We take the `CoordinateMatrix` and convert it into a `BlockMatrix`:'
  id: totrans-545
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE128]'
  id: totrans-546
  prefs: []
  type: TYPE_PRE
  zh: '[PRE128]'
- en: 'This is a very useful call with this type of matrix. In real life, it is often
    necessary to check the setup before proceeding to compute:'
  id: totrans-547
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE129]'
  id: totrans-548
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: 'The output is as follows:'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE130]'
  id: totrans-550
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: How it works...
  id: totrans-551
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A matrix block will be defined as a tuple of (int, int, Matrix). What is unique
    about this matrix is that it has `Add()` and `Multiply()` functions that can take
    another `BlockMatrix` as a second parameter to the distributed matrix. While setting
    it up is a bit confusing at first (especially on-the-fly as data arrives), there
    are helper functions that can help you verify your work and make sure the `BlockMatrix`
    is set up properly. This type of matrix can be converted to a local, `IndexRowMatrix`,
    and `CoordinateMatrix`. One of the most common use cases for the `BlockMatrix`
    is to have a `BlockMatrix` of `CoordinateMatrices`.
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵块将被定义为（int，int，Matrix）的元组。这种矩阵的独特之处在于它具有`Add()`和`Multiply()`函数，这些函数可以将另一个`BlockMatrix`作为分布式矩阵的第二个参数。虽然一开始设置它有点令人困惑（特别是在数据到达时），但有一些辅助函数可以帮助您验证您的工作，并确保`BlockMatrix`被正确设置。这种类型的矩阵可以转换为本地的`IndexRowMatrix`和`CoordinateMatrix`。`BlockMatrix`最常见的用例之一是拥有`CoordinateMatrices`的`BlockMatrix`。
- en: See also
  id: totrans-553
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation for constructor is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#constructor_summary)
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#constructor_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#constructor_summary)找到。
- en: Documentation for method calls is available at [https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#method_summary)
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方法调用的文档可在[https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#method_summary](https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/linalg/distributed/BlockMatrix.html#method_summary)找到。
