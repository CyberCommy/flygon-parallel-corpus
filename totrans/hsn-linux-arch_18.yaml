- en: Getting Your Hands Salty
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After going through the basic concepts of **Salt**, we will finally in this
    chapter get hands-on with Salt. We will have the chance to work on a real-life
    scenario and to design and install proof-of-concept infrastructure for our potential
    customer. We will do such things as the following:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning cloud infrastructure via Terraform
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing and configuring Salt masters
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing and configuring minions
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating states and formulas for minions
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provisioning a load balancer via Salt
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After performing these tasks, you should have the basic knowledge and hands-on
    experience to start learning Salt more in depth.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Hands-on with Salt
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have learned about the different Salt components and capabilities that the
    software has, and how it can help us to achieve control of our infrastructure.
    But we haven't used any of the components to actually maintain any system or even
    install Salt. So, let's get our hands dirty with Salt and start making use of
    our newly acquired knowledge.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Before starting, we are going to set up a scenario to make more sense of what
    we will be doing in this chapter, and it will be related to a real-life scenario.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Scenario
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You have been hired by Mr. Don High to design the system's management platform
    for his company. He wants to run his web server workloads on Azure **Virtual Machines**
    (**VMs**), with an **Infrastructure as a Service** (**IaaS**) model.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: 'His setup is fairly simple: he wants to have two virtual machines running a
    website written in `Node.js` in front of an nginx load balancer to route the traffic
    into the website''s VMs. All of his infrastructure has to be managed via a configuration
    management solution, in a way that, every time they provision a new VM, the application
    is loaded alongside any configuration that might be needed for their website to
    run.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: One more thing that he mentioned to you is that the company's staff haven't
    deployed any resources in Azure, and that they would like to see how **Infrastructure
    as Code** (**IaC**) works for deployments in the cloud, so that their developers
    are able to use it in the future.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Terraforming our initial infrastructure
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We mentioned **Terraform** in the previous chapter, and we want to take advantage
    of the fact that our client is asking us to deploy his infrastructure via an IaC
    software, so this is the perfect chance to use this great tool.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: We will briefly explain each step before executing it, but if you would like to
    find out more, we will suggest more books in the *Further reading* section that
    talk more in depth about Terraform.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Terraform
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will assume that you will be executing the following steps from a Unix-like
    workstation. Installing Terraform is fairly simple. Terraform is only a binary
    that can be downloaded from the `terraform.io` website.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.terraform.io/downloads.html](https://www.terraform.io/downloads.html)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: 'In my case, I will be using a macOS Terminal to install Terraform:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/feabe7e2-a66a-428a-931c-9ccbbdb755bb.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
- en: 'Once downloaded, you can go ahead and unzip the binary in a directory part
    of your path:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5d5c9321-527e-4c2d-98d9-8bb819acce1b.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
- en: 'Check the Terraform version by running `terraform version`:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9dab0bb8-1b00-4e36-b1ec-018bd71ee8cb.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
- en: Once Terraform has been installed, we require the Azure CLI to be installed
    to configure access to the customer's Azure subscription. You can find the steps
    to install the Azure CLI and set up the subscription in our *Installing Kubernetes* chapters.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: With the Azure CLI installed and your default account set, we can configure
    Terraform to use the appropriate credentials in order for it to be able to deploy
    infrastructure.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will create a directory to store our Terraform files:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Next, we will create a service principal ID via the Azure CLI, which will be
    used to authenticate Terraform with our subscription.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: 'Save the subscription ID from the output of this command into a `$SUB_ID` variable:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, run the following command to create the service principal:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Take note of the returned values of `appId`, `password`, and `tenant` returned
    from the previous command.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Now, inside the `terrafiles` directory, create a file called `terraform.tfvars`.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: This file is special because Terraform will automatically load by default any
    file with this name if any is present in the directory when we execute Terraform.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: 'This file should contain the following information:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'When you have the file ready, create another file called `az_creds.tf` with
    the following:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This file will be our variables file, and it will load the credential variables
    into the Azure Resource Manager Terraform provider.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Creating IaC
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we are ready to start creating our IaC declaration files. Terraform uses
    its own language called **Hashicorp Configuration Language** (**HCL**). You can
    find out more about it in the following link: [https://www.terraform.io/docs/configuration/index.html](https://www.terraform.io/docs/configuration/index.html).'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Let's begin defining our resources. Create a file called `main.tf`*.* This will
    be our main modules file. A module is a set of resources that share a common goal
    or are all part of the same application.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: The name `main.tf`is the recommended name by Hashicorp, the company owner of
    the Terraform Open Source project, for a minimal module.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find out more about modules in the Terraform documentation here: [https://www.terraform.io/docs/modules/index.html](https://www.terraform.io/docs/modules/index.html).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Our file should contain all of the following resources that we will be declaring
    next.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the resource group that will contain our Azure resources:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here is the virtual network for our subnets:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Note that we are getting values from our previous resources, by calling them
    with the following syntax:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here is the subnet(s) with the address space for our VMs:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Here, we are creating only one subnet that will contain our masters and minions,
    but you can always create separate subnets, as long as they are inside the VNET
    address space, for the masters and minions to have network separation.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: With our virtual network and subnet created, we need to create the firewall
    rules for our virtual machines. Firewalls in Azure are called **network security
    groups**, and we will go ahead and use the network security group provider to
    create the firewall and its rules.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the network security group for the load balancer:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The following are the network security group rules for access to the load balancer
    VM.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: 'Ports for `https`:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Port for `http`:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Port for SSH `access`:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The second network security group for the master VM is as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The following are the network security group rules for the master VM.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the Salt `publisher` port:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following is the request server port for Salt:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The `ssh` port for the master is as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The network security group for the minions is as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This last network security group is special because we will not create any rules
    for it. The default rules that Azure provides only allow VMs to talk with Azure
    resources, which is exactly what we want for these VMs.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'A public IP address for our Nginx load balancer VM is as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The virtual network interface for our load balancer is as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The virtual network interfaces for our web server VMs are as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Following is the public IP address for our master VM:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This public IP address will be used for us to SSH into the master VM; that's
    why we are allocating it dynamically.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: 'The virtual network interface for the master VM is as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Following are the web server VMs:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Replace `os_profile.admin_username` and `os_profile_linux_config.key_data` with
    your own information.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: 'The master VM is as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Following is the Nginx load balancer VM:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Once you have saved the file with all of the previously created resources,
    run the `terraform init` command; this will initialize the current directory with
    the Terraform files and download the Azure Resource Manager plugin:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/93e5f877-3ccb-4d9a-8341-7c5856fe74e1.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
- en: If you want to learn more about the `init` command, you can go to [https://www.terraform.io/docs/commands/init.html](https://www.terraform.io/docs/commands/init.html).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: After running the `init` command, we will proceed to run the `terraform plan`
    command, which will calculate all of the changes necessary to achieve the desired
    state that we defined in our `tf` file.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: 'This will not make any changes to the existing infrastructure until we run
    the `terraform``apply` command:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a8664294-dfb1-4dac-b50f-0e8b9ba6c0c4.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
- en: For more information about the `plan` command, visit [https://www.terraform.io/docs/commands/plan.html](https://www.terraform.io/docs/commands/plan.html).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: 'Immediately after you have finished the `plan` command, you can go ahead and
    run `terraform apply` and you will be prompted with a confirmation to apply the
    changes:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dc8b2af1-fd20-4c75-88fe-34fda9b02123.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
- en: 'Once it is finished, you should be able to see the following message:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'There are two ways of installing Salt: you can either use a bootstrap script
    to install the masters and minions, or you can install and configure them manually
    via the Salt repositories.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: We will be covering both ways in order to familiarize ourselves with the install
    process.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Installing Salt with package managers
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our current infrastructure, we have one master and three minions. Our master
    and one minion are running CentOS 7.5 and the rest of the VMs are on Ubuntu 16.04\.
    The process will be sort of different on both distros but some steps will be the
    same on both.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: Installing CentOS yum
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Previously, Salt was only available through the EPEL repositories. But now SaltStack
    has its own repository that we can import and perform the install from there.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'First, install SSH into the master VM and run the following command to import
    the SaltStack repository:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Optionally, you can run `yum clean expire-cache`, but as this is a new VM, this
    is not necessary.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 'Once finished, we will go ahead and install the `salt-master` package:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Go ahead and enable the `systemd` salt-master service unit:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Check whether the service is running:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e769658e-a6f2-4b19-bccb-a448ec47b6f6.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
- en: 'Once the service is up and running, check whether the private IP of the VM
    is the one that we configured in our Terraform definitions by running the following:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Once you have the IP address confirmed, open another terminal and SSH into the
    load balancer minion. Repeat the process of adding the repository as we did in
    the master VM.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the repository is added, run the following command to install the `salt-minion`
    package:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Enable and start the `systemd` service unit by running this:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Let''s check whether the service started successfully before we implement any
    changes to it:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/825d4968-b0ff-44e2-9a6a-1f48c0e6d3e8.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
- en: We can see that we are getting errors on the service saying that the master
    has changed the public key and we are not unable to connect to the Salt master.
    We now need to configure the minion to talk to the master. But first, let's install
    the remaining two Ubuntu minions, because the process of registering the minions
    is the same on both distributions.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Ubuntu apt-getting Salt
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The only complicated part of this is that, due to the fact that our web servers
    do not have a public IP address assigned to them, you have to SSH to them from
    either the master VM or the load balancer VM. To do this, you can set up SSH key
    authentication to the minions from either of these two VMs. If you are reading
    this book, you will be familiar with how to perform such a task.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: When you log in to the web server VMs, perform the following task in both VMs.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the `gpg` key for the Salt repository:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1e052271-d854-4803-bf72-0f1141732e2f.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
- en: 'Run the following to create the repository:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Once the repository has been added, run `apt update`, and you should be able
    to see the repository listed:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4b4b29ec-0fb9-492b-a738-586bd3599e16.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
- en: 'Proceed to install the `salt-minion` package:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Enable and check the status of the `salt-minion` service by running the following:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: You should see the same messages we saw in the CentOS LB virtual machine.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Installing Salt via the bootstrap script
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The second way of installing Salt is via a **bootstrap script**. This script
    automatically detects our distribution and downloads the defined packages. The
    script also provides us with the `-A` flag, which will add the address of the
    master to our minions.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'To get the script, you can either use `wget` or `curl`; the official SaltStack
    uses `curl`:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: This script applies for both masters and minions; the difference is which flags
    you use when running the script.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: 'To install the master components, run the script with the `-M` flag for master
    and `-P` to allow any Python `pip` packages to be installed. We can also specify
    the master address with `-A` and tell the script not to install the minion service
    in the master with the `-N` flag:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'To install the minion, just run this:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Master and minion handshake
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: On this stage of the install, we will go ahead and allow our minions to talk
    to the master, verify their fingerprints, and set up configuration files.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: First, we will SSH into the master VM and edit the master's configuration file
    to tell the salt-master daemon to which IP we want it to bind.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: 'Edit the `/etc/salt/master` file, look for the `interface:` line, and add the
    master''s IP address:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b4c6833d-9ee3-48ef-8875-5dac0eb854b1.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
- en: 'After modifying the file, run the `daemon-reload` and `restart` commands so
    that the service acknowledges the changes:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'You can verify whether the Salt master is listening on the correct IP address
    by running an `ss` command:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9204ea5f-fd29-400e-9658-997a74380305.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
- en: Now that our master is listening on the IP address that we require, it's time
    to configure our minions.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: Let's start by modifying the minion's configuration file. Remember that these
    steps are to be performed on all of the minions regardless of their distribution.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: 'Look for the `/etc/salt/minion` file and edit it by adding the noted IP address
    of the master under `master:`. We will find an already-configured value: `master:
    salt`*; *this is because Salt, by default, looks for the master via a DNS query
    to the hostname, `salt`, but as we intend in the future to have more than one
    master, we will be setting this file with the static IP address of our master
    VM:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/119ef727-6f47-4379-ab79-30e57a5d9790.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
- en: Before our minions can exchange keys, we need to add the master's fingerprint
    into our minions' configuration file.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: 'SSH back to the master and run the following command to obtain your master''s
    public fingerprint:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2ad8c09e-e899-4e05-b0a0-1b694a2372d9.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
- en: 'Copy the value of `master.pub` and go back to editing the minion''s configuration
    file. In the minion''s configuration file, edit the `master_finger: '' ''` line
    with the master''s public key, obtained in the preceding step:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/457bff79-3eda-4ead-afe0-3d8ea04b6c68.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
- en: 'Reload and restart the minion daemon, once you have completed this last task:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Before exiting each minion, run the following command and take note of the
    minion''s fingerprint:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Once you have taken note of all of the minions' fingerprints, go ahead and log
    in to the master.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: In the master, we will compare the fingerprints that the master sees to the
    fingerprint that we saw locally on each minion. In this way, we will identify
    that the minions that we will be accepting are indeed our minions.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, run the following command in the master: `salt-key -F`. This will
    print all of the keys, so you don''t have to print each key individually:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6cbc1bd3-57c7-419a-b01d-ade25cef3e1b.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
- en: Make sure the keys are the same, and then we will proceed to accept the keys.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: 'Under the `salt-key -F` command, we saw that we have unaccepted keys to accept after
    verifying them; we will run `salt-key -A` to accept all of the pending keys and
    you can run `salt-key -L` to verify that the keys were accepted:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9e63d0bb-c9b8-4324-abda-1dcf5aeab75f.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
- en: Now that our minions have been authenticated, we can go ahead and issue commands
    from our master.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: 'To test our minions, we will invoke the `ping` function from the test module:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/62c648ed-d9c6-4e8c-b3f5-7580aec2204d.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
- en: All minions should respond `True`, meaning that the Salt minion daemon is responding
    and we are ready to begin managing our infrastructure.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: Working with Salt
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With our SaltStack up and running, we are ready to start creating the formulas
    and customized configurations for our VMs.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Creating WebServer formulas
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now be creating the necessary state files to create the formula that
    will install and configure our webservers.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we begin, we need to create our state tree first, which will contain
    all of our state files:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Inside this directory, we will be creating something called the `top.sls` file.
    This file is what tells Salt which states are applied to which minions. As for
    every definition in Salt, `top.sls` is a YAML- based file that will contain the
    minions to target and the state files that should be applied to those minions.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a file called `top.sls` in the `/srv/salt` directory with the following
    content:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '`base:` means the environment in which we are working on; as this is a simple
    environment, we only need the base environment; for working with multiple environments,
    you can consult one of the books we will suggest in the *Further reading* section.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Next, we have the `web*`entry; this entry tells Salt which minion IDs are going
    to be the states applied to. As you can see, you are able to use globbing to target
    minion IDs.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: Finally, `- webserver.nodejs` is where we indicate which states to apply; `webserver`indicates
    the folder in which the `nodejs.sls` file is in. As the YAML is read by the Python
    interpreter, we need to define the paths with periods (.) instead of slashes (`/`).
    The last word would be the name of the `.sls` file to load.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: 'Because we defined the `Node.js` file to be in a directory called `webserver`,
    which is the directory that we will be storing all of our web server state files,
    we need to create such a directory:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Now that we have the directory where we will store our state definitions, let''s
    create our first state definition that will install the `node.js` package and
    `npm`. Create a file called `nodejs.sls` in the `/srv/salt/webserver/` directory
    with the following content:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The `nodejs` field is the package to be installed, followed by the `pkg.installed` function
    to invoke.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: 'With the `state` file created, apply the `state` files to the web server minions:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'After a while, you will receive output with the applied changes and the duration:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c190431a-8901-4572-a771-31a159e753ce.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
- en: The output of the following example has been truncated for readability.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: With Node.JS installed, we need to create now the user for the Node.JS website
    to run on.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: We will create another state file that will define the user configuration.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: 'Create another file called `webuser.sls` under the `/srv/salt/webserver/` directory,
    with the following declaration:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Before executing the state, modify the `top.sls` file to reflect the newly
    added state file:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Execute the `salt ''*'' state.apply` command again, and you should receive
    the output of the user creation:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a4c327a2-dc6f-482c-b61c-fe50304b37be.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
- en: Now that we have the user that will be running the website, it's time to copy
    the website files into our website servers. For this, we will be creating another
    state file, which will use Git to download the website files and load them into
    the VM.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: 'Modify your `top.sls` file and add another state called `gitfetch` under the
    same web server directory, like this:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Now, proceed to create the `gitfetch.sls`file using the `git.latest` function
    to download the code from a Git repository and install the `Node.js` dependencies
    every time the repository is downloaded:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Go ahead and run the `state.apply`function again to download the application
    on both web servers. You should be able to see output similar to this after running
    the command:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/57ccb71f-cd5a-4e5f-a3e6-9ed585b01935.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
- en: With the code in our web servers, we are almost done with the configuration
    of our Ubuntu minions.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: We now require our Node.JS application to run as a daemon.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: 'For this, we will be using the Supervisor Open Source Project: [https://github.com/Supervisor/supervisor](https://github.com/Supervisor/supervisor).'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s configure Salt, to make `Supervisor` watch our Node.JS web application.
    Edit the `top.sls` file with the following line, as we have done before:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Before creating the `supervisor` state file, we first need to create the configuration
    file for `supervisor` that we are going to push to our minions. Create a file
    called `supervisor.conf` in the web server directory, with the following content:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Now create the `suppkg.sls` state file, which will be in charge of managing
    the previous configuration file, under the web server folder:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Once the file is created, go ahead and run the `salt 'web*' state.apply` command
    to apply the latest states.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: 'With this last state applied, our web application should be up and running.
    You can try accessing it via the `curl` command:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/16008511-4326-40d9-93f0-2217fe0f0660.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
- en: Now that our web servers are ready, we shall tag them as such. Remember in the
    previous chapter when we talked about grains. This is what we will be doing next.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: Let's go ahead and tag our `web-00` and `web-01` servers with the appropriate
    role tags.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, run the following command for each server:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/972a54da-2dcc-4f31-8cb0-058bfe8cf641.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
- en: 'You can check whether the roles were successfully applied by running the following
    `grep`:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1e6f0ed5-af0b-404a-9595-534b7ea5b304.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
- en: Creating load-balancing formulas
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that both our web servers are correctly set up, we can configure our last
    minion. This minion will be running Nginx in order to balance and proxy requests
    to our web servers behind the load balancer.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a directory where we will store all of the states for our load
    balancer:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'With the directory created, let''s proceed to edit our `top.sls` file one last
    time to include the `load balancer` state file. The `top.sls` file should look
    like this:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2bd3ae04-7f0a-4f1e-952e-e79ae6e34324.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
- en: 'Before we create our `load balancer` state file, we will create the Nginx configuration
    file that we will be pushing to our `load balancer` VM. Create a file called `nginx.conf`
    with the following content:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Now, let''s proceed to create our final state file. Create a file named `lb.sls`
    under the `nginxlb` directory in `/srv/salt/`, with the following content:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: To apply the final changes, you can run the `state.apply` command.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: 'Once it''s done, you can go ahead and test the load balancer running a cURL
    to its public IP address:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0c17a1c2-32f2-43dd-8521-734d0f1fecc4.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
- en: With this final configuration, we have concluded the proof of concept for Mr.
    Don High. One very important fact to note is that this example is nowhere near
    ready for be put into production; this is just an example to show you the basic
    functionalities and what is possible with Salt Stack.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-260
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we finally got hands-on interaction with Salt by deploying
    an infrastructure through IaC. We used Terraform to set up our initial environment
    and to start using Terraform, we simply downloaded the binary from `terraform.io`.
    The version of Terraform can be checked through the `terraform version` command.
    With Terraform installed, we obtained the correct details to connect to our Azure
    subscription using the AZ CLI.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: Once Terraform was able to connect to Azure, we proceeded to create the IaC
    declaration file, which contained the necessary information to correctly deploy
    the resources we wanted in Azure, the way we wanted it.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦Terraform能够连接到Azure，我们就开始创建IaC声明文件，其中包含了在Azure中正确部署我们想要的资源的必要信息，以我们想要的方式。
- en: With the deployment up and running through Terraform, we then moved into installing
    Salt. This can be done in two different ways, through the package manager of the
    OS (`yum` and `apt`) or through a bootstrap script.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 通过Terraform部署完成后，我们开始安装Salt。这可以通过操作系统的软件包管理器（`yum`和`apt`）或引导脚本的两种不同方式来完成。
- en: When installing through the package manager, we needed to add the Salt repository,
    as it was not available in the base repos; we did this by downloading the `rpm`
    from the `saltstack` site.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在通过软件包管理器安装时，我们需要添加Salt存储库，因为它在基本存储库中不可用；我们通过从`saltstack`网站下载`rpm`来完成这一点。
- en: To install the master, we ran `sudo yum install salt-master`, and to install
    the minions, we ran `sudo yum install salt-minion -y`. For Ubuntu, the process
    was similar, except the `apt` package manager was used.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 为了安装master，我们运行了`sudo yum install salt-master`，为了安装minions，我们运行了`sudo yum install
    salt-minion -y`。对于Ubuntu，过程类似，只是使用了`apt`软件包管理器。
- en: After Salt completed the installation, we enabled the `systemctl` units. Once
    Salt was running, we needed to allow the minions to talk to the master; this was
    done through SSH fingerprints.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在Salt完成安装后，我们启用了`systemctl`单元。一旦Salt运行起来，我们需要允许minions与master通信；这是通过SSH指纹完成的。
- en: At this point, Salt was running and the minions were communicating to the master,
    so we then moved into creating the web server formulas, which ran the definitions
    necessary to deploy the application.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，Salt正在运行，minions正在与master通信，所以我们开始创建web服务器公式，运行必要的定义来部署应用程序。
- en: In the next chapter, the last of this book, we will go through some of the best
    practices when designing solutions.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，本书的最后一章，我们将介绍设计解决方案时的一些最佳实践。
