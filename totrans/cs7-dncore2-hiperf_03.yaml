- en: Multithreading and Asynchronous Programming in .NET Core
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multithreading and asynchronous programming are two essential techniques that
    facilitate the development of highly scalable and performant applications. If
    the application is not responsive, it affects the user experience and increases
    the level of dissatisfaction. On the other hand, it also increases the resource
    usage on the server side, or where the application is running, and also increases
    the memory size and/or CPU usage. Nowadays, hardware is very cheap, and every
    machine comes with multiple CPU cores. Implementing multithreading and using asynchronous
    programming techniques not only increases the performance of the application,
    but also makes the application more responsive in nature.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter examines the core concepts of multithreading and the asynchronous
    programming model to help you use them in your projects and increase the overall
    performance of your applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a list of the topics that we will learn about in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Multithreading versus asynchronous programming
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multithreading in .NET Core
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Threads in .NET Core
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thread synchronization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Task parallel library (TPL)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a task using TPL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Task-based asynchronous pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Design patterns for parallel programming
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I/O bound operations are code that is dependent on external resources. Examples
    include accessing a filesystem, accessing a network, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Multithreading versus asynchronous programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multithreading and asynchronous programming, if properly implemented, improve
    the performance of an application. Multithreading refers to the practice of executing
    multiple threads at the same time to execute multiple operations or tasks in parallel.
    There could be one main thread and several background threads, usually known as
    worker threads, running in parallel at the same time, executing multiple tasks
    concurrently, whereas both synchronous and asynchronous operations can run on
    a single-threaded or a multithreaded environment.
  prefs: []
  type: TYPE_NORMAL
- en: In a single-threaded synchronous operation, there is only one thread that performs
    all the tasks in a defined sequence, and it executes them one after the other.
    In a single-threaded asynchronous operation, there is only one thread that executes
    the tasks, but it allocates a time slice in which to run each task. When the time
    slice is over, it saves the state of that task and starts executing the next one.
    Internally, the processor performs the context switching between each task and
    allocates a time slice in which to run them.
  prefs: []
  type: TYPE_NORMAL
- en: In a multithreaded synchronous operation, there are multiple threads that run
    the tasks in parallel. There is no context switching between the tasks, like we
    have in an asynchronous operation. One thread is responsible for executing the
    tasks assigned to it and then starting another task, whereas in a multithreaded
    asynchronous operation, multiple threads run multiple tasks and the task can be
    served and executed by single or multiple threads.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram depicts the differences between the single and multithreaded
    synchronous and asynchronous operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00039.gif)'
  prefs: []
  type: TYPE_IMG
- en: The preceding diagram shows four types of operations. In the single-threaded
    synchronous operation, we have one thread running five tasks sequentially. Once
    **Task 1** is completed, **Task 2** is executed, and so on. In the single-threaded
    asynchronous operation, we have a single thread, but each task will get a time
    slice to execute before the next task is executed and so on. Each task will be
    executed multiple times and resume from where it was paused. In the multi-threaded
    synchronous operation, we have three threads running three tasks **Task 1**, **Task
    2**, and **Task 3** in parallel. Lastly, in the multithreaded asynchronous operation,
    we have three tasks—**Task 1**, **Task 2**, and **Task 3**—running by three threads,
    but each thread performs some context switching based on the time slice allocated
    to each task.
  prefs: []
  type: TYPE_NORMAL
- en: In asynchronous programming, it is not always the case that each asynchronous
    operation will be running on a new thread. *`Async`/`Await`* is a good example
    of a situation where there is no additional thread created. The `*async*` operation
    is executed in the current synchronization context of the main thread and queues
    the asynchronous operation executed in the allocated time slice.
  prefs: []
  type: TYPE_NORMAL
- en: Multithreading in .NET Core
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many benefits in using multithreading in CPU and/or I/O-bound applications.
    It is often used for long-running processes that have a longer or infinite lifetime,
    working as background tasks, keeping the main thread available in order to manage
    or handle user requests. However, unnecessary use may completely degrade the application's
    performance. There are cases where creating too many threads is not a good architecture
    practice.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some examples where multithreading is a good fit:'
  prefs: []
  type: TYPE_NORMAL
- en: I/O operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running long-running background tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Database operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Communicating over a network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multithreading caveats
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Although there are many benefits to multithreading, there are some caveats
    that need to be thoroughly addressed when writing multithreaded applications.
    If the machine is a single or two-core machine and the application is creating
    lots of threads, the context switching between these threads will slow the performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00040.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The preceding diagram depicts the program running on a single-processor machine.
    The first task executes synchronously, and runs comparatively faster than the
    three threads running on the single processor. The system executes the first thread,
    then waits for a while before moving on to execute the second thread, and so on.
    This adds an unnecessary overhead of switching between threads and, thus, delays
    the overall operation. In the field of threading, this is known as context switching.
    The boxes between each thread represent the delay occurring during each context
    switch between threads.
  prefs: []
  type: TYPE_NORMAL
- en: As far as the developer experience is concerned, debugging and testing are two
    other issues that are challenging for developers when creating a multithreaded
    application.
  prefs: []
  type: TYPE_NORMAL
- en: Threads in .NET Core
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every application in .NET starts with a single thread, which is the main thread.
    A thread is the basic unit that the operating system uses to allocate processor
    time. Each thread has a priority, exception handlers, and a data structure saved
    in its own thread context. If the exception is thrown, it is thrown inside the
    context of the thread and other threads are not affected by it. The thread context
    contains some low-level information about, for example, the CPU registers, the
    address space of the thread's host process, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: If an application is running multiple threads on a single processor, each thread
    will be assigned a period of processor time and will be executed one after the
    other. The time slice is usually small, which makes it seem as if the threads
    are being executed at the same time. Once the allocated time is over, the processor
    moves to the other thread and the previous thread wait for the processor to become
    available again and execute it based on the time slice allocated. On the other
    hand, if the threads are running on multiple CPUs, then they may execute at the
    same time, but if there are other processes and threads running, the time slice
    will be allocated and executed accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: Creating threads in .NET Core
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In .NET Core, the threading API is the same as that used in the full .NET Framework
    version. A new thread can be created by creating a `Thread` class object and passing
    the `ThreadStart` or `ParameterizedThreadStart` delegate as a parameter. `ThreadStart`
    and `ParameterizedThreadStart` wrap a method that is invoked when the new thread
    is started. `ParameterizedThreadStart` is used for method containing parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a basic example that runs the `ExecuteLongRunningOperation `method on
    a separate thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also pass parameters while starting the thread and use the `ParameterizedThreadStart`
    delegate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The `ParameterizedThreadStart` delegate takes an object as a parameter. So,
    if you want to pass multiple parameters, this can be done by creating a custom
    class and adding the following properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Every thread has a thread priority. When a thread is created, its priority
    is set to normal. The priority affects the execution of the thread. The higher
    the priority, the higher the precedence that will be given to the thread. The
    thread priority can be defined on the thread object, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '`RunBackgroundService` is the method that executes in a separate thread, and
    the priority can be set by using the `ThreadPriority` enum and referencing the
    current thread object by calling `Thread.CurrentThread`, as shown in the preceding
    code snippet.'
  prefs: []
  type: TYPE_NORMAL
- en: Thread lifetime
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The lifetime of the thread depends on the method executing within that thread.
    Once the method is executed, CLR de-allocates the memory taken by the thread and
    disposes of. On the other hand, the thread can also be disposed of explicitly
    by calling the `Interrupt` or `Abort` methods.
  prefs: []
  type: TYPE_NORMAL
- en: Another very important factor to consider is exceptions. If the exceptions are
    not properly handled within a thread, they are propagated to the `calling` method
    and so on until they reach the `root` method in the call stack. When it reaches
    this point, CLR will shut down the thread if it is not handled.
  prefs: []
  type: TYPE_NORMAL
- en: 'For continuous or long-running threads, the shutdown process should be properly
    defined. One of the best approaches to smoothly shut down the thread is by using
    a `volatile bool` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we have used the `volatile bool` variable `isActive`,
    that decides if the `while` loop execute or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `volatile` keyword indicates that a field may be modified by multiple threads
    that are executing at the same time. Fields that are declared volatile are not
    subject to compiler optimizations that assume access by a single thread. This
    ensures that the most up-to-date value is present in the field at all times. To
    learn more about volatile, kindly refer the following URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/volatile](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/volatile)'
  prefs: []
  type: TYPE_NORMAL
- en: The thread pool in .NET
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CLR provides a separate thread pool that contains the list of threads to be
    used to execute tasks asynchronously. Each process has its own specific thread
    pool. CLR adds and removes threads in or from the thread pool.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run a thread using `ThreadPool`, we can use `ThreadPool.QueueUserWorkItem`,
    as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '`QueueUserWorkItem` queues the task to be executed by the CLR in a thread that
    is available in the thread pool. The task queues are maintained in **First In,
    First Out** (**FIFO**) order. However, depending on the thread''s availability
    and the task job itself, the task completion may be delayed.'
  prefs: []
  type: TYPE_NORMAL
- en: Thread synchronization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In multithreaded applications, we have shared resources that are accessible
    by multiple threads executing simultaneously. The area where the resources are
    shared across multiple threads is known as the critical section. To protect these
    resources and provide thread-safe access, there are certain techniques that we
    will discuss in this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take an example where we have a singleton class for logging a message
    into the filesystem. A singleton, by definition, denotes that there should only be one
    instance shared across multiple calls. Here is the basic implementation of a singleton
    pattern that is not thread-safe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code is a lazy initialization singleton that creates an instance
    on the first call on the `GetInstance` method. `GetInstance` is the critical section
    and is not thread-safe. If multiple threads enter into the critical section, multiple
    instances will be created and the race condition will occur.
  prefs: []
  type: TYPE_NORMAL
- en: The race condition is a problem in multithreaded programming that occurs when
    the outcome depends on the timing of events. A race condition arises when two
    or more parallel tasks access a shared object.
  prefs: []
  type: TYPE_NORMAL
- en: 'To implement the thread-safe singleton, we can use a locking pattern. Locking
    ensures that only one thread can enter into the critical section, and if another
    thread attempts to enter, it will wait until the thread is released. Here is a
    modified version that enables a singleton to be thread-safe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Monitors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Monitors are used to provide thread-safe access to the resource. It is applicable
    to multithread programming, where there are multiple threads that need access
    to a resource simultaneously. When multiple threads attempt to enter `monitor`
    to access any resource, CLR allows only one thread at a time to enter and the
    other threads are blocked. When the thread exits the monitor, the next waiting
    thread enters, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: If we look into the `Monitor` class, all the methods such as `Monitor.Enter`
    and `Monitor.Exit` operate on object references. Similarly to `lock`, `Monitor`
    also provides gated access to the resource; however, a developer will have greater
    control in terms of the API it provides.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a basic example of using `Monitor` in .NET Core:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: There are certain cases where the critical section has to wait for the resources
    to be available. Once they are available, we want to pulse the waiting block to
    execute.
  prefs: []
  type: TYPE_NORMAL
- en: To help us understand, let's take an example of a running `Job` whose task is
    to run the jobs added by multiple threads. If no job is present, it should wait
    for the threads to push and start executing them immediately.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: It's a singleton class, and other threads can access the `JobExecutor` instance
    using the static `Instance` property and call the `AddJobsItems` method to add
    the list of jobs to be executed. The `CheckandExecuteJobBatch` method runs continuously
    and checks for new jobs in the list every 10 minutes. Or, if it is interrupted
    by the `AddJobsItems` method by calling the `Monitor.PulseAll` method, it will
    immediately move to the `while` statement and check for the items count. If the
    items are present, the `CheckandExecuteJobBatch` method calls the `ExecuteJob`
    method that runs that job.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, on the main `Program` class, we can invoke three worker threads and
    one thread for `JobExecutor`, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output of running this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00041.gif)'
  prefs: []
  type: TYPE_IMG
- en: Task parallel library (TPL)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have learned some core concepts about multithreading, and have used
    threads to perform multiple tasks. Compared to the classic threading model in
    .NET, TPL minimizes the complexity of using threads and provides an abstraction
    through a set of APIs that helps developers to focus more on the application program
    instead of focusing on how the threads will be provisioned, as well as other things.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several benefits of using TPL over threads:'
  prefs: []
  type: TYPE_NORMAL
- en: It autoscales the concurrency to a multicore level
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It autoscales LINQ queries to a multicore level
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It handles the partitioning of the work and uses `ThreadPool` where required
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is easy to use and reduces the complexity of working with threads directly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a task using TPL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TPL APIs are available in the `System.Threading` and `System.Threading.Tasks`
    namespaces. They work around the task, which is a program or a block of code that
    runs asynchronously. An asynchronous task can be run by calling either the `Task.Run`
    or `TaskFactory.StartNew` methods. When we create a task, we provide a named delegate,
    anonymous method, or a lambda expression that the task executes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Alternatively, we can also use the `Task.Factory.StartNew` method, which is
    more advanced and provides more options. While calling the `Task.Factory.StartNew`
    method, we can specify `CancellationToken`, `TaskCreationOptions`, and `TaskScheduler`
    to set the state, specify other options, and schedule tasks.
  prefs: []
  type: TYPE_NORMAL
- en: TPL uses multiple cores of the CPU out of the box. When the task is executed
    using the TPL API, it automatically splits the task into one or more threads and
    utilizes multiple processors, if they are available. The decision as to how many
    threads will be created is calculated at runtime by CLR. Whereas a thread only has
    an affinity to a single processor, running any task on multiple processors needs
    a proper manual implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Task-based asynchronous pattern (TAP)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When developing any software, it is always good to implement the best practices
    while designing its architecture. The task-based asynchronous pattern is one of
    the recommended patterns that can be used when working with TPL. There are, however,
    a few things to bear in mind while implementing TAP.
  prefs: []
  type: TYPE_NORMAL
- en: Naming convention
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The method executing asynchronously should have the naming suffix `Async`. For
    example, if the method name starts with `ExecuteLongRunningOperation`, it should
    have the suffix `Async`, with the resulting name of `ExecuteLongRunningOperationAsync`.
  prefs: []
  type: TYPE_NORMAL
- en: Return type
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The method signature should return either a `System.Threading.Tasks.Task` or
    `System.Threading.Tasks.Task<TResult>`. The task's return type is equivalent to
    the method that returns `void`, whereas `TResult` is the data type.
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `out` and `ref` parameters are not allowed as parameters in the method signature.
    If multiple values need to be returned, tuples or a custom data structure can
    be used. The method should always return `Task` or `Task<TResult>`, as discussed
    previously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few signatures for both synchronous and asynchronous methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Synchronous method** | **Asynchronous method** |'
  prefs: []
  type: TYPE_TB
- en: '| `Void Execute();` | `Task ExecuteAsync();` |'
  prefs: []
  type: TYPE_TB
- en: '| `List<string> GetCountries();` | `Task<List<string>> GetCountriesAsync();`
    |'
  prefs: []
  type: TYPE_TB
- en: '| `Tuple<int, string> GetState(int stateID);` | `Task<Tuple<int, string>> GetStateAsync(int
    stateID);` |'
  prefs: []
  type: TYPE_TB
- en: '| `Person GetPerson(int personID);` | `Task<Person> GetPersonAsync(int personID);`
    |'
  prefs: []
  type: TYPE_TB
- en: Exceptions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The asynchronous method should always throw exceptions that are assigned to
    the returning task. However, the usage errors, such as passing null parameters
    to the asynchronous method, should be properly handled.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s suppose we want to generate several documents dynamically based on a
    predefined templates list, where each template populates the placeholders with
    dynamic values and writes it on the filesystem. We assume that this operation
    will take a sufficient amount of time to generate a document for each template.
    Here is a code snippet showing how the exceptions can be handled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we have a `GenerateDocumentAsync` method that performs
    a long running operation, such as reading the template from the database, populating
    placeholders, and writing a document to the filesystem. To automate this process,
    we used `Thread.Sleep` to sleep the thread for three seconds and then throw an
    exception that will be propagated to the calling method. The `Main` method loops
    the templates list and calls the `GenerateDocumentAsync` method for each template.
    Each `GenerateDocumentAsync` method returns a task. When calling an asynchronous
    method, the exception is actually hidden until the `Wait`, `WaitAll`, `WhenAll`,
    and other methods are called. In the preceding example, the exception will be
    thrown once the `Task.WaitAll` method is called, and will log the exception on
    the console.
  prefs: []
  type: TYPE_NORMAL
- en: Task status
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The task object provides a `TaskStatus` that is used to know whether the task
    is executing the method running, has completed the method, has encountered a fault,
    or whether some other occurrence has taken place. The task initialized using `Task.Run`
    initially has the status of `Created`, but when the `Start` method is called,
    its status is changed to `Running`. When applying the TAP pattern, all the methods
    return the `Task` object, and whether they are using the `Task.Run` inside, the
    method body should be activated. That means that the status should be anything
    other than `Created`. The TAP pattern ensures the consumer that the task is activated
    and the starting task is not required.
  prefs: []
  type: TYPE_NORMAL
- en: Task cancellation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Cancellation is an optional thing for TAP-based asynchronous methods. If the
    method accepts the `CancellationToken` as the parameter, it can be used by the
    caller party to cancel a task. However, for a TAP, the cancellation should be
    properly handled. Here is a basic example showing how cancellation can be implemented:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we have a `SaveFileAsync` method that takes the `byte`
    array and the `CancellationToken` as parameters. In the `Main` method, we initialize
    the `CancellationTokenSource` that can be used to cancel the asynchronous operation
    later in the program. To test the cancellation scenario, we will just call the
    `Cancel` method of the `tokenSource` after the `Task.Factory.StartNew` method
    and the operation will be canceled. Moreover, when the task is canceled, its status
    is set to `Cancelled` and the `IsCompleted` property is set to `true`.
  prefs: []
  type: TYPE_NORMAL
- en: Task progress reporting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With TPL, we can use the `IProgress<T>` interface to get real-time progress
    notifications from the asynchronous operations. This can be used in scenarios
    where we need to update the user interface or the console app of asynchronous
    operations. When defining the TAP-based asynchronous methods, defining `IProgress<T>`
    in a parameter is optional. We can have overloaded methods that can help consumers
    to use in the case of specific needs. However, they should only be used if the
    asynchronous method supports them.  Here is the modified version of `SaveFileAsync`
    that updates the user about the real progress:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Implementing TAP using compilers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Any method that is attributed with the `async` keyword (for C#) or `Async` for
    (Visual Basic) is called an asynchronous method. The `async` keyword can be applied
    to a method, anonymous method, or a Lambda expression, and the language compiler
    can execute that task asynchronously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a simple implementation of the TAP method using the compiler approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we have the `ExecuteLongRunningOperationAsync` method,
    which is implemented as per the compiler approach. It calls the `RunLoopAsync`
    that executes a loop for a certain number of milliseconds that is passed in the
    parameter. The `async` keyword on the `ExecuteLongRunningOperationAsync` method
    actually tells the compiler that this method has to be executed asynchronously,
    and, once the `await` statement is reached, the method returns to the `Main` method
    that writes the line on a console and waits for the task to be completed. Once
    the `RunLoopAsync` is executed, the control comes back to `await` and starts executing
    the next statements in the `ExecuteLongRunningOperationAsync` method.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing TAP with greater control over Task
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we know, that the TPL is centered on the `Task` and `Task<TResult>` objects.
    We can execute an asynchronous task by calling the `Task.Run` method and execute
    a `delegate` method or a block of code asynchronously and use `Wait` or other
    methods on that task. However, this approach is not always adequate, and there
    are scenarios where we may have different approaches to executing asynchronous
    operations, and we may use an **E****vent-based Asynchronous Pattern** (**EAP**)
    or an **A****synchronous Programming Model** (**APM**)*.* To implement TAP principles
    here, and to get the same control over asynchronous operations executing with
    different models, we can use the `TaskCompletionSource<TResult>` object.
  prefs: []
  type: TYPE_NORMAL
- en: '`The TaskCompletionSource<TResult> `object is used to create a task that executes
    an asynchronous operation. When the asynchronous operation completes, we can use
    the `TaskCompletionSource<TResult>` object to set the result, exception, or state
    of the task.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a basic example that executes the `ExecuteTask` method that returns
    `Task`, where the `ExecuteTask` method uses the `TaskCompletionSource<TResult>`
    object to wrap the response as a `Task` and executes the `ExecuteLongRunningTask`
    through the `Task.StartNew` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Design patterns for parallel programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are various ways in which the tasks can be designed to run in parallel.
    In this section, we will learn some top design patterns used in TPL:'
  prefs: []
  type: TYPE_NORMAL
- en: Pipeline pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataflow pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Producer-consumer pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parallel.ForEach
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parallel LINQ (PLINQ)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipeline pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The pipeline pattern is commonly used in scenarios where we need to execute
    the asynchronous tasks in sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00042.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Consider a task where we need to create a user record first, then initiate
    a workflow and send an email. To implement this scenario, we can use the `ContinueWith`
    method of TPL. Here is a complete example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Dataflow pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The dataflow pattern is a generalized pattern with a one-to-many and a many-to-one
    relationship. For example, the following diagram represents two tasks, **Task
    1** and **Task 2**, that execute in parallel, and a third task, **Task 3**, that
    will only start when both of the first two tasks are completed. Once **Task 3**
    is completed, **Task 4** and **Task 5** will be executed in parallel:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00043.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We can implement the preceding example using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Producer/consumer pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the best patterns to execute long-running operations is the producer/consumer
    pattern. In this pattern, there are producers and consumers, and one or more producers
    are connected to one or more consumers through a shared data structure known as
    `BlockingCollection`. `BlockingCollection` is a fixed-sized collection used in
    parallel programming. If the collection is full, the producers are blocked, and
    if the collection is empty, no more consumers should be added:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00044.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'In a real-world example, the producer could be a component reading images from
    a database and the consumer could be a component that processes that image and
    saves it into a filesystem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we initialized the generic `BlockingCollection<int>`
    to store the `imageID` that will be added by the producer and processed through
    the consumer. We set the maximum size of the collection to 10\. Then, we added
    a `Producer` item that reads the image from a database and calls the `Add` method
    to add the `imageID` in the blocking collection, which can be further picked up
    and processed by the consumer. The consumer task just checks any available item
    in the collection and processes it.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more about the data structures available for parallel programming,
    please refer to [https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/data-structures-for-parallel-programming](https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/data-structures-for-parallel-programming).
  prefs: []
  type: TYPE_NORMAL
- en: Parallel.ForEach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `Parallel.ForEach` is a multithreaded version of the classic `foreach` loop.
    The `foreach` loop runs on a single thread, whereas the `Parallel.ForEach` runs
    on multiple threads and utilizes multiple cores of the CPU, if available.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a basic example using `Parallel.ForEach` on a list of documents that
    needs to be processed, and which contains an I/O-bound operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: To replicate the I/O-bound operation, we just added a delay of 1 second to the
    `ManageDocument` method. If you execute the same method using the `foreach` loop,
    the difference will be obvious.
  prefs: []
  type: TYPE_NORMAL
- en: Parallel LINQ (PLINQ)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Parallel LINQ is a version of LINQ that executes queries in parallel on multi-core
    CPUs. It contains the full set of standard LINQ query operators plus some additional
    operators for parallel operations. It is highly advisable that you use this for
    long-running tasks, although incorrect use may slow down the performance of your
    app. Parallel LINQ operates on collections such as `List`, `List<T>`, `IEnumerable`,
    `IEnumerable<T>` and so on. Under the hood, it splits the list into segments and
    runs each segment on a different processor of the CPU.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a modified version of the previous example, with `Parallel.ForEach` instead
    of the PLINQ operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned about the core fundamentals of multithreaded
    and asynchronous programming. The chapter starts with the basic differences between
    both and walks you through some core concepts about multithreading, what APIs there are
    available, and how to write multithreading applications. We also looked at how
    the task-programming library can be used to serve asynchronous operations and
    how to implement the task asynchronous pattern. Finally, we explored parallel
    programming techniques and some of the best design patterns that are used for
    these techniques.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore the types of data structures and their
    impact on performance, how to write optimized code, and some best practices.
  prefs: []
  type: TYPE_NORMAL
