- en: Assessment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chapter 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Answer 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Concatenation of a `byte` type, which is an immutable type, and a `str` type
    isn't permissible in the Python 3 standard; any attempt to concatenate these two
    types will raise `TypeError`*.*
  prefs: []
  type: TYPE_NORMAL
- en: Answer 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The type-hinting support introduced in Python 3 is only intended to provide
    greater clarity in documenting the methods and the parameters and doesn't enforce
    any standards on the operations.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Beyond the functional and nonfunctional requirements, a software requirements
    specification document also specifies other requirements, such as UI, performance,
    business, and market requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The various kinds of requirements are categorized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Must-have requirements:** These are requirements that must be present inside
    a system. If any are missing, their absence will affect a critical functionality
    in the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Should-have requirements:** These are requirements that, if present, will
    enhance the functionality of the application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Could-have requirements:** These are requirements that are noncritical in
    nature. If they are missing, they won''t have any impact on the application''s
    functionality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Requirements wish list:** These are requirements that the stakeholders might
    want to see in future updates of the application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer 5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once the software requirements specification document has been generated, the
    next steps in the process include the design phase of the software. In the design
    phase, the structure of the software application is decided upon and decisions
    are made regarding the possible technology stacks that might be used to build
    the software.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Answer 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The chain of responsibility pattern inside Python allows us to build an application
    with loose coupling in mind. This is achieved by passing a received request through
    a chain of objects inside the software.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet shows the implementation of the chain of responsibility
    pattern inside Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Answer 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `__new__` method is the first method that's called when a new instance of
    an object needs to be created, whereas the  `__init__` method is run only when
    the newly created instance of the object needs to be initialized. In the normal
    flow of class instance creation, the `__new__` method will always be executed
    first and should only be overridden when the developer wants to gain control over
    the creation of new instances. This method should then be followed by a call to
    the` __init__` method, which will be called once the instance has been created
    and will need to be initialized.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It''s quite easy to define a new abstract class using the ABC metaclass. The
    following code snippet shows an example of achieving this kind of behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Chapter 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Answer 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The normalization of the schema inside a DBMS provides a number of benefits,
    such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Improved overall organization of the relationships
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in storage of redundant data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improved consistency of the data inside the database
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Better indexing of the data, which improves access to the data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The lazy loading in SQLAlchemy provides the developer with an option to use
    the *select* or *joined* modes, in which the lazy loading can be performed. When
    the developer goes with the *select* mode of loading the data, the loading of
    the datasets happens through the emission of SQL `SELECT` statements, which load
    the data on a per-requirement basis.
  prefs: []
  type: TYPE_NORMAL
- en: When using *joined,* the related datasets are loaded all at once through the
    emission of SQL `JOIN` statements. This technique is also known as joined eager
    loading.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are multiple ways through which we can maintain the integrity of data
    as we perform data updates. One of the easiest methods for this that we can implement
    is through the use of transactions, which allow us to make a number of updates
    in an atomic transaction, where either all of the updates in the transaction are
    applied or none are applied.
  prefs: []
  type: TYPE_NORMAL
- en: In the case that one of the updates inside the transaction fails, the previously
    applied updates inside the transaction are rolled back as well, thereby maintaining
    a consistent state of relations across the database.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The different levels of caching that can be implemented with a database are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Caching at database level:** When we cache at the database level, we usually
    utilize the built-in functionality of the database, which caches the datasets
    that are being frequently used by maintaining the query caches.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Caching at block level:** Caching at the block level happens at the application
    level, where we cache the data fetched by the ORM layer into a memory-based data
    store so as to avoid running a database query every time a certain result is asked
    for.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Caching at the user level:** When caching at the user level, the non-security-critical
    data is cached at the client side through the use of session cookies or local
    storage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chapter 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Answer 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Python has two different ways in which it allows us to build applications that
    can process requests concurrently. These are listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Multiprocessing:** The Python multiprocessing module allows the developer
    to launch multiple processes to handle the workloads in parallel'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multithreading:** The Python multithreading module allows the developer to
    execute multiple threads, which can be used to handle the concurrent workloads'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When the thread that has acquired a lock terminates abruptly, there are multiple
    possible scenarios based on how the lock was acquired.
  prefs: []
  type: TYPE_NORMAL
- en: If the lock was acquired through the use of a `with` statement in Python, then
    the lock will be released as soon as the thread terminates.
  prefs: []
  type: TYPE_NORMAL
- en: If the lock was acquired inside the `try-except-final` approach, then the lock
    will be freed as the exception propagates to the final statement.
  prefs: []
  type: TYPE_NORMAL
- en: If the lock was acquired without any kind of safety procedure, an abrupt termination
    of the thread will cause a deadlock because the lock has not been freed.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Usually, when the main program receives a termination signal, the signal is
    also propagated to its threads; otherwise, a thread can be marked as a daemon
    thread so that its execution is terminated with the main program.
  prefs: []
  type: TYPE_NORMAL
- en: Another way to achieve this is through the use of flags, which a thread can
    check at regular intervals. If the flag is set, then the thread starts with the
    termination.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The sharing of state between different processes can be achieved through the
    use of pipes, which can help the processes communicate with each other.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In Python, we have multiple ways of creating process pools for the distribution
    of the tasks. We can create these pools manually—as shown in the example in the
    *Synchronization of processes* section in this chapter—or we can utilize the provided
    `ProcessPoolExecutor` from the `concurrent.futures` library.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Answer 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For handling requests through the use of multiple application instances, we
    use the concept of horizontal scaling, where we launch more than one instance
    of the same application behind a load balancer. The load balancer is then responsible
    for distributing the incoming requests across this pool of application instances.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The process pools can be implemented through the use of `ProcessPoolExecutor`
    from the `concurrent.futures` library in Python. An example of how to use `ProcessPoolExecutor`
    to distribute the requests over a pool can be seen in the *Using thread pools
    for handling incoming connections* section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is completely possible to have a program that combines the use of multiprocessing
    and multithreading. The following snippet of code shows this implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The preceding way of achieving this is valid and can be easily implemented without
    any issues, though you might find that it has a limited number of use cases, and
    its use will be limited by the implementation of the GIL.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A simple example of implementing a socket server is shown in the *Implementing
    a simple socket server with AsyncIO* section of this chapter. Another way is to
    implement a fully functional web server through the use of AsyncIO is by using
    the `aiohttp` framework, which provides an AIO-based HTTP server.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Answer 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In addition to the generic `View` class that we saw during this chapter, Flask
    also provides another prebuilt pluggable view class known as `MethodView`.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Yes, it's possible for us to remove the foreign key constraint for the role
    table from the user table and keep the relationship there. But whenever we need
    to store the data, we will need to manually insert the required object for the
    role object inside the user table.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are a number of alternatives to Gunicorn to serve a Flask-based Python
    application, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: uWSGI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Twisted web
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mod_wsgi`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gevent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Increasing the number of Gunicorn workers is very simple. All we need to do
    is to add the `-w <worker count>` parameter in the command to set the number of
    Gunicorn workers, as shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Chapter 7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Answer 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The use of CDN does improve the loading performance of a web page. This is
    because of the way the browser caches the content from a given URL. Sometimes,
    we can gain the following benefits when we use an existing CDN to serve some of
    the content:'
  prefs: []
  type: TYPE_NORMAL
- en: For some of the frontend libraries that are common, there is a chance that the
    libraries are already cached by the user's browser while they visited some other
    website, which include the content from the CDN. This helps us to avoid redownloading
    those libraries and reduces the bandwidth usage and improves the loading speed
    of the page.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CDNs can also route the request to the servers based on the user geography so
    that the content is downloaded with the least possible latency, thereby improving
    the loading speed of the page.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To make the browser use the existing connections, we can utilize a concept called
    `KeepAlive`. When the `KeepAlive` headers are set in a request, the connection
    that is used to make the request is kept open by the server for a fixed amount
    of time in the hope that the same connection can be used for working on another
    request, avoiding the cost of the initial connection setup for every other request.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The JavaScript API provides a very handy method known as `removeKey(key)`, which
    can be used to remove a particular key from the local/session storage of the browser.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Answer 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The major difference between a unit test and a functional test is the scope
    of testing, as described in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Unit test:** A unit test usually focuses on the testing of individual components
    in a software that could be factored to a single function or a method of a class'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Functional test:** Functional tests are also known as integration tests and
    usually test a specific functionality of the system that may encompass the interaction
    of multiple components with each other, along with their interaction with the
    external environment, such as database systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A test suite is a collection of test cases that needs to be run on a specific
    program. Writing a test suite using Python''s `unittest` library is quite easy
    to achieve. For example, if you''ve written a few test cases, such as `TestTextInput`,
    `TestTextUppercase`, and `TestTextEncode`, we can combine them into a test suite
    by using the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Answer 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The purpose of fixtures inside Pytest is to provide a fixed and stable environment
    over which the tests cases can execute. These fixtures are responsible for initializing
    the environment by setting up the required variables or interfaces that may be
    required for a test to execute.
  prefs: []
  type: TYPE_NORMAL
- en: Another advantage of using a fixture is its reusability, which allows the same
    fixture to be used for multiple tests without any issue.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The fixture scopes in Pytest describe how often a fixture will be called. The
    fixtures have a lot of different scopes that can be applied to them, as shown
    in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Function scope:** Fixture is run once per test'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Class scope:** Fixture is run once per class'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Module scope:** Fixture is run once per module'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Session scope:** Fixture is run once per test session'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chapter 9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Answer 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are multiple factors that can be a cause of performance bottlenecks inside
    an application, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Inadequate planning of hardware resources required to run an application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Poor choice of algorithms for implementing a functionality in the application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improperly implemented database relations with a lot of redundancy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Not implementing proper caching for frequently accessed data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Time profiling on a method in Python helps us to understand how much time was
    taken by the method to execute. Based on the requirements, there are several different
    ways through which we can run a time profile on a method, as shown in the following
    lost:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Using the** `timeit` **module:** The `timeit` module provides us with a functionality
    that we can use to find out the time it takes for a script or a method to execute.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Using the** `time` **module:** We can also use the `time` module to help
    us measure the runtime of a method in Python. We can do this through the creation
    of decorators, which can help in the profiling of the method runtime.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Using the** `cProfile` **module:** The `cProfile` module allows us to profile
    the runtime of the different steps inside a Python program.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although Python is a garbage-collected language with no direct access to memory
    pointers, the typical memory leaks possible through illegal pointer operations
    can hardly happen. But there's another way through which the Python program can
    continue to consume more and more memory without releasing it. When the program
    forgets to dereference the objects once they're no longer in use, this may cause
    new objects to be allocated without the garbage collection of objects that are
    no longer in use taking place.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The API response from an application can be profiled by measuring the average
    time taken for an API to return a response over a fixed set of executions. This
    can be measured in multiple ways that may involve the use of the `timeit` or `time`
    modules from the Python standard library.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The design patterns can have an important role in the performance of the application,
    and an incorrect design pattern can have a performance penalty on the application
    performance. For example, consider the allocation of an object that may be used
    implement logging throughout an application. If this logger object allocation
    needs to happen separately for every individual module or class, then we might
    be wasting quite a lot of resources to allocate an object when it could have been
    shared across the different modules.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Answer 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are a number of issues that make security an application hard these days.
    These issues include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The rise in sophisticated attacks that are hard to mitigate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The increase in the rise of 0-day vulnerabilities that have not been patched
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More and more state-sponsored attacks that target multiple vulnerabilities of
    a system and are usually hard to trace
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An ever-increasing number of devices coming online without proper security in
    place, making them vulnerable to being used in DDoS attacks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An XSS—or cross-site scripting—attack is when an attacker injects a malicious
    script inside a trusted website. When the page with the malicious script is loaded,
    it causes the client system to be compromised by the attacker.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A DoS—or denial of service—attack is used by an attacker to make a service or
    resource unavailable to its users by flooding the system with superfluous requests,
    which causes the system to queue up those requests causing a disruption in the
    service.
  prefs: []
  type: TYPE_NORMAL
- en: 'The attack can be mitigated through the use of different techniques, implemented
    at different levels, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Adding a firewall rule to deny traffic from a given untrusted source
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using services from the cloud security providers, who can analyze the incoming
    traffic and block it before it reaches the application infrastructure, helping
    to mitigate the DoS attack
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring the infrastructure to sink the traffic to a node where there is
    no application running, or by rerouting ...
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are lot of possible mistakes that can compromise the security of the
    application, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Using insecure third-party libraries inside an application, which may contain
    security vulnerabilities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Not filtering the user-provided input to the application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storing security-sensitive data unencrypted inside an application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Not implementing proper restrictions to control access to the internal infrastructure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chapter 11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Answer 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The major difference between service-oriented architecture and microservices
    architecture is the fact that, in a service-oriented architecture, the application
    consists of different services, each providing the functionality to work on one
    of the business domains of an organization. These services communicate with each
    other through the use of the enterprise service bus, which routes the messages
    from one service to another while also providing a common format for message exchange.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of microservices, the application will consist of a number of small
    microservices, where each microservice is responsible for providing only a single
    functionality that may not map to a complete domain of an organization and may
    just be a subset of larger problem domain. These microservices communicate with
    each other through the use of APIs exposed by the individual microservices or
    through the use of stateless message routers that allow the delivery of messages
    from one service to another.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To ensure that a microservice-based application has a high uptime, we can make
    use of the following techniques:'
  prefs: []
  type: TYPE_NORMAL
- en: Not using a single storage for all of the microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running multiple instances of the same microservice behind the load balancer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using API gateways to provide graceful degradation in a service where the client
    still receives a response when a critical service has failed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The use of service-level agreements—or SLAs—provides a number of guarantees,
    such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A guarantee about the API stability of a service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A guarantee about the uptime of a service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A guarantee of the expected response times of a service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A guarantee of the request rate limitation implemented by a service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The API gateways can communicate directly with the service registry through
    the use of the SDK provided by the service registry or through the use of the
    APIs exposed by the service registry. This allows the API gateway to automatically
    fetch the correct location for a given service from the service registry.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Asynchronous communication inside microservices can be implemented through the
    use of stateless message brokers. To implement asynchronous communication, some
    microservices act as producers and send a message to the message-broker queue.
    Then, other microservices may consume that message, process it, and send a response
    back to the microservice that sent the message. The response is then processed
    by the callback that was set by the requesting microservice. This is how the asynchronous
    communication between the microservices is established.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Answer 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The integration tests for microservices are written in mostly the same way
    as those for monolithic applications, with the following few differences:'
  prefs: []
  type: TYPE_NORMAL
- en: If the microservice needs to communicate with some another external microservice,
    then the integration test might need to have the external service set up so as
    to properly execute the test case
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The components that comprise the individual service should be set up for all
    of the microservices in place in the infrastructure—for example, a database that
    accompanies a particular microservice that is needed for testing purposes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The tracing of a monolithic application differs from that of a microservice-based
    application in the way that the tracing of a monolithic application involves understanding
    the flow of the request from one component to another inside the application.
    In contrast, tracing a microservices-based application involves understanding
    how the request flows not only inside a particular microservice, but also from
    one microservice to another.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are multiple tools that are available for tracing within the microservice
    architecture, as shown in the following list:'
  prefs: []
  type: TYPE_NORMAL
- en: Jaeger
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zipkin
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appdash
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For tracing the individual components inside a microservice, we can utilize
    one of the functionalities provided by Jaeger known as spans. An example of how
    to use spans can be seen at [https://github.com/jaegertracing/jaeger-client-python](https://github.com/jaegertracing/jaeger-client-python).
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Answer 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are a number of advantages that are provided by a move to serverless
    architecture, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Reduced development effort through the integration of third-party services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Less operational complexity, because now the organization doesn't need to take
    care of the infrastructure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improved security, since the individual functions execute in their own separate
    containers, which helps us to keep the different functions from interfering with
    each other
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improved scalability of the application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The use of **Backend as a Service** (**BaaS**) helps in the creation of applications
    by providing common set of functionality through the integration of the APIs.
    These services are hosted by a third-party provider,thereby reducing the effort
    that the application developers will have to expend in rebuilding them in their
    application from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The API gateway in a serverless architecture maps the API endpoints to a function
    in the backend. These API endpoints can then be called by the clients when a particular
    event occurs, invoking the backend function.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are certain reasons why an application cannot be ported successfully
    to a serverless architecture. These reasons are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The use of a technology stack that may not be supported by the serverless infrastructure
    provider
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applications that need to store the state of the request processing to generate
    correct results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A tightly coupled code base that makes it hard to define individual methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some components of the application taking an extremely long time to execute
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chapter 14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Answer 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The use of blue–green deployments provides us with the following set of benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: The ability to switch the application from one version to another instantly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ability to easily roll back the application from a newer version to an older
    version in case the new version experiences some critical functionality bugs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A reduction in downtime related to application upgrades
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using a canary deployment can help in the testing of an application in the following
    ways:'
  prefs: []
  type: TYPE_NORMAL
- en: The application is tested with a small sample of real-world requests, which
    may help expose any unidentified bugs in the application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Canary deployment gives us the ability to run the new version of the application
    along with the older version so as to compare the responses provided by the APIs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using virtual machines for running microservices-based applications can cause
    increased overhead for running the microservice instances because of the higher
    requirements incurred by a virtual machine. In addition, the use of virtual machines
    limits the number of services that can coexist on the same infrastructure because
    a virtual machine is comparably heavier to run than containers, which utilize
    operating-system functionality to keep the programs isolated.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The deployments in the hybrid cloud model can be handled in the same way that
    they are handled in the public or private clouds. The difference arises when the
    application needs to be scaled. In this case, when using the hybrid cloud approach,
    an organization can pool the resources from the public cloud based on the scaling
    necessity and can then run some parts of their application in the public cloud
    and the others in the private cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Answer 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The point-to-point integration of the enterprise applications requires a connector
    to be built for every pair of applications that needs to integrate. This creates
    a complex infrastructure that can be hard to manage as well as scale if new applications
    are introduced into the environment.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The enterprise service bus is responsible for helping different services inside
    an infrastructure connect to each other through the use of message-passing mechanisms.
    The ESB provides connectors for the applications through which the applications
    can connect to the ESB and send messages to the ESB.
  prefs: []
  type: TYPE_NORMAL
- en: The ESB then assumes responsibility for routing these messages to the correct
    service that they are intended for, thereby promoting communication between the
    two services inside an infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The different types of patterns that facilitate the approach of EAI are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Mediation pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Federation pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chapter 16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Answer 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The point-to-point integration of different microservices is hard to achieve
    because of the different technology stacks that may be used by a particular microservice
    that is present in the infrastructure. This may cause individual connectors to
    be built for every pair of microservices in order to translate the data format
    of one microservice to another.
  prefs: []
  type: TYPE_NORMAL
- en: Another bottleneck happens because of the scalability of these services, since
    now the connectors have to connect every single instance of the deployed microservice.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The enterprise service bus has been replaced with stateless message routers
    with the advent of microservice architecture, where these routers can be scaled
    up individually and implement message routing for the wide number of microservices
    that might be running inside an infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Answer 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The message brokers inside a microservice architecture provide high availability
    by replicating message queues between the multiple instances of the message broker
    that might be running. This allows the routers to take the place of a failing
    router and keep communication inside the infrastructure intact.
  prefs: []
  type: TYPE_NORMAL
