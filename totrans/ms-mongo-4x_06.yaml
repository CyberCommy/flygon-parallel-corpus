- en: Advanced Querying
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous chapter, we learned how to use the mongo shell for scripting,
    administration, and developing in a secure way. In this chapter, we will dive
    deeper into using MongoDB with drivers and popular frameworks from Ruby, Python,
    and PHP: **Hypertext Preprocessor** (**PHP**).'
  prefs: []
  type: TYPE_NORMAL
- en: We will also show the best practices for using these languages and the variety
    of comparison and update operators that MongoDB supports on a database level,
    which are accessible through Ruby, Python, and PHP.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter we will learn the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: MongoDB operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CRUD using Ruby, Mongoid, Python, PyMODM, PHP and Doctrine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Comparison operators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change streams
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MongoDB CRUD operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will cover CRUD operations using Ruby, Python, and PHP with
    the official MongoDB driver and some popular frameworks for each language, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: CRUD using the Ruby driver
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 3](e61d07bb-3244-4180-a77c-e8cde4be6189.xhtml), *MongoDB CRUD Operations*,
    we covered how to connect to MongoDB from Ruby, Python, and PHP using the drivers
    and ODM. In this chapter, we will explore `create`, `read`, `update`, and `delete`
    operations using the official drivers and the most commonly used ODM frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: Creating documents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using the process described in Chapter 2, *Schema Design and Data Modeling,*
    we assume that we have an `@collection` instance variable pointing to our `books`
    collection in a `mongo_book` database in the `127.0.0.1:27017` default database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We insert a single document with our definition, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This can be performed with a single line of code as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting object is a `Mongo::Operation::Result` class with content that
    is similar to what we had in the shell, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Here, `n` is the number of affected documents; `1` means we inserted one object
    and `ok` means `1` (`true`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating multiple documents in one step is similar to this. For two documents
    with `isbn 102` and `103`, and using `insert_many` instead of `insert_one`, we
    have the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The resulting object is now a `Mongo::BulkWrite::Result` class, meaning that
    the `BulkWrite` interface was used for improved performance.
  prefs: []
  type: TYPE_NORMAL
- en: The main difference is that we now have an attribute, `inserted_ids,`, which
    will return `ObjectId` of the inserted objects from the `BSON::ObjectId` class.
  prefs: []
  type: TYPE_NORMAL
- en: Read
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Finding documents work in the same way as creating them, that is, at the collection
    level:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Multiple search criteria can be chained and are equivalent to an `AND` operator
    in SQL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The mongo-ruby-driver API provides several query options to enhance queries;
    the most widely used query options are listed in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Option** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `allow_partial_results` | This is for use with sharded clusters. If a shard
    is down, it allows the query to return results from the shards that are up, potentially
    getting only a portion of the results. |'
  prefs: []
  type: TYPE_TB
- en: '| `batch_size(Integer)` | This can change the batch size that the cursor will
    fetch from MongoDB. This is done on each `GETMORE` operation (for example, by
    typing it on the mongo shell). |'
  prefs: []
  type: TYPE_TB
- en: '| `comment(String)` | With this command we can add a comment in our query for
    documentation reasons. |'
  prefs: []
  type: TYPE_TB
- en: '| `hint(Hash)` | We can force usage of an index using `hint()`. |'
  prefs: []
  type: TYPE_TB
- en: '| `limit(Integer)` | We can limit the result set to the number of documents
    specified by `Integer`. |'
  prefs: []
  type: TYPE_TB
- en: '| `max_scan(Integer)` | We can limit the number of documents that will be scanned.
    This will return incomplete results and is useful if we are performing operations
    where we want to guarantee that they won''t take a long time, such as when we
    connect to our production database. |'
  prefs: []
  type: TYPE_TB
- en: '| `no_cursor_timeout` | If we don''t specify this parameter, MongoDB will close
    any inactive cursor after 600 seconds. With this parameter our cursor will never
    be closed. |'
  prefs: []
  type: TYPE_TB
- en: '| `projection(Hash)` | We can use this parameter to fetch or exclude specific
    attributes from our results. This will reduce data transfer over the wire. An
    example of this can be`client[:books].find.projection(:price => 1)`. |'
  prefs: []
  type: TYPE_TB
- en: '| `read(Hash)` | We can specify a read preference to be applied only for this
    query:`client[:books].find.read(:mode => :secondary_preferred)`. |'
  prefs: []
  type: TYPE_TB
- en: '| `show_disk_loc(Boolean)` | We should use this option if we want to find the
    actual location of our results on a disk. |'
  prefs: []
  type: TYPE_TB
- en: '| `skip(Integer)` | This can be used to skip the specified number of documents.
    It''s useful for the pagination of results. |'
  prefs: []
  type: TYPE_TB
- en: '| `snapshot` | This can be used to execute our query in snapshot mode. This
    is useful for when we want a more stringent consistency. |'
  prefs: []
  type: TYPE_TB
- en: '| `sort(Hash)` | We can use this to sort our results, for example,`client[:books].find.sort(:name
    => -1)`. |'
  prefs: []
  type: TYPE_TB
- en: 'On top of the query options, mongo-ruby-driver provides some helper functions
    that can be chained at the method call level, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`.count`: The total count for the preceding query'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.distinct(:field_name)`: To distinguish between the results of the preceding
    query by `:field_name`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Find()` returns a cursor containing the result set that we can iterate using
    `.each` in Ruby like every other object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The output for our `books` collection is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Chaining operations in find()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`find()`, by default, uses an `AND` operator to match multiple fields. If we
    want to use an `OR` operator, our query needs to be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also use `$and` instead of `$or` in the previous example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This, of course, will return no results since no document can have both `isbn
    101` and `102`.
  prefs: []
  type: TYPE_NORMAL
- en: 'An interesting and hard bug to find is if we define the same key multiple times,
    such as in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'In comparison, the opposite order will cause the document with `isbn 101` to
    be returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This is because in Ruby hashes, by default, all duplicated keys except for the
    last one are silently ignored. This may not happen in the simplistic form shown
    in the preceding example, but it is prone to happen if we create keys programmatically.
  prefs: []
  type: TYPE_NORMAL
- en: Nested operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Accessing embedded documents in mongo-ruby-driver is as simple as using the
    dot notation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We need to enclose the key name in quotes (`''`) to access the embedded object
    just as we need it for operations starting with `$`, such as `'$set'`.
  prefs: []
  type: TYPE_NORMAL
- en: Update
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Updating documents using mongo-ruby-driver is chained to finding them. Using
    our example `books` collection, we can do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This finds the document with `isbn 101` and changes its name to `Mastering MongoDB,
    2nd Edition`.
  prefs: []
  type: TYPE_NORMAL
- en: In a similar way to `update_one`, we can use `update_many` to update multiple
    documents retrieved via the first parameter of the method.
  prefs: []
  type: TYPE_NORMAL
- en: If we don't use the `$set` operator, the contents of the document will be replaced
    by the new document.
  prefs: []
  type: TYPE_NORMAL
- en: 'Assuming Ruby version >=2.2, keys can be either quoted or unquoted; however,
    keys that start with `$` need to be quoted as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting object of an update will contain information about the operation,
    including these methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ok?`: A Boolean value that shows whether the operation was successful or not'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`matched_count`: The number of documents matching the query'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modified_count`: The number of documents affected (updated)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`upserted_count`: The number of documents upserted if the operation includes
    `$set`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`upserted_id`: The unique `ObjectId` of the upserted document if there is one'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Updates that modify fields of a constant data size will be *in place*; this
    means that they won't move the document from its physical location on the disk.
    This includes operations such as `$inc` and `$set` on the `Integer` and `Date`
    fields.
  prefs: []
  type: TYPE_NORMAL
- en: 'Updates that can increase the size of a document may result in the document
    being moved from its physical location on the disk to a new location at the end
    of the file. In this case, queries may miss or return the document multiple times.
    To avoid this, we can use `$snapshot: true` while querying.'
  prefs: []
  type: TYPE_NORMAL
- en: Delete
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deleting documents work in a similar way to finding documents. We need to find
    documents and then apply the delete operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, with our `books` collection used before, we can issue the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This will delete a single document. In our case, since `isbn` is unique for
    every document, this is expected. If our `find()` clause had matched multiple
    documents, then `delete_one` would have deleted just the first one that `find()`
    returned, which may or may not have been what we wanted.
  prefs: []
  type: TYPE_NORMAL
- en: If we use `delete_one` with a query matching multiple documents, the results
    may be unexpected.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to delete all documents matching our `find()` query, we have to
    use `delete_many`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we are deleting all books that have a price greater
    than or equal to `30`.
  prefs: []
  type: TYPE_NORMAL
- en: Batch operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can use the `BulkWrite` API for batch operations. In our previous insert
    many documents example, this would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The `BulkWrite` API can take the following parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`insertOne`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`updateOne`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`updateMany`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`replaceOne`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`deleteOne`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`deleteMany`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One version of these commands will `insert`/`update`/`replace`/`delete` a single
    document even if the filter that we specify matches more than one document. In
    this case, it's important to have a filter that matches a single document to avoid
    unexpected behaviors.
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s also possible, and a perfectly valid use case, to include several operations
    in the first argument of the `bulk_write` command. This allows us to issue commands
    in a sequence when we have operations that depend on each other and we want to
    batch them in a logical order according to our business logic. Any error will
    stop `ordered:true` batch writes and we will need to manually roll back our operations.
    A notable exception is `writeConcern` errors, for example, requesting a majority
    of our replica set members to acknowledge our write. In this case, batch writes
    will go through and we can observe the errors in the `writeConcernErrors` result
    field:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In the previous example, we made sure that we deleted the original book before
    adding the new (and more expensive) edition of our `MongoDB for experts` book.
  prefs: []
  type: TYPE_NORMAL
- en: '`BulkWrite` can batch up to 1,000 operations. If we have more than 1,000 underlying
    operations in our commands, these will be split into chunks of thousands. It is
    good practice to try to keep our write operations to a single batch if we can
    to avoid unexpected behavior.'
  prefs: []
  type: TYPE_NORMAL
- en: CRUD in Mongoid
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will use Mongoid to perform `create`, `read`, `update`,
    and `delete` operations. All of this code is also available on GitHub at [https://github.com/agiamas/mastering-mongodb/tree/master/chapter_4](https://github.com/agiamas/mastering-mongodb/tree/master/chapter_4).
  prefs: []
  type: TYPE_NORMAL
- en: Read
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Back in Chapter 2, *Schema Design and Data Modeling**,* we described how to
    install, connect, and set up models, including an inheritance to Mongoid. Here,
    we will go through the most common use cases of CRUD.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finding documents is done using a DSL similar to **Active Record** (**AR**).
    As with AR using a relational database, Mongoid assigns a class to a MongoDB collection
    (table) and any object instance to a document (row from a relational database):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This will find the document by `ObjectId` and return the document with `isbn
    101`, as will the query by a name attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'In a similar fashion to the dynamically generated AR queries by an attribute,
    we can use the helper method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: This queries by attribute name, equivalent to the previous query.
  prefs: []
  type: TYPE_NORMAL
- en: 'We should enable `QueryCache` to avoid hitting the database for the same query
    multiple times, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This can be added in any code block that we want to enable, or in the initializer
    for Mongoid.
  prefs: []
  type: TYPE_NORMAL
- en: Scoping queries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can scope queries in Mongoid using class methods, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we will use this query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: It will query for books with a price greater than 20.
  prefs: []
  type: TYPE_NORMAL
- en: Create, update, and delete
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Ruby interface for creating documents is similar to active record:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: This will return an error if the creation fails.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the bang version to force an exception to be raised if saving the
    document fails:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The `BulkWrite` API is not supported as of Mongoid version 6.x. The workaround
    is to use the mongo-ruby-driver API, which will not use the `mongoid.yml` configuration
    or custom validations. Otherwise, you can use `insert_many([array_of_documents])`,
    which will insert the documents one by one.
  prefs: []
  type: TYPE_NORMAL
- en: 'To update documents, we can use `update` or `update_all`. Using `update` will
    update only the first document retrieved by the query part, whereas `update_all`
    will update all of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Deleting a document is similar to creating it, providing `delete` to skip callbacks,
    and `destroy` if we want to execute any available callbacks in the affected document.
  prefs: []
  type: TYPE_NORMAL
- en: '`delete_all` and `destroy_all` are convenient methods for multiple documents.'
  prefs: []
  type: TYPE_NORMAL
- en: '`destroy_all` should be avoided if possible, as it will load all documents
    into the memory to execute callbacks and thus can be memory-intensive.'
  prefs: []
  type: TYPE_NORMAL
- en: CRUD using the Python driver
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PyMongo is the officially supported driver for Python by MongoDB. In this section,
    we will use PyMongo to `create`, `read`, `update`, and `delete` documents in MongoDB.
  prefs: []
  type: TYPE_NORMAL
- en: Creating and deleting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Python driver provides methods for CRUD just like Ruby and PHP. Following
    on from Chapter 2, *Schema Design and Data Modeling,* and the `books` variable
    that points to our `books` collection, we will write the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: In the previous example, we used `insert_one()` to insert a single document,
    which we can define using the Python dictionary notation; we can then query it
    for all documents in the collection.
  prefs: []
  type: TYPE_NORMAL
- en: 'The resulting object for `insert_one` and `insert_many` has two fields of interest:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Acknowledged`: A Boolean that is `true` if the insert has succeeded and `false`
    if it hasn''t, or if write concern is `0` (fire and forget write).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inserted_id` for `insert_one`: The `ObjectId` of the written document and
    `inserted_ids` for `insert_many`. The array of `ObjectIds` of the written documents.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We used the `pprint` library to pretty-print the `find()` results. The built-in
    way to iterate through the result set is by using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Deleting documents work in a similar to creating them. We can use `delete_one`
    to delete the first instance or `delete_many` to delete all instances of the matched
    query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The `deleted_count` instance tells us how many documents were deleted; in our
    case, it is `1`, even though we used the `delete_many` method.
  prefs: []
  type: TYPE_NORMAL
- en: To delete all documents from a collection, we can pass in the empty document
    `{}`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To drop a collection, we can use `drop()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Finding documents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To find documents based on top-level attributes, we can simply use a dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'To find documents in an embedded document, we can use the dot notation. In
    the following example, we use `meta.authors` to access the `authors` embedded
    document inside the `meta` document:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we used a regular expression to match `aLEx`, which is case
    insensitive, in every document that the string is mentioned in the `meta.authors`
    embedded document. PyMongo uses this notation for regular expression queries,
    called the `$regex` notation in MongoDB documentation. The second parameter is
    the options parameter for `$regex`, which we will explain in detail in the *Using
    regular expressions* section later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Comparison operators are also supported, and a full list of these are given
    in the *Comparison operators* section, which can be seen later in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Adding multiple dictionaries in our query results in a logical `AND` query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'For books having both `isbn=101` and `name=Mastering MongoDB`, to use logical
    operators such as `$or` and `$and`, we have to use the following syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'For books having an `isbn` of `101` or `102`, if we want to combine `AND` and
    `OR` operators, we have to use the `$and` operator, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'For a result of `OR` between two queries, consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The first query is asking for documents that have `isbn=101 AND name=Mastering
    MongoDB`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second query is asking for documents that have `isbn=102 AND name=MongoDB`
    in 7 years.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The result is the union of these two datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Updating documents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the following code block, you can see an example of updating a single document
    using the `update_one` helper method.
  prefs: []
  type: TYPE_NORMAL
- en: 'This operation matches one document in the search phase and modifies one document
    based on the operation to be applied to the matched documents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'In a similar way to inserting documents, when updating documents, we can use
    `update_one` or `update_many`:'
  prefs: []
  type: TYPE_NORMAL
- en: The first argument here is the filter document for matching the documents that
    will be updated
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second argument is the operation to be applied to the matched documents
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The third (optional) argument is to use `upsert=false` (the default) or `true`,
    which is used to create a new document if it's not found
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another interesting argument is `bypass_document_validation=false` (the default)
    or `true`, which is optional. This will ignore validations (if there are any)
    for the documents in the collection.
  prefs: []
  type: TYPE_NORMAL
- en: The resulting object will have `matched_count` for the number of documents that
    matched the filter query, and `modified_count` for the number of documents that
    were affected by the `update` part of the query.
  prefs: []
  type: TYPE_NORMAL
- en: In our example, we are setting `price=100` for the first book with `isbn=101`
    through the `$set` update operator. A list of all update operators is displayed
    in the *Update operators* section later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: If we don't use an update operator as the second argument, the contents of the
    matched document will be entirely replaced by the new document.
  prefs: []
  type: TYPE_NORMAL
- en: CRUD using PyMODM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PyMODM is a core ODM that provides simple and extensible functionality. It is
    developed and maintained by MongoDB's engineers who get fast updates and support
    for the latest stable version of MongoDB available.
  prefs: []
  type: TYPE_NORMAL
- en: In Chapter 2, *Schema Design and Data Modeling**,* we explored how to define
    different models and connect to MongoDB. CRUD when using PyMODM, as with every
    ODM, is simpler than when using low-level drivers.
  prefs: []
  type: TYPE_NORMAL
- en: Creating documents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A new `user` object, as defined in Chapter 2, *Schema Design and Data Modeling,*
    can be created with a single line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we used positional arguments in the same order that they were
    defined in the `user` model to assign values to the `user` model attributes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also use keyword arguments or a mix of both, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Bulk saving can be done by passing in an array of users to `bulk_create()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Updating documents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can modify a document by directly accessing the attributes and calling `save()` again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'If we want to update one or more documents, we have to use `raw()` to filter
    out the documents that will be affected and chain `update()` to set the new values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we search for all `User` documents that have a first
    name and set a new field, `updated_at`, to the current timestamp. The result of
    the `raw()` method is `QuerySet`, a class used in PyMODM to handle queries and
    work with documents in bulk.
  prefs: []
  type: TYPE_NORMAL
- en: Deleting documents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Deleting an API is similar to updating it – by using `QuerySet` to find the
    affected documents and then chaining on a `.delete()` method to delete them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: The `BulkWrite` API is still not supported at the time of writing this book
    (December, 2018) and the relevant ticket, PYMODM-43, is open. Methods such as
    `bulk_create()` will, under the hood, issue multiple commands to the database.
  prefs: []
  type: TYPE_NORMAL
- en: Querying documents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Querying is done using `QuerySet`, as described before the `update` and `delete`
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some convenience methods available include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`all()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`count()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`first()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`exclude(*fields)` to exclude some fields from the result'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`only(*fields)` to include only some fields in the result (this can be chained
    for a union of fields)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '``limit(limit)``'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`order_by(ordering)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reverse()` if we want to reverse the `order_by()` order'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`skip(number)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`values()` to return Python dict instances instead of model instances'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By using `raw()`, we can use the same queries that we described in the previous
    PyMongo section for querying and still exploit the flexibility and convenience
    methods provided by the ODM layer.
  prefs: []
  type: TYPE_NORMAL
- en: CRUD using the PHP driver
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In PHP, there is a new driver called `mongo-php-library` that should be used
    instead of the deprecated MongoClient. The overall architecture was explained
    in Chapter 2, *Schema Design and Data Modeling*. Here, we will cover more details
    of the API and how we can perform CRUD operations using it.
  prefs: []
  type: TYPE_NORMAL
- en: Creating and deleting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following command will insert a single `$document` that contains an array
    of two key/value pairs, with the key names of `isbn` and `name`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The output from the `var_dump($result)` command is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: This rather lengthy output contains all the information that we may need. We
    can get the `ObjectId` of the document inserted; the number of `inserted`, `matched`,
    `modified`, `removed`, and `upserted` documents by fields prefixed with `n`; and
    information about `writeError` or `writeConcernError`.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are also convenience methods in the `$result` object if we want to get
    the information:'
  prefs: []
  type: TYPE_NORMAL
- en: '`$result->getInsertedCount()`: To get the number of inserted objects'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`$result->getInsertedId()`: To get the `ObjectId` of the inserted document'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can also use the `->insertMany()` method to insert many documents at once,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The result can be seen as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, `$result->getInsertedCount()` will return `2`, whereas `$result->getInsertedIds()`
    will return an array with the two newly-created `ObjectIds`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Deleting documents is a similar process to inserting documents, but uses the `deleteOne()`
    and `deleteMany()` methods instead; an example of `deleteMany()` is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code block shows the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we used `->getDeletedCount()` to get the number of affected
    documents, which is printed in the last line of the output.
  prefs: []
  type: TYPE_NORMAL
- en: BulkWrite
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The new PHP driver supports the `BulkWrite` interface to minimize network calls
    to MongoDB:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'The result can be seen as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we executed two inserts, one `update`, and a third
    `insert` in an ordered fashion. The `WriteResult` object contains a total of three
    inserted documents and one modified document.
  prefs: []
  type: TYPE_NORMAL
- en: The main difference compared to simple create/delete queries is that `executeBulkWrite()`
    is a method of the `MongoDB\Driver\Manager` class, which we instantiate on the
    first line.
  prefs: []
  type: TYPE_NORMAL
- en: Read
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Querying an interface is similar to inserting and deleting, with the `findOne()`
    and `find()` methods used to retrieve the first result or all results of a query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: In the second example, we are using a regular expression to search for a key
    name with the value, `mongo` (which is case insensitive).
  prefs: []
  type: TYPE_NORMAL
- en: 'Embedded documents can be queried using the `.` notation, as with the other
    languages that we examined earlier in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: We do this to query for a `price` embedded document inside the meta key field.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly to Ruby and Python, in PHP, we can query using comparison operators,
    as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: A complete list of comparison operators supported in the PHP driver is available
    at the end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Querying with multiple key-value pairs is an implicit `AND`, whereas queries
    using `$or`, `$in`, `$nin`, or `AND` (`$and`) combined with `$or` can be achieved
    with nested queries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: This finds documents that have `price>=60 OR price<=20`.
  prefs: []
  type: TYPE_NORMAL
- en: Updating documents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Updating documents has a similar interface with the `->updateOne() OR ->updateMany()`
    method.
  prefs: []
  type: TYPE_NORMAL
- en: The first parameter is the query used to find documents and the second one will
    update our documents.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use any of the update operators explained at the end of this chapter
    to update in place, or specify a new document to completely replace the document
    in the query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: We can use single quotes or double quotes for key names, but if we have special
    operators starting with `$`, we need to use single quotes. We can use `array(
    "key" => "value" )` or `["key" => "value"]`. We prefer the more explicit `array()`
    notation in this book.
  prefs: []
  type: TYPE_NORMAL
- en: The `->getMatchedCount()` and `->getModifiedCount()` methods will return the
    number of documents matched in the query part or the ones modified from the query.
    If the new value is the same as the existing value of a document, it will not
    be counted as modified.
  prefs: []
  type: TYPE_NORMAL
- en: CRUD using Doctrine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Following on from our Doctrine example in Chapter 2, *Schema Design and Data
    Modeling*, we will work on these models for CRUD operations.
  prefs: []
  type: TYPE_NORMAL
- en: Creating, updating, and deleting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Creating documents is a two-step process. First, we create our document and
    set the attribute values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Following this, we ask Doctrine to save `$book` in the next `flush()` call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'We can force saving by manually calling `flush()`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, `$dm` is a `DocumentManager` object that we use to connect
    to our MongoDB instance, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Updating a document is as easy as assigning values to the attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: This will save our `MongoDB with Doctrine` book with the new price of `39`.
  prefs: []
  type: TYPE_NORMAL
- en: Updating documents in place uses the `QueryBuilder` interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'Doctrine provides several helper methods around atomic updates, listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`set($name, $value, $atomic = true)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`setNewObj($newObj)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inc($name, $value)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unsetField($field)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`push($field, $value)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pushAll($field, array $valueArray)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`addToSet($field, $value)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`addManyToSet($field, array $values)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`popFirst($field)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`popLast($field)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pull($field, $value)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pullAll($field, array $valueArray)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`update` will, by default, update the first document found by the query. If
    we want to change multiple documents, we need to use `->updateMany()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we are setting the price of the book with `name='MongoDB
    with Doctrine'` to be `69`. The list of comparison operators in Doctrine is available
    in the following *Read*  section.
  prefs: []
  type: TYPE_NORMAL
- en: We can chain multiple comparison operators, resulting in an `AND` query and
    also multiple helper methods, resulting in updates to several fields.
  prefs: []
  type: TYPE_NORMAL
- en: 'Deleting a document is similar to creating it, as demonstrated in the following
    code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Removing multiple documents is best done using the `QueryBuilder` interface,
    which we will explore further in the following section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: Read
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Doctrine provides a `QueryBuilder` interface to build queries for MongoDB.
    Given that we have defined our models as described in Chapter 2, *Schema Design
    and Data Modeling**,* we can do this to obtain an instance of a `QueryBuilder` interface
    named `$db`, get a default find-all query, and execute it, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: The `$books` variable now contains an iterable lazy data-loading cursor over
    our result set.
  prefs: []
  type: TYPE_NORMAL
- en: Using `$qb->eagerCursor(true)`; over the `QueryBuilder` object will return an
    eager cursor, fetching all data from MongoDB as soon as we start iterating our
    results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some helper methods for querying are listed here:'
  prefs: []
  type: TYPE_NORMAL
- en: '`->getSingleResult()`: This is equivalent to `findOne()`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`->select(''name'')`: This returns only the values for the `''key''` attribute
    from our `books` collection. `ObjectId` will always be returned.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`->hint(''book_name_idx'')`: This forces the query to use this index. We''ll
    see more about indexes in [Chapter 7](afc0e040-c29c-4520-8daa-30a475ca9ae6.xhtml),
    *Indexing*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`->distinct(''name'')`: This returns distinct results by name.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`->limit(10)`: This returns the first `10` results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`->sort(''name'', ''desc'')`: This sorts by name (such as `desc` or `asc`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doctrine uses the concept of hydration when fetching documents from MongoDB.
    Hydration defines the query's result schema. We can, for example, configure hydration
    to return a collection of objects, a single scalar value, or an array of arrays
    representing different records. Using an identity map, it will cache MongoDB results
    in memory and consult this map before hitting the database. Disabling hydration
    can be done per query by using `->hydration(false)`, or globally using the configuration
    as explained in Chapter 2, *Schema Design and Data Modeling*.
  prefs: []
  type: TYPE_NORMAL
- en: We can also force Doctrine to refresh data in the identity map for a query from
    MongoDB using `->refresh()` on `$qb`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The comparison operators that we can use with Doctrine are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`where($javascript)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`in($values)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`notIn($values)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`equals($value)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`notEqual($value)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gt($value)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gte($value)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lt($value)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lte($value)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`range($start, $end)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`size($size)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`exists($bool)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`type($type)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`all($values)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mod($mod)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`addOr($expr)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`addAnd($expr)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`references($document)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`includesReferenceTo($document)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Consider the following query as an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: This will return all books whose price is less than 30.
  prefs: []
  type: TYPE_NORMAL
- en: '`addAnd()` may seem redundant since chaining multiple query expressions in
    Doctrine is implicitly `AND`, but it is useful if we want to do `AND ( (A OR B),
    (C OR D) )` where `A`, `B`, `C`, and `D` are standalone expressions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To nest multiple `OR` operators with an external `AND` query, and in other
    equally complex cases, the nested `ORs` need to be evaluated as expressions using
    `->expr()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: '`$expression` is a standalone expression that can be used with `$qb->addOr($expression)`
    and similarly with `addAnd()`.'
  prefs: []
  type: TYPE_NORMAL
- en: Best practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Some best practices for using Doctrine with MongoDB are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Don't use unnecessary cascading.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don't use unnecessary life cycle events.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don't use special characters such as non-ASCII ones in class, field, table,
    or column names, as Doctrine is not Unicode-safe yet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Initialize collection references in the model's constructor.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Constrain relationships between objects as much as possible. Avoid bidirectional
    associations between models and eliminate the ones that are not needed. This helps
    with performance, loose coupling, and produces simpler and more easily maintainable
    code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Comparison operators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following is a list of all comparison operators that MongoDB supports:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Name** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `$eq` | Matches values that are equal to a specified value |'
  prefs: []
  type: TYPE_TB
- en: '| `$gt` | Matches values that are greater than a specified value |'
  prefs: []
  type: TYPE_TB
- en: '| `$gte` | Matches values that are greater than or equal to the specified value
    |'
  prefs: []
  type: TYPE_TB
- en: '| `$lt` | Matches values that are less than the specified value |'
  prefs: []
  type: TYPE_TB
- en: '| `$lte` | Matches values that are less than or equal to the specified value
    |'
  prefs: []
  type: TYPE_TB
- en: '| `$ne` | Matches all values that are not equal to the specified value |'
  prefs: []
  type: TYPE_TB
- en: '| `$in` | Matches any of the values specified in an array |'
  prefs: []
  type: TYPE_TB
- en: '| `$nin` | Matches none of the values specified in an array |'
  prefs: []
  type: TYPE_TB
- en: Update operators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following is a list of all update operators that MongoDB supports:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Name** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `$inc` | This increments the value of the field by the specified amount.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `$mul` | This multiplies the value of the field by the specified amount.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `$rename` | This renames a field. |'
  prefs: []
  type: TYPE_TB
- en: '| `$setOnInsert` | This sets the value of a field if an update results in an
    insert of a document. It has no effect on update operations and modifying existing
    documents. |'
  prefs: []
  type: TYPE_TB
- en: '| `$set` | This sets the value of a field in a document. |'
  prefs: []
  type: TYPE_TB
- en: '| `$unset` | This removes the specified field from a document. |'
  prefs: []
  type: TYPE_TB
- en: '| `$min` | This only updates the field if the specified value is less than
    the existing field value. |'
  prefs: []
  type: TYPE_TB
- en: '| `$max` | This only updates the field if the specified value is greater than
    the existing field value. |'
  prefs: []
  type: TYPE_TB
- en: '| `$currentDate` | This sets the value of a field to the current date, either
    as a date or as a timestamp. |'
  prefs: []
  type: TYPE_TB
- en: Smart querying
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are several considerations when querying in MongoDB that we have to take
    into account. Here are some best practices for using regular expressions, query
    results, cursors, and when deleting documents.
  prefs: []
  type: TYPE_NORMAL
- en: Using regular expressions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'MongoDB offers a rich interface for querying using regular expressions. In
    its simplest form, we can use regular expressions in queries by modifying the
    query string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: This is done to search for books in our `books` collection that contain the
    `mongo` name. It is the equivalent of a SQL `LIKE` query.
  prefs: []
  type: TYPE_NORMAL
- en: MongoDB uses **Perl Compatible Regular Expression** (**PCRE**) version 8.39
    with UTF-8 support.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also use some options when querying:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Option** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `i` | This option queries case insensitivity. |'
  prefs: []
  type: TYPE_TB
- en: '| `m` | For patterns that include anchors (that is, `^` for the start and `$`
    for the end), this option matches at the beginning or end of each line for strings
    with multiline values. Without this option, these anchors match at the beginning
    or end of the string.If the pattern contains no anchors, or if the string value
    has no newline characters (for example, `\n`), the `m` option has no effect. |'
  prefs: []
  type: TYPE_TB
- en: 'In our previous example, if we wanted to search for `mongo`, `Mongo`, `MONGO`,
    and any other case-insensitive variation, we would need to use the `i` option,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: Alternatively, we can use the `$regex` operator, which provides more flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: 'The same queries using `$regex` will be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'By using the `$regex` operator, we can also use the following two options:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Option** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `x` | Extended capability to ignore all whitespace characters in the `$regex`
    pattern, unless they have escaped or are included in a character class.Additionally,
    it ignores characters in between (and including) an unescaped hash/pound (`#`, `£`)
    character and the next newline so that you may include comments in complicated
    patterns. This only applies to data characters; whitespace characters may never
    appear within special character sequences in a pattern.The `x` option does not
    affect the handling of the VT character. |'
  prefs: []
  type: TYPE_TB
- en: '| `s` | This option allows the dot character (that is, `.`) to match all characters,
    including newline characters. |'
  prefs: []
  type: TYPE_TB
- en: Expanding matching documents using regex makes our queries slower to execute.
  prefs: []
  type: TYPE_NORMAL
- en: Indexes using regular expressions can only be used if our regular expression
    does queries for the beginning of a string that is indexed; that is, regular expressions
    starting with `^` or `\A`. If we want to query only using a `starts with` regular
    expression, we should avoid writing lengthier regular expressions, even if they
    will match the same strings.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take the following code block as an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: Both queries will match name values starting with `mongo` (case-sensitive),
    but the first one will be faster as it will stop matching as soon as it hits the
    sixth character in every name value.
  prefs: []
  type: TYPE_NORMAL
- en: Querying results and cursors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MongoDB's lack of support for transactions means that several semantics that
    we take for granted in RDBMS work differently.
  prefs: []
  type: TYPE_NORMAL
- en: As explained previously, updates can modify the size of a document. Modifying
    the size can result in MongoDB moving the document on the disk to a new slot toward
    the end of the storage file.
  prefs: []
  type: TYPE_NORMAL
- en: When we have multiple threads querying and updating a single collection, we
    can end up with a document appearing multiple times in the result set.
  prefs: []
  type: TYPE_NORMAL
- en: 'This will happen in the following scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: Thread `A` starts querying the collection and matches document `A1`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thread `B` updates document `A1`, increasing its size and forcing MongoDB to
    move it to a different physical location toward the end of the storage file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Thread `A` is still querying the collection. It reaches the end of the collection
    and finds document `A1` again with its new value, as shown in the following diagram:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/91064db2-8b5e-4ad4-9d26-03e08cca5006.png)'
  prefs: []
  type: TYPE_IMG
- en: This is rare, but it can happen in production; if we can't safeguard from such
    a case in the application layer, we can use `snapshot()` to prevent it.
  prefs: []
  type: TYPE_NORMAL
- en: '`snapshot()` is supported by official drivers and the shell by appending it
    into an operation that returns a cursor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '`$snapshot` cannot be used with sharded collections. `$snapshot` has to be
    applied before the query returns the first document. Snapshot cannot be used together
    with the `hint()` or `sort()` operators.'
  prefs: []
  type: TYPE_NORMAL
- en: We can simulate the `snapshot()` behavior by querying using `hint({id :1})`,
    thus forcing the query engine to use the `id` index just like the `$snapshot`
    operator.
  prefs: []
  type: TYPE_NORMAL
- en: If our query runs on a unique index of a field whose values won't get modified
    during the duration of the query, we should use this query to get the same query
    behavior. Even then, `snapshot()` cannot protect us from insertions or deletions
    happening in the middle of a query. The `$snapshot` operator will traverse the
    built-in index that every collection has on the `id` field, making it inherently
    slow. This should only be used as a last resort.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to `update`, `insert`, or `delete` multiple documents without other
    threads seeing the results of our operation while it''s happening, we can use
    the `$isolated` operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: In this example, threads querying the `books` collection will see either all
    books with a price greater than `30` or no books at all. The isolated operator
    will acquire an exclusive write lock in the collection for the whole duration
    of the query, no matter what the storage engine can support, contributing to the
    contention in this collection.
  prefs: []
  type: TYPE_NORMAL
- en: Isolated operations are still not transactions; they don't provide `atomicity
    ( "all-or-nothing")`. So, if they fail midway, we need to manually roll back the
    operation to get our database into a consistent state.
  prefs: []
  type: TYPE_NORMAL
- en: Again, this should be a last resort and only used in cases where it's mission-critical
    to avoid multiple threads seeing inconsistent information at any time.
  prefs: []
  type: TYPE_NORMAL
- en: Storage considerations for the delete operation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deleting documents in MongoDB does not reclaim the disk space used by it. If
    we have 10 GB of disk space used by MongoDB and we delete all documents, we will
    still be using 10 GB. What happens under the hood is that MongoDB will mark these
    documents as deleted and may use the space to store new documents.
  prefs: []
  type: TYPE_NORMAL
- en: 'This results in our disk having space that is not used, but is not freed up
    for the operating system. If we want to claim it back, we can use `compact()`
    to reclaim any unused space:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: Alternatively, we can start the `mongod` server with the `--repair` option.
  prefs: []
  type: TYPE_NORMAL
- en: A better option is to enable compression, which is available from version 3.0
    and only with the WiredTiger storage engine. We can use the snappy or zlib algorithms
    to compress our document size. This will, again, not prevent storage holes, but
    if we are tight on disk space, it is preferable to the heavy operational route
    of repair and compact.
  prefs: []
  type: TYPE_NORMAL
- en: Storage compression uses less disk space at the expense of CPU usage, but this
    trade-off is mostly worth it.
  prefs: []
  type: TYPE_NORMAL
- en: Always take a backup before running operations that can result in a catastrophic
    loss of data. Repair or compact will run in a single thread, blocking the entire
    database from other operations. In production systems, always perform these on
    the slave first; then switch the master-slave roles, and compact the ex-master,
    now-slave instance.
  prefs: []
  type: TYPE_NORMAL
- en: Change streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Change streams functionality was introduced in version 3.6 and augmented in
    version 4.0, making it a safe and efficient way to listen for database changes.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The fundamental problem that change streams solve is the need for applications
    to react immediately to changes in the underlying data. Modern web applications
    need to be reactive to data changes and refresh the page view without reloading
    the entire page. This is one of the problems that frontend frameworks (such as
    Angular, React, and Vue.js) are solving. When a user performs an action, the frontend
    framework will submit the request to the server asynchronously and refresh the
    relevant fragment of the page based on the response from the server.
  prefs: []
  type: TYPE_NORMAL
- en: Thinking of a multiuser web application, there are cases where a database change
    may have occurred as a result of another user's action. For example, in a project
    management Kanban board, user A may be viewing the Kanban board, while another
    user, B, may be changing the status of a ticket from "To do" to "In progress".
  prefs: []
  type: TYPE_NORMAL
- en: 'User A''s view needs to be updated with the change that user B has performed
    in real time, without refreshing the page. There are already three approaches
    to this problem, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The most simple approach is to poll the database every X number of seconds and
    determine if there has been a change. Usually this code will need to use some
    kind of status, timestamp, or version number to avoid fetching the same change
    multiple times. This is simple, yet inefficient, as it cannot scale with a great
    number of users. Having thousands of users polling the database at the same time
    will result in a high database-locking rate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To overcome the problems imposed by the first approach, database-and application-level
    triggers have been implemented. A database trigger relies on the underlying database
    executing some code in response to a database change. However, the main downside
    is again similar to the first approach in that the more triggers that we add to
    a database, the slower our database will become. It is also coupled to the database,
    instead of being a part of the application code base.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we can use the database transaction or replication log to query for
    the latest changes and react to them. This is the most efficient and scalable
    approach of the three previously mentioned as it doesn't put a strain on the database.
    The database writes to this log anyway, it is usually append only and our background
    task serially reads entries as they come into the log. The downside of this method
    is that it is the most complicated one to implement and one that can lead to nasty
    bugs if it's not implemented properly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change streams provide a way to solve this problem that is developer-friendly
    and easy to implement and maintain. It is based on the oplog, which is essentially
    MongoDB's operations log, containing each and every operation happening server-wide
    across all databases in the server. This way the developer does not have to deal
    with the server-wide oplog or tailable cursors, which are often not exposed or
    easy to deal with from MongoDB language-specific drivers. Also, the developer
    does not have to decipher and understand any of the internal oplog data structures
    that are designed and built for MongoDB's benefit, and not for an application
    developer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Change streams have other advantages in which they are secure: users can only
    create change streams on collections, databases, or deployments to those for which
    they have read access.'
  prefs: []
  type: TYPE_NORMAL
- en: Change streams are also idempotent by design. Even in the case that the application
    cannot fetch the absolute latest change stream event notification ID, it can resume
    applying from an earlier known one and it will eventually reach the same state.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, change streams are resumable. Every change stream response document
    includes a resume token. If the application gets out of sync with the database,
    it can send the latest resume token back to the database and continue processing
    from there. This token needs to be persisted in the application, as the MongoDB
    driver won't keep application failures and restarts. It will only keep state and
    retry in case of transient network failures and MongoDB replica set elections.
  prefs: []
  type: TYPE_NORMAL
- en: Setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A change stream can be opened against a collection, a database, or an entire
    deployment (such as a replica set or sharded cluster). A change stream will not
    react to changes in any system collection or any collection in the admin, config,
    and local databases.
  prefs: []
  type: TYPE_NORMAL
- en: A change stream requires a WiredTiger storage engine and replica set protocol
    version 1 (pv1). pv1 is the only supported version starting from MongoDB 4.0\.
    Change streams are compatible with deployments that use encryption-at-rest.
  prefs: []
  type: TYPE_NORMAL
- en: Using change streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To use a change stream, we need to connect to our replica set. A replica set
    is a prerequisite to using change streams. As change streams internally use the
    oplog, it's not possible to work without it. Change streams will also output documents
    that won't be rolled back in a replica set setting, so they need to follow a majority
    read concern. Either way, it's a good practice to develop and test locally using
    a replica set, as this is the recommended deployment for production. As an example,
    we are going to use a `signals` collection within our database named `streams`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the following sample Python code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: We can open one Terminal and run it using `python change_streams.py`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, in another Terminal, we connect to our MongoDB replica set using the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Going back to our first Terminal window, we can now observe that the output
    is similar to the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: What has happened here is that we have opened a cursor watching the entire `streams` database
    for changes. Every data update in our database will be logged and outputted in
    the console.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if we go back to the mongo shell, we can issue the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'The Python code output should then be similar to the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: This means that we are getting notifications for each and every data update
    across all collections in our database.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can then change line 11 of our code to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: This will result in only watching the `signals` collection, as should be the
    most common use case.
  prefs: []
  type: TYPE_NORMAL
- en: 'PyMongo''s `watch` command can take several parameters, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'The most important parameters are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Pipeline`: This is an optional parameter that we can use to define an aggregation
    pipeline to be executed on each document that matches `watch()`. Because the change
    stream itself uses the aggregation pipeline, we can attach events to it. The aggregation
    pipeline events we can use are as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: '`Full_document`: This is an optional parameter that we can use by setting it
    to `''updateLookup''` to make change streams return both a delta describing the
    changes to the document, and a copy of the entire document that was changed from
    some time after the change occurred in the case of a partial update.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Start_at_operation_time`: This is an optional parameter that we can use to
    only watch for changes that occurred at, or after, the specified timestamp.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Session`: This is an optional parameter in case our driver supports passing
    a `ClientSession` object to watch for updates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change streams response documents have to be under 16 MB in size. This is a
    global limit in MongoDB for BSON documents and the change stream has to follow
    this rule.
  prefs: []
  type: TYPE_NORMAL
- en: Specification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following document shows all of the possible fields that a change event
    response may or may not include, depending on the actual change that happened:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'The most important fields are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `fullDocument` | This is the new state of the document, which can include
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: If it's a delete operation, this field is omitted as the document no longer
    exists.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If it's an insert or replace operation, this will be the new value of the document.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If it's an update operation and we have enabled `'updateLookup'`, then it will
    have the most recently major-committed version of the document modified by the
    update operation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| `operationType` | This is the type of operation; it can be either of `insert`,
    `delete`, `replace`, `update`, or `invalidate`. |'
  prefs: []
  type: TYPE_TB
- en: '| `documentKey` | This is `ObjectID` of the document that was affected by the
    operation. |'
  prefs: []
  type: TYPE_TB
- en: '| `updateDescription.updatedFields / removedFields` | This is a document or
    an array of keys respectively, showing the data that was updated or removed by
    the update or remove operation. |'
  prefs: []
  type: TYPE_TB
- en: '| `txnNumber` | This is the transaction number. It is only applicable if the
    operation is part of a multi-document **ACID** (**atomicity, consistency, isolation,
    durability**) transaction. |'
  prefs: []
  type: TYPE_TB
- en: '| `lsid` | This is the session identifier of the transaction. It is only applicable
    if the operation is part of a multi-document ACID transaction. |'
  prefs: []
  type: TYPE_TB
- en: Important notes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When using a sharded database, change streams need to be opened against a MongoDB
    server. When using replica sets, a change stream can only be opened against a
    data-bearing instance. Each change stream will open a new connection, as of 4.0.2\.
    If we want to have lots of change streams in parallel, we need to increase the
    connection pool (as per the SERVER-32946 JIRA MongoDB ticket) to avoid severe
    performance degradation.
  prefs: []
  type: TYPE_NORMAL
- en: Production recommendations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Change streams are a fairly recent addition to the MongoDB database. As such,
    the following recommendations for production deployments may change in later versions.
    These are the guidelines as recommended by MongoDB and expert architects at the
    time of writing this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Replica sets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A change stream will only process an event that has been written to the majority
    of members processing data. It will pause if we lose the majority of data-storing
    servers, or if we rely on arbiters to establish a majority.
  prefs: []
  type: TYPE_NORMAL
- en: Invalidating events, such as dropping or renaming a collection, will close the
    change stream. We cannot resume a change stream after an invalidate event closes
    it.
  prefs: []
  type: TYPE_NORMAL
- en: As the change stream relies on the oplog size, we need to make sure that the
    oplog size is large enough to hold events until they are processed by the application.
  prefs: []
  type: TYPE_NORMAL
- en: Sharded clusters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'On top of the considerations for replica sets, there are a few more to keep
    in mind for sharded clusters. They are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The change stream is executed against every shard in a cluster and will be as
    fast as the slowest shard.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To avoid creating change stream events for orphaned documents, we need to use
    the new feature of ACID compliant transactions if we have multi-document updates
    under sharding.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While sharding an unsharded collection (that is, migrating from replica sets
    to sharding), `documentKey` of the change stream notification document will include `_id`
    until the change stream catches up to the first chunk migration.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we went through advanced querying concepts using Ruby, Python,
    and PHP by both using the official drivers and an ODM.
  prefs: []
  type: TYPE_NORMAL
- en: Using Ruby and the Mongoid ODM, Python and the PyMODM ODM, and PHP and the Doctrine
    ODM, we went through code samples exploring how to `create`, `read`, `update`,
    and `delete` documents.
  prefs: []
  type: TYPE_NORMAL
- en: We also discussed batching operations for performance and best practices. We
    presented an exhaustive list of comparison and update operators that MongoDB uses.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we discussed smart querying, how cursors in querying work, what our
    storage performance considerations should be on delete, and how to use regular
    expressions.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about the aggregation framework, using a
    complete use case that involves processing transaction data from the Ethereum
    blockchain.
  prefs: []
  type: TYPE_NORMAL
