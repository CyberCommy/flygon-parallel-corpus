- en: Profiling Applications for Performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the course of this book, we have seen how much the performance and scalability
    of an application matters inside an enterprise environment; with this in mind,
    we dedicated a significant portion of the book to understanding how to build an
    application that is not only performant but is also scalable.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have just seen some best practices for what we can do to build a
    performant and scalable application, but not how to figure out whether a particular
    piece of code in our application is slow and what might be causing it.
  prefs: []
  type: TYPE_NORMAL
- en: For any enterprise-grade application, improving its performance and scalability
    is an ongoing process, as the user base of the application keeps growing and the
    application's ...
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The code listings in this book can be found under `chapter09` directory at [https://github.com/PacktPublishing/Hands-On-Enterprise-Application-Development-with-Python.](https://github.com/PacktPublishing/Hands-On-Enterprise-Application-Development-with-Python)
  prefs: []
  type: TYPE_NORMAL
- en: The code samples related to the profiling and benchmarking of bugzot sample
    application can be found under the `chapter06` directory itself under the tests
    module of the code base.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code samples can be cloned by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This chapter also has some dependencies on third-party Python libraries, which
    can be easily installed by running the following command on your development system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Behind the scenes of performance bottlenecks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before an application enters the development phase, there is a thorough discussion
    on what the application is supposed to do, how it will do it, and what kind of
    third-party components the application will need to interact with. Once all of
    this is finalized, the application enters the development phase, where the developers
    are responsible for building the application in such a way that the tasks to be
    performed by the application can be achieved in the most efficient manner possible.
    This efficiency is usually measured in terms of how much time an application takes
    to complete a provided task and how many resources it uses while working on that
    task.
  prefs: []
  type: TYPE_NORMAL
- en: When the application is deployed into production, ...
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the causes of performance bottlenecks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Usually, performance bottlenecks can be caused by a number of factors, which
    may include shortage of physical resources in the environment where the application
    is deployed or choosing a bad algorithm to process a particular workload when
    a better algorithm was available. Let''s take a look at some of the possible issues
    that may lead to performance bottlenecks in a deployed application:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Not having enough hardware resources:** Initially, most of the bottlenecks
    in performance and scalability are due to poor planning of the hardware resources
    required to run an application. This may happen due to incorrect estimations or
    a sudden unplanned surge in the user base of the application. When this happens,
    the existing hardware resources get stressed and the system slows down.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Incorrect design choices:** In [Chapter 2](8e39d4d7-6b81-4724-8baa-e09d43c68475.xhtml),* Design
    Patterns – Making a Choice*, we looked at how important design choices are to
    any enterprise-grade application. Constantly allocating new objects for something
    that could have been done through the allocation of a single shared object is
    going to impact the application''s performance by not only stressing the available
    resources but also by causing unnecessary delays due to repeated allocations of
    objects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inefficient algorithms:** The places where a large amount of data is being
    processed or the systems that perform a large amount of calculations to generate
    a result may often see degraded performance due to choosing inefficient algorithms.
    A careful study of the availability of alternative algorithms or in-place algorithmic
    optimizations may help boost the performance of the application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Memory leaks:** In large applications, there could be places where memory
    leaks may happen in an unexpected manner. Although this is difficult in garbage-collected
    languages such as Python, it''s still a possibility. There could be times when
    objects, although no longer in use, still aren''t garbage collected because of
    the way they have been mapped inside the application. Over a longer period of
    runtime, this will cause the available memory to decrease and eventually will
    bring the application to a halt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These were a few reasons why performance bottlenecks in a system happen. Fortunately
    for us as software developers, we have a number of tools that can help us pinpoint
    bottlenecks, as well as find things such as memory leaks or even just profile
    the memory usage of individual portions.
  prefs: []
  type: TYPE_NORMAL
- en: With this knowledge about why some performance bottlenecks happen, it's time
    for us to move onto learning how to look for these performance bottlenecks in
    an application and then trying to understand some of the ways we can reduce their
    impact.
  prefs: []
  type: TYPE_NORMAL
- en: Probing an application for performance issues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Performance is a critical component of any enterprise-grade application, and
    you cannot afford to have an application that slows down often and impacts the
    business process of the whole organization. Unfortunately, performance issues
    are also one of the most complex issues to understand and debug. This complexity
    arises because there's no standard way to access the performance of a particular
    piece of code inside the application, and because once the application has been
    developed, the complete flow of code needs to be understood so as to pinpoint
    the possible areas that might cause a specific performance issue.
  prefs: []
  type: TYPE_NORMAL
- en: As developers, we can reduce these hardships by building our application in
    such a ...
  prefs: []
  type: TYPE_NORMAL
- en: Writing performance benchmarks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's start with a discussion about how we, as software developers, can build
    the application in a way that helps us flag the performance bottlenecks early
    in the development cycle and how we can make our life easy in terms of debugging
    these bottlenecks.
  prefs: []
  type: TYPE_NORMAL
- en: The first and most important thing we can do during our application development
    cycle is to write benchmark tests for the individual components of our application.
  prefs: []
  type: TYPE_NORMAL
- en: Benchmark tests are simple tests that aim to evaluate the performance of a particular
    piece of code by executing it for multiple iterations and averaging the time required
    to execute the code over those iterations. Do you remember hearing the name of
    a library known as Pytest, which we used to write unit tests in [Chapter 8](4d91a05b-243d-4e79-9112-7ca44520c596.xhtml), *Writing
    Testable Code*?
  prefs: []
  type: TYPE_NORMAL
- en: 'We''re going to utilize the same library to help us write our performance benchmark
    tests. But, before we can make Pytest usable for writing benchmark tests, we need
    to make it understand the benchmarking concept, which is very easy with Python,
    specifically because of the availability of a huge Python ecosystem. To make Pytest
    understand the concept of benchmarking, we are going to import a new library known
    as `pytest-benchmark`, which adds benchmarking fixtures to Pytest and allows us
    to write benchmarking tests for our application. To do this, we need to run the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Once we have the library installed, we are ready to write our performance-benchmarking
    tests for our application.
  prefs: []
  type: TYPE_NORMAL
- en: Writing our first benchmark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the required library installed, it''s time for us to write our first performance
    benchmark. For this, we will use a simple example and then move forward to understand
    how we can write a benchmark test for our application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We have written our first benchmark test. A very simple one indeed, but there
    are quite a few things which we need to understand to see what we are doing here:'
  prefs: []
  type: TYPE_NORMAL
- en: First, as we started writing the benchmark test, we imported ...
  prefs: []
  type: TYPE_NORMAL
- en: Writing an API benchmark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With this, we know how to write a simple benchmark. So, how about writing something
    similar for our API? Let's take a look at how we can modify one of our API tests
    that we used to validate the functioning of our index API endpoint and see how
    we can run a benchmark on that.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code modifies our existing index API test case to include a benchmark
    test for the API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, all we did to make the API endpoint benchmark was add
    a new method, known as `test_index_benchmark()`, which takes in two fixtures as
    a parameter. One of the fixtures is responsible for setting up our application
    instance, and the second fixture—the benchmark fixture—is used to run the benchmark
    on the client API endpoint and generate the results.
  prefs: []
  type: TYPE_NORMAL
- en: Also, one important thing to note here is how we were able to mix the unit test
    code with the benchmark code so that we do not need to write two different methods
    for each class of the test; all of this is made possible by Pytest, which allows
    us to run the benchmark on the method as well as allow us to validate if the method
    being tested provides a correct result or not through the use of a single testing
    method.
  prefs: []
  type: TYPE_NORMAL
- en: Now we know how to write benchmark tests inside the application. But what if
    we had to debug something that was slow but for which the benchmark operation
    doesn't flags any concern. What can we do here? Fortunately for us, Python provides
    a lot of options that allow us to test for any kind of performance anomalies that
    may happen inside the code. So, let's spend some time looking over them.
  prefs: []
  type: TYPE_NORMAL
- en: Doing component-level performance analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With Python, a lot of facilities come built-in and others can be easily implemented
    with third-party libraries. So, let's take a look at what python has in store
    for us for running component-level performance analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring slow operations with timeit
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python provides a very nice module, known as `timeit`, that we can use to run
    some simple time-analysis tasks on small snippets of code or to understand how
    much time a particular method call is taking.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at a simple script that shows us how we can use `timeit` to
    understand how much time a particular method is taking, and then we will understand
    a bit more about how we can use the functionality provided by `timeit` to run
    time-profiling for the applications that we intend to build.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet shows a simple use of `timeit` for running timing
    analysis on a method call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'On running this file, we get an output that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: As we can see from the preceding example, we can use `timeit` to do a simple
    time analysis for the execution of a given method.
  prefs: []
  type: TYPE_NORMAL
- en: Now, this is handy, but we cannot go on writing multiple setup statements when
    we have to time more than a couple of methods. What should we do here? There should
    be a simple way to achieve this.
  prefs: []
  type: TYPE_NORMAL
- en: So, how about we create a simple decorator that we can use to time our methods
    that may need time profiling.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create this simple decorator method. The following example shows us
    how to write a decorator method that we can use later to do time comparisons on
    our methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This was a decorator that we created. Inside the decorator, we take in the function
    that we want to profile as a parameter, along with any of the arguments that were
    passed to it. Now, we initialize the start time for the function, followed by
    a call to the function and then we store the end time of the call once the execution
    of the function returns. Based on this, we calculate the total time it took for
    the function to execute.
  prefs: []
  type: TYPE_NORMAL
- en: 'But how can we use this decorator to profile our methods? The following example
    shows a sample of that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This was very simple and far easier to do than importing individual methods
    again and again for the timing profile.
  prefs: []
  type: TYPE_NORMAL
- en: So, our `timeit` method is a very simple method to use and can provide us with
    some basic information about how much time it took for a particular method to
    execute. We can even profile individual statements with these methods. But what
    if we wanted a more detailed explanation of how much time individual statements
    are taking inside a particular method or to understand what exactly is causing
    a given method to slow down? For things such as these, our simple timing solution
    isn't an ideal option. We need something more sophisticated.
  prefs: []
  type: TYPE_NORMAL
- en: As a matter of fact, Python provides us with some built-in profilers that we
    can use to perform in-depth performance profiling of an application. Let's take
    a look at how we can do this.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling with cProfile
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Python library provides us with an application profiler which can help ease
    the life of the developers by allowing to easily profile not only the whole application,
    but also the individual components of the application.
  prefs: []
  type: TYPE_NORMAL
- en: Profile is a built-in code profiler that comes bundled as a module with some
    of the python distributions. The module is able to collect the information about
    the individual method calls that have been made, along with the profiling of any
    of the calls made to third-party functions.
  prefs: []
  type: TYPE_NORMAL
- en: Once these details are collected, the module provides us with a host of statistics
    that can help us get a better picture of what's going on inside the component.
    Before we dive into what details are collected and represented, ...
  prefs: []
  type: TYPE_NORMAL
- en: Profiling for memory usage with memory_profiler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Memory profiling forms a very important aspect of the performance analysis of
    an application. When building an application, there are places where we may implement
    an incorrect mechanism of dealing with the dynamically allocated objects and hence
    may land up in a situation where these objects which are no longer in use are
    still having a reference pointing to them preventing their garbage collection
    by the Garbage Collector.
  prefs: []
  type: TYPE_NORMAL
- en: This results in the growth of the application-memory usage over time, causing
    the application to come to a halt once the system runs out of memory that can
    be allocated to the application for performing its regular activities.
  prefs: []
  type: TYPE_NORMAL
- en: Now, to address these kinds of issues, we don't require a profiler that will
    help us analyze the call stack of the application and provide us details about
    how much time an individual call took. Instead, what we need here is a profiler
    that can tell us about the memory trends of an application, such as how much memory
    individual methods might be consuming and how that memory grows as the application
    continues to run.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the place where `memory_profiler` comes in, which is a third-party
    module that we can easily include in our application to allow memory profiling.
    But, before we dive into how to use `memory_profiler`, we need to get the module
    into our development environment first. The following line of code fetches the
    required module into our development environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Once the memory profiler has been fetched into the developer environment, we
    are now ready to get up and running with it. Let's take a look at a sample program
    and see how we can use `memory_profiler` to understand the memory usage patterns
    of our application.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet shows us an example of how we can use `memory_profiler`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Now, with the code in place, let's try to understand what we did here.
  prefs: []
  type: TYPE_NORMAL
- en: At the start, we imported a decorator known as profile, which is provided by
    the `memory_profiler` library. This decorator is used to notify `memory_profiler`
    of which methods needs to be profiled for the memory usage.
  prefs: []
  type: TYPE_NORMAL
- en: To enable memory profiling for a method, all we need to do is decorate that
    method with the decorator. For example, in our sample application code, we decorated
    the `calc_sum()` method with the decorator.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s run our sample code and see what we get as an output by running
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the command is executed, we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: As we can see from the preceding output, we got some detailed statistics about
    the memory allocation for the method. The output provided us information about
    how much memory was being used and how much memory increment each of the steps
    caused to the application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s take one more example to see how the memory allocation changes
    when one method calls another method. The following code showcases this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'On executing the preceding code, we get to see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, when a call to the `say_hello()` method was made, the call caused
    an increment of 0.1 MB of memory usage. This is quite a handy library in case
    we suspect that there's some memory leak that may be happening somewhere in the
    code.
  prefs: []
  type: TYPE_NORMAL
- en: Collecting live performance data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have seen how we can use the different profiling tools to profile
    the performance of the application when needed so as to assist us in figuring
    out which portion of the code is causing performance bottlenecks. But how will
    we know whether an operation is taking long than it should?
  prefs: []
  type: TYPE_NORMAL
- en: One of the answers to this could be the slow response times being reported by
    users, but that could have quite a lot of factors behind it, which may involve
    a slowdown at the user end only.
  prefs: []
  type: TYPE_NORMAL
- en: There are a few other mechanisms that we can use to monitor the performance
    issues in our application in real time. So, let's take a look at one of these
    methods, which allows us to gather information about the time taken for individual
    ...
  prefs: []
  type: TYPE_NORMAL
- en: Logging performance metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Inside an application, there could be several steps. Each of these steps can
    be profiled for their performance through the use of different tools. One of the
    most basic tools is logging. In this, we collect the execution time of the different
    methods and keep the entry for it inside the log file.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following snippet of code shows a small example of how this can be achieved
    inside the demo application that we built in [Chapter 6](68cb369b-628d-4950-91fd-b165b961c660.xhtml), *Example
    – Building BugZot*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This was a simple code and logs the execution time of every API endpoint called
    in a request. What we do here is very minimalistic. We first create a `before_request`
    handler, which initializes a property, `start_time`, in the flask global namespace.
    Once this is done, the request is sent to processing. Once the request has been
    processed, it goes to the `teardown` handler that we have defined.
  prefs: []
  type: TYPE_NORMAL
- en: Once the request reaches this `teardown` handler, we calculate the total time
    it took to process the request and log it inside the application logs.
  prefs: []
  type: TYPE_NORMAL
- en: This kind of approach allows us to query or process our log files to understand
    how much time every request is taking and which API endpoints are taking the longest
    amount of time.
  prefs: []
  type: TYPE_NORMAL
- en: Avoiding performance bottlenecks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the last few sections, we took a look at the different ways we can profile
    our application for different kinds of performance bottlenecks that may involve
    slowdowns to memory leaks. But once we're aware of these issues and why they're
    happening, what other options do we have to prevent them from occurring again?
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortunately, we have a couple of helpful guidelines that may help prevent performance
    bottlenecks or can limit the possible impact of these bottlenecks. So, let''s
    take a look at some of these guidelines:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Choosing the correct design patterns:** Design patterns are an important
    choice in the application. For example, a logging object doesn''t need to be reinitialized
    in every submodule of the application ...'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we took a look at how the performance of an application is
    an important aspect of the software's development and what kind of issues usually
    cause performance bottlenecks to appear in the application. Moving forward, we
    took a look at the different ways in which we can profile an application for performance
    issues. This involved, first the writing of benchmark tests for individual components
    as well as the individual APIs and then moving to more specific, component-level
    analysis, where we took a look at different ways of profiling the components.
    These profiling techniques included the use of simple timing profiles of methods
    using the Python `timeit` module, then we moved on to using more sophisticated
    techniques with Python cProfile and covered memory profiling. Another topic we
    took a look at during our journey is the use of logging techniques to help us
    evaluate slow requests whenever we want. Finally, we took a look at some of the
    general principles that can help us to prevent performance bottlenecks inside
    an application.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will take a look at how important it is to secure our
    application. If not done, it'll not only pave the way to serious data theft, but
    also a lot of liabilities and can erode the trust of your users.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What factors can cause a performance bottleneck when the application is deployed?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the different ways in which we can run a time profile on a method?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What may cause a memory leak in Python, which is a garbage-collected language?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can we profile an API response and figure out what could be the cause of
    its slowing down?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Can choosing an incorrect design pattern result in a performance bottleneck?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
