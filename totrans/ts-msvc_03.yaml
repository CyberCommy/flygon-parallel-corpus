- en: Exploring Reactive Programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Until now, we described our application as a mixture of very famous industry
    buzz words, such as asynchronous, real-time, loosely coupled, scalable, distributed,
    message-driven, concurrent, non-blocking, fault tolerant, low latency, and high
    throughput. In this chapter, we'll go one step further and understand reactive
    programming, which brings together all of these characteristics. We will see and
    understand the Reactive Manifesto—a set of principles that when collectively applied,
    will bring all of the preceding advantages. We will understand some key aspects
    of a reactive microservice, what it should be, and what are the key advantages
    of reactive programming. We will look at what problems reactive programming solves,
    different styles of reactive programming, and more.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will focus on the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to reactive programming
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reactive Manifesto
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reactive microservice—major building blocks and concerns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When to react and when not to react (orchestrate)—introduction to hybrid approaches
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Being reactive in Node.js
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to reactive programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If we want a view of reactive programming from 50,000 above ground level, it
    can briefly be termed as:'
  prefs: []
  type: TYPE_NORMAL
- en: <q>When input x in any function changes, output y automatically updates in the
    corresponding response without the need to manually invoke it. In short, the sole
    purpose is to continuously respond to external inputs whenever prompted by output
    worlds.</q>
  prefs: []
  type: TYPE_NORMAL
- en: Reactive programming is achieved through utilities such as map, filter, reduce,
    subscribe, unsubscribe, streams. Reactive programming focuses more on events and
    message-driven patterns rather than manually fiddling with huge implementation
    details.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a practical day-to-day example to understand reactive programming.
    We all have used Excel since the beginning of our IT lives. Now, let's say you
    write one formula based on a cell value. Now, whenever the cell value is changed,
    all corresponding results based on that value will reflect the change automatically.
    That's called being **reactive**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Briefly understanding reactive programming when combined to deal with various
    data flows, the reactive programming can be advanced data flows with the ability
    to handle the following things:'
  prefs: []
  type: TYPE_NORMAL
- en: Event streams, streams we can tap into and subscribe, and then use subscription
    output as a data source.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having streams gives us the ability to manipulate streams, create new streams
    from original ones, and apply transformations as and when needed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transformations should work independently in a distributed system. A specific
    transformation can be the merge of several streams received from various places.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Functional reactive programming is the variant of reactive programming that
    we are going to use. Briefly stated, our functional reactive microservice should
    have the following two fundamental properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Signifying or denotative**: Each function, service, or type is precise, simple,
    single, responsible, and implementation-independent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Continuous time**: Programming should keep in mind time-varying values. Variables
    in functional reactive programming have a value for a very short time. It should
    provide us transformation flexibility, efficiency, modularity, single responsibility.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following are the characteristics of functional reactive programming:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dynamic**: Knows how to react to time or to handle various input changes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Handle time variations**: When reacting values change continuously, handle
    appropriate changes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Efficient**: When there is a change in input value, have a minimum amount
    of processing as and when required'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Aware of historic transitions**: Maintain state changes locally and not globally'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we briefly know about reactive programming, let's look into what advantages
    we get while adopting reactive programming. The next section talks about and gives
    us very strong reasons for why you should drop everything and start reactive programming.
  prefs: []
  type: TYPE_NORMAL
- en: Why should I consider adopting reactive programming?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have unveiled the mystery of reactive programming, the next big
    question is why we should care about reactive programming and what advantages
    we can get while doing reactive programming. In this section, we''ll see major
    benefits of reactive programming and how easily code can be managed to introduce
    major new functionalities at any point in time:'
  prefs: []
  type: TYPE_NORMAL
- en: Easy to interpret or tap into any functions compared to callbacks or middleware.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handle errors and memory management easily, without any centralized configurations.
    A single subscription can have an error function in which you can easily dispose
    of the resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Efficiently handle time-related complexities. Sometimes, we are bound by rate
    limiting constraints in calling some external APIs such as the Google Cloud Vision
    API. Reactive programming has immense use cases in such situations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Go to market rate is faster. When correctively implemented, reactive programming
    drastically reduces old school code to a very few lines of code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Easy-to-handle throttleable input streams, that is, my input stream is dynamic.
    It can increase or decrease as per demand.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have gone through some of the major advantages of reactive programming,
    in the next section we will talk about the outcome of reactive programming, a
    reactive system. We will see a set of standards defined in the Reactive Manifesto.
  prefs: []
  type: TYPE_NORMAL
- en: Reactive Manifesto
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A reactive system is meant to be more loosely coupled, flexible, easy to migrate,
    and easily scalable on demand. These qualities make it easy to develop, gracefully
    handle faults, and react to errors. Errors are met with elegance rather than claustrophobic
    disasters. Reactive systems are effective and instantly respond, giving effective
    and interactive feedback to users. In order to summarize all the traits of a reactive
    system, the **Reactive Manifesto** was introduced. In this section, we'll look
    at the Reactive Manifesto and all the criteria needed. Now, let's look at what
    the Reactive Manifesto states.
  prefs: []
  type: TYPE_NORMAL
- en: Responsive systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As part of responsive criteria, reactive systems always need to be responsive.
    They need to provide and respond to the user in a timely manner. This improves
    user experience, and we can handle errors in a better way. Any failure in the
    service should not propagate to the system, as it can cause a series of errors.
    A response is an essential thing. A failed service should provide a response even
    if it is degraded.
  prefs: []
  type: TYPE_NORMAL
- en: Resilient to errors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Systems should be resilient to all errors. Resiliency should be such that errors
    are handled gracefully and not crash the entire system. A resilient architecture
    can be achieved by the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Replication in order to make sure that there's a replica in case the main node
    goes down. This avoids single points of failure. In order to make sure that components
    or services should delegate services between them in such a way that single responsibility
    is handled.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensuring containment and isolation in the system so that the component is contained
    in its boundaries. It should prevent cascading errors. The client of a component
    is not burdened with handling its own failures.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elastic scalable
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is usually used to reference a system's capability to handle varying loads
    by increasing or decreasing the number of resources utilized in time. Reactive
    systems should be able to react to a point-in-time load and take actions on the
    available resources accordingly to provide a cost-effective solution, that is,
    or scaling down when resources are not required, scaling up but only to that percentage
    of resources that is needed in order to keep the cost of infrastructure under
    a preset value. The system should be able to shard or replicate components and
    distribute inputs among them. A system should have the ability to spawn new instances
    for downstream and upstream services for client service requests as and when needed.
    There should be an efficient service discovery process to aid elastic scaling.
  prefs: []
  type: TYPE_NORMAL
- en: Message-driven
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Asynchronous message passing is the base of reactive systems. This helps us
    to establish boundaries between components and parallelly ensure loose coupling,
    isolation, and location transparency. If a particular component is not available
    now, the system should delegate failures as messages. This pattern helps us to
    enable load management, elasticity, and flow control by controlling the message
    queues in the system with the option of applying back pressure as and when needed.
    Non-blocking communication leads to less system overhead. There are many tools
    available for message passing such as **Apache Kafka**, **Rabbit MQ**, **Amazon
    Simple Queue Service**, **ActiveMQ**, **Akka**, and so on. Different modules of
    the code interact with each other via message passing. Thinking deeply about the
    Reactive Manifesto, microservices just seems to be an extension of the Reactive
    Manifesto.
  prefs: []
  type: TYPE_NORMAL
- en: Major building blocks and concerns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Continuing on our reactive journey, we will now talk about major building blocks
    of reactive programming (functional reactive programming to be precise) and what
    concerns a reactive microservice should actually handle. The following is a list
    of major building blocks of reactive programming and what they all handle. A reactive
    microservice should be designed on similar principles. These building blocks will
    allow us to make sure that a microservice is isolated, has a single responsibility,
    can pass a message asynchronously, and is mobile.
  prefs: []
  type: TYPE_NORMAL
- en: Observable streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An oservable streams is nothing but an array that is built over time. Instead
    of being stored in memory, items arrive asynchronously over time. Observables
    can be subscribed to, and events emitted by them can be listened to and reacted
    upon. Every reactive microservice should be able to deal with native observable
    streams of events. An observable allows you to emit values to the subscriber by
    calling the `next()` function in the series:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hot and cold observables**: Observables are further classified into hot and
    cold, based on the producer of the subscription. If it needs to be created more
    than once, it is called a **hot observable**, whereas if it needs to be created
    only once, it is called a **cold observable**. Simply stated, hot observables
    usually *multicast,* while cold observables usually *unicast*. Taking a live example,
    when you open up any video on YouTube, each subscriber will see the same sequence,
    from start to end that''s basically a cold observable. However, when you open
    a live stream, you only can view the most recent view and see further on. This
    is a hot observable, where only a reference to the producer/subscriber is there
    and the producer is not created from the beginning of each subscription.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Subjects**: A subject is just an observable that can call the `next()` method
    by itself in order to emit new values on demand. Subjects allow you to broadcast
    values from a common point while limiting the subscription to only one occurrence.
    A single shared subscription is created. A subject can be termed both an observer
    and as observable. It can act as a proxy for a group of subscribers. Subjects
    are used for implementing observables for general purpose utilities such as caching,
    buffering, logs, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Subscription
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While an observable is an array that fills over time, a **subscription** is
    a `for` loop that iterates over that array, which happens over time. A subscription
    provides easy to use and easy to dispose of methods, so there are no memory loading
    issues. On disposing of a subscription, an observable will stop listening to particular
    subscriptions.
  prefs: []
  type: TYPE_NORMAL
- en: emit and map
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When an observable throws out a value, there is a subscriber that listens to
    the value thrown by the observable. **emit** and **map** allow you to listen to
    this value and manipulate it as per your needs. For example, it can be used to
    convert a response of an HTTP observable to JSON. To further add-on to the chain,
    the `flatMap` operator is provided, which creates a new stream from the functions
    return value it receives.
  prefs: []
  type: TYPE_NORMAL
- en: Operator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When an observable emits values, they are not always in the form that we desire.
    Operators come in handy, as they help us to alter the way in which observables
    emit values. Operators can be used in the following stages:'
  prefs: []
  type: TYPE_NORMAL
- en: While creating an observable sequence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Converting events or some asynchronous patterns to observable sequences
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dealing with multiple observable sequences to combine them into single observables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sharing side effects of an observable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doing some mathematical transformations on observable sequences
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time-based operations such as throttling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling exceptions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filtering values emitted by the observable sequence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grouping and windowing values emitted
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backpressure strategy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Up to now, we have played with observables and observers. We imitated our problem
    using streams of data (observables), transferred it to our desired output (using
    operators), and threw out some values or some side effects (observers). Now, a
    case can also occur where an observable is throwing out data faster than what
    the observer can process. This eventually leads to loss of data, which is called
    the **backpressure problem**. To handle back pressure, either we need to accept
    a loss of data or we need to buffer the observable stream and process it in chunks
    when losing data is not an option. Different strategies are available in both
    of the options:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **When losing is an option** | **When losing isn''t an option** |'
  prefs: []
  type: TYPE_TB
- en: '| **Debouncing**: Emit data only after timespan has passed. | **Buffer**: Set
    an amount of time or max number of events to buffer. |'
  prefs: []
  type: TYPE_TB
- en: '| **Pausing**: Pause source stream for some time. | **BufferedPause**: Buffer
    whatever is emitted by the source stream. |'
  prefs: []
  type: TYPE_TB
- en: '|  | **Controlled Streams**: This is a push-pull strategy with the producer
    pushing events, and the consumer pulling only as much as it can process. |'
  prefs: []
  type: TYPE_TB
- en: Currying functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Currying** is a process of evaluating function arguments one by one, at the
    end of each evaluation producing a new function with one argument less. Currying
    is useful when arguments of a function need to be evaluated at different places.
    Using the currying process, one argument may be evaluated at some component, then
    it can be passed to any other place, and then the result can be passed to another
    component until all the arguments are evaluated. This seems very similar to our
    microservices analogy. We will use currying later on when we have service dependencies.'
  prefs: []
  type: TYPE_NORMAL
- en: When to react and when not to react (orchestrate)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, we are at a stage where we are well acquainted with the core concepts of
    microservices. The next question that we often interact with is regarding the
    implementation of microservices, and how they will interact with each other. The
    most common question is when to use orchestration, when to react, and is it possible
    to use a hybrid approach. In this section, we will understand each of the approaches,
    its pros and cons, and look at practical examples for the use of each approach.
    Let's start with orchestration.
  prefs: []
  type: TYPE_NORMAL
- en: Orchestration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Orchestration** is more of a **Service Oriented Architecture (SOA)** approach
    where we handle interaction between various services in an SOA. When we say orchestration,
    we maintain one controller that is the orchestrator or the main coordinator of
    all the service interactions. This typically follows more of a request/response-type
    pattern where a mode of communication can be anything. For example, we can have
    one orchestrator in our shopping microservices that does the following tasks synchronously—first,
    take customer orders, then check the product, prepare a bill, and after successful
    payment, update the product inventory.'
  prefs: []
  type: TYPE_NORMAL
- en: Benefits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It provides a systematic way to handle the flow of the programming, where you
    can actually control the manner in which requests are made. For example, you can
    ensure that request B can be successfully invoked only after request A completes.
  prefs: []
  type: TYPE_NORMAL
- en: Disadvantages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While the orchestration pattern may look beneficial, there are several trade-offs
    involved in this pattern, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: There is a tight dependency on the system. Say if one of the initial services
    is down, then the next services in the chain will never be called. The system
    can soon become a bottleneck as several single points of failure would be there.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synchronous behavior would be introduced in the system. The total end to end
    time taken would be the sum of the time taken to process all of the individual
    services.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reactive approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices are meant to coexist on their own. They are not meant to be dependent
    on each other. A **reactive approach** tends to solve some of the challenges of
    an orchestration approach. Instead of having a controlling orchestrator that takes
    care of the logic for which steps to happen at what stage, a reactive pattern
    promotes the service knowing the logic to be built in and executed ahead of time.
    The services know what to react to and how to deal with it ahead of time. The
    communication mode for services are dumb pipes and they don't have any logic inside
    them. Being asynchronous in nature, it removes the waiting part of the orchestration
    process. Services can produce events and keep on processing. Producing and consuming
    services are decoupled, so the producer doesn't need to know whether the consumer
    is up or not. There can be multiple patterns in this approach where producers
    may want to receive an acknowledgment from consumers. The centralized event stream
    takes care of all these things in a reactive approach.
  prefs: []
  type: TYPE_NORMAL
- en: Benefits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The reactive approach has lots of advantages and it overcomes lots of traditional
    problems:'
  prefs: []
  type: TYPE_NORMAL
- en: Parallel or asynchronous execution gives faster end to end processing. Asynchronous
    processing essentially won't prevent resource blocking while serving a request.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having a centralized event stream or a dumb communication pipe as a mode of
    communication has the advantage of easily adding or removing any service at any
    point in time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Control of the system is distributed. There is no longer a single point of failure
    in the system as the orchestrator.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When this approach is clubbed with several other approaches, then various benefits
    can be achieved.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When this approach is clubbed with event sourcing, all the events are stored
    and it enables event replay. So even if some service is down, the event store
    can still replay that event when the service is online again and the service can
    check up on updates.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another advantage is **Command Query Responsibility Segregation** (**CQRS**). As
    seen in [Chapter 1](2eeeb09d-ecd0-403b-8a64-ac754090cebe.xhtml), *Debunking Microservices*,
    we can apply this pattern to separate out the read and write activities. Hence,
    any of the services can be scaled out independently. This is extremely helpful
    in situations where applications are either read or write heavy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disadvantages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While this approach does solve most of the complexities, it introduces a few
    trade-offs:'
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous programming can sometimes be painful to handle. It can't be figured
    out by just looking at the code. A thorough understanding of Event Loop as shown
    in [Chapter 2](c1987454-3c62-4e25-abf5-28a9abf833e8.xhtml), *Gearing up for the
    Journey*, is must to understand the actual workflow in *async coding*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Complexity and centralized code are now shifted in individual services. The
    flow control is now broken up and distributed across all the services. This may
    introduce redundant code in the system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Like everything, a one-size-fits-all approach doesn't work here. Several hybrid
    approaches have come along, which take advantage of both processes. Let's now
    take a look at some hybrid approaches. A hybrid approach can add a lot of value.
  prefs: []
  type: TYPE_NORMAL
- en: React outside, orchestrate inside
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first hybrid patterns promote reactive patterns between different microservices
    and orchestration inside a service. Let''s consider an example to understand this.
    Consider our shopping microservices example. Whenever someone buys a product,
    we will check inventory, calculate price, process payment, check out payment,
    add recommendation products, and so on. Each of these microservices would be different.
    Here, we can have a reactive approach between product inventory service, payment
    service, and recommendation products, and an orchestration approach between checkout
    service, process payment, and dispatch product. A collective service produces
    an event based on the outcome of all these three services, which can then be produced.
    There are several advantages and value additions, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Most of the services are decoupled. Orchestration only comes into the picture
    whenever it is required. The overall flow of the application is distributed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having asynchronous events and an event-based approach ensures no single point
    of failure. If events are missed out by services, then events can be replayed
    whenever the service is available online.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While there are several advantages, there are some trade-offs introduced:'
  prefs: []
  type: TYPE_NORMAL
- en: If services are coupled, then they can soon become a single point of failure.
    They cannot be scaled independently.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synchronous processing can cause system blocking and resources would be occupied
    until the request is fully completed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reactive coordinator to drive the flow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The second approach introduces something more like a reactive orchestrator
    to drive the flow between various services. It uses more of a command-based and
    event-based approach to control the overall flow of the entire ecosystem. Commands
    indicate things that need to be done and events are outcomes of the commands that
    are done. The reactive coordinator takes in requests and produces commands, then
    pushes them to the event stream. Various microservices that are already set up
    for the commands consume those commands, do some processing, and then throw out
    an event when the command is successfully done and executed. The reactive coordinator
    consumes those events and reacts to the events as programmed and as and when necessary.
    This approach has several value additions, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Services are decoupled; even though there seems to be a coupling between the
    coordinator and services, the reactive approach and centralized event stream takes
    care of most of the previous drawbacks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An event stream or centralized event bus ensures asynchronous programming between
    microservices. Events can be replayed on demand. There are no single points of
    failure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overall flow can be centralized in one place in the reactive coordinator. All
    such centralized logic can be kept there and there won't be any duplicated code
    anywhere.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While there are lots of benefits, there is the following trade-off introduced
    by this approach—the coordinator needs to be taken care of. If the coordinator
    goes down, the entire system can be impacted. The coordinator needs to know what
    commands are needed in order to react or perform a preset of actions.
  prefs: []
  type: TYPE_NORMAL
- en: Synopsis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After going through all the approaches, pure reactive, pure orchestration, and
    two different hybrid approaches, we will now go through various use cases in which
    we can apply the preceding four approaches. We will now learn which approach fits
    where.
  prefs: []
  type: TYPE_NORMAL
- en: When a pure reactive approach is a perfect fit
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following scenarios, a purely reactive approach is a perfect fit:'
  prefs: []
  type: TYPE_NORMAL
- en: When most of the processing in your application can be done asynchronously.
    When you can have parallel processing in your application, the reactive architecture
    pattern is a great fit for processing application needs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decentralizing the application flow in each service is manageable and it doesn't
    become a pain in the neck. For monitoring and auditing, centralized views can
    be generated using correlation IDs (**UUID**, **GUID**, **CUID**).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the application needs to be deployed quickly and speed to market is a top-most
    goal. When microservices are combined with a reactive approach, it helps to increase
    decoupling, minimize dependencies, handle temporary shutoff situations, and thus
    help to get products get faster to market.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When pure orchestration is a perfect fit
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following scenarios, a pure orchestration approach is a perfect fit:'
  prefs: []
  type: TYPE_NORMAL
- en: When your application's needs are not fulfilled by parallel processing. All
    the steps have to be done with sequential processing and there are zero opportunities
    for parallel processing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the application needs demand centralized flow control. Various domains such
    as **banking** and **ERP** have needs where viewing the end to end flow in one
    place is a high priority. If there are 100 services, each with their own flow
    of control, then maintaining a centralized flow may soon become a bottleneck in
    distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When react outside, orchestrate inside is a perfect fit
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following scenarios, a hybrid approach, more specifically react outside,
    orchestrate inside, is a perfect fit:'
  prefs: []
  type: TYPE_NORMAL
- en: Most of your processing can be done asynchronously. Your services can communicate
    with each other via an event stream and you can have parallel processing in the
    system, that is, you can pass data via event streams or commands based on your
    system. For example, whenever payment is successfully credited, then one microservice
    to show related products and one microservice to dispatch orders to the seller.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decentralizing flow in each microservice is easily manageable and there is not
    duplicated code everywhere.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Speed to market is the main priority.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sequential steps don't apply within the system and they apply within the service.
    As long as sequential steps don't apply across the system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When introducing a reactive coordinator is the perfect fit
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following scenarios, introducing a reactive coordinator is the perfect
    solution:'
  prefs: []
  type: TYPE_NORMAL
- en: Based on the data being processed, the flow of the application can change. The
    flow could have several hundred microservices and application demands temporary
    shut-ins and as soon as the application gets back online events can be replayed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are several asynchronous processing blocks that need to be processed synchronously
    in the system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It allows easy service discovery. Services can easily be scaled at any time.
    Moving the entire service can be easily done.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on your overall needs, you can decide on any one of the strategies in
    your microservice architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Being reactive in Node.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have gone through the concepts of reactive programming and advantages
    of reactive programming in microservices, let's now look at some practical implementations
    of reactive programming in Node.js. In this section, we will understand the building
    blocks of reactive programming by seeing implementations of reactive programming
    in Node.js.
  prefs: []
  type: TYPE_NORMAL
- en: Rx.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is one of the most trending libraries and it is actively maintained. This
    library is available for most programming languages in different forms such as
    **RxJava**, **RxJS**, **Rx.Net**, **RxScala**, **RxClojure**, and so on. At the
    time of writing, it had more than 40 lakh downloads in the last month. Besides
    this, a huge amount of documentation and online support is available for this.
    We will be using this library most of the time, except when the need arises. You
    can check this out at: [http://reactivex.io/](http://reactivex.io/). At the time
    of writing, the stable version of Rx.js was **5.5.6**. Rx.js has lots of operators.
    We can use the Rx.js operators for various things such as combining various things,
    applying conditions as and when needed, creating new observables from promises
    or events, error handling, filtering data, having a publisher-subscriber pattern,
    transforming data, request-response utilities, and so on. Let''s have a quick
    hands on. In order to install RxJS, we need to install the Rx package and Node-Rx
    bindings. Open up a Terminal and shoot `npm install rx node-rx --save`. We will
    need one more module as this library has to support our Node.js as a build system.
    Hit this command in the Terminal—`npm install @reactivex/rxjs --save`. Throughout
    the chapter, we will be using our `Hello World` microservices skeleton, which
    we just created in [Chapter 2](c1987454-3c62-4e25-abf5-28a9abf833e8.xhtml), *Gearing
    up for the Journey*, and continuing further with this. The following are various
    options that we are going to see in the demo:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `forkjoin` | When we have a group of observables and we want only the last
    value. This cannot be used if one of the observable never completes. |'
  prefs: []
  type: TYPE_TB
- en: '| `combineAll` | It just flattens/combines an observable of observables by
    waiting for an outer observable to complete and then automatically applying `combineLatest`.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `race` | The observable whose value is emitted first will be used. |'
  prefs: []
  type: TYPE_TB
- en: '| `retry` | Retries an observable sequence a specific number of times should
    an error occur. |'
  prefs: []
  type: TYPE_TB
- en: '| `debounce` | Ignores emitted values that take less than a specified time.
    Example, if we set debounce to one second, then any values that are emitted before
    one second will be ignored. |'
  prefs: []
  type: TYPE_TB
- en: '| `throttle` | Emits a value only when a duration determined by the provided
    function has passed. |'
  prefs: []
  type: TYPE_TB
- en: 'The following example throttles values until two seconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The following example will trigger a race condition on observables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: You can follow along with the source at `using_rxjs` in a source folder. An
    example of all the operators in the preceding table can be found at `rx_combinations.ts`,
    `rx_error_handing.ts`, and `rx_filtering.ts`. A full list of API's can be found
    at [http://reactivex.io/rxjs/](http://reactivex.io/rxjs/).
  prefs: []
  type: TYPE_NORMAL
- en: Bacon.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Bacon.js** is a small, compact functional reactive programming library. When
    integrated with Node.js, you can easily turn your spaghetti code into clean, declarative
    code. It has more than 29,000 downloads a month. At the time of writing, the version
    available was **1.0.0**. Let''s have a quick hands on. In order to install Bacon.js,
    we need to install Bacon.js and its typings. Open up a Terminal and shoot `npm
    install baconjs --save` and `npm install @types/baconjs --only=dev`. Now, let''s
    see one basic example where we will see how clean the code looks. We have one
    JSON object where some products are mapped with a number `1` for `mobile`, `2` for
    `tv`, and so on. We create one service to return the product name and if the product
    is not there, it should return `Not found`. The following is the service code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the controller code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: You can follow along with the source code at `using_baconjs` in the source folder.
    A full list of APIs can be found at [https://baconjs.github.io/api.html](https://baconjs.github.io/api.html).
  prefs: []
  type: TYPE_NORMAL
- en: HighLand.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is more of a generic functional library and it is built on top of Node.js
    streams, thus allowing it to handle asynchronous and synchronous code. One of
    the best features of **HighLand.js** is the way it handles backpressure. It has
    a built-in feature for pausing and buffering, that is, when the client is not
    able to handle any more data, the stream will be paused until it's ready, and
    if the source can't be paused then it will maintain a temporary buffer until normal
    operations can be resumed. Time to get our hands dirty with a practical example.
    Let's deviate from the express theme and focus on a file-reading theme. We will
    see the power of Node.js I/O operations with parallel executions that can take
    place. Shoot up a Terminal and hit `npm install highland --save`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Going with our previous skeleton, create `index.ts` with the following code,
    which basically reads three files and prints their contents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Transpile the file, keep three `.txt` files parallel to `package.json`, and
    run the `node` file. The contents will be read. You can follow along with the
    project at `using_highlandjs` in the `src` folder of the source code. A full list
    of APIs is available at [http://highlandjs.org/](http://highlandjs.org/).
  prefs: []
  type: TYPE_NORMAL
- en: Key takeaways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have seen all three libraries, we will summarize the following
    key points and salient features:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Rx.js** | **Bacon.js** | **Highland.js** |'
  prefs: []
  type: TYPE_TB
- en: '| **Documentation** | Well documented, very mature APIs along with lots of
    options, has extensions in other languages. | Fewer examples for Node.js, great
    API docs, native support for Node.js. | Very little documentation and fewer helper
    methods, evolving footprint. |'
  prefs: []
  type: TYPE_TB
- en: '| **Backpressure** | Implemented. | Not supported. | Best implementation. |'
  prefs: []
  type: TYPE_TB
- en: '| **Community** | Used by big companies such as Netflix, and Microsoft. Has
    similar concepts in all other languages, more like Java, learning curve. | Smaller
    than Rx.js, reduced learning curve compared to Rx.js. | Least active community,
    have to dig right into the code base. |'
  prefs: []
  type: TYPE_TB
- en: '| **Licenses** | Apache 2.0 | MIT | Apache 2.0 |'
  prefs: []
  type: TYPE_TB
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about the Reactive Manifesto. We clubbed reactive
    principles and applied them in microservices. We learned how to apply reactive
    programming in Node.js. We learned about possible approaches to design the microservice
    architecture, saw its advantages and disadvantages, and saw some practical scenarios
    to find out in which situations we can apply those patterns. We saw orchestration
    processes, reaction processes, and two special cases of hybrid approaches.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will begin developing our shopping cart microservices.
    We will design our microservice architecture, write some microservices, and deploy
    them. We will see how to organize our code into the proper structure.
  prefs: []
  type: TYPE_NORMAL
