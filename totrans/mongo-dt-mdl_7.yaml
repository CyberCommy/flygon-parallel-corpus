- en: Chapter 7. Scaling
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Scalability has been a much-discussed subject over the years. Even though many
    things have already been said about it, this topic is very important and here,
    in this book, it will surely find its place too.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: It is not in our interest to deal with all the concepts that involve database
    scalability, especially in NoSQL databases, but to show the possibilities that
    MongoDB offers when working with scalability in our collections and also how the
    flexibility of MongoDB's data model can influence our choices.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: It is possible to horizontally scale MongoDB based on a simple infrastructure
    and low-cost sharding requests. Sharding is the technique of distributing data
    through multiple physical partitions called **shards**. Even though the database
    is physically partitioned, to our clients the database itself is a single instance.
    The technique of sharding is completely transparent for the database's clients.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'Dear reader, get ready! In this chapter, you will see some crucial topics for
    database maintenance, such as:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Scaling out with sharding
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing the shard key
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling a social inbox schema design
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling out MongoDB with sharding
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When we talk about database scalability, we have two reference methods:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '**Scale up or vertical scale**: In this method, we add more resources to a
    machine. For example, a CPU, disk, and memory in order to increase the system''s
    capacity.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scale out or horizontal scale**: In this method, we add more nodes to the
    systems and distribute the work among the available nodes.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The choice between one or the other does not depend on our desire. It depends
    on the system that we want to scale. It is necessary to know whether it is possible
    to scale that system in the way that we want to. We must also keep in mind that
    there is a difference and trade-off between the two techniques.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Increasing the storage capacity, CPU, or memory can be very expensive and sometimes
    impossible due to our service provider's limitations. On the other hand, increasing
    the number of nodes in a system can also increase complexity both conceptually
    and operationally.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: However, considering the advances in virtualization technology and the facilities
    offered by cloud providers, scaling horizontally is becoming the more practical
    solution for some applications.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: MongoDB is prepared to scale horizontally. This is done with the help of a technique
    of sharding. This technique consists of partitioning our data set and distributing
    the data among many servers. The main purpose of sharding is to support bigger
    databases that are able to deal with a high-throughput operation by distributing
    the operation's load between each shard.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: For example, if we have a 1-terabyte database and four configured shards, each
    shard should have 256 GB of data. But, this does not mean that each shard will
    manage 25 percent of throughput operation. This will only depend on the way that
    we decided to construct our shard. This is a big challenge and the main target
    of this chapter.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram demonstrates how a shard works on MongoDB:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '![Scaling out MongoDB with sharding](img/B04075_07_01.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
- en: 'At the time that this book was written, MongoDB, in its 3.0 version, offers
    multiple sharding policies: **range-based**, **hash-based**, and **location-based**
    sharding.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: In the range-based policy, MongoDB will partition the data based on the value
    for the shard key. The documents that the shard key values close to each other
    will be allocated in the same shard.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the hash-based policy, the documents are distributed considering the MD5
    value for the shard key.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the location-based policy, the documents will be distributed in shards based
    on a configuration that will associate shard range values with a specific shard.
    This configuration uses tags to do this, which is very similar to what you saw
    in [Chapter 6](ch06.html "Chapter 6. Managing the Data"), *Managing the Data*,
    where we discussed operation segregation.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sharding works in MongoDB at the collections level, which means we can have
    collections with sharding and without sharding enabled in the same database. To
    set sharding in a collection, we must configure a sharded cluster. The elements
    for a sharded cluster are shards, query routers, and configuration servers:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: A **shard** is where a part of our data set will be allocated. A shard can be
    a MongoDB instance or a replica set
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **query router** is the interface offered for the database clients that
    will be responsible for directing the operations to the correct shard
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **config server** is a MongoDB instance that is responsible for keeping
    the sharded cluster configurations or, in other words, the cluster's metadata
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram shows a shared cluster and its components:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '![Scaling out MongoDB with sharding](img/B04075_07_02.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
- en: We will not go any deeper into the creation and maintenance of a sharded cluster,
    as this is not our objective in this chapter. However, it is important to know
    that the sharded cluster's setup depends on the scenario.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: In a production environment, the minimum recommended setup is at least three
    configuration servers, two or more replica sets, which will be our shards, and
    one or more query routers. By doing this, we can ensure the minimum redundancy
    and high availability for our environment.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the shard key
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once we've decided that we have the need for a sharded cluster, the next step
    is to choose the shard key. The shard key is responsible for determining the distribution
    of documents among the cluster's shards. These will also be a key factor in determining
    the success or the failure of our database.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: 'For each write operation, MongoDB will allocate a new document based on the
    range value for the shard key. A shard key''s range is also known as a **chunk**.
    A chunk has a default length of 64 MB, but if you want this value to be customized
    to your need, it can be configured. In the following diagram, you can see how
    documents are distributed on chunks given an numeric shard key from infinity negative
    to infinity positive:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '![Choosing the shard key](img/B04075_07_03.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
- en: Before starting a discussion about the things that can affect our shard key's
    construction, there are some limitations in MongoDB that must be respected. These
    limitations are significant and, in some ways, they help us to eliminate the possibilities
    of some errors in our choices.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: A shard key cannot exceed a length of 512 bytes. A shard key is an indexed field
    in the document. This index can be a simple field or a composed field, but it
    will never be a multikey field. It is also possible to use indexes of simple hash
    fields since the 2.4 version of MongoDB.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: The following information must be read quietly, like a mantra, so you will not
    make any mistakes from the very beginning.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You have to keep one thing in your mind: the shard key is unchangeable.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: To repeat, the shard key is unchangeable. That means, dear reader, that once
    a shard key is created, you can never change it. Never!
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: You can find detailed information about MongoDB sharded cluster limitations
    in the MongoDB manual reference at [http://docs.mongodb.org/manual/reference/limits/#sharded-clusters](http://docs.mongodb.org/manual/reference/limits/#sharded-clusters).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: 'But what if I created a shard key and I want to change it? What should I do?
    Instead of trying to change it, we should do the following:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Execute a dump of the database in a disk file.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drop the collection.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure a new collection using the new shard key.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Execute a pre-split of the chunks.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Recover the dump file.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As you can see, we do not change the shard key. We recreated almost everything
    from scratch. Therefore, be careful when executing the command for shard key's
    creation or you will get a headache if you need to change it.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The next piece of information you need to remember is that you cannot update
    the value of one or more fields that are a part of the shard key. In other words,
    the value for a shard key is also unchangeable.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要记住的下一个信息是，你不能更新分片键的一个或多个字段的值。换句话说，分片键的值也是不可更改的。
- en: There is no use in trying to execute the `update()` method in a field that is
    part of a shard key. It will not work.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试在分片键的字段中执行`update()`方法是没有用的。它不起作用。
- en: 'Before we proceed, let''s see in practice what we discussed until this point.
    Let''s create a sharded cluster for testing. The following shard configuration
    is very useful for testing and developing. Never use this configuration in a production
    environment. The commands given will create:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，让我们实际看一下我们到目前为止讨论的内容。让我们为测试创建一个分片集群。以下的分片配置对于测试和开发非常有用。在生产环境中永远不要使用这个配置。给出的命令将创建：
- en: Two shards
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个分片
- en: One configuration server
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个配置服务器
- en: One query router
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个查询路由器
- en: 'As a first step, let''s start a configuration server instance. The configuration
    server is nothing more than a `mongod` instance with the initialization parameter
    `--configsvr.` If we do not set a value for the parameter `--port <port number>`,
    it will start on port 27019 by default:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一步，让我们启动一个配置服务器实例。配置服务器只是一个带有初始化参数`--configsvr`的`mongod`实例。如果我们不为参数`--port
    <port number>`设置一个值，它将默认在端口27019上启动：
- en: '[PRE0]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The next step is to start the query router. The query router is a `mongos`
    MongoDB instance, which route queries and write operations to shards, using the
    parameter `--configdb <configdb hostname or ip:port>`, which indicates the configuration
    server. By default, MongoDB starts it on port 27017:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是启动查询路由器。查询路由器是一个`mongos` MongoDB实例，它使用参数`--configdb <configdb hostname or
    ip:port>`来将查询和写操作路由到分片，该参数指示配置服务器。默认情况下，MongoDB在端口27017上启动它：
- en: '[PRE1]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Finally, let''s start the shards. The shards in this example will be just two
    simple instances of `mongod`. Similar to `mongos`, a `mongod` instance starts
    on port 27017 by default. As we already started the `mongos` instance on this
    port, let''s set a different port for the `mongod` instance:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们启动分片。在这个例子中，分片将是两个简单的`mongod`实例。与`mongos`类似，`mongod`实例默认在端口27017上启动。由于我们已经在这个端口上启动了`mongos`实例，让我们为`mongod`实例设置一个不同的端口：
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Done! Now we have the basic infrastructure for our test sharded cluster. But,
    wait! We do not have a sharded cluster yet. The next step is to add the shards
    to the cluster. To do this, we must connect the `mongos` instance that we already
    started to the query router:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 完成！现在我们为测试分片集群建立了基本的基础设施。但是，等等！我们还没有一个分片集群。下一步是向集群添加分片。为此，我们必须将已经启动的`mongos`实例连接到查询路由器：
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Once on the `mongos` shell, we have to execute the `addShard` method in the
    following way:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦在`mongos` shell中，我们必须以以下方式执行`addShard`方法：
- en: '[PRE4]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'If we want to check the result of the preceding operations, we can execute
    the `status()`command and see some information about the created shard:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要检查前面操作的结果，我们可以执行`status()`命令，并查看关于创建的分片的一些信息：
- en: '[PRE5]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In the returned document, we can only see basic information, such as which the
    hosts are for our sharded cluster and the databases that we have. For now, we
    do not have any collection using the sharding enabled. For that reason, the information
    is greatly simplified.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在返回的文档中，我们只能看到基本信息，比如我们的分片集群的主机是谁，我们有哪些数据库。目前，我们没有任何使用分片启用的集合。因此，信息被大大简化了。
- en: 'Now that we have the shards, the configuration server, and the query router,
    let''s enable sharding in the database. It is necessary first to enable sharding
    in a database before doing the same for a collection. The following command enables
    sharding in a database called `ecommerce`:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了分片、配置服务器和查询路由器，让我们在数据库中启用分片。在对集合进行相同操作之前，必须先在数据库中启用分片。以下命令在名为`ecommerce`的数据库中启用分片：
- en: '[PRE6]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'By consulting the sharded cluster''s status, we can notice that we have information
    about our `ecommerce` database:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查询分片集群的状态，我们可以注意到我们有关于我们的`ecommerce`数据库的信息：
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Consider that in the `ecommerce` database, we have a `customers` collection
    with the following documents:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一下，在`ecommerce`数据库中，我们有一个`customers`集合，其中包含以下文档：
- en: '[PRE8]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We must execute the `shardCollection` command to enable sharding in this collection,
    using the collection name and a document that will represent our shard key as
    a parameter.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须执行`shardCollection`命令来在这个集合中启用分片，使用集合名称和一个将代表我们的分片键的文档作为参数。
- en: 'Let''s enable the shard in the `customers` collection by executing the following
    command in the `mongos` shell:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在`mongos` shell中执行以下命令来启用`customers`集合中的分片：
- en: '[PRE9]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'As you can see, something went wrong during the command''s execution. MongoDB
    is warning us that we must have an index and the shard key must be a prefix. So,
    we must execute the following sequence on the `mongos` shell:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，命令执行过程中出现了一些问题。MongoDB警告我们必须有一个索引，并且分片键必须是一个前缀。因此，我们必须在`mongos` shell上执行以下序列：
- en: '[PRE10]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Well done! Now we have the `customers` collection of the `ecommerce` database
    with the shard enabled.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 干得好！现在我们有了启用了分片的`ecommerce`数据库的`customers`集合。
- en: Note
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: If you are sharding an empty collection, the `shardCollection` command will
    create the index of the shard key.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在对一个空集合进行分片，`shardCollection`命令将创建分片键的索引。
- en: But what was the factor that determined the choice of `address.zip` and `registered`
    as the shard key? In this case, as I said before, I chose a random field just
    to illustrate. From now on, let's think about what factors can establish the creation
    of a good shard key.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 但是是什么因素决定了选择`address.zip`和`registered`作为分片键？在这种情况下，正如我之前所说的，我选择了一个随机字段来进行说明。从现在开始，让我们考虑什么因素可以确定一个好的分片键的创建。
- en: Basic concerns when choosing a shard key
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择分片键时的基本注意事项
- en: The choice of which shard key is not an easy task and there is no recipe for
    it. Most of the time, knowing our domain and its use in advance is fundamental.
    It is essential to be very careful when doing this. A not-so-appropriate shard
    key can bring us a series of problems in our database and consequently affect
    its performance.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 选择分片键并不是一项容易的任务，也没有固定的配方。大多数情况下，提前了解我们的领域及其用途是至关重要的。在进行此操作时要非常小心。一个不太合适的分片键可能会给我们的数据库带来一系列问题，从而影响其性能。
- en: First of all is divisibility. We must think of a shard key that allows us to
    visualize the documents' division among the shards. A shard key with a limited
    number of values may result in "unsplittable" chunks.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 首先是可分性。我们必须考虑一个分片键，使我们能够在分片之间可视化文档的分割。具有有限数量值的分片键可能导致“不可分割”的块。
- en: We can state that this field must have a high cardinality, such as fields with
    a high variety of values and also unique fields. Identifications fields such as
    e-mail addresses, usernames, phone numbers, social security numbers, and zip codes
    are a good example of fields with high cardinality.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以说，这个领域必须具有高基数，例如具有高多样性值和唯一字段的字段。识别字段，如电子邮件地址、用户名、电话号码、社会安全号码和邮政编码，是高基数字段的一个很好的例子。
- en: In fact, each one of them can be unique if we take into account a certain situation.
    In an ecommerce system, if we have a document that is related to shipment, we
    will have more than one document with the same zip code. But, consider another
    example, a catalogue system for beauty salons in a city. Then, if a document represents
    a beauty salon, the zip code will be a more unique number than it was in the previous
    example.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，如果考虑到某种情况，它们每一个都可以是独特的。在电子商务系统中，如果我们有一个与装运相关的文档，我们将有多个具有相同邮政编码的文档。但是，考虑另一个例子，一个城市中美容沙龙的目录系统。那么，如果一个文档代表一个美容沙龙，那么邮政编码将比在前一个例子中更独特。
- en: The third is maybe the most polemical point until now because it contradicts
    the last one in a certain way. We have seen that a shard key with a high randomness
    degree is good practice in trying to increase the performance in write operations.
    Now, we will consider a shard key's creation to target a single shard. When we
    think about performance on read operations, it is a good idea to read from a single
    shard. As you already know, in a sharded cluster, the database complexity is abstracted
    on the query router. In other words, it is **mongos'** responsibility to discover
    which shards it should search for the information requested in a query. If our
    shard key is distributed across multiple shards, then `mongos` will search for
    the information on the shards, collect and merge them all, and then deliver it.
    But, if the shard key was planned to target a single shard, then the mongos task
    will search for the information in this unique shard and, in sequence, deliver
    it.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 第三点可能是迄今为止最有争议的，因为它在某种程度上与上一个点相矛盾。我们已经看到，具有高随机性的分片键是尝试增加写操作性能的良好实践。现在，我们将考虑创建一个分片键以针对单个分片。当我们考虑读操作的性能时，从单个分片读取是一个好主意。正如您已经知道的，在分片集群中，数据库复杂性被抽象为查询路由器。换句话说，发现应该在哪些分片上搜索查询中请求的信息是**mongos**的责任。如果我们的分片键分布在多个分片上，那么`mongos`将在分片上搜索信息，收集并合并它们，然后交付。但是，如果分片键旨在针对单个分片，那么mongos任务将在这个唯一的分片中搜索信息，然后交付。
- en: The fourth and last point is about cases when we do not have any field in the
    document that would be a good choice for our shard key. In this situation, we
    must think about a composed shard key. In the previous example, we use a composed
    shard key with the fields `address.zip` and `registered`. A composed shard key
    will also help us to have a more divisible key due the fact that if the first
    value from the shard key does not have a high cardinality, adding a second value
    will increase the cardinality.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 第四个也是最后一个点是关于当文档中没有任何字段适合作为我们的分片键的选择时。在这种情况下，我们必须考虑一个组合的分片键。在前面的例子中，我们使用了一个由字段`address.zip`和`registered`组成的分片键。组合的分片键也将帮助我们拥有一个更可分的键，因为如果分片键的第一个值没有高基数，添加第二个值将增加基数。
- en: So, these basic concerns show us that depending on what we want to search for,
    we should choose different approaches for the shard key's document. If we need
    query insulation, then a shard key that can focus on one shard is a good choice.
    But, when we need to escalate the write operation, the more random our shard key,
    the better it will be for performance.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这些基本问题告诉我们，根据我们想要搜索的内容，我们应该选择不同的分片键文档方法。如果我们需要查询隔离，那么可以专注于一个分片的分片键是一个不错的选择。但是，当我们需要扩展写操作时，我们的分片键越随机，对性能的影响就越好。
- en: Scaling a social inbox schema design
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展社交收件箱模式设计
- en: On October 31, 2014, MongoDB Inc. introduced on their community blog three different
    approaches to solve a very common problem, social inboxes.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 2014年10月31日，MongoDB公司在其社区博客上介绍了解决一个非常常见的问题，社交收件箱的三种不同方法。
- en: Note
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: If you want to see the blog post, refer to [http://blog.mongodb.org/post/65612078649/schema-design-for-social-inboxes-in-mongodb](http://blog.mongodb.org/post/65612078649/schema-design-for-social-inboxes-in-mongodb).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想查看博客文章，请参阅[http://blog.mongodb.org/post/65612078649/schema-design-for-social-inboxes-in-mongodb](http://blog.mongodb.org/post/65612078649/schema-design-for-social-inboxes-in-mongodb)。
- en: From the three presented schema designs, it is possible to see the application
    of all the scaling concepts we have seen until now in an easy and efficient way.
    In all of the cases, the concept of a fan out applies, in which the workload is
    distributed among the shards in parallel. Each approach has its own application
    according to the needs of the database client.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 从所呈现的三种模式设计中，可以看到我们迄今为止以一种简单有效的方式应用了所有扩展概念。在所有情况下，都应用了扇出的概念，即工作负载在分片之间并行分布。每种方法都根据数据库客户端的需求有其自己的应用。
- en: 'The three schema designs are:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 三种模式设计是：
- en: Fan out on read
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在读取时进行扇出操作
- en: Fan out on write
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在写入时进行扇出操作
- en: Fan out on write with buckets
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在写入时进行扇出操作
- en: Fan out on read
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在读取时进行扇出操作
- en: The fan out on read design bears this name due to the query router's behavior
    when a client reads an inbox. It is considered to be the design with the simplest
    mechanics compared to the others. It is also the easiest to implement.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: 'In the fan out on read design, we will have one `inbox` collection, where we
    will insert every new message. The document that will reside on this collection
    has four fields:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '`from`: A string that represents the message sender'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`to`: An array with all message recipients'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sent`: A date field that represents when the message was sent to the recipients'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`message`: A string field that represents the message itself'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the following document, we can see an example of a message sent from John
    to Mike and Billie:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The operations on this collection will be the most straightforward of all. To
    send a message is to make an insert operation in the `inbox` collection, while
    to read is to find all the messages with a specific recipient.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing to be done is to enable sharding on the database. Our `inbox`
    collection is in a database called `social`. To do this, and all other things
    that we will do in this chapter, we will use the `mongos` shell. So, let''s start
    out:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, we will have to create the collection''s shard key. To implement this
    design, we will create a shard key using the `from` field of the `inbox` collection:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In case our collection already has documents, we should create an index for
    the shard key field.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: 'The final step is to create a compound index on the `to` and `sent` fields,
    seeking a better performance on read operations:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We are now ready to send and read messages in our `inbox` collection. On the
    `mongos` shell, let''s create a message and send it to the recipients:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'If we want to read Mike''s inbox, we should use the following command:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The write operation in this design may be considered as efficient. Depending
    on the number of active users, we will have an even distribution of data across
    the shards.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, viewing an inbox is not so efficient. Every inbox read issues
    a `find` operation using the `to` field sorted by the `sent` field. Because our
    collection has the `from` field as a shard key, which means that the messages
    are grouped by sender on the shards, every query that does not use the shard key
    will be routed to all shards.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: This design applies well if our application is targeted to sending messages.
    As we need a social application in which you send and read messages, let's take
    a look at the next design approach, fan out on write.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Fan out on write
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the fan out on write design, we can say that we will have an opposite effect
    compared to the previous one. While in fan out on read, we reached every shard
    on the cluster to view an inbox, in fan out on write, we will have the write operations
    distributed between all the shards.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: 'To implement fan out on write instead of sharding on the sender, we will shard
    on the recipient of the message. The following command creates the shard key in
    the `inbox` collection:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We will use the same document we used on the fan out on read design. So, to
    send a message from John to Mike and Billie, we will execute the following commands
    in the `mongos` shell:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'To better understand what is happening, let''s do a little code breakdown:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing that we should do is to create a `msg` variable and store a
    message in JSON there:'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'To send a message to every recipient, we must iterate over the value in the
    `to` field, create a new field on the message JSON, `msg.recipient`, and store
    the message''s recipient:'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Finally, we insert the message in the `inbox` collection:'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'For every recipient of the message, we will insert a new document in the `inbox`
    collection. The following command, executed on the `mongos` shell, shows Mike''s
    inbox:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'As the message has both Mike and Billie as recipients, we can also read Billie''s
    inbox:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: By doing so, when we are reading a user's inbox, we are targeting a single shard,
    since we are using the shard key as criteria for the find query.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: But, even though we reach only one shard to view an inbox, we will have many
    random reads when the number of users grows. To deal with this problem, we are
    going to meet the concept of bucketing.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Fan out on write with buckets
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The fan out on write design is a very interesting approach to the social inboxes
    problem. Every time we need to, we could add more shards to our cluster, and the
    inboxes data will be evenly distributed between then. However, as we stated before,
    the random reads we made as our database grows are a bottleneck we must deal with.
    Although we target a single shard on a read operation by using the shard key as
    criteria for our find query, we will always have a random read on viewing an inbox.
    Suppose we have an average of 50 messages by each user, then for each inbox view
    it will produce 50 random reads. So, when we multiply these random reads by users
    simultaneously accessing their inboxes, we can imagine how fast we will saturate
    our database.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: In an attempt to reduce this bottleneck, the fan out on write with buckets approach
    emerges. Fan out with buckets is a refined fan out on write, by bucketing messages
    together in documents of messages sorted by time.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation of this design is quite different compared to the previous
    ones. In fan out on write with buckets, we will have two collections:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: One `users` collection
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One `inbox` collection
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `users` collection will have documents with user data. In this document
    besides the basic user information, we also have a field that stores the total
    number of inbox messages that the user has.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: The `inbox` collection will store documents with a set of user messages. We
    will have an `owner` field that will identify the user in this collection and
    a `sequence` field that identifies the bucket. These are the fields that we will
    shard the `inbox` collection with.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, each bucket will have 50 messages. The following commands will
    enable sharding on the social database and create the shard key in the `inbox`
    collection:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'As it was previously mentioned, we also have a `users` collection. The following
    command creates a shard key in the `user` collection:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now that we have created our shard keys, let''s send a message from John to
    Mike and Billie. The message document will be very similar to the previous one.
    The difference between them is the `owner` and `sequence` fields. The following
    code, executed on the `mongos` shell, will send a message from John to Mike and
    Billie:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'As we did before, to understand to send the message, let''s do a code breakdown:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: First, we create a `msg` variable and store message JSON there
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We iterate over the recipients in the `to` field, and execute a `findAndModify`
    method, where we look for a document in the `users` collection and who the owner
    of the message recipient is. As we use the `upsert` option with the value `true`,
    if we did not find the user, then we create a new one. The `update` field has
    a `$inc` operator, which means that we will increment one to the `msg_count` field.
    The method also uses a `new` option with the value `true`, and we will have executed
    the saved document as a result of this command.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From the returned document, we get the value of the `msg_count` field, which
    represents the total messages to the user, and store the value on a `count` variable.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To discover the bucket where the message will be saved, we will use the function
    `floor` of the `Math` class that is available on the `mongos` shell. As we said
    before, we will have 50 messages in each bucket, so we will divide the value of
    the `count` variable by 50, and get the `floor` function of the result. So, for
    example, if we are sending a third user message, then the bucket to save this
    message is the result of `Math.floor(3/50)`, which is 0\. When we reach the 50th
    message, the bucket value becomes 1, which means that the next message will be
    in a new bucket.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了发现消息将被保存的存储桶，我们将使用`mongos` shell上可用的`Math`类的`floor`函数。正如我们之前所说，我们将在每个存储桶中有50条消息，因此我们将通过50除以`count`变量的值，并得到结果的`floor`函数。例如，如果我们发送第三条用户消息，那么保存此消息的存储桶的结果是`Math.floor(3/50)`，即0。当我们达到第50条消息时，存储桶的值变为1，这意味着下一条消息将在一个新的存储桶中。
- en: We will update the document in the `inbox` collection that has the `owner` and
    `sequence` value we calculated. As we use the `upsert` option with the value `true`
    on the `update` command, it will create the document if it does not exist.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将更新`收件箱`集合中具有我们计算的`所有者`和`序列`值的文档。由于我们在`update`命令上使用了`upsert`选项，并且将值设置为`true`，如果文档不存在，它将创建该文档。
- en: It this way, we will guarantee that a user's inbox is entirely on a single shard.
    In contrast to fan on write, where we have many random reads when we view a inbox,
    in fan out on write with buckets, we do one document read for every 50 user messages.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，我们将确保用户的收件箱完全位于单个分片上。与扇入写相反，在查看收件箱时我们有许多随机读取，而在扇出写与存储桶中，我们对于每50条用户消息只进行一次文档读取。
- en: Fan out on write with buckets is without a doubt the best option to a social
    inbox schema design, when our requirements are to send and read messages efficiently.
    However, the document size of the `inbox` collection can become a problem. Depending
    on the messages' sizes, we will have to be careful with our storage.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在写入时使用存储桶进行扇出无疑是社交收件箱模式设计的最佳选择，当我们的要求是高效地发送和阅读消息时。然而，`收件箱`集合的文档大小可能会成为一个问题。根据消息的大小，我们将不得不小心管理我们的存储空间。
- en: Summary
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Schema design is a better scalability strategy. No matter how many techniques
    and tools we have at our disposal, to know how our data will be used and dedicate
    time to our design is the cheaper and long-lasting approach to use.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 模式设计是更好的可扩展性策略。无论我们手头有多少技术和工具，了解我们的数据将如何使用并花时间设计是更便宜和持久的方法。
- en: In the next chapter, you will use everything you've learned until now and create
    a schema design from scratch for a real-life example.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将运用到目前为止学到的一切，为一个真实的例子从零开始创建一个模式设计。
