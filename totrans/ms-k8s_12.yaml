- en: Customizing Kubernetes – API and Plugins
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will dig deep into the guts of Kubernetes. We will start
    with the Kubernetes API and learn how to work with Kubernetes programmatically
    via direct access to the API, the Python client, and then we will automate Kubectl.
    Then, we'll look into extending the Kubernetes API with custom resources. The
    last part is all about the various plugins Kubernetes supports. Many aspects of
    the Kubernetes operation are modular and designed for extension. We will examine
    several types of plugins, such as custom schedulers, authorization, admission
    control, custom metrics, and volumes. Finally, we'll look into extending Kubectl
    and adding your own commands.
  prefs: []
  type: TYPE_NORMAL
- en: 'The topics we cover are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Working with the Kubernetes API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extending the Kubernetes API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing Kubernetes and Kubectl plugins
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing webhooks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with the Kubernetes API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Kubernetes API is comprehensive and encompasses the entire functionality
    of Kubernetes. As you may expect, it is huge. But it is designed very well using
    best practices, and it is consistent. If you understand the basic principles,
    you can discover everything you need to know.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding OpenAPI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenAPI allows API providers to define their operations and models, and enables
    developers to automate their tools and generate their favorite language's client
    to talk to that API server. Kubernetes has supported Swagger 1.2 (an older version
    of the OpenAPI spec) for a while, but the spec was incomplete and invalid, making
    it hard to generate tools/clients based on it.
  prefs: []
  type: TYPE_NORMAL
- en: In Kubernetes 1.4, alpha support was added for the OpenAPI spec (formerly known
    as **Swagger 2.0** before it was donated to the OpenAPI Initiative) and current
    models and operations were updated. In Kubernetes 1.5, support for the OpenAPI
    spec has been completed by auto-generating the spec directly from the Kubernetes
    source, which keeps the spec and documentation completely in sync with future
    changes in operations/models.
  prefs: []
  type: TYPE_NORMAL
- en: The new spec enables better API documentation and an auto-generated Python client
    that we will explore later.
  prefs: []
  type: TYPE_NORMAL
- en: The spec is modular and divided by group version. This is future-proof. You
    can run multiple API servers that support different versions. Applications can
    transition gradually to newer versions.
  prefs: []
  type: TYPE_NORMAL
- en: The structure of the spec is explained in detail in the OpenAPI spec definition.
    The Kubernetes team used the operation's tags to separate each group version and
    fill in as much information as possible about paths/operations and models. For
    a specific operation, all parameters, calling methods, and responses are documented.
    The result is impressive.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a proxy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To simplify access, you can use Kubectl to set up a proxy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now, you can access the API server at `http://localhost:8080` and it will reach
    the same Kubernetes API server that Kubectl is configured for.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the Kubernetes API directly
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Kubernetes API is easy to find out about. You can just browse to the URL
    of the API server at `http://localhost:8080` and get a nice JSON document that
    describes all the available operations under the paths key.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a partial list due to space constraints:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'You can drill down any one of the paths. For example, here is the response
    from the `/api/v1/namespaces/default` endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: I discovered this endpoint by going first to `/api`, then discovered `/api/v1`,
    which told me there is `/api/v1/namespaces`, which pointed me to `/api/v1/namespaces/default`.
  prefs: []
  type: TYPE_NORMAL
- en: Using Postman to explore the Kubernetes API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Postman ([https://www.getpostman.com](https://www.getpostman.com)) is a very
    polished application for working with RESTful APIs. If you lean more to the GUI
    side, you may find it extremely useful.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the available endpoints under the batch `V1`
    API group:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/7fc19510-4e98-41c9-8439-f449c6bed88b.png)'
  prefs: []
  type: TYPE_IMG
- en: Postman has a lot of options, and it organizes the information in a very pleasing
    way. Give it a try.
  prefs: []
  type: TYPE_NORMAL
- en: Filtering the output with httpie and jq
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The output from the API can be too verbose sometimes. Often, you''re interested
    just in one value out of a huge chunk of JSON responses. For example, if you want
    to get the names of all running services, you can hit the `/api/v1/services` endpoint.
    The response, however, includes a lot of additional information that is irrelevant.
    Here is a very partial subset of the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The complete output is 121 lines long! Let's see how to use `httpie` and `jq`
    to gain full control over the output and show only the names of the services.
    I prefer ([https://httpie.org/](https://httpie.org/)) over CURL for interacting
    with REST APIs on the command line. The `jq` ([https://stedolan.github.io/jq/](https://stedolan.github.io/jq/))
    command-line JSON processor is great for slicing and dicing JSON.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examining the full output, you can see that the service names are in the metadata
    sections of each item in the items array. The `jq` expression that will select
    just the `name` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the full command and output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Creating a pod via the Kubernetes API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The API can be used for creating, updating, and deleting resources too, given
    the following pod manifest in `nginx-pod.json`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command will create the pod through the API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'To verify that it worked, let''s extract the name and status of the current
    pods. The endpoint is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The `jq` expression is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the full command and output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Accessing the Kubernetes API via the Python client
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Exploring the API interactively using `httpie` and `jq` is great, but the real
    power of API comes when you consume and integrate it with other software. The
    Kubernetes incubator project provides a full-fledged and very well-documented
    Python `client` library. It is available at `https://github.com/kubernetes-incubator/client-python`.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, make sure you have Python installed (either 2.7 or 3.5+). Then install
    the Kubernetes package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'To start talking to a Kubernetes cluster, you need to connect to it. Start
    an interactive Python session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The Python client can read your Kubectl config:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Or it can connect directly to an already running proxy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Note that the client module provides methods to get access to different group
    versions, such as `CoreV1API`.
  prefs: []
  type: TYPE_NORMAL
- en: Dissecting the CoreV1API group
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s dive in and understand the `CoreV1API` group. The Python object has
    `481 public attributes`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Ignore the `attributes` that starts with double underscores because those are
    special `class/instance` methods unrelated to Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s pick ten random methods and see what they look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Very interesting. The `attributes` begin with a verb such as list, patch, or
    read. Many of them have this notion of a `namespace`, and many have a `with_http_info`
    suffix. To understand the better, let''s count how many verbs exist and how many
    `attributes` use each verb (where the verb is the first token before the underscore):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We can drill further and look at the interactive help for a specific `attribute`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: You can poke around yourself and learn more about the API. Let's look at some
    common operations, such as listing, creating, watching, and deleting objects.
  prefs: []
  type: TYPE_NORMAL
- en: Listing objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can list different kinds of object. The method names start with `list_`.
    Here is an example listing all namespaces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Creating objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create an object, you need to pass a body parameter to the create method.
    The body must be a Python dictionary that is equivalent to a YAML configuration
    file you would use with Kubectl. The easiest way to do it is to actually use a
    YAML and then use the Python YAML module (this is not part of the standard library
    and must be installed separately) to read the YAML file and load it into a dictionary.
    For example, to create an `nginx-deployment` with `3` replicas, we can use this
    YAML configuration file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'To install the `yaml` Python module, type this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Then the following Python program will create the deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Watching objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Watching objects is an advanced capability. It is implemented using a separate
    watch module. Here is an example to watch for `10` namespace events and print
    them to the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Invoking Kubectl programmatically
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you''re not a Python developer and don''t want to deal with the REST API
    directly, you have another option. Kubectl is used mostly as an interactive command-line
    tool, but nothing is stopping you from automating it and invoking it through scripts
    and programs. Here are some of the benefits of using Kubectl as your Kubernetes
    API client:'
  prefs: []
  type: TYPE_NORMAL
- en: Easy to find examples for any usage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Easy to experiment on the command line to find the right combination of commands
    and arguments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubectl supports output in JSON or YAML for quick parsing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Authentication is built-in via Kubectl configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Python subprocess to run Kubectl
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I''ll use Python again, so you can compare using the official Python client
    with rolling your own. Python has a module called `subprocess` that can run external
    processes such as Kubectl and capture the output. Here is a Python 3 example running
    Kubectl on its own and displaying the beginning of the usage output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Kubectl controls the Kubernetes cluster manager. Find more information at [https://github.com/kubernetes/kubernetes](https://github.com/kubernetes/kubernetes).
  prefs: []
  type: TYPE_NORMAL
- en: '**Here are some basic commands for beginners**:'
  prefs: []
  type: TYPE_NORMAL
- en: '`create`: Create a resource using the filename or `stdin`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`expose`: Take a replication controller, service, deployment, or pod'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `check_checkout()` function captures the output as a bytes array that needs
    to be decoded to `utf-8` to display it properly. We can generalize it a little
    bit and create a convenience function called `k` that accepts parameters it feeds
    to Kubectl, and then decodes the output and returns it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'This is nice for display, but Kubectl already does that. The real power comes
    when you use the structured output options with the `-o` flag. Then the result
    can be converted automatically to a Python object. Here is a modified version
    of the `k()` function that accepts a Boolean `use_json` keyword argument (default
    is `False`); if `True` adds `-o json` and then parses the JSON output to a Python
    object (dictionary):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'That returns a full-fledged API object, which can be navigated and drilled
    down just like when accessing the REST API directly or using the official Python
    client:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see how to delete the `deployment` and wait until all the pods are gone.
    The Kubectl delete command doesn''t accept the `-o json` option (although it has
    `-o` name), so let''s leave out `use_json`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Extending the Kubernetes API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes is an extremely flexible platform. It allows you to extend its own
    API with new types of resources called custom resources. If that is not enough
    you can even provide your API server that integrates with the Kubernetes API server
    in a mechanism called API aggregation. What can you do with custom resources?
    Plenty. You can use them to manage the Kubernetes API resources that live outside
    the Kubernetes cluster, which your pods communicate with.
  prefs: []
  type: TYPE_NORMAL
- en: 'By adding those external resources as custom resources, you get a full picture
    of your system and you benefit from many Kubernetes API features such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Custom CRUD REST endpoints
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Versioning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Watches
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatic integration with generic Kubernetes tooling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other use cases for custom resources are metadata for custom controllers and
    automation programs.
  prefs: []
  type: TYPE_NORMAL
- en: Custom resources that were introduced in Kubernetes 1.7 are a significant improvement
    over the now deprecated third-party resources. Let's dive in and see what custom
    resources are all about.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the structure of a custom resource
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to play nice with the Kubernetes API server, third-party resources
    must conform to some basic requirements. Similar to built-in API objects, they
    must have the following fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '`apiVersion`: `apiextensions.k8s.io`/`v1beta1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`metadata`: Standard Kubernetes object metadata'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kind`: `CustomResourceDefinition`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`spec`: Describes how the resource appears in the API and tools'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`status`: Indicates the current status of the CRD'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The spec has an internal structure that includes fields like group, names, scope,
    validation, and version. The status includes the fields `acceptedNames` and `Conditions`.
    In the next section, I'll show you an example that clarifies the meaning of these
    fields.
  prefs: []
  type: TYPE_NORMAL
- en: Developing custom resource definitions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You develop your custom resources using custom resource definitions, aslo known
    as CRD. The intention is for CRDs to integrate smoothly with Kubernetes, its API,
    and its tooling, so you need to provide a lot of information. Here is an example
    for a custom resource called `Candy`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s create it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the metadata name with the plural notation is returned. Now, let''s
    verify that we can access it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'There is also a new API endpoint for managing this new resource:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s use our Python code to access it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Integrating custom resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once the `CustomResourceDefinition` object has been created, you can create
    custom resources of that resource kind in particular, `Candy` in this case (`candy`
    becomes `CamelCase Candy`). `Candy` objects can contain arbitrary fields with
    arbitrary JSON. In the following example, a `flavor` custom field is set on the
    `Candy` object. The `apiVersion` field is derived from the CRD spec''s group and
    version fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'You can add arbitrary fields to your custom resources. The values can be any
    JSON values. Note that these fields are not defined in the CRD. Different objects
    can have different fields. Let''s create it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, `kubectl` can operate on `Candy` objects just like it works
    on built-in objects. Note that resource names are case-insensitive when using
    `kubectl`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also view the raw JSON data using the standard `-o json` flag. I''ll
    use the short name `cn` this time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Finalizing custom resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Custom resources support finalizers just like standard API objects. A finalizer
    is a mechanism where objects are not deleted immediately but have to wait for
    special controllers that run in the background and watch for deletion requests.
    The controller may perform any necessary cleanup options and then remove its finalizer
    from the target object. There may be multiple finalizers on an object. Kubenetes
    will wait until all finalizers have been removed and only then delete the object.
    The finalizers in the metadata are just arbitrary strings that their corresponding
    controller can identify. Here is an example with a `Candy` object that has two
    finalizers, `eat-me` and `drink-me`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Validating custom resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can add any field to a CRD. This may cause invalid definitions. Kubernetes
    1.9 introduced a validation mechanism for CRDs based on the OpenAPI V3 schema.
    It''s still in beta and can be disabled using a feature gate when starting the
    API server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'In your CRD, you add a validation section to the spec:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'If you try to create objects that violate the validation in the spec, you''ll
    get an error message. You can read more about the OpenAPI schema here: `http://bit.ly/2FsBfWA`.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding API server aggregation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CRDs are great when all you need is some CRUD operations on your own types.
    You can just piggyback on the Kubernetes API server, which will store your objects
    and provide API support and integration with tooling such as Kubectl. You can
    run controllers that watch for your objects and perform some operations when they
    are created, updated, or deleted. But CRDs have limitations. If you need more
    advanced features and customization, you can use API server aggregation and write
    your own API server that the Kubernetes API server will delegate to.
  prefs: []
  type: TYPE_NORMAL
- en: 'Your API server will use the same API machinery as the Kubernetes API server
    itself. Some of the advanced capabilities are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Controlling the storage of your objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-versioning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Custom operations beyond CRUD (such as exec or scale)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using protocol buffer payloads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Writing an extension API server is a non-trivial effort. If you decide you
    need all that power, I recommend using the API builder project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/kubernetes-incubator/apiserver-builder](https://github.com/kubernetes-incubator/apiserver-builder)'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is a young project, but it takes care of a lot of the necessary boilerplate
    code. The API builder provides the following capabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: Bootstrap complete type definitions, controllers, and tests, as well as documentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can run the extension control plane locally, inside Minikube, or on an actual
    remote cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Your generated controllers will be able to watch and update API objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding resources (including sub-resources)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Default values you can override if needed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Utilizing the service catalog
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Kubernetes service catalog project allows you to integrate smoothly and
    painlessly any external service that support the Open Service Broker API specification:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/openservicebrokerapi/servicebroker](https://github.com/openservicebrokerapi/servicebroker)'
  prefs: []
  type: TYPE_NORMAL
- en: The intention of the open service broker API is to expose external services
    to any cloud environment through a standard specification with supporting documentation
    and a comprehensive test suite. That lets providers implement a single specification
    and supports multiple cloud environments. The current environments include Kubernetes
    and CloudFoundry. The project works towards broad industry adoption.
  prefs: []
  type: TYPE_NORMAL
- en: 'The service catalog is particularly useful for integrating the services of
    cloud platform providers. Here are some examples of such services:'
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft Azure Cloud Queue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Simple Queue Service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Cloud Pub/Sub
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This capability is a boon for organizations that are committed to the cloud.
    You get to build your system on Kubernetes, but you don't have to deploy, manage,
    and maintain every service in your cluster yourself. You can offload that to your
    cloud provider, enjoy deep integration, and focus on your application.
  prefs: []
  type: TYPE_NORMAL
- en: The service catalog can potentially make your Kubernetes cluster fully autonomous
    by allowing you to provision cloud resources through service brokers. We're not
    there yet, but the direction is very promising.
  prefs: []
  type: TYPE_NORMAL
- en: This concludes our discussion of accessing and extending Kubernetes from the
    outside. In the next section, we will direct our gaze inward and look into customizing
    the inner workings of Kubernetes itself via plugins.
  prefs: []
  type: TYPE_NORMAL
- en: Writing Kubernetes plugins
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will dive into the guts of Kubernetes and learn how to take
    advantage of its famous flexibility and extensibility. We will learn about the
    different aspects that can be customized via plugins, and how to implement such
    plugins and integrate them with Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Writing a custom scheduler plugin
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes defines itself as a container scheduling and management system.
    As such, the scheduler is the most important component of Kubernetes. Kubernetes
    comes with a default scheduler, but allows for writing additional schedulers.
    To write your own custom scheduler, you need to understand what the scheduler
    does, how it is packaged, how to deploy your custom scheduler, and how to integrate
    your scheduler. The scheduler source code is available here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/kubernetes/kubernetes/tree/master/pkg/scheduler](https://github.com/kubernetes/kubernetes/tree/master/pkg/scheduler)'
  prefs: []
  type: TYPE_NORMAL
- en: In the rest of this section, we will dive deep into the source and examine data
    types, algorithms, and code.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the design of the Kubernetes scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The job of the scheduler is to find a node for newly created or restarted pods,
    and create a binding in the API server and run it there. If the scheduler can't
    find a suitable node for the pod, it will remain in pending state.
  prefs: []
  type: TYPE_NORMAL
- en: The scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most of the work of the scheduler is pretty generic—it figures out which pods
    need to be scheduled, updates their state, and runs them on the selected node.
    The custom part is how to map pods to nodes. The Kubernetes team recognized the
    need for custom scheduling, and the generic scheduler can be configured with different
    scheduling algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main data type is the Scheduler `struct` that contains a `Config struct`
    with lots of properties (this will soon be replaced by a `configurator` interface):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the `Config struct`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Most of these are interfaces, so you can configure the scheduler with custom
    functionality. In particular, the scheduler algorithm is relevant if you want
    to customize pod scheduling.
  prefs: []
  type: TYPE_NORMAL
- en: Registering an algorithm provider
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The scheduler has the concept of an algorithm provider and an algorithm. Together,
    they let you use the substantial functionality of the built-in scheduler in order
    to replace the core scheduling algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'The algorithm provider lets you register new algorithm providers with the factory.
    There is already one custom provider registered, called `ClusterAutoScalerProvider`.
    We will see later how the scheduler knows which algorithm provider to use. The
    key file is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/kubernetes/kubernetes/blob/master/pkg/scheduler/algorithmprovider/defaults/defaults.go](https://github.com/kubernetes/kubernetes/blob/master/pkg/scheduler/algorithmprovider/defaults/defaults.go)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `init()` function calls the `registerAlgorithmProvider()`, which you should
    extend to include your algorithm provider in addition to the default and `autoscaler`
    providers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: In addition to registering the provider, you also need to register a fit predicate
    and a priority function, which are used to actually perform the scheduling.
  prefs: []
  type: TYPE_NORMAL
- en: You can use the factory's `RegisterFitPredicate()` and `RegisterPriorityFunction2()`
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The scheduler algorithm is provided as part of the configuration. Custom schedulers
    can implement the `ScheduleAlgorithm` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: When you run the scheduler, you can provide the name of the custom scheduler
    or a custom algorithm provider as a command-line argument. If none are provided,
    the default algorithm provider will be used. The command-line arguments to the
    scheduler are `--algorithm-provider` and `--scheduler-name`.
  prefs: []
  type: TYPE_NORMAL
- en: Packaging the scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The custom scheduler runs as a pod inside the same Kubernetes cluster it oversees.
    It needs to be packaged as a container image. Let''s use a copy of the standard
    Kubernetes scheduler for demonstration purposes. We can build Kubernetes from
    the source to get a scheduler image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the following Dockerfile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Use it to `build` a Docker image type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, push the image to a container registry. I''ll use DockerHub here.
    You''ll need to create an account on DockerHub and log in before pushing your
    image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Note that I built the scheduler locally, and in the Dockerfile I just copy it
    from the host into the image. That works when you deploy on the same OS that you
    build with. If this is not the case, then it may be better to insert the build
    commands into the Dockerfile. The price you pay is that you need to pull all of
    Kubernetes into the image.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the custom scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that the scheduler image is built and available in the registry, we need
    to create a Kubernetes deployment for it. The scheduler is, of course, critical,
    so we can use Kubernetes itself to ensure that it is always running. The following
    YAML file defines a deployment with a single replica and a few other bells and
    whistles, such as liveness and readiness probes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: The name of the scheduler (`custom-scheduler` here) is important and must be
    unique. It will be used later to associate pods with the scheduler to schedule
    them. Note that the custom scheduler belongs in the `kube-system` namespace.
  prefs: []
  type: TYPE_NORMAL
- en: Running another custom scheduler in the cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Running another custom scheduler is as simple as creating the deployment. This
    is the beauty of this encapsulated approach. Kubernetes is going to run a second
    scheduler, which is a big deal, but Kubernetes is unaware of what''s going on.
    It just deploys a pod like any other pod, except this pod happens to be a custom
    scheduler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s verify that the scheduler pod is running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Our custom scheduler is running.
  prefs: []
  type: TYPE_NORMAL
- en: Assigning pods to the custom scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'OK. The custom scheduler is running alongside the default scheduler. But how
    does Kubernetes choose which scheduler to use when a pod needs scheduling? The
    answer is that the pod decides and not Kubernetes. The pod spec has an optional
    scheduler name field. If it''s missing, the default scheduler is used; otherwise,
    the specified scheduler is used. This is the reason the custom scheduler names
    must be unique. The name of the default scheduler is `default-scheduler`, in case
    you want to be explicit in your pod spec. Here is a pod definition that will be
    scheduled using the default scheduler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'To have the `custom-scheduler` schedule this pod, change the pod spec to the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Verifying that the pods were scheduled using the custom scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are two primary ways to verify pods get scheduled by the correct scheduler.
    First, you can create pods that need to be scheduled by the custom scheduler before
    deploying the custom scheduler. The pods will remain in the pending state. Then,
    deploy the custom scheduler and the pending pods will be scheduled and start running.
  prefs: []
  type: TYPE_NORMAL
- en: 'The other method is to check the event logs and look for scheduled events using
    this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Employing access control webhooks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes always provided ways for you to customize access control. In Kubernetes
    access control can be denoted as triple-A: Authentication, Authorization, and
    Admission control. In early versions, it was done through plugins that required
    Go programming, installing into your cluster, registration, and other invasive
    procedures. Now, Kubernetes lets you customize authentication, authorization,
    and admission control webhooks.'
  prefs: []
  type: TYPE_NORMAL
- en: Using an authentication webhook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes lets you extend the authentication process by injecting a webhook
    for bearer tokens. It requires two pieces of information: how to access the remote
    authentication service and the duration of the authentication decision (it defaults
    to two minutes).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To provide this information and enable authentication webhooks, start the API
    server with the following command-line arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--runtime-config=authentication.k8s.io/v1beta1=true`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--authentication-token-webhook-config-file`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--authentication-token-webhook-cache-ttl`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The configuration file uses the `kubeconfig` file format. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: Note that a client certificate and key must be provided to Kubernetes for mutual
    authentication against the remote authentication service.
  prefs: []
  type: TYPE_NORMAL
- en: The cache TTL is useful because often users will make multiple consecutive requests
    to Kubernetes. Having the authentication decision cached can save a lot of round
    trips to the remote authentication service.
  prefs: []
  type: TYPE_NORMAL
- en: 'When an API HTTP request comes in, Kubernetes extracts the bearer token from
    its headers and posts a `TokenReview` JSON request to the remote authentication
    service through the webhook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'The remote authentication service will respond with a decision. The status
    authentication will either be true or false. Here is an example of a successful
    authentication:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'A rejected response is much more concise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Using an authorization webhook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The authorization webhook is very similar to the authentication webhook. It
    just requires a configuration file that is in the same format as the authentication
    webhook configuration file. There is no authorization caching because unlike authentication,
    the same user may make lots of requests to different API endpoints with different
    parameters and authorization decisions may be different, so caching is not a viable
    option.
  prefs: []
  type: TYPE_NORMAL
- en: 'You configure the webhook by passing the following command-line arguments to
    the API server:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--runtime-config=authorization.k8s.io/v1beta1=true`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--authorization-webhook-config-file=<configuration filename>`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When a request passes authentication, Kubernetes will send a `SubjectAccessReview`
    JSON object to the remote authorization service. It will contain the request user
    as well as requested resource and other request attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The request will be allowed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Or it will be disallowed (with a reason):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: A user may be authorized to access a resource, but not non-resource attributes
    such as /`api`, /`apis`, /`metrics`, /`resetMetrics`, /`logs`, /`debug`, /`healthz`,
    `/swagger-ui/`, `/swaggerapi/`, `/ui`, and `/version`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how to request access to the logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Using an admission control webhook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Dynamic admission control supports webhooks too. It is still in alpha. You
    need to enable the generic admission webhook by passing the following command-line
    arguments to the API server:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--admission-control=GenericAdmissionWebhook`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--runtime-config=admissionregistration.k8s.io/v1alpha1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring webhook admission controller on the fly
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The authentication and authorization webhooks must be configured when you start
    the API server. The admission control webhooks can be configured dynamically by
    creating `externaladmissionhookconfiguration` objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: Providing custom metrics for horizontal pod autoscaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Prior to Kubernetes 1.6, custom metrics were implemented as a Heapster model.
    In Kubernetes 1.6, a new custom metrics API landed and matured gradually. As of
    Kubernetes 1.9, they are enabled by default. Custom metrics rely on API aggregation.
    The recommended path is to start with the custom metrics API server boilerplate
    available here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/kubernetes-incubator/custom-metrics-apiserver](https://github.com/kubernetes-incubator/custom-metrics-apiserver)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, you implement the `CustomMetricsProvider` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Extending Kubernetes with custom storage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Volume plugins are yet another type of plugin. Prior to Kubernetes 1.8, you
    had to write a Kublet plugin that required implementing, registration with Kubernetes,
    and linking with the Kubelet. Kubernetes 1.8 introduced the FlexVolume, which
    is much more versatile. Kubernetes 1.9 took it to the next level with the **Container
    Storage Interface** (**CSI**).
  prefs: []
  type: TYPE_NORMAL
- en: Taking advantage of FlexVolume
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes volume plugins are designed to support a particular type of storage
    or storage provider. There are numerous volume plugins, which we covered in [Chapter
    7](2651f39a-2cf8-4562-9729-bc8927b07e66.xhtml), *Handling Kubernetes Storage*.
    The existing volume plugins are more than enough for most users, but if you need
    to integrate with a storage solution that is not supported you must implement
    your own volume plugin, which is not trivial. If you want it to get accepted as
    an official Kubernetes plugin then you have to get through a rigorous approval
    process. But `FlexVolume` provides another path. It is a generic plugin that allows
    you to hook up your unsupported storage backend without deep integration with
    Kubernetes itself.
  prefs: []
  type: TYPE_NORMAL
- en: '`FlexVolume` lets you add arbitrary attributes to the spec, and it communicates
    with your backend via a callout interface that includes the following operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Attach**: Attaches a volume to the Kubernetes Kubelet node'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Detach**: Detaches the volume from the Kubernetes Kubelet node'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mount**: Mounts the attached volume'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unmount**: Unmounts the attached volume'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each operation is implemented by the backend driver as a binary that the FlexVolume
    invokes at the right time. The driver must be installed in `/usr/libexec/kubernetes/kubelet-plugins/volume/exec/<vendor>~<driver>/<driver>`.
  prefs: []
  type: TYPE_NORMAL
- en: Benefitting from CSI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: FlexVolume provides out-of-tree plugin capability, but it still requires the
    FlexVolume plugin itself and a somewhat cumbersome installation and invocation
    model. The CSI will improve on it significantly by having the vendor implement
    it directly. The best thing about it is that you, as a developer, don't have to
    create and maintain those plugins. It is the responsibility of the storage solution
    provider to implement and maintain the CSI, and it's in their interest to make
    it as robust as possible so that people don't choose a different storage solution
    that works out of the box on Kubernetes (and other platforms that integrate with
    CSI).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we covered three major topics: working with the Kubernetes
    API, extending the Kubernetes API, and writing Kubernetes plugins. The Kubernetes
    API supports the OpenAPI spec and is a great example of REST API design that follows
    all current best practices. It is very consistent, well organized, and well documented,
    yet it is a big API and is not easy to understand. You can access the API directly
    via REST over HTTP, using client libraries including the official Python client,
    and even by invoking Kubectl.'
  prefs: []
  type: TYPE_NORMAL
- en: Extending the Kubernetes API involves defining your own custom resources and
    optionally extending the API server itself via API aggregation. Custom resources
    are most effective when you combine them with additional custom plugins or controllers
    when you query and update them externally.
  prefs: []
  type: TYPE_NORMAL
- en: Plugins and webhooks are the foundation of Kubernetes design. Kubernetes was
    always meant to be extended by users to accommodate any need. We looked at various
    plugins and webhooks you can write and how to register and integrate them seamlessly
    with Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: We also looked at custom metrics and even how to extend Kubernetes with custom
    storage options.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, you should be well aware of all the major mechanisms to extend,
    customize, and control Kubernetes through API access, custom resources, and custom
    plugins. You are in a great position to take advantage of these capabilities to
    augment the existing functionality of Kubernetes and adapt it to your needs and
    your systems.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll look at Helm, the Kubernetes package manager, and
    its charts. As you may have realized, deploying and configuring complex systems
    on Kubernetes is far from simple. Helm allows the grouping together of a bunch
    of manifests into a chart, which can be installed as a single unit.
  prefs: []
  type: TYPE_NORMAL
