- en: Concurrent and Multithreaded Programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Concurrent programming has always been a difficult task. It is a source of
    many hard-to-solve problems. In this chapter, we will show you different ways
    to incorporate concurrency and some best practices, such as immutability, which
    helps to create multithreaded processing. We will also discuss the implementation
    of some commonly used patterns, such as divide and- conquer and publish-subscribe,
    using the constructs provided by Java. We will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Using the basic element of concurrency—thread
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different synchronization approaches
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Immutability as a means of achieving concurrency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using concurrent collections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the executor service to execute async tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using fork/join to implement divide-and-conquer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using flow to implement the publish-subscribe pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Concurrency—the ability to execute several procedures in parallel—becomes increasingly
    important as big-data analysis moves into the mainstream of modern applications.
    Having CPUs or several cores in one CPU helps increase the throughput, but the
    growth rate of the data volume will always outpace hardware advances. Besides,
    even in a multiple-CPU system, one still has to structure the code and think about
    resource-sharing to take advantage of the available computational power.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapters, we demonstrated how lambdas with functional interfaces
    and parallel streams made concurrent processing part of the toolkit of every Java
    programmer. One can easily take advantage of this functionality with minimal,
    if any, guidance.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will describe some other—old (before Java 9) and new—Java
    features and APIs that allow more control over concurrency. The high-level concurrency
    Java API has been around since Java 5\. The JDK Enhancement Proposal (JEP) 266,
    *More Concurrency Updates* ([http://openjdk.java.net/jeps/266](http://openjdk.java.net/jeps/266)), introduced, to
    Java 9 in the `java.util.concurrent `package.
  prefs: []
  type: TYPE_NORMAL
- en: '"an interoperable publish-subscribe framework, enhancements to the CompletableFuture
    API, and various other improvements"'
  prefs: []
  type: TYPE_NORMAL
- en: But before we dive into the details of the latest additions, let's review the
    basics of concurrent programming in Java and see how to use them.
  prefs: []
  type: TYPE_NORMAL
- en: Java has two units of execution—process and thread. A process usually represents
    the whole JVM, although an application can create another process using `ProcessBuilder`.
    But since the multiprocess case is outside the scope of this book, we will focus
    on the second unit of execution, that is, a thread, which is similar to a process
    but less isolated from other threads and requires fewer resources for execution.
  prefs: []
  type: TYPE_NORMAL
- en: A process can have many threads running and at least one thread called the *main *thread. Threads
    can share resources, including memory and open files, which allows for better
    efficiency. But it comes with a price of higher risk of unintended mutual interference
    and even blocking of the execution. That is where programming skills and an understanding
    of the concurrency techniques are required. And that is what we are going to discuss
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Using the basic element of concurrency – thread
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will look at the `java.lang.Thread` class and see what it
    can do for concurrency and program performance in general.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Java application starts as the main thread (not counting system threads that
    support the process). It can then create other threads and let them run in parallel,
    sharing the same core via time-slicing or having a dedicated CPU for each thread.
    This can be done using the `java.lang.Thread` class that implements the `Runnable`
    functional interface with only one abstract method, `run()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two ways to create a new thread: creating a subclass of `Thread`,
    or implementing the `Runnable` interface and passing the object of the implementing
    class to the `Thread` constructor. We can invoke the new thread by calling the
    `start()` method of the `Thread` class which, in turn, calls the `run()` method
    that was implemented.'
  prefs: []
  type: TYPE_NORMAL
- en: Then, we can either let the new thread run until its completion or pause it
    and let it continue again. We can also access its properties or intermediate results
    if needed.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we create a class called `AThread` that extends `Thread` and overrides
    its `run()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, we want the thread to generate a stream of integers in a certain
    range. Then, we use the `peek()` operation to invoke the `doSomething()` static
    method of the main class for each stream element in order to make the thread busy
    for some time. Refer to the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the `doSomething()` method generates a stream of integers in
    the range of `i` to `99999`; it then converts the stream into a stream of doubles,
    calculates the square root of each of the stream elements, and finally calculates
    an average of the stream elements. We discard the result and return the passed-in
    parameter as a convenience that allows us to keep the fluent style in the stream
    pipeline of the thread, which ends by printing out each element. Using this new
    class, we can demonstrate the concurrent execution of the three threads, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The first thread generates the integers `1`, `2`, and `3`, the second generates
    the integers `11`, `12`, and `13`, and the third thread (main one) generates `21`,
    `22`, and `23`.
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned before, we can rewrite the same program by creating and using
    a class that could implement the `Runnable` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'One can run the same three threads like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also take advantage of `Runnable` being a functional interface and avoid
    creating an intermediate class by passing in a lambda expression instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Which implementation is better depends on your goal and style. Implementing
    `Runnable` has an advantage (and in some cases, is the only possible option) that
    allows the implementation to extend another class. It is particularly helpful when
    you would like to add thread-like behavior to an existing class. You can even
    invoke the `run()` method directly, without passing the object to the `Thread`
    constructor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using a lambda expression wins over the `Runnable` implementation when only the `run()` method
    implementation is needed, no matter how big it is. If it is too big, you can isolate
    it in a separate method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: One would be hard-pressed to come up with a shorter implementation of the preceding
    functionality.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we run any of the preceding versions, we will get an output that looks something
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/02e8e127-3a86-4d96-aa56-8c08b69770a4.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the three threads print out their numbers concurrently, but
    the sequence depends on the particular JVM implementation and underlying operating
    system. So, you will probably get a different output. Besides, it also may change
    from run to run.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Thread` class has several constructors that allow setting the thread name
    and the group it belongs to. Grouping threads helps manage them if there are many
    threads running in parallel. The class also has several methods that provide information
    about the thread''s status and properties, and allow us to control the thread''s
    behavior. Add these two lines to the preceding example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The result of the preceding code will look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ab04ad0e-d622-42c0-a51f-9bac8a1b1837.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, say you add a name to each thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the output will show the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e66d2aab-17fb-4b83-ac92-adff52f6f43e.png)'
  prefs: []
  type: TYPE_IMG
- en: The thread's `id` is generated automatically and cannot be changed, but it can
    be reused after the thread is terminated. Several threads, on the other hand,
    can be set with the same name. The execution priority can be set programmatically
    with a value between `Thread.MIN_PRIORITY` and `Thread.MAX_PRIORITY`. The smaller
    the value, the more time the thread is allowed to run, which means it has higher
    priority. If not set, the priority value defaults to `Thread.NORM_PRIORITY`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The state of a thread can have one of the following values:'
  prefs: []
  type: TYPE_NORMAL
- en: '`NEW`: When a thread has not yet started'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RUNNABLE`: When a thread is being executed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BLOCKED`: When a thread is blocked and is waiting for a monitor lock'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`WAITING`: When a thread is waiting indefinitely for another thread to perform
    a particular action'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TIMED_WAITING`: When a thread is waiting for another thread to perform an
    action for up to a specified waiting time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TERMINATED`: When a thread has exited'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `sleep()` method can be used to suspend the thread execution for a specified
    (in milliseconds) period of time. The complementary `interrupt()` method sends
    `InterruptedException` to the thread that can be used to wake up the *sleeping*
    thread. Let''s work this out in the code and create a new class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code produces intermediate results, which are stored in the `result` property.
    Each time a new result is produced, the thread pauses (sleeps) for one second.
    In this specific example, written for demonstrative purposes only, the code does
    not do anything particularly useful. It just iterates over a set of values and
    considers each of them a result. In real-world code, you would do some calculations
    based on the current state of the system and assign the calculated value to the `result` property.
    Now let''s use this class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/d420d69b-2e20-4865-a348-b973dda270f7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The output may look different on different computers, but you get the idea:
    this way, one thread can control the output of another thread.'
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are two other important methods that support thread cooperation. The first
    is the `join()` method, which allows the current thread to wait until another
    thread is terminated. Overloaded versions of `join()` accept the parameters that
    define how long the thread has to wait before it can do something else.
  prefs: []
  type: TYPE_NORMAL
- en: The `setDaemon()` method can be used to make the thread terminate automatically
    after all the non-daemon threads are terminated. Usually, daemon threads are used
    for background and supporting processes.
  prefs: []
  type: TYPE_NORMAL
- en: Different synchronization approaches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, you will learn about the two most popular methods of managing
    concurrent access to common resources in Java: `synchronized method` and `synchronized
    block`.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Two or more threads modifying the same value while other threads read it is
    the most general description of one of the problems of concurrent access. Subtler
    problems include **thread interference** and **memory consistency errors**, which
    both produce unexpected results in seemingly benign fragments of code. We are
    going to demonstrate such cases and ways to avoid them.
  prefs: []
  type: TYPE_NORMAL
- en: 'At first glance, it seems quite straightforward: just allow only one thread
    at a time to modify/access the resource and that''s it. But if the access takes
    a long time, it creates a bottleneck that might eliminate the advantage of having
    many threads working in parallel. Or, if one thread blocks access to one resource
    while waiting for access to another resource and the second thread blocks access
    to the second resource while waiting for access to the first one, it creates a
    problem called a **deadlock**. These are two very simple examples of the possible
    challenges a programmer has to tackle when dealing with multiple threads.'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we''ll reproduce a problem caused by the concurrent modification of
    the same value. Let''s create a `Calculator` class that has the `calculate()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This method assigns an input value to a property and then calculates its square
    root. We also inserted two lines of code that generate streams of 50 and 100 values.
    We did this to keep the method busy for some time. Otherwise, everything is done
    so quickly that there will be little chance for any concurrency to occur. Our
    adding the 100-values-generating code gives another thread a chance to assign
    the `prop` field another value before the current thread calculates the square
    root of the value the current thread has just assigned.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we are going to use the `calculate()` method in the following code fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The two preceding threads modify the same property of the same `Calculator` object
    concurrently. Here is the result we got from one of our runs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: If you run these examples on your computer and do not see the effect of concurrency,
    try to increase the number of doubles generated in the *slowing* line by replacing `100` with `1000`,
    for example. When the results of the threads are different, it means that in the
    period between setting the value of the `prop` field and returning its square
    root in the `calculate()` method, the other thread managed to assign a different
    value to `prop`. This is the case of thread interference.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two ways to protect code from such a problem: using `synchronized
    method` or `synchronized block`—both help to execute code as an atomic operation
    without any interference from another thread.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Making `synchronized method` is easy and straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We just add the `synchronized` keyword in front of the method definition. Now,
    the results of both threads are going to always be the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This is because another thread cannot enter the synchronized method until the
    current thread (the one that has entered the method already) has exited it. This
    approach may cause performance degradation if the method takes a long time to
    execute. In such cases, `synchronized block` can be used, which wraps not the
    whole method but only several lines of code in an atomic operation. In our case,
    we can move the *slowing* line of code that generates 50 values outside the synchronized
    block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This way, the synchronized portion is much smaller, thus it has fewer chances
    to become a bottleneck.
  prefs: []
  type: TYPE_NORMAL
- en: '`synchronized block` acquires a lock on an object—any object, for that matter.
    In a huge class, you might not notice that the current object (this) is used as
    a lock for several blocks. And a lock acquired on a class is even more susceptible
    to unexpected sharing. So, it is better to use a dedicated lock:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: A dedicated lock has a higher level of assurance that the lock will be used
    to access only a particular block.
  prefs: []
  type: TYPE_NORMAL
- en: 'We did all these examples just to demonstrate synchronization approaches. If
    they were real code, we would just let each thread create its own `Calculator`
    object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This would be in line with the general idea of making lambda expressions independent
    of the context in which they are created. This is because, in a multithreaded
    environment, one never knows how the context will look during their execution.
    The cost of creating a new object every time is negligible unless a large amount
    of data has to be processed, and testing ensures that the object-creation overhead
    is noticeable.
  prefs: []
  type: TYPE_NORMAL
- en: Memory consistency errors can have many forms and causes in a multithreaded
    environment. They are well discussed in the Javadoc of the `java.util.concurrent` package.
    Here, we will mention only the most common case, which is caused by a lack of
    visibility. When one thread changes a property value, the other might not see
    the change immediately, and you cannot use the `synchronized` keyword for a primitive
    type. In such a situation, consider using the `volatile` keyword for the property;
    it guarantees its read/write visibility between different threads.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Different types of locks for different needs and with different behaviors are
    assembled in the `java.util.concurrent.locks` package.
  prefs: []
  type: TYPE_NORMAL
- en: The `java.util.concurrent.atomic` package provides support for lock-free, thread-safe
    programming on single variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following classes provide synchronization support too:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Semaphore`: This restricts the number of threads that can access a resource'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CountDownLatch`: This allows one or more threads to wait until a set of operations
    being performed in other threads are completed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CyclicBarrier`: This allows a set of threads to wait for each other to reach
    a common barrier point'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Phaser`: This provides a more flexible form of barrier that may be used to
    control phased computation among multiple threads'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Exchanger`: This allows two threads to exchange objects at a rendezvous point
    and is useful in several pipeline designs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each object in Java inherits the `wait()`, `notify()`, and `notifyAll()` methods
    from the base object. These methods can also be used to control the threads' behavior
    and their access to the locks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Collections` class has methods that synchronize various collections. However,
    this means that only the modifications of the collection could become thread-safe,
    not the changes to the collection members. Also, while traversing the collection
    via its iterator, it has to be protected too because an iterator is not thread-safe.
    Here is a Javadoc example of the correct usage of a synchronized map:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'To add more to your plate as a programmer, you have to realize that the following
    code is not thread-safe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This is because although `List l` is synchronized, in multithreaded processing,
    it is quite possible that some other code would add more elements to the list
    or remove an element.
  prefs: []
  type: TYPE_NORMAL
- en: The concurrency problems are not easy to solve. That is why it is not surprising
    that more and more developers now take a more radical approach. Instead of managing
    an object state, they prefer processing data in a set of stateless operations.
    We saw examples of such code in [Chapter 5](eaa70333-8e9d-453d-a9b6-063152fcc1e1.xhtml),
    *Streams and Pipelines*. It seems that Java and many modern languages and computer
    systems are evolving in this direction.
  prefs: []
  type: TYPE_NORMAL
- en: Immutability as a means of achieving concurrency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will learn how to use immutability against problems caused
    by concurrency.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A concurrency problem most often occurs when different threads modify and read
    data of the same shared resource. Decreasing the number of modifying operations
    diminishes the risk of concurrency issues. This is where immutability—the condition
    of read-only values—enters the stage.
  prefs: []
  type: TYPE_NORMAL
- en: Object immutability means an absence of means to change its state after the
    object has been created. It does not guarantee thread-safety but helps to increase
    it significantly and provide sufficient protection from concurrency problems in
    many practical applications.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a new object instead of reusing an existing one (by changing its state
    via setters and getters) is often perceived as an expensive approach. But with
    the power of modern computers, there has to be a huge number of object creations
    done for performance to be affected in any significant way. And even if that is
    the case, programmers often choose some performance degradation as the price for
    getting predictable results.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here is an example of a class that produces mutable objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'To make it immutable, we need to remove the setter and add the `final` keyword
    to its only property and to the class itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Adding the `final` keyword to a class prevents it from being extended, so its
    methods cannot be overridden. Adding `final` to a private property is not as obvious.
    The motivation is somewhat complex and has to do with the way the compiler reorders
    the fields during object construction. If the field is declared `final`, it is
    treated by the compiler as synchronized. That is why adding `final` to a private property
    is necessary to make the object completely immutable.
  prefs: []
  type: TYPE_NORMAL
- en: 'The challenge mounts up if the class is composed of other classes, especially
    mutable ones. When this happens, the injected class might bring in code that would
    affect the containing class. Also, the inner (mutable) class, which is retrieved
    by references via the getter, could then be modified and propagate the change
    inside the containing class. The way to close such holes is to generate new objects
    during the composition of the object retrieval. Here is an example of this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In our examples, we used very simple code. If more complexity is added to any
    of the methods, especially with parameters (and especially when some of the parameters
    are objects), it is possible you''ll get concurrency issues again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Even if this method belongs to `ImmutableClass` and does not affect the state
    of the `ImmutableClass` object, it is still a subject of the thread's race and
    has to be analyzed and protected as needed.
  prefs: []
  type: TYPE_NORMAL
- en: The `Collections` class has methods that make various collections unmodifiable.
    It means that the modification of the collection itself becomes read-only, not
    the collection members.
  prefs: []
  type: TYPE_NORMAL
- en: Using concurrent collections
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will learn about the thread-safe collections of the `java.util.concurrent` package.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A collection can be synchronized if you apply one of the `Collections.synchronizeXYZ()` methods
    to it; here, we have used XYZ as a placeholder that represents either `Set`, `List`,
    `Map`, or one of the several collection types (see the API of the `Collections`
    class). We have already mentioned that the synchronization applies to the collection
    itself, not to its iterator or the collection members.
  prefs: []
  type: TYPE_NORMAL
- en: Such synchronized collections are also called **wrappers** because all of the
    functionality is still provided by the collections passed as parameters to the `Collections.synchronizeXYZ()` methods,
    while the wrappers provide only thread-safe access to them. The same effect could
    be achieved by acquiring a lock on the original collection. Obviously, such a
    synchronization incurs a performance overhead in a multithreading environment,
    causing each thread to wait for its turn to access the collection.
  prefs: []
  type: TYPE_NORMAL
- en: A well-tuned application for performance implementation of thread-safe collections
    is provided by the `java.util.concurrent` package.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Each of the concurrent collections of the `java.util.concurrent` package implements
    (or extends, if it is an interface) one of the four interfaces of the `java.util`
    package: `List`, `Set`, `Map`, or `Queue`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `List` interface has only one implementation: the `CopyOnWriteArrayList` class.
    The following is taken from the Javadoc of this class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '"all mutative operations (add, set, and so on) are implemented by making a
    fresh copy of the underlying array... The "snapshot" style iterator method uses
    a reference to the state of the array at the point that the iterator was created.
    This array never changes during the lifetime of the iterator, so interference
    is impossible and the iterator is guaranteed not to throw `ConcurrentModificationException`.
    The iterator will not reflect additions, removals, or changes to the list since
    the iterator was created. Element-changing operations on iterators themselves
    (remove, set, and add) are not supported. These methods throw `UnsupportedOperationException`."'
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate the behavior of the `CopyOnWriteArrayList` class, let''s compare
    it with `java.util.ArrayList` (which is not a thread-safe implementation of `List`).
    Here is the method that adds an element to the list while iterating on the same
    list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'If we execute this code, the result will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4ff7a7b6-d0d6-4594-9007-d4f8fe5e9d31.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, `ArrayList` throws `ConcurrentModificationException` when the
    list is modified while being iterated (we used the same thread for simplicity
    and because it leads to the same effect, as in the case of another thread modifying
    the list). The specification, though, does not guarantee that the exception will
    be thrown or the list modification applied (as in our case), so a programmer should
    not base the application logic on such behavior.
  prefs: []
  type: TYPE_NORMAL
- en: The `CopyOnWriteArrayList` class, on the other hand, tolerates the same intervention;
    however, note that it does not add a new element to the current list because the
    iterator was created from a snapshot of the fresh copy of the underlying array.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s try to remove a list element concurrently while traversing the list,
    using this method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'If we execute this, we will get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4bef3bd5-c517-4ec4-9882-24da9bec2772.png)'
  prefs: []
  type: TYPE_IMG
- en: The behavior is similar to the previous example. The `CopyOnWriteArrayList` class
    allows the concurrent access to the list but does not allow modify the current
    list's copy.
  prefs: []
  type: TYPE_NORMAL
- en: 'We knew `ArrayList` would not be thread-safe for a long time, so we used a
    different technique to remove an element from the list while traversing it. Here
    is how this was done before the Java 8 release:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s try this and run the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The result will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c3cdf125-0dbf-4fec-96b7-379aed0651a6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is exactly what the Javadoc warned about ([https://docs.oracle.com/cd/E17802_01/j2se/j2se/1.5.0/jcp/beta2/apidiffs/java/util/concurrent/CopyOnWriteArrayList.html](https://docs.oracle.com/cd/E17802_01/j2se/j2se/1.5.0/jcp/beta2/apidiffs/java/util/concurrent/CopyOnWriteArrayList.html)):'
  prefs: []
  type: TYPE_NORMAL
- en: '"Element-changing operations on iterators themselves (remove, set, and add)
    are not supported. These methods throw UnsupportedOperationException."'
  prefs: []
  type: TYPE_NORMAL
- en: We should remember this when upgrading an application to make it work in a multithreaded
    environment—just changing from `ArrayList()` to `CopyOnWriteArrayList` would not
    be enough if we use an iterator to remove a list element.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since Java 8, there is a better way to remove an element from a collection
    using a lambda, which should be used as it leaves the plumbing details to the
    library code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'So let''s do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The result of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f11bd846-7dc6-4cd3-9d78-701ecafaba2a.png)'
  prefs: []
  type: TYPE_IMG
- en: It is short and has no problem with any of the collections and is in line with
    the general trend of having a stateless parallel computation that uses streams
    with lambdas and functional interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, after we upgrade an application to use the `CopyOnWriteArrayList` class, we
    can take advantage of a simpler way of adding a new element to the list (without
    first checking whether it is already there):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: With `CopyOnWriteArrayList`, this can be done as an atomic operation, so one
    does not need to synchronize the if-not-present-then-add block of code.
  prefs: []
  type: TYPE_NORMAL
- en: Let's review the concurrent collections of the `java.util.concurrent` package
    that implements the `Set` interface. There are three such implementations—`ConcurrentHashMap.KeySetView`,
    `CopyOnWriteArraySet`, and `ConcurrentSkipListSet`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The first one is just a view of the keys of `ConcurrentHashMap`. It is backed
    up by `ConcurrentHashMap` (which can be retrieved by the `getMap()` method). We
    will review the behavior of  `ConcurrentHashMap` later.
  prefs: []
  type: TYPE_NORMAL
- en: The second implementation of `Set` in the `java.util.concurrent` package is
    the `CopyOnWriteArraySet` class. Its behavior is similar to the `CopyOnWriteArrayList` class.
    In fact, it uses the `CopyOnWriteArrayList` class's implementation under the hood.
    The only difference is that it does not allow duplicate elements in the collection.
  prefs: []
  type: TYPE_NORMAL
- en: 'The third (and last) implementation of `Set` in the `java.util.concurrent` package
    is `ConcurrentSkipListSet`; it implements a sub-interface of `Set` called `NavigableSet`.
    According to the Javadoc of the `ConcurrentSkipListSet` class, insertion, removal,
    and access operations are safely executed concurrently by multiple threads*.* There
    are some limitations described in the Javadoc too:'
  prefs: []
  type: TYPE_NORMAL
- en: It does not permit the use of `null` elements.
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: The size of the set is calculated dynamically by traversing the collection,
    so it may report inaccurate results if this collection is modified during the
    operation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `addAll()`, `removeIf()`, and `forEach()` operations are not guaranteed
    to be performed atomically. The `forEach()` operation, if concurrent with an `addAll()`
    operation for example, "might observe only some of the added elements."
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The implementation of the  `ConcurrentSkipListSet` class is based on the `ConcurrentSkipListMap` class,
    which we will discuss shortly. To demonstrate the behavior of the `ConcurrentSkipListSet` class,
    let''s compare it with the `java.util.TreeSet` class (non-concurrent implementation
    of `NavigableSet`). We start with removing an element:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Of course, this code is not very efficient; we''ve removed the same element
    many times without checking for its presence. We have done this just for demonstrative
    purposes. Besides, since Java 8, the same `removeIf()` method works for `Set`
    just fine. But we would like to bring up the behavior of the new `ConcurrentSkipListSet` class, so
    let''s execute this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2bacd443-00a8-45c1-8a5c-14c5fc52e246.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As expected, the `ConcurrentSkipListSet` class handles the concurrency and
    even removes an element from the current set, which is helpful. It also removes
    an element via an iterator without an exception. Consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Run this for `TreeSet` and  `ConcurrentSkipListSet`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We won''t get any exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/179b44f4-2176-4707-bb2a-dfd3d85e9793.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is because, according to the Javadoc, the iterator of `ConcurrentSkipListSet`
    is weakly consistent, which means the following:'
  prefs: []
  type: TYPE_NORMAL
- en: They may proceed concurrently with other operations
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: They will never throw `ConcurrentModificationException`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They are guaranteed to traverse elements as they existed upon construction exactly
    once, and may (but are not guaranteed to) reflect any modifications subsequent
    to construction (from the Javadoc)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This "not guaranteed" part is somewhat disappointing, but it is better than
    getting an exception, as with `CopyOnWriteArrayList`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Adding to a `Set` class is not as problematic as to a `List` class because
    `Set` does not allow duplicates and handles the necessary checks internally:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run this, we''ll get the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6063c61a-3f6d-4680-a137-5b6bc60d1d73.png)'
  prefs: []
  type: TYPE_IMG
- en: As before, we observe that the concurrent `Set` version handles concurrency
    better.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s turn to the `Map` interface, which has two implementations in the `java.util.concurrent` package:
    `ConcurrentHashMap` and `ConcurrentSkipListMap`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `ConcurrentHashMap` class from the Javadoc.
  prefs: []
  type: TYPE_NORMAL
- en: '"supports full concurrency of retrievals and high concurrency for updates"'
  prefs: []
  type: TYPE_NORMAL
- en: It is a thread-safe version of `java.util.HashMap` and is analogous to `java.util.Hashtable`
    in this respect. In fact, the `ConcurrentHashMap` class meets the requirements
    of the same functional specification as `java.util.Hashtable`, although its implementation
    is "somewhat different in synchronization details"(from the Javadoc).
  prefs: []
  type: TYPE_NORMAL
- en: Unlike `java.util.HashMap` and `java.util.Hashtable`, `ConcurrentHashMap` supports,
    according to its Javadoc ([https://docs.oracle.com/javase/9/docs/api/java/util/concurrent/ConcurrentHashMap.html](https://docs.oracle.com/javase/9/docs/api/java/util/concurrent/ConcurrentHashMap.html)),
  prefs: []
  type: TYPE_NORMAL
- en: '"a set of sequential and parallel bulk operations that, unlike most Stream
    methods, are designed to be safely, and often sensibly, applied even with maps
    that are being concurrently updated by other threads"'
  prefs: []
  type: TYPE_NORMAL
- en: '`forEach()`: This performs a given action on each element'
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: '`search()`: This returns the first available non-null result of applying a
    given function to each element'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reduce()`: This accumulates each element (there are five overloaded versions)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These bulk operations accept a `parallelismThreshold` argument that allows deferring
    parallelization until the map size reaches the specified threshold. Naturally,
    when the threshold is set to `Long.MAX_VALUE`, there will be no parallelism whatsoever.
  prefs: []
  type: TYPE_NORMAL
- en: There are many other methods in the class API, so refer to its Javadoc for an
    overview.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike `java.util.HashMap` (and similar to `java.util.Hashtable`), neither `ConcurrentHashMap` nor
    `ConcurrentSkipListMap` allows null to be used as a key or value.
  prefs: []
  type: TYPE_NORMAL
- en: The second implementation of `Map`—the `ConcurrentSkipListSet` class—is based,
    as we mentioned before, on the `ConcurrentSkipListMap` class, so all the limitations of
    the `ConcurrentSkipListSet` class we just described apply to the `ConcurrentSkipListMap` class
    too. The `ConcurrentSkipListSet` class is practically a thread-safe version of
    `java.util.TreeMap`. `SkipList` is a sorted data structure that allows fast searches
    concurrently. All the elements are sorted based on their natural sorting order
    of keys. The `NavigableSet` functionality we demonstrated for the `ConcurrentSkipListSet` class is
    present in the `ConcurrentSkipListMap` class too. For many other methods in the
    class API, refer to its Javadoc.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s demonstrate the difference in the behavior in response to concurrency
    between the `java.util.HashMap`, `ConcurrentHashMap`, and `ConcurrentSkipListMap` classes.
    First, we will write the method that generates a test `Map` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the code that adds an element to a `Map` object concurrently:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Run this for all three implementations of `Map`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'If we do this, we get an output for `HashMap` for the first key only:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/99df2694-2099-4ac5-8475-84cd92f6a363.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We also get an output for `ConcurrentHashMap` and `ConcurrentSkipListMap` for
    all the keys, including the newly added ones. Here is the last section of the `ConcurrentHashMap` output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c935da11-bec2-4daf-b06f-6fc4e2d1aa33.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As mentioned already, the appearance of `ConcurrentModificationException` is
    not guaranteed. Now we see that the moment it is thrown (if it is thrown) is the
    moment when the code discovers that the modification has taken place. In the case
    of our example, it happened in the next iteration. Another point worth noting
    is that the current set of keys changes even as we isolate the set in a separate
    variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: This reminds us not to dismiss the changes propagated through the objects via
    their references.
  prefs: []
  type: TYPE_NORMAL
- en: 'To save ourselves some space and time, we will not show the code for concurrent
    removal and just summarize the results. As expected, `HashMap` throws the `ConcurrentModificationException` exception
    when an element is removed in any of the following ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The concurrent removal can be done using `Iterator` in one of the following
    ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: By contrast, the two concurrent `Map` implementations allow a concurrent element
    removal not just using `Iterator`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar behavior is also exhibited by all the concurrent implementations of
    the `Queue` interface: `LinkedTransferQueue`, `LinkedBlockingQueue`, `LinkedBlockingDequeue`,
    `ArrayBlockingQueue`, `PriorityBlockingQueue`, `DelayQueue`, `SynchronousQueue`,
    `ConcurrentLinkedQueue`, and `ConcurrentLinkedDequeue`, all in the `java.util.concurrent`
    package. But to demonstrate all of them would require a separate volume, so we
    leave it up to you to browse the Javadoc and provide an example of `ArrayBlockingQueue`
    only. The queue will be represented by the `QueueElement` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The queue producer will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The following will be the queue consumer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Its results may look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1f475fea-7d38-4c00-af7e-518ba520b778.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we select which collections to use, read the Javadoc to see whether the
    limitations of the collection are acceptable for your application.
  prefs: []
  type: TYPE_NORMAL
- en: For example, as per the Javadoc, the `CopyOnWriteArrayList` class
  prefs: []
  type: TYPE_NORMAL
- en: '"is ordinarily too costly, but may be more efficient than alternatives when
    traversal operations vastly outnumber mutations, and is useful when you cannot
    or don''t want to synchronize traversals, yet need to preclude interference among
    concurrent threads."'
  prefs: []
  type: TYPE_NORMAL
- en: Use it when you do not need to add new elements at different positions and do
    not require sorting. Otherwise, use `ConcurrentSkipListSet`.
  prefs: []
  type: TYPE_NORMAL
- en: The `ConcurrentSkipListSet` and `ConcurrentSkipListMap` classes, as per the
    Javadoc,
  prefs: []
  type: TYPE_NORMAL
- en: '"provide expected average log(n) time cost for the contains, add, and remove
    operations and their variants. Ascending ordered views and their iterators are
    faster than descending ones."'
  prefs: []
  type: TYPE_NORMAL
- en: Use them when you need to iterate quickly through the elements in a certain
    order.
  prefs: []
  type: TYPE_NORMAL
- en: Use `ConcurrentHashMap` when the concurrency requirements are very demanding
    and you need to allow locking on the write operation but do not need to lock the
    element.
  prefs: []
  type: TYPE_NORMAL
- en: '`ConcurrentLinkedQueque` and `ConcurrentLinkedDeque` are an appropriate choice
    when many threads share access to a common collection. `ConcurrentLinkedQueque`
    employs an efficient non-blocking algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: '`PriorityBlockingQueue` is a better choice when a natural order is acceptable
    and you need fast adding of elements to the tail and fast removing of elements
    from the head of the queue. Blocking means that the queue waits to become non-empty
    when retrieving an element and waits for space to become available in the queue
    when storing an element.'
  prefs: []
  type: TYPE_NORMAL
- en: '`ArrayBlockingQueue`, `LinkedBlockingQueue`, and `LinkedBlockingDeque` have
    a fixed size (they are bounded). The other queues are unbounded.'
  prefs: []
  type: TYPE_NORMAL
- en: Use these and similar characteristics and recommendations as the guidelines,
    but execute comprehensive testing and performance-measuring before and after implementing
    your functionality.
  prefs: []
  type: TYPE_NORMAL
- en: Using the executor service to execute async tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will learn how to use `ExecutorService` to implement controllable
    thread-execution.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In an earlier recipe, we demonstrated how to create and execute threads using
    the `Thread` class directly. It is an acceptable mechanism for a small number
    of threads that run and produce results predictably quickly. For big-scale applications
    with longer-running threads with complex logic (which might keep them alive for
    an unpredictably long time) and/or a number of threads growing unpredictably too,
    a simple create-and-run-until-exit approach might result in an `OutOfMemory` error
    or require a complex customized system of threads' status maintenance and management.
    For such cases, `ExecutorService` and related classes of the `java.util.concurrent`
    package provides an out-of-the-box solution that relieves a programmer of the
    need to write and maintain a lot of infrastructural code.
  prefs: []
  type: TYPE_NORMAL
- en: At the foundation of the Executor Framework lies an `Executor` interface that
    has only one `void execute(Runnable command)` method that executes the given command
    at some time in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'Its subinterface, `ExecutorService`, adds methods that allow you to manage
    the executor:'
  prefs: []
  type: TYPE_NORMAL
- en: The `invokeAny()`, `invokeAll()`, and `awaitTermination()` methods and `submit()` allow
    you to define how the threads will be executed and whether they are expected to
    return some values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `shutdown()` and `shutdownNow()` methods allow you to shut down the executor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `isShutdown()` and `isTerminated()` methods provide the status of the executor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The objects of `ExecutorService` can be created with the static factory methods
    of the `java.util.concurrent.Executors` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '`newSingleThreadExecutor()`: Creates an `Executor` method that uses a single
    worker thread operating off an unbounded queue. It has an overloaded version with
    `ThreadFactory` as a parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`newCachedThreadPool()`: Creates a thread pool that creates new threads as
    needed, but reuses previously constructed threads when they are available. It
    has an overloaded version with `ThreadFactory` as a parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`newFixedThreadPool(int nThreads)`: Creates a thread pool that reuses a fixed
    number of threads operating off a shared unbounded queue. It has an overloaded
    version with `ThreadFactory` as a parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `ThreadFactory` implementation allows you to override the process of creating
    new threads, enabling applications to use special thread subclasses, priorities,
    and so on. A demonstration of its usage is outside the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One important aspect of the behavior of the `Executor` interface you need to
    remember is that once created, it keeps running (waiting for new tasks to execute)
    until the Java process is stopped. So, if you would like to free memory, the `Executor` interface
    has to be stopped explicitly. If not shut down, forgotten executors will create
    a memory leak. Here is one possible way to make sure no executor is left behind:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'You can pass a worker (an implementation of either the `Runnable` or `Callable` functional
    interface) for execution to `ExecutorService` in a variety of ways, which we will
    see shortly. In this example, we executed two threads: one using the `execute()`
    method and another using the `submit()` method. Both methods accept `Runnable`
    or `Callable`, but we used only `Runnable` in this example. The `submit()` method returns
    `Future`, which represents the result of an asynchronous computation.'
  prefs: []
  type: TYPE_NORMAL
- en: The `shutdown()` method initiates an orderly shutdown of the previously submitted
    tasks and prevents any new tasks from being accepted. This method does not wait
    for the task to complete the execution. The `awaitTermination()` method does that.
    But after `shutdownDelaySec`, it stops blocking and the code flow gets into the `finally`
    block, where the `isTerminated()` method returns `true` if all the tasks are completed
    following the shutdown. In this example, we have two tasks executed in two different
    statements. But note that other methods of `ExecutorService` accept a collection
    of tasks.
  prefs: []
  type: TYPE_NORMAL
- en: In such a case, when the service is shutting down, we iterate over the collection
    of `Future` objects. We call each task and cancel it if it is not completed yet,
    possibly doing something else that had to be done before canceling the task. How
    much time to wait (the value of `shutdownDelaySec`) has to be tested for each
    application and the possible running tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the `shutdownNow()` method says that it
  prefs: []
  type: TYPE_NORMAL
- en: '"attempts to stop all actively executing tasks, halts the processing of waiting
    tasks, and returns a list of the tasks that were awaiting execution"'
  prefs: []
  type: TYPE_NORMAL
- en: (according to the Javadoc).
  prefs: []
  type: TYPE_NORMAL
- en: 'Collect and assess the results. In a real application, we typically do not
    want to shut down a service often. We just check the status of the tasks and collect
    the results of those that return true from the `isDone()` method. In the preceding
    code example, we just show how to make sure that when we do stop the service,
    we do it in a controlled manner, without leaving behind any runaway process. If
    we run that code example, we will get the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3db89b96-4315-4b22-8ddb-3690ff485551.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Generalize the preceding code and create a method that shuts down a service
    and the task that has returned `Future`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Enhance the example by making `Runnable` (using the lambda expression) sleep
    for some time (simulating useful work to be done):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Note the two parameters, `shutdownDelaySec` (defines how long the service will
    wait without allowing new tasks to be submitted before moving on and shutting
    itself down, eventually) and `threadSleepSec` (defines how long the worker is
    sleeping, indicating that the simulating process is doing its job).
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the new code for different implementations of `ExecutorService` and the `shutdownDelaySec` and `threadSleepSec` values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'This is how the output may look (it might be slightly different on your computer,
    depending on the exact timing of the events controlled by the operating system):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/37890a3f-7807-46ef-b5e7-a0ba414fc995.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Analyze the results. In the first example, we find no surprise because of the
    following line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: It is blocking for three seconds, whereas each worker works for one second only.
    So it is enough time for each worker to complete its work even for a single-thread
    executor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s make the service wait for one second only:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/43c2a4e6-d333-437c-a082-47aceb424a33.png)'
  prefs: []
  type: TYPE_IMG
- en: When you do this, you will notice that none of the tasks will be completed.
    In this case, worker `One` was interrupted (see the last line of the output),
    while task `Two` was canceled.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s make the service wait for three seconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6b9b8113-e7fe-442f-b0cf-e2fde29a1554.png)'
  prefs: []
  type: TYPE_IMG
- en: Now we see that worker `One` was able to complete its task, while worker `Two`
    was interrupted.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ExecutorService` interface produced by `newCachedThreadPool()` or `newFixedThreadPool()`
    performs similarly on a one-core computer. The only significant difference is
    that if the `shutdownDelaySec` value is equal to the `threadSleepSec` value, then
    they both allow you to complete the threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e2998059-be37-4833-83bc-be14f7c2ed44.png)'
  prefs: []
  type: TYPE_IMG
- en: This was the result of using `newCachedThreadPool()`. The output of the example
    using `newFixedThreadPool()` looks exactly the same on a one-core computer.
  prefs: []
  type: TYPE_NORMAL
- en: 'To have more control over the task, check the returned value of the `Future` object,
    not just submit a task and wait hoping it will be completed as needed. There is
    another method, called `submit()`, in the `ExecutorService` interface that allows
    you to not only return a `Future` object but also include the result that is passed
    to the method as a second parameter in the return object. Let''s check out an
    example of this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The value of `result` is `42`. This method can be helpful when you have submitted
    many workers (`nWorkers`) and need to know which one is completed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Well, the catch is that `future.get()` is a blocking method. This is why we
    use a version of the `get()` method that allows us to set the `delaySec` timeout.
    Otherwise, `get()` blocks the iteration.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s move a step closer to real-life code and create a class that implements
    `Callable` and allows you to return a result from a worker as an object of the `Result` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: An actual numeric result is returned by the `getResult()` method. Here, we also
    included the name of the worker and how long the thread is expected to sleep (to
    work) just for convenience and to better illustrate the output.
  prefs: []
  type: TYPE_NORMAL
- en: 'The worker itself is going to be an instance of the `CallableWorkerImpl` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the number `42` is an actual numeric result, which a worker supposedly
    calculated (while sleeping). The  `CallableWorkerImpl` class implemented the `CallableWorker` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: We had to make the methods default and return some data (they will be overridden
    by the class implementation anyway) to preserve its `functional interface` status.
    Otherwise, we would not be able to use it in lambda expressions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will also create a factory that will generate a list of workers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can use all these new classes and methods to demonstrate the `invokeAll()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'The `printResults()` method outputs the results received from the workers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'To get the results, again we use a version of the `get()` method with timeout
    settings. Run the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Its output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/19552493-b1f0-4f37-965a-adb41534e80e.png)'
  prefs: []
  type: TYPE_IMG
- en: It's probably worth mentioning that the three workers were created with sleep
    times of one, two, and three seconds, while the waiting time before the service
    shuts down is one second. This is why all the workers were canceled.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now if we set the waiting time to six seconds, the output of the single-thread
    executor will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/64677f6d-f5e8-40bc-9fa2-79fde02c30a8.png)'
  prefs: []
  type: TYPE_IMG
- en: Naturally, if we increase the waiting time again, all the workers will be able
    to complete their tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ExecutorService` interface produced by `newCachedThreadPool()` or `newFixedThreadPool()`
    performs much better even on a one-core computer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/368e2984-b863-4348-944f-43a6c747de12.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, all the threads were able to complete even with three seconds
    of waiting time.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an alternative, instead of setting a timeout during the service shutdown,
    you can possibly set it on the overloaded version of the `invokeAll()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'There is one particular aspect of the `invokeAll()` method''s behavior that
    often gets overlooked and causes surprises for first-time users: it returns only
    after all the tasks are complete (either normally or by throwing an exception). Read
    the Javadoc and experiment until you recognize that this behavior is acceptable
    for your application.'
  prefs: []
  type: TYPE_NORMAL
- en: By contrast, the `invokeAny()` method blocks only until at least one task is
  prefs: []
  type: TYPE_NORMAL
- en: '"completed successfully (without throwing an exception), if any do. Upon normal
    or exceptional return, tasks that have not completed are cancelled"'
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding quote is from the Javadoc ([https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ExecutorService.html](https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ExecutorService.html)).
    Here is an example of the code that does this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: You can experiment with it, setting different values for the waiting time (`shutdownDelaySec`)
    and sleep time for threads until you are comfortable with how this method behaves.
    As you can see, we have reused the `shutdownAndCancelTasks()` method by passing
    an empty list of `Future` objects since we do not have them here.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two more static factory methods in the `Executors` class that create
    instances of `ExecutorService`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`newWorkStealingPool()`: This creates a work-stealing thread pool using the
    number of available processors as its target parallelism level. It has an overloaded
    version with a parallelism level as a parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unconfigurableExecutorService(ExecutorService executor)`: This returns an
    object that delegates all the defined `ExecutorService` methods to the given executor,
    except for those methods that might otherwise be accessible using casts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Also, a sub-interface of the `ExecutorService` interface, called `ScheduledExecutorService`,
    enhances the API with the capability to schedule a thread execution in future
    and/or their periodic execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The objects of `ScheduledExecutorService` can be created using the static factory
    methods of the `java.util.concurrent.Executors` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '`newSingleThreadScheduledExecutor()`: Creates a single-threaded executor that
    can schedule commands to run after a given delay or to execute them periodically.
    It has an overloaded version with `ThreadFactory` as a parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`newScheduledThreadPool(int corePoolSize)`: Creates a thread pool that can
    schedule commands to run after a given delay or to execute them periodically.
    It has an overloaded version with `ThreadFactory` as a parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unconfigurableScheduledExecutorService( ScheduledExecutorService executor
    )`: Returns an object that delegates all the defined `ScheduledExecutorService`
    methods to the given executor, but not any other methods that might otherwise
    be accessible using casts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Executors` class also has several overloaded methods that accept, execute,
    and return `Callable` (which, in contrast with `Runnable`, contains the result).
  prefs: []
  type: TYPE_NORMAL
- en: 'The `java.util.concurrent` package also includes classes that implement `ExecutorService`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ThreadPoolExecutor`: This class executes each submitted task using one of
    the several pooled threads, normally configured using the `Executors` factory
    methods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ScheduledThreadPoolExecutor`: This class extends the `ThreadPoolExecutor`
    class and implements the `ScheduledExecutorService` interface.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ForkJoinPool`: It manages the execution of workers (the `ForkJoinTask` processes)
    using a work-stealing algorithm. We will discuss it in the next recipe.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instances of these classes can be created via class constructors that accept
    more parameters, including the queue that holds the results, for providing more
    refined thread-pool management.
  prefs: []
  type: TYPE_NORMAL
- en: Using fork/join to implement divide-and-conquer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will learn how to use the fork/join framework for the divide-and-conquer
    computation pattern.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned in the previous recipe, the `ForkJoinPool` class is an implementation
    of the `ExecutorService` interface that manages the execution of workers—the `ForkJoinTask`
    processes—using the work-stealing algorithm. It takes advantage of multiple processors,
    if available, and works best on tasks that can be broken down into smaller tasks
    recursively, which is also called a **divide-and-conquer** strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Each thread in the pool has a dedicated double-ended queue (deque) that stores
    tasks, and the thread picks up the next task (from the head of the queue) as soon
    as the current task is completed. When another thread finishes executing all the
    tasks in its queue, it can take a task (steal it) from the tail of a non-empty
    queue of another thread.
  prefs: []
  type: TYPE_NORMAL
- en: As with any `ExecutorService` implementation, the fork/join framework distributes
    tasks to worker threads in a thread pool. This framework is distinct because it
    uses a work-stealing algorithm. Worker threads that run out of tasks can steal
    tasks from other threads that are still busy.
  prefs: []
  type: TYPE_NORMAL
- en: Such a design balances the load and allows an efficient use of the resources.
  prefs: []
  type: TYPE_NORMAL
- en: For demonstrative purposes, we are going to use the API created in [Chapter
    3](1b2f25bd-aef0-4b6f-a9e7-144ee4f8d6e1.xhtml), *Modular Programming*, the `TrafficUnit`,
    `SpeedModel`, and `Vehicle` interfaces and the `TrafficUnitWrapper`, `FactoryTraffic`,
    `FactoryVehicle`, and `FactorySpeedModel` classes. We will also rely on the streams
    and stream pipelines described in [Chapter 3](1b2f25bd-aef0-4b6f-a9e7-144ee4f8d6e1.xhtml),
    *Modular Programming*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Just to refresh your memory, here is the `TrafficUnitWrapper` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'We will also slightly modify the existing API interface and make it a bit more
    compact by introducing a new `DateLocation` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: It will also allow you to hide the details and help you see the important aspects
    of this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All computations are encapsulated inside a subclass of one of the two subclasses
    (`RecursiveAction` or `RecursiveTask<T>`) of the abstract `ForkJoinTask` class.
    You can extend either `RecursiveAction` (and implement the `void compute()` method)
    or `RecursiveTask<T>` (and implement the `T compute()` method). As you may have
    noticed, you can choose to extend the `RecursiveAction` class for tasks that do
    not return any value, and extend `RecursiveTask<T>` when you need your tasks to
    return a value. In our demo, we are going to use the latter because it is slightly
    more complex.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say we would like to calculate the average speed of traffic in a certain
    location on a certain date and time and driving conditions (all these parameters
    are defined by the `DateLocation` property object). Other parameters will be as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`timeSec`: The number of seconds during which the vehicles have a chance to
    accelerate after stopping at the traffic light'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`trafficUnitsNumber`: The number of vehicles to include in the average speed
    calculation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Naturally, the more vehicles included in the calculations, the better the prediction.
    But as this number increases, the number of calculations increases too. This gives
    rise to the need to break down the number of vehicles into smaller groups and
    compute the average speed of each group in parallel with the others. Yet, there
    is a certain minimal number of calculations that is not worth splitting between
    two threads. Here''s what Javadoc ([https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ForkJoinTask.html](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ForkJoinTask.html))
    has to say about it:'
  prefs: []
  type: TYPE_NORMAL
- en: '"As a very rough rule of thumb, a task should perform more than 100 and less
    than 10000 basic computational steps, and should avoid indefinite looping. If
    tasks are too big, then parallelism cannot improve throughput. If too small, then
    memory and internal task maintenance overhead may overwhelm processing."'
  prefs: []
  type: TYPE_NORMAL
- en: Yet, as always, the determination of the optimal number of calculations without
    splitting them between parallel threads should be based on testing. This is why
    we recommend you pass it as a parameter. We will call this parameter `threshold`.
    Note that it also serves as a criterion for exiting from the recursion.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will call our class (task) `AverageSpeed` and extend `RecursiveTask<Double>`
    because we would like to have as a result of the average speed value of the `double`
    type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Before we finish writing the code for the `compute()` method, let''s write
    the code that will execute this task. There are several ways to do this. We can
    use `fork()` and `join()`, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: This technique provided the name for the framework. The `fork()` method, according
    to Javadoc,
  prefs: []
  type: TYPE_NORMAL
- en: '"arranges to asynchronously execute this task in the pool the current task
    is running in, if applicable, or using the `ForkJoinPool.commonPool()` if not
    in `ForkJoinPool()`."'
  prefs: []
  type: TYPE_NORMAL
- en: In our case, we have not used any pool yet, so `fork()` is going to use `ForkJoinPool.commonPool()`
    by default. It places the task in the queue of a thread in the pool. The `join()` method
    returns the result of the computation when it is done.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `createTask()` method contains the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: Note the values of the `trafficUnitsNumber` and `threshold` parameters. This
    will be important for analyzing the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another way to accomplish this is to use either the `execute()` or `submit()` method—each
    providing the same functionality—for the execution of the task. The result of
    the execution can be retrieved by the `join()` method (the same as in the previous
    example):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The last method we are going to review is `invoke()`, which is equivalent to
    calling the `fork()` method followed by the `join()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: Naturally, this is the most popular way to start the divide-and-conquer process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s get back to the `compute()` method and see how it can be implemented.
    First, let''s implement the `if` block (calculates the average speed of less than
    `threshold` vehicles). We will use the technique and code we described in [Chapter
    3](1b2f25bd-aef0-4b6f-a9e7-144ee4f8d6e1.xhtml), *Modular Programming*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: We get `trafficUnitsNumber` of the vehicles from `FactoryTraffic`. We create
    an object of `TrafficUnitWrapper` for each emitted element and call the `setSpeedModel()`
    method on it (by passing in the newly generated `SpeedModel` object, based on
    the emitted `TrafficUnit` object). Then we calculate the speed, get an average
    of all the speeds in the stream, and get the result as `double` from the `Optional`
    object (the return type of the `average()` operation). We then print out the result
    and round to get a more presentable format.
  prefs: []
  type: TYPE_NORMAL
- en: It is also possible to achieve the same result using a traditional `for` loop.
    But, as mentioned before, it seems that Java follows the general trend of a more
    fluent and stream-like style, geared toward processing a large amount of data.
    So, we recommend you get used to it.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 14](402d6438-f308-4ae7-b637-8e60a1215bc4.xhtml), *Testing*, you
    will see another version of the same functionality that allows better unit testing
    of each step in isolation, which again supports the view that unit testing, along
    with writing code, helps you make your code more testable and decreases the need
    to rewrite it later.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s review the options of the `else` block implementation. The first
    few lines are always going to be the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: We divide the `trafficUnitsNumber` number by 2 (we do not worry about possible
    loss of one unit in the case of an average across a big set) and create two tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following—the actual task execution code—can be written in several different
    ways. Here is the first possible solution, which is familiar to us already, that
    comes to mind:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'If we do this, we will see the same output (but with different speed values)
    three times:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/44998580-49bf-4d7f-8e32-13e1151df68b.png)'
  prefs: []
  type: TYPE_IMG
- en: You see how the original task of calculating average speed over 1,001 units
    (vehicles) was first divided by 2 several times until the number of one group
    (62) fell under the threshold of 100\. Then, an average speed of the last two
    groups was calculated and combined (joined) with the results of other groups.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another way to implement an `else` block of the `compute()` method could be
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s how the result will look:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/12e0f057-8665-4758-88df-ab8166d67dfd.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see how, in this case, the `compute()` method (of the second task) was
    called recursively many times until it reached the threshold by the number of
    elements, then its results were joined with the results of the call to the `fork()`
    and `join()` methods of the first task.
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned before, all this complexity can be replaced by a call to the `invoke()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'It produces a result similar to the one produced by calling `fork()` and `join()`
    on each of the tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5b63f37b-25bb-4baf-aa17-144ac7bc60a2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Yet, there is an even better way to implement an `else` block of the `compute()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'If this looks complex to you, just note that it is just a stream-like way to
    iterate over the results of `invokeAll()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'It is also to iterate over the results of calling `join()` on each of the returned
    tasks (and combining the results into average). The advantage is that we yield
    to the framework to decide how to optimize the load distribution. The result is
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5cd22de5-19dd-45f9-a868-186d9770a80b.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see that it differs from any of the preceding results and can change
    depending on the availability and load of the CPUs on your computer.
  prefs: []
  type: TYPE_NORMAL
- en: Using flow to implement the publish-subscribe pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will learn about the new publish-subscribe capability introduced
    in Java 9.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Among many other features, Java 9 introduced these four interfaces in the `java.util.concurrent.Flow` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: With this, Java stepped into the world of reactive programming—programming with
    the asynchronous processing of data streams.
  prefs: []
  type: TYPE_NORMAL
- en: We discussed streams in [Chapter 3](1b2f25bd-aef0-4b6f-a9e7-144ee4f8d6e1.xhtml),
    *Modular Programming,* and pointed out that they are not data structures, as they
    do not keep data in memory. The stream pipeline does nothing until an element
    is emitted. Such a model allows minimal resource-allocation and uses resources
    only as needed. The application behaves *in response* to the appearance of the
    data it reacts to, thus the name.
  prefs: []
  type: TYPE_NORMAL
- en: In a publish-subscribe pattern, the main two actors are `Publisher`, which streams
    data (publishes), and `Subscriber`, which listens to data (subscribes).
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Flow.Publisher<T>` interface is a functional interface. It only has one
    abstract method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: According to the Javadoc ([https://docs.oracle.com/javase/10/docs/api/java/util/concurrent/SubmissionPublisher.html](https://docs.oracle.com/javase/10/docs/api/java/util/concurrent/SubmissionPublisher.html)),
    this method,
  prefs: []
  type: TYPE_NORMAL
- en: '"adds the given `Flow.Subscriber<T>` if possible. If already subscribed, or
    the attempt to subscribe fails, the `onError()` method of `Flow.Subscriber<T>`
    is invoked with an `IllegalStateException`. Otherwise, the `onSubscribe()` method
    of `Flow.Subscriber<T>` is invoked with a new `Flow.Subscription.` Subscribers
    may enable receiving items by invoking the `request()` method of this `Flow.Subscription`
    and may unsubscribe by invoking its `cancel()` method."'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Flow.Subscriber<T>` interface has four methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`void onSubscribe(Flow.Subscription subscription)`: Invoked prior to invoking
    any other `Subscriber` methods for the given `Subscription`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`void onError(Throwable throwable)`: Invoked upon an unrecoverable error encountered
    by a `Publisher` or `Subscription`, after which no other `Subscriber` methods
    are invoked by `Subscription`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`void onNext(T item)`: Invoked with the next item of `Subscription`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`void onComplete()`: Invoked when it is known that no additional `Subscriber`
    method invocations will occur for `Subscription`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `Flow.Subscription` interface has two methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`void cancel()`: Causes `Subscriber` to (eventually) stop receiving messages'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`void request(long n)`: Adds the given *n* number of items to the current unfulfilled
    demand for this subscription'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Flow.Processor<T,R>` interface is outside the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To save some time and space, instead of creating our own implementation of
    the `Flow.Publisher<T>` interface, we can use the `SubmissionPublisher<T>` class from
    the `java.util.concurrent` package. But, we will create our own implementation
    of the `Flow.Subscriber<T>` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'We will also implement the `Flow.Subscription` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we just followed Javadoc recommendations and expect the `onSubscribe()`
    method of a subscriber to be called when the subscriber is added to a publisher.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another detail to note is that the `SubmissionPublisher<T>` class has the `submit(T
    item)` method that, according to Javadoc ([https://docs.oracle.com/javase/10/docs/api/java/util/concurrent/SubmissionPublisher.html](https://docs.oracle.com/javase/10/docs/api/java/util/concurrent/SubmissionPublisher.html)):'
  prefs: []
  type: TYPE_NORMAL
- en: '"publishes the given item to each current subscriber by asynchronously invoking
    its `onNext()` method, blocking uninterruptibly while resources for any subscriber
    are unavailable."'
  prefs: []
  type: TYPE_NORMAL
- en: This way, the `SubmissionPublisher<T>` class submits items to the current subscribers
    until it is closed. This allows item generators to act as reactive-streams publishers.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate this, let''s create several subscribers and subscriptions using
    the `demoSubscribe()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'Then use them in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code creates three subscribers, connected to the same publisher
    with a dedicated subscription. The last line generates a stream of numbers, 1,
    2, 3, and 4, and submits each of them to the publisher. We expect that every subscriber
    will get each of the generated numbers as the parameter of the `onNext()` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `finally` block, we included the code you are already familiar with
    from the previous recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run the preceding code, the output may look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a9ef8e7a-c418-44c6-a0bc-2aa9a68eb56f.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, because of asynchronous processing, the control gets to the
    `finally` block very quickly and waits one second before shutting down the service.
    This period of waiting is enough for the items to be generated and passed to the
    subscribers. We also confirmed that every generated item was sent to each of the
    subscribers. The three `null` values were generated every time the `onSubscribe()`
    method of each of the subscribers was called.
  prefs: []
  type: TYPE_NORMAL
- en: It is reasonable to expect that, in future Java releases, there will be more
    support added for reactive (asynchronous and non-blocking) functionality.
  prefs: []
  type: TYPE_NORMAL
