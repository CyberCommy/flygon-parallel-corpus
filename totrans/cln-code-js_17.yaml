- en: The Landscape of Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the beginning of this book, we set out the primary tenets of clean code.
    Among these was reliability. There truly is no greater way to confirm reliability
    than to expose your code base to continued and multivariate usage. This means
    having real users sit in front of your software and use it, for real. Only via
    this type of exposure can we understand whether our code truly fulfills its purpose.
    However, it is usually unreasonable, and possibly even dangerous, to conduct such
    real-life tests constantly. If code is changed, it is possible for a piece of
    functionality that a user relies on to falter or regress. To prevent such cases,
    and to generally confirm that our expectations are met, we write tests. Without
    a good suite of tests, we are passively and arrogantly closing our eyes and hoping
    that nothing goes wrong.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll be covering the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is a test?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Types of testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test-Driven Development** (**TDD**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is a test?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A software test is an automated procedure that makes assertions about a piece
    of code and then reports the success of those assertions back to you. A test may
    make assertions about anything from an individual function to the behavior of
    an entire feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'Tests, much like the rest of our code, deal in layers of abstraction and granularity.
    If we were to test a car abstractly, we may simply seek to assert the following
    attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: It has four wheels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It has a steering wheel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It drives
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It has a working horn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Obviously, this is not a very useful set of assertions for car engineers, as
    these attributes are either incredibly obvious or insufficiently described. The
    assertion It drives is important, but without extra detail, all it expresses is
    a generic business-oriented objective. It's similar to a project manager asking
    for a software engineer to ensure that a user-login portal, for example, can allow
    users to log in successfully. It is the engineer's job to not only implement the
    user-login portal but to derive working tests that successfully investigate the
    truth of the assertion users can log in successfully. And it is not always easy
    to derive good tests from generic statements.
  prefs: []
  type: TYPE_NORMAL
- en: 'To correctly engineer a test, we must take the generic and abstract requirements
    and distill them to their granular and unabstracted details. In the case of us
    asserting that our car *has a working horn*, for example, we can distill it like
    so:'
  prefs: []
  type: TYPE_NORMAL
- en: When the driver raises at least one hand and directs the hand to depress by
    2 cm the center of the steering wheel for a period of 1 second, a loud sound of
    fixed frequency at 400 Hz will be emitted by the car at approximately 107 decibels
    for 1 second.
  prefs: []
  type: TYPE_NORMAL
- en: When we start to add crucial detail to our assertions, they become useful to
    us. We can use them as both guides of implementation and confirmations of functionality.
    Even with this added detail though, our statement is only an assertion or a *requirement*.
    Such requirements are a useful step in the design of software. In fact, we should
    be very reluctant to even begin implementing software until we have such levels
    of specificity.
  prefs: []
  type: TYPE_NORMAL
- en: 'If a client were to ask you to implement a payment form, for example, it would
    be wise to gather the exact requirements: what types of payments shall it accept?
    What other customer information requires collection? What regulations or constraints
    are we beholden to in our storage of this data? These expanded requirements then
    become the yardstick via which we, and the client, will measure completeness.
    It follows naturally that we can then implement these requirements as individual
    tests to confirm their existence in the software.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A good testing methodology will involve tests for all distinct parts of a code
    base and will provide the following benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Prove fulfillment**: Tests allow us to prove to ourselves and our stakeholders
    that expectations and requirements are fulfilled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Have** **confidence**: Tests allow us and our colleagues to have confidence
    in our code base—both that it works correctly and that it can accommodate changes
    without faults arising unbeknownst to us.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Share** **knowledge**: Tests allow us to share vital knowledge about how
    parts of our code operate together. In a sense, they are a form of documentation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many second-order effects of a good testing methodology as well. The
    increased confidence in the code base by your colleagues will mean you can be
    more productive and make more significant changes more quickly, cutting costs
    and pain in the long run. The sharing of knowledge can enable both your colleagues
    and your users to perform their actions quicker, with more understanding and less
    overhead in time and expense. The ability to prove fulfillment enables teams and
    individuals to better communicate the value of their work to stakeholders, managers,
    and users.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've discussed the obvious benefits of tests, we can discuss how we
    should go about authoring them. At the core of every test is a set of assertions,
    so we'll now explore what we mean by assertion and how we can use assertions to
    encode our expectations.
  prefs: []
  type: TYPE_NORMAL
- en: The simple assertion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many tools, terms, and paradigms of testing. The existence of so much
    complexity can seem intimidating but it's important to remember that, at the core,
    testing is really just about making assertions about how something works.
  prefs: []
  type: TYPE_NORMAL
- en: 'Assertions can be made programmatically by expressing either `SUCCESS` or `FAILURE` depending
    on a specific outcome, as in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we will receive a our `FAILURE!` log if our `sum` function is not giving
    the expected output. We can abstract this pattern of success and failure by implementing
    an `assert` function, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This can then be used to make a series of assertions with added descriptions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the fundamental core of any testing framework or library. They all
    have a mechanism for making assertions and reporting both the success and failure
    of those assertions. It is also normal for testing libraries to provide a mechanism
    to wrap up or contain related assertions and, together, call them a *test* or
    *test case*. We can do something similar by providing a test function that allows
    you to pass a description and a function (to contain assertions):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then use it like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The produced testing log from running this would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: From a technical perspective, the pure action of authoring assertions and simple
    tests is not too challenging. Writing a test for a singular function is rarely
    hard. However, to write entire test suites and to thoroughly test all parts of
    a code base, we must utilize several more complicated testing mechanisms and methodologies
    to help us out.
  prefs: []
  type: TYPE_NORMAL
- en: Many moving parts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To recall the car analogy, let's imagine that we have a car sitting in front
    of us, and we wish to test its horn. The horn is not a standalone piece of machinery.
    It is embedded within the car and dependent on a power source separate to itself.
    In fact, what we may discover is that we must first start the car up via the ignition
    before the horn will work. And the success of an ignition is itself dependent
    upon several other components, including a working ignition switch, fuel in the
    tank, a working fuel filter, and a non-drained battery. The functionality of the
    horn is therefore dependent upon a series of many moving parts. So, our test of
    the horn becomes not only a test of the horn itself but effectively a test of
    almost the entire car! This is not ideal.
  prefs: []
  type: TYPE_NORMAL
- en: To get around this issue, we could hook the horn up to a separate power supply
    just for testing purposes. By doing this, we are isolating the horn, enabling
    the test to only reflect the functionality of the horn itself. In the testing
    world, this **stand-in** power supply we're using might be called a **stub** or
    a **mock**.
  prefs: []
  type: TYPE_NORMAL
- en: In the software world, both *stubs* and *mocks* are a type of stand-in abstraction
    for the *real* abstraction that provides appropriate outputs without carrying
    out the real work of the replaced abstraction. An example would be a `makeCreditCardPayment`
    stub, which returns `SUCCESS` without creating a real-world payment. This would
    be used in the context of testing e-commerce functionality, possibly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our approach of isolating the power supply of the horn is unfortunately flawed.
    Even if our test is successful—and the horn works—we haven''t guaranteed that
    the horn will still work when hooked up to the real power supply within the car.
    The isolated test of the horn is still, arguably, useful because it tells us about
    any failures within the horn''s specific circuitry and mechanism, but it is not
    sufficient on its own. We need to test how the horn will work when it is embedded
    in the real-life situation of having to depend on other components. In software,
    we call such real-life tests **integration tests** or **end-to-end tests**, while
    the isolated tests are typically called **unit tests**. An effective testing methodology
    will always include both types:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/7daaa2d6-8926-4891-9f93-731f9ee697fd.png)'
  prefs: []
  type: TYPE_IMG
- en: There is a risk when isolating individuals parts for testing, of creating an
    unrealistic scenario in which you end up not actually testing the true functionality
    of a code base, but instead testing the efficacy of your mocks. Here, in our car
    analogy, isolating the horn by supplying it with a *mock* power supply enables
    us to purely test the horn's circuitry and sound-making mechanism and gives us
    a clear path to debugging issues if the test fails. But we need to complement
    this test with several integration tests so that we can be confident that the
    entire system works correctly. Even if we have a thousand unit tests for all parts
    of a system, there is no guarantee of a working system without testing the integration
    of all of these parts.
  prefs: []
  type: TYPE_NORMAL
- en: Types of testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To ensure a thoroughly tested code base, we must engage in different types of
    testing. As touched on already, the *unit* test enables us to test isolated parts,
    while the various combinations of parts can be tested via either **integration**,
    **functional**, or **E2E** tests. It's useful first to understand what we mean
    when we talk about a *part* or a *unit*.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we talk about a unit of code, there is admittedly a fuzziness to the concept.
    Typically, it will be a piece of code that has a singular responsibility within
    a system. When a user wishes to perform an action via our software, they will,
    in fact, be activating a series of parts of our code, all working together to
    give the user the output they desire. Consider an app in which users can create
    and share images. A typical user experience (a flow or journey) may involve a
    few distinct steps that all involve different parts of the code base. Every action
    the *User* performs, often without them knowing, will encapsulate a series of
    code actions:'
  prefs: []
  type: TYPE_NORMAL
- en: '(User) Create a new image by uploading a photo stored on the desktop:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (Code) Upload the photo via `<form>`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (Code) Save photo to a CDN
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (Code) Show the bitmap within `<canvas>` so that filters can be applied
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(User) Apply a filter to the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (Code) Apply the filter via `<canvas>` pixel manipulation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (Code) Update image stored on the CDN
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (Code) Re-download saved image
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(User) Share the image with friends:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (Code) Find the user's *friends* in the database
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (Code) Add the image to each friend's feed
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (Code) Send the *push notification* to all friends
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Together, all of these steps, combined with all other steps a user could potentially
    take, can be considered a system. And a fully-tested system might involve **unit**
    tests for each individual step, **integration** tests for each pair of steps,
    and **functional** or **End-to-End** (**E2E**) tests for every combination of
    steps that together form a *user flow* or *user journey*. We can visualize the
    types of tests that may need to exist as part of a system as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/132ddbe3-92d9-4e98-b072-55279e538f7d.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, we can see one **Start** point and two **End** points, indicating two
    distinct *user journeys*. Each dot can be thought of as a single area of responsibility
    or *unit* that is activated as part of these journeys. As you can see, a unit
    test is only concerned with a single area of responsibility. The integration test
    is concerned with two (or more) neighboring areas that integrate. And an E2E or
    functional test is concerned with all of the areas involved in a singular user
    journey. In the former example of our image-sharing app, we can imagine that we
    may have specific unit tests for actions such as uploading a photo to the CDN or
    sending push notifications, an integration test that tests the integration of
    the friends database, and an E2E test that tests the entire flow from creating
    to sharing a new image. Each of these testing methodologies would be vital in
    ensuring a truly well-tested system, and each has its own unique benefits as well
    as pitfalls and challenges to overcome.
  prefs: []
  type: TYPE_NORMAL
- en: Unit testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we described with our car analogy, a unit test is a test that deals with
    an isolated *unit* of code. This will usually be either a singular function or
    module that will make one or more simple assertions about the operation of the
    code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some examples of singular unit test scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: You have a `Button` component that should contain the value `Submit My Data` and
    should have a class of `btn_success`. You can assert these characteristics via
    a simple unit test that checks the attributes of the produced DOM element.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You have a task-scheduling utility that will perform a given action at the requested
    time. You can assert that it does so by giving it a task to perform at a specific
    time and then checking for the successful execution of that task.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You have a REST API endpoint of `/todo/list/item/{ID}` that retrieves a specific
    item from a database. You can assert that the route works correctly by mocking
    the database abstraction (providing fake data) and then asserting that requesting
    the URL returns your data correctly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are several benefits of testing individually-isolated units of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Completeness**: A given unit will typically have a small number of clearly
    defined requirements. As such, it''s easy to ensure that you''re testing the full
    gamut of a unit''s functionality. All input variations can be tested quite easily.
    The very limits of each unit can also be tested, including the often complex minutiae
    of how something operates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reportability:** When a given unit test fails, you can quite easily discern
    the exact nature and circumstance of the failure, meaning quicker debugging and
    fixing of the underlying problem. This is in contrast to integration tests, which,
    as we will discover, may have far more generic reporting that doesn''t indicate
    the exact point of failure in the code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Comprehension:** Unit tests are a useful and self-contained form of documentation
    for given modules or functions. The narrowness and specificity of unit tests help
    us to fully understand how something works, easing maintainability. This is especially
    useful when there isn''t up-to-date documentation elsewhere.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Completeness* here is similar to the popular concept of *test covera**ge*.
    The crucial difference is that while coverage is about maximizing the amount of
    code within a code base that is tested, completeness is about maximizing the coverage
    of each individual unit, so that the entire input space of the unit is expressed.
    Test coverage, as a metric, only tells us whether things are tested, not whether
    they''re well-tested.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are, however, challenges that come unit-testing as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mocking correctly**: Creating properly isolated unit tests sometimes means
    we have to constructs mocks or stubs of other units, as discussed in our former
    car analogy. It''s sometimes challenging to create realistic mocks and to ensure
    that you''re not introducing new areas of complexity and potential failures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Testing realistic inputs**: Writing unit tests that provide a wide variety
    of realistic inputs is key although it can be challenging. It''s quite easy to
    fall into a trap of writing tests that appear to give confidence but in fact don''t
    test the kinds of situations that would arise when the code is in production.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Testing true units and not combinations**: If not carefully constructed,
    unit tests can begin to bloat and become integration tests. Sometimes, a test
    can seem very simple on the surface but in fact depends on a series of integrations
    beneath the surface. To re-use our car analogy, an example of this would be if
    we were to attempt to make a simple unit test asserting the sound of the car horn
    without first isolating its circuitry. We''d unknowingly be creating an E2E test.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The unit test, as the most granular type of test, is vital to any code base.
    It is perhaps easiest to think of it as a type of double-entry bookkeeping system.
    When you make a change, you must reflect that change via an assertion. This implementation-then-testing
    cycle is best done in proximity—one after the other—perhaps via TDD, which will
    be discussed later. The unit test is your way of confirming to yourself that you
    truly wrote the code you intended to write. It provides a level of certainty and
    reliability that your team and stakeholders will be hugely grateful for.
  prefs: []
  type: TYPE_NORMAL
- en: Integration testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Integration testing, as the name suggests, deals with integrations of distinct
    *units *of code. An integration test will provide a more useful signal about how
    your software will operate in production than simple unit tests. In our car analogy,
    an integration test might assert the functionality of the horn, based on how it
    operates with the car's own power supply, instead of providing a mock power supply.
    It may however still be a partially isolated test, ensuring it does not involve
    all components within the car.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a couple of examples of possible integration tests:'
  prefs: []
  type: TYPE_NORMAL
- en: You have a `Button` component that should add an item to a list when clicked.
    A possible integration test would be to render the component in the real DOM and
    check that a simulated `click` event correctly adds the item to the list. This
    tests the integration between the `Button` component, the DOM, and the logic that
    determines when items are added to the list.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You have a REST API route of `/users/get/{ID}`, which should return user profile
    data from the database. A possible integration test would be to create a genuine
    database entry with ID of `456` and then request that data back via `/users/get/456`.
    This tests the integration between the HTTP routing abstraction and the database
    layer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are quite a few advantages of integrating modules and testing their behavior
    together:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Get better coverage**: Integration tests have one or more integrated modules
    as their test subject, and so by having such tests, we can increase our ''test
    coverage'' throughout our code base, meaning we are increasing the amount of our
    code that is exposed to tests and therefore increasing the likelihood that we''ll
    be able to catch faults.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clearly see faults**: Emulating, at least in part, the integration of modules
    that we would see in production enables us to see real integration faults and
    failures as they may naturally occur. A clear view of these faults enables us
    to iterate with fixes quickly and retain a reliable system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Expose bad expectations**: Integration tests allow us to challenge the assumptions
    we may have made when building individual units of code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So,while unit tests give us a narrow and detailed view of the input and output
    of specific modules and functions, integration tests allow us to see how all of
    these modules work together and, by doing so, provide us with a view into potential
    problems of integration. This is incredibly useful, but there are traps and challenges
    to writing integration tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Isolating integrations** (avoiding big bang tests): When implementing integration
    tests, it is sometimes easier to avoid isolating individual integrations and instead
    just test a large part of the system with all of its integrations intact. This
    is more akin to an E2E test and is certainly useful, but it''s important to also
    have isolated integrations so you can get granular insight into potential failures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Realistic integrations** (for example, database server and client): When
    picking and isolating integrations to test, it is sometimes difficult to create
    realistic circumstances. An example would be testing how your REST API integrates
    with your database server but instead of having a separate database server for
    testing purposes, you just have a local one. This is still an insightful test
    but because it does not emulate the remoteness of the database server (that would
    exist in production) you may get a false sense of confidence. There may be failures
    lurking, undetected.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The integration test provides vital insight at the crucial points of interfacing
    and I/O that govern how all of the individual parts of a code base work together
    as a system. Integration tests often provide the most signal about potential faults
    in a system, as they are both usually quick to run and highly transparent upon
    failures (unlike potentially clunky E2E tests). Naturally, integration tests can
    only tell you things about the points of integrations they encapsulate. For more
    complete confidence in the functionality of a system, it's always a good idea
    to employ E2E testing.
  prefs: []
  type: TYPE_NORMAL
- en: E2E and functional testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: E2E testing is a more extreme form of integration test where, instead of testing
    individual integrations between modules, we'll test the entire system, usually
    by executing a series of actions that would happen in reality to produce a given
    result. These tests are sometimes also called **functional tests** because they
    are interested in testing areas of functionality from the user's perspective.
    Well-constructed E2E tests give us confidence that our entire system is working
    correctly, but are most valuable when combined with more granular unit and integration
    tests so that faults can be more quickly and precisely identified.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a quick lowdown of the benefits of writing E2E tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Correctness and health**: E2E tests give you a clear insight into the general
    health of a system. Since many individual parts will effectively be tested via
    the typical E2E test, its success can give you a good indication that things are
    okay in production. Granular unit or integration tests, while very useful in their
    own way, don''t give you this kind of systemic insight.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Realistic effects**: Via E2E tests we can tryout more realistic circumstances,
    emulating the way our code will run in the wild. By emulating the flow of a typical
    user, an E2E test can highlight potential issues that more granular unit or integration
    tests might not reveal. An example of this would be when there are race conditions
    or other timing issues that can only be revealed when a code base is made to run
    as one consolidated system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**More holistic view**: E2E tests give developers a holistic view of a system,
    enabling them to reason more accurately about how distinct modules work together
    to produce a working user flow. This can be incredibly valuable when trying to
    build a full understanding of how a system operates. Much like both unit and integration
    tests, E2E tests can serve as a form of documentation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are challenges involved in crafting E2E tests, however:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Performance and time costs**: E2E tests, because they involve the activation
    of many individual pieces of code immersed in realistic environments, can be quite
    expensive in terms of time and hardware resources. The time that E2E tests take
    to run can impede development, and so it''s not rare for teams to avoid E2E tests
    for fear of a slowed development cycle.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Realistic steps**: Accurately emulating real-life circumstances in an E2E
    test can be a challenge. Using fake or made-up situations and data can still provide
    a realistic enough test but can also provide you a false sense of confidence.
    Since E2E tests are scripted, it''s quite common to not only rely on fake data
    but to have actions conducted in an unrealistically fast or direct manner, missing
    out on possible insights you could gain by creating more human circumstances (repeat
    after me: *always think of the user*).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Complex tooling**: The point of an E2E test is to realistically emulate a
    user flow as it would exist in the wild. To accomplish this, we need good tooling
    that enables us to set up realistic environments (for example, headless and scriptable
    browser instances). Such tooling can be buggy or complicated to use and can introduce
    yet another variable to the testing process that can result in unrealistic failures
    (tools can give you false signals about whether things are really working).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: E2E testing, although challenging to get right, can provide a level of insight
    and confidence that is hard to get from only unit and integration tests. In terms
    of automated testing procedures, E2E testing is the closest we can reasonably
    get to getting our software in front of real users. It is the least granular and
    most systemic way of discerning whether our software works in the way our users
    expect it to, which, after all, is what we're most interested in.
  prefs: []
  type: TYPE_NORMAL
- en: Test-Driven Development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TDD is a paradigm in which we write tests before implementation. In doing so,
    our tests end up informing and affecting the design of our implementation and
    its interface. By doing this, we begin to see tests as not only a form of documentation
    but a form of specification. Via our tests, we can designate how we wish something
    to work, writing assertions as if the functionality existed, and then we can iteratively
    build out the implementation such that all of our tests eventually pass.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate TDD, let''s imagine that we wish to implement a word-counting
    function. Before implementing it, we can begin to write some assertions about
    how we wish for it to work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a rather simple function and so we''ve been able to express most of
    its functionality in just three assertions. There are naturally other edge cases
    but we''ve pieced together enough expectations that we can begin to implement
    the function. Here is our first attempt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Immediately running this implementation via our small test suite, we receive
    the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Hyphenated words` test is failing. TDD, by its nature, expects iterative
    failure and refactor to bring an implementation inline with a test suite. Given
    this particular failure, we can simply add a hyphen to our regular expression''s
    character class (between the `[...]` delimiters):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces the following test logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Success! Via incremental iteration, although simplified for the sake of illustration,
    we have implemented something via TDD.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you may have observed, TDD is not a particular type or style of test, but
    rather it is a paradigm for *when*, *how*, and *why* we go about testing. The
    traditional view of testing as an afterthought is limited and often can force
    us into a position where we simply don''t have time to write a good test suite.
    TDD, however, forces us to lead with a solid test suite, giving us a few notable
    benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: It guides implementation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It prioritizes the user
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It forces complete test coverage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It forces single responsibility
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It enables quick problem domain discovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It gives you immediate feedback
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TDD is an especially useful paradigm when getting started with testing as it
    will force you to take a step back before implementing something and really consider
    what you're trying to do. This planning stage is really helpful in ensuring that
    our code fully aligns with user expectations.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced the concept of testing and how it relates to
    software. While brief and introductory, these foundational concepts are crucial
    if we're going to approach testing with an aim toward reliability and maintainability.
    Testing, like many other concerns in the software world, can be liable to cargo
    culting, so it's crucial to retain a perspective on the fundamentals and the theory
    behind the tests we write. Testing, at its core, is about proving expectations
    and protecting against faults. We've covered the differences between unit, integration,
    and E2E tests, discussing both the advantages and challenges inherent in each.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll look into how we can take this knowledge and apply
    it to crafting clean tests alongside real-life examples. Specifically, we will
    cover what measures and guiding principles we can use to ensure that our tests
    and the assertions within them are reliable, intuitive, and maximally useful.
  prefs: []
  type: TYPE_NORMAL
