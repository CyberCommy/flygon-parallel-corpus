- en: '*Chapter 4*'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing JavaScript
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Learning Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will be able to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Analyze the benefit of tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explain the various forms of code testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build code-testing environments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement tests for your JavaScript code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter will cover the concepts of testing, test frameworks, and how to
    work with the different ways to effectively testing code.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the first chapter, we covered many of the new and powerful features released
    in ES6\. We discussed the evolution of JavaScript and highlighted the key additions
    in ES6\. We discussed scope rules, variable declaration, arrow functions, template
    literals, enhanced object properties, destructuring assignment, classes and modules,
    transpiling, and iterators and generators. In the second chapter, we covered JavaScript's
    asynchronous programming paradigm. We discussed the JavaScript event loop, callbacks,
    promises, and the async/await syntax. In the third chapter, we learned about the
    Document Object Model (DOM), the JavaScript Event object, and the jQuery library.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will learn about testing code and code-testing frameworks
    in JavaScript. In the first topic, we will introduce testing and discuss test-driven
    development. Then, we will discuss applying test-driven development and several
    different ways you can test your code and applications. In the final topic, we
    will discuss several JavaScript code-testing frameworks that you can use to build
    powerful tests for your code.
  prefs: []
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Testing code is a lot like going to the gym. You know it is good for you. All
    of the arguments make sense, but getting up and starting down the road to fitness
    is difficult. The initial rush feels amazing; however, it is closely followed
    by sore muscles and you begin to wonder if it was really worth it. You take an
    hour or more out of your day but all you have to show for it is sore arms and
    legs. But, after a few weeks, it gets easier. You start to notice the benefits
    of working out.
  prefs: []
  type: TYPE_NORMAL
- en: Much like going to the gym, you have probably heard how important testing code
    can be. Writing tests is an integral part of writing good and sustainable code.
    It can be difficult when you first start writing tests. Writing your first tests
    and having them run successfully brings a thrill or rush, but after a day or two
    of taking an hour out of your work day to write tests, you begin to wonder if
    it is really worth it. But you stick with it. After several weeks, it becomes
    less tedious and you begin to notice the small benefits testing your code brings.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will discuss the reasons to test code, the types of tests
    you may need to implement, and some JavaScript frameworks you may use to implement
    and run your tests.
  prefs: []
  type: TYPE_NORMAL
- en: Reasons to Test Code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are many reasons to test your code. These reasons include program correctness,
    agile development, code quality, bug catching, legal liability, gratification,
    and many more. We will briefly discuss each of the listed reasons and explain
    their benefits.
  prefs: []
  type: TYPE_NORMAL
- en: '**Correctness**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The simplest and most important reason to test code is that testing code checks
    for code correctness. Intelligently written tests will test all the logic in your
    code against predetermined input values and their corresponding output values.
    By comparing the program's output with the expected output, we can verify that
    code works as expected, catching semantic or syntactic errors before they are
    integrated into code.
  prefs: []
  type: TYPE_NORMAL
- en: '**Agile Development**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Testing code makes the development process more agile. The **Agile Development
    Cycle** is one of the most popular and hottest development styles, and is being
    adopted by software companies including Lockheed Martin, Snapchat, and Google.
    Agile development relies on short duration goals. Changing old and tested code
    is a very slow process. If any old code needs to be refactored or needs to have
    features added or removed, we would need to go through the entire process of testing
    it again. With written code tests, we can automate them, and expedite the testing
    process, and save hours of time over doing manual tests. This could be the difference
    between meeting our Agile sprint goals and missing a deadline.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note:'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The Agile Development Cycle focuses on short sprints to design, implement, and
    release new features. These sprints are usually two or three weeks in length.
    This short and speedy development strategy allows you to build a large product
    in smaller parts and manage potentially changing requirements.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bug Catching**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Testing code will allow you to find bugs earlier in the development cycle. Tests
    should be performed before integration into a product or module. This means that
    any bugs found by the tests will be found and fixed before they are integrated
    into a product. Debugging a module that has already been fully integrated into
    an application is much more difficult than debugging a module that is still in
    development. Writing and running tests before integration will allow you to find
    and fix these bugs before they interact with other code, saving large amounts
    of time. Catching errors before integration and pushing correct working code is
    one of the most important skills a developer can have, and code testing can greatly
    improve this skill.
  prefs: []
  type: TYPE_NORMAL
- en: '**Code Quality**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code tests increase the quality of written code. When writing code with tests,
    we must design and implement our code explicitly with these tests in mind. Writing
    good tests helps us to think more completely about the problem we are trying to
    solve and the way we are going to go about solving the problem; we must consider
    things such as edge cases and design a good implementation that meets the test's
    requirements. Writing tests will help you better understand the design and implementation
    of your code, which will result in higher quality and better thought out code.
  prefs: []
  type: TYPE_NORMAL
- en: '**Legal Liability**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Writing tests can help prevent and mitigate legal liability. In many jurisdictions
    and market areas, vendors are required to ensure or prove that the provided software
    is of marketable quality. A documented test process has the potential to limit
    your legal liability in some cases. This may prevent you from being sued for a
    software bug. In the worst of cases, a well-documented testing process can also
    be provided to prove that the software bug involved in litigation did not arise
    through malpractice. This could reduce your punitive damages or personal responsibility.
  prefs: []
  type: TYPE_NORMAL
- en: '**Gratification**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The final reason to test code is often overlooked by most people. Testing code
    can be very gratifying. Tests can give you instant visual feedback about the correctness
    of your code. Seeing green check marks across the board is very satisfying. Releasing
    code that you know is well written and well tested, and will perform flawlessly,
    is very satisfying. Knowing your code is well tested can help you be confident
    about the release when the deadline comes up.
  prefs: []
  type: TYPE_NORMAL
- en: Test-driven Development
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Test-driven development** (**TDD**) is a form of software development focused
    around writing tests before implementing code. It is generally an Agile cycle
    and is one of the simplest ways to integrate tests into your code. TDD is a software
    development process that is built around a short and simple development cycle.
    In its most basic form, the cycle consists of adding a test that defines how the
    new function should work, and then writing code until the test''s requirements
    are met. This cycle is repeated until all functionality has been added.'
  prefs: []
  type: TYPE_NORMAL
- en: Test-driven development requires that the automated tests are created by the
    developer. These tests should well define the code's requirements and should be
    defined before any code is written. The tests should cover all expected or potential
    use cases, especially edge cases. The passing of the tests will inform the developer
    when development is complete.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note:'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: An edge case is a situation that occurs at the extremes of operating parameters.
    In code, an edge case refers to valid input values that could require special
    handling. For example, the Fibonacci sequence algorithm (F(n)=F(n-1)+F(n-2)) requires
    special handling if the sequence value is 0 or 1.
  prefs: []
  type: TYPE_NORMAL
- en: TDD allows developers to break their code into small and manageable steps when
    necessary. This is possible because TDD requires that each function and feature
    added must have tests. We can write one small test, then write the code that makes
    that test pass. Large features and functions can be broken down into small pieces
    and built in increments. This can greatly help with understanding all the parts
    of a problem.
  prefs: []
  type: TYPE_NORMAL
- en: TDD can also promote more modular and reusable code. Each piece of code must
    be tested, and large pieces of code can be broken down into smaller parts. This
    can lead to smaller, more focused classes and functions, and fewer cross-dependencies
    between code files. These smaller parts can be wrapped in a module with their
    tests and shared through a program. Updates to the module can simply be verified
    for correctness by running the attached test suite.
  prefs: []
  type: TYPE_NORMAL
- en: TDD Cycle
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The TDD cycle is generally a sequence of six steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Add a test:** In TDD, every new feature should begin with test writing. To
    write a new test, you must clearly understand the feature''s specifications and
    requirements. The requirements for the feature must be thought out and broken
    into testable pieces that can be written as tests one at a time.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Run all tests and see if any fail:** To check if the new test passes, the
    test should obviously fail because the feature we are adding has not been implemented
    yet. If the test does not fail, then the feature already exists or the test was
    written incorrectly. This serves as a sanity check of the written test. The test
    should fail for the intended purpose and serves to help check that the intended
    logic is being tested.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Write code to fix tests:** The code does not need to be perfect at this stage.
    The test may be fixed in an inefficient way but this is acceptable because it
    can be refactored later in the process.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Run tests and make sure they pass:** The tests should all pass, including
    all the previously added tests. If new code has broken a test that previously
    passed, changes can be reverted to figure out what the breaking change may have
    been.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Refactor/clean up code:** If any code cleanup is needed, it can be done in
    this step. Here, you can improve the implementation of the newly added code or
    fix any tests that may have broken when adding new code. After any refactoring,
    you should run the tests again to make sure all changes were correct. Repeat the
    refactor and run the test step as needed until the refactor is correct.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Repeat:** Add a new test and repeat the TDD cycle until the feature has been
    fully implemented and tested.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test-driven development is a powerful way to ensure that all code is tested
    but it can lead to several pitfalls if the developers are not conscientious. TDD
    can be difficult to use when a full stack or functional test is required. A full
    stack or functional test is a test of multiple parts of a technology stack at
    once. Tests that require user interface elements, database calls, or network calls
    can be very difficult to write. Typically, outside world interaction for a test
    in your code can be spoofed by using mock data or network calls.
  prefs: []
  type: TYPE_NORMAL
- en: TDD can also begin to break down if tests are not run frequently or are poorly
    maintained. If tests are abandoned and never run, or only run infrequently, the
    entire purpose of TDD breaks down. The features added to a program are designed
    with tests in mind, and the tests are used to validate that the features are properly
    implemented. If the tests are never run, the entire purpose of TDD is ignored.
    Tests that are poorly maintained also prevent TDD from being effective. Poor maintenance
    can occur through either not being updated to meet adjusted feature requirements,
    or through not having new tests added that outline the requirements of new features.
    Poorly maintained tests will not properly inform you of whether the code written
    is performing in the way we want it to.
  prefs: []
  type: TYPE_NORMAL
- en: TDD can also fall prey to poorly or lazily written tests. If tests are too coarse,
    they will not be able to find bugs in the code. The tests must be written with
    enough specificity to test each bit of logic independently from the others. On
    the other end of the spectrum, if trivial tests are added, we waste time in our
    TDD Agile process. If tests are written that are trivial or that duplicate previous
    tests, we will decrease our development efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, TDD can break down if any members of the team do not adopt the development
    strategy. If only part of a development team writes the tests before the addition
    of new code, we will only be able to test and validate a small part of the code
    base. For TDD to have the best results, it has to be fully adopted by all members
    of a development team.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Testing your code is the best way to ensure that it functions in the intended
    way. If you do not currently test your code, it can be very difficult to get started
    implementing tests; however, it should be done. Testing your code can make your
    code more correct, easy to write, and of higher quality.
  prefs: []
  type: TYPE_NORMAL
- en: 'Test-driven development is one of the simplest ways to begin integrating tests
    in a project. TDD revolves around writing tests that outline the requirements
    of any feature or function added before any implementation code is written. It
    forces the developer to understand exactly how each feature will be implemented.
    TDD is a simple six-step process: add a test, run tests, write code, run tests,
    refactor, repeat. This process ensures that each small piece of a feature gets
    tested.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 24: Applying Test-Driven Development'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You have been tasked to write a Fibonacci number generator. Use the test-driven
    development cycle to write tests and develop the Fibonacci algorithm. You can
    use the Fibonacci code written in *Chapter 1: Introducing ECMAScript 6*, Activity
    I, for reference (it may or may not need to be modified). You should write tests
    for the `n=0` condition, then implement the `n=0` condition, then write tests
    for and implement the `n=1` condition, then write tests for and implement the
    `n=2` condition, and finally the `n=5`, `n=7`, and `n=9` conditions. If the test
    passes, log `Test passed`. Otherwise, throw an error.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To develop and test an algorithm using TDD, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: By hand, calculate the values for the Fibonacci sequence at n=0, n=1, n=2, n=5,
    n=7, and n=9.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write a function called `fibonacci` that recursively calculates the Fibonacci
    sequence value where the value takes in a variable `i` and checks if `i<=0`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If it is, return `1`, then it checks `if i==1`.
  prefs: []
  type: TYPE_NORMAL
- en: If it is, then it returns `1`. Otherwise, it recursively gets the Fibonacci
    value.
  prefs: []
  type: TYPE_NORMAL
- en: It then returns `fibonacci(i-1) + fibonacci(i-2)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Write a general testing function called test that takes in two arguments: a
    calculated value (`value`) and an expected value (`expected`).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check whether the two values are different. If they are, throw an error.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the two values are the same, print the `Test passed` message.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each condition to test (calculated in step 1, n=0, n=1, n=2, n=5, n=7, and
    n=9), write a test for the test condition using the `test` function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Call the `test` function and pass in the value returned from the `fibonacci`
    function and the value calculated manually.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the tests.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the test fails, fix the bugs in the `fibonacci` function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the test again until the bugs are fixed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the test passes, continue to the next test condition.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the test fails, fix the bug and rerun the tests.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Code**'
  prefs: []
  type: TYPE_NORMAL
- en: index.js
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: https://bit.ly/2H5CNv0
  prefs: []
  type: TYPE_NORMAL
- en: 'Snippet 4.1: Testing code'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Output**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1: Fibonacci test'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_4.1.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.1: Fibonacci test'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You have successfully applied test-driven development to develop and test an
    algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Types of Testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Software testing comes in many different forms. In this section, we will discuss
    the different methodologies for testing code and cover the most common types of
    code tests.
  prefs: []
  type: TYPE_NORMAL
- en: Black Box and White Box Testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are two methodologies to testing code, black box and white box. The term
    **black box** signifies a system where the internal workings are not known. The
    only way the system can be observed is through its inputs and outputs. A **white
    box** system is a system where the internal workings are known. It can be observed
    through its inputs, outputs, and exact internal workings. Black box and white
    box systems could be anything from a software program, to a mechanical device,
    or any other system.
  prefs: []
  type: TYPE_NORMAL
- en: '**Black box testing** refers to software testing when the internal structure
    or implementation of the code is not known to the tester. We are only able to
    observe the inputs to, and outputs from the code system. **White box testing**
    refers to software testing when the internal structure or implementation is known
    to the tester. We are able to observe the inputs and outputs'' and exactly how
    the internal state changes at every step of the program. Nearly all forms of code
    testing are based on black box or white box testing principles. A visualization
    showing black box versus white box is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2: Black box and white box visualization'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_4.2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.2: Black box and white box visualization'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We will discuss three types of tests: **unit tests**, **functional tests**,
    and **integration tests**. Unit tests are designed to verify all pieces of testable
    code against the intended purpose. They test the smallest pieces of logic to ensure
    implementation correctness. Functional testing is designed to confirm functionality
    of a feature or component. Integration tests are designed to test integrated components
    to verify they work as intended together in an integrated system. These three
    types of code tests provide a good foundation from which you can approach testing
    code.'
  prefs: []
  type: TYPE_NORMAL
- en: Unit Tests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Unit testing** is one of the most common forms of testing. Unit tests are
    used to ensure that a specific piece of functionality of a function has met the
    requirements. Unit tests are generally built from a white box testing perspective
    and we will discuss unit tests in this chapter, assuming that the internal functionality
    of the code is known. While unit tests can be built from a black box perspective,
    this is closer to functional testing and will be talked about more in the next
    section.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A unit test is simply a test that tests a piece of code in the smallest unit
    possible. A "unit" of code is a small piece that is logically isolated from other
    parts of code. In other words, it is a piece of code that does not logically depend
    on other parts of the code. The unit of code can be updated without affecting
    the way the code around it functions. For example, consider the code shown in
    the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 4.2: Code unit example'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The function `adjustValue()` takes in a number. If the number is greater than
    5, it subtracts 1 from the number, and if the value is less than -5, it adds 1
    to the number. We can break this code snippet into three logical units as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The first unit is the `if` statement that checks if the value is greater than
    5 and the decrement operator (`value--`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The second unit is the else `if` statement that checks if the value is less
    than -5 and the increment operator (`value++`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The third unit of logic is the `return` statement. Changing any one of these
    three logic units does not affect the logical structure of the code around it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can create a unit test for each of these units to ensure that they function
    correctly. Our unit tests should test only one unit of code at a time. For this
    example we will need 3 unit tests. We will build tests to check the return value,
    the greater than 5 condition, and the less than -5 condition. To test the return
    condition, we simply need to pass in a value less than or equal to 5 and greater
    than or equal to -5\. The value returned should be the same as the value passed
    into the function. To test the greater than 5 condition, we must pass in a value
    greater than 5\. We know that the value returned must be 1 lower than the value
    entered. To test the less than condition, we must pass in a value less than -5\.
    We know that the value returned should be 1 higher than the value entered. These
    three unit tests can be put into a code file and run after we make modifications
    to our code.
  prefs: []
  type: TYPE_NORMAL
- en: Unit tests should be run as frequently as possible. The unit test should be
    put into files and run whenever any code logic is changed. Minor changes in the
    logic of a piece of code can result in major changes in the results. Continuous
    testing will help to ensure that no small bugs creep through the cracks. Many
    companies have automated testing systems that will run unit tests automatically
    on a Git repository commits or on a version release. This automated testing can
    be very good for helping to track down the commit and change that broke the code.
    This can drastically cut down on debug time and effort.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 25: Building Unit Tests'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You have been tasked with building unit tests for a piece of code. To complete
    this assignment, follow these instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: Reference the file provided in `exercises/exercise25/exercise.js` and look at
    the function titled `fakeRounding`. We will build unit tests for this function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In that file, write a general testing function called `test` that takes in
    two arguments: a calculated value (`value`) and an expected value (`expected`).
    Check whether the two values are different. If they are, throw an error.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the two values are the same, print the test passed message. You may use the test
    function from *Exercise 24* if you wish.
  prefs: []
  type: TYPE_NORMAL
- en: Reference the `fakeRounding` function, line by line, and analyze what the function
    does to the input and the resultant output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It obtains the decimal part of the absolute value of the number passed in. It returns
    the input rounded up to the nearest integer if the decimal is <=0.5\. Next, it
    returns the input rounded down to the nearest integer if the decimal is >0.5.
  prefs: []
  type: TYPE_NORMAL
- en: Write tests to check the following cases using the `test` function we created.
    Calculate the expected value from the provided input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Write tests for multiple inputs, 0, 0.4999, 0.5, 0.5001, -0.4999, -0.5, and
    -0.5001:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Code:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**solution.js**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 4.3: Unit testing'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: https://bit.ly/2Fjulqw
  prefs: []
  type: TYPE_NORMAL
- en: '**Output:**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3: Unit Test'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_4.3.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.3: Unit Test'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You have successfully built unit tests for a piece of code.
  prefs: []
  type: TYPE_NORMAL
- en: Functional Testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Functional testing** is a black box testing method done to determine whether
    a component of an application is working to the defined specification. Functional
    tests are generally more complex than unit tests. Where unit tests test the logic
    of the functions inside of a component, functional tests are designed to test
    whether the component meets the specifications defined in the specification sheet
    or data sheet. For example, if we had a form on a web page that only accepted
    numbers, we may do functional tests with numbers and strings to ensure that the
    number-only spec was met correctly.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Functional testing can be broken down into five steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Determine functionality
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create input data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Determine output data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare input and output
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fix bugs
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The first step to building functional tests is determining the functionality
    that needs to be tested. Functional tests generally test for the main functionality,
    error conditions, usability, and many others. It is often easiest to determine
    what tests need to be built by looking at the feature/component specification
    or data sheet. You can take the required program behavior and error handling for
    the component from the data sheet, and break it into a series of tests.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have decided what functionality needs to be tested and how you will
    go about testing that functionality you must create input data to test with. The input
    data required for tests is heavily dependent on the component or feature being
    built, and therefore can be difficult to generalize for the purposes of a textbook.
    However, you should test with both values that you expect the program to accept
    and values that may be unexpected for the program. For example, if we are creating
    an email input form, we should test the input field with both a valid email (`xxxx@yyy.zzz`)
    and an invalid email (`12344312`). When generating arbitrary test data, it is
    often a good idea to test with non-sequential values in arrays, strings, or other
    data structures. Using random values can help you discover logic errors.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have determined the input data required for your tests, you must figure
    out the expected output from the feature. This part of the process is arguably
    the most important and should not be rushed. Output values should NEVER be calculated
    by putting the input through the program being tested. This will result in a tautology
    when running the tests and no bugs will be found. I have seen many tests fail
    because the programmer did not properly calculate the expected output values and
    the tests were invalid.
  prefs: []
  type: TYPE_NORMAL
- en: Once the output values have been determined, we are ready to run our tests.
    The input values should be run through the feature or component and compared against
    the output values. A test passes if the output values from the component match
    the expected output values calculated in the previous step. If the values do not
    match, the test did not pass and a bug needs to be fixed.
  prefs: []
  type: TYPE_NORMAL
- en: The final step in the process is bug fixing. If a test does not pass, then there
    is a bug somewhere in the component. Once the bugs have been fixed, the test can
    be re-run. If all of the tests pass for all of the functionality being tested,
    the component may be considered ready for integration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Building tests can be one of the most difficult parts of functional testing.
    There are two different types of tests that we need to build: positive and negative
    tests. Positive tests test the expected program use flows and negative tests test
    the unexpected use flows.'
  prefs: []
  type: TYPE_NORMAL
- en: Positive tests are relatively easy to generate. Any action you might want or
    expect a user to do can be turned into a positive test case. For example, clicking
    a button on an application or entering information into a text field. These two
    use cases can be turned into a functional test for clicking the button and a functional
    test for typing in the text field. Since positive tests are designed to test the
    expected program flow, they should use valid and expected data. In a case where
    a test does not use data but instead uses some other functionality, such as a
    user's mouse click, we would only need to write positive tests for the expected
    behaviors.
  prefs: []
  type: TYPE_NORMAL
- en: Negative tests are more difficult to create. They require much more creativity
    to build and implement effectively because you must come up with weird ways to
    break your own code. It can often be difficult to anticipate how a user may misuse
    a feature. Negative tests are designed to test error paths and failures. For example,
    if we intend a user to click a button on our website, it may be prudent to write
    negative tests for the double-click condition. A double-click is unexpected behavior
    and may result in a form resubmission if not properly accounted for. Negative
    tests are essential to fully testing a feature.
  prefs: []
  type: TYPE_NORMAL
- en: Integration Tests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Integration tests are a step back from functional tests. Integration tests are
    designed to test how modules and components work when they are fully integrated.
    Unit tests test functions one by one. Functional tests test full components or
    modules one by one. Integration tests test the combined components to make sure
    they interact with each other correctly. Integration tests are generally more
    complex than unit or functional tests. Integration tests can be written for something
    as simple as an individual web page once all the components have been built and
    integrated together, or for something as complex as a full frontend application
    with an API, multiple servers, and databases once all of the individual components
    are prepared and combined. Integration testing is often the most difficult and
    time consuming form of testing.
  prefs: []
  type: TYPE_NORMAL
- en: '**Integration testing** can be simplified and thought of like the process for
    manufacturing a ballpoint pen. The cap, body, ink, ballpoint, and tail cap with
    clip are all components of a ballpoint pen. They are all manufactured and tested
    separately to ensure that each component meets the specifications set for it.
    When the pieces are ready, they are put together for an integration test that
    will test whether the components function correctly together. For example, our
    integration test may test whether the ballpoint fits into the ink cartridge, the
    ink and ballpoint fit into the pen body, or the cap fits onto the body or not.
    If one of these tests fail, the integrated system (ballpoint pen) will not function
    to spec and one or more components must be updated.'
  prefs: []
  type: TYPE_NORMAL
- en: There are several methods to use to go about integration testing. They are big
    bang testing, bottom-up testing, top-down testing, and sandwich testing. Each
    has its advantages and disadvantages.
  prefs: []
  type: TYPE_NORMAL
- en: Big bang testing consists of combining all of the components at once and then
    running your tests. It is called **big bang testing** because you throw everything
    together at once and get an explosion of (likely) failed integration tests. **Big
    bang testing** is very convenient for small systems that do not have very many
    component-to-component interactions. When applied to large systems, big bang testing
    can often break down. The first breakdown is that fault localization can be much
    more difficult in a very large and very complex system. If finding the source
    of a bug takes a long time, our test cycle will be very slow. The second breakdown
    is that some links between components can be missed and not tested because of
    the complexity of the system. If there are hundreds of component links that need
    to be tested, it can be difficult to keep track of them all if they are all linked
    at once. The third fault in big bang testing is that integration tests cannot
    start until all modules or components are designed and fully built. Since you
    must combine all the modules at once, a delay in one module pushes back integration
    testing for the entire system.
  prefs: []
  type: TYPE_NORMAL
- en: The second form of integration testing is **bottom up testing**. In **bottom
    up testing**, we must imagine the hierarchy of our system as a tree. We start
    by integrating the bottom layer of modules first. Then, once all the tests pass,
    we add the next layer of modules or components, until we have the full system
    being tested. To test in this manner, we must use drivers to simulate the upper
    layers and make calls to the modules or components in the bottom layers we are
    testing. Drivers are simply bits of code that simulate higher-level modules and
    the calls they make to lower-level modules for the purpose of tests. Bottom up
    testing has two main benefits. The first is that fault localization is very easy.
    Modules are integrated from the lowest level up. If a newly integrated module
    fails, then we can quickly pinpoint and blame the module that needs fixing. The
    second benefit is that there is no wasted time waiting for all modules to be developed.
    If the modules are also developed in a bottom up approach, we can simply add them
    to the integration tests once they are ready. We can integration test as pieces
    are ready, instead of waiting until the entire system is built. Bottom up testing
    has two main disadvantages. The first is that it can be difficult to create an
    early working prototype. Since modules are built and integrated from the bottom
    up, the user-facing features and modules are generally the last to be implemented
    and tested. It can be difficult to have an early prototype since the prototype
    components are generally ready last. The second disadvantage is that critical
    components and modules at the top level that control app flow are tested last
    and may not be tested as fully as the modules tested first. For large integrated
    systems, I generally believe that bottom up testing is better than big bang testing.
  prefs: []
  type: TYPE_NORMAL
- en: The third form of integration testing is **top down testing**. In **top down
    testing**, we must imagine our system hierarchy as a tree. We start by integrating
    the top layers of the system first. These are generally user-facing components
    and program flow modules. Top down testing requires the tester to build stubs
    to simulate the functionality of the modules at lower levels. The stubs imitate
    the undeveloped modules so that the modules being tested can make the calls they
    need to make. Top down testing has three major advantages. Like bottom up testing,
    the first major advantage is that fault localization is very easy, and we do not
    need to wait for the entire system to be built before we can start integration
    tests. Components can be added one at a time once they are built. The second advantage
    to top down testing is that an early prototype can be created very easily. The
    user-facing and most critical components are built and tested first, so it is
    very easy to integrate those into a prototype for early demos. The final major
    advantage is that critical modules are tested on priority. The critical modules
    are built first and therefore tested more frequently and usually more completely.
    Top down testing has two major drawbacks. The first is that many stubs are needed.
    Each module or component at a lower level must be built into a stub for testing.
    This can require a large amount of extra code to be written. The second disadvantage
    is that modules at lower levels are built and tested last. Generally, they are
    not as thoroughly tested.
  prefs: []
  type: TYPE_NORMAL
- en: The final form of integration testing is **sandwich testing**. **Sandwich testing**
    is a combination of the top down and bottom up approaches. The most important
    and lowest-level modules are built and integrated at the same time. This approach
    has the benefit of providing a more general and big bang-like integration testing
    approach, while maintaining the benefits of both top down and bottom up testing.
    The largest drawback to sandwich testing is that both stubs and drivers need to
    be built. It can sometimes be difficult to follow what is a stub or a driver if
    the system is very convoluted.
  prefs: []
  type: TYPE_NORMAL
- en: Building Tests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Building tests can seem like a very daunting process. It can be very difficult
    to come up with an entire test suite from scratch. Test-driven development, however,
    provides us with a very good starting point for creating tests. As outlined previously,
    in the *Test-driven Development* section, building tests should always start with
    writing a requirements sheet.
  prefs: []
  type: TYPE_NORMAL
- en: 'The requirements sheet is a data sheet for the function, feature, or entire
    system being built. The requirements sheet should break down the requirements
    for the feature into a very detailed and specific list. Writing requirements sheets
    for software applications is out of the scope of this book, but we will walk through
    a brief example. Imagine that we have been tasked to build a Facebook-style comment
    creation component. The component must have a text field with a character limit
    and a button that posts the comment. The two general requirements we can easily
    build from this scenario are a character limit for our text field and a button
    that makes an API call after a click event. These two requirements can then be
    refined into the following list of requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: The text field must accept user-typed characters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: No characters can be added to the text field when the text field contains 250
    or more characters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Any characters in the text field may be deleted by pressing the Backspace key.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The button must respond to an `onclick` event.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On a click event, the component must make a call to the API with the test field data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is not a full list of requirements for the feature or the components in
    the feature, but for this example, it is sufficient. With these requirements,
    we can begin to write our tests.
  prefs: []
  type: TYPE_NORMAL
- en: We can begin to write tests, going item by item through our requirements list.
    Each requirement should be broken down into one or more tests. Each test should
    test exactly one thing and have a very specific success criterion.
  prefs: []
  type: TYPE_NORMAL
- en: The first requirement is that the text area must accept user-typed characters.
    If we press a key on the keyboard, the character pressed should be added to the
    text area, so our first test should be pressing a key on the keyboard and verifying
    that the same character was added to the text area.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second requirement states that no characters can be added to the text field
    when the text field contains 250 or more characters. This can be broken into two
    tests: when the text area has 250 characters, no key presses can add to the text
    area, and when the text area has more than 250 characters, no key presses can
    add to the text area.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The third requirement states that any characters in the text field may be deleted
    by pressing the backspace key. This requirement can be converted into a test quite
    easily. We must test that if the backspace key is pressed, a character is removed
    from the text area. To properly test edge cases, we should run this test four
    times: once with an empty text area, once with a text area with more than 0 but
    fewer than 250 characters, once with 250 characters, and once with more than 250
    characters. Testing all of the operating conditions for our text area (even the
    test case with more than 250 character that we never expect to reach) will ensure
    that no failure can occur.'
  prefs: []
  type: TYPE_NORMAL
- en: The fourth requirement states that the button must respond to an on-click event.
    This test is very easy to write. We simply need to add a test where the user clicks
    on the button. The final requirement states that a click event on the button must
    call the API. We can easily turn this into a test by simulating the on-click event
    and ensuring that the website makes the API call with the correct data.
  prefs: []
  type: TYPE_NORMAL
- en: We have outlined the list of five requirements in a series of tests. These tests
    can now be compiled together and written in code form in a test file. This test
    file will be used to verify that the requirements outlined in our requirements
    sheet are properly met.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 26: Writing Tests'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Your team has been tasked to build a registration page for your newsletter.
    The registration page must have three text fields for name, email, and age, as
    well as a **Submit** button. Your registration page must accept a name between
    1 and 50 characters (inclusive), an email between 1 and 50 characters (inclusive,
    and email format not validated), and the user's age (must be older than 13 years
    old). When the **submit** button is pressed, the user information must be validated
    (against the specification provided in the preceding section). If any part of
    the specification is not met, throw an error in the browser console. Write a very
    basic specification sheet detailing the requirements for each input and the submit
    button, then build tests from the specification sheet. Implement the page (use
    `exercises/exercise26/exercise.html` as a starting point) and perform the tests
    manually from the UI. The starter file contains hints for the tests you must write.
    Write the specification sheet and tests before opening the starter file.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build a basic specification sheet and run tests from the specification sheet,
    perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Write the specification sheet by taking each sentence that contains specification
    information in the scenario description and break it into one or more requirements.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Decompose the specification sheet into manual UI tests by taking each item on
    the spec sheet and write one or more tests for it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the starter HTML file at `exercises/exercise26/exercise.html`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the three input fields with the IDs `name`, `email`, and `age`. This is
    shown in the following figure:![Figure 4.4: Data Sheet (After step 4)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](image/Figure_4.4.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.4: Data sheet (after step 4)'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Add the **Submit** button to the HTML document and have it call the `validate`
    function on click.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the validate function, get the `name` text field by email id and save its
    value in the `name` variable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Get the `email` text field by id and save its value in the `email` variable.
  prefs: []
  type: TYPE_NORMAL
- en: Get the `age` text field by id, get its value, parse the value for a number,
    and then save the parsed value in the `age` variable.
  prefs: []
  type: TYPE_NORMAL
- en: Check the conditions on the specification sheet that relate to the `name` field.
    Also check if the name doesn't exist, or is false, and throw an error if it does
    not. Check if `name length <= 0 or > 50`, then throw an error if it is.
  prefs: []
  type: TYPE_NORMAL
- en: Check the conditions on the specification sheet that relate to the `email` field.
    Also, check if the email doesn't exist, or is falsy; throw an error if it is.
    Check if `email length is <=0 or > 50`, then throw an error if it is.
  prefs: []
  type: TYPE_NORMAL
- en: Check the conditions on the specification sheet that relate to the `age` field.
    Also, check if age doesn't exist, or is falsy; then throw an error. Check if `age
    < 13` and throw an error if it is.
  prefs: []
  type: TYPE_NORMAL
- en: Log the user details (`name`, `email`, and `age`) to the console.
  prefs: []
  type: TYPE_NORMAL
- en: For each test you wrote in the specification sheet, test it manually. Fill in
    the values in the text fields and then click **Submit**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare the errors logged to the console against the expected result of the test.
  prefs: []
  type: TYPE_NORMAL
- en: If a test fails, then update the validate function to fix the bug and rerun
    the test.
  prefs: []
  type: TYPE_NORMAL
- en: '**Code**'
  prefs: []
  type: TYPE_NORMAL
- en: solution.html
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 4.4: Testing front-end input code'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: https://bit.ly/2H5E7OJ
  prefs: []
  type: TYPE_NORMAL
- en: '**Output**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5: Data Sheet (Final Output)'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_4.5.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.5: Data sheet (final Output)'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You have successfully built a basic specification sheet and run tests from the
    specification sheet.
  prefs: []
  type: TYPE_NORMAL
- en: Test Tools and Environments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Testing tools, frameworks, and environments are designed to make testing code
    simpler and quicker. There are many testing frameworks available for JavaScript
    and the most popular will be mentioned briefly. We then dive deeper into one of
    the frameworks and demonstrate how to use the framework to write good tests.
  prefs: []
  type: TYPE_NORMAL
- en: Testing Frameworks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You will need to select a testing framework based on the types of tests you
    wish to conduct. JavaScript is generally tested in one of three ways: **general
    test**, **code coverage tests**, and **user interface tests**. When selecting
    a framework, you must decide what you are testing and how you wish to go about
    it.'
  prefs: []
  type: TYPE_NORMAL
- en: General tests will include your unit tests, functional tests, and integration
    tests. It is a sort of catch-all for your tests. The most popular frameworks for
    tests are **Mocha**, **Jasmine**, and **Jest**. Jest is used by Facebook and is
    one of the simpler frameworks to set up. Mocha is the most popular testing framework
    available for JavaScript and it will be covered in much more detail later in this
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Code coverage tests are used to help check test completeness. Code coverage
    can be defined as the percentage of your code base covered, or tested, by your
    automated tests. Code coverage can be used as a general guideline for the completeness
    of your code tests. In theory, the more code coverage your application has, the
    more complete and better the tests. However, in practice, having 100% code coverage
    does not mean that the tests for the code are well thought out and valid. It just
    means that every code path is referenced somehow in a test. It is more important
    to write well thought out tests than throw together useless tests that hit every
    line of code. The most popular and simplest code coverage library is **Istanbul**.
    It is compatible with many testing frameworks and can be easily worked into most
    testing suites. If you need a third-party library for testing code coverage, I
    recommend using Istanbul.
  prefs: []
  type: TYPE_NORMAL
- en: The final form of tests is **User Interface** (**UI**) tests. Like general tests,
    we can break UI tests into integration, functional, and unit tests. However, UI
    tests are generally not included under general tests because they require special
    and more complex frameworks. To perform UI tests, we must load the user view and
    simulate user interactions. Some of the more common UI test frameworks are Testcafe,
    WebdriverIO, and Casper.
  prefs: []
  type: TYPE_NORMAL
- en: Mocha
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Mocha** is a framework for testing JavaScript in Node.js. It is a simple
    library designed to simplify and automate the testing process. Mocha is designed
    to be simple, flexible, and extendable. My company uses Mocha for unit, functional,
    and integration tests. We will discuss some of the benefits to using Mocha over
    other frameworks, cover how to set up and run your first tests with Mocha, and
    explain some of the advanced functionality Mocha offers.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The full documentation for Mocha can be found at [https://mochajs.org/](https://mochajs.org/).
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many benefits to Mocha. As stated earlier, Mocha is the most popular
    testing framework for Node.js. This immediately gives Mocha its largest advantage:
    Mocha has the largest development community. This is important for support and
    extensions. If you run into issues with your Mocha tests, this community can provide
    extensive support. The Stack Overflow community is prompt in answering questions
    about Mocha. The Mocha community also has built many plugins or extensions for
    unique test scenarios. If your project has unique testing needs, it is likely
    that a plugin has been built to suit your needs.'
  prefs: []
  type: TYPE_NORMAL
- en: Aside from the large community support, Mocha also provides advantages such
    as simple setup, assertion, and simple asynchronous testing. Setting up Mocha
    can be done through the command line with npm. With any testing framework, we
    want to make sure that setting it up does not take too much of our time. Mocha
    also allows for the use of assertion modules. While not necessary, if your team
    wants to approach testing from an assertion standard, Mocha allows you to install
    and import many JavaScript assertion libraries. Finally, Mocha is designed for
    asynchronous tests. With any JavaScript testing module, we must rely on asynchronous
    support to write complete tests. Mocha is designed to work with callbacks, promises,
    and the ES6 async/await syntax. It can easily be integrated into most backend
    setups.
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up Mocha
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Installing Mocha is done with the npm command `npm install -g mocha`. This command
    will install Mocha globally on your system. Any Node.js project will now be able
    to use Mocha to run tests. Once installed globally, we will be able to run tests
    from the command line with the `mocha` keyword.
  prefs: []
  type: TYPE_NORMAL
- en: Once mocha has been installed on our system, we must add it to a project. If
    you do not have a Node.js project, create a path to the desired project directory
    and initialize the project with `npm init`. This is the same command used in *Chapter
    1* to set up a project when we were discussing transpiling and Babel. The `npm
    init` command will create a file called `package.json`. After we have created
    our JavaScript project, we need to create our project files. Create a file called
    `index.js` and a file called `test.js`. `index.js` will contain our project code
    and `test.js` will contain our test code.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `package.json` file, there will be a field called `scripts`. To run
    our tests from npm, we must add a field to the `scripts` object. Replace the `scripts`
    object with the code shown in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 4.5: Test script in package.json'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The code in the preceding snippet adds a script called `test` to the `package`
    object. We can run this script with the `npm run test` command. When we run this
    command, it calls the `mocha` keyword with the`./test.js` parameter. The mocha
    testing framework is run with the tests contained in the `test.js` file. We are
    now ready to start adding tests to `test.js`.
  prefs: []
  type: TYPE_NORMAL
- en: Mocha organizes tests with the `describe` and `it` keywords. Both are functions
    that take in a string as the first parameter and a function as the second parameter.
    The `describe` function is used to group tests together. The `it` function is
    used to define a test. The function argument for `describe()` contains test declarations
    (with `it()`) or more description functions. The function argument for `it()`
    contains the test function to be run.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can think of the describe function as a way to describe and group together
    a group of tests. For example, if we have a group of tests that all test a function
    called `calculateModifier`, we might group the tests together with a description
    using the describe function: `describe( ''calculateModifier tests'', () => { ...
    } )`. This groups the tests contained in the function under the description `calculateModifier`
    `test`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can think of the `it` function as a way to define a test in the form "it
    should …". The string input to the `it` function describes the test, usually what
    the test is trying to accomplish. The function argument contains the actual test
    code. For example, if we want to define a test that checks whether two values
    are equal, we can use the `it function` to do this: `it( ''should have two inputs
    that are equal'', () => { ... } )`. The description tells us what should happen
    and the code to check the values will go in the function argument.'
  prefs: []
  type: TYPE_NORMAL
- en: Mocha Basics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Understanding the basics of tests, we can look at the Mocha starter documentation
    and see the code shown in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 4.6: Mocha basics'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: What do you think this code snippet is doing? First, we describe a set of tests
    with the description `Array`. Inside the function argument of the first `describe`
    block, we have another `describe` block. This new block describes a set of tests
    with the description `#indexOf`; because these describe blocks are nested, we
    can assume that we are testing the `indexOf` functionality of an array. Inside
    the second `describe` block, we define a test with the `it` function. We define
    a test that says `it should return -1 when the value is not present`. As expected
    from the description of the test, we would expect the `indexOf` function to return
    the value `-1` if the value is not present in an array. In this example, we use
    the assert library to assert that the expected value of `-1` is equal to the actual
    value. The assert library is not strictly necessary, but makes this example simpler
    to understand.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 27: Setting Up a Mocha Testing Environment'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The aim is to set up a Mocha testing environment and prepare a test file. To
    complete this assignment, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Run `npm` `init` to create a `package.json` file in the exercise directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run `npm` `install mocha -g` to install the testing package.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a file called `test.js` where our tests will go.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a script to the `package.json` file that runs the mocha test suite on the
    `test.js` file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Inside the `test.js` file, add a `describe()` block that describes tests as
    `My first test!`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Inside the `describe` block's callback, add a test with `it()` that passes and
    has the description `Passing test!`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the tests by calling the `npm` script added to `package.json`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Code:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**test.js**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 4.7: Mocha basics'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: https://bit.ly/2RhzNAy
  prefs: []
  type: TYPE_NORMAL
- en: '**Output:**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6: Mocha Testing'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_4.6.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.6: Mocha Testing'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You have successfully set up a Mocha testing environment and prepared a test
    file.
  prefs: []
  type: TYPE_NORMAL
- en: Mocha Async
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Mocha supports asynchronous tests as well as synchronous tests. In the example
    shown in snippet 4.6, we perform synchronous tests. To support asynchronous tests,
    all we need to do is pass a done callback parameter into the function parameter
    of the `it()` function: `it( ''description'', ( done ) => {} )`. This tells mocha
    to wait until the `done` callback is called before proceeding to the next test.
    The `done` parameter is a function. If a test succeeds, done should be called
    with a `falsy` value (no error). If done is called with a `truthy` value, mocha
    will interpret that value as an error. It is best practice to pass an error object
    into the done callback but any value that evaluates to true will tell Mocha that
    the test failed.'
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous tests are performed synchronously by Mocha in the order in which
    they are defined in the test file. The tests may query resources asynchronously,
    but the next test will not begin running until the previous test has completely
    finished (done has been called). Running tests synchronously is important. Even
    though running tests synchronously may result in longer testing times, it allows
    us to test asynchronous systems that may rely on some shared state. For example,
    we can test systems such as databases and database interfaces with Mocha. If we
    need to perform an integration test that tests the process of adding to and removing
    from a database, we can create a test to add an item to the database and a test
    to remove the added item from the database. If the tests run these two asynchronously,
    we might run into timing issues. Due to network lag, or some other unexpected
    error, the remove operation may be processed before the add operation and the
    tests would fail. Mocha prevents the need to debug problems like this by forcing
    tests to run synchronously.
  prefs: []
  type: TYPE_NORMAL
- en: Mocha Hooks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For more complex tests, Mocha allows us to attach hooks to our tests. **Hooks**
    can be used to set up preconditions and post-conditions to our tests. In simpler
    terms, hooks allow us to set up before and clean up after tests. Mocha provides
    the following hooks: `before`, `after`, `beforeEach`, and `afterEach`. Hooks take
    in two arguments, a `description` and a `callback` function argument. This function
    argument can accept one parameter—a done function. An example of the syntax for
    the hooks is shown in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: describe( 'Array', () => {
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Snippet 4.8: Mocha hooks'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Hooks are only run before or after the tests in the describe block they are
    contained within. The `before` hooks are run once before any of the defined tests
    are started. They can be used to set up a general shared state between tests.
    The `beforeEach` hooks are run before each test starts, inside the `describe`
    block. They can be used to set or reset a shared state or set of variables required
    for each test. The `after` hooks are run once after all tests have finished running.
    They can be used to clean up or reset a state shared between tests. The `afterEach`
    hook is run after each test completes but before the next starts. It can be used
    to clean up or reset test-specific shared states.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 4: Utilizing Test Environments'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You have been tasked to upgrade your Fibonacci sequence test code to use the
    Mocha test framework. Take the Fibonacci sequence code and test the code you created
    for *Activity 1: Implementing Generators* and upgrade it to use the Mocha test
    framework to test the code. You should write tests for the `n=0` condition, implement
    it, then write for tests and implement the `n=1` condition. Repeat this for `n=5`,
    `n=6`, as well as `n=8`. If the `it()` test passes, call the done callback with
    no argument, otherwise call the test done callback with an error or other `truthy`
    value.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To write and run tests using the Mocha test framework, perform the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Set up the NPM project and install the mocha module.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a test script to the `package.json` that runs mocha and the tests in `test.js`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an `index.js` file with a Fibonacci sequence calculator function. Export
    this function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create `test.js`, which tests the Fibonacci sequence function using the mocha
    framework. Test `fibonacci` for n=0, n=1, n=2, n=5, n=7, and n=9.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Output**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.7: Testing the Fibonacci sequence with Mocha'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_4.7.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.7: Testing the Fibonacci sequence with Mocha'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You have successfully utilized the Mocha test framework to write and run tests.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution for this activity can be found on page 288.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Code testing is one of the most important skills a developer can have. Testing
    code is like going to the gym. You know it''s good for you, but it can often be
    difficult to begin. In this chapter, we discussed the reasons to test code, several
    types of code tests, and several JavaScript code testing frameworks. Code tests
    need to be done to ensure program correctness. Test-Driven Development is one
    of the simplest ways to begin integrating tests into a project. TDD revolves around
    writing tests that outline the requirements of any feature or function added,
    before any implementation code is written. There are many forms of code tests.
    In this chapter, we covered unit tests, functional tests, and integration tests.
    These types of code tests are the most common and are generally built from one
    of two methodologies: black box and white box. Functional, unit, and integration
    tests can all be built in many of the frameworks covered in the previous topic.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will cover the functional programming coding principle
    and define object-oriented programming and functional programming.
  prefs: []
  type: TYPE_NORMAL
