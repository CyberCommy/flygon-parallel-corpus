- en: Creating Automated Tests with unittest
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the size and complexity of your application rapidly expanding, you've become
    nervous about making changes. What if you break something? How will you know?
    You need a reliable way to make sure your program is working properly as the code
    changes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortunately, we have a way: automated testing. In this chapter, you''ll cover
    the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Learning the basics of automated testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning specific strategies for testing Tkinter applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying this knowledge to our data entry application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automated testing basics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up until now, testing our application has been a process of launching it, running
    it through a few basic procedures, and verifying that it did what we expected
    it to do. This approach works acceptably on a very small script, but, as our application
    grows, it becomes an increasingly time-consuming and error-prone process to verify
    the application's behavior. Using automated testing, we can consistently verify
    our application logic within seconds.
  prefs: []
  type: TYPE_NORMAL
- en: There are several forms of automated testing, but the two most common are **unit
    testing** and **integration testing**. Unit tests work with discrete pieces of
    code in isolation, allowing us to quickly verify the behavior of specific sections.
    Integration tests verify the interactions of multiple units of code. We'll be
    writing both kinds of tests to verify the behavior of our application.
  prefs: []
  type: TYPE_NORMAL
- en: A simple unit test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At its most basic, a unit test is just a short program that runs a unit of code
    under different conditions and compares its output against expected results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following calculation class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This class is initialized with two numbers and can then perform a variety of
    arithmetic methods on them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a naive test for this function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Our test code creates a `MyCalc` object and then uses `assert` statements to
    check the output of `add()` and `mod_divide()` against expected values. The `assert`
    keyword in Python is a special statement that raises an `AssertionError` exception
    if the statement that follows it evaluates to `False`. The message string after
    the comma is the error string that will be passed to the `AssertionError` exception.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code `assert statement, "message"` is essentially equivalent to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Currently, all tests pass if you run the test script for `MyCalc`. Let''s try
    changing the `add()` method as follows to make it fail:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, running the test gives this error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'What is the value of such tests? Suppose someone decides to refactor our `mod_divide()`
    method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Since this passes our tests, we can be pretty sure this algorithm is correct,
    even if we didn't understand the code. If there were a problem with the refactor,
    our tests should show that fairly quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Testing pure mathematical functions is fairly simple; unfortunately, testing
    real application code presents us with some challenges that demand a more sophisticated
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider these issues:'
  prefs: []
  type: TYPE_NORMAL
- en: Code units often rely on a pre-existing state that must be set up before the
    test and cleared up afterwards.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code may have side effects that change objects outside the code unit.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code may interact with resources that are slow, unreliable, or unpredictable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Real applications contain many functions and classes that require testing, and
    ideally we'd like to be alerted to all problems at once. Our tests, as written,
    would stop on the first failed assertion, so we'd only get alerted to one problem
    at a time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To address these issues and others, programmers rely on **testing frameworks**
    to make writing and executing automated tests as simple and reliable as possible.
  prefs: []
  type: TYPE_NORMAL
- en: The unittest module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `unittest` module is  the Python standard library's automated testing framework.
    It provides us with some powerful tools to make testing our code reasonably easy.
  prefs: []
  type: TYPE_NORMAL
- en: '`unittest` is based on these standard unit testing concepts found in many test
    frameworks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Test**: A **test** is a single method that will either finish or raise an
    exception. Tests generally focus on one unit of code, such as a function, method,
    or process. A test can either pass, meaning the test was successful; fail, meaning
    the code failed the test; or error, meaning the test itself encountered a problem'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test case**: A test case is a collection of tests which should be run together
    and contain similar setup and tear-down requirements, typically corresponding
    to a class or module. Test cases can have fixtures, which are items that need
    to be set up before each test and torn down after each test to provide a clean,
    predictable environment in which the test can run'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test suite**: A test suite is a collection of test cases which cover all
    the code for an application or module.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mock**: A mock is an object that stands in for an external resource, such
    as a file or database. Mocks are patched over those resources during the test.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To explore these concepts in depth, let's test our `MyCalc` class using `unittest`.
  prefs: []
  type: TYPE_NORMAL
- en: Writing a test case
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s create a test case for the `MyCalc` class in the `test_mycalc.py` as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The names of both your test modules and your test methods should be prefixed
    with `test_`. Doing so allows the `unittest` runner to automatically find test
    modules and distinguish test methods from other methods in your test case classes.
  prefs: []
  type: TYPE_NORMAL
- en: As you probably guessed, the `TestCase` class represents a test case. To make
    our test case for `MyCalc`, we subclass `TestCase` and start adding the `test_`
    methods to test various aspects of our class. Our `test_add()` method creates
    a `MyCalc` object, then makes an assertion about the output of `add()`. To run
    the test case, we add a call to `unittest.main()` at the end of the file.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you run your test file at the command line, you should get the following
    output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The single dot on the first line represents our test (`test_add()`). For each
    test method, `unittest.main()` will output a dot for passing, `F` for failure,
    or `E` for error. At the end, we get a summary of what happened.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see what happens when a test fails, let''s alter our test to be incorrect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now when you run the test module, you should see a failure as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Note the single `F` at the top, representing our failed test. After all the
    tests have run, we get the full traceback of any failed tests, so that we can
    easily locate the failing code and correct it. This traceback output isn't very
    ideal, though; we can see that `mc.add()` didn't equal `12`, but we don't know
    what it was equal to. We could add a comment string to our `assert` call, but
    `unittest` provides a nicer method.
  prefs: []
  type: TYPE_NORMAL
- en: TestCase assertion methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`TestCase` objects have a number of assertion methods that provide a cleaner
    and more robust way to run various tests on our code output.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, there is the `TestCase.assertEqual()` method to test equality,
    which we can use as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'When we run our tests with this code, you can see that the traceback is improved:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Now, we can see the value that `mc.add()` created, which is much more helpful
    for debugging. `TestCase` contains more than 20 assertion methods that can simplify
    testing for a variety of conditions such as class inheritance, raised exceptions,
    and sequence membership.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some more commonly used ones are listed in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Method** | **Tests** |'
  prefs: []
  type: TYPE_TB
- en: '| `assertEqual(a, b)` | `a == b` |'
  prefs: []
  type: TYPE_TB
- en: '| `assertTrue(a)` | `a` is `True` |'
  prefs: []
  type: TYPE_TB
- en: '| `assertFalse(a)` | `a` is `False` |'
  prefs: []
  type: TYPE_TB
- en: '| `assertIn(item, sequence)` | `item` is in `sequence` |'
  prefs: []
  type: TYPE_TB
- en: '| `assertRaises(exception, callable, args)` | `callable` called with `args`
    raises `exception` |'
  prefs: []
  type: TYPE_TB
- en: '| `assertGreater(a, b)` | `a` is greater than `b` |'
  prefs: []
  type: TYPE_TB
- en: '| `assertLess(a, b)` | `a` is less than `b` |'
  prefs: []
  type: TYPE_TB
- en: You can easily add your own custom assertion methods to your test case as well;
    it's simply a matter of creating a method that raises an `AssertionError` exception
    under some condition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use an assertion method to test that `mod_divide()` raises `ValueError`
    when `b` is `0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '`assertRaises` passes if the function raises the given assertion when called.
    If we need to pass any arguments into the tested function, they can be specified
    as additional arguments to `assertRaises()`.'
  prefs: []
  type: TYPE_NORMAL
- en: '`assertRaises()` can also be used as a context manager like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This code accomplishes the exact same thing, but is a little clearer and more
    flexible.
  prefs: []
  type: TYPE_NORMAL
- en: Fixtures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Rather than perform the tedious task of creating the `MyCalc` objects in every
    test, our `TestCase` object can have a `setUp()` method that automatically creates
    any resources our tests need.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Now, every test case can use these objects to run its tests. The `setUp()` method
    will be rerun before every test, so these objects will always be reset between
    test methods. If we have items that need to cleaned up after each test, we can
    define a `tearDown()` method, which will be run after each test (in this case,
    it's not necessary).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, for example, our `test_add()` method can be much simpler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: In addition to the instance methods `setUp()` and `tearDown()`, `TestCase` has
    class methods for setup and tear down as well, namely `setUpClass()` and `tearDownClass()`.
    These can be used for slower operations that can be run when the test case is
    created and destroyed, rather than needing to be refreshed between each test method.
  prefs: []
  type: TYPE_NORMAL
- en: Using Mock and patch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `rand_between()` method generates a random number between `a` and `b`. Because
    we can't possibly predict its output, we can't provide a fixed value to test it
    against. How can we test this method?
  prefs: []
  type: TYPE_NORMAL
- en: 'A naive approach is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This test passes if our code is correct, but it doesn't necessarily fail if
    the code is wrong; in fact, if the code is wrong, it may pass or fail unpredictably.
    For example, if `MyCalc(1, 10).rand_between()` was incorrectly returning values
    between 2 and 11, there is only a 10% chance that the test would fail on each
    run.
  prefs: []
  type: TYPE_NORMAL
- en: We can safely assume that a standard library function such `random()` works
    correctly, so our unit test should really test whether our method correctly handles
    the number provided to it by `random()`. If we could temporarily replace `random()`
    with a function that returns a fixed value, it would be simple to test the correctness
    of our subsequent calculations.
  prefs: []
  type: TYPE_NORMAL
- en: The `unittest.mock` module provides us with the `Mock` class for this purpose.
    `Mock` objects can be used to predictably simulate the behavior of another class,
    method, or library. We can give our `Mock` objects return values, side effects,
    properties, methods, and other features needed to fake the behavior of another
    object, then drop it in place of that object before running our tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a fake `random()` function using `Mock` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The `Mock` object's `return_value` argument allows us to hard code a value to
    be returned whenever it's called as a function. Here,  `fakerandom` will always
    return `0.5`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can put `fakerandom` in place of `random()` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We start by saving a reference to `mycalc.random.random` before replacing it.
    Note that we're specifically replacing only the version of `random` being used
    in `mycalc.py` so that we don't affect `random` anywhere else. It's a best practice
    to be as specific as possible when patching libraries to avoid unforeseen side
    effects.
  prefs: []
  type: TYPE_NORMAL
- en: With `fakerandom` in place, we call our method and test the output. Because
    `fakerandom` will always return `0.5`, we know that the answer should be (0.5
    × 1 + 0)  or `0.5` when `a` is `1` and `b` is `0`. Any other value would indicate
    an error in our algorithm.  Last of all, we revert `random` to the original function
    so that other tests don't accidentally use the mock.
  prefs: []
  type: TYPE_NORMAL
- en: Having to store or revert the original library each time is an annoyance we
    can do without, so `unittest.mock` provides a cleaner approach using `patch`.
    The `patch` command can be used as either a context manager or a decorator, and
    either approach makes patching a `Mock` object into our code much cleaner.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using our mock `random()` using `patch` as a context manager looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '`The patch()` command takes an import path string and provides us with a `Mock`
    object that it has patched in. We can set methods and properties on the `Mock` object
    and run our actual tests in the block, and the patched library will be reverted
    when the block ends.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using `patch()` as a decorator is similar:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In this case, the mock object created by `patch` is passed as an argument to
    our test method and will remain patched for the duration of the decorated function.
  prefs: []
  type: TYPE_NORMAL
- en: Running multiple unit tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While we can run our unit tests by including a call to `unittest.main()` at
    the end, that approach doesn't scale well. As our application grows, we're going
    to write many test files, which we'll want to run in groups or all at once.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortunately, `unittest` can discover and run all tests in a project with one
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: So long as you have followed the recommended naming scheme of prefixing your
    test modules with `test_`, running this command in your project's root directory
    should run all your tests.
  prefs: []
  type: TYPE_NORMAL
- en: Testing Tkinter code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing Tkinter code presents us with a few particular challenges. First, Tkinter
    handles many callbacks and methods **asynchronously**, meaning that we can't count
    on the results of some code to be apparent immediately. Also, testing GUI behaviors
    often relies on external factors such as window management or visual cues that
    our tests cannot detect.
  prefs: []
  type: TYPE_NORMAL
- en: We're going to learn some tools and strategies that will help you craft tests
    for your Tkinter code.
  prefs: []
  type: TYPE_NORMAL
- en: Managing asynchronous code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Whenever you interact with a Tkinter UI—whether it's clicking a button, typing
    in a field, or raising a window, for example—the response is not executed immediately
    in-place. Instead, these actions are placed in a to-do list, called an **event
    queue**, to be handled later while your code execution continues. While these
    actions seem instant to users, test code cannot count on a requested action being
    completed before the next line of code.
  prefs: []
  type: TYPE_NORMAL
- en: 'To solve this problem, we can use these special widget methods that allow us
    to manage the event queue:'
  prefs: []
  type: TYPE_NORMAL
- en: '`wait_visibility()`: This method causes the program to wait until a widget
    is fully drawn on-screen before executing the next line of code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`update_idletasks()`: This method forces Tkinter to process any idle tasks
    currently outstanding on the widget. Idle tasks are low-priority tasks such as
    drawing and rendering.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`update()`: This method forces Tkinter to process all events which are outstanding
    on a widget, including calling callbacks, redraws, and geometry management. It
    includes everything that `update_idletasks()` does and more.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simulating user actions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When automating GUI tests, we may wish to know what happens when a user clicks
    on a certain widget, or types a certain keystroke. When these actions happen in
    the GUI, Tkinter generates an `Event` object for the widget and passes it to the
    event queue. We can do the same thing in code, using a widget's `event_generate()`
    method.
  prefs: []
  type: TYPE_NORMAL
- en: Specifying an event sequence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To create an event with `event_generate()`, we need to pass in an event sequence
    string, in the format `<EventModifier-EventType-EventDetail>`.
  prefs: []
  type: TYPE_NORMAL
- en: '**Event type** specifies the kind of event we''re sending, such as a keystroke,
    mouse click, windowing event, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Tkinter has around 30 event types, but you will typically only need to work
    with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Event types** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `ButtonPress` | Also `Button`, represents a mouse button click |'
  prefs: []
  type: TYPE_TB
- en: '| `ButtonRelease` | Represents lifting off a mouse button |'
  prefs: []
  type: TYPE_TB
- en: '| `KeyPress` | Also `Key`, represents pressing a keyboard key |'
  prefs: []
  type: TYPE_TB
- en: '| `KeyRelease` | Represents lifting off a keyboard key |'
  prefs: []
  type: TYPE_TB
- en: '| `FocusIn` | Represents giving focus to a widget |'
  prefs: []
  type: TYPE_TB
- en: '| `FocusOut` | Represents exiting a widget |'
  prefs: []
  type: TYPE_TB
- en: '| `Enter` | Represents the mouse cursor entering a widget |'
  prefs: []
  type: TYPE_TB
- en: '| `Leave` | Represents the mouse cursor moving off a widget |'
  prefs: []
  type: TYPE_TB
- en: '| `Configure` | Called when the widget''s configuration changes, either by
    a `.config()` call or user action (resize, for example) |'
  prefs: []
  type: TYPE_TB
- en: '**Event modifiers** are optional words that can alter the event type; for example,
    `Control`, `Alt`, and `Shift` can be used to indicate that one of those modifier
    keys is held down; `Double` or `Triple` can be used to indicate a double or triple
    click of the described button. Multiple modifiers can be strung together if required.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Event detail**, only valid for keyboard or mouse events, describes which
    key or button was pressed. For example, `<Button-1>` refers to the left mouse
    button, while `<Button-3>` refers to the right. For letter and number keys, the
    literal letter or number can be used; most symbols, however, are described by
    a word (`minus`, `colon`, `semicolon`, and so on) to avoid syntactic clashes.'
  prefs: []
  type: TYPE_NORMAL
- en: For button presses and key presses, the event type is technically optional;
    however, it's probably a good idea to leave it in for the sake of clarity. For
    example, `<1>` is a valid event, but does it refer to the left mouse button or
    typing the `1` key? You may be surprised to find that it's the mouse button.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table shows some examples of valid event sequences:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Sequence** | **Meaning** |'
  prefs: []
  type: TYPE_TB
- en: '| `<Double-Button-3>` | Double-clicking the right mouse button |'
  prefs: []
  type: TYPE_TB
- en: '| `<Alt-KeyPress-exclam>` | Holding `Alt` and typing an exclamation point |'
  prefs: []
  type: TYPE_TB
- en: '| `<Control-Alt-Key-m>` | Holding `Control` and `Alt` and pressing the `m`
    key |'
  prefs: []
  type: TYPE_TB
- en: '| `<KeyRelease-minus>` | Lifting off a pressed minus key |'
  prefs: []
  type: TYPE_TB
- en: In addition to the sequence, we can pass other arguments to `event_generate()`
    which describe various aspects of the event.  Many of these are redundant, but,
    in some cases, we need to provide extra information for the event to have any
    meaning; for example, mouse button events need to include the `x` and `y` arguments
    that specify the coordinates of the click.
  prefs: []
  type: TYPE_NORMAL
- en: Managing focus and grab
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Focus refers to the widget or window which is currently receiving keyboard input.
    Widgets can also grab focus, preventing mouse movements or keystrokes outside
    their bounds.
  prefs: []
  type: TYPE_NORMAL
- en: 'Tkinter gives us these widget methods for managing focus and grab, some of
    which are useful for running tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Method** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `focus_set()` | Focuses the widget whenever its window next gains focus |'
  prefs: []
  type: TYPE_TB
- en: '| `focus_force()` | Focuses a widget and the window it''s in, immediately |'
  prefs: []
  type: TYPE_TB
- en: '| `grab_set()` | The widget grabs all events for the application |'
  prefs: []
  type: TYPE_TB
- en: '| `grab_set_global()` | The widget grabs all screen events |'
  prefs: []
  type: TYPE_TB
- en: '| `grab_release()` | The widget relinquishes its grab |'
  prefs: []
  type: TYPE_TB
- en: In a test environment, we can use these methods to make sure that our generated
    keyboard and mouse events are going to the correct widget or window.
  prefs: []
  type: TYPE_NORMAL
- en: Getting widget information
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tkinter widgets have a set of `winfo_` methods that give us access to information
    about the widget. While this set of methods leaves much to be desired, it does
    provide a few methods we can use in tests to provide feedback about the state
    of a given widget.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are a few `winfo_` methods that we will find useful:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Method** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `winfo_height()`, `winfo_width()` | Get the height and width of the widget
    |'
  prefs: []
  type: TYPE_TB
- en: '| `winfo_children()` | Get a list of child widgets |'
  prefs: []
  type: TYPE_TB
- en: '| `winfo_geometry()` | Get the size and location of the widget |'
  prefs: []
  type: TYPE_TB
- en: '| `winfo_ismapped()` | Determine whether the widget is mapped, meaning it''s
    been added to a layout using `pack()` or `grid()`, for instance |'
  prefs: []
  type: TYPE_TB
- en: '| `winfo_viewable()` | Determine whether a widget is viewable, meaning it and
    all its parents have been mapped |'
  prefs: []
  type: TYPE_TB
- en: '| `winfo_x()`, `winfo_y()` | Get the `x` or `y` coordinate of the widget''s
    top left corner |'
  prefs: []
  type: TYPE_TB
- en: Writing tests for our application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's put our knowledge of `unittest` to work and write some tests for our application.
    To get started, we need to create a test module for our application. Make a directory
    called `test` inside the `abq_data_entry` package, and create the customary empty
    `__init__.py` file inside. We'll create all of our test modules inside this directory.
  prefs: []
  type: TYPE_NORMAL
- en: Testing our model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our `CSVModel` code is fairly self-contained apart from its need to read and
    write files. Since file operations are one of the more common things that need
    to be mocked out in a test, the `mock` module provides `mock_open`, a `Mock` subclass
    ready-made to replace Python's `open` method. When called, a `mock_open` object
    returns a `mock` file handle object, complete with support for the `read()`, `write()`,
    and `readlines()` methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s begin creating our test case class in `test/test_models.py` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The `mock_open` and `read_data` arguments allows us to specify a string that
    will be returned when its file handle is read. We've created two `mock_open` objects,
    one containing a CSV header and two lines of data, and the other containing nothing.
  prefs: []
  type: TYPE_NORMAL
- en: We've also created two `CSVModel` objects, one with a filename of `file1` and
    the other with a filename of `file2`. It's worth mentioning that there's no actual
    connection between our models and our `mock_open` objects. The choice of the `mock_open`
    object, rather than the filename, will determine what data will be returned
  prefs: []
  type: TYPE_NORMAL
- en: Testing file reading in get_all_records()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To see how we use these, let''s start a test for the `get_all_records()` method
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Since our filenames don't actually exist, we're using the decorator version
    of `patch` to patch `os.path.exists` with a mock function that always returns
    `True`. We can later change the `return_value` value if we want to test a scenario
    where the file doesn't exist.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run the `get_all_records()` method, we''ll use the context manager form
    of `patch()` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Any call to `open()` inside the `models.py` file which has been initiated inside
    the context manager block will be replaced by our `mock_open` object, and the
    file handle returned will contain `read_data` we specified. However, before we
    can go on, there's an unfortunate shortcoming in `mock_open` that we'll need to
    work around. While it implements most file methods, it doesn't implement the iterator
    methods that the `csv` library requires to read data from the file handler.
  prefs: []
  type: TYPE_NORMAL
- en: 'A slight alteration to our `models.py` code will fix this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Instead of simply passing `fh` into `DictReader`, we need to call `readlines()`
    and cast it to `list`. This won't affect the program in any way, but it will allow
    `mock_open()` to work correctly.
  prefs: []
  type: TYPE_NORMAL
- en: There's nothing wrong with making adjustments to your code to accommodate tests;
    in many cases, the code will even be better for it! However, if you make an unintuitive
    change such as the previous one, be sure to add a comment to your code to explain
    why. Otherwise, someone is likely to factor it out at some point in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can start making assertions about the records which have been returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Here, we're checking that `records` contains two lines (since our read data
    contained two `csv` records), that it's a `list` object, and that its first member
    is a `dict` object (or subclass of `dict`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s make sure all our fields made it through and that our Boolean
    conversion worked:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: By iterating a tuple of all our field names, we can check that all our fields
    are present in the record output.  Don't be afraid to use loops in a test this
    way to check a large amount of content quickly.
  prefs: []
  type: TYPE_NORMAL
- en: A `Mock` object can do more than just stand in for another class or function;
    it also has its own assertion methods that can tell us if it's been called, how
    many times, and with what arguments.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, we can check our `mock_open` object to make sure it was called
    with the expected arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '`assert_called_with()` takes a set of arguments and checks if the last call
    to the `mock` object used those arguments. We expected `file1_open` to be called
    with the filename `file1`, a mode of `r`, and an encoding of `utf-8`. By confirming
    that a mocked function was called with the correct arguments, and assuming the
    correctness of the real function (the built-in `open()` function, in this case),
    we can avoid having to test the actual outcome.'
  prefs: []
  type: TYPE_NORMAL
- en: Testing file saving in save_record()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To demonstrate how to test file-writing with `mock_open`, let''s test `save_record()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'To test the conversion from a `dict` to a `csv` string, we''ll need a sample
    record in both formats:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: You may be tempted to generate either the record or its expected output using
    code, but it's always better to stick to literals in tests; doing so makes the
    expectations of the test explicit and avoids logic errors in your tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'For our first scenario, let''s simulate writing to an empty but existing file
    by using `file2_open` and `model2` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Setting our `mock_exists.return_value` to `True` to tell our method that the
    file already exists, we then patch over `open()` with our second `mock_open` object
    and call the `save_record()` method. Since we passed in a record with no row number
    (which indicates a record insert), this should result in our code trying to open
    `file2` in append mode and writing in the CSV-formatted record.
  prefs: []
  type: TYPE_NORMAL
- en: '`assert_called_with()` will test that assumption as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '`file2_open` can tell us that it was called with the expected parameters, but
    how do we access its file handler so that we can see what was written to it?'
  prefs: []
  type: TYPE_NORMAL
- en: 'It turns out we can just call our `mock_open` object and retrieve the `mock`
    file handle object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Once we have the `mock` file handle (which is itself a `Mock`), we can run test
    methods on it to find out if it was called with the CSV data as expected. In this
    case, the file handle's `write` method should have been called with the CSV-format
    record string.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s do a similar set of tests, passing in a row number to simulate a record
    update:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Checking that our update was done correctly presents a problem: `assert_called_with()` only
    checks the last call made to the mock function. When we update our CSV file, the
    entire CSV file is updated, with one `write()` call per row. We can''t just check
    that the last call was correct; we need to make sure the `write()` calls for all
    the row*s* were correct. To accomplish this, `Mock` provides us with `assert_has_calls()`,
    to which we can pass a list of `Call` objects to compare against the object''s
    call history.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We create `Call` objects using the `mock.call()` function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The arguments to `call()` represent the arguments that were passed to the function
    call. The list of `Call` objects we pass to `assert_has_calls()` represents each
    call that should have been made to `write()` in order. The keyword argument `in_order`
    can also be set to `False`, in which case the order won't need to match. In this
    case, order matters, since a wrong order would result in a corrupt CSV file.
  prefs: []
  type: TYPE_NORMAL
- en: More tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing the remainder of the `CSVModel` class and the `SettingsModel` class
    methods should be essentially along the same lines as these two methods. A few
    more tests are included in the sample code, but see if you can come up with some
    of your own as well.
  prefs: []
  type: TYPE_NORMAL
- en: Testing our application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''ve implemented our application as a `Tk` object that acts not only as a
    main window but as a controller, patching together models and views defined elsewhere
    in the application. As you may expect, `patch()` is going to figure heavily into
    our testing code as we mock out all of those other components to isolate `Application`.
    Let''s take a look at how this is done:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In a new file called `test_application.py`, import `unittest` and `application`.
    Now start a test case as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Our `TestApplication` class will be using mocks in place of our data and settings
    models, so we've created some class properties to store samples of the data which `Application`
    expects to retrieve from those models. The `setUp()` method is going to patch
    out all the external classes with mocks, configure the mocked models to return
    our sample data, and then create an `Application` instance that our tests can
    use.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by using `patch()` as a context manager  to replace all the external
    resources as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Here, we've created a `with` block using five `patch()` context managers, one
    for each library we're mocking out. Notice that we're only creating aliases for
    the model mocks, since we'll want to do some extra configuration on them. The
    view mocks won't really need to do much except be imported or called, and we can
    access them as properties of our `Application` object anyway.
  prefs: []
  type: TYPE_NORMAL
- en: Since Python 3.2, you can create a block with multiple context managers by separating
    each context manager call with a comma. Unfortunately, you can't put them in parenthesis,
    so we're using the comparatively ugly escaped-newline method of breaking this
    gigantic call into multiple lines.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside the block, we''ll need to configure our model mocks to return the appropriate
    data as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we're instantiating our `settingsmodel` and `csvmodel` objects and
    configuring methods on the return values rather than the mocks themselves. Remember
    that our mocks are replacing the *classes*, not the *objects*, and it is the objects
    which will contain the methods our `Application` object will be calling. Therefore,
    we need to call them to access the actual `Mock` object that will be used by `Application`
    as the data or settings model.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike the actual class that it stands in for, a `Mock` object called as a function
    will return the same object every time it's called. Thus, we don't have to save
    a reference to the object created by calling a mocked class; we can just call
    the mocked class repeatedly to access that object. Note, however, that the `Mock`
    class will return a unique `Mock` object each time.
  prefs: []
  type: TYPE_NORMAL
- en: 'This takes care of our mocks, so let''s create an `Application` object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Because `Application` is a subclass of Tk, it''s a good idea for us to safely
    dispose of it after each use; even though we''re reassigning its variable name,
    it will go on existing and cause problems with our tests. To solve this, create
    a `tearDown()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Notice the call to `app.update()`. If we don't call this before destroying `app`
    , there may be tasks in the event queue that will try to access it after it's
    gone. This won't break our code, but it will clutter up our test output with error
    messages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that our fixtures are taken care of, let''s write a test:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '`Application.show_recordlist()` contains one line of code, which is merely
    a call to `recordlist.tkraise()`. Because we made `recordlist` a mock object,
    `tkraise` is also a mock object, and we can check to see that it was called. `assert_called()`
    merely checks that a method was called, without checking arguments, which is appropriate
    in this case because `tkraise()` takes none.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use a similar technique to check `populate_recordlist()` as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Under some circumstances, `get_all_records()` can raise an exception, in which
    case we''re supposed to show an error message box. But since we''ve mocked out
    our data model, how can we get it to raise an exception? The solution is to use
    mock''s `side_effect` property as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '`side_effect` can be used to simulate more complex functionality in a mocked
    callable. It can be set to a function, in which case the mock will run that function
    and return the results when called; it can be set to an iterable, in which case
    the mock will return the next item in the iterable each time it''s called; or,
    as in this case, it can be set to an exception, which will be raised when the
    mock is called.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we can use this, we''ll need to patch out `messagebox` as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: This time when we call `populate_recordlist()`, it throws an exception, prompting
    the method to call `messagebox.showerror()`. Since we've mocked `showerror()`,
    we can assert that it was called with the expected arguments.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Clearly, the hardest part of testing our `Application` object is patching in
    all the mocked components and making sure they behave enough like the real thing
    to satisfy `Application`. Once we've done that, writing the actual tests is fairly
    straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: Testing our widgets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we've done well with `patch`, `Mock`, and the default `TestCase`, but
    testing our widgets module is going to present some new challenges. To begin with,
    our widgets will need a `Tk` instance to be their root window. We can create this
    in each case's `setUp()` method, but this will slow down the tests considerably,
    and it isn't really necessary; our tests aren't going to modify the root window,
    so one root window will suffice for each test case. We can take advantage of the
    `setUpClass()` method to create a single instance of Tk just once at class instantiation.
    Secondly, we have a large number of widgets to test, which means we have a large
    number of test cases requiring the same boilerplate `Tk()` setup and tear down.
  prefs: []
  type: TYPE_NORMAL
- en: 'To address this, let''s start our `test_widgets.py` module with a custom `TestCase`
    class as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: The `setUpClass()` method creates the `Tk()` object and calls `wait_visibility()`
    just to make sure our window is visible before our tests start working with it.
    Just as we did with our `Application` test, we also supply a complimentary tear-down
    method that updates the Tk instance and destroys it.
  prefs: []
  type: TYPE_NORMAL
- en: Unit testing the ValidatedSpinbox widget
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`ValidatedSpinbox` is one of the more complicated widgets we created for our
    application, so it''s a good place to start writing tests.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Subclass the `TkTestCase` class to create a test case for `ValidatedSpinbox` as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Our setup method creates a variable in which to store the widget''s value,
    then creates an instance of the `ValidatedSpinbox` widget with some basic settings:
    a minimum value of -10, a maximum of 10, and an increment of 1\. After creating
    it, we pack it and wait for it to become visible. For our tear-down method, we
    simply destroy the widget.'
  prefs: []
  type: TYPE_NORMAL
- en: There are a couple of approaches we can take in testing our widget. The first
    approach is a unit testing-oriented approach, in which we focus on the actual
    method code, simply mocking out any external functionality.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try that with the `_key_validate()` method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: We're simply iterating from 0 to 9 and testing both the positive and negative
    of the number against `_key_validate()`, which should return `True` for all of
    these values. The `_key_validate()` method takes a lot of positional arguments,
    and most of them are redundant; it might be nice to have a wrapper method that
    makes it easier to call, since our test case is potentially going to call it dozens
    of times.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s call that method `key_validate()` and add it to our `TestValidatedSpinbox`
    class as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: This will make future calls to the method shorter and less error-prone.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use it now to test some invalid input as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: In the first example, we're entering `a`; in the second, `1` when `0.` is already
    in the box, resulting in `0.1`; in the third, `0` when `10` is in the box, resulting
    in `100`. All of these scenarios should fail the validation method.
  prefs: []
  type: TYPE_NORMAL
- en: Integration testing the ValidatedSpinbox widget
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the preceding tests, we weren't actually entering any data into the widget;
    we were simply calling the key validation method directly and evaluating its output.
    This is good unit testing, but it isn't quite satisfying as a test of this code.
    Since our custom widget is so deeply dependent on Tkinter's validation API, we'd
    like to test that we've actually implemented this API correctly. After all, that
    aspect of the code was more challenging than the actual logic in our validation
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: We can accomplish this by creating some integration tests that simulate actual
    user actions and then check the results of those actions. To do this cleanly,
    we'll first need to create some supporting methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by adding a new method to the `TkTestCase` class as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: This class will take a widget and a string and attempt to simulate a user typing
    the string into the widget. The first thing we do is force the focus to the widget;
    we need to use `focus_force()` because our test Tk window is unlikely to be in
    focus when the test is being run.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have focus, we'll iterate through the characters in the string and translate
    the raw character into the appropriate key symbols for our event sequence. Recall
    that some characters, particularly symbols, must be represented as strings, such
    as `minus` or `colon`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make this work, we''ll need a class property called `dict` to translate
    between characters and their key symbols as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: More key symbols can be found at [http://www.tcl.tk/man/tcl8.4/TkCmd/keysyms.htm](http://www.tcl.tk/man/tcl8.4/TkCmd/keysyms.htm)
    , but these should do for now.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once our character is translated to the appropriate key symbol, we can create
    our event sequences and generate our key events.  Back in the  `type_in_widget()`
    method, we can create and call a key event sequence as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Note that we call `self.root.update()` both before and after generating the
    keypress event. This ensures the widget is prepared for input, and that the inputs
    register after being generated. `update_idletasks()` will not do here, by the
    way; try it and you'll find that the tests will fail.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create a similar method for simulating mouse button clicks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Just as we did with our keystroke method, we first force focus, update the application,
    generate our events, then update again. In this method, however, we also need
    to specify the `x` and `y` coordinates for the mouse click. These are coordinates
    relative to the upper-left corner of the widget. We can also specify a button
    number, but we'll default to the left button (`1`).
  prefs: []
  type: TYPE_NORMAL
- en: 'With these methods in place, return to `TestValidatedSpinbox` and write a new
    test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: This method starts by clearing the widget, then simulates some valid input with
    `type_in _widget()` and checks that it was accepted by the widget. Note that in
    these integration tests we'll need to clear the widget each time because we are
    simulating keystrokes in an actual widget and triggering all the side effects
    of that action.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s test some invalid input by executing the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use our mouse click method to test the functionality of the `Spinbox`
    arrow buttons as well. To make this simpler, let''s create a helper method in
    our test case class to click on the arrow we want. Add this to `TestValidatedSpinbox`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'We can target the increment arrow by clicking `5` pixels from the right and
    `5` from the top of the widget. The decrement arrow can be found at `5` pixels
    from the right and `15` from the top. This may need some adjustment depending
    on the theme or screen settings, of course. Now, we can test our arrow key functionality
    easily as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: By setting the value of the widget, then clicking the appropriate arrow a specified
    number of times, we can test that the arrows did their jobs according to the rules
    of our widget class.
  prefs: []
  type: TYPE_NORMAL
- en: Testing our mixin class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One additional challenge we haven''t approached yet is testing our mixin class.
    Unlike our other widget classes, our mixin cannot really exist on its own: it
    depends on methods and properties found in the `ttk` widget which it''s combined
    with.'
  prefs: []
  type: TYPE_NORMAL
- en: One approach to testing this class would be to mix it with a `Mock` object which
    mocks out any inherited methods. This approach has merit, but a simpler (if less
    ideal) approach is to subclass it with the simplest possible `ttk` widget and
    test the resulting child class.
  prefs: []
  type: TYPE_NORMAL
- en: 'That approach looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Here, we've created just a basic child class using `ttk.Entry` and modified
    nothing else. Then, we created an instance of the class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s test our `_validate()` method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Because we're sending a key event to `_validate()`, it routes the request to
    `_key_validate()`, which simply returns `True` by default. We'll need to verify
    that `_validate()` does what is needed when `_key_validate()` returns `False`
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll employ `Mock` to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: We test that `False` is returned and that `_key_validate` was called with the
    correct arguments.
  prefs: []
  type: TYPE_NORMAL
- en: 'By updating the `event` value in `args`, we can check that `focusout` events
    also work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: We've taken an identical approach here, just mocking out `_focusout_validate()`
    to make it return `False`.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, once we've created our test class, testing `ValidatedMixin`
    is like testing any other widget class. There are other test method examples in
    the included source code; these should be enough to get you started with creating
    a complete test suite.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about automated testing and the capabilities provided
    by Python's `unittest` library. We wrote both unit tests and integration tests
    against portions of our application, and you learned methods for tackling a variety
    of testing challenges.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll upgrade our backend to use a relational database.
    You'll also learn about relational databases, SQL, and database normalization.
    You'll learn to work with the PostgreSQL database server and Python's `psycopg2`
    PostgreSQL interface library.
  prefs: []
  type: TYPE_NORMAL
