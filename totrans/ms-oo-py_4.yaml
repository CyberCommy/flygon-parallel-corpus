- en: Part 3. Testing, Debugging, Deploying, and Maintaining
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*[The Logging and Warning Modules](ch14.html "Chapter 14. The Logging and Warning
    Modules")*'
  prefs: []
  type: TYPE_NORMAL
- en: '*[Designing for Testability](ch15.html "Chapter 15. Designing for Testability")*'
  prefs: []
  type: TYPE_NORMAL
- en: '*[Coping with the Command Line](ch16.html "Chapter 16. Coping With the Command
    Line")*'
  prefs: []
  type: TYPE_NORMAL
- en: '*[Module and Package Design](ch17.html "Chapter 17. The Module and Package
    Design")*'
  prefs: []
  type: TYPE_NORMAL
- en: '*[Quality and Documentation](ch18.html "Chapter 18. Quality and Documentation")*'
  prefs: []
  type: TYPE_NORMAL
- en: Testing, Debugging, Deploying, and Maintaining
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Application development involves a number of skills beyond object-oriented
    designing and programming in Python. We''ll take a look at some additional topics
    that help us move from merely programming towards solving the user''s problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 14](ch14.html "Chapter 14. The Logging and Warning Modules"), *The
    Logging and Warning Modules*, will look at using the `logging` and `warnings`
    modules to create audit information as well as debugging. We''ll take a significant
    step beyond using the `print()` function. The `logging` module provides us with
    a number of features that allow us to produce audit, debug, and informational
    messages in a simple and uniform way. Because this is so highly configurable,
    we can provide useful debugging as well as verbose processing options.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We'll look at designing for testability and how we use `unittest` and `doctest`
    in [Chapter 15](ch15.html "Chapter 15. Designing for Testability"), *Designing
    for Testability*. Automated testing should be considered absolutely essential.
    No programming should be considered complete until there are automated unit tests
    that provide ample evidence to show us that the code works.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The command-line interface to our programs provides us with options and arguments.
    This applies mostly to small, text-oriented programs as well as long-running application
    servers. However, even a GUI application may use command-line options for configuration.
    [Chapter 16](ch16.html "Chapter 16. Coping With the Command Line"), *Coping with
    the Command Line*, will look at using the `argparse` module to parse options and
    arguments. We'll take this a step further and use the **Command** design pattern
    to create program components that can be combined and expanded without resorting
    to writing shell scripts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In [Chapter 17](ch17.html "Chapter 17. The Module and Package Design"), *The
    Module and Package Design*, we'll look at the module and package design. This
    is a higher-level set of considerations than the class design topics we've been
    looking at so far. Module and class design repeat strategies of Wrap, Extend,
    or Invent. Rather than looking at related data and operations, we're looking at
    related classes in a module and related modules in a package.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In [Chapter 18](ch18.html "Chapter 18. Quality and Documentation"), *Quality
    and Documentation*, we'll look at how we can document our design to create the
    trust that our software is correct and is properly implemented.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This part emphasizes ways to improve the quality of our software using these
    additional modules. Unlike the topics of [Part 1](pt01.html "Part 1. Pythonic
    Classes via Special Methods"), *Pythonic Classes via Special Methods* and [Part
    2](pt02.html "Part 2. Persistence and Serialization"), *Persistence and Serialization*
    these tools and techniques aren't narrowly focused on solving a particular problem.
    These topics are more broadly applicable to mastering object-oriented Python.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 14. The Logging and Warning Modules
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are some essential logging techniques that we can use both for debugging
    as well as operational support of an application. In particular, a good log can
    help demonstrate that an application meets its security and auditability requirements.
  prefs: []
  type: TYPE_NORMAL
- en: There are times when we'll have multiple logs with different kinds of information.
    We might separate security, audit, and debugging into separate logs. In some cases,
    we might want a unified log. We'll look at a few examples of doing this.
  prefs: []
  type: TYPE_NORMAL
- en: Our users may want verbose output to confirm that the program works correctly.
    This is different from the debugging output; end users are examining how the program
    solves their problem. They might, for example, want to change their inputs or
    process your program's outputs differently. Setting the verbosity level produces
    a log focused on the needs of users.
  prefs: []
  type: TYPE_NORMAL
- en: The `warnings` module can provide helpful information for developers as well
    as users. In the case of developers, we may use warnings to show you that an API
    has been deprecated. In the case of users, we might want to show you that the
    results are questionable but not—strictly speaking—erroneous. There might be questionable
    assumptions or possibly confusing default values that should be pointed out to
    users.
  prefs: []
  type: TYPE_NORMAL
- en: 'Software maintainers will need to enable logging to perform useful debugging.
    We rarely want *blanket* debugging output: the resulting log might be unreadably
    dense. We often need focused debugging to track down a specific problem so that
    we can revise the unit test cases and fix the software.'
  prefs: []
  type: TYPE_NORMAL
- en: In the case of trying to solve problems with a program that crashes, we might
    want to create a small circular queue to capture the last few events. We may be
    able to use this to isolate problems without having to filter through giant logfiles.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a basic log
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two necessary steps to logging:'
  prefs: []
  type: TYPE_NORMAL
- en: Get a `logging.Logger` instance with the `logging.getLogger()` function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create messages with that `Logger`. There are a number of methods with names
    such as `warn()`, `info()`, `debug()`, `error(),` and `fatal()` that create messages
    with different levels of importance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These two steps are not sufficient to give us any output, however. There's a
    third step that we take only when we need to see the output. Some logging is for
    debugging purposes, and seeing a log isn't always required. The optional step
    is to configure the `logging` module's handlers, filters, and formatters. We can
    use the `logging.basicConfig()` function for this.
  prefs: []
  type: TYPE_NORMAL
- en: It's technically possibly to even skip the first step. We can use the default
    logger that's part of the `logging` module's top-level functions. We showed you
    this in [Chapter 8](ch08.html "Chapter 8. Decorators and Mixins – Cross-cutting
    Aspects"), *Decorators and Mixins – Cross-cutting Aspects*, because the focus
    was on decoration, not logging. We advise you against using the default root logger.
    We'll need a little background to see why it's good to avoid using the root logger.
  prefs: []
  type: TYPE_NORMAL
- en: Instances of `Logger` are identified by name. The names are `.`-separated strings
    that form a hierarchy. There's a root logger with a name of `""`—the empty string.
    All other `Loggers` are children of this root `Logger`.
  prefs: []
  type: TYPE_NORMAL
- en: Because of this tree of named `Loggers`, we'll generally use the root `Logger`
    to configure the entire tree. We'll also use it when an appropriately named `Logger`
    can't be found. We'll only sow confusion if we also use the root `Logger` as the
    first class log for a particular module.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to a name, `Logger` can be configured with a list of handlers that
    determines where the messages are written and a list of `Filters` to determine
    which kinds of messages are passed or rejected. A logger is the essential API
    for logging: we use a logger to create `LogRecords`. These records are then routed
    to `Filters` and `Handlers`, where the passed records are formatted and eventually
    wind up getting stored in a local file or transmitted over a network.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The best practice is to have a distinct logger for each of our classes or modules.
    As `Logger` names are `.`-separated strings, the `Logger` names can parallel class
    or module names; our application''s hierarchy of component definitions will have
    a parallel hierarchy of loggers. We might have a class that starts like the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This will ensure the `Logger` object used for this class will have a name that
    matches the qualified name of the class.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a shared class-level logger
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As we noted in [Chapter 8](ch08.html "Chapter 8. Decorators and Mixins – Cross-cutting
    Aspects"), *Decorators and Mixins – Cross-cutting Aspects*, creating a class-level
    logger is made slightly cleaner by defining a decorator that creates the logger
    outside the class definition itself. Here''s the decorator that we defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This creates `logger` as a feature of the class, shared by all the instances.
    Now, we can define a class like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This will assure us that the class has the logger with the expected name. We
    can then use `self.logger` in the various methods with the confidence that it
    will be a valid instance of `logging.Logger`.
  prefs: []
  type: TYPE_NORMAL
- en: When we create an instance of `Player`, we're going to exercise the logger.
    By default, we won't see anything. The initial configuration for the `logging`
    module doesn't include a handler or a level that produces any output. We'll need
    to change the `logging` configuration to see anything.
  prefs: []
  type: TYPE_NORMAL
- en: The most important benefit of the way the `logging` module works is that we
    can include logging features in our classes and modules without worrying about
    the overall configuration. The default behavior will be silent and introduce very
    little overhead. For this reason, we can always include logging features in every
    class that we define.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the loggers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are two configuration details that we need to provide to see the output
    in our logs:'
  prefs: []
  type: TYPE_NORMAL
- en: The logger we're using needs to be associated with a handler that produces conspicuous
    output
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The handler needs a logging level that will pass our logging messages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `logging` package has a variety of configuration methods. We'll show you
    `logging.basicConfig()` here. We'll take a look at `logging.config.dictConfig()`
    separately.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `logging.basicConfig()` method permits a few parameters to create a single
    `logging.handlers.StreamHandler` for logging the output. In many cases, this is
    all we need:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This will configure a `StreamHandler` instance that will write to `sys.stderr`.
    It will pass messages that have a level that is greater than or equal to the given
    level. By using `logging.DEBUG`, we're assured of seeing all the messages. The
    default level is `logging.WARN`.
  prefs: []
  type: TYPE_NORMAL
- en: 'After performing this configuration, we''ll see our debugging messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The default format shows us the level (`DEBUG`), the name of the logger (`Player`),
    and the string that we produced. There are more attributes in `LogRecord` that
    can be shown. Often, this default format is acceptable.
  prefs: []
  type: TYPE_NORMAL
- en: Starting up and shutting down the logging system
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `logging` module is defined in a way that avoids manually managing the global
    state information. The global state is handled within the `logging` module. We
    can write applications in separate parts and be well assured that those components
    will cooperate properly through the `logging` interface. We can, for example,
    include `logging` in some modules and omit it entirely from other modules without
    worrying about the compatibility or configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Most importantly, we can include logging requests throughout an application
    and never configure any handlers. The top-level main script can omit `import logging`
    entirely. In this case, there will be no errors or problems from the logging code.
  prefs: []
  type: TYPE_NORMAL
- en: Because of the decentralized nature of logging, it's easy to configure it just
    once at the top level of an application. We should only configure `logging` inside
    the `if __name__ == "__main__":` portion of an application. We'll look at this
    in more detail in [Chapter 16](ch16.html "Chapter 16. Coping With the Command
    Line"), *Coping with the Command Line*.
  prefs: []
  type: TYPE_NORMAL
- en: Many of our logging handlers involve buffering. For the most part, the buffers
    will flush in the normal course of events. While we can ignore how logging shuts
    down, it's slightly more reliable to use `logging.shutdown()` to be sure that
    all the buffers are flushed to the devices.
  prefs: []
  type: TYPE_NORMAL
- en: 'When handling top-level errors and exceptions, we have two explicit techniques
    to ensure all buffers are written. One technique is to use a `finally` clause
    on a `try:` block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This example shows us how we configure `logging` as early as possible and shut
    down `logging` as late as possible. This ensures as much of the application as
    possible is properly bracketed by properly configured loggers. This includes an
    exception logger; in some applications, the `main()` function handles all exceptions,
    making the except clause here redundant.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another approach is to include an `atexit` handler to shut down `logging`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This version shows us how to use the `atexit` handler to invoke `logging.shutdown()`.
    When the application exits, the given function will be called. If the exceptions
    are properly handled inside the `main()` function, the `try:` block can be replaced
    with much simpler `status= main(); sys.exit(status)`.
  prefs: []
  type: TYPE_NORMAL
- en: There's a third technique that uses a context manager to control logging. We'll
    look at that alternative in [Chapter 16](ch16.html "Chapter 16. Coping With the
    Command Line"), *Coping with the Command Line*.
  prefs: []
  type: TYPE_NORMAL
- en: Naming the loggers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are four common use cases for using `logging.getLogger()` to name our
    `Loggers`. We often pick names to parallel our application''s architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Module names**: We might have a module global `Logger` instance for modules
    that contain a large number of small functions or classes for which a large number
    of objects are created. When we extend `tuple`, for example, we don''t want a
    reference to `Logger` in each instance. We''ll often do this globally, and usually
    this logger creation is kept close to the front of the module. In this example,
    right after the imports:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**Object instances**: This is shown previously, when we created `Logger` in
    the `__init__()` method. This `Logger` will be unique to the instance; using only
    a qualified class name might be misleading, because there will be multiple instances
    of the class. A better design is to include a unique instance identifier in the
    logger''s name:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '**Class names**: This is shown previously, when we defined a simple decorator.
    We can use `__class__.__qualname__` as the `Logger` name and assign `Logger` to
    the class as a whole. It will be shared by all instances of the class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Function names**: For small functions that are used frequently, we''ll often
    use a module-level log, shown previously. For larger functions that are rarely
    used, we might create a log within the function:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The idea here is to be sure that our `Logger` names match our software architecture.
    This provides us with the most transparent logging, simplifying debugging.
  prefs: []
  type: TYPE_NORMAL
- en: 'In some cases, however, we might have a more complex collection of `Loggers`.
    We might have several distinct types of informational messages from a class. Two
    common examples are financial audit logs and security access logs. We might want
    several parallel hierarchies of `Loggers`: one with names that start with `audit.`
    and another with names that start with `security.`. A class might have the more
    specialized `Loggers` with names such as `audit.module.Class` or `security.module.Class`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Having multiple logger objects available in a class allows us to finely control
    the kinds of output. We can configure each `Logger` to have different `handlers`.
    We'll use the more advanced configurations in the following section to direct
    the output to different destinations.
  prefs: []
  type: TYPE_NORMAL
- en: Extending the logger levels
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `logging` module has five predefined levels of importance. Each level has
    a global variable (or two) with the level number. The level of importance represents
    a spectrum of optionality from debugging messages (rarely important enough to
    show) to critical or fatal errors (always important).
  prefs: []
  type: TYPE_NORMAL
- en: '| Logging module variable | Value |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `DEBUG` | `10` |'
  prefs: []
  type: TYPE_TB
- en: '| `INFO` | `20` |'
  prefs: []
  type: TYPE_TB
- en: '| `WARNING or WARN` | `30` |'
  prefs: []
  type: TYPE_TB
- en: '| `ERROR` | `40` |'
  prefs: []
  type: TYPE_TB
- en: '| `CRITICAL or FATAL` | `50` |'
  prefs: []
  type: TYPE_TB
- en: We can add additional levels for even more nuanced control over what messages
    are passed or rejected. For example, some applications support multiple levels
    of verbosity. Similarly, some applications include multiple levels of debugging
    details.
  prefs: []
  type: TYPE_NORMAL
- en: For ordinary silent output, we might set the logging level to `logging.WARNING`
    so that only warnings and errors are shown. For the first level of verbosity,
    we can set the level of `logging.INFO` to see informational messages. For the
    second level of verbosity, we might want to add a level with a value of 15 and
    set the root logger to include this new level.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use this to define our new level of verbose messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use our new levels via the `Logger.log( )` method, which takes the level
    number as an argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: While there's little overhead to add levels such as this, they can be overused.
    The subtlety is that a level conflates multiple concepts—visibility and erroneous
    behavior—into a single numeric code. The levels should be confined to a simple
    visibility or error spectrum. Anything more complex must be done via the `Logger`
    names or the actual `Filter` objects.
  prefs: []
  type: TYPE_NORMAL
- en: Defining handlers for multiple destinations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We have several use cases to send the log output to multiple destinations,
    which are shown in the following bullet list:'
  prefs: []
  type: TYPE_NORMAL
- en: We might want duplicate logs to improve the reliability of operations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We might be using the sophisticated `Filter` objects to create distinct subsets
    of messages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We might have different levels for each destination. We can use this to separate
    debugging messages from informational messages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We might have different handlers based on the `Logger` names to represent different
    foci.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of course, we can also combine these to create quite complex scenarios. In order
    to create multiple destinations, we must create multiple `Handlers`. Each `Handler`
    might contain a customized `Formatter`; it can contain an optional level, and
    an optional list of filters that can be applied.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have multiple `Handlers`, we can bind `Loggers` to the desired `Handlers`.
    The `Loggers` form a proper hierarchy; this means we can bind `Loggers` to `Handlers`
    using high-level or low-level names. As `Handlers` have a level filter, we can
    have multiple handlers that will show us different groups of messages based on
    the level. Also, we can explicitly use the `Filter` objects if we need even more
    sophisticated filtering.
  prefs: []
  type: TYPE_NORMAL
- en: While we can configure this through the `logging` module API, it's often more
    clear to define most of the logging details in a configuration file. One elegant
    way to handle this is to use the YAML notation for a configuration dictionary.
    We can then load the dictionary with a relatively straightforward use of `logging.config.dictConfig(yaml.load(somefile))`.
  prefs: []
  type: TYPE_NORMAL
- en: The YAML notation is somewhat more compact than the notation accepted by `configparser`.
    The documentation for `logging.config` in *Python Standard Library* uses YAML
    examples because of their clarity. We'll follow this pattern.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example of a configuration file with two handlers and two families
    of loggers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We defined two handlers: `console` and `audit_file`. The `console` is `StreamHandler`
    that is sent to `sys.stderr`. Note that we have to use a URI-style syntax of `ext://sys.stderr`
    to name an *external* Python resource. In this context, external means external
    to the configuration file. The default assumption is that the value is a simple
    string, not a reference to an object. The `audit_file` is `FileHandler` that will
    write to a given file. By default, files are opened with a mode of `a` to append.'
  prefs: []
  type: TYPE_NORMAL
- en: We also defined the formatter, named `basic`, to produce the log format that
    we get from `basicConfig()`. If we don't use this, our messages will use a slightly
    different default format that only has the message text.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we defined two top-level loggers: `verbose` and `audit`. The `verbose`
    instance will be used by all the loggers that have a top-level name of `verbose`.
    We can then use a `Logger` name such as `verbose.example.SomeClass` to create
    an instance that is a child of `verbose`. Each logger has a list of handlers;
    in this case, there''s just one element in each list. Additionally, we''ve specified
    the logging level for each logger.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s how we can load this configuration file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We parsed the YAML text into `dict` and then used the `dictConfig()` function
    to configure the logging with the given dictionary. Here are some examples of
    getting loggers and writing messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: We created two `Logger` objects, one under the `verbose` family tree and the
    other under the `audit` family tree. When we write to the `verbose` logger, we'll
    see the output on the console. When we write to the `audit` logger, however, we'll
    see nothing on the console; the record will go to the file that is named in the
    configuration.
  prefs: []
  type: TYPE_NORMAL
- en: When we look at the `logging.handlers` module, we see a large number of handlers
    that we can leverage. By default, the `logging` module uses older-looking `%`
    style formatting specifications. These are not like the format specifications
    for the `str.format()` method. When we defined our formatter parameters, we used
    the `{` style formatting, which is consistent with `str.format()`.
  prefs: []
  type: TYPE_NORMAL
- en: Managing the propagation rules
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The default behavior for `Loggers` is for a logging record to propagate from
    the named `Logger` up through all parent-level `Loggers` to the root `Logger`.
    We may have lower-level `Loggers` that have special behaviors and a root `Logger`
    that defines the default behavior for all `Loggers`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because logging records propagate, a root-level logger will *also* handle any
    log records from the lower-level `Loggers` that we define. If child loggers produce
    output and allow propagation, this will lead to duplicated output: first from
    the child and then from the parent. If we want to avoid duplication when child
    loggers produce output, we must turn the propagation off for the lower-level logger.'
  prefs: []
  type: TYPE_NORMAL
- en: Our previous example does not configure a root-level `Logger`. If some part
    of our application creates the logger with a name that doesn't start with `audit.`
    or `verbose.`, then that additional logger won't be associated with `Handler`.
    Either we need more top-level names or we need to configure a catch-all, root-level
    logger.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we add a root-level logger to capture all these other names, then we have
    to be careful about the propagation rules. Here''s a modification to the configuration
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We turned the propagation off for the two lower-level loggers: `verbose` and
    `audit`. We added a new root-level logger. As this logger has no name, this is
    done as a separate top-level dictionary named `root:` in parallel with the `loggers:`
    entry.'
  prefs: []
  type: TYPE_NORMAL
- en: If we didn't turn the propagation off in the two lower-level loggers, each `verbose`
    or `audit` record would have been handled twice. In the case of an audit log,
    the double handling may actually be desirable. The audit data would go to the
    console as well as the audit file.
  prefs: []
  type: TYPE_NORMAL
- en: What's important about the `logging` module is that we don't have to make any
    application changes to refine and control the logging. We can do almost anything
    required through the configuration file. As YAML is a relatively elegant notation,
    we can encode a lot of capability very simply.
  prefs: []
  type: TYPE_NORMAL
- en: Configuration gotcha
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `basicConfig()` method of logging is careful about preserving any loggers
    created before the configuration is made. The `logging.config.dictConfig()` method,
    however, has the default behavior of disabling any loggers created prior to configuration.
  prefs: []
  type: TYPE_NORMAL
- en: When assembling a large and complex application, we may have module-level loggers
    that are created during the `import` process. The modules imported by the main
    script can potentially create loggers before `logging.config` is created. Also,
    any global objects or class definitions might have loggers created prior to the
    configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'We often have to add a line such as this to our configuration file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This will ensure all the loggers created prior to the configuration will still
    propagate to the root logger created by the configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Specializing logging for control, debug, audit, and security
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are many kinds of logging; we''ll focus on these four varieties:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Errors and Control**: Basic error and control of an application leads to
    a main log that helps users confirm that the program really is doing what it''s
    supposed to do. This would include enough error information with which the users
    can correct their problems and rerun the application. If a user enables verbose
    logging, it will amplify this main error and control the log with additional user-friendly
    details.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Debugging**: This is used by developers and maintainers; it can include rather
    complex implementation details. We''ll rarely want to enable *blanket* debugging,
    but will often enable debugging for specific modules or classes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Audit**: This is a formal confirmation that tracks the transformations applied
    to data so we can be sure that processing was done correctly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security**: This can be used to show us who has been authenticated; it can
    help confirm that the authorization rules are being followed. It can also be used
    to detect some kinds of attacks that involve repeated password failures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We often have different formatting and handling requirements for each of these
    kinds of logs. Also, some of these are enabled and disabled dynamically. The main
    error and control log is often built from the non-DEBUG messages. We might have
    an application with a structure like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We created a logger with a name that matches the class qualified name (`Main`).
    We've written informational messages to this logger to show you that our application
    started normally and finished normally. In this case, we used `Counter` to accumulate
    some balance information that can be used to confirm that the right amount of
    data was processed.
  prefs: []
  type: TYPE_NORMAL
- en: 'In some cases, we''ll have more formal balance information displayed at the
    end of the processing. We might do something like this to provide a slightly easier-to-read
    display:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This version will show us the keys and values on separate lines in the log.
    The errors and control log often uses the simplest formats; it might show us just
    the message text with little or no additional context. A logging `Formatter` object
    like this might be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This configures `formatter` to show us the level name (`INFO`, `WARNING`, `ERROR`,
    `CRITICAL`) along with the message text. This eliminates a number of details,
    providing just the essential facts for the benefit of the users. We've called
    the formatter `control`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, we have associated the control formatter with the console
    handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This will use `control` `formatter` with the `console` `handler`.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a debugging log
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A debugging log is usually enabled by a developer to monitor a program under
    development. It's often narrowly focused on specific features, modules, or classes.
    Consequently, we'll often enable and disable loggers by name. A configuration
    file might set the level of a few loggers to `DEBUG`, leaving others at `INFO,`
    or possibly even a `WARNING` level.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll often design debugging information into our classes. Indeed, we might
    use the debugging ability as a specific quality feature for a class design. This
    may mean introducing a rich set of logging requests. For example, we might have
    a complex calculation for which the class state is essential information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: In this class definition, we created a `_state()` method that exposes the relevant
    internal state. This method is only used to support debugging. We've avoided using
    `self.__dict__` because this often has too much information to be helpful. We
    can then audit the changes to this state information in several places in our
    method functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Debugging output is often selectively enabled by editing the configuration
    file to enable and disable debugging in certain places. We might make a change
    such as this to the logging configuration file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We identified the logger for a particular class based on the qualified name
    for the class. This example assumes there's a handler named `console` already
    defined. Also, we've turned off the propagation to prevent the debugging messages
    from being duplicated into the root logger.
  prefs: []
  type: TYPE_NORMAL
- en: Implicit in this design is the idea that debugging is not something we want
    to simply enable from the command line via a simplistic `-D` option or a `--DEBUG`
    option. To perform effective debugging, we'll often want to enable selected loggers
    via a configuration file. We'll look at command-line issues in [Chapter 16,](ch16.html
    "Chapter 16. Coping With the Command Line") *Coping with the Command Line*.
  prefs: []
  type: TYPE_NORMAL
- en: Creating audit and security logs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Audit and security logs are often duplicated between two handlers: the main
    control handler plus a file handler that is used for audit and security reviews.
    This means we''ll do the following things:'
  prefs: []
  type: TYPE_NORMAL
- en: Define additional loggers for the audit and security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define multiple handlers for these loggers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optionally, define additional formats for the audit handler
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As shown previously, we'll often create separate hierarchies of the `audit`
    or `security` logs. Creating separate hierarchies of loggers is considerably simpler
    than trying to introduce audit or security via a new logging level. Adding new
    levels is challenging because the messages are essentially `INFO` messages; they
    don't belong on the `WARNING` side of `INFO` because they're not errors, nor do
    they belong on the `DEBUG` side of `INFO` because they're not optional.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a decorator that can be used to build a class that includes auditing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'This creates two loggers. One logger has a name simply based on the qualified
    name of the class. The other logger uses the qualified name, but with a prefix
    that puts it in the `audit` hierarchy. Here''s how we can use this decorator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We created a class that will produce records on a logger in the `audit` hierarchy.
    We can configure logging to handle this additional hierarchy of loggers. We''ll
    look at the two handlers that we need:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The `console` handler has the user-oriented log entries that use the `basic`
    format. The `audit_file` handler uses a more complex formatter named `detailed`.
    Here are the two `formatters` referenced by these `handlers`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The `basic` format shows us just three attributes of the message. The `detailed`
    format rules are somewhat complex because the date formatting is done separate
    from the rest of the message formatting. The `datetime` module uses the `%` style
    formatting. We used the `{` style formatting for the overall message. Here are
    the two `Logger` definitions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: We defined a logger for the `audit` hierarchy. All the children of `audit` will
    write their messages to both `console Handler` as well as `audit_file Handler`.
    The root logger will define all the other loggers to use the console only. We'll
    now see two forms of the audit messages.
  prefs: []
  type: TYPE_NORMAL
- en: 'The console might contain lines like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The audit file might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: This duplication provides us with the audit information in the context of the
    main console log, plus a focused audit trail in a separate log that can be saved
    for later analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Using the warnings module
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Object-oriented development often involves performing a significant refactoring
    of a class or module. It''s difficult to get the API exactly right the very first
    time we write an application. Indeed, the design time required to get the API
    exactly right might get wasted: Python''s flexibility permits us great latitude
    in making changes as we learn more about the problem domain and the user''s requirements.'
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the tools that we can use to support the design evolution is the `warnings`
    module. There are two clear use cases for `warnings` and one fuzzy use case:'
  prefs: []
  type: TYPE_NORMAL
- en: To alert developers of the API changes, usually features that are deprecated
    or pending deprecation. The deprecation and pending deprecation warnings are silent
    by default. These messages are not silent when running the `unittest` module;
    this helps us ensure that we're making proper use of upgraded library packages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To alert the users about a configuration problem. For example, there might
    be several alternative implementations of a module: when the preferred implementation
    is not available, we might want to provide a warning that an optimal implementation
    is not being used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We might push the edge of the envelope by alerting users that the results of
    the computation may have other problems. There's a blurry spectrum of ways in
    which our applications can behave.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the first two use cases, we'll often use Python's `warnings` module to show
    you that there are correctable problems. For the third blurry use case, we might
    use the `logger.warn()` method to alert the user about the potential issues. We
    shouldn't rely on the `warnings` module for this, because the default behavior
    is to show a warning just once.
  prefs: []
  type: TYPE_NORMAL
- en: 'We may see any of the following behaviors in an application:'
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, our application finishes normally and everything works. The results
    are unambiguously valid.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An application produces warning messages but finishes normally; the warning
    messages mean that the results are not trustworthy. Any output files will be readable,
    but the quality or completeness may be questionable. This is potentially confusing
    to the users; we'll wander around in the morass of these specific kinds of ambiguities
    showing possible software problems with a warning section, in the following section.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An application may produce error messages but still come to an orderly conclusion.
    It is clear that the results are unambiguously erroneous and shouldn't be used
    for anything other than debugging. The `logging` module allows us to further subdivide
    this world of errors. A program that produces an error may still come to an orderly
    conclusion. We often use the `CRITICAL` (or `FATAL`) error message to indicate
    that the Python program may not have terminated properly and any output files
    are probably damaged. We often reserve the `CRITICAL` message for a top-level
    `try:` block.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An application might crash at the OS level. In this case, there may be no messages
    from Python's exception handling or logging. This, too, is very clear as there
    are no usable results.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This second sense of *questionable results* is not a good design. Using warnings—either
    via the `warnings` module or the `WARN` messages from `logging`—doesn't really
    help the users.
  prefs: []
  type: TYPE_NORMAL
- en: Showing API changes with a warning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When we change the API for one of our modules, packages, or classes, we can
    provide a handy marking via the `warnings` module. This will raise a warning in
    the method that is deprecated or is pending deprecation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'When we do this, any part of the application that uses `Player.bet()` will
    receive `DeprecationWarning`. By default, this warning is silent. We can, however,
    adjust the `warnings` filter to see the message, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This technique allows us to locate all of the places where our application must
    change because of an API change. If we have unit test cases with close to 100
    percent code coverage, this simple technique is likely to reveal all the uses
    of deprecated methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because this is so valuable for planning and managing software change, we have
    three ways to be sure that we see all of the warnings in our applications:'
  prefs: []
  type: TYPE_NORMAL
- en: The command-line `-Wd` option will set the action to `default` for all warnings.
    This will enable the normally silent deprecation warnings. When we run `python3.3
    -Wd`, we'll see all the deprecation warnings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using `unittest`, which always executes in the `warnings.simplefilter('default')`
    mode.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Including `warnings.simplefilter('default')` in our application program. This
    will also apply the `default` action to all warnings; it's equivalent to the `-Wd`
    command-line option.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Showing configuration problems with a warning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We may have multiple implementations for a given class or module. We'll often
    use a configuration file parameter to decide which implementation is appropriate.
    See [Chapter 13](ch13.html "Chapter 13. Configuration Files and Persistence"),
    *Configuration Files and Persistence*, for more information on this technique.
  prefs: []
  type: TYPE_NORMAL
- en: 'In some cases, however, an application may silently depend on whether or not
    other packages are part of the Python installation. One implementation may be
    optimal, and another implementation may be the fallback plan. A common technique
    is to try multiple `import` alternatives to locate a package that''s installed.
    We can produce warnings that show us the possible configuration difficulties.
    Here''s a way to manage this alternative implementation import:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: We tried one import for a module. If this fails, we'll try another import. We
    used an `if` statement to reduce the nesting of the exceptions. If there are more
    than two alternatives, nested exceptions can lead to a very complex-looking exception.
    By using extra `if` statements, we can flatten a long sequence of alternatives
    so that the exceptions aren't nested.
  prefs: []
  type: TYPE_NORMAL
- en: We can better manage this warning message by changing the class of the message.
    In the preceding code, this will be `UserWarning`. These are shown by default,
    providing the users with some evidence that the configuration is not optimal.
  prefs: []
  type: TYPE_NORMAL
- en: If we change the class to `ImportWarning`, it will be silent by default. This
    provides a normally silent operation in the cases where the choice of packages
    doesn't matter to the users. The typical developer's technique of running with
    the `-Wd` option will reveal the `ImportWarning` messages.
  prefs: []
  type: TYPE_NORMAL
- en: 'To change the class of the warning, we change the call to `warnings.warn()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: This changes the warning to a class that is silent by default. The message can
    still be visible to developers who should be using the `-Wd` option.
  prefs: []
  type: TYPE_NORMAL
- en: Showing possible software problems with a warning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The idea of warnings aimed at end users is a bit nebulous: did the application
    work or did it fail? What does a warning really mean? Is there something the user
    should do differently?'
  prefs: []
  type: TYPE_NORMAL
- en: Because of this potential ambiguity, warnings in the user interface aren't a
    great idea. To be truly usable, a program should either work correctly or should
    not work at all. When there's an error, the error message should include advice
    for the user's response to the problem. We shouldn't impose a burden on the user
    to judge the quality of the output and determine its fitness for purpose. We'll
    emphasize on this point.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A program should either work correctly or should not work at all*.*
  prefs: []
  type: TYPE_NORMAL
- en: One potential unambiguous use for end user warnings is to alert the user that
    the output is incomplete. An application may have a problem completing a network
    connection, for example. The essential results are correct, but one of the data
    sources didn't work properly.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are situations where the application is taking an action that is not
    what the user requested, and the output is valid and useful. In the case of a
    network problem, a default behavior was used instead of a behavior based on the
    network resources. Generally, replacing something faulty with something correct
    but not exactly what the user requested is a good candidate for a warning. This
    kind of warning is best done with `logging` at the WARN level, not with the `warnings`
    module. The warnings module produces one-time messages; we may want to provide
    more details to the user. Here''s how we might use a simple `Logger.warn()` message
    to describe the problem in the log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: If a timeout occurs, a warning message is written to the log and the program
    keeps running. The content of the resource will be set to an empty list. The log
    message will be written every time. A `warnings` module warning is ordinarily
    shown only once from a given location in the program and is suppressed after that.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced logging – the last few messages and network destinations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''ll look at two more advanced techniques that can help provide useful debugging
    information. The first of these is a *log tail*: this is a buffer of the last
    few log messages before some significant event. The idea is to have a small file
    that can be read to see the last few log messages before an application died.
    It''s a bit like having the OS `tail` command automatically applied to the full
    log output.'
  prefs: []
  type: TYPE_NORMAL
- en: The second technique uses a feature of the logging framework to send log messages
    through a network to a centralized log-handling service. This can be used to consolidate
    logs from a number of parallel web servers. We need to create both senders and
    receivers for the logs.
  prefs: []
  type: TYPE_NORMAL
- en: Building an automatic tail buffer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The log tail buffer is an extension to the `logging` framework. We''re going
    to extend `MemoryHandler` to slightly alter its behavior. The built-in behavior
    for `MemoryHandler` includes three use cases for writing: it will write to another
    `handler` when the capacity is reached; it will write any buffered messages when
    `logging` shuts down; most importantly, it will write the entire buffer when a
    message of a given level is logged.'
  prefs: []
  type: TYPE_NORMAL
- en: We'll change the first use case slightly. Instead of writing when the buffer
    is full, we'll remove just the oldest message, leaving the others in the buffer.
    The other two use cases will be left alone. This will have the effect of dumping
    the last few messages before the shutdown as well as dumping the last few messages
    before an error.
  prefs: []
  type: TYPE_NORMAL
- en: We'll often configure the memory handler to buffer messages until a message
    greater than or equal to the error level is logged. This will lead to dumping
    the buffer ending with the error.
  prefs: []
  type: TYPE_NORMAL
- en: To understand this example, it's important to locate your Python installation
    and review the `logging.handlers` module in detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'This extension to `MemoryHandler` will keep the last few messages, based on
    the defined capacity when the `TailHandler` class is created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: We extended `MemoryHandler` so that it will accumulate log messages up to the
    given capacity. When the capacity is reached, old messages will be removed as
    new messages are added. Note that we must lock the data structure to permit multithreaded
    logging.
  prefs: []
  type: TYPE_NORMAL
- en: If a message with an appropriate level is received, then the entire structure
    is emitted to the target handler. Usually, the target is `FileHandler`, which
    writes to a tail file for debugging and support purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, when `logging` shuts down, the final few messages will also be
    written to the tail file. This should indicate a normal termination that doesn't
    require any debugging or support.
  prefs: []
  type: TYPE_NORMAL
- en: Generally, we'd send `DEBUG` level messages to this kind of handler so that
    we have a great deal of detail surrounding a crash situation. The configuration
    should specifically set the level to `DEBUG` rather than allowing the level to
    default.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a configuration that uses this `TailHandler`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: The definition of `TailHandler` shows us several additional features of the
    `logging` configuration. It shows us class references as well as other elements
    of the configuration file.
  prefs: []
  type: TYPE_NORMAL
- en: We referred to a customized class definition in the configuration. A label of
    `()` specifies that the value should be interpreted as a module and class name.
    In this case, it is an instance of our `__main__.TailHandler` class. A label of
    `class` instead of `()` uses a module and class that are part of the `logging`
    package.
  prefs: []
  type: TYPE_NORMAL
- en: We referred to another logger that's defined within the configuration. The text
    `cgf://handlers.console` in the preceding configuration file refers to the `console`
    handler defined within the `handlers` section of this configuration file. For
    demonstration purposes, we've had the tail target `StreamHandler` that uses `sys.stderr`.
    As noted previously, an alternative design might be to use a `FileHandler` that
    targets a debugging file.
  prefs: []
  type: TYPE_NORMAL
- en: We created the `test` hierarchy of loggers that used our `tail` handler. The
    messages written to these loggers will be buffered and only shown on the error
    or shutdown.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a demonstration script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'We generated 20 messages prior to an error. Then, we generated 20 more messages
    before shutting down the logging and flushing the buffers. This will produce output
    like the following one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: The intermediate messages were silently dropped by the `tail` handler. As the
    capacity was set to five, the last five messages prior to an error (or shutdown)
    are displayed.
  prefs: []
  type: TYPE_NORMAL
- en: Sending logging messages to a remote process
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One high-performance design pattern is to have a cluster of processes that are
    being used to solve a single problem. We might have an application that is spread
    across multiple application servers or multiple database clients. For this kind
    of architecture, we often want a centralized log among all of the various processes.
  prefs: []
  type: TYPE_NORMAL
- en: One technique to create a unified log is to include accurate timestamps and
    then sort records from multiple logfiles into a single, unified log. This sorting
    and merging is extra processing that can be avoided by remotely logging from a
    number of concurrent producer processes to a single consumer process.
  prefs: []
  type: TYPE_NORMAL
- en: Our shared logging solution makes use of the shared queues from the `multiprocessing`
    module. For additional information on multiprocessing, see [Chapter 12](ch12.html
    "Chapter 12. Transmitting and Sharing Objects"), *Transmitting and Sharing Objects*.
  prefs: []
  type: TYPE_NORMAL
- en: 'There''s a three-step process to build a multiprocessing application:'
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, we'll create the shared queue object so that the logging consumer can
    apply filters to the messages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Secondly, we'll create the consumer process that gets the logging records from
    the queue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thirdly, we'll create the pool of source processes that do the real work of
    our application and produce logging records into the shared queue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `ERROR` and `FATAL` messages could provide immediate notification via an
    SMS or e-mail to concerned users. The consumer can also handle the (relatively)
    slow processing associated with rotating logfiles.
  prefs: []
  type: TYPE_NORMAL
- en: The overall parent application that creates the producers and consumers is roughly
    analogous to the Linux `init` program that starts the various OS-level processes.
    If we follow the `init` design pattern, then the parent application can monitor
    the various producer children to see if they crash, and it can either log the
    associated errors or even attempt to restart them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the definition of a consumer process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: This process is a subclass of `multiprocessing.Process`. We will start it with
    the `start()` method; the superclass will fork a subprocess that executes the
    `run()` method.
  prefs: []
  type: TYPE_NORMAL
- en: While the process is running, it will get the log records from the queue and
    then route them to a logger instance. In this case, we're going to create a special
    logger named with a parent name of `combined.`; this will be given each record
    from a source process.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we'll provide some counts based on the second word of each message.
    In this example, we've designed the applications so that the second word will
    be the process ID number from the message text. The counts will show us how many
    messages were processed correctly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a `logging` configuration file for this process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: We defined a simple console `Logger` with a basic format. We also defined the
    top-level of a hierarchy of loggers with names that begin with `combined.`. These
    loggers will be used to display the combined output of the various producers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the logging producer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: The producer doesn't do much in the way of configuration. It simply gets a logger
    to use the qualified class name and an instance identifier (`self.proc_id`). It
    sets the list of handlers to be just `QueueHandler` wrapped around the destination
    a `Queue` instance. The level of this logger is set to `INFO`.
  prefs: []
  type: TYPE_NORMAL
- en: We made `handler_class` an attribute of the class definition because we plan
    to change it. For the first example, it will be `logging.handlers.QueueHandler`.
    For a later example, we'll change to another class.
  prefs: []
  type: TYPE_NORMAL
- en: The process to actually do this work uses the logger to create log messages.
    These messages will be enqueued for processing by the centralized consumer. In
    this case, the process simply floods the queue with 102 messages as quickly as
    possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s how we can start the consumer and producers. We''ll show this in small
    groups of steps. First, we create the queue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'This queue is way too small to handle 10 producers blasting 102 messages in
    a fraction of a second. The idea of a small queue is to see what happens when
    messages are lost. Here''s how we start the consumer process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s how we start an array of producer processes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: As expected, 10 concurrent producers will overflow the queue. Each producer
    will receive a number of queues full of exceptions to show us that the messages
    were lost.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s how we cleanly finish the processing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: First, we wait for each producer process to finish and then rejoin the parent
    process. Then, we put a sentinel object into the queue so that the consumer will
    terminate cleanly. Finally, we wait for the consumer process to finish and join
    the parent process.
  prefs: []
  type: TYPE_NORMAL
- en: Preventing queue overrun
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The default behavior of the logging module puts messages into the queue with
    the `Queue.put_nowait()` method. The advantage of this is that it allows the producers
    to run without the delays associated with logging. The disadvantage of this is
    that messages will get lost if the queue is too small to handle the worst-case
    burst of logging messages.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have two choices to gracefully handle this burst of messages:'
  prefs: []
  type: TYPE_NORMAL
- en: We can switch from `Queue` to `SimpleQueue`. `SimpleQueue` has an indefinite
    size. As it has a slightly different API, we'll need to extend `QueueHandler`
    to use `Queue.put()` instead of `Queue.put_nowait()`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can slow down the producer in the rare case that the queue is full. This
    is a small change to `QueueHandler` to use `Queue.put()` instead of `Queue.put_nowait()`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Interestingly, the same API change works for both `Queue` and `SimpleQueue`.
    Here''s the change:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: We replaced the body of the `enqueue()` method to use a different method of
    `Queue`. Now, we can use `SimpleQueue` or `Queue`. If we use `Queue`, it will
    wait when the queue is full, preventing the loss of logging messages. If we use
    `SimpleQueue`, the queue will silently expand to hold all the messages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the revised producer class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: This class uses our new `WaitQueueHandler`. Otherwise, the producer is identical
    to the previous version.
  prefs: []
  type: TYPE_NORMAL
- en: The rest of the script to create `Queue` and start the consumer is identical.
    The producers are instances of `Log_Producer_2`, but otherwise, the script to
    start and join remains identical to the first example.
  prefs: []
  type: TYPE_NORMAL
- en: This variation runs more slowly, but never loses a message. We can improve the
    performance by creating a larger queue capacity. If we create a queue with a capacity
    of 1,020 messages, the performance is maximized for this example. Finding an optimal
    queue capacity requires careful experimentation.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We saw how to use the logging module with more advanced object-oriented design
    techniques. We created logs associated with modules, classes, instances, and functions.
    We used decorators to create logging as a consistent cross-cutting aspect across
    multiple class definitions.
  prefs: []
  type: TYPE_NORMAL
- en: We saw how to use the `warnings` module to show you that there's a problem with
    the configuration or the deprecated methods. We can use warnings for other purposes,
    but we need to be cautious about the overuse of warnings and creating murky situations
    where it's not clear whether the application worked correctly or not.
  prefs: []
  type: TYPE_NORMAL
- en: Design considerations and trade-offs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `logging` module supports auditability and debugging ability as well as
    some security requirements. We can use logging as a simple way to keep records
    of the processing steps. By selectively enabling and disabling logging, we can
    support developers who are trying to learn what the code is really doing when
    processing real-world data.
  prefs: []
  type: TYPE_NORMAL
- en: The `warnings` module supports debugging ability as well as maintainability
    features. We can use warnings to alert the developers about the API problems,
    configuration problems, and other potential sources of bugs.
  prefs: []
  type: TYPE_NORMAL
- en: 'When working with the `logging` module, we''ll often be creating large numbers
    of distinct loggers that feed a few `handlers`. We can use the hierarchical nature
    of the `Logger` names to introduce new or specialized collections of logging messages.
    There''s no reason why a class can''t have two loggers: one for audit and one
    for more general-purpose debugging.'
  prefs: []
  type: TYPE_NORMAL
- en: We can introduce new logging-level numbers, but this should be done reluctantly.
    The levels tend to conflate the developer focus (debug, info, warning) with user
    focus (info, error, fatal). There's a kind of spectrum of *optionality* from debug
    messages that are not required for fatal error messages, which should never be
    silenced. We might add a level for verbose information or possibly detailed debugging,
    but that's about all that should be done with levels.
  prefs: []
  type: TYPE_NORMAL
- en: The `logging` module allows us to provide a number of configuration files for
    different purposes. As developers, we may use a configuration file that sets the
    logging levels to `DEBUG` and enables specific loggers for modules under development.
    For final deployment, we can provide a configuration file that sets the logging
    levels to `INFO` and provides different handlers to support more formal audit
    or security review needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll include some thoughts from the *Zen of Python*:'
  prefs: []
  type: TYPE_NORMAL
- en: Errors should never pass silently.Unless explicitly silenced.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The `warnings` and `logging` module directly support this idea.
  prefs: []
  type: TYPE_NORMAL
- en: These modules are oriented more towards the overall quality than towards the
    specific solution of a problem. They allow us to provide consistency via fairly
    simple programming. As our object-oriented designs become larger and more complex,
    we can focus more on the problem being solved without wasting time on the infrastructure
    considerations. Further, these modules allow us to tailor the output to provide
    information needed by the developer or user.
  prefs: []
  type: TYPE_NORMAL
- en: Looking forward
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the following chapters, we take a look at designing for testability and how
    we use `unittest` and `doctest`. Automated testing is essential; no programming
    should be considered complete until there are automated unit tests that provide
    ample evidence to show us that the code works. We'll look at object-oriented design
    techniques that will make software easier to test.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 15. Designing for Testability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'High-quality programs have automated tests. We need to use everything at our
    disposal to be sure that our software works. The golden rule is this: *to be deliverable,
    the feature must have a unit test*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Without an automated unit test, the feature cannot be trusted to work and should
    not be used. According to Kent Beck, in *Extreme Programming Explained*:'
  prefs: []
  type: TYPE_NORMAL
- en: '"Any program feature without an automated test simply doesn''t exist."'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'There are two essential points regarding the automated testing of program features:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Automated**: This means that there''s no human judgment involved. The testing
    involves a script that compares actual responses to expected responses.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Features**: These are tested in isolation to be sure that they work separately.
    This is unit testing, where each "unit" has enough software to implement a given
    feature. Ideally, it''s a small unit such as a class. However, it can also be
    a larger unit such as a module or package.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python has two built-in testing frameworks, making it easy to write automated
    unit tests. We'll look at using both `doctest` and `unittest` for automating testing.
    We'll look at some of the design considerations required to make testing practical.
  prefs: []
  type: TYPE_NORMAL
- en: 'For more ideas, read about *Ottinger and Langr''s* **FIRST** properties of
    unit tests: **Fast**, **Isolated**, **Repeatable**, **Self-validating**, and **Timely**.
    For the most part, Repeatable and Self-validating require an automated test framework.
    Timely means that the test is written before the code under test. See [http://pragprog.com/magazines/2012-01/unit-tests-are-first](http://pragprog.com/magazines/2012-01/unit-tests-are-first).'
  prefs: []
  type: TYPE_NORMAL
- en: Defining and isolating units for testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As testing is essential, testability is an important design consideration. Our
    designs must also support testing and debugging because a class that merely appears
    to work is of no value. A class that has evidence that it works is much more valuable.
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, we'd like a hierarchy of testing. At the foundation is unit testing.
    Here, we test each class or function in isolation to be sure that it meets the
    contractual obligations of the API. Each class or function is a single unit under
    test. Above this comes integration testing. Once we know that each class and function
    works individually, we can test groups and clusters of classes. We can test whole
    modules and whole packages, too. After the integration tests work, we can look
    at the automated testing of the complete application.
  prefs: []
  type: TYPE_NORMAL
- en: This is not an exhaustive list of the types of tests. We can do performance
    testing or security vulnerability testing too. We'll focus, however, on automated
    unit testing because it is central to all applications. This hierarchy of testing
    reveals an important complexity. Test cases for an individual class or group of
    classes can be very narrowly defined. As we introduce more units into integration
    testing, the domain of inputs grows. When we attempt to test a whole application,
    the entire spectrum of human behavior becomes a candidate input; this includes
    shutting devices off mid-test, pulling out plugs, and pushing things off tables
    to see whether they still work after being dropped three feet onto a hardwood
    floor. The hugeness of the domain of behavior makes it difficult to *fully* automate
    application testing.
  prefs: []
  type: TYPE_NORMAL
- en: We'll focus on the things that are easiest to test automatically. Once the unit
    tests work, the larger, aggregate systems are more likely to work.
  prefs: []
  type: TYPE_NORMAL
- en: Minimizing the dependencies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When we design a class, we must also consider the network of dependencies around
    that class: classes on which it depends and classes that depend on it. In order
    to simplify testing a class definition, we need to isolate it from the surrounding
    classes.'
  prefs: []
  type: TYPE_NORMAL
- en: An example of this is the `Deck` class that depends on the `Card` class. We
    can easily test `Card` in isolation but, when we want to test a `Deck` class,
    we need to tease it away from the definition of `Card`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s one (of many) previous definitions of `Card` that we''ve looked at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: We can see that each of these classes has a straightforward inheritance dependency.
    Each class can be tested in isolation because there are only two methods and four
    attributes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can (mis-)design a `Deck` class to have some problematic dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: This design has two deficiencies. First, it's intimately bound to the three
    classes in the `Card` class hierarchy. We can't isolate `Deck` from `Card` for
    a standalone unit test. Second, it is dependent on the random number generator,
    making it difficult to create a repeatable test.
  prefs: []
  type: TYPE_NORMAL
- en: On the one hand, `Card` is a pretty simple class. We could test this version
    of `Deck` with `Card` left in place. On the other hand, we might want to reuse
    `Deck` with poker cards or pinochle cards that have different behaviors from Blackjack
    cards.
  prefs: []
  type: TYPE_NORMAL
- en: The ideal situation is to make `Deck` independent of any particular `Card` implementation.
    If we do this well, then we can not only test `Deck` independently of any `Card`
    implementation, but we can also use any combination of `Card` and `Deck` definitions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s our preferred method to separate one of the dependencies. We can use
    a factory function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: The `card()` function will build proper subclasses of `Card` based on the requested
    rank. This allows the `Deck` class to use this function instead of directly building
    instances of the `Card` class. We separated the two class definitions by inserting
    an intermediate function.
  prefs: []
  type: TYPE_NORMAL
- en: We have other techniques to separate the `Card` class from the `Deck` class.
    We can refactor the factory function to be a method of `Deck`. We can also make
    the class names a separate binding via class-level attributes or even initialization
    method parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example that avoids a factory function by using more complex bindings
    in the initialization method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: While this initialization is wordy, the `Deck` class isn't intimately bound
    to the `Card` class hierarchy or a specific, random number generator. For testing
    purposes, we can provide a random number generator that has a known seed. We can
    also replace the various `Card` class definitions with other classes (such as
    `tuple`) that can simplify our testing.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we'll focus on another variation of the `Deck` class. This
    will use the `card()` factory function. That factory function encapsulates the
    `Card` hierarchy bindings and the rules for separating card classes by rank into
    a single, testable location.
  prefs: []
  type: TYPE_NORMAL
- en: Creating simple unit tests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We'll create some simple unit tests of the `Card` class hierarchy and the `card()`
    factory function.
  prefs: []
  type: TYPE_NORMAL
- en: As the `Card` classes are so simple, there's no reason for overly sophisticated
    testing. It's always possible to err on the side of needless complication. An
    *unthinking* slog through a test-driven development process can make it seem as
    though we need to write a fairly large number of not very interesting unit tests
    for a class that only has a few attributes and methods.
  prefs: []
  type: TYPE_NORMAL
- en: It's important to understand that test-driven development is *advice*, not a
    natural law such as the conservation of mass. Nor is it a ritual that must be
    followed without thinking.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several schools of thought on naming test methods. We''ll emphasize
    a style of naming that includes describing a test condition and expected results.
    Here are three variations on this theme:'
  prefs: []
  type: TYPE_NORMAL
- en: We can use a two-part name separated by `_should_` such as `StateUnderTest_should_ExpectedBehavior`.
    We summarize the state and the response. We'll focus on names of this form.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can use a two-part name with `when_`, and `_should_` such as `when_StateUnderTest_should_ExpectedBehavior`.
    We still summarize the state and response, but we provide a little more syntax.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can use a three-part name, `UnitOfWork_StateUnderTest_ExpectedBehavior`.
    This incorporates the unit under test, which may be helpful for reading test output
    logs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more information, read [http://osherove.com/blog/2005/4/3/naming-standards-for-unit-tests.html](http://osherove.com/blog/2005/4/3/naming-standards-for-unit-tests.html).
  prefs: []
  type: TYPE_NORMAL
- en: It's possible to configure the `unittest` module to use different patterns for
    discovering test methods. We could change it to look for `when_`. To keep things
    simple, we'll rely on the built-in pattern of having test method names begin with
    `test`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This, for example, is a test of the `Card` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'We defined a test `setUp()` method that creates an object of the class that
    is under test. We also defined two tests on this object. As there''s no real interaction
    here, there''s no *state under test* in the test names: they''re simple universal
    behaviors that should always work.'
  prefs: []
  type: TYPE_NORMAL
- en: Some ask if this kind of test is excessive because there's more test than application
    code. The answer is *no*; this is not excessive. There's no law that says that
    there should be more application code than test code. Indeed, it doesn't make
    sense to compare the volumes of test with application code. Most importantly,
    even a tiny class definition can still have bugs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Simply testing the values of attributes doesn''t seem to test the processing
    in this class. There are two perspectives on testing attribute values, as shown
    in this example:'
  prefs: []
  type: TYPE_NORMAL
- en: The **black box** perspective means that we disregard the implementation. In
    this case, we need to test all of the attributes. The attributes could, for example,
    be properties, and they must be tested.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **white box** perspective means that we can examine the implementation details.
    When performing this style of testing, we can be a little more circumspect in
    deciding which attributes we test. The `suit` attribute, for example, doesn't
    deserve much testing. The `hard` and `soft` attributes, however, do require testing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more information, see [http://en.wikipedia.org/wiki/White-box_testing](http://en.wikipedia.org/wiki/White-box_testing)
    and [http://en.wikipedia.org/wiki/Black-box_testing](http://en.wikipedia.org/wiki/Black-box_testing).
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, we need to test the rest of the `Card` class hierarchy. We''ll just
    show you the `AceCard` test case. The `FaceCard` test case should be clear after
    this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: This test case also sets up a particular `Card` instance so that we can test
    the string output. It checks the various attributes of this fixed card.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a test suite
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It is often helpful to formally define a test suite. The `unittest` package
    is capable of discovering tests by default. When aggregating tests from multiple
    test modules, it''s sometimes better to create a test suite in every test module.
    If each module defines a `suite()` function, we can replace test discovery with
    importing the `suite()` functions from each module. Also, if we customize `TestRunner`,
    we must use a suite. We can execute our tests as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: We built a suite from our three `TestCases` class definitions and then provided
    that suite to a `unittest.TextTestRunner()` instance. We used the default `TestLoader`
    in `unittest`. This `TestLoader` examines a `TestCase` class to locate all the
    test methods. The value of `TestLoader.testMethodPrefix` is `test`, which is how
    test methods are identified within a class. Each method name is used by the loader
    to create a separate test object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using `TestLoader` to build test instances from appropriately named methods
    of `TestCase` is one of the two ways to use `TestCases`. In a later section, we''ll
    look at creating instances of `TestCase` manually; we won''t rely on `TestLoader`
    for these examples. We can run this suite like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll see output like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: The `TestLoader` class created two tests from each `TestCase` class. This gives
    us a total of six tests. The test names are the method names that begin with `test`.
  prefs: []
  type: TYPE_NORMAL
- en: Clearly, we have a problem. Our tests provide an expected result that our class
    definitions don't meet. We've got more development work to do for the `Card` classes
    in order to pass this simple suite of unit tests. The fix should be clear and
    we'll leave it as an exercise for the reader.
  prefs: []
  type: TYPE_NORMAL
- en: Including edge and corner cases
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When we move to testing the `Deck` class as a whole, we''ll need to have some
    things confirmed: that it produces all of the required `Cards` class, and that
    it actually shuffles properly. We don''t really need to test that it deals properly
    because we''re depending on the `list` and `list.pop()` method; as these are first-class
    parts of Python, they don''t require additional testing.'
  prefs: []
  type: TYPE_NORMAL
- en: We'd like to test the `Deck` class construction and shuffling, independently
    of any specific `Card` class hierarchy. As noted previously, we can use a factory
    function to make the two `Deck` and `Card` definitions independent. Introducing
    a factory function introduces yet more testing. Not a bad thing, considering the
    bugs previously revealed in the `Card` class hierarchy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a test of the factory function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'We didn''t test all 13 ranks, as 2 through 10 should all be identical. Instead,
    we followed this advice from *Boris Beizer*:'
  prefs: []
  type: TYPE_NORMAL
- en: '"Bugs lurk in corners and congregate at boundaries."'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The test cases involve the edge values for each card range. Consequently, we
    have test cases for the values 1, 2, 10, 11, and 13, as well as illegal values
    of 0 and 14\. We bracketed each range with the least value, the maximum value,
    one below the least value, and one above the maximum value.
  prefs: []
  type: TYPE_NORMAL
- en: When this is run, there will be problems reported by this test case too. One
    of the biggest problems will be an undefined exception, `LogicError`. This is
    simply a subclass of `Exception` that defines that the exception still isn't enough
    to get the test case to pass. The rest of the fix is left as an exercise for the
    reader.
  prefs: []
  type: TYPE_NORMAL
- en: Mocking dependencies for testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In order to test `Deck`, we have two choices to handle the dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mocking**: We can create a mock (or stand-in) class for the `Card` class
    and a mock `card()` factory function that produces the mock class. The advantage
    of using mock objects is that we create real confidence that the unit under test
    is free from workarounds in one class; this makes up for bugs in another class.
    A rare potential disadvantage is that we may have to debug the behavior of a super-complex
    mock class to be sure it''s a valid stand-in for a real class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integrating**: If we have a degree of trust that the `Card` class hierarchy
    works, and the `card()` factory function works, we can leverage these to test
    `Deck`. This strays from the high road of pure unit testing, in which all dependencies
    are excised for test purposes. It can work out well in practice, however, as a
    class that passes all its unit tests can be as trustworthy as a mock class. In
    the cases of very complex, stateful APIs, an application class may be more trustworthy
    than a mock. The disadvantage of this is that a broken foundational class will
    cause a large number of testing failures in all the classes that depend on it.
    Also, it''s difficult to make detailed tests of API conformance with non-mock
    classes. Mock classes can track the call history, making it possible to track
    the number of times it was called and the arguments used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `unittest` package includes the `unittest.mock` module that can be used
    to patch the existing classes for test purposes. It can also be used to provide
    complete mock class definitions.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we design a class, we must consider the dependencies that must be mocked
    for unit testing. In the case of `Deck`, we have three dependencies to mock:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Card class**: This class is so simple that we could create a mock for
    this class without basing it on an existing implementation. As the `Deck` class
    behavior doesn''t depend on any specific feature of `Card`, our mock object can
    be simple.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The card() factory**: This function needs to be replaced with a mock that
    we can use to determine if `Deck` makes proper calls to this function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The random.Random.shuffle() method**: To determine if the method was called
    with proper argument values, we can provide a mock that will track usage rather
    than actually doing any shuffling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here''s a version of `Deck` that uses the `card()` factory function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: This definition has two dependencies that are specifically called out as arguments
    to the `__init__()` method. It requires a random number generator, `random`, and
    a card factory, `card_factory`. It has suitable default values so that it can
    be used in an application very simply. It can also be tested by providing mock
    objects instead of the default objects.
  prefs: []
  type: TYPE_NORMAL
- en: We've included a `deal()` method that makes a change to the object by popping
    a card. If the deck is empty, the `deal()` method will raise a `DeckEmpty` exception.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a test case to show you that the deck is built properly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: We created two mocks in the `setUp()` method of this test case. The mock card
    factory function, `test_card`, is a `Mock` function. The defined return value
    is a `mock.sentinel` object instead of a `Card` instance. The sentinel is a unique
    object that allows us to confirm that the right number of instances was created.
    It's distinct from all other Python objects, so we can distinguish functions without
    proper `return` statements that return `None`.
  prefs: []
  type: TYPE_NORMAL
- en: We created an instance of the `random.Random()` generator, but we replaced the
    `shuffle()` method with a mock function that returns `None`. This provides us
    with an appropriate return value for the method and allows us to determine that
    the `shuffle()` method was called with the proper argument values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our test creates a `Deck` class with our two mock objects. We can then make
    a number of assertions about this `Deck` instance, `d`:'
  prefs: []
  type: TYPE_NORMAL
- en: 52 objects were created. These are expected to be 52 copies of `mock.sentinel`,
    showing us that only the factory function was used to create objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `shuffle()` method was called with the `Deck` instance as the argument.
    This shows us how a mock object tracks its calls. We can use `assert_called_with()`
    to confirm that the argument values were as required when `shuffle()` was called.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The factory function was called 52 times.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The factory function was called with a specific list of expected rank and suit
    values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is a small bug in the `Deck` class definition, so this test doesn't pass.
    The fix is left as an exercise for the reader.
  prefs: []
  type: TYPE_NORMAL
- en: Using more mocks to test more behaviors
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The preceding mock objects were used to test how a `Deck` class was built. Having
    52 identical sentinels makes it difficult to confirm that a `Deck` deals properly.
    We'll define a different mock to test the deal feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a second test case to ensure that the `Deck` class deals properly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: This mock for the card factory function uses the `side_effect` argument to `Mock()`.
    When provided with an iterable, this returns another value of the iterable each
    time it's called.
  prefs: []
  type: TYPE_NORMAL
- en: We mocked the `shuffle()` method to be sure that the cards aren't actually rearranged.
    We want them to stay in their original order so that our tests have a predictable
    expected value.
  prefs: []
  type: TYPE_NORMAL
- en: The first test (`test_deck_1_should_deal`) accumulates the results of dealing
    52 cards into a variable, `dealt`. It then asserts that this variable has the
    52 expected values from the original mock card factory.
  prefs: []
  type: TYPE_NORMAL
- en: The second test (`test_empty_deck_should_exception`) deals all of the cards
    from a `Deck` instance. However, it makes one more API request. The assertion
    is that the `Deck.deal()` method will raise the proper exception after dealing
    all of the cards.
  prefs: []
  type: TYPE_NORMAL
- en: Because of the relative simplicity of the `Deck` class, it's possible to combine
    both `TestDeckBuild` and `TestDeckDeal` into a single, more sophisticated mock.
    While that's possible with this example, it's neither essential, nor necessarily
    desirable to refactor the test cases to make them simpler. Indeed, too much simplification
    of tests may miss out on API features.
  prefs: []
  type: TYPE_NORMAL
- en: Using doctest to define test cases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `doctest` module provides us with a simpler form of testing than the `unittest`
    module. There are many cases where a simple interaction can be shown in the docstring
    and the test can be automated via `doctest`. This will combine the documentation
    and test cases into one tidy package.
  prefs: []
  type: TYPE_NORMAL
- en: The `doctest` cases are written into the docstring for a module, class, method,
    or function. A `doctest` case shows us the interactive Python prompt `>>>`, statements
    and responses. The `doctest` module contains an application that looks for these
    examples in docstrings. It runs the given examples and compares the expected results
    shown in the docstrings with the actual outputs.
  prefs: []
  type: TYPE_NORMAL
- en: For larger and more complex class definitions, this can be challenging. In some
    cases, we may find that simple, printable results are difficult to work with,
    and we need more sophisticated comparisons to be made available from `unittest`.
  prefs: []
  type: TYPE_NORMAL
- en: With careful design of an API, we can create a class that can be used interactively.
    If it can be used interactively, then a `doctest` example can be built from that
    interaction.
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, two attributes of a well-designed class are that it can be used interactively
    and it has `doctest` examples in the documentation strings. Many built-in modules
    contain `doctest` examples of the API. Many other packages that we might choose
    to download will also include `doctest` examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'With a simple function, we can provide documentation such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: We've defined a version of Ackermann's function that includes docstring comments
    that include five sample responses from interactive Python. The first sample output
    is the `import` statement, which should produce no output. The other four sample
    outputs show us the different values of the function.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the results are all correct. There's no hidden bug left as an
    exercise for the reader. We can run these tests with the `doctest` module. When
    run as a program, the command-line argument is the file that should be tested.
    The `doctest` program locates all docstrings and looks for interactive Python
    examples in those strings. It's important to note that the `doctest` documentation
    provides details on the regular expressions used to locate the strings. In our
    example, we added a hard-to-see blank line after the last `doctest` example to
    help the `doctest` parser.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can run `doctest` from the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'If everything is correct, this is silent. We can make it show us some details
    by adding the `-v` option:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: This will provide us with the details of each docstring parsed and each test
    case gleaned from the docstrings.
  prefs: []
  type: TYPE_NORMAL
- en: This will show us the various classes, functions, and methods without any tests
    as well as the components that have tests. This provides some confirmation that
    our tests were properly formatted in the docstrings.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, we have output that will not match interactive Python easily.
    In these cases, we may need to supplement the docstring with some annotations
    that modify how the test cases and expected results are parsed.
  prefs: []
  type: TYPE_NORMAL
- en: 'There''s a special comment string that we can use for more complex outputs.
    We can append any one of the following two commands to enable (or disable) the
    various kinds of directives that are available. The following is the first command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the second command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: There are a dozen modifications that we can make to how the expected results
    are handled. Most of them are rare situations regarding spacing and how actual
    and expected values should be compared.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `doctest` documentation emphasizes on the **Exact Match Principle**:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"doctest is serious about requiring exact matches in expected output."*'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If even a single character doesn't match, the test fails. You'll need to build
    flexibility into some of the expected outputs. If building in flexibility gets
    too complex, it's a hint that `unittest` might be a better choice.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some specific situations where expected and actual values of `doctest`
    won''t match easily:'
  prefs: []
  type: TYPE_NORMAL
- en: The dictionary key order is not guaranteed by Python. Use a construct such as
    `sorted(some_dict.items())` instead of `some_dict`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The method functions `id()` and `repr()` involve physical memory addresses;
    Python makes no guarantee that they will be consistent. If you show `id()` or
    `repr()`, use the `#doctest: +ELLIPSIS` directive and replace the ID or address
    with `...` in the sample output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Floating-point results may not be consistent across platforms. Always show floating-point
    numbers with formatting or rounding to reduce the number of digits to digits that
    are meaningful. Use `"{:.4f}".format(value)` or `round(value,4)` to ensure that
    insignificant digits are ignored.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A set order is not guaranteed by Python. Use a construct such as `sorted(some_set)`
    instead of `some_set`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The current date or time, of course, cannot be used, as that won't be consistent.
    A test that involves time or date needs to force a specific date or time, generally
    by mocking `time` or `datetime`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operating system details such as file sizes or timestamps are likely to vary
    and should not be used without ellipsis. Sometimes, it's possible to include a
    useful setup or teardown in the `doctest` script to manage OS resources. In other
    cases, mocking the `os` module is helpful.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These considerations mean that our `doctest` module may contain some additional
    processing that''s not simply a part of the API. We may have done something such
    as this at the interactive Python prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'This shows us the full output from a particular implementation. We can''t simply
    copy-and-paste this into a docstring; the floating-point results might differ.
    We''ll need to do something resembling the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: This is rounded to a value that should not vary between implementations.
  prefs: []
  type: TYPE_NORMAL
- en: Combining doctest and unittest
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There's a hook in the `doctest` module that will create a proper `unittest.TestSuite`
    from docstring comments. This allows us to use both `doctest` and `unittest` in
    a large application.
  prefs: []
  type: TYPE_NORMAL
- en: 'What we''ll do is create an instance of `doctest.DocTestSuite()`. This will
    build a suite from a module''s docstrings. If we don''t specify a module, the
    module that is currently running is used to build the suite. We can use a module
    such as the following one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: We built a suite, `suite5`, from the `doctest` strings in the current module.
    We used `unittest` `TextTestRunner` on this suite. As an alternative, we can combine
    the `doctest` suite with other `TestCases` to create a larger, more complete suite.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a more complete test package
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For larger applications, each application module can have a parallel module
    that includes `TestCases` for that module. This can form two parallel package
    structures: a `src` structure with the application module and a `test` structure
    with the test modules. Here are two parallel directory trees that show us the
    collections of modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: Clearly, the parallelism isn't exact. We don't usually have an automated unit
    test for `setup.py`. A well-designed `__main__.py` may not require a separate
    unit test, as it shouldn't have much code in it. We'll look at some ways to design
    `__main__.py` in [Chapter 16](ch16.html "Chapter 16. Coping With the Command Line"),
    *Coping with the Command Line*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create a top-level `test/all.py` module with a body that builds all
    of the tests into a single suite:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: We built a single suite, `all_tests`, from the suites within the other test
    modules. This provides us with a handy script that will run all of the tests that
    are available as part of the distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are ways to use the test discovery features of the `unittest` module
    to do this as well. We perform package-wide testing from the command line, with
    something resembling the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: This will use the default test discovery features of `unittest` to locate `TestCases`
    in the given files. This has the disadvantage of relying on shell script features
    rather than pure Python features. The wild-card file specification can sometimes
    make development more complex because incomplete modules might get tested.
  prefs: []
  type: TYPE_NORMAL
- en: Using setup and teardown
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are three levels of setup and teardown available for the `unittest` modules.
    Here are the three different kinds of testing scopes: method, class, and module.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Test case setUp() and tearDown() methods**: These methods ensure that each
    individual test method within a `TestCase` class has had a proper setup and teardown.
    Often, we''ll use the `setUp()` method to create the unit objects and any mock
    objects that are required. We don''t want to do something costly such as creating
    whole databases, as these methods are used before and after each test method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test case setUpClass() and tearDownClass() methods**: These methods perform
    a one-time setup (and teardown) around all the tests in a `TestCase` class. These
    methods bracket the sequence of `setUp()-testMethod()-tearDown()` for each method.
    This can be a good place to create and destroy the test data or a test schema
    inside a database.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Module setUpModule() and tearDownModule() functions**: These standalone functions
    provide us with a one-time setup before all of the `TestCase` classes in a module.
    This is a good place to create and destroy a test database as a whole before running
    a series of `TestCase` classes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We rarely need to define all of these `setUp()` and `tearDown()` methods. There
    are several testing scenarios that are going to be part of our design for testability.
    The essential difference between these scenarios is the degree of integration
    involved. As noted previously, we have three tiers in our testing hierarchy: isolated
    unit tests, integration tests, and overall application tests. There are several
    ways in which these tiers of testing work with the various setup and teardown
    features:'
  prefs: []
  type: TYPE_NORMAL
- en: '**No integration – no dependencies**: Some classes or functions have no external
    dependencies; they don''t rely on files, devices, other processes, or other hosts.
    Other classes have some external resources that can be mocked. When the cost and
    complexity of the `TestCase.setUp()` method are small, we can create the needed
    objects there. If the mock objects are particularly complex, a class-level `TestCase.setUpClass()`
    might be more appropriate to amortize the cost of recreating the mock objects
    over several test methods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Internal Integration – some dependencies**: Automated integration testing
    among classes or modules often involves more complex setup situations. We may
    have a complex class-level `setUpClass()` or even a module-level `setUpModule()`
    to prepare an environment for integration testing. When working with the database
    access layers in [Chapter 10](ch10.html "Chapter 10. Storing and Retrieving Objects
    via Shelve"), *Storing and Retrieving Objects via Shelve*, and [Chapter 11](ch11.html
    "Chapter 11. Storing and Retrieving Objects via SQLite"), *Storing and Retrieving
    Objects via SQLite*, we often perform integration testing that includes our class
    definitions as well as our access layer. This may involve seeding a test database
    or shelf with appropriate data for the tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**External Integration**: We may perform automated integration testing with
    larger and more complex pieces of an application. In these cases, we may need
    to spawn external processes or create databases and seed them with data. In this
    case, we may have `setUpModule()` to prepare an empty database for use by all
    of the `TestCase` classes in a module. When working with RESTful web services
    in [Chapter 12](ch12.html "Chapter 12. Transmitting and Sharing Objects"), *Transmitting
    and Sharing Objects*, or testing **Programming In The Large** (**PITL**) in [Chapter
    17](ch17.html "Chapter 17. The Module and Package Design"), *The Module and Package
    Design*, this approach could be helpful.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that the concept of unit testing does not define what the unit under test
    is. The *unit* can be a class, a module, a package, or even an integrated collection
    of software components. It merely needs to be isolated from its environment to
    be a unit under test.
  prefs: []
  type: TYPE_NORMAL
- en: When designing automated integration tests, it's important to be aware of the
    components to be tested. We don't need to test Python libraries; they have their
    own tests. Similarly, we don't need to test the OS. An integration test must focus
    on testing the code we wrote, not the code we downloaded and installed.
  prefs: []
  type: TYPE_NORMAL
- en: Using setup and teardown with OS resources
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In many cases, a test case may require a particular OS environment. When working
    with external resources such as files, directories, or processes, we may need
    to create or initialize them before a test. We may also need to remove the resources
    before a test. We may need to tear down these resources at the end of the test.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s assume that we have a function, `rounds_final()` that is supposed to
    process a given file. We need to test the function''s behavior in the rare case
    that the file doesn''t exist. It''s common to see `TestCases` with a structure
    such as the following one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: We have to handle the possible exception of trying to remove a file that doesn't
    exist in the first place. This test case has a `setUp()` method that ensures that
    the required file is missing. Once `setuUp()`ensures that the file is truly gone,
    we can execute the `rounds_final()` function with an argument of the missing file,
    "`p3_c15_sample.csv`". We expect this to raise a `FileNotFoundError` error.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that raising `FileNotFoundError` is a default behavior of Python''s `open()`
    method. This may not require testing at all. This leads to an important question:
    *why test a built-in feature*? If we''re performing black-box testing, we need
    to exercise all features of the external interface, including the expected default
    behaviors. If we''re performing white-box testing, we may need to test the exception-handling
    `try:` statement within the body of the `rounds_final()` function.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `p3_c15_sample.csv` filename is repeated within the body of the test. Some
    people feel that the DRY rule should apply even to the test code. There''s a limit
    to how much of this kind of optimization is valuable while writing tests. Here''s
    the suggestion:'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It's okay for test code to be brittle. If a small change to the application
    leads to test failures, this really is a good thing. Tests should value simplicity
    and clarity, not robustness, and reliability.
  prefs: []
  type: TYPE_NORMAL
- en: Using setup and teardown with databases
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When working with a database and ORM layer, we often have to create test databases,
    files, directories, or server processes. We may need to tear down a test database
    after the tests pass, to be sure that the other tests can run. We may not want
    to tear down a database after failed tests; we may need to leave the database
    alone so that we can examine the resulting rows to diagnose the test failures.
  prefs: []
  type: TYPE_NORMAL
- en: It's important to manage the scope of testing in a complex, multilayered architecture.
    Looking back at [Chapter 11](ch11.html "Chapter 11. Storing and Retrieving Objects
    via SQLite"), *Storing and Retrieving Objects via SQLite*, we don't need to specifically
    test the SQLAlchemy ORM layer or the SQLite database. These components have their
    own test procedures outside our application tests. However, because of the way
    the ORM layer creates database definitions, SQL statements, and Python objects
    from our code, we can't easily mock SQLAlchemy and hope that we've used it properly.
    We need to test the way our application uses the ORM layer without digressing
    into testing the ORM layer itself.
  prefs: []
  type: TYPE_NORMAL
- en: One of the more complex test case setup situations will involve creating a database
    and then populating it with appropriate sample data for the given test. When working
    with SQL, this can involve running a fairly complex script of SQL DDL to create
    the necessary tables and then another script of SQL DML to populate those tables.
    The associated teardown will be another complex SQL DDL script.
  prefs: []
  type: TYPE_NORMAL
- en: 'This kind of test case can become long-winded, so we''ll break it into three
    sections: a useful function to create a database and schema, the `setUpClass()`
    method, and the rest of the unit test.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the create-database function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: This builds a fresh database by dropping all of the tables associated with the
    ORM classes and recreating the tables. The idea is to ensure a fresh, empty database
    that conforms to the current design, no matter how much that design has changed
    since the last time the unit tests were run.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we built a SQLite database using a file. We can use the *in-memory*
    SQLite database feature to make the test run somewhat more quickly. The downside
    of using an in-memory database is that we have no persistent database file that
    we can use to debug failed tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s how we use this in a `TestCase` subclass:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: We defined `setUpClass()` so that a database is created before the tests from
    this class are run. This allows us to define a number of test methods that will
    share a common database configuration. Once the database has been built, we can
    create a session and add data.
  prefs: []
  type: TYPE_NORMAL
- en: We've put the session maker object into the class as a class-level attribute,
    `Test_Blog_Queries.Session = sessionmaker(bind=engine)`. This class-level object
    can then be used in `setUp()` and individual test methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is `setUp()` and two of the individual test methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: The `setUp()` method creates a new, empty session object. This will ensure that
    every query must generate SQL and fetch data from the database.
  prefs: []
  type: TYPE_NORMAL
- en: The `query_eqTitle_should_return1Blog()` test will find the requested `Blog`
    instance and navigate to the `Post` instances via the `entries` relationship.
    The `filter()` portion of the request doesn't really test our application definitions;
    it exercises SQLAlchemy and SQLite. The `results[0].entries` test in the final
    assertion is a meaningful test of our class definitions.
  prefs: []
  type: TYPE_NORMAL
- en: The `query_likeTitle_should_return2Blog()` test is almost entirely a test of
    SQLAlchemy and SQLite. It isn't really making a meaningful use of anything in
    our application except the presence of an attribute named `title` in `Blog`. These
    kinds of tests are often left over from creating initial technical spikes. They
    can help clarify an application API, even if they don't provide much value as
    a test case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are two more test methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: The `query_eqW42_tag_should_return2Post()` test performs a more complex query
    to locate the posts that have a given tag. This exercises a number of relationships
    defined in the classes.
  prefs: []
  type: TYPE_NORMAL
- en: The `query_eqICW_tag_should_return1Post()` test, similarly, exercises a complex
    query. It tests the navigation from `Post` to owning `Blog` via `results[0].blog.title`.
    It also tests navigation from `Post` to an associated collection of `Tags` via
    `set(t.phrase for t in results[0].tags)`. We must use an explicit `set()` because
    the order of results in SQL is not guaranteed.
  prefs: []
  type: TYPE_NORMAL
- en: What's important about this `Test_Blog_Queries` subclass of `TestCase` is that
    it creates a database schema and a specific set of defined rows via the `setUpClass()`
    method. This kind of test setup is helpful for database applications. It can become
    rather complex and is often supplemented by loading sample rows from files or
    JSON documents rather than coding the rows in Python.
  prefs: []
  type: TYPE_NORMAL
- en: The TestCase class hierarchy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Inheritance works among the `TestCase` classes. Ideally, each `TestCase` is
    unique. Pragmatically, there may be common features among cases. There are three
    common ways in which `TestCase` classes may overlap:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Common setUp()**: We may have some data that is used in multiple `TestCases`.
    There''s no reason to repeat the data. A `TestCase` class that only defines `setUp()`
    or `tearDown()` with no test methods is legal, but it may lead to a confusing
    log because there are zero tests involved.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Common tearDown()**: It''s common to have a common cleanup for tests that
    involve OS resources. We might need to remove files and directories or kill subprocesses.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Common results checking**: For algorithmically complex tests, we may have
    a results checking method that verifies some properties of a result.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Looking back at [Chapter 3](ch03.html "Chapter 3. Attribute Access, Properties,
    and Descriptors"), *Attribute Access, Properties, and Descriptors*, for example,
    consider the `RateTimeDistance` class. This class fills in a missing value in
    a dictionary based on two other values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'Each unit test method for this can include the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'If we use a number of `TestCase` subclasses, we can inherit this validity check
    as a separate method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: This way, each test need only include `self.validate(object)` to be sure that
    all the tests provide a consistent definition of correctness.
  prefs: []
  type: TYPE_NORMAL
- en: An important feature of the definition of the `unittest` module is that the
    test cases are proper classes with proper inheritance. We can design the `TestCase`
    class hierarchy with the same care and attention to detail that we apply to the
    application classes.
  prefs: []
  type: TYPE_NORMAL
- en: Using externally defined expected results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For some applications, users can articulate processing rules that describe the
    software's behavior. In other cases, the job of an analyst or a designer transforms
    the user's desires into procedural descriptions of the software.
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, it's easier for users to provide concrete examples of expected
    results. For some business-oriented applications, the users may be more comfortable
    creating a spreadsheet that shows us sample inputs and expected results. Working
    from user-supplied, concrete sample data can simplify the developing software.
  prefs: []
  type: TYPE_NORMAL
- en: '*Whenever possible, have real users produce concrete examples of correct results*.
    Creating procedural descriptions or software specifications is remarkably difficult.
    Creating concrete examples and generalizing from the examples to a software specification
    is less fraught with complexity and confusion. Further, it plays into a style
    of development where the test cases drive the development effort. Given a suite
    of test cases, we have a concrete definition of *done*. Tracking the software
    development project status leads to asking how many test cases we have today and
    how many of them pass.'
  prefs: []
  type: TYPE_NORMAL
- en: Given a spreadsheet of concrete examples, we need to turn each row into a `TestCase`
    instance. We can then build a suite from these objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the previous examples in this chapter, we loaded the test cases from a
    `TestCase`-based class. We used `unittest.defaultTestLoader.loadTestsFromTestCase`
    to locate all the methods with a name that start with `test`. The loader creates
    a test object from each method and combines them into a test suite. In effect,
    each object built by the loader is a discrete object created by invoking the class
    constructor using the test case name: `SomeTestCase("test_method_name")`. The
    parameters to the `SomeTestCase__init__()` method will be the method names which
    were used to define the class. Each method is individually elaborated into a test
    case.'
  prefs: []
  type: TYPE_NORMAL
- en: For this example, we're going to use the other approach to build test case instances.
    We're going to define a class with a single test and load multiple instances of
    this `TestCase` class into a suite. When we do this, the `TestCase` class must
    define only one test and, by default, that method's name should be `runTest()`.
    We won't be using the loader to create the test objects; we'll be creating them
    directly from rows of externally supplied data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at a concrete function that we need to test. This is from
    [Chapter 3](ch03.html "Chapter 3. Attribute Access, Properties, and Descriptors"),
    *Attribute Access, Properties, and Descriptors*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a class that eagerly computes a number of attributes when it is initialized.
    The users of this simple function provided us with some test cases as a spreadsheet,
    from which we extracted the CSV file. For more information on CSV files, see [Chapter
    9](ch09.html "Chapter 9. Serializing and Saving – JSON, YAML, Pickle, CSV, and
    XML"), *Serializing and Saving – JSON, YAML, Pickle, CSV, and XML*. We need to
    transform each row into `TestCase`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s the test case that we can use to create test instances from each row
    of the CSV file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: The `float_or_none()` function is a common way to handle the CSV source data.
    It converts the text of a cell to a `float` value or `None`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Test_RTD` class does three things:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `__init__()` method parses a row of a spreadsheet into two dictionaries:
    the input values, `self.args` and the expected output values, `self.result`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `setUp()` method creates a `RateTimeDistance` object and provides the input
    argument values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `runTest()` method can simply validate the output by checking the results
    against the user-supplied values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We also provided you with a `shortDescription()` method that returns a pithy
    summary of the test. This can help with any debugging. We can build a suite as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'We opened the CSV file and read each test case row of that file as a `dict`
    object. If the CSV column titles properly match the expectations of the `Test_RTD.__init__()`
    method, then each row becomes a test case object and can be added to the suite.
    If the CSV column titles don''t match, we''ll have a `KeyError` exception; we''ll
    have to fix the spreadsheet to match the `Test_RTD` class. We run the tests as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'The output looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: The user-supplied data has a small problem; the users provided a value that
    has been rounded off to only two places. Either the sample data needs to provide
    more digits, or our test assertions need to cope with the rounding.
  prefs: []
  type: TYPE_NORMAL
- en: Getting users to supply precise example data may not work out well. If the users
    can't be more precise, then our test assertions need to include some rounding
    based on the user's input. This can be challenging because of the way spreadsheets
    display data as if it's a precise decimal value, when it's really a rounded and
    formatted floating-point approximation. In many cases, a blanket rounding assumption
    can be used rather than trying to parse the user's intent via reverse-engineering
    a spreadsheet.
  prefs: []
  type: TYPE_NORMAL
- en: Automated integration or performance testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can use the `unittest` package to perform testing that isn't focused on a
    single, isolated class definition. As noted previously, we can use the `unittest`
    automation to test a unit that is an integration of multiple components. This
    kind of testing can only be performed on software that has passed unit tests on
    isolated components. There's no point in trying to debug a failed integration
    test when a component's unit test didn't work correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Performance testing can be done at several levels of integration. For a large
    application, performance testing with the entire build may not be completely helpful.
    One traditional view is that a program spends 90 percent of its time executing
    just 10 percent of the available code. Therefore, we don't often need to optimize
    an entire application; we only need to locate the small fraction of the program
    that represents the real performance bottleneck.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, it's clear that we have a data structure that involves a search.
    We know that removing the search will lead to a tremendous improvement in the
    performance. As we saw in [Chapter 5](ch05.html "Chapter 5. Using Callables and
    Contexts"), *Using Callables and Contexts*, implementing memoization can lead
    to dramatic performance improvements by avoiding recalculation.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to perform proper performance testing, we need to follow a three-step
    work cycle:'
  prefs: []
  type: TYPE_NORMAL
- en: Use a combination of design reviews and code profiling to locate the parts of
    the application that are likely to be a performance problem. Python has two profiling
    modules in the standard library. Unless there are more complex requirements, `cProfile`
    will locate the part of the application that requires focus.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an automated test scenario with `unittest` to demonstrate any actual
    performance problem. Collect the performance data with `timeit` or `time.perf_counter()`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Optimize the code for the selected test case until the performance is acceptable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The point is to automate as much as possible and avoid vaguely tweaking things
    in the hope of an improvement in the performance. Most of the time, a central
    data structure or algorithm (or both) must be replaced, leading to extensive refactoring.
    Having automated unit tests makes wholesale refactoring practical.
  prefs: []
  type: TYPE_NORMAL
- en: An awkward situation can arise when a performance test lacks specific pass-fail
    criteria. It may be necessary to make something *faster* without a concrete definition
    of *fast enough*. It's always simpler when there are measurable performance objectives;
    formal, automated testing can be used to assert both that the results are correct
    and that the time taken to get those results is acceptable.
  prefs: []
  type: TYPE_NORMAL
- en: 'For performance testing, we might use something like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: This use of `unittest` gives us an automated performance test. As the `timeit`
    module executes the given statement 1,000,000 times, this should minimize the
    variability in the measurement from the background work on the computer that does
    the testing.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding example, each execution of the RTD constructor is required
    to take less than 1/100,000 of a second. A million executions should take less
    than 10 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We looked at using `unittest` and `doctest` to create automated unit tests.
    We also looked at creating a test suite so that collections of tests can be packaged
    for reuse and aggregation into suites with larger scopes, without relying on the
    automated test discovery process.
  prefs: []
  type: TYPE_NORMAL
- en: We looked at how to create mock objects so that we can test software units in
    isolation. We also looked at the various kinds of setup and teardown features.
    These allow us to write tests with complex initial states or persistent results.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **FIRST** properties of unit tests fit well with both `doctest` and `unittest`.
    The FIRST properties are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Fast**: Unless we write egregiously bad tests, the performance of `doctest`
    and `unitest` should be very fast.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Isolated**: The `unittest` package offers us a mock module that we can use
    to isolate our class definitions. In addition, we can exercise some care in our
    design to ensure that our components are isolated from each other.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Repeatable**: Using `doctest` and `unittest` for automated testing ensures
    repeatability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Self-validating**: Both `doctest` and `unittest` bind the test results with
    the test case condition, ensuring that no subjective judgment is involved in testing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Timely**: We can write and run the test cases as soon as we have the skeleton
    of a class, function, or module. A class whose body has simply `pass` is sufficient
    to run the test script.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the purposes of project management, a count of written tests and passed
    tests is sometimes a very useful status report.
  prefs: []
  type: TYPE_NORMAL
- en: Design considerations and trade-offs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Test cases are a required to be deliverable when creating software. Any feature
    that is without an automated test might as well not exist. A feature certainly
    can't be trusted to be correct if there's no test. If it can't be trusted, it
    shouldn't be used.
  prefs: []
  type: TYPE_NORMAL
- en: The only real trade-off question is whether to use `doctest` or `unittest` or
    both. For simple programming, `doctest` may be perfectly suitable. For more complex
    situations, `unittest` will be necessary. For frameworks where the API documentation
    needs to include examples, a combination works out well.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, simply creating a module full of `TestCase` class definitions
    may be sufficient. The `TestLoader` class and test discovery features may be perfectly
    adequate to locate all of the tests.
  prefs: []
  type: TYPE_NORMAL
- en: More generally, `unittest` involves using `TestLoader` to extract multiple test
    methods from each `TestCase` subclass. We package the test methods into a single
    class based on who they can share class-level `setUp()`, and possibly with the
    `setUpClass()` methods.
  prefs: []
  type: TYPE_NORMAL
- en: We can also create the `TestCase` instances without `TestLoader`. In this case,
    the default method of `runTest()` is defined to have the test case assertions.
    We can create a suite from instances of this kind of class.
  prefs: []
  type: TYPE_NORMAL
- en: The most difficult part can be designing for testability. Removing dependencies
    so that units can be tested independently can sometimes feel like adding to the
    level of software design complexity. In most cases, the time expended to expose
    dependencies is time invested in creating more maintainable and more flexible
    software.
  prefs: []
  type: TYPE_NORMAL
- en: 'The general rule is this: *an implicit dependency among classes is bad design*.'
  prefs: []
  type: TYPE_NORMAL
- en: A testable design has explicit dependencies; these can easily be replaced with
    mock objects.
  prefs: []
  type: TYPE_NORMAL
- en: Looking forward
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The next chapter will look at writing complete applications that are started
    from the command line. We'll look at ways to handle startup options, environment
    variables, and configuration files in Python applications.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 17](ch17.html "Chapter 17. The Module and Package Design"), *The
    Module and Package Design*, we'll expand on application design. We'll add the
    ability to compose applications into larger applications as well as decompose
    applications into smaller pieces.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 16. Coping With the Command Line
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Command-line startup options, environment variables, and configuration files
    are important to many applications, particularly the implementation of servers.
    There are a number of ways of dealing with program startup and object creation.
    We''ll look at two issues in this chapter: argument parsing and the overall architecture
    for an application.'
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will extend the configuration file handling from [Chapter 13](ch13.html
    "Chapter 13. Configuration Files and Persistence"), *Configuration Files and Persistence*,
    with yet more techniques for command-line programs and the top-level of a server.
    It will also extend some logging design features from [Chapter 14](ch14.html "Chapter 14. The
    Logging and Warning Modules"), *The Logging and Warning Modules*.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll extend these principles to continue looking at a
    kind of architectural design that we'll call *programming in the Large*. We'll
    use the **Command** design pattern to define software components that can be aggregated
    without resorting to shell scripts. This is particularly helpful when writing
    the background processing components used by application servers.
  prefs: []
  type: TYPE_NORMAL
- en: The OS interface and the command line
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Generally, the shell starts applications with several pieces of information
    that constitute the OS API:'
  prefs: []
  type: TYPE_NORMAL
- en: The shell provides each application its collection of environment variables.
    In Python, these are accessed through `os.environ`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The shell prepares three standard files. In Python, these are mapped to `sys.stdin`,
    `sys.stdout`, and `sys.stderr`. There are some other modules such as `fileinput`
    that can provide access to `sys.stdin`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The command line is parsed by the shell into words. Parts of the command line
    are available in `sys.argv`. Python will provide some of the original command
    line; we'll look at the details in the following sections. For POSIX operating
    systems, the shell may replace shell environment variables and glob wildcard filenames.
    In Windows, the simple `cmd.exe` shell will not glob filenames for us.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The OS also maintains context settings such as the current working directory,
    user ID, and group. These are available through the `os` module. They aren't provided
    as arguments on the command line.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The OS expects an application to provide a numeric status code when terminating.
    If we want to return a specific numeric code, we can use `sys.exit()` in our applications.
    Python will return a zero if our program is terminated normally.
  prefs: []
  type: TYPE_NORMAL
- en: The shell's operation is an important part of this OS API. Given a line of input,
    the shell performs a number of substitutions, depending on the (rather complex)
    quoting rules and substitution options. It then parses the resulting line into
    space-delimited words. The first word must be either a built-in shell command
    (such as `cd` or `set`), or it must be the name of a file. The shell searches
    its defined `PATH` for this file.
  prefs: []
  type: TYPE_NORMAL
- en: The file named on the first word of a command must have `execute (x)` permission.
    The shell command, `chmod +x somefile.py`, marks a file as executable. A filename
    that matches but isn't executable gets an *OS Permission Denied error*.
  prefs: []
  type: TYPE_NORMAL
- en: The first bytes of an executable file have a magic number that is used by the
    shell to decide how to execute that file. Some magic numbers indicate that the
    file is a binary executable; the shell can fork a subshell and execute it. Other
    magic numbers, specifically `b'#!'`, indicate that the file is properly a text
    script and requires an interpreter. The rest of the first line of this kind of
    file is the name of the interpreter.
  prefs: []
  type: TYPE_NORMAL
- en: 'We often use a line like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: If a Python file has permission to execute, and has this as the first line,
    then the shell will run the `env` program. The `env` program's argument (`python3.3`)
    will cause it to set up an environment and run the Python3.3 program with the
    Python file as the first positional argument.
  prefs: []
  type: TYPE_NORMAL
- en: 'In effect, the conceptual sequence of steps from the OS shell via an executable
    script to Python looks like the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The shell parses the `ourapp.py -s someinput.csv` line. The first word is `ourapp.py`.
    This file is on the shell''s `PATH` and has the `x` executable permission. The
    shell opens the file and finds the `#!` bytes. The shell reads the rest of this
    line and finds a new command: `/usr/bin/env python3.3`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The shell parses the new `/usr/bin/env` command, which is a binary executable.
    So, the shell starts this program. This program, in turn, starts `python3.3`.
    The sequence of words from the original command line is provided to Python as
    part of the OS API.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Python will parse this sequence of words from the original command line to extract
    any options that are prior to the first argument. These first options are used
    by Python. The first argument is the Python filename to be run. This filename
    argument and all of the remaining words on the line will be saved separately in
    `sys.argv`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Python does its normal startup based on the options that have been found. Depending
    on the `-s` option, the `site` module may be used to setup the import path, `sys.path`.
    If we used the `-m` option, Python will use the `runpy` module to start our application.
    The given script files may be (re)compiled to byte code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Our application can make use of `sys.argv` to parse options and arguments with
    the `argparse` module. Our application can use environment variables in `os.environ`.
    It can also parse configuration files; see [Chapter 13](ch13.html "Chapter 13. Configuration
    Files and Persistence"), *Configuration Files and Persistence*, for more on this
    topic.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On lacking a filename, the Python interpreter will read from standard input.
    If the standard input is a console (called a TTY in Linux parlance), then Python
    will enter **Read-Execute-Print Loop (REPL)** and display the `>>>` prompt. While
    we use this mode as developers, we don't generally make use of this mode for a
    finished application.
  prefs: []
  type: TYPE_NORMAL
- en: Another possibility is that standard input is a redirected file; for example,
    `python <some_file` or `some_app | python`. Both are valid but potentially confusing.
  prefs: []
  type: TYPE_NORMAL
- en: Arguments and options
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to run programs, the shell parses a command line into words. This sequence
    of words is made available to all programs that are started. Generally, the first
    word of this sequence is the shell's understanding of the command. The remaining
    words on the command line are understood to be options and arguments.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a number of guidelines to handle options and arguments. The essential
    rules are these:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Options come first. They are preceded by `-` or `--`. There are two formats:
    `-letter` and `--word`. There are two species of options: options with no arguments
    and options with arguments. Examples of options without arguments are to use `-V`
    to show a version or use `--version` to show the version. An examples of options
    with arguments is `-m module`, where the `-m` option must be followed by a module
    name.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Short format (single-letter) options with no option arguments can be grouped
    behind a single `-`. We might use `-bqv` to combine the `-b -q -v` options for
    convenience.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Arguments come last. They don''t have a leading `-` or `--`. There are two
    common kinds of arguments:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For positional arguments, the position is semantically significant. We might
    have two positional arguments: an input filename and an output filename. The order
    matters because the output file will be modified. When files will be overridden,
    simply distinguishing by position needs to be done carefully to prevent confusion.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A list of arguments, all of which are semantically equivalent. We might have
    arguments that are all the names of input files. This fits nicely with the way
    the shell performs filename globbing. When we say `process.py *.html`, the `*.html`
    command is expanded by the shell to filenames that become the positional parameters.
    (This doesn't work in Windows, so the `glob` module must be used.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are still more details. For more information on command-line options,
    see [http://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap12.html#tag_12_02](http://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap12.html#tag_12_02).
    The Python command line has 12 or so options that can control some details of
    Python's behavior. See the *Python Setup and Usage* document for more information
    on what these options are. The positional argument to the Python command is the
    name of the script to be run; this will be our application's top-most file.
  prefs: []
  type: TYPE_NORMAL
- en: Parsing the command line with argparse
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The general approach to using `argparse` involves four steps.
  prefs: []
  type: TYPE_NORMAL
- en: Create `ArgumentParser`. We can provide you with overall information about the
    command-line interface here. This might include a description, format changes
    for the displayed options and arguments, and whether or not `-h` is the "help"
    option. Generally, we only need to provide the description; the rest of the options
    have sensible defaults.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define the command-line options and arguments. This is done by adding arguments
    with the `ArgumentParser.add_argument()` method function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Parse the `sys.argv` command line to create a namespace object that details
    the options, option arguments and overall command-line arguments.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the resulting namespace object to configure the application and process
    the arguments. There are a number of alternative approaches to handle this gracefully.
    It may involve parsing configuration files, as well as command-line options. We'll
    look at several designs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An important feature of `argparse` is that it provides us with a unified view
    of options and arguments. The principle difference between the two is the number
    of times they can occur. Options are—well—optional and can occur zero or one time.
    Arguments generally occur one or more times.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create a parser as easily as the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'We provided the description, as there''s no good default value for that. Here
    are some common patterns to define the command-line API for an application:'
  prefs: []
  type: TYPE_NORMAL
- en: '**A simple on-off option**: We''ll often see this as a `-v` or `--verbose`
    option'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**An option with an argument**: This might be a `-s '',''` or `–separator ''|''`
    option'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A positional argument**: This might be used when we have an input file and
    an output file as command-line arguments'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**All other arguments**: We''d use these when we have a list of input files'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**--version**: This is a special option to display the version number and exit'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**--help**: This option will display the help and exit. This is a default,
    we don''t need to do anything to make this happen'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once the arguments have been defined, we can parse them and use them. Here''s
    how we parse them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: The `config` object is an `argparse.Namespace` object; the class is similar
    to `types.SimpleNamespace`. It will have a number of attributes, and we can easily
    add more attributes to this object.
  prefs: []
  type: TYPE_NORMAL
- en: We'll look at each of these six common kinds of arguments individually. There
    are a lot of clever and sophisticated parsing options available in the `ArgumentParser`
    class. Most of them go beyond the simplistic guidelines commonly suggested for
    command-line argument processing. In general, we should avoid the kind of super-complex
    options that characterize programs such as `find`. When the options get terribly
    complex, we may have drifted into creating a domain-specific language on top of
    Python. Why not just use Python?
  prefs: []
  type: TYPE_NORMAL
- en: A simple on/off option
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We''ll define a simple on-off option with the one-letter short name, we can
    also provide a longer name; we should also provide an explicit action. We might
    want to provide a destination variable if we omit the longer name or the longer
    name is unpleasant as a Python variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'This will define the long and short versions of the command-line option. If
    the option is present, it will set the `verbose` option to `True`. If the option
    is absent, the verbose option will default to `False`. Here are some common variations
    of this theme:'
  prefs: []
  type: TYPE_NORMAL
- en: We might change the action to `'store_false'` with a default of `True`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sometimes, we'll have a default of `None` instead of `True` or `False`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sometimes, we'll use an action of `'store_const'` with an additional `const=`
    argument. This allows us to move beyond simple Boolean values and store things
    such as logging levels or other objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We might also have an action of `'count'`, which allows the option to get repeated,
    increasing the count. In this case, the default is often zero.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If we''re using the logger, we might define a debugging option like the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: We changed the action to `store_const`, which stores a constant value and provides
    a specific constant value of `logging.DEBUG`. This means that the resulting options
    object will directly provide the value needed to configure the root logger. We
    can then simply configure the logger using `config.logging_level` without any
    further mapping or conditional processing.
  prefs: []
  type: TYPE_NORMAL
- en: An option with an argument
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We''ll define an option that has an argument with the long and optional short
    name. We''ll provide an action that stores the value provided with the argument.
    We can also provide a type conversion, in case we want `float` or `int` values
    instead of a string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: The first example will define two versions of the command-line syntax, both
    long and short. When parsing the command-line argument values, a string value
    must follow the option, and it must be from the available choices. The destination
    name, `betting_rule`, will receive the option's argument string.
  prefs: []
  type: TYPE_NORMAL
- en: The second example also defines two versions of the command-line syntax; it
    includes a type conversion. When parsing argument values, this will store an integer
    value that follows the option. The long name, `stake`, will be the value in the
    options object created by the parser.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, there may be a list of values associated with the argument. In
    this case, we may provide a `nargs="+"` option to collect multiple values separated
    by spaces into a list.
  prefs: []
  type: TYPE_NORMAL
- en: Positional arguments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We define positional arguments using a name with no "`-`" decoration. In the
    case where we have a fixed number of positional arguments, we''ll add them appropriately
    to the parser:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: When parsing argument values, the two positional argument strings will be stored
    into the final namespace object. We can use `config.input_filename` and `config.output_filename`
    to work with these argument values.
  prefs: []
  type: TYPE_NORMAL
- en: All other arguments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We define argument lists with a name that has no `-` decoration and a piece
    of advice in the `nargs`= parameter. If the rule is one-or-more argument values,
    we specify `nargs="+"`. If the rule is zero-or-more argument values, we specify
    `nargs="*"`. If the rule is *optional*, we specify `nargs="?"`. This will collect
    all other argument values into a single sequence in the resulting namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: When the list of filenames is optional, it generally means that `STDIN` or `STDOUT`
    will be used if no specific filenames are provided.
  prefs: []
  type: TYPE_NORMAL
- en: If we specify `nargs=`, then the result becomes a list. If we specify `nargs=1`,
    then the resulting object is a one-element list. If we omit `nargs`, then the
    result is just the single value that was provided.
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating a list (even if it has only one element) is handy because we might
    want to process the arguments in this manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'In some cases, we may want to provide a sequence of input files that includes
    `STDIN`. The common convention for this is a filename of `-` as an argument. We''ll
    have to handle this within our application with something like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: This shows us a loop that will attempt to handle a number of filenames, potentially
    including `-` to show when to process standard input among a list of files. A
    `try:` block should probably be used around the `with` statement.
  prefs: []
  type: TYPE_NORMAL
- en: --version display and exit
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'An option to display the version number is so common that there''s a special
    shortcut to show us the version information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: This example assumes that we have a global module `__version__= "3.3.2"` somewhere
    in the file. This special `action="version"` will have the side effect of exiting
    the program after displaying the version information.
  prefs: []
  type: TYPE_NORMAL
- en: --help display and exit
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An option to display help is a default feature of `argparse`. Another special
    case allows us to change the `help` option from the default setting of`-h` or
    `--help`. This requires two things. First, we must create the parser with `add_help=False`.
    This will turn off the built-in `-h`, `--help` feature. After doing that, we will
    add the argument that we want to use (for example, `'-?'`) with `action="help"`.
    This will display the help text and exit.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating command-line options and environment variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The general policy for environment variables is that they are configuration
    inputs, similar to command-line options and arguments. For the most part, we use
    environment variables for settings that rarely change. We'll often set them via
    the `.bashrc` or `.bash_profile` files so that the values apply every time we
    log in. We may set the environment variables more globally in an `/etc/bashrc`
    file so that they apply to all users. We can also set environment variables on
    the command line, but these settings only last as long as the session is logged
    in.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, all of our configuration settings can be provided on the command
    line. In this case, the environment variables could be used as a kind of backup
    syntax for slowly changing variables.
  prefs: []
  type: TYPE_NORMAL
- en: In other cases, the configuration values we provide may be segregated into settings
    provided by environment variables different from settings provided by command-line
    options. We may need to get some values from the environment and merge in values
    that come from the command line.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can leverage environment variables to set the default values in a configuration
    object. We want to gather these values prior to parsing the command-line arguments.
    This way, command-line arguments can override environment variables. There are
    two common approaches to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Explicitly setting the values when defining the command-line options**: This
    has the advantage of making the default value show up in the help message. It
    only works for environment variables that overlap with command-line options. We
    might do something like this to use the `SIM_SAMPLES` environment variable to
    provide a default value that can be overridden:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: '**Implicitly setting the values as part of the parsing process**: This makes
    it simple to merge environment variables with command-line options into a single
    configuration. We can populate a namespace with default values and then overwrite
    it with the parsed values from the command line. This provides us with three levels
    of option values: the default defined in the parser, an override value seeded
    into the namespace, and finally, any override value provided on the command line.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The argument parser can perform type conversions for values that are not simple
    strings. Gathering environment variables, however, doesn't automatically involve
    a type conversion. For options that have non-string values, we must perform the
    type conversion in our application.
  prefs: []
  type: TYPE_NORMAL
- en: Providing more configurable defaults
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can incorporate configuration files along with environment variables and
    the command-line options. This gives us three ways to provide a configuration
    to an application program:'
  prefs: []
  type: TYPE_NORMAL
- en: A hierarchy of configuration files can provide defaults values. See [Chapter
    13](ch13.html "Chapter 13. Configuration Files and Persistence"), *Configuration
    Files and Persistence*, for examples on the ways to do this.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Environment variables can provide overrides to the configuration files. This
    may mean translating from an environment variable namespace to the configuration
    namespace.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The command-line options define the final overrides.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using all three may be too much of a good thing. Tracking down a setting can
    become murky if there are too many places to search. The final decision on the
    configuration often rests on staying consistent with the overall collection of
    applications and frameworks. We should strive to make our programming fit seamlessly
    with other components.
  prefs: []
  type: TYPE_NORMAL
- en: We'll look at two minor variations on this theme. The first example shows us
    how we can have environment variables that override configuration file settings.
    The second example shows us configuration files that override global environment
    variable settings.
  prefs: []
  type: TYPE_NORMAL
- en: Overriding configuration file settings with environment variables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We''ll use a three-stage process to incorporate environment variables and consider
    them more important than configuration file settings. First, we''ll build some
    default settings from the environment variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: Creating a mapping like this has the effect of rewriting the external environment
    variable names (`SOMEAPP_VARNAME`) into internal configuration names (`attribute_name`)
    that will match our application's configuration attributes. For environment variables
    that were not defined, we'll get `None` as the default value. We'll filter these
    out later.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we''ll parse a hierarchy of configuration files to gather the background
    configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: We built a list of locations, in priority order from the most important (owned
    by the user) to the least important (part of the installation.) For each file
    that actually exists, we parsed the content to create a mapping from names to
    values. We relied on the YAML notation, as it's flexible and easy for people to
    work with.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can build instance of a `ChainMap` object from these sources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: We combined the various mappings into a single `ChainMap`. The environment variables
    are searched first. When values are present there, the values are looked up from
    the user's configuration file first and then other configurations, if the user
    configuration file didn't provide a value.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the following code to parse the command-line arguments and update
    these defaults:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: We transformed our `ChainMap` of configuration file settings into an `argparse.Namespace`
    object. Then, we parsed the command-line options to update that namespace object.
    As the environment variables are first in `ChainMap`, they override any configuration
    files.
  prefs: []
  type: TYPE_NORMAL
- en: Overriding environment variables with the configuration files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Some applications use environment variables as the foundational defaults that
    can be overridden by configuration files. In this case, we will change the order
    to build `ChainMap`. In the previous example, we put the environment variables
    first. We can put `env_config` in `defaults.maps` last to make it the final fallback:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can use the following code to parse the command-line arguments
    and update these defaults:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: We transform our `ChainMap` of configuration file settings into an `argparse.Namespace`
    object. Then, we parse the command-line options to update that namespace object.
    As the environment variables are last in `ChainMap`, they provide any values that
    are missing from the configuration files.
  prefs: []
  type: TYPE_NORMAL
- en: Making the configuration aware of the None values
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This three-stage process to set the environment variables includes many common
    sources of parameters and configuration settings. We don't always need environment
    variables, configuration files, and command-line options. Some applications may
    only need a subset of these techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 'We often need type conversions that will preserve the `None` values. Keeping
    the `None` values will ensure that we can tell when an environment variable was
    not set. Here''s a more sophisticated type conversion that is `None-aware`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use this `nint()` conversion in the following context to gather the
    environment variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: If an environment variable is not set, a default of `None` will be used. If
    the environment variable is set, then the value will be converted to an integer.
    In later processing steps, we can depend on the `None` value to build a dictionary
    from only the proper values that are not `None`.
  prefs: []
  type: TYPE_NORMAL
- en: Customizing the help output
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here''s some typical output that comes directly from the default `argparse.print_help()`
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: 'The default help text is built from four things in our parser definition:'
  prefs: []
  type: TYPE_NORMAL
- en: The usage line is a summary of the options. We can replace the default calculation
    with our own usage text that omits the less commonly used details.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is followed by the description. By default, the text we provide is cleaned
    up a bit. In this example, we provided a shabby two-word description, so there's
    no obvious cleanup.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, the arguments are shown. First the positional arguments and then the options,
    in the order that we defined them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After this, an optional epilog text is shown.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In some cases, this kind of terse reminder is adequate. In other cases, however,
    we may need to provide more details. We have three tiers of support for more detailed
    help:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Add help= to the argument definitions**: This is the place to start when
    customizing the help details'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use one of the other help formatter classes that create better-looking output**:
    This is done with the `formatter_class=` argument when building `ArgumentParser`.
    Note that `ArgumentDefaultsHelpFormatter` requires `help=` for an argument definition;
    it will add the default to the help text that we supply.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Extend the ArgumentParser class and override the print_usage() and print_help()
    methods**: We can always write a new help formatter as well. If we have options
    so complex that this is required, perhaps we''ve gone too far.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our goal is to improve usability. Even if our programs work correctly, we can
    build trust by providing command-line support that makes our program easier to
    use.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a top-level main() function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In [Chapter 13](ch13.html "Chapter 13. Configuration Files and Persistence"),
    *Configuration Files and Persistence*, we suggested two application configuration
    design patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The global property map**: In the previous examples, we implemented the global
    property map with a `Namespace` object created by `ArgumentParser`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Object construction**: The idea behind object construction was to build the
    required object instances from the configuration parameters, effectively demoting
    the global property map to a local property map inside the `main()` function and
    not saving the properties.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What we showed you in the previous section was the use of a local `Namespace`
    object to collect all of the parameters. From this, we can build the necessary
    application objects that will do the real work of the application. The two design
    patterns aren't a dichotomy; they're complementary. We used `Namespace` to accumulate
    a consistent set of values and then built the various objects based on the values
    in that namespace.
  prefs: []
  type: TYPE_NORMAL
- en: 'This leads us to a design for a top-level function. Before looking at the implementation,
    we need to consider a proper name for this function; there are two ways to name
    the function:'
  prefs: []
  type: TYPE_NORMAL
- en: Name it `main()` because that's a common term for the starting point of the
    application as a whole
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don't name it `main()` because `main()` is too vague to be meaningful in the
    long run
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We think this is not a dichotomy either, and we should do two things. Define
    a top-level function with a name that's a `verb_noun()` phrase that describes
    the operation fairly. Add a line `main= verb_noun` to provide a `main()` function
    that helps other developers see how the application works.
  prefs: []
  type: TYPE_NORMAL
- en: This two-part implementation lets us change the definition of `main()` through
    extension. We can add functions and reassign the name `main`. Old function names
    are left in place as part of a stable, growing API.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a top-level application script that builds objects from a configuration
    `Namespace` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: This function depends on an externally supplied `Namespace` object with the
    configuration attributes. It's not named `main()` so that we can make future changes
    that would change the meaning of `main`.
  prefs: []
  type: TYPE_NORMAL
- en: We built the various objects—`Table`, `Player`, `Simulate`—that are required.
    We configured these objects with the initial values based on the configuration
    parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ve actually done the real work. After all of the object construction, the
    actual work is a single, highlighted line: `wtr.writerows( simulate )`. 90 percent
    of the program''s time will be spent here, generating samples and writing them
    to the required file.'
  prefs: []
  type: TYPE_NORMAL
- en: A similar pattern holds for GUI applications. They enter a main loop to process
    GUI events. The pattern also holds for servers that enter a main loop to process
    requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ve depended on having a configuration object passed in as an argument.
    This follows from our testing strategy of minimizing dependencies. This top-level
    `simulate_blackjack()` function doesn''t depend on the details of how the configuration
    was created. We can then use this function in an application script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: This represents a separation of concerns. We've nested the work of the application
    into two levels of enclosure.
  prefs: []
  type: TYPE_NORMAL
- en: The outer level of enclosure is defined by logging. We configured logging outside
    of all other application components to ensure that there are no conflicts among
    various top-level modules, classes, or functions attempting to configure logging.
    If any particular portion of the application attempts to configure logging, then
    making changes can lead to conflicts. In particular, when we look at combining
    applications into larger composite processing, we need to be sure that the two
    applications being combined don't make conflicting logging configurations.
  prefs: []
  type: TYPE_NORMAL
- en: The inner level of enclosure is defined by the application's configuration.
    We don't want conflicts among separate application components. We'd like to allow
    our command-line API to evolve separately from our application. We'd like to be
    able to embed our application processing into separate environments, perhaps defined
    by `multiprocessing` or a RESTful web server.
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring DRY for the configuration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have a potential DRY issue between our construction of the argument parser
    and the use of the arguments to configure the application. We built the arguments
    using some keys that are repeated.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can eliminate this repetition by creating some global internal configurations.
    For example, we might define this global as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use it to create the argument parser:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use it to create the working objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: 'This eliminates the repetition. It allows us to add new class definitions and
    parameter key mappings in one place as the application evolves. It also allows
    us to abbreviate or otherwise rewrite the external API as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: There are four of these kinds of mappings from the command-line (or configuration
    file) string to application class. Using these internal mappings simplifies the
    `simulate_blackjack()` function.
  prefs: []
  type: TYPE_NORMAL
- en: Managing nested configuration contexts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In a way, the presence of nested contexts means that top level scripts ought
    to look like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: 'We add two context managers. For more information, see [Chapter 5](ch05.html
    "Chapter 5. Using Callables and Contexts"), *Using Callables and Contexts*. Here
    are two context managers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: The `Logging_Config` context manager configures the logging. It also ensures
    that logging is properly shut down when the application is finished.
  prefs: []
  type: TYPE_NORMAL
- en: The `Application_Config` context manager can gather configuration from a number
    of files as well as command-line arguments. The use of a context manager isn't
    essential in this case. However, it leaves room for ready extension.
  prefs: []
  type: TYPE_NORMAL
- en: This design pattern may clarify the various concerns that surround the application
    startup and shutdown. While it may be a bit much for most applications, this design
    fits with the philosophy of Python context managers seems like it could be helpful
    as an application grows and expands.
  prefs: []
  type: TYPE_NORMAL
- en: When we're confronted with an application that grows and expands, we often wind
    up doing larger-scale programming. For this, it's important to separate the changeable
    application processing from the less changeable processing context.
  prefs: []
  type: TYPE_NORMAL
- en: Programming In The Large
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s add a feature to our Blackjack simulation: analysis of results. We have
    several paths to implement this added feature. There are two dimensions to our
    considerations, leading to a large number of combinations. One dimension of our
    consideration is how to design the new features:'
  prefs: []
  type: TYPE_NORMAL
- en: Add a function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the Command design pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The other dimension is how to package the new features:'
  prefs: []
  type: TYPE_NORMAL
- en: Write a new top-level script file. We would have new commands based on files
    with names such as `simulate.py` and `analyze.py`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add a parameter to an application that allows one script to perform the simulation
    or analysis. We would have commands that look like `app.py simulate` and `app.py
    analyze`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All four combinations are sensible ways to implement this. We'll focus on using
    the **command** design pattern. First, we'll revise our existing application to
    use the command design pattern. Then, we'll extend our application by adding features.
  prefs: []
  type: TYPE_NORMAL
- en: Designing command classes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Many applications involve an implicit Command design pattern. After all, we're
    *processing* data. To do this, there must be at least one active-voice verb that
    defines how the application transforms, creates, or consumes data. A very simple
    application may have only a single verb, implemented as a function. Using the
    Command class design pattern may not be helpful.
  prefs: []
  type: TYPE_NORMAL
- en: More complex applications will have multiple, related verbs. One of the key
    features of GUIs and web servers is that they can do multiple things, leading
    to multiple commands. In many cases, the GUI menu options define the domain of
    the verbs for an application.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, an application's design stems from a decomposition of a larger,
    more complex verb. We may factor the overall processing into several smaller command
    steps that are combined into the final application.
  prefs: []
  type: TYPE_NORMAL
- en: When we look at the evolution of an application, we often see a pattern where
    new functionality is accreted. In these cases, each new feature can become a kind
    of separate command subclass that is added to the application class hierarchy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an abstract superclass for commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: We configure this `Command` class by setting the `config` property to a `types.SimpleNamespace`
    or `argparse.Namespace`, or even another `Command` instance. This will populate
    the instance variables from the `namespace` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the object is configured, we can set it to doing the work of the command
    by calling the `run()` method. This class implements a relatively simple use case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s a concrete subclass that implements a Blackjack simulation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: 'This class implements the essential top-level function that configures the
    various objects and then executes the simulation. We wrapped the `simulate_blackjack()`
    function shown previously to create a concrete extension of the `Command` class.
    This can be used in the main script like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: 'While we could make this command into `Callable` and use `main()` instead of
    `main.run()`, the use of a callable can be confusing. We''re explicitly separating
    three design issues:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Construction**: We''ve specifically kept the initialization empty. In the
    later section, we''ll show you some examples of PITL, where we''ll build a larger
    composite command from smaller component commands.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Configuration**: We''ve put the configuration in via a `property` setter,
    isolated from the construction and control.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Control**: This is the real work of the command after it''s been built and
    configured.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we look at a callable or a function, the construction is part of the definition.
    The configuration and control are combined into the function call itself. We sacrifice
    a small bit of flexibility if we try to define a callable.
  prefs: []
  type: TYPE_NORMAL
- en: Adding the analysis command subclass
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We'll extend our application by adding the analysis feature. As we're using
    the Command design pattern, we can add yet another subclass for analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s our analysis feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: This is not too statistically meaningful, true, but the point is to show you
    a second command that uses the configuration namespace to do work related to our
    simulation. We used the `outputfile` configuration parameter to name the file
    that is read to perform some statistical analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Adding and packaging more features into an application
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Previously, we noted one common approach to supporting multiple features. Some
    applications use multiple top-level main programs in separate `.py` script files.
  prefs: []
  type: TYPE_NORMAL
- en: When we want to combine commands that are in separate files, we're forced to
    write a shell script to create a higher-level, composite program. It doesn't seem
    optimal to introduce yet another tool and another language to do PITL.
  prefs: []
  type: TYPE_NORMAL
- en: 'A slightly more flexible alternative to creating separate script files is using
    a positional parameter to select a specific top-level `Command` object. For our
    example, we''d like to select either the simulation or the analysis command. To
    do this, we would add a parameter to the command-line argument parsing the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: 'This would change the command-line API to add the top-level verb to the command
    line. We can easily map our argument values to class names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: This allows us to create even higher-level composite features. For example,
    we might want to combine simulation and analysis into a single, overall program.
    Also, we'd like to do this without resorting to using the shell.
  prefs: []
  type: TYPE_NORMAL
- en: Designing a higher-level composite command
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Here''s how we can design a composite command that''s built from other commands.
    We have two design strategies: object composition and class composition.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we use object composition, then our composite command is based on the built-in
    `list` or `tuple`. We can extend or wrap one of the existing sequences. We''ll
    create the composite `Command` object as a collection of instances of other `Command`
    objects. We might consider writing something like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE125]'
  prefs: []
  type: TYPE_PRE
- en: This has the disadvantage that we haven't created a new class for our unique
    composite command. We created a generic composite and populated it with instances.
    If we want to create even higher-level compositions, we'll have to address this
    asymmetry between low-level `Command` classes and higher-level composite `Command`
    objects based on built-in sequence classes.
  prefs: []
  type: TYPE_NORMAL
- en: We'd prefer to have a composite command also be a subclass of command. If we
    use class composition, then we'll have a more consistent structure for our low-level
    commands and our higher-level composite commands.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a class that implements a sequence of other commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: We defined a class-level variable, `sequence`, to contain a sequence of command
    classes. During the object initialization, `__init__()` will construct an internal
    instance variable, `_sequence`, with objects of the named classes in `self.sequence`.
  prefs: []
  type: TYPE_NORMAL
- en: When the configuration is set, it will be pushed into each constituent object.
    When the composite command is executed via `run()`, it is delegated to each component
    in the composite command.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a `Command` subclass built from two other `Command` subclasses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: We can now create a class that is a sequence of individual steps. As this is
    a subclass of the `Command` class itself, it has the necessary polymorphic API.
    We can now create compositions with this class because it's compatible with all
    other subclasses of `Command`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now make a very small modification to argument parsing to add this feature
    to the application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: 'We simply added another choice to the argument option values. We''ll also need
    to tweak the mapping from the argument option string to the class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: Note that we shouldn't use a vague name such as `both` to combine two commands.
    If we avoid vagueness, we create opportunities to expand or revise our application.
    Using the Command design pattern makes it pleasant to add features. We can define
    composite commands, or we can decompose a larger command into smaller subcommands.
  prefs: []
  type: TYPE_NORMAL
- en: Packaging and implementation may involve adding an option choice and mapping
    that choice to a class name. If we use a more sophisticated configuration file
    (see [Chapter 13](ch13.html "Chapter 13. Configuration Files and Persistence"),
    *Configuration Files and Persistence*), we can provide the class name directly
    in the configuration file and save the mapping from an option string to a class.
  prefs: []
  type: TYPE_NORMAL
- en: Additional composite command design patterns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can identify a number of composite design patterns. In the previous example,
    we designed a sequence composite. For inspiration, we can look at the bash shell
    composite operators: `;`, `&`, `|`, as well as `()` for grouping. Beyond these,
    we have `if`, `for`, and `while` loops within the shell.'
  prefs: []
  type: TYPE_NORMAL
- en: We looked at the sequence operator (`;`) in the `Command_Sequence` class definition.
    This concept of *sequence* is so ubiquitous that many programming languages (such
    as the shell and Python) don't require an explicit operator; the syntax simply
    uses end-of-line as an implied sequence operator.
  prefs: []
  type: TYPE_NORMAL
- en: The shell's `&` operator creates two commands that run concurrently instead
    of sequentially. We can create a `Command_Concurrent` class definition with a
    `run()` method that uses `multiprocessing` to create two subprocesses and waits
    for both to finish.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `|` operator in the shell creates a pipeline: one command''s output buffer
    is another command''s input buffer; the commands run concurrently. In Python,
    we''d need to create a queue as well as two processes to read and write that queue.
    This is a more complex situation; it involves populating the queue objects into
    the configurations of each of the various children. [Chapter 12](ch12.html "Chapter 12. Transmitting
    and Sharing Objects"), *Transmitting and Sharing Objects*, has some examples of
    using `multiprocessing` with queues to pass objects among concurrent processes.'
  prefs: []
  type: TYPE_NORMAL
- en: The `if` command in the shell has a number of use cases. However, there's no
    compelling reason to provide anything more than a native Python implementation
    via a method in a subclass of `Command`. Creating a complex `Command` class to
    mimic Python's `if-elif-else` processing isn't helpful. We can—and should—just
    use Python.
  prefs: []
  type: TYPE_NORMAL
- en: The `while` and `for` commands in the shell, similarly, aren't the sort of things
    we need to define in a higher-level `Command` subclass. We can simply write this
    in a method in Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example of a *for-all* class definition that applies an existing
    command to all the values in a collection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs: []
  type: TYPE_PRE
- en: We enumerated the three classes of betting in our simulation. For each of these
    classes, we tweaked the configuration, created a simulation, and executed that
    simulation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that this *for-all* class won''t work with the `Analyze_Command` class
    defined previously. We can''t simply create composites that reflect different
    scopes of work. The `Analyze_Command` class runs a single simulation, but the
    `ForAllBets_Simulate` class runs a collection of simulations. We have two choices
    to create compatible scopes of work: we could create an `Analyze_All` command
    or `ForAllBets_Sim_and_Analyze` command. The design decision depends on the needs
    of the users.'
  prefs: []
  type: TYPE_NORMAL
- en: Integrating with other applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are several ways in which we can use Python when integrating with other
    applications. It''s difficult to provide a comprehensive overview, as there are
    so many applications, each with unique, distinctive features. We can show you
    some broad design patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Python may be the application''s scripting language. For many examples, here''s
    a list of applications that simply include Python as the primary method to add
    features: [https://wiki.python.org/moin/AppsWithPythonScripting](https://wiki.python.org/moin/AppsWithPythonScripting)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Python module can implement the application's API. There are numerous applications
    that include Python modules that provide a binding to the application's API. Application
    developers working in one language will often provide API libraries for other
    languages, including Python.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can use the `ctypes` module to implement another application's API directly
    in Python. This works out well in the case of an application library that is focused
    on C or C++.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can use `STDIN` and `STDOUT` to create a shell-level pipeline that connects
    us to another application. We might also want to look at the `fileinput` module
    when building shell-compatible applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can use the `subprocess` module to access an application's command-line interface.
    This may also involve connecting to an application's stdin and stdout to interact
    properly with it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can also write our own Python-compatible module in C or C++. In this case,
    we can implement the foreign application's API in C, offering classes or functions
    that a Python application can leverage. This may be a better performance than
    using the `ctypes` API. As this requires compiling C or C++, it's also a bit more
    tool intensive.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This level of flexibility means that we often use Python as the integration
    framework or glue to create a larger, composite application from smaller applications.
    When using Python for integration, we'll often have Python classes and objects
    that mirror the definitions in another application.
  prefs: []
  type: TYPE_NORMAL
- en: There are some additional design considerations that we'll save for [Chapter
    17](ch17.html "Chapter 17. The Module and Package Design"), *The Modules and Package
    Design*. These are higher-level architectural design considerations, above and
    beyond coping with the command line.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We looked at how to use `argparse` and `os.environ` to gather command-line argument
    and configuration parameters. This builds on the techniques shown in [Chapter
    13](ch13.html "Chapter 13. Configuration Files and Persistence"), *Configuration
    Files and Persistence*.
  prefs: []
  type: TYPE_NORMAL
- en: We can implement a number of common command-line features using `argparse`.
    This includes common features, such as showing the version number and exiting
    or showing the help text and exiting.
  prefs: []
  type: TYPE_NORMAL
- en: We looked at using the Command design pattern to create applications that can
    be expanded or refactored to offer new features. Our goal is to explicitly keep
    the body of the top-level main function as small as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Design considerations and trade-offs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The command-line API is an important part of a finished application. While
    most of our design effort focuses on what the program does while it''s running,
    we do need to address two boundary states: startup and shutdown. An application
    must be easy to configure when we start it up. Also, it must shut down gracefully,
    properly flushing all of the output buffers and releasing all of the OS resources.'
  prefs: []
  type: TYPE_NORMAL
- en: When working with a public-facing API, we have to address a variation on the
    problem of schema evolution. As our application evolves—and as our knowledge of
    the users evolves—we will modify the command-line API. This may mean that we'll
    have legacy features or legacy syntax. It may also mean that we need to break
    the compatibility with the legacy command-line design.
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, we'll need to be sure that the major version number is part of
    our application's name. We shouldn't write a top-level module named `someapp`.
    We should consider starting with `someapp1` so that the number is always part
    of the application name. We shouldn't change the command-line API by adding the
    version number as a new suffix; starting with `someapp1` anticipates a possible
    transition to `someapp2`.
  prefs: []
  type: TYPE_NORMAL
- en: Looking forward
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the next chapter, we'll expand some of these top-level design ideas and look
    at the module and package design. A small Python application can also be a module;
    it can be imported into a larger application. A complex Python application may
    be a package. It may include other application modules and it may be included
    into larger-scale applications.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 17. The Module and Package Design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python gives us several higher-level constructs to organize software. In [Part
    1](pt01.html "Part 1. Pythonic Classes via Special Methods"), *Pythonic Classes
    via Special Methods* we looked at advanced techniques to use class definitions
    to properly bind the structure and behavior together. In this chapter, we'll look
    at modules to encapsulate classes, functions, and global objects. Above the module
    grouping, we also have packages as a design pattern to group related modules together.
  prefs: []
  type: TYPE_NORMAL
- en: Python makes it very easy to create simple modules. Any time we create a Python
    file, we're creating a module. As the scope of our designs gets larger and more
    sophisticated, the use of packages becomes more important to maintain a clear
    organization among the modules.
  prefs: []
  type: TYPE_NORMAL
- en: We have some specialized modules as well. For a larger application, we may implement
    a `__main__` module. This module must be designed to expose the OS command-line
    interface to the application. It must also be defined in such a way that it doesn't
    block the simple reuse of the application to create larger, composite applications.
  prefs: []
  type: TYPE_NORMAL
- en: We also have some flexibility in how we install the modules. We can use the
    default working directory, an environment variable setting, `.pth` files, as well
    as the Python `lib/site-packages` directory. Each of these has advantages and
    disadvantages.
  prefs: []
  type: TYPE_NORMAL
- en: We're going to avoid the more complex problem of distributing Python code. There
    are a number of techniques to create a source distribution for a Python project.
    The various distribution technologies move outside object-oriented design. *Chapter
    30* of *Python Standard Library* addresses some of the physical file-packaging
    issues. The *Distributing Python Modules* document provides information on creating
    a code distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Designing a module
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A module is the unit of the Python implementation and reuse. All Python programming
    is provided at the module level. The class is the foundation of object-oriented
    design and programming. The module—a collection of classes—is a higher-level grouping
    and is the unit of reuse in Python. We can't easily reuse a single class in isolation.
    A properly designed module can be reused.
  prefs: []
  type: TYPE_NORMAL
- en: 'A Python module is a file. The filename extension must be `.py`. The filename
    in front of `.py` must be a valid Python name. Section 2.3 of *Python Language
    Reference* provides us with the complete definition of a name. One of the clauses
    in this definition is: *Within the ASCII range (U+0001..U+007F), the valid characters
    for identifiers are the uppercase and lowercase letters A through Z, the underscore
    _ and, except for the first character, the digits 0 through 9*.'
  prefs: []
  type: TYPE_NORMAL
- en: OS filenames permit more characters from the ASCII range than Python names;
    this extra OS complexity must be ignored. The filename (without `.py`) is the
    module name.
  prefs: []
  type: TYPE_NORMAL
- en: Every time we create a `.py` file, we create a module. Often, we'll create a
    Python file without doing too much design work. In this chapter, we'll take a
    look at some of the design considerations to create a reusable module.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Python may also create `.pyc` and `.pyo` files for its own private purposes;
    it's best to simply ignore these files. Many brain calories have been wasted by
    programmers trying to exploit the `.pyc` file as a kind of compiled object-code
    that can be used instead of the `.py` file to somehow keep the source code a secret.
    We need to emphasize the *wasted* part of that. The `.pyc` files can be decompiled
    easily; they don't keep anything secret. If you need to prevent the reverse-engineering
    of your application, you might want to consider using a different language.
  prefs: []
  type: TYPE_NORMAL
- en: Some module design patterns
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are three commonly seen design patterns for Python modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pure library modules**: These are meant to be imported. They contain definitions
    of classes, functions, and perhaps some assignment statements to create a few
    global variables. They do not do any real work so that they can be imported without
    any worry about the side effects of the import operation. There are two use cases
    that we''ll look at:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Whole module**: Some modules are designed to be imported as a whole, creating
    a module namespace that contains all of the items'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Item collection**: Some modules are designed to have individual items imported
    instead of creating a module object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Main script modules**: These are meant to be executed from the command line.
    They contain much more than class and function definitions. They will include
    statements that will do the real work; they may have side effects; they cannot
    be meaningfully imported because of an astonishing side effect. If a main script
    module import is attempted, it will actually execute—doing work, possibly updating
    files, or doing whatever the module is designed to do when run.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Conditional script modules**: These modules have two use cases: they can
    be imported and they can also be run from the command line. These modules will
    have the main-import switch as described in *Python Standard Library*, section
    28.4, *__main__—top-level script environment*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here''s the simplified conditional script switch from the library documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE131]'
  prefs: []
  type: TYPE_PRE
- en: 'The `main()`function does the work of the script. This design supports two
    use cases: `run` and `import`. When the module is run from the command line, it
    evaluates `main()` and does the expected work. When the module is imported, the
    function will not be evaluated, and the import will simply provide definitions
    without doing any real work.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We suggest something a bit more sophisticated, as shown in [Chapter 16](ch16.html
    "Chapter 16. Coping With the Command Line"), *Coping with the Command Line*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: 'Our point is to echo the following essential design tip:'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Importing a module should have few side effects.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a few module-level variables is an acceptable side effect of an import.
    The real work—accessing network resources, printing output, updating files, and
    other kinds of side effects—should not happen when a module is getting imported.
  prefs: []
  type: TYPE_NORMAL
- en: A main script module without a `__name__ == "__main__"` section is often a bad
    idea because it can't be imported and reused. Beyond that, it's difficult for
    documentation tools to work with a main script module, and it's difficult to test.
    The documentation tools tend to import modules, causing work to be done unexpectedly.
    Similarly, testing requires care to avoid importing the module as part of a test
    setup.
  prefs: []
  type: TYPE_NORMAL
- en: Module versus class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are numerous parallels between a module and a class definition:'
  prefs: []
  type: TYPE_NORMAL
- en: A module and a class each have a Python name. Modules usually have a leading
    lowercase letter; classes usually have a leading uppercase letter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A module and a class definition are namespaces that contain other objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A module is a **singleton** object within a global namespace, `sys.modules`.
    A class definition is unique within a namespace, either the global namespace,
    `__main__` or some local namespace. A class isn't a proper **Singleton**; the
    definition can be replaced. Once imported, a module isn't imported again unless
    it's deleted.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The definition of the class or module is evaluated as a sequence of statements
    within a namespace.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A function defined in a module is analogous to a static method within a class
    definition.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A class defined in a module is analogous to a class defined within another class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are two significant differences between a module and class:'
  prefs: []
  type: TYPE_NORMAL
- en: We can't create an instance of a module; it's always a singleton. We can create
    multiple instances of a class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An assignment statement in a module creates a variable that's global within
    the module's namespace; it can be used inside the module without a qualifier.
    An assignment statement within a class definition creates a variable that's part
    of the class namespace it requires a qualifier to distinguish it from the global
    variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A module is like a class. Modules, packages, and classes can be used to encapsulate
    data and processing—attributes and operations—into a tidy object.
  prefs: []
  type: TYPE_NORMAL
- en: The similarities between modules and classes mean that choosing between them
    is a design decision with trade-offs and alternatives. In most cases, the need
    for an *instance of* is the deciding factor. A module's singleton feature means
    that we'll use a module (or package) to contain class and function definitions
    that are expanded just once even if imported multiple times.
  prefs: []
  type: TYPE_NORMAL
- en: However, there are some modules that might be very class-like. The `logging`
    module, for example, is often imported in multiple other modules. The singleton
    feature means that the logging configuration can be done once and will apply to
    all other modules.
  prefs: []
  type: TYPE_NORMAL
- en: A configuration module, similarly, might be imported in several places. The
    singleton nature of a module ensures the configuration can be imported by any
    module but will be truly global.
  prefs: []
  type: TYPE_NORMAL
- en: When writing applications that work with a single connected database, a module
    with a number of functions will be similar to a singleton class. The database
    access layer can be imported throughout an application but will be a single, shared
    global object.
  prefs: []
  type: TYPE_NORMAL
- en: The expected content of a module
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Python modules have a typical organization. To an extent, this is defined by
    PEP 8, [http://www.python.org/dev/peps/pep-0008/](http://www.python.org/dev/peps/pep-0008/).
  prefs: []
  type: TYPE_NORMAL
- en: 'The first line of a module can be a `#!` comment; a typical version looks like
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE133]'
  prefs: []
  type: TYPE_PRE
- en: This is used to help OS tools such as `bash` locate the Python interpreter for
    an executable script file. For Windows, this line may be something like `#!C:\Python3\python.exe`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Older Python modules may include a coding comment to specify the encoding for
    the rest of the text. This may look like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: The coding comment is not generally needed for Python 3; the OS encoding information
    is adequate. Older Python implementations assumed the files were encoded in ASCII;
    a coding comment was required for files that were not in ASCII.
  prefs: []
  type: TYPE_NORMAL
- en: The next lines of a module should be a triple-quoted module docstring that defines
    the contents of the module file. As with other Python docstrings, the first paragraph
    of the text should be a summary. This should be followed by a more complete definition
    of the module's contents, purpose, and usage. This may include RST markup so that
    the documentation tools can produce elegant-looking results from the docstring.
    We'll address this in [Chapter 18](ch18.html "Chapter 18. Quality and Documentation"),
    *Quality and Documentation*.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the docstring, we can include any version''s control information. For
    example, we might have the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: This is a global module that we might use elsewhere in our application to determine
    the version number of the module. This is after the docstring but before the body
    of the module. Below this comes the module's `import` statement. Conventionally,
    they're in a big block at the front of the module.
  prefs: []
  type: TYPE_NORMAL
- en: After the `import` statements come the various class and function definitions
    of the module. These are presented in whatever order is required to ensure that
    they work correctly and make sense to someone who is reading the code.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Java and C++ tend to focus on one class per file.
  prefs: []
  type: TYPE_NORMAL
- en: That's a silly limitation. It doesn't apply to Python, nor is it a natural law
    of the universe.
  prefs: []
  type: TYPE_NORMAL
- en: If the file has a lot of classes, we might find that the module is a bit hard
    to follow. If we find ourselves using big comment blocks to break a module into
    sections, this is a hint that what we're writing may be more complex than a single
    module. We certainly have multiple modules; we may have a package.
  prefs: []
  type: TYPE_NORMAL
- en: Another common feature of some modules is the creation of objects within the
    module's namespace. Stateful module variables, such as class-level attributes,
    are not a great idea. The lack of visibility of these variables is a potential
    area for confusion.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, global modules are handy. The `logging` module makes heavy use of
    this. Another example is the way the `random` module creates a default instance
    of the `Random` class. This allows a number of module-level functions to provide
    a simple API for random numbers. We're not forced to create an instance of `random.Random`.
  prefs: []
  type: TYPE_NORMAL
- en: Whole module versus module items
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are two approaches to the contents of a library module. Some modules are
    an integrated whole, some are more like a collection of less-well-related items.
    When we've designed a module as a whole, it will often have a few classes or functions
    that are the public-facing API of the module. When we've designed a module as
    a collection of loosely related items, each individual class or function tends
    to stand alone.
  prefs: []
  type: TYPE_NORMAL
- en: 'We often see this distinction in the way we import and use a module. We''ll
    look at three variations:'
  prefs: []
  type: TYPE_NORMAL
- en: Using the `import some_module` command
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `some_module.py` module file is evaluated and the resulting objects are
    collected into a single namespace called `some_module`. This requires us to use
    qualified names for all of the objects in the module. We must use `some_module.this`
    and `some_module.that`. This use of qualified names makes the module an integrated
    whole.
  prefs: []
  type: TYPE_NORMAL
- en: Using the `from some_module import this` command
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `some_module.py` module file is evaluated and only the named objects are
    created in the current local namespace. Often, this is the global namespace. We
    can now use `this` or `that` without the qualification. This use of unqualified
    names claims that the module seems like a collection of disjointed objects.
  prefs: []
  type: TYPE_NORMAL
- en: Using the `from math import sqrt, sin, cos` command
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This will provide us with a few math functions that we can use without qualification.
  prefs: []
  type: TYPE_NORMAL
- en: Using the `from some_module import *` command
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The default behavior is to make all non-private names part of the namespace
    perform the import. A private name begins with `_`. We can explicitly limit the
    number of names imported by a module by providing an `__all__` list within the
    module. This is a list of string object names; these are the names that are elaborated
    by the `import *` statement.
  prefs: []
  type: TYPE_NORMAL
- en: We can use the `__all__` variable to conceal the utility functions that are
    part of building the module but not part of the API that's provided to clients
    of the module.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we look back at our design for decks of cards, we could elect to keep
    the suits as an implementation detail that''s not imported by default. If we had
    a `cards.py` module, we could include the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: 'The use of the `__all__` variable keeps the class definitions of the `Suit`
    and `Card` classes, the `card()`function, and the `suits` variable as implementation
    details that are not imported by default. For example, when we perform the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs: []
  type: TYPE_PRE
- en: This statement will only create `Deck` and `Shoe` in an application script,
    as those are the only explicitly given names in the `__all__` variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we execute the following command, it will import the module without putting
    any names into the global namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs: []
  type: TYPE_PRE
- en: Even though it's not imported into the namespace, we can still access the qualified
    `cards.card()` method to create a `Card` class.
  prefs: []
  type: TYPE_NORMAL
- en: There are advantages and disadvantages of each technique. A whole module requires
    using the module name as a qualifier; this makes the origin of an object explicit.
    Importing items from a module shortens their names, which can make complex programming
    more compact and easier to understand.
  prefs: []
  type: TYPE_NORMAL
- en: Designing a package
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One important consideration to design a package is *don''t*. The *Zen of Python*
    poem (also known as `import this`) includes this line:'
  prefs: []
  type: TYPE_NORMAL
- en: '"Flat is better than nested"'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We can see this in the Python Standard Library. The structure of the library
    is relatively flat; there are few nested modules. Deeply nested packages can be
    overused. We should be skeptical of excessive nesting.
  prefs: []
  type: TYPE_NORMAL
- en: A package is essentially a directory with an extra file, `__init__.py`. The
    directory name must be a proper Python name. OS names include a lot of characters
    that are not allowed in Python names.
  prefs: []
  type: TYPE_NORMAL
- en: 'We often see three design patterns for packages:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Simple packages are a directory with an empty `__init__.py` file. This package
    name becomes a qualifier for the internal module names. We''ll use the following
    code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE139]'
  prefs: []
  type: TYPE_PRE
- en: 'A module package can have an `__init__.py` file that is effectively a module
    definition. This can import other modules from the package directory. Or, it can
    stand as a part of a larger design that includes the top-level module and the
    qualified submodules. We''ll use the following code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE140]'
  prefs: []
  type: TYPE_PRE
- en: 'Directories are where the `__init__.py` file selects among alternative implementations.
    We''ll use the following code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE141]'
  prefs: []
  type: TYPE_PRE
- en: The first kind of package is relatively simple. We add an `__init__.py` file
    and we're done creating a package. The other two are a bit more involved; we'll
    look at these in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Designing a module-package hybrid
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In some cases, a design evolves into a module that is very complex—so complex
    that a single file becomes a bad idea. We might need to refactor this complex
    module into a package with several smaller modules.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the package can be as simple as the following kind of structure.
    Here''s the `__init__.py` file from a package directory named `blackjack`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE142]'
  prefs: []
  type: TYPE_PRE
- en: 'This shows us how we can build a module-like package that is actually an assembly
    of parts imported from other subsidiary modules. An overall application can then
    do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE143]'
  prefs: []
  type: TYPE_PRE
- en: 'This snippet shows us how we can use `from blackjack import *` to create a
    number of class definitions that originate in a number of other packages. Specifically,
    there''s an overall `blackjack` package that has the following modules within
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: The `blackjack.cards` package contains the `Card`, `Deck`, and `Shoe` definitions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `blackjack.player` package contains various strategies for play
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `blackjack.casino` package contains a number of classes that customize how
    casino rules vary
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `blackjack.simulator` package contains the top-level simulation tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `betting` package is also used by the application to define various betting
    strategies that are not unique to Blackjack but apply to any casino game
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The architecture of this package may simplify upgrading our design. If each
    module is smaller and more focused, it's more readable and more understandable.
    It may be simpler to update each module in isolation.
  prefs: []
  type: TYPE_NORMAL
- en: Designing a package with alternate implementations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In some cases, we'll have a top-level `__init__.py` file that chooses between
    some alternative implementations within the package directory. The decision might
    be based on the platform, CPU architecture, or the availability of OS libraries.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two common design patterns and one less common design pattern for
    packages with alternative implementations:'
  prefs: []
  type: TYPE_NORMAL
- en: Examine `platform` or `sys` to determine the details of the implementation and
    decide what to import with an `if` statement.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attempt `import` and use a `try` block exception handling to work out the configuration
    details.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a less common alternative, an application may examine a configuration parameter
    to determine what should be imported. This is a bit more complex. We have an ordering
    issue between importing an application configuration and importing other application
    modules based on the configuration. It's far simpler to import without this potentially
    complex sequence of steps.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here''s `__init__.py` for a `some_algorithm` package, which chooses an implementation
    based on the platform information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE144]'
  prefs: []
  type: TYPE_PRE
- en: This uses the `platform` module to determine the details of the platform's architecture.
    There is an ordering dependency here, but depending on a standard library module
    is superior to a more complex application configuration module.
  prefs: []
  type: TYPE_NORMAL
- en: We will provide two modules within the `some_algorithm` package the `long_version`
    module provides an implementation appropriate for a 64-bit architecture; the `short_version`
    module provides an alternate implementation. The design must have module isomorphism;
    this is similar to class isomorphism. Both the modules must contain classes and
    functions with the same names and same APIs.
  prefs: []
  type: TYPE_NORMAL
- en: 'If both the files define a class named `SomeClass`, then we can write the following
    code in an application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE145]'
  prefs: []
  type: TYPE_PRE
- en: We can import the `some_algorithm` package as if it were a module. The package
    locates an appropriate implementation and provides the needed class and function
    definitions.
  prefs: []
  type: TYPE_NORMAL
- en: The alternative to an `if` statement is to use a `try` statement to locate a
    candidate's implementation. This technique works well when there are different
    distributions. Often, a platform-specific distribution may include files that
    are unique to the platform.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 14](ch14.html "Chapter 14. The Logging and Warning Modules"), *The
    Logging and Warning Modules*, we showed you this design pattern in the context
    of providing warnings in the event of a configuration error or problem. In some
    cases, tracking down variant configurations doesn't deserve a warning, because
    the variant configuration is a design feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s `__init__.py` for a `some_algorithm` package, which chooses an implementation
    based on the availability of the module files within the package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE146]'
  prefs: []
  type: TYPE_PRE
- en: This depends on having two distinct distributions that will include either the
    `some_algorithm/long_version.py` file or the `some_algorithm/short_version.py`
    file. If the `some_algorithm.long_version` module is not found, then `short_version`
    will be imported.
  prefs: []
  type: TYPE_NORMAL
- en: This doesn't scale to more than two or three alternative implementations. As
    the number of choices grows, the `except` blocks will become very deeply nested.
    The alternative is to wrap each `try` in `if` to create a flatter design.
  prefs: []
  type: TYPE_NORMAL
- en: Designing a main script and the __main__ module
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A top-level main script will execute our application. In some cases, we may
    have multiple main scripts because our application does several things. We have
    three general approaches to writing the top-level main script:'
  prefs: []
  type: TYPE_NORMAL
- en: For very small applications, we can run the application with `python3.3 some_script.py`.
    This is the style that we've shown you in most examples.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For some larger applications, we'll have one or more files that we mark as executable
    with the OS `chmod +x` command. We can put these executable files into Python's
    `scripts` directory with our `setup.py` installation. We run these applications
    with `some_script.py` at the command line.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For complex applications, we might add a `__main__.py` module in the application's
    package. To provide a tidy interface, the standard library offers the `runpy`
    module and the `-m` command-line option that will use this specially named module.
    We can run this with `python3.3 -m some_app`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We'll look at the last two options in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an executable script file
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To use an executable script file, we have a two-step implementation: make it
    executable and include a `#!` ("shebang") line. We will take a look at the details.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We mark the script executable with `chmod +x some_script.py`. Then, we include
    a `#!` shebang line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE147]'
  prefs: []
  type: TYPE_PRE
- en: This line will direct the OS to use the named program to execute the script
    file. In this case, we used the `/usr/bin/env` program to locate the `python3.3`
    program to run the script. The Python3.3 program will be given the script file
    as its input.
  prefs: []
  type: TYPE_NORMAL
- en: Once the script file is marked executable—and includes the `#!` line—we can
    use `some_script.py` at the command line to run the script.
  prefs: []
  type: TYPE_NORMAL
- en: For a more complex application, this top-level script may import other modules
    and packages. It's important that these top-level executable script files should
    be as simple as possible. We have emphasized the design of top-level executable
    script files.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Keep the script module as small as possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A script module should have no new or distinctive code. It should always import
    existing code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No program stands alone.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our design goals must always include the idea of composite, larger-scale programming.
    It''s awkward to have some parts of our program in the proper Python library but
    other parts in the scripts directory. A main script file should be as short as
    possible. Here''s our example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE148]'
  prefs: []
  type: TYPE_PRE
- en: All of the relevant working code is imported from a module named `simulation`.
    There's no unique or distinctive new code introduced in this module.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a __main__ module
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To work with the `runpy` interface, we have a simple implementation. We add
    a small `__main__.py` module to our application's top-level package. We have emphasized
    the design of this top-level executable script file.
  prefs: []
  type: TYPE_NORMAL
- en: We should always permit refactoring an application to build a larger, more sophisticated
    composite application. If there's functionality buried in `__main__.py`, we need
    to pull this into a module with a clear, importable name so that it can be used
    by other applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'A `__main__.py` module should be something small like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE149]'
  prefs: []
  type: TYPE_PRE
- en: We've done the minimum to create the working contexts for our application. All
    of the real processing is imported from the package. Also, we've assumed that
    this `__main__.py` module will never be imported.
  prefs: []
  type: TYPE_NORMAL
- en: This is about all that should be in a `__main__` module. Our goal is to maximize
    the reuse potential of our application.
  prefs: []
  type: TYPE_NORMAL
- en: Programming in the large
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Here's an example that shows us why we shouldn't put unique, working code into
    the `__main__.py` module. We'll show you a quick hypothetical example to extend
    existing packages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine that we have a generic statistical package, named `stats`, with a top-level
    `__main__.py` module. This implements a command-line interface that will compute
    descriptive statistics of a given CSV file. This application has a command-line
    API as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE150]'
  prefs: []
  type: TYPE_PRE
- en: This command uses a `–c` option to specify which column to analyze. The input
    filename is provided as a positional argument on the command line.
  prefs: []
  type: TYPE_NORMAL
- en: Let's assume, further, that we have a terrible design problem. We've defined
    a high-level function, `analyze()`, in the `stats/__main__.py` module.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our goal is to combine this with our Blackjack simulation. As we have a design
    error, this won''t work out well. We might *think* we can do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE151]'
  prefs: []
  type: TYPE_PRE
- en: We tried to use `stats.analyze()`, assuming that the useful, high-level interface
    is part of the package, not part of `__main__.py`. This kind of simple composition
    was made needlessly difficult by defining a function in `__main__`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We want to avoid being forced to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE152]'
  prefs: []
  type: TYPE_PRE
- en: We shouldn't need to create composite Python applications via the command-line
    API. In order to create a sensible composition of the existing applications, we
    might be forced to refactor `stats/__main__.py` to remove any definitions from
    this module and push them up into the package as a whole.
  prefs: []
  type: TYPE_NORMAL
- en: Designing long-running applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A long-running application server will be reading requests from some kind of
    queue and formulating responses to those requests. In many cases, we leverage
    the HTTP protocol and build application servers into a web server framework. See
    [Chapter 12](ch12.html "Chapter 12. Transmitting and Sharing Objects"), *Transmitting
    and Sharing Objects*, for details on how to implement RESTful web services following
    the WSGI design pattern.
  prefs: []
  type: TYPE_NORMAL
- en: A desktop GUI application has a lot of features in common with a server. It
    reads events from a queue that includes mouse and keyboard actions. It handles
    each event and gives some kind of GUI response. In some cases, the response may
    be a small update to a text widget. In other cases, a file might get opened or
    closed, and the state of menu items may change.
  prefs: []
  type: TYPE_NORMAL
- en: 'In both cases, the central feature of the application is a loop that runs forever,
    handling events or requests. Because these loops are simple, they''re often part
    of the framework. For a GUI application, we might have a loop like the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE153]'
  prefs: []
  type: TYPE_PRE
- en: For `Tkinter` applications, the top-level widget's `mainloop()` gets each GUI
    event and hands it to the appropriate framework component for handling. When the
    object handling events—the top-level widget, `root`, in the example—executes the
    `quit()` method, then the loop will be gracefully terminated.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a WSGI-based web server framework, we might have a loop like the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE154]'
  prefs: []
  type: TYPE_PRE
- en: In this case, the server's `serve_forever()` method gets each request and hands
    it to the application—`debug` in this example—for handling. When the application
    executes the server's `shutdown()` method, the loop will be gracefully terminated.
  prefs: []
  type: TYPE_NORMAL
- en: 'We often have some additional requirements that distinguish long-running applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Robust**: In one sense, this requirement is needless; all software should
    work. However, when dealing with external OS or network resources, there are timeouts
    and other errors that must be confronted successfully. An application framework
    that allows for plugins and extensions enjoys the possibility of an extension
    component harboring an error that the overall framework must handle gracefully.
    Python''s ordinary exception handling is perfectly adequate for writing robust
    servers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Auditable**: A simple, centralized log is not always sufficient. In [Chapter
    14](ch14.html "Chapter 14. The Logging and Warning Modules"), *The Logging and
    Warning Modules*, we addressed techniques to create multiple logs to support the
    security or financial audit requirements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Debuggable**: Ordinary unit testing and integration testing reduces the need
    for complex debugging tools. However, external resources and software plugins
    or extensions create complexities that may be difficult to handle without providing
    some debugging support. More sophisticated logging can be helpful.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Configurable**: Except for simple technology spikes, we want to be able to
    enable or disable the application features. Enabling or disabling debugging logs,
    for example, is a common configuration change. In some cases, we want to make
    these changes without completely stopping and restarting an application. In [Chapter
    13](ch13.html "Chapter 13. Configuration Files and Persistence"), *Configuration
    Files and Persistence*, we looked at some techniques to configure an application.
    In [Chapter 16](ch16.html "Chapter 16. Coping With the Command Line"), *Coping
    with the Command Line*, we extended these techniques.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Controllable**: A simplistic long-running server can simply be killed to
    restart it with a different configuration. In order to ensure that buffers are
    flushed properly and OS resources are released properly, it''s better to use a
    signal other than `SIGKILL` to force termination. Python has signal-handling capabilities
    available in the `signal` module.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These last two requirements—dynamic configuration and clean shutdown—lead us
    to separate the primary event or request input from a secondary control input.
    This control input can provide additional requests for configuration or shutdown.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have a number of ways to provide asynchronous inputs through an additional
    channel:'
  prefs: []
  type: TYPE_NORMAL
- en: One of the simplest ways is to create a queue using the `multiprocessing` module.
    In this case, a simple administrative client can interact with this queue to control
    or interrogate the server or GUI. For more examples of `multiprocessing`, see
    [Chapter 12](ch12.html "Chapter 12. Transmitting and Sharing Objects"), *Transmitting
    and Sharing Objects*. We can transmit the control or status objects between the
    administrative client and the server.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lower-level techniques are defined in *Chapter 18* of *Python Standard Library*.
    These modules can also be used to coordinate with a long-running server or GUI
    application. They're not as sophisticated as creating a queue or a pipe via `multiprocessing`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generally, we're going to be most successful using the higher-level APIs available
    through `multiprocessing`. The lower-level techniques (`socket`, `signal`, `mmap`,
    `asyncore`, and `asynchat`) are relatively primitive and provide few features.
    They should be viewed as the internal support for higher-level modules such as
    `multiprocessing`.
  prefs: []
  type: TYPE_NORMAL
- en: Organizing code into src, bin, and test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we noted in the previous section, there's no essential need for a complex
    directory structure. Simple Python applications can be built in a simple, flat
    directory. We can include the application modules, test modules, as well as `setup.py`
    and `README`. This is pleasantly simple and easy to work with.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the modules and packages get more complex, however, we''ll often need
    to be a bit more structured. For complex applications, one common approach is
    to segregate Python code into three bundles. To make the examples concrete, let''s
    assume that our application is called `my_app`. Here are the typical directories
    we might create:'
  prefs: []
  type: TYPE_NORMAL
- en: '`my_app/my_app`: This directory has all of the working application code. All
    of the various modules and packages are here. A vaguely named `src` directory
    is uninformative. This `my_app` directory should include an empty `__init__.py`
    file so that the application also acts as a package.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`my_app/bin` or `my_spp/scripts`: This directory can have any scripts that
    form an OS-level command-line API. These scripts can be copied to the Python `scripts`
    directory by `setup.py`. As noted previously, these should be like the `__main__.py`
    module; they should be very short, and they can be thought of as OS filename aliases
    for Python code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`my_app/test`: This directory can have the various `unittest` modules. This
    directory, too, should include an empty `__init__.py` file so that it acts as
    a package. It can also include `__main__.py` to run all of the tests in the entire
    package.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The top-level directory name, `my_app`, might be augmented with a version number
    to permit having versions without confusion. We might have `my_app-v1.1` as a
    top-level directory name. The application within that top-level directory must
    have a proper Python name, so we'd see `my_app-v1.1/my_app` as the path to the
    application.
  prefs: []
  type: TYPE_NORMAL
- en: The top-level directory should contain the `setup.py` file to install the application
    into Python's standard library structure. See *Distributing Python Modules* for
    more information. Additionally, of course, a `README` file would be placed in
    this directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the application modules and test modules are in separate directories,
    we need to refer to the application as an installed module when running tests.
    We can use the `PYTHONPATH` environment variable for this. We can run the test
    suite like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE155]'
  prefs: []
  type: TYPE_PRE
- en: We set an environment variable on the same line where we execute a command.
    This may be surprising, but it's a first-class feature of the `bash` shell. This
    allows us to make a very localized override to the `PYTHONPATH` environment variable.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Python modules
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have several techniques to install a Python module or package:'
  prefs: []
  type: TYPE_NORMAL
- en: We can write `setup.py` and use the distribution utilities module, `distutils`,
    to install the package into Python's `lib/site-packages` directory. See *Distributing
    Python Modules*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can set the `PYTHONPATH` environment variable to include our packages and
    modules. We can set this temporarily in a shell, or we can set it more permanently
    by editing our `~/.bash_profile` or the system's `/etc/profile`. We'll take a
    look at this in a little more depth in the later section.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can include the `.pth` files to add directories to the import path. These
    files can be located in the local directory or `lib/site-packages` to provide
    an indirect reference to a module or package. See the `site` module documentation
    in *Python Standard Library* for more information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The local directory is a package as well. It's always first on the `sys.path`
    list. When working on a simple one-module Python application, this is very handy.
    When working on a more complex application, the current working directory may
    change as we edit different files, making it a poor choice.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Setting the environment variable can be done transiently or persistently. We
    can set it in an interactive session with a command like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE156]'
  prefs: []
  type: TYPE_PRE
- en: This sets `PYTHONPATH` to include the named directory when searching for a module.
    The module is effectively installed through this simple change to the environment.
    Nothing is written to Python's `lib/site-packages`.
  prefs: []
  type: TYPE_NORMAL
- en: This is a transient setting that may be lost when we end the terminal session.
    The alternative is to update our `~/.bash_profile` to include a more permanent
    change to the environment. We simply append that `export` line to `.bash_profile`
    so that the package is used every time we log in.
  prefs: []
  type: TYPE_NORMAL
- en: For users on a shared server, we might include the environment setting in `/etc/profile`
    so that they do not have to make changes to their `~/.bash_profile`. For users
    on individual workstations, offering `setup.py` based on `distutils` may be simpler
    than tweaking system settings.
  prefs: []
  type: TYPE_NORMAL
- en: For web applications, the Apache configuration may need to be updated to include
    access to the necessary Python modules. To support the rapid deployment of application
    changes, it's generally not necessary to use `setup.py` for a large, complex application.
    Instead, we often use a series of application directories and a simple `.pth`
    change or `PYTHONPATH` change to move to the new release.
  prefs: []
  type: TYPE_NORMAL
- en: 'We might have the following kind of directories owned by a fake user, `myapp`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE157]'
  prefs: []
  type: TYPE_PRE
- en: This allows us to build a new release in parallel with an existing release.
    We can switch from Version 1.2 to Version 1.3 by changing `PYTHONPATH` to refer
    to `/Users/myapp/my_app-v1.3/my_app`.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We looked at a number of considerations to design modules and packages. The
    parallels between a module and singleton class are deep. When we design a module,
    the essential questions of the encapsulation of the structure and processing are
    as relevant as they are for class design.
  prefs: []
  type: TYPE_NORMAL
- en: When we design a package, we need to be skeptical of the need for deeply nested
    structures. We'll need to use packages when there are variant implementations;
    we looked at a number of ways to handle this variability. We may also need to
    define a package to combine a number of modules into a single module-like package.
    We looked at how `__init__.py` can import from within the package.
  prefs: []
  type: TYPE_NORMAL
- en: Design considerations and trade-offs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have a deep hierarchy of packaging techniques. We can simply organize the
    functionality into defined functions. We can combine the defined functions and
    their related data into a class. We can combine related classes into a module.
    We can combine related modules into a package.
  prefs: []
  type: TYPE_NORMAL
- en: When we think of software as a language to capture knowledge and representation,
    we have to consider what a class or module *means*. A module is the unit of the
    Python software construction, distribution, use, and reuse. With rare exceptions,
    modules must be designed around the possibility of reuse.
  prefs: []
  type: TYPE_NORMAL
- en: In most cases, we'll use a class because we expect to have multiple objects
    that are instances of the class. Often—but not universally—a class will have stateful
    instance variables.
  prefs: []
  type: TYPE_NORMAL
- en: When we look at classes with only a single instance, it's not perfectly clear
    if a class is truly necessary. Standalone functions may be as meaningful as a
    single-instance class. In some instances, a module of separate functions may be
    an appropriate design because modules are inherently singletons.
  prefs: []
  type: TYPE_NORMAL
- en: A stateful module—such as a stateful class—is the general expectation. A module
    is a namespace with local variables that can be modified.
  prefs: []
  type: TYPE_NORMAL
- en: While we can create immutable classes (using `__slots__`, extending `tuple`,
    or overriding the attribute setter methods), we can't easily create an immutable
    module. There doesn't seem to be a use case for an immutable module object.
  prefs: []
  type: TYPE_NORMAL
- en: A small application may be a single module. A larger application will often
    be a package. As with module design, packages should be designed for reuse. A
    larger application package should properly include a `__main__` module.
  prefs: []
  type: TYPE_NORMAL
- en: Looking forward
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the next chapter, we'll consolidate a number of our OO design techniques.
    We'll take a look at the overall quality of our design and implementation. One
    consideration is assuring others that our software is trustworthy. One aspect
    of trustworthy software is coherent, easy-to-use documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 18. Quality and Documentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Good software doesn''t just happen; it''s crafted. A deliverable product includes
    readable, accurate documentation. We''ll look at two tools to produce the documentation
    from the code: `pydoc` and Sphinx. The Sphinx tool is enhanced if we write the
    documentation using a lightweight markup language. We''ll describe some features
    of **ReStructured Text** (**RST**) to help make our documentation more readable.'
  prefs: []
  type: TYPE_NORMAL
- en: Documentation is an important quality aspect of software; it is one aspect of
    building trust. Test cases are another way to build trust. Using `doctest` to
    write test cases addresses both the quality aspects.
  prefs: []
  type: TYPE_NORMAL
- en: We'll also take a brief look at literate programming techniques. The idea is
    to write a pleasant, easy-to-understand document that contains the entire body
    of the source code along with explanatory notes and design details. Literate programming
    isn't simple, but it can produce good code coupled with a resulting document that
    is very clear and complete.
  prefs: []
  type: TYPE_NORMAL
- en: Writing docstrings for the help() function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Python provides numerous places to include the documentation. The definition
    of a package, module, class, or function has room for a string that includes a
    description of the object that is being defined. Throughout this book, we avoided
    showing you docstrings in each example because our focus is on the Python programming
    details, not the overall software product that is being delivered.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we move beyond advanced OO design and look at the overall deliverable product,
    docstrings become an important part of the deliverable. Docstrings can provide
    us with several key pieces of information:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The API: the parameters, return values, and exceptions raised.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A description of what to expect.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optionally, the `doctest` test results. For more information, see [Chapter 15](ch15.html
    "Chapter 15. Designing for Testability"), *Designing for Testability*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can, of course, write even more in a docstring. We can provide more details
    on the design, architecture, and requirements. At some point, these more abstract,
    higher-level considerations are not directly tied to the Python code. This higher-level
    design and the requirements don't properly belong to the code or the docstrings.
  prefs: []
  type: TYPE_NORMAL
- en: The `help()` function extracts and displays the docstrings. It performs some
    minimal formatting on the text. The `help()` function is installed into the interactive
    Python environment by the `site` package. The function is actually defined in
    the `pydoc` package. In principle, we can import and extend this package to customize
    the `help()` output.
  prefs: []
  type: TYPE_NORMAL
- en: Writing documentation that is suitable for `help()` is relatively simple. Here's
    a typical example of output from `help(round)`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE158]'
  prefs: []
  type: TYPE_PRE
- en: 'This shows us the required elements: the summary, the API, and the description.
    The API and the summary are the first line: `function( parameters ) -> results`.'
  prefs: []
  type: TYPE_NORMAL
- en: The description text defines what the function does. More complex functions
    may describe exceptions or edge cases that might be important or unique to this
    function. The `round()` function, for example, doesn't detail things, such as
    `TypeError`, that might get raised.
  prefs: []
  type: TYPE_NORMAL
- en: A `help()` oriented docstring is expected to be pure text with no markup. We
    can add some RST markup but it isn't used by `help()`.
  prefs: []
  type: TYPE_NORMAL
- en: To make `help()` work, we simply provide docstrings. As it's so simple, there's
    no reason not to do it. Every function or class needs a docstring so that `help()`
    shows us something useful.
  prefs: []
  type: TYPE_NORMAL
- en: Using pydoc for documentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We use the library module `pydoc` to produce HTML documentation from Python
    code. It turns out that we're using it when we evaluate the `help()` function
    in interactive Python. This function produces the *text mode* documentation with
    no markup.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we use `pydoc` to produce the documentation, we''ll use it in one of the
    following three ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Prepare text-mode documentation files and view them with command-line tools
    such as `more` or `less`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prepare HTML documentation and save a file for browsing later
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run an HTTP server and create the HTML files as needed for browsing immediately
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can run the following command-line tool to prepare the text-based documentation
    for a module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE159]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE160]'
  prefs: []
  type: TYPE_PRE
- en: Either command will create text documentation based on the Python code. The
    output will be displayed with programs such as `less` (on Linux or Mac OS X) or
    `more` (on Windows) that paginate the long stream of output.
  prefs: []
  type: TYPE_NORMAL
- en: Ordinarily, `pydoc` presumes that we're providing a module name to import. This
    means that the module must be on the Python path for ordinary import. As an alternative,
    we can specify a physical filename by including a path separator character `/`
    (on Linux or Mac OS X) or `\` (on Windows) and the `.py` filename extension. Something
    such as `pydoc ./mymodule.py` will work to pick a file that's not on the import
    path.
  prefs: []
  type: TYPE_NORMAL
- en: 'To view the HTML documentation, we use the `-w` option. This will write an
    HTML file into the local directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE161]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then open `somemodule.html` in a browser to read the documentation for
    the given module. The third option is to start a special-purpose web server to
    browse a package or module''s documentation. In addition to simply starting the
    server, we can combine starting the server and launching our default browser.
    Here''s a way to simply start a server on port 8080:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE162]'
  prefs: []
  type: TYPE_PRE
- en: This will start an HTTP server that looks at the code in the current directory.
    If the current directory is a proper package (that is, it has a `__init__.py`
    file), then there will be a nice top-level module index.
  prefs: []
  type: TYPE_NORMAL
- en: Once we've started a server, we can point a browser at `http://localhost:8080`
    to view the documentation. We can also use a rewrite rule to point a local Apache
    server at this `pydoc` server so that a team can share the documentation on a
    web server.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also start both a local server and a browser at the same time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE163]'
  prefs: []
  type: TYPE_PRE
- en: This will locate an unused port, start a server, and then launch your default
    browser to point at the server. Note the use of the `python3.3` command; this
    doesn't work in the older releases of Python.
  prefs: []
  type: TYPE_NORMAL
- en: It's not easy to customize the output from `pydoc`. The various styles and colors
    are effectively hardcoded into the class definitions. Revising and expanding `pydoc`
    to use the external CSS styles would be an interesting exercise.
  prefs: []
  type: TYPE_NORMAL
- en: Better output via the RST markup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our documentation can be much nicer if we use a more sophisticated toolset.
    There are several things that we''d like to be able to do, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tune the presentation to include emphasis such as bold, italic, or color.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide the semantic markup for the parameters, return values, exceptions, and
    cross-references among Python objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide a link to view the source code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Filter the code that''s included or rejected. We can fine-tune this filtering
    to include or exclude a number of components and members: standard library modules,
    private members with a leading `__`, system members with a leading `__`, or superclass
    members.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adjust the CSS to provide a different style for the resulting HTML pages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can address the first two requirements through more sophisticated markup
    in our docstrings; we'll need to use the RST markup language. We'll need an additional
    tool to address the last three requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Once we start using more sophisticated markup, we can branch out beyond HTML
    to include LaTeX for even better-looking documentation. This allows us to also
    produce PostScript or PDF output in addition to HTML from a single source.
  prefs: []
  type: TYPE_NORMAL
- en: RST is a simple, lightweight markup. There are plenty of good tutorials and
    summaries associated with the Python `docutils` project. See [http://docutils.sourceforge.net](http://docutils.sourceforge.net)
    for details.
  prefs: []
  type: TYPE_NORMAL
- en: 'A quick overview is available here: [http://docutils.sourceforge.net/docs/user/rst/quickstart.html](http://docutils.sourceforge.net/docs/user/rst/quickstart.html).'
  prefs: []
  type: TYPE_NORMAL
- en: The point of the `docutils` toolset is that a very smart parser allows us to
    use very simple markup. HTML and XML rely on a relatively unsophisticated parser
    and put the burden on the human (or an editing tool) to create the complex markup.
    While XML and HTML allow for a wide variety of use cases, the `docutils` parser
    is more narrowly focused on the natural language text. Because of the narrow focus,
    `docutils` is able to deduce our intent based on the use of blank lines and some
    ASCII punctuation characters.
  prefs: []
  type: TYPE_NORMAL
- en: 'For our purposes, the `docutils` parser recognizes the following three fundamental
    things:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Blocks of text: paragraphs, headings, lists, block quotes, code samples, and
    the `doctest` blocks. These are all separated by blank lines.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inline markup can appear inside the text blocks. This involves the use of simple
    punctuation to mark the characters within the text block. There are two kinds
    of inline markup; we'll look at the details in the later section.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Directives are also blocks of text, but they begin with `..` as the first two
    characters of the line. Directives are open-ended and can be extended to add features
    to docutils.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blocks of text
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A block of text is simply a paragraph, set off from other paragraphs by a blank
    line. This is the fundamental unit of the RST markup. RST recognizes a number
    of kinds of paragraphs, based on the pattern that is followed. Here''s an example
    of a heading:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE164]'
  prefs: []
  type: TYPE_PRE
- en: This is recognized as a heading because it's *underlined* with a repeated string
    of special characters.
  prefs: []
  type: TYPE_NORMAL
- en: The `docutils` parser deduces the hierarchy of title underlines based entirely
    on their usage. We must be consistent with our headings and their nesting. It
    helps to pick a standard and stick to it. It also helps to keep documents fairly
    *flat* without complex, nested headings. Three levels are often all that's needed;
    this means that we can use `====`, `----`, and `~~~~` for the three levels.
  prefs: []
  type: TYPE_NORMAL
- en: 'A bullet list item begins with a special character; the content must also be
    indented. As Python uses a 4-space indent, this is common in RST as well. However,
    almost any consistent indent will work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE165]'
  prefs: []
  type: TYPE_PRE
- en: Note the blank line between paragraphs. For some kinds of simple bullet lists,
    the blank lines aren't required. In general, blank lines are a good idea.
  prefs: []
  type: TYPE_NORMAL
- en: 'A numeric list begins with a digit or letter and a roman numeral. To have numbers
    generated automatically, `#` can be used as the list item:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE166]'
  prefs: []
  type: TYPE_PRE
- en: We can use the indent rules to create lists within lists. It can be complex,
    and the `docutils` RST parser will usually figure out what you meant.
  prefs: []
  type: TYPE_NORMAL
- en: 'A block quote is simply indented text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE167]'
  prefs: []
  type: TYPE_PRE
- en: Code samples are indicated with a `::` double colon; they are indented and they
    end with a blank line. While `::` can be at the end of a line or on a line by
    itself, putting `::` on a separate line makes it slightly easier to find code
    samples.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a code sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE168]'
  prefs: []
  type: TYPE_PRE
- en: The `docutils` parser will also locate the `doctest` material and set it aside
    for special formatting, similar to a code block. They begin with `>>>` and end
    with a blank line.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s some sample output from `doctest`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE169]'
  prefs: []
  type: TYPE_PRE
- en: The blank line at the end of the test output is essential and is easily overlooked.
  prefs: []
  type: TYPE_NORMAL
- en: The RST inline markup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Within most blocks of text, we can include inline markup. We can't include inline
    markup in the code samples or `doctest` blocks. Note that we cannot nest inline
    markup, either.
  prefs: []
  type: TYPE_NORMAL
- en: The RST inline markup includes a variety of common ASCII treatments of text.
    For example, we have `*emphasis*` and `**strong emphasis**`, which will usually
    produce italic and bold respectively. We might want to emphasize code segments
    within a block of text; we use [PRE170] to force a monospaced font.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also include cross-references as the inline markup. A trailing `_` indicates
    a reference, and it points away; a leading `_` indicates a target, and it points
    toward. For example, we might have ``some phrase`_` as a reference. We can then
    use `_`some phrase`` as the target for that reference. We don''t need to provide
    explicit targets for section titles: we can reference ``This Is A Heading`_` because
    all the section titles are already defined as targets. For the HTML output, this
    will generate the expected `<a>` tags. For the PDF output, in-text links will
    be generated.'
  prefs: []
  type: TYPE_NORMAL
- en: We cannot nest inline markup. There's little need for nested inline markup;
    using too many typographic tricks devolves to visual clutter. If our writing is
    so sensitive to typography, we should probably use LaTeX directly.
  prefs: []
  type: TYPE_NORMAL
- en: Inline markup can also have explicit role indicators. This is `:role:` followed
    by ``text``. Simple RST has relatively few roles. We might use `:code:`some code``
    to be more explicit about the presence of a code sample in the text. When we look
    at Sphinx, there are numerous role indicators. The use of explicit roles can provide
    a great deal of semantic information.
  prefs: []
  type: TYPE_NORMAL
- en: 'When doing things that have more complex math, we might use the LaTeX math
    typesetting capabilities. This uses the `:math:` role; it looks like this: `:math:`a=\pi
    r^2``.'
  prefs: []
  type: TYPE_NORMAL
- en: Roles are open-ended. We can provide a configuration to docutils that adds new
    roles.
  prefs: []
  type: TYPE_NORMAL
- en: RST directives
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: RST also includes directives. A directive is written in a block that starts
    with `..`; it may have content that's indented. It may also have parameters. RST
    has a large number of directives that we might use to create a more sophisticated
    document. For docstring preparation, we'll rarely use more than a few of the available
    directives. The directives are open-ended; tools such as Sphinx will add directives
    to produce more sophisticated documentation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Three commonly used directives are `image`, `csv-table`, and `math`. If we
    have an image that should be part of our document, we might include it in the
    following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE171]'
  prefs: []
  type: TYPE_PRE
- en: We named the file `media/some_file.png`. We also provided it with a `width`
    parameter to ensure that our image fits our document page layout. There are a
    number of other parameters that we can use to adjust the presentation of an image.
  prefs: []
  type: TYPE_NORMAL
- en: '`:align`: We can provide keywords such as `top`, `middle`, `bottom`, `left`,
    `center`, or `right`. This value will be provided to the `align` attribute of
    the HTML `<img>` tag.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`:alt`: This is the alternative text for the image. This value will be provided
    to the `alt` attribute of the HTML `<img>` tag.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`:height`: This is the height of the image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`:scale`:This is a scale factor that can be provided instead of the height
    and width.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`:width`: This is the width of the image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`:target`: This is a target hyperlink for the image. This can be a complete
    URI or an RST reference of the ``name`_` form.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For the height and width, any of the length units available in CSS can be used.
    These include `em` (the height of the element''s font), `ex` (the height of the
    letter "x"), `px` (pixels), as well as absolute sizes: `in`, `cm`, `mm`, `pt`
    (point), and `pc` (pica).'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can include a table in our document in the following manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE172]'
  prefs: []
  type: TYPE_PRE
- en: 'This allows us to prepare data that will become a complex HTML table in a simple
    CSV notation. We can have a more complex formula using the `math` directive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE173]'
  prefs: []
  type: TYPE_PRE
- en: This allows us to write larger LaTeX math that will be a separate equation.
    These can be numbered and cross-referenced as well.
  prefs: []
  type: TYPE_NORMAL
- en: Learning RST
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One way to build skills in RST is to install `docutils` and use the `rst2html.py`
    script to parse an RST document and convert it to HTML pages. A simple practice
    document can easily show us the various RST features.
  prefs: []
  type: TYPE_NORMAL
- en: All of a project's requirements, architecture, and documentation can be written
    using RST and transformed into HTML or LaTeX. It's relatively inexpensive to write
    user stories in RST and drop those files into a directory that can be organized
    and reorganized as stories are groomed, put into development, and implemented.
    More complex tools may not be any more valuable than `docutils`.
  prefs: []
  type: TYPE_NORMAL
- en: The advantage of using pure text files and the RST markup is that we can easily
    manage our documentation in parallel with our source code. We're not using a proprietary
    word processing file format. We're not using a wordy and long-winded HTML or XML
    markup that must be compressed to be practical. We're simply storing more text
    along with the source code.
  prefs: []
  type: TYPE_NORMAL
- en: If we're using RST to create the documentation, we can also use the `rst2latex.py`
    script to create a `.tex` file that we can run through a LaTeX toolset to create
    postscript or PDF documents. This requires a LaTeX toolset; usually, the **TeXLive**
    distribution is used for this. See [http://www.tug.org/texlive/](http://www.tug.org/texlive/)
    for a comprehensive set of tools to transform TeX into elegant, final documents.
    TeXLive includes the pdfTeX tool that can be used to convert the LaTeX output
    into a PDF file.
  prefs: []
  type: TYPE_NORMAL
- en: Writing effective docstrings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When writing docstrings, we need to focus on the essential information that
    our audience needs. When we look at using a library module, what do we need to
    know? Whatever questions we ask, other programmers will often have similar questions.
    There are two boundaries that we should stay inside when we write docstrings:'
  prefs: []
  type: TYPE_NORMAL
- en: It's best to avoid abstract overviews, high-level requirements, user stories,
    or background that is not tied directly to the code. We should focus the docstring
    on the code itself. We should provide the background in a separate document. A
    tool such as Sphinx can combine background material and code into a single document.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's best to also avoid overly detailed *how it works* implementation trivia.
    The code is readily available, so there's no point in recapitulating the code
    in the documentation. If the code is too obscure, perhaps it should be rewritten
    to make it clearer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perhaps the single most important thing that developers want is a working example
    of how to use the Python object. The RST `::` literal block is the backbone of
    these examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll often write code samples in the following manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE174]'
  prefs: []
  type: TYPE_PRE
- en: The double colon, `::`, precedes an indented block. The indented block is recognized
    by the RST parser as code and will be literally passed through to the final document.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to an example, the formal API is also important. We'll take a look
    at several API definition techniques in the later section. These rely on the RST
    *field list* syntax. It's very simple, which makes it very flexible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we''re past the example and the API, there are a number of other things
    that compete for third place. What else we need to write depends on the context.
    There appear to be three cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Files (including packages and modules)**: In these cases, we''re providing
    an overview or introduction to a collection of modules, classes, or function definitions.
    We need to provide a simple roadmap or overview of the various elements in the
    file. In the case where the module is relatively small, we might provide the doctest
    and code samples at this level.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Classes (including method functions)**: This is where we often provide code
    samples and `doctest` blocks that explain the class API. Because a class may be
    stateful and may have a relatively complex API, we may need to provide rather
    lengthy documentation. Individual method functions will often have detailed documentation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Functions**: We may provide code samples and `doctest` blocks that explain
    the function. Because a function is often stateless, we may have a relatively
    simple API. In some cases, we may avoid more sophisticated RST markup and focus
    on the `help()` function''s documentation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We'll take a look at each of these broad, vague documentation contexts in some
    detail.
  prefs: []
  type: TYPE_NORMAL
- en: Writing file-level docstrings, including modules and packages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A package or a module's purpose is to contain a number of elements. A package
    contains modules as well as classes, global variables, and functions. A module
    contains classes, global variables, and functions. The top-level docstrings on
    these containers can act as road-maps to explain the general features of the package
    or module. The details are delegated to the individual classes or functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We might have a module docstring that looks like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE175]'
  prefs: []
  type: TYPE_PRE
- en: Most of the text in this docstring provides a roadmap to the contents of this
    module. It describes the class hierarchies, making it slightly easier to locate
    a relevant class.
  prefs: []
  type: TYPE_NORMAL
- en: The docstring includes a simple example of the `card()` factory function based
    on `doctest`. This advertises this function as an important feature of the module
    as a whole. It might make sense to provide the `doctest` explanation of the `Shoe`
    class, as that's perhaps the most important part of this module.
  prefs: []
  type: TYPE_NORMAL
- en: This docstring includes some inline RST markup to put class names into a monospaced
    font. The section titles are *underlined* with `===` and `---` lines. The RST
    parser can determine that the heading underlined with `===` is the parent of the
    headings underlined with `---`.
  prefs: []
  type: TYPE_NORMAL
- en: We'll look at using Sphinx to produce the documentation, in the later section.
    Sphinx will leverage the RST markup to produce great-looking HTML documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Writing API details in RST markup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'One of the benefits of using the RST markup is that we can provide formal API
    documentation. The API parameters and return values are formatted using an RST
    *field list*. Generally, a field list has the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE176]'
  prefs: []
  type: TYPE_PRE
- en: A field list is a sequence of field labels (as `:label:`) and a value associated
    with that label. The label is generally short, and the value can be as long as
    needed. Field lists are also used to provide parameters to directives.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the field list''s text is present in an RST document, the docutils tools
    can create a nice-looking, table-like display. In PDF, it might look like the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE177]'
  prefs: []
  type: TYPE_PRE
- en: We'll use an extended form of the RST field list syntax to write the API documentation.
    We'll extend the field name to become a multipart item. We'll add prefixes with
    keywords such as `param` or `type`. The prefix will be followed by the parameter's
    name.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several field prefixes. We can use any of these: `param`, `parameter`,
    `arg`, `argument`, `key`, and `keyword`. For example, we might write the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE178]'
  prefs: []
  type: TYPE_PRE
- en: We generally use `param` (or `parameter`) for the positional parameters and
    `key` (or `keyword`) for the keyword parameters. We advise you against using `arg`
    or `argument` to document Python code, as they don't fit the Python syntax categories.
    These prefixes could be used to document shell scripts or APIs in other languages.
  prefs: []
  type: TYPE_NORMAL
- en: These field list definitions will be collected into an indented section. The
    Sphinx tool will also compare the names in the documentation with the names in
    the function argument list to be sure that they match.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also define the type of a parameter using `type` as a prefix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE179]'
  prefs: []
  type: TYPE_PRE
- en: 'Because of Python''s flexibility, this can be a needless detail. In many cases,
    the argument value need only be numeric, and simple `:param somearg:` can include
    generic type information as part of the description. We showed you this style
    in the earlier example: `Numeric rank of the card`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For functions that return a value, we should describe the result. We can summarize
    the return value with the field label of `returns` or `return`. We can also formally
    specify the type of the return value with `rtype`. We might write the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE180]'
  prefs: []
  type: TYPE_PRE
- en: 'Additionally, we should also include information about exceptions that are
    unique to this function. We have four aliases for this field: `raises`, `raise`,
    `except`, and `exception`. We would write the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE181]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also describe the attributes of a class. For this, we can use `var`,
    `ivar`, or `cvar`. We might write the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE182]'
  prefs: []
  type: TYPE_PRE
- en: We should use `ivar` for instance variables and `cvar` for class variables.
    However, there's no visible difference in the final HTML output.
  prefs: []
  type: TYPE_NORMAL
- en: These field list constructs are used to prepare docstrings for classes, class
    methods, and standalone functions. We'll look at each case in the later section.
  prefs: []
  type: TYPE_NORMAL
- en: Writing class and method function docstrings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A class will often contain a number of elements, including attributes and method
    functions. A stateful class may also have a relatively complex API. Objects will
    be created, undergo changes in state, and possibly be garbage-collected at the
    end of their lives. We might want to describe some (or all) of these state changes
    in the class docstring or the method function docstrings.
  prefs: []
  type: TYPE_NORMAL
- en: We'll use the field list technique to document the class variables in the overall
    class docstring. This will generally focus on using the `:ivar variable:`, `:cvar
    variable:`, and `:var variable:` field list items.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each individual method function will also use field lists to define the parameters
    and return the values and exceptions raised by each method function. Here''s how
    we might start to write a class with docstrings for the class and method functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE183]'
  prefs: []
  type: TYPE_PRE
- en: When we include this kind of RST markup in the docstring, then a tool such as
    Sphinx can format very nice-looking HTML output. We've provided you with both
    class-level documentation of the instance variables as well as method-level documentation
    of the parameters to one of the method functions.
  prefs: []
  type: TYPE_NORMAL
- en: When we look at this with `help()`, the RST is visible. It's not too objectionable,
    as it's semantically meaningful and not very confusing. This points out a balance
    that we may need to strike between the `help()` text and the Sphinx documents.
  prefs: []
  type: TYPE_NORMAL
- en: Writing function docstrings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A function docstring can be formatted using field lists to define the parameters
    and return the values and raised exceptions. Here''s an example of a function
    that includes a docstring:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE184]'
  prefs: []
  type: TYPE_PRE
- en: This function docstring includes parameter definitions, return values, and the
    raised exceptions. There are four individual field list items that formalize the
    API. We've included a `doctest` sequence as well. When we document this module
    in Sphinx, we'll get very nice-looking HTML output. Additionally, we can use the
    `doctest` tool to confirm that the function matches the simple test case.
  prefs: []
  type: TYPE_NORMAL
- en: More sophisticated markup techniques
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are some additional markup techniques that can make a document easier
    to read. In particular, we often want useful cross-references between class definitions.
    We may also want cross-references between sections and topics within a document.
  prefs: []
  type: TYPE_NORMAL
- en: 'In *pure* RST (that is, without Sphinx), we need to provide proper URLs that
    reference different sections of our documents. We have three kinds of references:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Implicit references to section titles**: We can use ``Some Heading`_` to
    refer to the `Some Heading` section. This will work for all the headings that
    docutils recognizes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Explicit references to targets**: We can use `target_` to reference the location
    of `_target` in the document.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inter-document references**: We have to create a full URL that explicitly
    references a section title. Docutils will translate section titles into all lowercase,
    replacing the punctuation with `-`. This allows us to create a reference to a
    section title in an external document like this: ``Design <file:build.py.html#design>`_`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we use Sphinx, we get even more inter-document, cross-reference capabilities.
    These capabilities allow us to avoid trying to write detailed URLs.
  prefs: []
  type: TYPE_NORMAL
- en: Using Sphinx to produce the documentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Sphinx tool produces very good-looking documentation in a variety of formats.
    It can easily combine documentation from source code as well as external files
    with additional design notes, requirements, or background.
  prefs: []
  type: TYPE_NORMAL
- en: The Sphinx tool can be found at [http://sphinx-doc.org](http://sphinx-doc.org).
    The download can become complex because Sphinx depends on several other projects.
    It may be easier to first install `setuptools`, which includes the `easy_install`
    script, and then use this to install Sphinx. This can help us with the details
    of tracking down the additional projects that must be installed first.
  prefs: []
  type: TYPE_NORMAL
- en: See [https://pypi.python.org/pypi/setuptools](https://pypi.python.org/pypi/setuptools)
    for help on `setuptools`.
  prefs: []
  type: TYPE_NORMAL
- en: Some developers prefer to use `pip` for this kind of installation. See [https://pypi.python.org/pypi/pip](https://pypi.python.org/pypi/pip)
    for information on `pip`.
  prefs: []
  type: TYPE_NORMAL
- en: The Sphinx tutorial is outstanding. Start there and be sure that you can use
    `sphinx-quickstart` and `sphinx-build`. Often, running `sphinx-build` is handled
    via the `make` program, which slightly simplifies the command-line use of Sphinx.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Sphinx quickstart
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The handy feature of `sphinx-quickstart` is that it populates the rather complex
    `config.py` file via an interactive question-and-answer session.
  prefs: []
  type: TYPE_NORMAL
- en: Here's a part of one such session that shows how the dialog looks; we've highlighted
    a few responses where the defaults don't seem to be optimal.
  prefs: []
  type: TYPE_NORMAL
- en: 'For more complex projects, it''s simpler in the long run to separate the documentation
    from the working code. It''s often a good idea to create a `doc` directory within
    the overall project tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE185]'
  prefs: []
  type: TYPE_PRE
- en: 'For very small documents, it''s fine to interleave the source and HTML. For
    larger documents, particularly documents where there may be a need to produce
    LaTeX and PDF, it''s handy to keep these files separate from the HTML version
    of the documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE186]'
  prefs: []
  type: TYPE_PRE
- en: 'The next batch of questions identifies specific add-ons; it starts with the
    following note:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE187]'
  prefs: []
  type: TYPE_PRE
- en: We'll suggest a set of add-ons that seem most useful for general Python development.
    For first-time users of Sphinx, this will be enough to get started and produce
    excellent documentation. Clearly, specific project needs and objectives will override
    these generic suggestions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll almost always want to include the `autodoc` feature to produce the documentation
    from the docstrings. If we''re using Sphinx to produce the documentation outside
    the Python programming, perhaps we might turn `autodoc` off:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE188]'
  prefs: []
  type: TYPE_PRE
- en: 'If we have `doctest` examples, we can have Sphinx run the doctest for us. For
    small projects, where most of the testing is done via `doctest`, this can be very
    handy. For larger projects, we''ll often have a unit test script that includes
    doctest. Performing the doctest via Sphinx as well as through the formal unit
    test is still a good idea:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE189]'
  prefs: []
  type: TYPE_PRE
- en: 'A mature development effort may have many projects that are closely related;
    this might have multiple, related Sphinx documentation directories:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE190]'
  prefs: []
  type: TYPE_PRE
- en: 'The `todo` extension allows us to include a `.. todo::` directive in our docstrings.
    We can then add a special `.. todolist::` directive to create an official to-do
    list in the documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE191]'
  prefs: []
  type: TYPE_PRE
- en: 'The coverage report could be a handy quality assurance metric:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE192]'
  prefs: []
  type: TYPE_PRE
- en: 'For projects that involve any math, having a LaTeX toolset allows us to have
    the math nicely typeset as graphic images and included into HTML. It also leaves
    the raw math in the LaTeX output. MathJax is a web-based JavaScript library that
    also works in the following manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE193]'
  prefs: []
  type: TYPE_PRE
- en: 'For very complex projects, we might need to produce the variant documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE194]'
  prefs: []
  type: TYPE_PRE
- en: 'Most application documentations describe an API. We should include both the
    `autodoc` and `viewcode` features. The `viewcode` option allows the reader to
    view the source so they can understand the implementation in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE195]'
  prefs: []
  type: TYPE_PRE
- en: The `autodoc` and `doctest` features mean that we can focus on writing docstrings
    within our code. We only need to write very small Sphinx documentation files to
    extract the docstring information. For some developers, the ability to focus on
    the code reduces the fear factor associated with writing the documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Writing the Sphinx documentation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are two common starting points for software development projects:'
  prefs: []
  type: TYPE_NORMAL
- en: Some inception documentation has been created, and this should be preserved
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nothing; inception starts from a blank slate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the cases where a project starts with some legacy documentation, this might
    include the requirements, user stories, or architectural notes. It may also include
    notes on organizational politics, out-of-date budgets and schedules, and other
    technically irrelevant material.
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, these inception documents are already text files. If not, they may
    be in some word processor format that can be saved as text. When we have text-oriented
    inception documents, it's relatively easy to add enough RST markup to show us
    the outline structure and organize these text files into a simple directory structure.
  prefs: []
  type: TYPE_NORMAL
- en: There's little reason to preserve the content as a word-processing document.
    Once it's part of the technical content of a software development project, RST
    permits more flexible use of the inception information.
  prefs: []
  type: TYPE_NORMAL
- en: One of the difficult cases is a project where the inception documentation is
    a slideshow built using Keynote, PowerPoint, or a similar tool. These don't readily
    convert to text-centric RST, as the diagrams and images are first-class parts
    of the content. In these cases, it's sometimes best to export the presentation
    as an HTML document and put this into the Sphinx `doc/source/_static` directory.
    This will allow us to integrate the original material into Sphinx via simple RST
    links of the ``Inception <_static/inception_doc/index.html>`_` form.
  prefs: []
  type: TYPE_NORMAL
- en: 'When an interactive, web-based tool is used to manage the project or user stories,
    the inception and background documentation needs to be handled via simple URL
    references of this form: ``Background <http://someservice/path/to/page.html>`_`.'
  prefs: []
  type: TYPE_NORMAL
- en: It's often easiest to start with an outline of placeholders for the documentation
    that will accumulate as the software development proceeds. One structure that
    might be helpful is based on the 4+1 views of an architecture. The inception documents
    are often part of the scenarios or user stories in the 4+1 views. Sometimes, the
    inception documents are part of the development or physical deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'For more information, see this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://en.wikipedia.org/wiki/4%2B1_architectural_view_model](http://en.wikipedia.org/wiki/4%2B1_architectural_view_model)'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create five top-level documents under our `index.html` root: `user_stories`,
    `logical`, `process`, `implementation`, and `physical`. Each of these must have
    an RST title but needs nothing more in the file.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can then update the `.. toctree::` directive that''s generated in the Sphinx
    `index.rst` file by default:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE196]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have a top-level structure, we can use the `make` command to build
    our documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE197]'
  prefs: []
  type: TYPE_PRE
- en: This will run our doctests; if all the tests pass, it will create the HTML documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Filling in the 4+1 views for documentation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As the development proceeds, the 4+1 views can be used to organize the details
    that accumulate. This is used for the information that belongs outside the narrow
    focus of docstrings.
  prefs: []
  type: TYPE_NORMAL
- en: The `user_stories.rst` document is where we collect user stories, requirements,
    and other high-level background notes. This might evolve into a directory tree
    if the user stories become complex.
  prefs: []
  type: TYPE_NORMAL
- en: The `logical.rst` document will collect our initial OO designs for the class,
    module, and package. This should be the origin of our design thinking. It might
    contain alternatives, notes, mathematical backgrounds, proofs of correctness,
    and diagrams of the logical software design. For relatively simple projects—where
    the design is relatively clear—this may remain empty. For complex projects, this
    may describe some sophisticated analysis and design that serve as the background
    or justification for the implementation.
  prefs: []
  type: TYPE_NORMAL
- en: The final OO design will be the Python modules and classes that belong in the
    `implementation.rst` file. We'll take a look at this in a little more detail,
    as this will become our API documentation. This part will be based in a direct
    way on our Python code and the RST-markup docstrings.
  prefs: []
  type: TYPE_NORMAL
- en: The `process.rst` document can collect information about the dynamic, runtime
    behavior. This would include topics such as concurrency, distribution, and integration.
    It might also contain information on the performance and scalability. The network
    design and protocols used might be described here.
  prefs: []
  type: TYPE_NORMAL
- en: For smaller applications, the material that should go into the process document
    isn't perfectly clear. This document may overlap with the logical design and the
    overall architectural information. When in doubt, we have to strive for clarity
    based on the audience's need for information. For some users, many small documents
    are helpful. For other users, a single large document is preferred.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `physical.rst` file is where the deployment details can be recorded. A
    description of the configuration details would go here: the environment variables,
    the configuration file format details, the available logger names, and other information
    required for the administration and support. This might also include configuration
    information such as server names, IP addresses, account names, directory paths,
    and related notes. In some organizations, an administrator might feel that some
    of these details are not appropriate for general software documentation.'
  prefs: []
  type: TYPE_NORMAL
- en: Writing the implementation document
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `implementation.rst` document can be based on using `automodule` to create
    the documentation. Here's how an `implementation.rst` document might start.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE198]'
  prefs: []
  type: TYPE_PRE
- en: 'We used two kinds of RST headings: there''s a single top-level heading and
    two subheadings. RST deduces the relationship between the parent and the children.
    In this example, we''ve used "`===`" underlines for the parent heading (also the
    title) and "`---`" for the subheadings.'
  prefs: []
  type: TYPE_NORMAL
- en: We've provided you with an explicit reference to a document that was copied
    into the `_static` directory as `inception_doc`. We created a sophisticated RST
    link from the words *inception document* to the actual document's `index.html`
    file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Within the two subheadings, we used the Sphinx `.. automodule::` directive
    to extract the docstrings from two modules. We''ve provided you with three parameters
    to the automodule directives:'
  prefs: []
  type: TYPE_NORMAL
- en: '`:members:`: This includes all the members of the module. We can list explicit
    member classes and functions instead of listing all the members.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`:undoc-members:`: This includes members who lack proper docstrings. This is
    handy when starting development; we''ll still get some API information, but it
    will be minimal.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`:undoc-members:`: This includes special-method name members, not included
    in the Sphinx documentation by default.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This gives us a relatively complete view that is too complete sometimes. If
    we leave out all of these parameters, `:undoc-members:` and `:special-members:`,
    we'll get a smaller, more focused document.
  prefs: []
  type: TYPE_NORMAL
- en: Our `implementation.rst` file can evolve as our project evolves. We'll add the
    `automodule` references as the modules are completed.
  prefs: []
  type: TYPE_NORMAL
- en: The organization of the `.. automodule::` directives can provide us with a useful
    roadmap or overview of a complex collection of modules or packages. A little time
    spent organizing the presentation so that it shows us how the software components
    work together is more valuable than a great deal of verbiage. The point is not
    to create great narrative literature; the point is to provide guidance to the
    other developers.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the Sphinx cross-references
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sphinx expands the cross-reference techniques available via RST. The most important
    set of cross-reference capabilities is the ability to directly refer to specific
    Python code features. These make use of the inline RST markup using the `:role:`text``
    syntax. In this case, a large number of additional roles is part of Sphinx.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have the following kinds of cross-reference roles available:'
  prefs: []
  type: TYPE_NORMAL
- en: The `:py:mod:`some_module`` syntax will generate a link to the definition of
    this module or package.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `:py:func:`some_function`` syntax will generate a link to the definition
    of the function. A qualified name with `module.function` or `package.module.function`
    can be used.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `:py:data:`variable`` and `:py:const:`variable`` syntax will generate a
    link to a module variable that''s defined with a `.. py:data:: variable` directive.
    A *constant* is simply a variable that should not be changed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `:py:class:`some_class`` syntax will link to the class definition. Qualified
    names such as `module.class` can be used.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `:py:meth:`class.method`` syntax will link to a method definition.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `:py:attr:`class.attribute`` syntax will link to an attribute that''s defined
    with a `.. py:attribute:: name` directive.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `:py:exc:`exception`` syntax will link to a defined exception.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `:py:obj:`some_object`` syntax can create a generic link to an object.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we use [PRE199] in our docstring, we'll get the class name in a monospaced
    font. If we use `:py:class:`SomeClass``, we get a proper link to the class definition,
    which is often far more helpful.
  prefs: []
  type: TYPE_NORMAL
- en: The `:py:` prefix on each role is there because Sphinx can be used to write
    the documentation about other languages in addition to Python. By using this `:py:`
    prefix on each role, Sphinx can provide proper syntax additions and highlighting.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a docstring that includes explicit cross-references to other classes
    and exceptions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE200]'
  prefs: []
  type: TYPE_PRE
- en: By using `:py:class:`Card`` instead of [PRE201], we're able to create explicit
    links between this comment block and the definition of the `Card` class. Similarly,
    we used `:py:exc:`TypeError`` to permit an explicit link to this exception's definition.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we can define a link target via `.._some-name::` and reference
    that label from any document in the Sphinx documentation tree with `:ref:`some-name``.
    The name, `some-name`, must be globally unique. To ensure this, it's often good
    to define a kind of hierarchy so that the names are a kind of path from the document
    to the section to the topic.
  prefs: []
  type: TYPE_NORMAL
- en: Refactoring Sphinx files into directories
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For larger projects, we''ll need to use directories instead of simple files.
    In this case, we''ll perform the following steps to refactor a file into a directory:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the directory: `implementation`, for example.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Move the original `implementation.rst` file to `implementation/index.rst`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change the original `index.rst` file. Switch the `.. toctree::` directive to
    reference `implementation/index` instead of `implementation`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can then work within the `implementation` directory using the `.. toctree::`
    directive in the `implementation/index.rst` file to include other files that are
    in this directory.
  prefs: []
  type: TYPE_NORMAL
- en: When our documentation is split into simple directories of simple text files,
    we can edit small, focused files. Individual developers can make significant contributions
    without encountering any file-sharing conflicts that arise when trying to edit
    a large word-processing document.
  prefs: []
  type: TYPE_NORMAL
- en: Writing the documentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An important part of software quality comes from noting that the product is
    not simply *code* directed at a compiler or interpreter. As we noted in [Chapter
    15](ch15.html "Chapter 15. Designing for Testability"), *Designing for Testability*,
    code that cannot be trusted cannot be used. In that chapter, we suggested that
    testing was essential to establishing trust. We'd like to generalize that a bit.
    In addition to detailed testing, there are several other quality attributes that
    make the code usable, and trustworthiness is one of those attributes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We trust code in the following scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: We understand the use cases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We understand the data model and processing model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We understand the test cases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we look at more technical quality attributes, we see that these are really
    about understanding. For example, debugging seems to mean that we can confirm
    our understanding of how the application works. Auditability also seems to mean
    that we can confirm our understanding of processing by viewing specific examples
    to show that they work as expected.
  prefs: []
  type: TYPE_NORMAL
- en: 'Documentation creates trust. For more information on the software quality,
    start here: [http://en.wikipedia.org/wiki/Software_quality](http://en.wikipedia.org/wiki/Software_quality).
    There is a lot to learn about software quality; it''s a very large subject, and
    this is only one small aspect.'
  prefs: []
  type: TYPE_NORMAL
- en: Literate programming
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The idea of separating *documentation* from *code* can be viewed as an artificial
    distinction. Historically, we wrote documentation outside the code because the
    programming languages were relatively opaque and biased toward efficient compilation
    rather than clear exposition. Different techniques have been tried to reduce the
    distance between the working code and documentation about the code. Embedding
    more sophisticated comments, for example, is a long-standing tradition. Python
    takes this a step further by including a formal docstring in packages, modules,
    classes, and functions.
  prefs: []
  type: TYPE_NORMAL
- en: The literate programming approach to software development was pioneered by *Don
    Knuth*. The idea is that a single source document can produce efficient code as
    well as good-looking documentation. For machine-oriented assembler languages,
    and languages such as C, there's an additional benefit of moving away from the
    source language—a notation that emphasizes translation—toward a document that
    emphasizes clear exposition. Additionally, some literate programming languages
    act as a higher-level programming language; this might be appropriate for C or
    Pascal, but it is decidedly unhelpful for Python.
  prefs: []
  type: TYPE_NORMAL
- en: Literate programming is about promoting a deeper understanding of the code.
    In the case of Python, the source starts out very readable. Sophisticated literate
    programming isn't required to make a Python program understandable. Indeed, the
    main benefit of literate programming for Python is the idea of carrying deeper
    design and use case information in a form that is more readable than simple Unicode
    text.
  prefs: []
  type: TYPE_NORMAL
- en: For more information, see [http://www.literateprogramming.com](http://www.literateprogramming.com)
    and [http://xml.coverpages.org/xmlLitProg.html](http://xml.coverpages.org/xmlLitProg.html).
    The book *Literate Programming* by *Donald Knuth* is the seminal title on this
    topic.
  prefs: []
  type: TYPE_NORMAL
- en: Use cases for literate programming
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are two essential goals when creating a literate program:'
  prefs: []
  type: TYPE_NORMAL
- en: '**A working program**: This is the code, extracted from the source document(s)
    and prepared for the compiler or interpreter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Easy-to-read documentation**: This is the explanation plus the code plus
    any helpful markup prepared for the presentation. This document could be in HTML,
    ready to be viewed. Or it could be in RST, and we''d use docutils `rst2html.py`
    to convert it to HTML. Or, it could be in LaTeX and we run it through a LaTeX
    processor to create a PDF document.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *working program* goal means that our literate programming document will
    cover the entire suite of the source code files. While this seems daunting, we
    have to remember that well-organized code snippets don't require a lot of complex
    hand-waving; in Python, code itself can be clear and meaningful.
  prefs: []
  type: TYPE_NORMAL
- en: The *easy-to-read documentation* goal means that we want to produce a document
    that uses something other than a single font. While most code is written in a
    monospaced font, it isn't the easiest on our eyes. The essential Unicode character
    set doesn't include helpful font variants such as bold or italic either. These
    additional display details (the font change, size change, and style change) have
    evolved over the centuries to make a document more readable.
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, our Python IDE will color-code the Python source. This is helpful
    too. The history of written communication includes a lot of features that can
    enhance readability, none of which are available in simple Python source using
    a single font.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, a document should be organized around the problem and the solution.
    In many languages, the code itself *cannot* follow a clear organization because
    it's constrained by purely technical considerations of syntax and the order of
    the compilation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our two goals boil down to two technical use cases:'
  prefs: []
  type: TYPE_NORMAL
- en: Convert an original source text into the code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Covert an original source text into the final documentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can—to an extent—refactor these two use cases in some profound ways. For
    example, we can extract the documentation from the code. This is what the `pydoc`
    module does, but it doesn't handle the markup very well.
  prefs: []
  type: TYPE_NORMAL
- en: Both versions, code and final document, can be made isomorphic. This is the
    approach taken by the PyLit project. The final documentation can be embedded entirely
    in Python code via docstrings as well as `#` comments. The code can be embedded
    entirely in RST documents using `::` literal blocks.
  prefs: []
  type: TYPE_NORMAL
- en: Working with a literate programming tool
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Many **Literate Programming** (**LP**) tools are available. The essential ingredient
    —that varies from tool to tool—is the high-level markup language that separates
    the explanation from the code.
  prefs: []
  type: TYPE_NORMAL
- en: 'The source files that we write will contain the following three things:'
  prefs: []
  type: TYPE_NORMAL
- en: Text with markup that is the explanation and the description
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High-level markup to separate the text (with markup) from the code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because of the flexibility of XML, this can be used as the high-level markup
    for literate programming. It's not easy to write, however. There are tools that
    work with a LaTeX-like markup based on the original Web (and later CWeb) tools.
    There are some tools that work with RST as the high-level markup.
  prefs: []
  type: TYPE_NORMAL
- en: The essential step in choosing a tool, then, is to take a look at the high-level
    markup that is used. If we find that the markup is easy to write, we can comfortably
    use it to produce the source document.
  prefs: []
  type: TYPE_NORMAL
- en: 'Python presents an interesting challenge. Because we have RST-based tools such
    as Sphinx, we can have very literate docstrings. This leads us to two tiers of
    documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: Literate Programming explanations and the background that is outside the code.
    This should be the background material that's too general and not focused on the
    code itself.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The reference and API documentation embedded inside the docstrings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This leads to a pleasant, evolutionary approach to literate programming:'
  prefs: []
  type: TYPE_NORMAL
- en: Initially, we can start by embedding the RST markup in our docstrings so that
    a Sphinx-produced document looks good and provides a tidy explanation for the
    implementation choices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can step beyond a narrow docstring focus to create the background documentation.
    This might include information on the design decisions, architecture, requirements,
    and user stories. In particular, descriptions of nonfunctional quality requirements
    belong outside the code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once we've started to formalize this higher-level design documentation, we can
    more easily pick an LP tool. This tool will then dictate how we combine the documentation
    and code into a single, overall documentation structure. We can use an LP tool
    to extract the code and produce the documentation. Some LP tools can be used to
    run the test suite too.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our goal is to create software that is not only well designed, but also trustworthy.
    As noted previously, we create trust in a number of ways, including providing
    a tidy, clear explanation of why our design is good.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we use a tool such as PyLit, we might create RST files that look like the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE202]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a file written entirely in an RST markup. It contains some explanatory
    text, some formal math, and even some test cases. These provide us with additional
    details to support the relevant code sections. Because of the way PyLit works,
    we named the file `combo.py.txt`. There are three things we can do with this file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use PyLit to extract the code from this text file in the following manner:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE203]'
  prefs: []
  type: TYPE_PRE
- en: This creates `combo.py` from `combo.py.txt`. This is a Python module that is
    ready to be used.
  prefs: []
  type: TYPE_NORMAL
- en: We can also use docutils to format this RST into an HTML page that provides
    the documentation and code in a form that we can read more easily than the original
    single-font text.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE204]'
  prefs: []
  type: TYPE_PRE
- en: This creates `combo.py.html` ready for browsing. The `mathjax` package will
    be used by docutils to typeset the mathematical portions, leading to very nice-looking
    output.
  prefs: []
  type: TYPE_NORMAL
- en: We can, additionally, use PyLit to run `doctest` and confirm that this program
    really works.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE205]'
  prefs: []
  type: TYPE_PRE
- en: This will extract the `doctest` blocks from the code and run them through the
    `doctest` tool. We'll see that the three tests (the import and the two function
    evaluations) all produce the expected results.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final web page produced by this would look something like the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Working with a literate programming tool](graphics/0971OS_18_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Our goal is to create software that is trustworthy. A tidy, clear explanation
    of why our design is good is an important part of this trust. By writing the software
    and the documentation side-by-side in a single source text, we can be sure that
    our documentation is complete and provides a sensible review of the design decisions
    and the overall quality of the software. A simple tool can extract working code
    and documentation from a single source, making it easy for us to create the software
    and the documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We looked at the following four ways to create usable documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: We can incorporate the information into the docstrings in our software
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can use `pydoc` to extract the API reference information from our software.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can use Sphinx to create more sophisticated and elaborate documentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Also, we can use a literate programming tool to create even deeper and more
    meaningful documentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Design considerations and trade-offs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The docstring should be considered as essential as any other part of the Python
    source. This ensures that the `help()` function and `pydoc` will work correctly.
    As with unit test cases, this should be viewed as a mandatory element of the software.
  prefs: []
  type: TYPE_NORMAL
- en: The documentation created by Sphinx can be very good looking; it will tend to
    parallel the Python documentation. Our objective all along has been seamless integration
    with the other features of Python. Using Sphinx tends to introduce an additional
    directory structure for the documentation source and build.
  prefs: []
  type: TYPE_NORMAL
- en: As we design our classes, the question of how to describe the design is almost
    as important as the resulting design itself. Software that can't be explained
    quickly and clearly will be viewed as untrustworthy.
  prefs: []
  type: TYPE_NORMAL
- en: Taking the time to write an explanation may identify hidden complexities or
    irregularities. In these cases, we might not refactor a design to correct a bug
    or to improve the performance, but rather to make it easier to explain. The ability
    to explain is a quality factor that has tremendous value.
  prefs: []
  type: TYPE_NORMAL
