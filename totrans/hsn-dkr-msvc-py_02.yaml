- en: Making the Move – Design, Plan, and Execute
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As web services get more and more complex, and software service companies grow
    in size, we require new ways of working to adapt and increase the speed of change,
    while setting a high quality standard. Microservices architecture has emerged
    as one of the best tools to control big software systems, enabled by new tools
    such as containers and orchestrators. We will start by presenting the differences
    between the traditional monolith architecture and the microservices architecture,
    as well as the advantages of moving to the latter. We will cover how to structure
    an architecture migration and how to plan to succeed in this difficult process.
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we will deal with web server services, though some of the ideas
    can be used for other kinds of software applications, obviously by adapting them.
    The monolith/microservice architectures have some similarities with the monolithic/microkernel
    discussions in operating system design, including the famous debate ([https://www.oreilly.com/openbook/opensources/book/appa.html](https://www.oreilly.com/openbook/opensources/book/appa.html)) between
    Linus Torvalds and Andrew S. Tanenbaum, back in 1992\. This chapter is relatively
    agnostic about tools, while the following chapters will present specific ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The traditional monolith approach and its problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The characteristics of a microservices approach
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parallel deployment and development speed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Challenges and red flags
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyzing the current system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preparing and adapting by measuring usage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strategic planning to break the monolith
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Executing the move
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the end of the chapter, you'll be familiar with the basic concepts we will
    be using throughout the book, different strategies for how to proceed with and
    structure work during the migration to microservices, and a practical example
    that we will be working on in the remaining chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter does not focus on specific technologies, going for a more agnostic
    approach. We will discuss a Python Django application for our monolith example.
  prefs: []
  type: TYPE_NORMAL
- en: 'The monolith example can be found at: [https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter01/Monolith](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter01/Monolith).
    Installation and running instructions can be found in its `README.md` file.'
  prefs: []
  type: TYPE_NORMAL
- en: The traditional monolith approach and its problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The traditional approach to the software when developing a system has been
    to create a monolith. This is a fancy word to say *a single element, containing
    everything*, and it is the way virtually every project starts. In the context
    of web applications, that means creating deployable code that can be replicated
    so that requests can be directed to any of the deployed copies:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/a6a73149-82f7-4880-9121-7b110bda40ad.png)'
  prefs: []
  type: TYPE_IMG
- en: After all, every project will start off small. Making strict divisions early
    on is inconvenient and even doesn't make sense. A newly created project is small
    and probably handled by a single developer. While the design can fit in the head
    of a few people, making strict boundaries between parts of the system is counterproductive.
  prefs: []
  type: TYPE_NORMAL
- en: There are a lot of options for running a web service, but one will typically
    consist of one or more servers (physical boxes, virtual machines, and cloud instances
    such as EC2 and more)  running a  web server application (such as NGINX or Apache)
    to direct requests directed to HTTP port `80` or HTTPS port `443` toward one or
    more Python workers (normally, through the WSGI protocol), run by `mod_wsgi`—[https://github.com/GrahamDumpleton/mod_wsgi](https://github.com/GrahamDumpleton/mod_wsgi) (Apache
    only), uWSGI, GNUnicorn, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: If more than one server is used, there will be a load balancer to spread the
    load among them. We'll talk about them later in this chapter. The server (or load
    balancer) needs to be accessible on the internet, so it will have a dedicated
    DNS and a public IP address.
  prefs: []
  type: TYPE_NORMAL
- en: 'In other programming languages, the structure will be similar: a frontend web
    server that exposes the port in HTTP/HTTPS, and a backend that runs the monolith
    code in a dedicated web worker.'
  prefs: []
  type: TYPE_NORMAL
- en: But things change, successful software grows and, after some time, having a
    big ball of code is maybe not the best way of structuring a big project.
  prefs: []
  type: TYPE_NORMAL
- en: Monoliths can have, in any case, internal structure, meaning they don't necessarily
    get into the realms of spaghetti code. It may be perfectly structured code. What
    defines a monolith is the requirement to deploy the system as a whole, without
    being able to make partial deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Spaghetti code is a common way of referring to code that lacks any structure
    and is difficult to read and follow.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the monolith grows, some of its limitations will start to show up:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The code will increase in size**: Without strict boundaries between modules,
    developers will start having problems understanding the whole code base. While
    good practices can help, the complexity naturally tends to increase, making it
    more difficult to change the code in certain ways and increasing subtle bugs.
    Running all tests will become slow, decreasing the speed of any Continuous Integration
    system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inefficient utilization of resources**: Each individual deployed web worker
    will require all the resources required for the whole system to work, for example,
    the maximum amount of memory for any kind of request, even if a request that demands
    a lot of memory is rare and just a couple of workers will be sufficient. The same
    may happen with the CPU. If the monolith connects to a database, each individual
    worker will require a connection to it, whether that''s used regularly or not,
    and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Issues with development scalability**: Even if the system is perfectly designed
    to be horizontally scalable (unlimited new workers can be added), as the system
    grows and the development team grows, development will be more and more difficult
    without stepping on each other''s toes. A small team can coordinate easily, but
    once several teams are working on the same code base, the probability of clashing
    will increase. Imposing boundaries for teams in terms of ownership and responsibility
    can also become blurry unless strict discipline is enforced. In any case, teams
    will need to be actively coordinated, which reduces their independence and speed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment limitations**: The deployment approach will need to be shared
    across teams, and teams can''t be individually responsible for each deployment,
    as deployment will probably involve work for multiple teams. A deployment problem
    will bring down the whole system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Interdependency of technologies**: Any new tech needs to fit with the tech
    in use in the monolith. A new technology, for example, a tool that''s perfect
    for a particular problem, may be complicated to add to the monolith, due to a
    mismatch of technologies. Updating dependencies can also cause issues. For example,
    an update to a new version of Python (or a submodule) needs to operate with the
    whole code base. Some required maintenance tasks, such as a security patch, can
    cause a problem just because the monolith already uses a specific version of a
    library, which will break if changed. Adapting to these changes requires extra
    work too.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A bug in a small part of the system can bring down the whole service**: As
    the service is a whole, any critical issue that affects the stability affects
    everything, making it difficult to generate quality service strategies or causing
    degraded results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see in the examples, most of the monolith issues are growing issues.
    They are not really important unless the system has a sizeable code base. There
    are some things that work very well in monoliths, such as the fact that, because
    there are no boundaries in the code, the code can be changed very quickly and
    efficiently. But as teams grow and more and more developers are working in the
    system, boundaries help to define objectives and responsibilities. Too much flexibility
    becomes a problem in the long term.
  prefs: []
  type: TYPE_NORMAL
- en: The characteristics of a microservices approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The monolith approach works until the point it doesn't. But, what is the alternative?
    That's where the microservices architecture enters into the scene.
  prefs: []
  type: TYPE_NORMAL
- en: 'A system following a microservices architecture *is a collection of loosely
    coupled specialized services that work in unison to provide a comprehensive service*.
    Let''s divide the definition a bit, in more specific terms:'
  prefs: []
  type: TYPE_NORMAL
- en: A **collection of specialized services**, meaning that there are different,
    well-defined modules.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Loosely coupled**, meaning that each of the microservices can be independently
    deployed.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That **work in unison**—each microservice is capable of communicating with others.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To provide a **comprehensive service**, because our microservice system will
    need to replicate the same functionalities that were available using a monolith
    approach. There is an intent behind its design.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In contrast to the previous diagram, the microservice architecture will look
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/037b0910-8b4b-48af-b863-4c1ece183ba4.png)'
  prefs: []
  type: TYPE_IMG
- en: Each of the external requests will be channeled to either **Microservice A**
    or **Microservice B**, each one specializing in a particular kind of requests.
    In certain cases, **Microservice B** communicates with **Microservice C**, not
    directly available externally. Note that there may be multiple workers per microservice.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several advantages and implications to this architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: If the communication between microservices is done through a standard protocol,
    each microservice can be programmed in different languages.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Throughout the book, we will use HTTP requests with data encoded in JSON to
    communicate between microservices. Though there are more options, this is definitively
    the most standard and widely-used option, as virtually every widely-used programming
    language has good support for it.
  prefs: []
  type: TYPE_NORMAL
- en: This is very useful in cases where a specialized language is ideal for a specialized
    problem, but limiting its use so that it is contained, not requiring a drastic
    change in the company.
  prefs: []
  type: TYPE_NORMAL
- en: Better resource utilization—if **Microservice A** requires more memory, we can
    reduce the number of worker copies. While on a monolith, each worker requires
    the maximum resource allocation, now each microservice uses only the resources
    required for its part of the whole system. Maybe some of them don't need to connect
    to the database, for example. Each individual element can be tweaked, potentially even at
    the hardware level.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each individual service is smaller and can be dealt with independently. That
    means fewer lines of code to maintain, faster builds, and a simpler design, with
    less technical debt to maintain. There are no dependency issues between services,
    as each can define and move them at their own pace. Performing refactors can be
    done in a more controlled way, as they won't affect the totality of the system. Furthermore,
    each microservice can change the programming language it's written in, without
    affecting other microservices.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'From a certain point of view, the microservices architecture is similar to
    the UNIX philosophy, applied to web services: write each program (service) to
    do one thing and do it well, write programs (services) to work together and write
    programs (services) to handle text streams (HTTP calls), because that is a universal
    interface.'
  prefs: []
  type: TYPE_NORMAL
- en: Some services can be hidden from external access. For example, **Microservice
    C** is only called by other services, not externally. In some scenarios, that
    can improve security, reducing the attack surface area for sensitive data or services.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As the systems are independent, a stability problem in one won't completely
    stop the system. This reduces critical responses and limits the scope of a catastrophic
    failure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each service can be maintained independently by different developers. This allows
    for parallel development and deployment, increasing the amount of work that can
    be done by the company. This requires the exposed APIs to be backward compatible,
    as we will describe later.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Docker containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The microservice architecture is pretty agnostic about the platform that supports
    it. It can be deployed on old physical boxes in a dedicated data center, in a
    public cloud, or in containerized form.
  prefs: []
  type: TYPE_NORMAL
- en: There's a tendency, though, to use containers to deploy microservices. Containers
    are a packetized bundle of software that encapsulates everything that is required
    to run, including all dependencies. It only requires a compatible OS kernel to
    run autonomously.
  prefs: []
  type: TYPE_NORMAL
- en: Docker is the lead actor in containers for web applications. It has an extremely
    vibrant community supporting it as well as great tooling to work on all kinds
    of operations. We will learn how to work and operate using Docker.
  prefs: []
  type: TYPE_NORMAL
- en: The first time that I worked with Docker containers, they looked like a sort
    of *light virtual machine* to me; a small operative system that didn't require
    simulating the hardware to run. But after a while, I realized that's not the correct
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: The best way to describe a container is to think of *a process that's surrounded
    by its own filesystem*. You run one process (or a few related ones), and they
    *see* a whole filesystem, not shared by anyone.
  prefs: []
  type: TYPE_NORMAL
- en: This makes containers extremely portable, as they are detached from the underlying
    hardware and the platform that runs them; they are very lightweight, as a minimal
    amount of data needs to be included, and they are secure, as the exposed attack
    surface of a container is extremely small. You don't need applications to manage
    them in the same way you do on a traditional server, such as an `sshd` server,
    or a configuration tool such as Puppet. They are specialized and designed to be
    small and single-purpose.
  prefs: []
  type: TYPE_NORMAL
- en: In particular, try to keep your containers small and single-purpose. If you
    end up adding several daemons and a lot of configuration, it's likely that you
    are trying to include too much; maybe you need to split it into several containers.
  prefs: []
  type: TYPE_NORMAL
- en: Working with Docker containers has two steps. First, we build the container,
    executing layer after layer of changes on the filesystem, such as adding the software
    and configuration files that will be executed. Then, we execute it, launching
    its main command. We will see exactly how to do this in [Chapter 3](05dd2141-e113-43a2-8bd9-26fb97057913.xhtml),
    *Dockerizing the Service*.
  prefs: []
  type: TYPE_NORMAL
- en: The microservices architecture aligns very well with some of the characteristics
    of Docker containers—small, single-purpose elements that communicate through HTTP
    calls. That's why, even though it's not a hard requirement, they're typically
    presented together these days.
  prefs: []
  type: TYPE_NORMAL
- en: The Twelve-Factor App principles ([https://12factor.net/](https://12factor.net/)),
    which are a collection of practices that have been proven successful in developing
    web applications, are also very aligned with Docker containers and with the microservice
    architecture. Some of the principles are extremely easy to follow with Docker,
    and we will comment on them in depth later in the book.
  prefs: []
  type: TYPE_NORMAL
- en: An important factor for dealing with containers is that containers should be
    stateless (Factor VI—[https://12factor.net/processes](https://12factor.net/processes)).
    Any state needs to be stored in a database and each container stores no persistent
    data. This is one of the key elements for scalable web servers that, when dealing
    with a couple of servers, may not be done. Be sure to keep it in mind.
  prefs: []
  type: TYPE_NORMAL
- en: Another advantage of Docker is the availability of a lot of ready-to-use containers. Docker
    Hub ([https://hub.docker.com/](https://hub.docker.com/)) is a public registry
    full of interesting containers to inherit or to use directly, either in development
    or production. This helps you to have examples for your own services, and to quickly
    create small services that require little configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Container orchestration and Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Though Docker presents on how to deal with each of the individual microservices,
    we will need an orchestrator to handle the whole cluster of services. For that,
    we will use Kubernetes ([https://kubernetes.io/](https://kubernetes.io/)) throughout
    the book. This is the main orchestration project, and it has great support from
    the main cloud vendors. We will talk in detail about it in [Chapter 5](1cdffcc1-54b3-4502-8862-20eddc002dbc.xhtml), *Using
    Kubernetes to Coordinate Microservices*.
  prefs: []
  type: TYPE_NORMAL
- en: Parallel deployment and development speed
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The single most important element is the capacity to deploy independently. Rule
    number one for creating a successful microservices system is to ensure that each
    microservice can operate as **independently** as possible from the rest. That
    includes development, testing, and deployment.
  prefs: []
  type: TYPE_NORMAL
- en: This is the key element that allows developing in parallel between different
    teams, allowing them to scale the work. This increases the speed of change in
    a complex system.
  prefs: []
  type: TYPE_NORMAL
- en: The team responsible for a specific microservice needs to be capable of deploying
    a new version of the microservice without interrupting any other teams or services.
    The objective is to increase the number of deployments and the speed of each of
    them.
  prefs: []
  type: TYPE_NORMAL
- en: The microservice architecture is strongly related to Continuous Integration
    and Continuous Deployment principles. Small services are easy to keep up to date
    and to continuously build, as well as to deploy without interruption. In that
    regard, a CI/CD system tends to be microservices due to the increase in parallelization
    and the speed of delivery.
  prefs: []
  type: TYPE_NORMAL
- en: As deploying a microservice should be transparent for dependent services, special
    attention should be paid to backward compatibility. Some changes will need to
    be escalated and coordinated with other teams to remove old, incorrect functionality
    without interrupting the system.
  prefs: []
  type: TYPE_NORMAL
- en: While, theoretically, it's possible to have totally disconnected services, that's
    not realistic in practice. Some services will have dependencies between them.
    A microservice system will force you to define strong boundaries between the services,
    and any feature that requires cross-service communication will carry some overhead,
    maybe even having to coordinate the work across different teams.
  prefs: []
  type: TYPE_NORMAL
- en: When moving to a microservices architecture, the move is not purely technical
    but also implies a big change in the way the company works. The development of
    microservices will require autonomy and structured communication, which requires
    extra effort up front in planning the general architecture of the system. In monolith
    systems, this may be ad hoc and could have evolved into a not-so-separated internal
    structure, increasing the risk of tangled code and technical debt.
  prefs: []
  type: TYPE_NORMAL
- en: The need to clearly communicate and define owners cannot be stressed enough.
    Aim to allow each team to make their own decisions about their code and formalize
    and maintain the external APIs where other services depend on them.
  prefs: []
  type: TYPE_NORMAL
- en: This extra planning, though, increases long-term delivery bandwidth, as teams
    are empowered to make more autonomous decisions, including big ones such as which operating
    system to use, or which programming language, but also a myriad of smaller ones,
    such as using third-party packages, frameworks, or module structures. This increases
    the development pace in day-to-day operations.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices may also affect how the teams are structured in your organization.
    As a general rule, existing teams should be respected. There will be expertise
    in them that will be very useful, and causing a total revolution will disrupt
    that. But some tweaks may be necessary. Some concepts, such as understanding web
    services and RESTful interfaces will need to be present in every microservice,
    as well as knowledge on how to deploy its own service.
  prefs: []
  type: TYPE_NORMAL
- en: A traditional way of dividing teams is to create an operations team that is
    in charge of infrastructure and any new deployments because they are the only
    ones allowed to have access to the production servers. The microservices approach
    interferes with this as it needs teams to be able to have control over their own
    deployments. In [Chapter 5](1cdffcc1-54b3-4502-8862-20eddc002dbc.xhtml), *Using
    Kubernetes to Coordinate Microservices*, we'll see how using Kubernetes helps
    in this situation, detaching the maintenance of the infrastructure from the deployment
    of services.
  prefs: []
  type: TYPE_NORMAL
- en: It also allows creating a big sense of ownership, as teams are encouraged to
    work in their own preferred way in their own kingdom, while they play the game
    with the rest of the teams within clearly defined and structured borders. Microservices
    architecture can allow experimentation and innovation in small parts of the system
    that, once proven, can be disseminated across the whole system.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges and red flags
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've discussed a lot of advantages that the microservice architecture has over
    a monolith, but migrating is a massive undertaking that should not be underestimated.
  prefs: []
  type: TYPE_NORMAL
- en: Systems get started as monoliths, as it is simpler and allows for quicker iteration
    in a small code base. In any new company, pivoting and changing the code, searching
    for a successful business model is critical. This takes preference over clear
    structures and architecture separations—it is the way it should be.
  prefs: []
  type: TYPE_NORMAL
- en: However, once the system matures, the company grows. As more and more developers
    get involved, the advantages of a monolith start to become less evident, and the
    need for long-term strategy and structure becomes more important. More structure
    doesn't necessarily mean moving toward a microservice architecture. A great deal
    can be achieved with a well-architected monolith.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moving to microservices also has its own problems. Some of them are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Migrating to microservices requires a lot of effort, actively changing the way
    an organization operates, and a big investment until it starts to pay off. The
    transition will probably be painful, as a pragmatic approach is required and compromises
    will need to be made. It will also involve a lot of designing documents and meetings
    to plan the migration—all while the business continues to operate. This requires
    full commitment and an understanding of what's involved.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do not underestimate the cultural change—organizations are made of people, and
    people do not like change. A lot of the changes in microservices are related to
    different ways of operating and doing things in different ways. While this empowers
    different teams, it also forces them to clarify their interfaces and APIs and
    to formalize communication and boundaries. This can lead to frustration and resistance
    by members of the teams.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There's an adage called Conway's law ([http://www.melconway.com/Home/Conways_Law.html](http://www.melconway.com/Home/Conways_Law.html))
    that states that *organizations which design systems are constrained to produce
    designs which are copies of the communication structures of these organizations.*
    For microservices, this means that divisions between teams should reflect the
    different services. Having multiple teams working in the same microservice will
    blur the interfaces. We will discuss Conway's law in detail in [Chapter 12](d1a54332-1f4f-4ec7-a5a4-7ea81121bbea.xhtml),
    *Collaborating and Communicating across Teams*.
  prefs: []
  type: TYPE_NORMAL
- en: There's also a learning curve in learning the tools and procedures. Managing
    clusters is done differently than a single monolith, and developers will need
    to understand how to interoperate different services for testing locally. In the
    same way, that deployment will be different from traditional, local development
    as well. In particular, learning Docker takes some time to adapt. Plan accordingly
    and give support and training to everyone involved.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Debugging a request that moves across services is more difficult than a monolithic
    system. Monitoring the life cycle of a request is important and some subtle bugs
    can be difficult to replicate and fix in development.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Splitting a monolith into different services requires careful consideration.
    A bad division line can make two services tightly coupled, not allowing independent
    deployment. A red flag in that means almost any change to one service requires
    a change in the other, even if, normally, it could be done independently. This
    creates duplication of work, as routinely working on a single feature requires
    changing and deploying multiple microservices. Microservices can be mutated later
    and boundaries redefined, but there's a cost associated with that. The same care
    should be taken when adding new services.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There's an overhead in creating microservices, as there's some work that gets
    replicated on each service. That overhead gets compensated by allowing independent
    and parallel development. But, to fully take advantage of that, you need numbers.
    A small development team of up to 10 people can coordinate and handle a monolith
    very efficiently. It's only when the size grows and independent teams are formed
    that migrating to microservices starts to make sense. The bigger the company,
    the more it makes sense.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A balance between freedom and allowing each team to make their own decisions
    and standardize some common elements and decisions is necessary. If teams have
    too little direction, they'll keep reinventing the wheel over and over. They'll
    also end up creating knowledge silos where the knowledge in a section of the company
    is totally nontransferable to another team, making it difficult to learn lessons
    collectively. Solid communication between teams is required to allow consensus
    and the reuse of common solutions. Allow controlled experimentation, label it
    as such, and get the lessons learned across the board so that the rest of the
    teams benefit. There will be tension between shared and reusable ideas and independent,
    multiple-implementation ideas.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Be careful when introducing shared code across services. If the code grows,
    it will make services dependent on each other. This can reduce the independence
    of the microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Following the Agile principles, we know that working software is more important
    than extensive documentation. However, in microservices, it's important to maximize
    the usability of each individual microservice to reduce the amount of support
    between teams. That involves some degree of documentation. The best approach is
    to create self-documenting services. We'll look at some examples later in the
    book on how to use tools to allow documenting how to use a service with minimal
    effort.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each call to another service, such as internal microservices calling each other,
    can increase the delay of responses, as multiple layers will have to be involved.
    This can produce latency problems, with external responses taking longer. They
    will also be affected by the performance and capacity of the internal network
    connecting the microservices.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A move to microservices should be taken with care and by carefully analyzing
    its pros and cons. It is possible that it will take years to complete the migration
    in a mature system. But for a big system, the resulting system will be much more
    agile and easy to change, allowing you to tackle technical debt effectively and
    to empower developers to take full ownership and innovate, structuring communication
    and delivering a high quality, reliable service.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the current system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The very first step, as we defined before, to migrate from a monolith to a collection
    of microservices is understanding the current system. This stage should not be
    underestimated. It is highly likely that no single person has a good understanding
    of the different components of the monolith, especially if some parts are legacy.
  prefs: []
  type: TYPE_NORMAL
- en: The objective of this phase is to determine whether a change to microservices
    will actually be beneficial and to get an initial idea of what microservices will
    be the result of the migration. As we have discussed, making the move is a big
    investment and should not be taken lightly. Making a detailed estimation of the
    effort required won't be possible at this stage; uncertainty will be big at this
    point, but a thousand-mile journey starts with a single step.
  prefs: []
  type: TYPE_NORMAL
- en: The effort involved will vastly depend on how structured the monolith is. This
    may vary from a mess of spaghetti code that has grown organically without much
    direction, to a well-structured and modularized code base.
  prefs: []
  type: TYPE_NORMAL
- en: We will use an example application in this book—a micro-blogging site called
    MyThoughts, a simple service that will allow us to post and read short messages
    or thoughts. The website allows us to log in, post a new thought, see our thoughts,
    and search for thoughts in the system.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/9169859c-18ea-4693-8c23-c0d91fc9aaab.png)'
  prefs: []
  type: TYPE_IMG
- en: As a first step, we will draw an architectural diagram of the monolith. Reduce
    the current system to a list of blocks that interact with each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for our example is available here: [https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter01/Monolith](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter01/Monolith).
    It is a Django application that uses Bootstrap for its HTML interface. See the
    `README` for instructions on how to run it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, the MyThoughts model is described in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/db5b3617-82b8-4ffd-b2fc-5e01ba308c01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, the monolith seems to be following a Model View Controller
    structure ([https://www.codecademy.com/articles/mvc](https://www.codecademy.com/articles/mvc)):'
  prefs: []
  type: TYPE_NORMAL
- en: Django uses a structure called Model Template View, which follows a similar
    pattern to the MVC one. Read the article at [https://medium.com/shecodeafrica/understanding-the-mvc-pattern-in-django-edda05b9f43f](https://medium.com/shecodeafrica/understanding-the-mvc-pattern-in-django-edda05b9f43f)
    for more information. Whether it's 100% MCV or not is debatable. Let's not get
    stuck on semantics, but use the definition as a starting point to describe the
    system.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three entities stored in a database and accessed through the models:
    the user, the thoughts, and the session models. The session is used for keeping
    track of logins.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A user can log in and out to access the site through the code in `login.py`.
    If the user logs in, a session is created that allows the user to see the rest
    of the website.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Please note that the handling of authentication and passwords in this example
    is for demonstration purposes only. Use the default mechanisms in Django for more
    secure access. It's the same for the session, where the native session management
    is not used.
  prefs: []
  type: TYPE_NORMAL
- en: A user can see their own thoughts. On the same page, there's a new form that
    creates a new thought. This is handled by the `thoughts.py` file, which retrieves
    and stores the thoughts through `ThoughtModel`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To search other users' thoughts, there's a search bar that connects to the `search.py`
    module and returns the obtained values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The HTML is rendered through the `login.html`, `search.html`, `list_thoughts.html`, and
    `base.html` templates.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On top of that, there are static assets that style the website.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This example is very simple, but we are able to see some of the interdependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: The static data is very isolated. It can be changed at any point without requiring
    any changes anywhere else (as long as the templates are compatible with Bootstrap).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The search functionality is strongly related to list down thoughts. The template
    is similar, and the information is displayed in the same way.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Login and logout don't interact with `ThoughtModel`*.* They edit the session,
    but the rest of the application only reads the information there.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `base.html` template generates the top bar and it's used for all pages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After this analysis, some ideas on how to proceed come to mind:'
  prefs: []
  type: TYPE_NORMAL
- en: Just leave it the way it is, investing in structuring it, but without splitting
    it into several services. It has a certain structure already, though some parts
    could be improved. For example, the handling of whether the user is logged in
    or not could be better. This is obviously a small example, and, in real life,
    splitting it into microservices would have a big overhead. Remember that sticking
    with a monolith may be a viable strategy, but if you do, please invest time in
    cleaning up code and paying technical debt.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Searching for thoughts is pretty basic. At the moment, we directly search the
    database. If there are millions of thoughts, this won't be a viable option. The
    code in `search.py` could call a specific search microservice, backed by a search
    engine such as Solr ([https://lucene.apache.org/solr/](https://lucene.apache.org/solr/)) or
    Elasticsearch ([https://www.elastic.co/products/elasticsearch](https://www.elastic.co/products/elasticsearch)).
    This will scale the searches and could add capabilities like searching between
    dates or displaying the text matches. Search is also read-only, so it may be a
    good idea to detach calls creating new thoughts from calls searching them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Authentication is also a different problem from reading and writing thoughts.
    Splitting it will allow us to keep on track for new security issues and have a
    team specifically dealing with those issues. From the point of view of the rest
    of the application, it only requires you to have something available to check
    whether a user is logged or not, and that can be delegated in a module or package.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The frontend is pretty static at the moment. Maybe we want to create a single-page
    application that calls a backend API to render the frontend in the client. To
    do that, a RESTful API microservice that is able to return elements for thoughts
    and searches will need to be created. The frontend could be coded in a JavaScript
    framework, such as Angular ([https://angular.io](https://angular.io)) or React
    ([https://reactjs.org/](https://reactjs.org/)). In this case, the new microservice
    will be the frontend, which will be served as static, precompiled code, and will
    pull from the backend.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The RESTful API backend will also be available to allow external developers
    to create their own tools on top of the MyThoughts data, for example, to create
    a native phone app.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These are just some ideas, which will need to be discussed and evaluated. What
    are the specific pain points for your monolithic app? What is the roadmap and
    the strategic future? What are the most important points and features for the
    present or the future? Maybe, for one company, having strong security is a priority,
    and point 3 is critical, but for another, point 5 might be part of the expansion
    model to work with partners.
  prefs: []
  type: TYPE_NORMAL
- en: The team's structure is also important. Point 4 will require a team with good
    frontend and JavaScript skills, while point 2 may involve backend optimization
    and database work to allow an efficient search of millions of records.
  prefs: []
  type: TYPE_NORMAL
- en: Do not jump too quickly to conclusions here; think about what capacity is viable
    and what your teams can achieve. As we discussed before, the change to microservices
    requires a certain way of working. Check with the people involved for their feedback
    and suggestions.
  prefs: []
  type: TYPE_NORMAL
- en: 'After some consideration, for our example, we propose the following potential
    architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/e0b5fd45-46bf-49e7-ac45-ecfe9c6daca7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The system will be divided into the following modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Users backend:** This will have the responsibility for all authentication
    tasks and keep information about the users. It will store its data in the database.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Thoughts backend:** This will create and store *thoughts*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Search backend**: This will allow searching *thoughts*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A proxy that will route any request to the proper backend. This needs to be
    externally accessible.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**HTML frontend:** This will replicate the current functionality. This will
    ensure that we work in a backward-compatible way and that the transition can be
    made smoothly.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Allowing clients to access the backends will allow the creation of other clients
    than our HTML frontend. A dynamic frontend server will be created, and there are
    talks with an external company to create a mobile app.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Static assets:** A web server capable of handling static files. This will
    serve the styling for the HTML frontend and the index files and JavaScript files
    for the dynamic frontend.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This architecture will need to adapt to real-life usage; to validate it, we'll
    need to measure the existing usage.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing and adapting by measuring usage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Obviously, any real-world system will be more complicated than our example.
    There's a limit to what a code analysis can discover just by looking at it carefully,
    and plans often don't survive contact with the real world.
  prefs: []
  type: TYPE_NORMAL
- en: Any division needs to be validated to ensure that it will have the expected
    result and that the effort will be worth it. So double-check that the system is
    working the way you think it is working.
  prefs: []
  type: TYPE_NORMAL
- en: The ability to know how a live system is working is called **observability**.
    The main tools for it are metrics and logs. The problem you'll find is that they
    will normally be configured to reflect external requests and give no information
    about internal modules. We will talk about the observability of systems in depth
    in [Chapter 10](ca9b0606-730a-4006-a575-de8e897a19ba.xhtml), *Monitoring Logs
    and Metrics*. You can refer to it for more information and apply the techniques
    described there at this stage.
  prefs: []
  type: TYPE_NORMAL
- en: If your system is a web service, by default, it will have activated its access
    log. This will log each HTTP request that comes into the system and store the
    URL, result, and time when it happens. Check with your team where these logs are
    located, as they will provide good information on what URLs are being called.
  prefs: []
  type: TYPE_NORMAL
- en: This analysis, though, will probably give only information about what the external
    endpoints being called are, but won't say much about internal modules that will
    be split into different microservices according to our plan. Remember that the
    most important element for the long-term success of the move to microservices
    is to allow teams to be independent. If you split across modules that constantly
    need to be changed in unison, deployments won't be truly independent, and, after
    the transition, you'll be forced to work with two tightly coupled services.
  prefs: []
  type: TYPE_NORMAL
- en: Be careful, in particular, about making a microservice that's a dependency for
    every other service. Unless the service is extremely stable, that will make frequent
    updates likely when any other service requires a new feature.
  prefs: []
  type: TYPE_NORMAL
- en: To verify that the new microservices won't be tightly coupled, make the teams
    aware of the divisions and how often they have to change the interfaces surrounding
    them. Monitor these changes for a few weeks to be sure that the division lines
    are stable and don't require constant change. If the interface between microservices
    is very actively being changed, any feature will require multiple changes in several
    services, and that will slow the pace of delivering new features.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, after analyzing the proposed architecture, we decide to simplify
    the design, as shown in this diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/82ea1d40-9fc8-4d9a-8452-84332c3e2780.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Some changes have been decided after monitoring and talking with the teams:'
  prefs: []
  type: TYPE_NORMAL
- en: The teams don't have good knowledge of JavaScript dynamic programming. The change
    to the frontend, at the same time as making the move to microservices, is seen
    as too risky.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The external mobile application, on the other hand, is seen as a strategic move
    for the company, making the externally accessible API a desirable move.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Analyzing the logs, it seems like the search functionality is not often used.
    The growth in the number of searches is small, and splitting search into its own
    service will require coordination with the Thoughts Backend, as it's an area of
    active development, with new fields being added. It is decided to keep search under
    the Thoughts Backend, as both work with the same thoughts.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Users Backend has been received well. It will allow improving the security
    of authentication by having clear ownership of who's responsible for patching
    security vulnerabilities and improving the services. The rest of the microservices
    will have to work independently with verification by the Users Backend, which
    means the team responsible for this microservice will need to create and maintain
    a package with information on how to validate a request.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once we've decided on the final state, we still have to decide how are we going
    to move from one state to another.
  prefs: []
  type: TYPE_NORMAL
- en: Strategic planning to break the monolith
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we've discussed previously, moving from the initial state to the desired
    one will be a slow process. Not only because it involves new ways of doing things,
    but also because it will happen in parallel with other features and developments
    that are "business as usual." Being realistic, the company's business activities
    will not stop. That's why a plan should be in place to allow a smooth transition
    between one state and the other.
  prefs: []
  type: TYPE_NORMAL
- en: This is known as the **strangler pattern** ([https://docs.microsoft.com/en-us/azure/architecture/patterns/strangler](https://docs.microsoft.com/en-us/azure/architecture/patterns/strangler))—replacing
    parts of a system gradually until the old system is "strangled" and can be removed
    safely.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few alternatives as to what technical approach to take to make
    the move and how to divide each of the elements to migrate to the new system:'
  prefs: []
  type: TYPE_NORMAL
- en: The replacement approach, which replaces the older code with new code written
    from scratch the new service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The divide approach, which cherry-picks existing code and moves it into its
    own new service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A combination of the two
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's take a better look at them.
  prefs: []
  type: TYPE_NORMAL
- en: The replacement approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Services are replaced in big chunks, only taking into account their external
    interfaces or effects. This black-box approach completely replaces existing functionality
    coding with an alternative from scratch. Once the new code is ready, it gets activated
    and the functionality in the old system is deprecated.
  prefs: []
  type: TYPE_NORMAL
- en: Note that this does not refer to a single deployment that replaces the whole
    system. This can be done partially, chunk by chunk. The basis of this approach
    is that it creates a new external service that aims to replace the old system.
  prefs: []
  type: TYPE_NORMAL
- en: The pros of this approach are that it greatly helps in structuring the new service,
    as it doesn't inherit the technical debt, and allows for a fresh look at an old
    problem, with hindsight.
  prefs: []
  type: TYPE_NORMAL
- en: The new service can also use new tools and doesn't need to continue with any
    old stack that is not aligned with the strategic views on the future direction
    of the technology in the company.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with this approach is that it can be costly and can take a long
    time. For old services that are undocumented, replacing them could take a lot
    of effort. Also, this approach can only be applied to modules that are stable;
    if they are developed actively, trying to replace them with something else is
    moving the goalposts all the time.
  prefs: []
  type: TYPE_NORMAL
- en: This approach makes the most sense for old legacy systems that are small, or
    at least have a small part that performs limited functionality, and are developed
    in an old tech stack that's difficult or is no longer considered desirable to
    maintain.
  prefs: []
  type: TYPE_NORMAL
- en: The divide approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If the system is well structured, maybe some parts of it can be cleanly split
    into its own system, maintaining the same code.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, creating a new service is more an exercise of copy-pasting and
    wrapping it around with the minimal amount of code to allow it to be executed
    independently and to interoperate with other systems, in other words, to structure
    its API around HTTP requests to have a standard interface.
  prefs: []
  type: TYPE_NORMAL
- en: If this approach can be used, it means that the code was already quite structured,
    which is fantastic news.
  prefs: []
  type: TYPE_NORMAL
- en: 'The systems that are called to this part will also have to be adapted to make
    the call, not to internal code, but through HTTP calls. The good part is that
    this can be done in a few steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Copy the code into its own microservice and deploy it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The old calling system is using the old embedded code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Migrate a call and check that the system is working fine.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Iterate until all old calls are migrated to the new system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Delete the divided code from the old system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the code is not so cleanly structured, we will need to change it first.
  prefs: []
  type: TYPE_NORMAL
- en: Change and structured approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If the monolith has been growing organically, it's not likely that all its modules
    will be cleanly structured. Some structures may exist, but maybe they're not the
    correct ones for our desired microservices division.
  prefs: []
  type: TYPE_NORMAL
- en: To adapt the service, we will need to make some internal changes. These internal
    changes could be done iteratively until the service can be cleanly divided.
  prefs: []
  type: TYPE_NORMAL
- en: These three approaches can be combined to generate full migration. The effort
    involved in each is not the same, as an easily divisible service will be able
    to make the move faster than a replacement of badly-documented legacy code.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this phase of the project, the objective is to have a clear roadmap, that
    should analyze the following elements:'
  prefs: []
  type: TYPE_NORMAL
- en: An ordered plan of what microservices will be available first, taking into account
    how to deal with dependencies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An idea of what the biggest pain points are, and whether working on them is
    a priority. Pain points are the elements that are worked with frequently and the
    current way of dealing with the monolith makes them difficult.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the difficult points and the cans of worms? It's likely that there'll
    be some. Acknowledge that they exist and minimize their impact on other services.
    Note that they may be the same as the pain points, or not. The difficult points
    may be old systems that are very stable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A couple of quick wins that will keep the momentum of the project going. Show
    the advantages to your teams and stakeholders quickly! This will also allow everyone
    to understand the new mode of operation you want to move to and start working
    that way.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An idea of the training that teams will require and what the new elements are
    that you want to introduce. Also, whether there are any skills lacking in your
    team – it's possible that you may plan to hire.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any team changes and ownership of the new services. It's important to consider
    feedback from the teams, so they can express their concerns over any oversights
    during the creation of the plan.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For our specific example, the resulting plan will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: As a prerequisite, a load balancer will need to be in front of the operation.
    This will be responsible for channeling requests to the proper microservice. Then,
    changing the configuration of this element, we will be able to route the requests
    toward the old monolith or any new microservice.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After that, the static files will be served through their own independent service,
    which is an easy change. A static web server is enough, though it will be deployed
    as an independent microservice. This project will help in understanding the move
    to Docker.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code for authentication will be replicated in a new service. It will use
    a RESTful API to log in and generate a session, and to log out. The service will
    be responsible for checking whether a user exists or not, as well as adding them
    and removing them:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first idea was to check each session retrieved against the service, but,
    given that checking a session is a very common operation, we decided to generate
    a package, shared across the externally faced microservices, which will allow
    checking to see whether a session has been generated with our own service. This
    will be achieved by signing the session cryptographically and sharing the secret
    across our services. This module is expected not to change often, as it's a dependency
    for all the microservices. This makes the session one that does not need to be
    stored.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Users Backend needs to be able to allow authentication using OAuth 2.0 schema,
    which will allow other external services, not based on web browsers, to authenticate
    and operate, for example, a mobile app.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Thoughts Backend will also be replicated as a RESTful API. This backend
    is quite simple at the moment, and it will include the search functionality.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After both backends are available, the current monolith will be changed, from
    calling the database directly, to use the RESTful APIs of the backends. After
    this is successfully done, the old deployment will be replaced with a Docker build
    and added to the load balancer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The new API will be added externally to the load balancer and promoted as externally
    accessible. The company making the mobile app will then start integrating their
    clients.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our new architecture schema is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/4eebde2f-2787-40c3-855e-855bb045daf0.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that the HTML frontend will use the same APIs that are available externally.
    This will validate that the calls are useful, as we will use them first for our
    own client.
  prefs: []
  type: TYPE_NORMAL
- en: 'This action plan can have measurable times and a schedule. Some technology
    options can be taken as well—in our case, the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Each of the microservices will be deployed in its own Docker container ([https://www.docker.com/](https://www.docker.com/)).
    We will set up a Kubernetes cluster to orchestrate the different services.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We decided to make the new backend services in Flask ([https://palletsprojects.com/p/flask/](https://palletsprojects.com/p/flask/)),
    using Flask-RESTPlus ([https://flask-restplus.readthedocs.io/en/stable/](https://flask-restplus.readthedocs.io/en/stable/))
    to generate a well-documented RESTful app and connect to the existing database
    with SQLAlchemy ([https://www.sqlalchemy.org/](https://www.sqlalchemy.org/)).
    These tools are Python, but take a lighter approach than Django.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The backend services will be served using the uWSGI server ([https://uwsgi-docs.readthedocs.io/en/latest/](https://uwsgi-docs.readthedocs.io/en/latest/)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The static files will be served using NGINX ([https://www.nginx.com/](https://www.nginx.com/)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NGINX will also be used as a load balancer to control the inputs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HTML frontend will continue to use Django ([https://www.djangoproject.com/](https://www.djangoproject.com/)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The teams are OK with proceeding with these tech stacks, and are looking forward
    to learning some new tricks!
  prefs: []
  type: TYPE_NORMAL
- en: Executing the move
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The final step is to execute the carefully devised plan to start moving from
    the outdated monolith to the new promised land of microservices!
  prefs: []
  type: TYPE_NORMAL
- en: But this stage of the trip can actually be the longest and most difficult—especially
    if we want to keep the services running and not have outages that interrupt our
    business.
  prefs: []
  type: TYPE_NORMAL
- en: The single most important idea during this phase is **backward compatibility**.
    This means that the system is still behaving as the old system was from an external
    point of view. If we are able to behave like that, we can transparently change
    our internal operation while our customers are able to continue their operations
    uninterrupted.
  prefs: []
  type: TYPE_NORMAL
- en: That's obviously more easy to say than to do and sometimes has been referred
    to as starting a race with a Ford T and ending it with a Ferrari, changing every
    single piece of it without stopping. The good news is that software is so absolutely
    flexible and malleable that it is actually possible.
  prefs: []
  type: TYPE_NORMAL
- en: Web services' best friend – the load balancer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A load balancer is a tool that allows distributing HTTP requests (or other kinds
    of network requests) among several backend resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main operation of a load balancer is to allow traffic to be directed to
    a single address to be distributed among several identical backend servers that
    can spread the load and achieve better throughput. Typically, the traffic will
    be distributed through round-robin, that is, sequentially across all of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/a75b18b4-6475-4d39-b42c-3db3a565acf2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'First one worker, then the other, consecutively:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/67724773-c5dd-4193-8803-14b43fd27f9b.png)'
  prefs: []
  type: TYPE_IMG
- en: That's the normal operation. But it can also be used to replace services. The
    load balancer ensures that each request goes cleanly to one worker or another.
    The services in the pool of workers can be different, so we can use it to cleanly
    make the transition between one version of the web service and another.
  prefs: []
  type: TYPE_NORMAL
- en: For our purposes, a group of old web services that are behind a load balancer
    can add one or more replacement services that are backward compatible, without
    interrupting the operation. The new service replacing the old one will be added
    in small numbers (maybe one or two workers) to split the traffic in a reasonable
    configuration, and ensure that everything is working as expected. After the verification,
    replace it completely by stopping sending new requests to the old services, draining
    them, and leaving only the new servers.
  prefs: []
  type: TYPE_NORMAL
- en: If done in a quick movement, like when deploying a new version of a service,
    this is called a rolling update, so the workers are replaced one by one.
  prefs: []
  type: TYPE_NORMAL
- en: But for migrating from the old monolith to the new microservices, a slower pace
    is wiser. A service can live for days in a split of 5%/95% so any unexpected error
    will appear only a twentieth of the time, before moving to 33/66, then 50/50,
    then 100% migrated.
  prefs: []
  type: TYPE_NORMAL
- en: A highly loaded system with good observability will be able to detect problems
    very quickly and may only need to wait minutes before proceeding. Most legacy
    systems will likely not fall into this category, though.
  prefs: []
  type: TYPE_NORMAL
- en: Any web server capable of acting in reverse proxy mode, such as NGINX, is capable
    of working as a load balancer, but, for this task, probably the most complete
    option is HAProxy ([http://www.haproxy.org/](http://www.haproxy.org/)).
  prefs: []
  type: TYPE_NORMAL
- en: HAProxy is specialized in acting as a load balancer in situations of high availability
    and high demand. It's very configurable and accepts traffic from HTTP to lower-level
    TCP connection if necessary. It also has a fantastic status page that will help
    to monitor the traffic going through it, as well as taking fast action such as
    disabling a failing worker.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud providers such as AWS or Google also offer integrated load balancer products.
    They are very interesting to work from the edge of our network, as their stability
    makes them great, but they won't be as configurable and easy to integrate into
    your operating system as HAProxy. For example, the offering by Amazon Web Services
    is called **Elastic Load Balancing** (**ELB**)—[https://aws.amazon.com/elasticloadbalancing/](https://aws.amazon.com/elasticloadbalancing/).
  prefs: []
  type: TYPE_NORMAL
- en: 'To migrate from a traditional server with an external IP referenced by DNS
    and put a load balancer in the front, you need to follow the following procedure:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new DNS to access the current system. This will allow you to refer
    to the old system independently when the transition is done.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy your load balancer, configured to serve the traffic to your old system
    on the old DNS. This way, accessing either the load balancer or the old system,
    the request will ultimately be delivered in the same place. Create a DNS just
    for the load balancer, to allow referring specifically to it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Test that sending a request to the load balancer directed to the host of the
    old DNS works as expected. You can send a request using the following `curl` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Change the DNS to point to the load balancer IP. Changing DNS registries takes
    time, as caches will be involved. During that time, no matter where the request
    is received, it will be processed in the same way. Leave this state for a day
    or two, to be totally sure that every possible cache is outdated and uses the
    new IP value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The old IP is no longer in use. The server can (and should) be removed from
    the externally facing network, leaving only the load balancer to connect. Any
    request that needs to go to the old server can use its specific new DNS.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that a load balancer like HAProxy can work with URL paths, meaning it can
    direct different paths to different microservices, something extremely useful
    in the migration from a monolith.
  prefs: []
  type: TYPE_NORMAL
- en: Because a load balancer is a single point of failure, you'll need to load balance
    your load balancer. The easiest way of doing it is creating several identical
    copies of HAProxy, as you'd do with any other web service, and adding a cloud
    provider load balancer on top.
  prefs: []
  type: TYPE_NORMAL
- en: Because HAProxy is so versatile and fast, when properly configured, you can
    use it as a central point to redirect your requests—in true microservices fashion!
  prefs: []
  type: TYPE_NORMAL
- en: Keeping the balance between new and old
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Plans are just plans, and a move to microservices is something to do for internal
    benefits, as it requires investment until external improvements can be shown in
    the shape of a better pace of innovation.
  prefs: []
  type: TYPE_NORMAL
- en: This means that there'll be external pressure on the development team to add
    new features and requirements on top of the normal operation of the company. Even
    if we make this migration to move faster, there's an initial stage where you'll
    move slower. After all, changing things is difficult and you will need to overcome
    the initial inertia.
  prefs: []
  type: TYPE_NORMAL
- en: The migration will take three rough phases.
  prefs: []
  type: TYPE_NORMAL
- en: The pilot phase – setting up the first couple of microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A lot of infrastructures may be required before seeing the first deployment.
    This phase can be difficult to overcome and it''s the one that needs the biggest
    push. A good strategy for that is to put together a dedicated team of **enthusiasts**
    in the new microservice architecture and allow them to lead the development. They
    can be people that have been involved in the design, or maybe they like the new
    technologies or have worked with Docker and Kubernetes on side projects. Not every
    developer in your team will be excited about changing the way you operate, but
    some of them will be. Use their passion to start the project and take care of
    it in its initial steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Start **small**—there'll be enough work to set up the infrastructure. The objective
    in this phase is to learn the tools, set up the platform, and adjust how to work
    with the new system. The aspect of teamwork and coordination is important and
    starting with a small team allows us to test a couple of approaches and iterate
    to be sure that they work.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose **non-critical services**. At this stage, there are a lot of things that
    can go wrong. Be sure that a problem does not have a huge impact on operations
    or revenue.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Be sure to maintain **backward compatibility**. Substitute parts of the monolith
    with new services, but do not try to change the behavior at the same time, unless
    they are obvious bugs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If there's a new feature that can be implemented as a new microservice, take
    the chance to go straight for the new approach, but be sure that the risk in extra
    time to deliver, or bugs, is worth it.
  prefs: []
  type: TYPE_NORMAL
- en: The consolidation phase – steady migration to microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After the initial setup, other teams start working with the microservices approach.
    This expands the number of people dealing with containers and new deployments,
    so the initial team will need to give them support and training.
  prefs: []
  type: TYPE_NORMAL
- en: Training will be a critical part of the migration project—be sure to allocate
    enough time. While training events such as workshops and courses can be very useful
    to kickstart the process, constant support from experienced developers is invaluable.
    Appoint developers as a point of contact for questions, and tell them explicitly
    that their job is to ensure that they answer questions and help other developers.
    Make the supporting team meet up regularly to share concerns and improvements
    on the knowledge transfer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Spreading knowledge is one of the main focuses in this phase, but there are
    another two: clarify and standardize the process and maintain an adequate pace
    of migrating the microservices.'
  prefs: []
  type: TYPE_NORMAL
- en: Documenting standards will be helpful to give clarity and direction. Create
    checkpoints to make very explicit requirements across the board, so it's very
    clear when a microservice is ready for production. Create adequate channels for
    feedback, to be sure that the process can be improved.
  prefs: []
  type: TYPE_NORMAL
- en: During this time, the pace of migration can be increased because a lot of uncertainties
    and problems have already been ironed out; and because the development will be
    done in parallel. You should try to work on any new feature in a microservice
    way, though compromises may need to be taken. Be sure to keep the motivation and
    follow the plan.
  prefs: []
  type: TYPE_NORMAL
- en: The final phase – the microservices shop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The monolith has been split, and the architecture is now microservices. There
    may be remains of the monolith that are deemed to have lower priority. Any new
    feature is implemented in the microservices style.
  prefs: []
  type: TYPE_NORMAL
- en: While desirable, it may not be realistic to migrate absolutely everything from
    the monolith. Some parts may take a long time to migrate because they are especially
    difficult to migrate or they deal with strange corners of your company. If that's
    the case, at least clearly define the boundaries and limit their action radius.
  prefs: []
  type: TYPE_NORMAL
- en: This phase is where the teams can take full ownership of their microservices
    and start making tests and innovations such as changing the programming language.
    Architecture can change as well, and microservices can be split or joined. Have
    clear boundaries defining what the agreed requirements for microservices are,
    but allow freedom within them.
  prefs: []
  type: TYPE_NORMAL
- en: Teams will be well-established and the process will run smoothly. Keep an eye
    on good ideas coming from different teams and be sure to spread the word.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You did it!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we saw what the differences are between the traditional monolith
    approach and microservices architecture, and how microservices allow us to scale
    development across several teams and improve the delivery of quality software.
  prefs: []
  type: TYPE_NORMAL
- en: 'We discussed the main challenges that are faced during a transition from a
    monolith to microservices and how to perform the change in different stages: analyzing
    the current system, measuring to validate our assumptions, creating a plan to
    split the monolith in a controlled way, and tactics to successfully perform the
    move.'
  prefs: []
  type: TYPE_NORMAL
- en: Though this chapter was written in a technology-agnostic way, we've learned
    why Docker containers are a great way of implementing microservices, something
    that will be explored in the following chapters. You also now know how using a
    load balancer helps to maintain backward compatibility and deploy new services
    in an uninterrupted way.
  prefs: []
  type: TYPE_NORMAL
- en: You learned how to structure a plan to divide a monolith into smaller microservices.
    We described an example of such a process and an example of a monolith and how
    it will be divided. We'll see how to do this in detail in the following chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is a monolith?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are some of the problems of monoliths?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Describe the microservice architecture.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which is the most important property of microservices?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the main challenges to overcome in a migration from a monolith to microservices?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the basic steps to make such a migration?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Describe how to use a load balancer to migrate from an old server to a new one
    without interrupting the system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can learn more about systems architecture and how to divide and structure
    complex systems in the books *Architectural Patterns* ([https://www.packtpub.com/application-development/architectural-patterns](https://www.packtpub.com/application-development/architectural-patterns))
    and *Software Architect's Handbook* ([https://www.packtpub.com/application-development/software-architects-handbook](https://www.packtpub.com/application-development/software-architects-handbook))[.](https://prod.packtpub.com/application-development/architectural-patterns)
  prefs: []
  type: TYPE_NORMAL
