- en: Chapter 5. Scaling Microservices with Spring Cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to manage Internet-scale microservices, one requires more capabilities
    than what are offered by the Spring Boot framework. The Spring Cloud project has
    a suite of purpose-built components to achieve these additional capabilities effortlessly.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will provide a deep insight into the various components of the
    Spring Cloud project such as Eureka, Zuul, Ribbon, and Spring Config by positioning
    them against the microservices capability model discussed in [Chapter 3](ch03.html
    "Chapter 3. Applying Microservices Concepts"), *Applying Microservices Concepts*.
    It will demonstrate how the Spring Cloud components help to scale the BrownField
    Airline's PSS microservices system, developed in the previous chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will learn about the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The Spring Config server for externalizing configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Eureka server for service registration and discovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The relevance of Zuul as a service proxy and gateway
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The implementation of automatic microservice registration and service discovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spring Cloud messaging for asynchronous microservice composition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reviewing microservices capabilities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The examples in this chapter explore the following microservices capabilities
    from the microservices capability model discussed in [Chapter 3](ch03.html "Chapter 3. Applying
    Microservices Concepts"), *Applying Microservices Concepts*:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Software Defined Load Balancer**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service Registry**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Configuration Service**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reliable Cloud Messaging**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**API Gateways**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Reviewing microservices capabilities](img/B05447_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Reviewing BrownField's PSS implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 4](ch04.html "Chapter 4. Microservices Evolution – A Case Study"),
    *Microservices Evolution – A Case Study*, we designed and developed a microservice-based
    PSS system for BrownField Airlines using the Spring framework and Spring Boot.
    The implementation is satisfactory from the development point of view, and it
    serves the purpose for low volume transactions. However, this is not good enough
    for deploying large, enterprise-scale deployments with hundreds or even thousands
    of microservices.
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Chapter 4](ch04.html "Chapter 4. Microservices Evolution – A Case Study"),
    *Microservices Evolution – A Case Study*, we developed four microservices: Search,
    Booking, Fares, and Check-in. We also developed a website to test the microservices.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have accomplished the following items in our microservice implementation
    so far:'
  prefs: []
  type: TYPE_NORMAL
- en: Each microservice exposes a set of REST/JSON endpoints for accessing business
    capabilities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each microservice implements certain business functions using the Spring framework.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each microservice stores its own persistent data using H2, an in-memory database
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservices are built with Spring Boot, which has an embedded Tomcat server
    as the HTTP listener
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RabbitMQ is used as an external messaging service. Search, Booking, and Check-in
    interact with each other through asynchronous messaging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Swagger is integrated with all microservices for documenting the REST APIs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An OAuth2-based security mechanism is developed to protect the microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is Spring Cloud?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Spring Cloud project is an umbrella project from the Spring team that implements
    a set of common patterns required by distributed systems, as a set of easy-to-use
    Java Spring libraries. Despite its name, Spring Cloud by itself is not a cloud
    solution. Rather, it provides a number of capabilities that are essential when
    developing applications targeting cloud deployments that adhere to the Twelve-Factor
    application principles. By using Spring Cloud, developers just need to focus on
    building business capabilities using Spring Boot, and leverage the distributed,
    fault-tolerant, and self-healing capabilities available out of the box from Spring
    Cloud.
  prefs: []
  type: TYPE_NORMAL
- en: The Spring Cloud solutions are agnostic to the deployment environment, and can
    be developed and deployed in a desktop PC or in an elastic cloud. The cloud-ready
    solutions that are developed using Spring Cloud are also agnostic and portable
    across many cloud providers such as Cloud Foundry, AWS, Heroku, and so on. When
    not using Spring Cloud, developers will end up using services natively provided
    by the cloud vendors, resulting in deep coupling with the PaaS providers. An alternate
    option for developers is to write quite a lot of boilerplate code to build these
    services. Spring Cloud also provides simple, easy-to-use Spring-friendly APIs,
    which abstract the cloud provider's service APIs such as those APIs coming with
    AWS Notification Service.
  prefs: []
  type: TYPE_NORMAL
- en: Built on Spring's "convention over configuration" approach, Spring Cloud defaults
    all configurations, and helps the developers get off to a quick start. Spring
    Cloud also hides the complexities, and provides simple declarative configurations
    to build systems. The smaller footprints of the Spring Cloud components make it
    developer friendly, and also make it easy to develop cloud-native applications.
  prefs: []
  type: TYPE_NORMAL
- en: Spring Cloud offers many choices of solutions for developers based on their
    requirements. For example, the service registry can be implemented using popular
    options such as Eureka, ZooKeeper, or Consul. The components of Spring Cloud are
    fairly decoupled, hence, developers get the flexibility to pick and choose what
    is required.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**What is the difference between Spring Cloud and Cloud Foundry?**'
  prefs: []
  type: TYPE_NORMAL
- en: Spring Cloud is a developer kit for developing Internet-scale Spring Boot applications,
    whereas Cloud Foundry is an open-source Platform as a Service for building, deploying,
    and scaling applications.
  prefs: []
  type: TYPE_NORMAL
- en: Spring Cloud releases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Spring Cloud project is an overarching Spring project that includes a combination
    of different components. The versions of these components are defined in the `spring-cloud-starter-parent`
    BOM.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this book, we are relying on the `Brixton.RELEASE` version of the Spring
    Cloud:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The `spring-cloud-starter-parent` defines different versions of its subcomponents
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The names of the Spring Cloud releases are in an alphabetic sequence, starting
    with A, following the names of the London Tube stations. **Angel** was the first
    release, and **Brixton** is the second release.
  prefs: []
  type: TYPE_NORMAL
- en: Components of Spring Cloud
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Each Spring Cloud component specifically addresses certain distributed system
    capabilities. The grayed-out boxes at the bottom of the following diagram show
    the capabilities, and the boxes placed on top of these capabilities showcase the
    Spring Cloud subprojects addressing these capabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Components of Spring Cloud](img/B05447_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The Spring Cloud capabilities are explained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Distributed configuration**: Configuration properties are hard to manage
    when there are many microservice instances running under different profiles such
    as development, test, production, and so on. It is, therefore, important to manage
    them centrally, in a controlled way. The distributed configuration management
    module is to externalize and centralize microservice configuration parameters.
    Spring Cloud Config is an externalized configuration server with Git or SVN as
    the backing repository. Spring Cloud Bus provides support for propagating configuration
    changes to multiple subscribers, generally a microservice instance. Alternately,
    ZooKeeper or HashiCorp''s Consul can also be used for distributed configuration
    management.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Routing**: Routing is an API gateway component, primarily used similar to
    a reverse proxy that forwards requests from consumers to service providers. The
    gateway component can also perform software-based routing and filtering. Zuul
    is a lightweight API gateway solution that offers fine-grained controls to developers
    for traffic shaping and request/response transformations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Load balancing**: The load balancer capability requires a software-defined
    load balancer module which can route requests to available servers using a variety
    of load balancing algorithms. Ribbon is a Spring Cloud subproject which supports
    this capability. Ribbon can work as a standalone component, or integrate and work
    seamlessly with Zuul for traffic routing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service registration and discovery**: The service registration and discovery
    module enables services to programmatically register with a repository when a
    service is available and ready to accept traffic. The microservices advertise
    their existence, and make them discoverable. The consumers can then look up the
    registry to get a view of the service availability and the endpoint locations.
    The registry, in many cases, is more or less a dump. But the components around
    the registry make the ecosystem intelligent. There are many subprojects existing
    under Spring Cloud which support registry and discovery capability. Eureka, ZooKeeper,
    and Consul are three subprojects implementing the registry capability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service-to-service calls**: The Spring Cloud Feign subproject under Spring
    Cloud offers a declarative approach for making RESTful service-to-service calls
    in a synchronous way. The declarative approach allows applications to work with
    **POJO** (**Plain Old Java Object**) interfaces instead of low-level HTTP client
    APIs. Feign internally uses reactive libraries for communication.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Circuit breaker**: The circuit breaker subproject implements the circuit
    breaker pattern. The circuit breaker breaks the circuit when it encounters failures
    in the primary service by diverting traffic to another temporary fallback service.
    It also automatically reconnects back to the primary service when the service
    is back to normal. It finally provides a monitoring dashboard for monitoring the
    service state changes. The Spring Cloud Hystrix project and Hystrix Dashboard
    implement the circuit breaker and the dashboard respectively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Global locks, leadership election and cluster state**: This capability is
    required for cluster management and coordination when dealing with large deployments.
    It also offers global locks for various purposes such as sequence generation.
    The Spring Cloud Cluster project implements these capabilities using Redis, ZooKeeper,
    and Consul.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security**: Security capability is required for building security for cloud-native
    distributed systems using externalized authorization providers such as OAuth2\.
    The Spring Cloud Security project implements this capability using customizable
    authorization and resource servers. It also offers SSO capabilities, which are
    essential when dealing with many microservices.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Big data support**: The big data support capability is a capability that
    is required for data services and data flows in connection with big data solutions.
    The Spring Cloud Streams and the Spring Cloud Data Flow projects implement these
    capabilities. The Spring Cloud Data Flow is the re-engineered version of Spring
    XD.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distributed tracing**: The distributed tracing capability helps to thread
    and correlate transitions that are spanned across multiple microservice instances.
    Spring Cloud Sleuth implements this by providing an abstraction on top of various
    distributed tracing mechanisms such as Zipkin and HTrace with the support of a
    64-bit ID.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distributed messaging**: Spring Cloud Stream provides declarative messaging
    integration on top of reliable messaging solutions such as Kafka, Redis, and RabbitMQ.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud support**: Spring Cloud also provides a set of capabilities that offers
    various connectors, integration mechanisms, and abstraction on top of different
    cloud providers such as the Cloud Foundry and AWS.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spring Cloud and Netflix OSS
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Many of the Spring Cloud components which are critical for microservices' deployment
    came from the **Netflix Open Source Software** (**Netflix OSS**) center. Netflix
    is one of the pioneers and early adaptors in the microservices space. In order
    to manage large scale microservices, engineers at Netflix came up with a number
    of homegrown tools and techniques for managing their microservices. These are
    fundamentally crafted to fill some of the software gaps recognized in the AWS
    platform for managing Netflix services. Later, Netflix open-sourced these components,
    and made them available under the Netflix OSS platform for public use. These components
    are extensively used in production systems, and are battle-tested with large scale
    microservice deployments at Netflix.
  prefs: []
  type: TYPE_NORMAL
- en: Spring Cloud offers higher levels of abstraction for these Netflix OSS components,
    making it more Spring developer friendly. It also provides a declarative mechanism,
    well-integrated and aligned with Spring Boot and the Spring framework.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the environment for BrownField PSS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will amend the BrownField PSS microservices developed in
    [Chapter 4](ch04.html "Chapter 4. Microservices Evolution – A Case Study"), *Microservices
    Evolution – A Case Study*, using Spring Cloud capabilities. We will also examine
    how to make these services enterprise grade using Spring Cloud components.
  prefs: []
  type: TYPE_NORMAL
- en: Subsequent sections of this chapter will explore how to scale the microservices
    developed in the previous chapter for cloud scale deployments, using some out-of-the-box
    capabilities provided by the Spring Cloud project. The rest of this chapter will
    explore Spring Cloud capabilities such as configuration using the Spring Config
    server, Ribbon-based service load balancing, service discovery using Eureka, Zuul
    for API gateway, and finally, Spring Cloud messaging for message-based service
    interactions. We will demonstrate the capabilities by modifying the BrownField
    PSS microservices developed in [Chapter 4](ch04.html "Chapter 4. Microservices
    Evolution – A Case Study"), *Microservices Evolution – A Case Study*.
  prefs: []
  type: TYPE_NORMAL
- en: In order to prepare the environment for this chapter, import and rename (`chapter4.*`
    to `chapter5.*`) projects into a new STS workspace.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The full source code of this chapter is available under the `Chapter 5` projects
    in the code files.
  prefs: []
  type: TYPE_NORMAL
- en: Spring Cloud Config
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Spring Cloud Config server is an externalized configuration server in which
    applications and services can deposit, access, and manage all runtime configuration
    properties. The Spring Config server also supports version control of the configuration
    properties.
  prefs: []
  type: TYPE_NORMAL
- en: In the earlier examples with Spring Boot, all configuration parameters were
    read from a property file packaged inside the project, either `application.properties`
    or `application.yaml`. This approach is good, since all properties are moved out
    of code to a property file. However, when microservices are moved from one environment
    to another, these properties need to undergo changes, which require an application
    re-build. This is violation of one of the Twelve-Factor application principles,
    which advocate one-time build and moving of the binaries across environments.
  prefs: []
  type: TYPE_NORMAL
- en: A better approach is to use the concept of profiles. Profiles, as discussed
    in [Chapter 2](ch02.html "Chapter 2. Building Microservices with Spring Boot"),
    *Building Microservices with Spring Boot*, is used for partitioning different
    properties for different environments. The profile-specific configuration will
    be named `application-{profile}.properties`. For example, `application-development.properties`
    represents a property file targeted for the development environment.
  prefs: []
  type: TYPE_NORMAL
- en: However, the disadvantage of this approach is that the configurations are statically
    packaged along with the application. Any changes in the configuration properties
    require the application to be rebuilt.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are alternate ways to externalize the configuration properties from the
    application deployment package. Configurable properties can also be read from
    an external source in a number of ways:'
  prefs: []
  type: TYPE_NORMAL
- en: From an external JNDI server using JNDI namespace (`java:comp/env`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the Java system properties (`System.getProperties()`) or using the `–D`
    command line option
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using the `PropertySource` configuration:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Using a command-line parameter pointing a file to an external location:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: JNDI operations are expensive, lack flexibility, have difficulties in replication,
    and are not version controlled. `System.properties` is not flexible enough for
    large-scale deployments. The last two options rely on a local or a shared filesystem
    mounted on the server.
  prefs: []
  type: TYPE_NORMAL
- en: 'For large scale deployments, a simple yet powerful centralized configuration
    management solution is required:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Spring Cloud Config](img/B05447_05_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As shown in the preceding diagram, all microservices point to a central server
    to get the required configuration parameters. The microservices then locally cache
    these parameters to improve performance. The Config server propagates the configuration
    state changes to all subscribed microservices so that the local cache's state
    can be updated with the latest changes. The Config server also uses profiles to
    resolve values specific to an environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in the following screenshot, there are multiple options available
    under the Spring Cloud project for building the configuration server. **Config
    Server**, **Zookeeper Configuration**, and **Consul Configuration** are available
    as options. However, this chapter will only focus on the Spring Config server
    implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Spring Cloud Config](img/B05447_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The Spring Config server stores properties in a version-controlled repository
    such as Git or SVN. The Git repository can be local or remote. A highly available
    remote Git server is preferred for large scale distributed microservice deployments.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Spring Cloud Config server architecture is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Spring Cloud Config](img/B05447_05_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As shown in the preceding diagram, the Config client embedded in the Spring
    Boot microservices does a configuration lookup from a central configuration server
    using a simple declarative mechanism, and stores properties into the Spring environment.
    The configuration properties can be application-level configurations such as trade
    limit per day, or infrastructure-related configurations such as server URLs, credentials,
    and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike Spring Boot, Spring Cloud uses a bootstrap context, which is a parent
    context of the main application. Bootstrap context is responsible for loading
    configuration properties from the Config server. The bootstrap context looks for
    `bootstrap.yaml` or `bootstrap.properties` for loading initial configuration properties.
    To make this work in a Spring Boot application, rename the `application.*` file
    to `bootstrap.*`.
  prefs: []
  type: TYPE_NORMAL
- en: What's next?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The next few sections demonstrate how to use the Config server in a real-world
    scenario. In order to do this, we will modify our search microservice (`chapter5.search`)
    to use the Config server. The following diagram depicts the scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: '![What''s next?](img/B05447_05_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In this example, the Search service will read the Config server at startup by
    passing the service name. In this case, the service name of the search service
    will be `search-service`. The properties configured for the `search-service` include
    the RabbitMQ properties as well as a custom property.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The full source code of this section is available under the `chapter5.configserver`
    project in the code files.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the Config server
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps need to be followed to create a new Config server using
    STS:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new **Spring Starter Project**, and select **Config Server** and **Actuator**
    as shown in the following diagram:![Setting up the Config server](img/B05447_05_07.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set up a Git repository. This can be done by pointing to a remote Git configuration
    repository like the one at [https://github.com/spring-cloud-samples/config-repo](https://github.com/spring-cloud-samples/config-repo).
    This URL is an indicative one, a Git repository used by the Spring Cloud examples.
    We will have to use our own Git repository instead.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Alternately, a local filesystem-based Git repository can be used. In a real
    production scenario, an external Git is recommended. The Config server in this
    chapter will use a local filesystem-based Git repository for demonstration purposes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Enter the commands listed next to set up a local Git repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The file `application.properties` is created for demonstration purposes. We
    will change this in the subsequent sections.
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to change the configuration in the Config server to use the
    Git repository created in the previous step. In order to do this, rename the file
    `application.properties` to `bootstrap.properties`:![Setting up the Config server](img/B05447_05_08.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Edit the contents of the new `bootstrap.properties` file to match the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Port `8888` is the default port for the Config server. Even without configuring
    `server.port`, the Config server should bind to `8888`. In the Windows environment,
    an extra `/` is required in the file URL.
  prefs: []
  type: TYPE_NORMAL
- en: 'Optionally, rename the default package of the auto-generated `Application.java`
    from `com.example` to `com.brownfield.configserver`. Add `@EnableConfigServer`
    in `Application.java`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Run the Config server by right-clicking on the project, and running it as a
    Spring Boot app.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Visit `http://localhost:8888/env` to see whether the server is running. If everything
    is fine, this will list all environment configurations. Note that `/env` is an
    actuator endpoint.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Check `http://localhost:8888/application/default/master` to see the properties
    specific to `application.properties`, which were added in the earlier step. The
    browser will display the properties configured in `application.properties`. The
    browser should display contents similar to the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Understanding the Config server URL
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, we used `http://localhost:8888/application/default/master`
    to explore the properties. How do we interpret this URL?
  prefs: []
  type: TYPE_NORMAL
- en: The first element in the URL is the application name. In the given example,
    the application name should be `application`. The application name is a logical
    name given to the application, using the `spring.application.name` property in
    `bootstrap.properties` of the Spring Boot application. Each application must have
    a unique name. The Config server will use the name to resolve and pick up appropriate
    properties from the Config server repository. The application name is also sometimes
    referred to as service ID. If there is an application with the name `myapp`, then
    there should be a `myapp.properties` in the configuration repository to store
    all the properties related to that application.
  prefs: []
  type: TYPE_NORMAL
- en: The second part of the URL represents the profile. There can be more than one
    profile configured within the repository for an application. The profiles can
    be used in various scenarios. The two common scenarios are segregating different
    environments such as `Dev`, `Test`, `Stage`, `Prod`, and the like, or segregating
    server configurations such as `Primary`, `Secondary`, and so on. The first one
    represents different environments of an application, whereas the second one represents
    different servers where an application is deployed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The profile names are logical names that will be used for matching the file
    name in the repository. The default profile is named `default`. To configure properties
    for different environments, we have to configure different files as given in the
    following example. In this example, the first file is for the development environment
    whereas the second is for the production environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'These are accessible using the following URLs respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: http://localhost:8888/application/development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: http://localhost:8888/application/production
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The last part of the URL is the label, and is named `master` by default. The
    label is an optional Git label that can be used, if required.
  prefs: []
  type: TYPE_NORMAL
- en: 'In short, the URL is based on the following pattern: `http://localhost:8888/{name}/{profile}/{label}`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The configuration can also be accessed by ignoring the profile. In the preceding
    example, all the following three URLs point to the same configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: http://localhost:8888/application/default
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: http://localhost:8888/application/master
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: http://localhost:8888/application/default/master
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is an option to have different Git repositories for different profiles.
    This makes sense for production systems, since the access to different repositories
    could be different.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing the Config Server from clients
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the previous section, a Config server is set up and accessed using a web
    browser. In this section, the Search microservice will be modified to use the
    Config server. The Search microservice will act as a Config client.
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these steps to use the Config server instead of reading properties from
    the `application.properties` file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the Spring Cloud Config dependency and the actuator (if the actuator is
    not already in place) to the `pom.xml` file. The actuator is mandatory for refreshing
    the configuration properties:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we are modifying the Spring Boot Search microservice from the earlier
    chapter, we will have to add the following to include the Spring Cloud dependencies.
    This is not required if the project is created from scratch:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The next screenshot shows the Cloud starter library selection screen. If the
    application is built from the ground up, select the libraries as shown in the
    following screenshot:![Accessing the Config Server from clients](img/B05447_05_09.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Rename `application.properties` to `bootstrap.properties`, and add an application
    name and a configuration server URL. The configuration server URL is not mandatory
    if the Config server is running on the default port (`8888`) on the local host:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The new `bootstrap.properties` file will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '`search-service` is a logical name given to the Search microservice. This will
    be treated as service ID. The Config server will look for `search-service.properties`
    in the repository to resolve the properties.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new configuration file for `search-service`. Create a new `search-service.properties`
    under the `config-repo` folder where the Git repository is created. Note that
    `search-service` is the service ID given to the Search microservice in the `bootstrap.properties`
    file. Move service-specific properties from `bootstrap.properties` to the new
    `search-service.properties` file. The following properties will be removed from
    `bootstrap.properties`, and added to `search-service.properties`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to demonstrate the centralized configuration of properties and propagation
    of changes, add a new application-specific property to the property file. We will
    add `originairports.shutdown` to temporarily take out an airport from the search.
    Users will not get any flights when searching for an airport mentioned in the
    shutdown list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we will not return any flights when searching with `SEA` as
    origin.
  prefs: []
  type: TYPE_NORMAL
- en: 'Commit this new file into the Git repository by executing the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The final `search-service.properties` file should look as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The `chapter5.search` project''s `bootstrap.properties` should look like the
    following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Modify the Search microservice code to use the configured parameter, `originairports.shutdown`.
    A `RefreshScope` annotation has to be added at the class level to allow properties
    to be refreshed when there is a change. In this case, we are adding a refresh
    scope to the `SearchRestController` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following instance variable as a place holder for the new property
    that is just added in the Config server. The property names in the `search-service.properties`
    file must match:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Change the application code to use this property. This is done by modifying
    the `search` method as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The `search` method is modified to read the parameter `originAirportShutdownList`
    and see whether the requested origin is in the shutdown list. If there is a match,
    then instead of proceeding with the actual search, the search method will return
    an empty flight list.
  prefs: []
  type: TYPE_NORMAL
- en: Start the Config server. Then start the Search microservice. Make sure that
    the RabbitMQ server is running.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Modify the `chapter5.website` project to match the `bootstrap.properties` content
    as follows to utilize the Config server:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Change the `run` method of `CommandLineRunner` in `Application.java` to query
    SEA as the origin airport:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the `chapter5.website` project. The `CommandLineRunner` will now return
    an empty flight list. The following message will be printed in the server:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Handling configuration changes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section will demonstrate how to propagate configuration properties when
    there is a change:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Change the property in the `search-service.properties` file to the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Commit the change in the Git repository. Refresh the Config server URL (`http://localhost:8888/search-service/default`)
    for this service and see whether the property change is reflected. If everything
    is fine, we will see the property change. The preceding request will force the
    Config server to read the property file again from the repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rerun the website project again, and observe the `CommandLineRunner` execution.
    Note that in this case, we are not restarting the Search microservice nor the
    Config server. The service returns an empty flight list as earlier, and still
    complains as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: This means the change is not reflected in the Search service, and the service
    is still working with an old copy of the configuration properties.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to force reloading of the configuration properties, call the `/refresh`
    endpoint of the Search microservice. This is actually the actuator''s refresh
    endpoint. The following command will send an empty POST to the `/refresh` endpoint:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Rerun the website project, and observe the `CommandLineRunner` execution. This
    should return the list of flights that we have requested from SEA. Note that the
    website project may fail if the Booking service is not up and running.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `/refresh` endpoint will refresh the locally cached configuration properties,
    and reload fresh values from the Config server.
  prefs: []
  type: TYPE_NORMAL
- en: Spring Cloud Bus for propagating configuration changes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the preceding approach, configuration parameters can be changed without
    restarting the microservices. This is good when there are only one or two instances
    of the services running. What happens if there are many instances? For example,
    if there are five instances, then we have to hit `/refresh` against each service
    instance. This is definitely a cumbersome activity:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Spring Cloud Bus for propagating configuration changes](img/B05447_05_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The Spring Cloud Bus provides a mechanism to refresh configurations across multiple
    instances without knowing how many instances there are, or their locations. This
    is particularly handy when there are many service instances of a microservice
    running or when there are many microservices of different types running. This
    is done by connecting all service instances through a single message broker. Each
    instance subscribes for change events, and refreshes its local configuration when
    required. This refresh is triggered by making a call to any one instance by hitting
    the `/bus/refresh` endpoint, which then propagates the changes through the cloud
    bus and the common message broker.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, RabbitMQ is used as the AMQP message broker. Implement this
    by following the steps documented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a new dependency in the `chapter5.search` project''s `pom.xml` file to
    introduce the Cloud Bus dependency:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The Search microservice also needs connectivity to the RabbitMQ, but this is
    already provided in `search-service.properties`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Rebuild and restart the Search microservice. In this case, we will run two
    instances of the Search microservice from a command line, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The two instances of the Search service will be now running, one on port `8090`
    and another one on `8091`.
  prefs: []
  type: TYPE_NORMAL
- en: Rerun the website project. This is just to make sure that everything is working.
    The Search service should return one flight at this point.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, update `search-service.properties` with the following value, and commit
    to Git:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following command to `/bus/refresh`. Note that we are running a new
    bus endpoint against one of the instances, `8090` in this case:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Immediately, we will see the following message for both instances:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The bus endpoint sends a message to the message broker internally, which is
    eventually consumed by all instances, reloading their property files. Changes
    can also be applied to a specific application by specifying the application name
    like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: We can also refresh specific properties by setting the property name as a parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up high availability for the Config server
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The previous sections explored how to set up the Config server, allowing real-time
    refresh of configuration properties. However, the Config server is a single point
    of failure in this architecture.
  prefs: []
  type: TYPE_NORMAL
- en: There are three single points of failure in the default architecture that was
    established in the previous section. One of them is the availability of the Config
    server itself, the second one is the Git repository, and the third one is the
    RabbitMQ server.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows a high availability architecture for the Config
    server:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Setting up high availability for the Config server](img/B05447_05_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The architecture mechanisms and rationale are explained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The Config server requires high availability, since the services won't be able
    to bootstrap if the Config server is not available. Hence, redundant Config servers
    are required for high availability. However, the applications can continue to
    run if the Config server is unavailable after the services are bootstrapped. In
    this case, services will run with the last known configuration state. Hence, the
    Config server availability is not at the same critical level as the microservices
    availability.
  prefs: []
  type: TYPE_NORMAL
- en: In order to make the Config server highly available, we need multiple instances
    of the Config servers. Since the Config server is a stateless HTTP service, multiple
    instances of configuration servers can be run in parallel. Based on the load on
    the configuration server, a number of instances have to be adjusted. The `bootstrap.properties`
    file is not capable of handling more than one server address. Hence, multiple
    configuration servers should be configured to run behind a load balancer or behind
    a local DNS with failover and fallback capabilities. The load balancer or DNS
    server URL will be configured in the microservices' `bootstrap.properties` file.
    This is with the assumption that the DNS or the load balancer is highly available
    and capable of handling failovers.
  prefs: []
  type: TYPE_NORMAL
- en: In a production scenario, it is not recommended to use a local file-based Git
    repository. The configuration server should be typically backed with a highly
    available Git service. This is possible by either using an external highly available
    Git service or a highly available internal Git service. SVN can also be considered.
  prefs: []
  type: TYPE_NORMAL
- en: Having said that, an already bootstrapped Config server is always capable of
    working with a local copy of the configuration. Hence, we need a highly available
    Git only when the Config server needs to be scaled. Therefore, this too is not
    as critical as the microservices availability or the Config server availability.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The GitLab example for setting up high availability is available at [https://about.gitlab.com/high-availability/](https://about.gitlab.com/high-availability/).
  prefs: []
  type: TYPE_NORMAL
- en: RabbitMQ also has to be configured for high availability. The high availability
    for RabbitMQ is needed only to push configuration changes dynamically to all instances.
    Since this is more of an offline controlled activity, it does not really require
    the same high availability as required by the components.
  prefs: []
  type: TYPE_NORMAL
- en: RabbitMQ high availability can be achieved by either using a cloud service or
    a locally configured highly available RabbitMQ service.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Setting up high availability for Rabbit MQ is documented at [https://www.rabbitmq.com/ha.html](https://www.rabbitmq.com/ha.html).
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring the Config server health
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Config server is nothing but a Spring Boot application, and is, by default,
    configured with an actuator. Hence, all actuator endpoints are applicable for
    the Config server. The health of the server can be monitored using the following
    actuator URL: `http://localhost:8888/health`.'
  prefs: []
  type: TYPE_NORMAL
- en: Config server for configuration files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We may run into scenarios where we need a complete configuration file such
    as `logback.xml` to be externalized. The Config server provides a mechanism to
    configure and store such files. This is achievable by using the URL format as
    follows: `/{name}/{profile}/{label}/{path}`.'
  prefs: []
  type: TYPE_NORMAL
- en: The name, profile, and label have the same meanings as explained earlier. The
    path indicates the file name such as `logback.xml`.
  prefs: []
  type: TYPE_NORMAL
- en: Completing changes to use the Config server
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to build this capability to complete BrownField Airline's PSS, we have
    to make use of the configuration server for all services. All microservices in
    the examples given in `chapter5.*` need to make similar changes to look to the
    Config server for getting the configuration parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are a few key change considerations:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Fare service URL in the booking component will also be externalized:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: We are not externalizing the queue names used in the Search, Booking, and Check-in
    services at the moment. Later in this chapter, these will be changed to use Spring
    Cloud Streams.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feign as a declarative REST client
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to use Feign, first we need to change the `pom.xml` file to include
    the Feign dependency as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'For a new Spring Starter project, **Feign** can be selected from the starter
    library selection screen, or from [http://start.spring.io/](http://start.spring.io/).
    This is available under **Cloud Routing** as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Feign as a declarative REST client](img/B05447_05_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The next step is to create a new `FareServiceProxy` interface. This will act
    as a proxy interface of the actual Fare service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: The `FareServiceProxy` interface has a `@FeignClient` annotation. This annotation
    tells Spring to create a REST client based on the interface provided. The value
    could be a service ID or a logical name. The `url` indicates the actual URL where
    the target service is running. Either name or value is mandatory. In this case,
    since we have `url`, the `name` attribute is irrelevant.
  prefs: []
  type: TYPE_NORMAL
- en: Use this service proxy to call the Fare service. In the Booking microservice,
    we have to tell Spring that Feign clients exist in the Spring Boot application,
    which are to be scanned and discovered. This will be done by adding `@EnableFeignClients`
    at the class level of `BookingComponent`. Optionally, we can also give the package
    names to scan.
  prefs: []
  type: TYPE_NORMAL
- en: 'Change `BookingComponent`, and make changes to the calling part. This is as
    simple as calling another Java interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Rerun the Booking microservice to see the effect.
  prefs: []
  type: TYPE_NORMAL
- en: 'The URL of the Fare service in the `FareServiceProxy` interface is hardcoded:
    `url="localhost:8080/fares"`.'
  prefs: []
  type: TYPE_NORMAL
- en: For the time being, we will keep it like this, but we are going to change this
    later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Ribbon for load balancing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous setup, we were always running with a single instance of the
    microservice. The URL is hardcoded both in client as well as in the service-to-service
    calls. In the real world, this is not a recommended approach, since there could
    be more than one service instance. If there are multiple instances, then ideally,
    we should use a load balancer or a local DNS server to abstract the actual instance
    locations, and configure an alias name or the load balancer address in the clients.
    The load balancer then receives the alias name, and resolves it with one of the
    available instances. With this approach, we can configure as many instances behind
    a load balancer. It also helps us to handle server failures transparent to the
    client.
  prefs: []
  type: TYPE_NORMAL
- en: This is achievable with Spring Cloud Netflix Ribbon. Ribbon is a client-side
    load balancer which can do round-robin load balancing across a set of servers.
    There could be other load balancing algorithms possible with the Ribbon library.
    Spring Cloud offers a declarative way to configure and use the Ribbon client.
  prefs: []
  type: TYPE_NORMAL
- en: '![Ribbon for load balancing](img/B05447_05_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As shown in the preceding diagram, the Ribbon client looks for the Config server
    to get the list of available microservice instances, and, by default, applies
    a round-robin load balancing algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to use the Ribbon client, we will have to add the following dependency
    to the `pom.xml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'In case of development from ground up, this can be selected from the Spring
    Starter libraries, or from [http://start.spring.io/](http://start.spring.io/).
    Ribbon is available under **Cloud Routing**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Ribbon for load balancing](img/B05447_05_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Update the Booking microservice configuration file, `booking-service.properties`,
    to include a new property to keep the list of the Fare microservices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Going back and editing the `FareServiceProxy` class created in the previous
    section to use the Ribbon client, we note that the value of the `@RequestMapping`
    annotations is changed from `/get` to `/fares/get` so that we can move the host
    name and port to the configuration easily:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now run two instances of the Fares microservices. Start one of them
    on `8080`, and the other one on `8081`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Run the Booking microservice. When the Booking microservice is bootstrapped,
    the `CommandLineRunner` automatically inserts one booking record. This will go
    to the first server.
  prefs: []
  type: TYPE_NORMAL
- en: When running the website project, it calls the Booking service. This request
    will go to the second server.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the Booking service, we see the following trace, which says there are two
    servers enlisted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Eureka for registration and discovery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have achieved externalizing configuration parameters as well as load
    balancing across many service instances.
  prefs: []
  type: TYPE_NORMAL
- en: 'Ribbon-based load balancing is sufficient for most of the microservices requirements.
    However, this approach falls short in a couple of scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: If there is a large number of microservices, and if we want to optimize infrastructure
    utilization, we will have to dynamically change the number of service instances
    and the associated servers. It is not easy to predict and preconfigure the server
    URLs in a configuration file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When targeting cloud deployments for highly scalable microservices, static registration
    and discovery is not a good solution considering the elastic nature of the cloud
    environment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the cloud deployment scenarios, IP addresses are not predictable, and will
    be difficult to statically configure in a file. We will have to update the configuration
    file every time there is a change in address.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Ribbon approach partially addresses this issue. With Ribbon, we can dynamically
    change the service instances, but whenever we add new service instances or shut
    down instances, we will have to manually update the Config server. Though the
    configuration changes will be automatically propagated to all required instances,
    the manual configuration changes will not work with large scale deployments. When
    managing large deployments, automation, wherever possible, is paramount.
  prefs: []
  type: TYPE_NORMAL
- en: To fix this gap, the microservices should self-manage their life cycle by dynamically
    registering service availability, and provision automated discovery for consumers.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding dynamic service registration and discovery
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Dynamic registration is primarily from the service provider's point of view.
    With dynamic registration, when a new service is started, it automatically enlists
    its availability in a central service registry. Similarly, when a service goes
    out of service, it is automatically delisted from the service registry. The registry
    always keeps up-to-date information of the services available, as well as their
    metadata.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic discovery is applicable from the service consumer's point of view. Dynamic
    discovery is where clients look for the service registry to get the current state
    of the services topology, and then invoke the services accordingly. In this approach,
    instead of statically configuring the service URLs, the URLs are picked up from
    the service registry.
  prefs: []
  type: TYPE_NORMAL
- en: The clients may keep a local cache of the registry data for faster access. Some
    registry implementations allow clients to keep a watch on the items they are interested
    in. In this approach, the state changes in the registry server will be propagated
    to the interested parties to avoid using stale data.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a number of options available for dynamic service registration and
    discovery. Netflix Eureka, ZooKeeper, and Consul are available as part of Spring
    Cloud, as shown in the [http://start.spring.io/](http://start.spring.io/) screenshot
    given next. Etcd is another service registry available outside of Spring Cloud
    to achieve dynamic service registration and discovery. In this chapter, we will
    focus on the Eureka implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding dynamic service registration and discovery](img/B05447_05_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Understanding Eureka
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Spring Cloud Eureka also comes from Netflix OSS. The Spring Cloud project provides
    a Spring-friendly declarative approach for integrating Eureka with Spring-based
    applications. Eureka is primarily used for self-registration, dynamic discovery,
    and load balancing. Eureka uses Ribbon for load balancing internally:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding Eureka](img/B05447_05_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As shown in the preceding diagram, Eureka consists of a server component and
    a client-side component. The server component is the registry in which all microservices
    register their availability. The registration typically includes service identity
    and its URLs. The microservices use the Eureka client for registering their availability.
    The consuming components will also use the Eureka client for discovering the service
    instances.
  prefs: []
  type: TYPE_NORMAL
- en: When a microservice is bootstrapped, it reaches out to the Eureka server, and
    advertises its existence with the binding information. Once registered, the service
    endpoint sends ping requests to the registry every 30 seconds to renew its lease.
    If a service endpoint cannot renew its lease in a few attempts, that service endpoint
    will be taken out of the service registry. The registry information will be replicated
    to all Eureka clients so that the clients have to go to the remote Eureka server
    for each and every request. Eureka clients fetch the registry information from
    the server, and cache it locally. After that, the clients use that information
    to find other services. This information is updated periodically (every 30 seconds)
    by getting the delta updates between the last fetch cycle and the current one.
  prefs: []
  type: TYPE_NORMAL
- en: When a client wants to contact a microservice endpoint, the Eureka client provides
    a list of currently available services based on the requested service ID. The
    Eureka server is zone aware. Zone information can also be supplied when registering
    a service. When a client requests for a services instance, the Eureka service
    tries to find the service running in the same zone. The Ribbon client then load
    balances across these available service instances supplied by the Eureka client.
    The communication between the Eureka client and the server is done using REST
    and JSON.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the Eureka server
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will run through the steps required for setting up the Eureka
    server.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The full source code of this section is available under the `chapter5.eurekaserver`
    project in the code files. Note that the Eureka server registration and refresh
    cycles take up to 30 seconds. Hence, when running services and clients, wait for
    40-50 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: Start a new Spring Starter project, and select **Config Client**, **Eureka Server**,
    and **Actuator**:![Setting up the Eureka server](img/B05447_05_17.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The project structure of the Eureka server is shown in the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Setting up the Eureka server](img/B05447_05_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note that the main application is named `EurekaserverApplication.java`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rename `application.properties` to `bootstrap.properties` since this is using
    the Config server. As we did earlier, configure the details of the Config server
    in the `bootsratp.properties` file so that it can locate the Config server instance.
    The `bootstrap.properties` file will look as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The Eureka server can be set up in a standalone mode or in a clustered mode.
    We will start with the standalone mode. By default, the Eureka server itself is
    another Eureka client. This is particularly useful when there are multiple Eureka
    servers running for high availability. The client component is responsible for
    synchronizing state from the other Eureka servers. The Eureka client is taken
    to its peers by configuring the `eureka.client.serviceUrl.defaultZone` property.
  prefs: []
  type: TYPE_NORMAL
- en: In the standalone mode, we point `eureka.client.serviceUrl.defaultZone` back
    to the same standalone instance. Later we will see how we can run Eureka servers
    in a clustered mode.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a `eureka-server1.properties` file, and update it in the Git repository.
    `eureka-server1` is the name of the application given in the application''s `bootstrap.properties`
    file in the previous step. As shown in the following code, `serviceUrl` points
    back to the same server. Once the following properties are added, commit the file
    to the Git repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Change the default `Application.java`. In this example, the package is also
    renamed as `com.brownfield.pss.eurekaserver`, and the class name changed to `EurekaserverApplication`.
    In `EurekaserverApplication`, add `@EnableEurekaServer`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: We are now ready to start the Eureka server. Ensure that the Config server is
    also started. Right-click on the application and then choose **Run As** | **Spring
    Boot App**. Once the application is started, open `http://localhost:8761` in a
    browser to see the Eureka console.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the console, note that there is no instance registered under **Instances
    currently registered with Eureka**. Since no services have been started with the
    Eureka client enabled, the list is empty at this point.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Making a few changes to our microservice will enable dynamic registration and
    discovery using the Eureka service. To do this, first we have to add the Eureka
    dependencies to the `pom.xml` file. If the services are being built up fresh using
    the Spring Starter project, then select **Config Client**, **Actuator**, **Web**
    as well as **Eureka discovery** client as follows:![Setting up the Eureka server](img/B05447_05_19.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Since we are modifying our microservices, add the following additional dependency
    to all microservices in their `pom.xml` files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The following property has to be added to all microservices in their respective
    configuration files under `config-repo`. This will help the microservices to connect
    to the Eureka server. Commit to Git once updates are completed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Add `@EnableDiscoveryClient` to all microservices in their respective Spring
    Boot main classes. This asks Spring Boot to register these services at start up
    to advertise their availability.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start all servers except Booking. Since we are using the Ribbon client on the
    Booking service, the behavior could be different when we add the Eureka client
    in the class path. We will fix this soon.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Going to the Eureka URL (`http://localhost:8761`), you can see that all three
    instances are up and running:![Setting up the Eureka server](img/B05447_05_20.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Time to fix the issue with Booking. We will remove our earlier Ribbon client,
    and use Eureka instead. Eureka internally uses Ribbon for load balancing. Hence,
    the load balancing behavior will not change.
  prefs: []
  type: TYPE_NORMAL
- en: 'Remove the following dependency:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Also remove the `@RibbonClient(name="fares")` annotation from the `FareServiceProxy`
    class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update `@FeignClient(name="fares-service")` to match the actual Fare microservices'
    service ID. In this case, `fare-service` is the service ID configured in the Fare
    microservices' `bootstrap.properties`. This is the name that the Eureka discovery
    client sends to the Eureka server. The service ID will be used as a key for the
    services registered in the Eureka server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Also remove the list of servers from the `booking-service.properties` file.
    With Eureka, we are going to dynamically discover this list from the Eureka server:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Start the Booking service. You will see that `CommandLineRunner` successfully
    created a booking, which involves calling the Fare services using the Eureka discovery
    mechanism. Go back to the URL to see all the registered services:![Setting up
    the Eureka server](img/B05447_05_21.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Change the website project''s `bootstrap.properties` file to make use of Eureka
    rather than connecting directly to the service instances. We will not use the
    Feign client in this case. Instead, for demonstration purposes, we will use the
    load balanced `RestTemplate`. Commit these changes to the Git repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Add `@EnableDiscoveryClient` to the `Application` class to make the client Eureka-aware.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Edit both `Application.java` as well as `BrownFieldSiteController.java`. Add
    three `RestTemplate` instances. This time, we annotate them with `@Loadbalanced`
    to ensure that we use the load balancing features using Eureka and Ribbon. `RestTemplate`
    cannot be automatically injected. Hence, we have to provide a configuration entry
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'We use these `RestTemplate` instances to call the microservices. Replace the
    hardcoded URLs with service IDs that are registered in the Eureka server. In the
    following code, we use the service names `search-service`, `book-service`, and
    `checkin-service` instead of explicit host names and ports:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: We are now ready to run the client. Run the website project. If everything is
    fine, the website project's `CommandLineRunner` will successfully perform search,
    booking, and check-in. The same can also be tested using the browser by pointing
    the browser to `http://localhost:8001`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: High availability for Eureka
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Update the `bootstrap.properties` file of Eureka, and change the application
    name to `eureka`. Since we are using two profiles, based on the active profile
    supplied at startup, the Config server will look for either `eureka-server1` or
    `eureka-server2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Start two instances of the Eureka servers, `server1` on `8761` and `server2`
    on `8762`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'All our services still point to the first server, `server1`. Open both the
    browser windows: `http://localhost:8761` and `http://localhost:8762`.'
  prefs: []
  type: TYPE_NORMAL
- en: Start all microservices. The one which opened `8761` will immediately reflect
    the changes, whereas the other one will take 30 seconds for reflecting the states.
    Since both the servers are in a cluster, the state is synchronized between these
    two servers. If we keep these servers behind a load balancer/DNS, then the client
    will always connect to one of the available servers.
  prefs: []
  type: TYPE_NORMAL
- en: After completing this exercise, switch back to the standalone mode for the remaining
    exercises.
  prefs: []
  type: TYPE_NORMAL
- en: Zuul proxy as the API gateway
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In most microservice implementations, internal microservice endpoints are not
    exposed outside. They are kept as private services. A set of public services will
    be exposed to the clients using an API gateway. There are many reasons to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: Only a selected set of microservices are required by the clients.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If there are client-specific policies to be applied, it is easy to apply them
    in a single place rather than in multiple places. An example of such a scenario
    is the cross-origin access policy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is hard to implement client-specific transformations at the service endpoint.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If there is data aggregation required, especially to avoid multiple client calls
    in a bandwidth-restricted environment, then a gateway is required in the middle.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zuul is a simple gateway service or edge service that suits these situations
    well. Zuul also comes from the Netflix family of microservice products. Unlike
    many enterprise API gateway products, Zuul provides complete control for the developers
    to configure or program based on specific requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Zuul proxy as the API gateway](img/B05447_05_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The Zuul proxy internally uses the Eureka server for service discovery, and
    Ribbon for load balancing between service instances.
  prefs: []
  type: TYPE_NORMAL
- en: The Zuul proxy is also capable of routing, monitoring, managing resiliency,
    security, and so on. In simple terms, we can consider Zuul a reverse proxy service.
    With Zuul, we can even change the behaviors of the underlying services by overriding
    them at the API layer.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Zuul
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Unlike the Eureka server and the Config server, in typical deployments, Zuul
    is specific to a microservice. However, there are deployments in which one API
    gateway covers many microservices. In this case, we are going to add Zuul for
    each of our microservices: Search, Booking, Fare, and Check-in:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The full source code of this section is available under the `chapter5.*-apigateway`
    project in the code files.
  prefs: []
  type: TYPE_NORMAL
- en: Convert the microservices one by one. Start with Search API Gateway. Create
    a new Spring Starter project, and select **Zuul**, **Config Client**, **Actuator**,
    and **Eureka Discovery**:![Setting up Zuul](img/B05447_05_24.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The project structure for `search-apigateway` is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Setting up Zuul](img/B05447_05_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The next step is to integrate the API gateway with Eureka and the Config server.
    Create a `search-apigateway.property` file with the contents given next, and commit
    to the Git repository.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This configuration also sets a rule on how to forward traffic. In this case,
    any request coming on the `/api` endpoint of the API gateway should be sent to
    `search-service`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '`search-service` is the service ID of the Search service, and it will be resolved
    using the Eureka server.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Update the `bootstrap.properties` file of `search-apigateway` as follows. There
    is nothing new in this configuration—a name to the service, the port, and the
    Config server URL:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Edit `Application.java`. In this case, the package name and the class name
    are also changed to `com.brownfield.pss.search.apigateway` and `SearchApiGateway`
    respectively. Also add `@EnableZuulProxy` to tell Spring Boot that this is a Zuul
    proxy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Run this as a Spring Boot app. Before that, ensure that the Config server, the
    Eureka server, and the Search microservice are running.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Change the website project''s `CommandLineRunner` as well as `BrownFieldSiteController`
    to make use of the API gateway:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: In this case, the Zuul proxy acts as a reverse proxy which proxies all microservice
    endpoints to consumers. In the preceding example, the Zuul proxy does not add
    much value, as we just pass through the incoming requests to the corresponding
    backend service.
  prefs: []
  type: TYPE_NORMAL
- en: 'Zuul is particularly useful when we have one or more requirements like the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: Enforcing authentication and other security policies at the gateway instead
    of doing that on every microservice endpoint. The gateway can handle security
    policies, token handling, and so on before passing the request to the relevant
    services behind. It can also do basic rejections based on some business policies
    such as blocking requests coming from certain black-listed users.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Business insights and monitoring can be implemented at the gateway level. Collect
    real-time statistical data, and push it to an external system for analysis. This
    will be handy as we can do this at one place rather than applying it across many
    microservices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: API gateways are useful in scenarios where dynamic routing is required based
    on fine-grained controls. For example, send requests to different service instances
    based on business specific values such as "origin country". Another example is
    all requests coming from a region to be sent to one group of service instances.
    Yet another example is all requests requesting for a particular product have to
    be routed to a group of service instances.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling the load shredding and throttling requirements is another scenario
    where API gateways are useful. This is when we have to control load based on set
    thresholds such as number of requests in a day. For example, control requests
    coming from a low-value third party online channel.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Zuul gateway is useful for fine-grained load balancing scenarios. The Zuul,
    Eureka client, and Ribbon together provide fine-grained controls over the load
    balancing requirements. Since the Zuul implementation is nothing but another Spring
    Boot application, the developer has full control over the load balancing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Zuul gateway is also useful in scenarios where data aggregation requirements
    are in place. If the consumer wants higher level coarse-grained services, then
    the gateway can internally aggregate data by calling more than one service on
    behalf of the client. This is particularly applicable when the clients are working
    in low bandwidth environments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zuul also provides a number of filters. These filters are classified as pre
    filters, routing filters, post filters, and error filters. As the names indicate,
    these are applied at different stages of the life cycle of a service call. Zuul
    also provides an option for developers to write custom filters. In order to write
    a custom filter, extend from the abstract `ZuulFilter`, and implement the following
    methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Once a custom filter is implemented, add that class to the main context. In
    our example case, add this to the `SearchApiGateway` class as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'As mentioned earlier, the Zuul proxy is a Spring Boot service. We can customize
    the gateway programmatically in the way we want. As shown in the following code,
    we can add custom endpoints to the gateway, which, in turn, can call the backend
    services:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding case, it just adds a new endpoint, and returns a value from
    the gateway. We can further use `@Loadbalanced RestTemplate` to call a backend
    service. Since we have full control, we can do transformations, data aggregation,
    and so on. We can also use the Eureka APIs to get the server list, and implement
    completely independent load-balancing or traffic-shaping mechanisms instead of
    the out-of-the-box load balancing features provided by Ribbon.
  prefs: []
  type: TYPE_NORMAL
- en: High availability of Zuul
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Zuul is just a stateless service with an HTTP endpoint, hence, we can have as
    many Zuul instances as we need. There is no affinity or stickiness required. However,
    the availability of Zuul is extremely critical as all traffic from the consumer
    to the provider flows through the Zuul proxy. However, the elastic scaling requirements
    are not as critical as the backend microservices where all the heavy lifting happens.
  prefs: []
  type: TYPE_NORMAL
- en: 'The high availability architecture of Zuul is determined by the scenario in
    which we are using Zuul. The typical usage scenarios are:'
  prefs: []
  type: TYPE_NORMAL
- en: When a client-side JavaScript MVC such as AngularJS accesses Zuul services from
    a remote browser.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another microservice or non-microservice accesses services via Zuul
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In some cases, the client may not have the capabilities to use the Eureka client
    libraries, for example, a legacy application written on PL/SQL. In some cases,
    organization policies do not allow Internet clients to handle client-side load
    balancing. In the case of browser-based clients, there are third-party Eureka
    JavaScript libraries available.
  prefs: []
  type: TYPE_NORMAL
- en: It all boils down to whether the client is using Eureka client libraries or
    not. Based on this, there are two ways we can set up Zuul for high availability.
  prefs: []
  type: TYPE_NORMAL
- en: High availability of Zuul when the client is also a Eureka client
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this case, since the client is also another Eureka client, Zuul can be configured
    just like other microservices. Zuul registers itself to Eureka with a service
    ID. The clients then use Eureka and the service ID to resolve Zuul instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '![High availability of Zuul when the client is also a Eureka client](img/B05447_05_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As shown in the preceding diagram, Zuul services register themselves with Eureka
    with a service ID, `search-apigateway` in our case. The Eureka client asks for
    the server list with the ID `search-apigateway`. The Eureka server returns the
    list of servers based on the current Zuul topology. The Eureka client, based on
    this list picks up one of the servers, and initiates the call.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we saw earlier, the client uses the service ID to resolve the Zuul instance.
    In the following case, `search-apigateway` is the Zuul instance ID registered
    with Eureka:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: High availability when the client is not a Eureka client
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this case, the client is not capable of handling load balancing by using
    the Eureka server. As shown in the following diagram, the client sends the request
    to a load balancer, which in turn identifies the right Zuul service instance.
    The Zuul instance, in this case, will be running behind a load balancer such as
    HAProxy or a hardware load balancer like NetScaler:'
  prefs: []
  type: TYPE_NORMAL
- en: '![High availability when the client is not a Eureka client](img/B05447_05_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The microservices will still be load balanced by Zuul using the Eureka server.
  prefs: []
  type: TYPE_NORMAL
- en: Completing Zuul for all other services
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to complete this exercise, add API gateway projects (name them as
    `*-apigateway`) for all our microservices. The following steps are required to
    achieve this task:'
  prefs: []
  type: TYPE_NORMAL
- en: Create new property files per service, and check in to the Git repositories.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change `application.properties` to `bootstrap.properties`, and add the required
    configurations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add `@EnableZuulProxy` to `Application.java` in each of the `*-apigateway` projects.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add `@EnableDiscoveryClient` in all the `Application.java` files under each
    of the `*-apigateway` projects.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Optionally, change the package names and file names generated by default.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the end, we will have the following API gateway projects:'
  prefs: []
  type: TYPE_NORMAL
- en: '`chapter5.fares-apigateway`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`chapter5.search-apigateway`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`chapter5.checkin-apigateway`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`chapter5.book-apigateway`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Streams for reactive microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Spring Cloud Stream provides an abstraction over the messaging infrastructure.
    The underlying messaging implementation can be RabbitMQ, Redis, or Kafka. Spring
    Cloud Stream provides a declarative approach for sending and receiving messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Streams for reactive microservices](img/B05447_05_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As shown in the preceding diagram, Cloud Stream works on the concept of a **source**
    and a sink. The source represents the sender perspective of the messaging, and
    sink represents the receiver perspective of the messaging.
  prefs: []
  type: TYPE_NORMAL
- en: In the example shown in the diagram, the sender defines a logical queue called
    `Source.OUTPUT` to which the sender sends messages. The receiver defines a logical
    queue called `Sink.INPUT` from which the receiver retrieves messages. The physical
    binding of `OUTPUT` to `INPUT` is managed through the configuration. In this case,
    both link to the same physical queue—`MyQueue` on RabbitMQ. So, while at one end,
    `Source.OUTPUT` points to `MyQueue`, on the other end, `Sink.INPUT` points to
    the same `MyQueue`.
  prefs: []
  type: TYPE_NORMAL
- en: Spring Cloud offers the flexibility to use multiple messaging providers in one
    application such as connecting an input stream from Kafka to a Redis output stream,
    without managing the complexities. Spring Cloud Stream is the basis for message-based
    integration. The Cloud Stream Modules subproject is another Spring Cloud library
    that provides many endpoint implementations.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the next step, rebuild the inter-microservice messaging communication with
    the Cloud Streams. As shown in the next diagram, we will define a `SearchSink`
    connected to `InventoryQ` under the Search microservice. Booking will define a
    `BookingSource` for sending inventory change messages connected to `InventoryQ`.
    Similarly, Check-in defines a `CheckinSource` for sending the check-in messages.
    Booking defines a sink, `BookingSink`, for receiving messages, both bound to the
    `CheckinQ` queue on the RabbitMQ:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Streams for reactive microservices](img/B05447_05_29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In this example, we will use RabbitMQ as the message broker:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following Maven dependency to Booking, Search, and Check-in, as these
    are the three modules using messaging:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following two properties to `booking-service.properties`. These properties
    bind the logical queue `inventoryQ` to physical `inventoryQ`, and the logical
    `checkinQ` to the physical `checkinQ`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following property to `search-service.properties`. This property binds
    the logical queue `inventoryQ` to the physical `inventoryQ`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following property to `checkin-service.properties`. This property binds
    the logical queue `checkinQ` to the physical `checkinQ`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: Commit all files to the Git repository.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The next step is to edit the code. The Search microservice consumes a message
    from the Booking microservice. In this case, Booking is the source and Search
    is the sink.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add `@EnableBinding` to the `Sender` class of the Booking service. This enables
    the Cloud Stream to work on autoconfigurations based on the message broker library
    available in the class path. In our case, it is RabbitMQ. The parameter `BookingSource`
    defines the logical channels to be used for this configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, `BookingSource` defines a message channel called `inventoryQ`,
    which is physically bound to RabbitMQ''s `inventoryQ`, as configured in the configuration.
    `BookingSource` uses an annotation, `@Output`, to indicate that this is of the
    output type—a message that is outgoing from a module. This information will be
    used for autoconfiguration of the message channel:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Instead of defining a custom class, we can also use the default `Source` class
    that comes with Spring Cloud Stream if the service has only one source and sink:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a message channel in the sender, based on `BookingSource`. The following
    code will inject an output message channel with the name `inventory`, which is
    already configured in `BookingSource`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'Reimplement the `send` message method in `BookingSender`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Now add the following to the `SearchReceiver` class the same way we did for
    the Booking service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the `SearchSink` interface will look like the following. This
    will define the logical sink queue it is connected with. The message channel in
    this case is defined as `@Input` to indicate that this message channel is to accept
    messages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Amend the Search service to accept this message:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'We will still need the RabbitMQ configurations that we have in our configuration
    files to connect to the message broker:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: Run all services, and run the website project. If everything is fine, the website
    project successfully executes the Search, Booking, and Check-in functions. The
    same can also be tested using the browser by pointing to `http://localhost:8001`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summarizing the BrownField PSS architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following diagram shows the overall architecture that we have created with
    the Config server, Eureka, Feign, Zuul, and Cloud Streams. The architecture also
    includes the high availability of all components. In this case, we assume that
    the client uses the Eureka client libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Summarizing the BrownField PSS architecture](img/B05447_05_30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The summary of the projects and the port they are listening on is given in
    the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Microservice | Projects | Port |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Book microservice | `chapter5.book` | `8060` to `8064` |'
  prefs: []
  type: TYPE_TB
- en: '| Check-in microservice | `chapter5.checkin` | `8070` to `8074` |'
  prefs: []
  type: TYPE_TB
- en: '| Fare microservice | `chapter5.fares` | `8080` to `8084` |'
  prefs: []
  type: TYPE_TB
- en: '| Search microservice | `chapter5.search` | `8090` to `8094` |'
  prefs: []
  type: TYPE_TB
- en: '| Website client | `chapter5.website` | `8001` |'
  prefs: []
  type: TYPE_TB
- en: '| Spring Cloud Config server | `chapter5.configserver` | `8888`/`8889` |'
  prefs: []
  type: TYPE_TB
- en: '| Spring Cloud Eureka server | `chapter5.eurekaserver` | `8761`/`8762` |'
  prefs: []
  type: TYPE_TB
- en: '| Book API gateway | `chapter5.book-apigateway` | `8095` to `8099` |'
  prefs: []
  type: TYPE_TB
- en: '| Check-in API gateway | `chapter5.checkin-apigateway` | `8075` to `8079` |'
  prefs: []
  type: TYPE_TB
- en: '| Fares API gateway | `chapter5.fares-apigateway` | `8085` to `8089` |'
  prefs: []
  type: TYPE_TB
- en: '| Search API gateway | `chapter5.search-apigateway` | `8065` to `8069` |'
  prefs: []
  type: TYPE_TB
- en: 'Follow these steps to do a final run:'
  prefs: []
  type: TYPE_NORMAL
- en: Run RabbitMQ.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Build all projects using `pom.xml` at the root level:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following projects from their respective folders. Remember to wait
    for 40 to 50 seconds before starting the next service. This will ensure that the
    dependent services are registered and are available before we start a new service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: Open the browser window, and point to `http://localhost:8001`. Follow the steps
    mentioned in the *Running and testing the project* section in [Chapter 4](ch04.html
    "Chapter 4. Microservices Evolution – A Case Study"), *Microservices Evolution
    – A Case Study*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to scale a Twelve-Factor Spring Boot microservice
    using the Spring Cloud project. What you learned was then applied to the BrownField
    Airline's PSS microservice that we developed in the previous chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We then explored the Spring Config server for externalizing the microservices'
    configuration, and the way to deploy the Config server for high availability.
    We also discussed the declarative service calls using Feign, examined the use
    of Ribbon and Eureka for load balancing, dynamic service registration, and discovery.
    Implementation of an API gateway was examined by implementing Zuul. Finally, we
    concluded with a reactive style integration of microservices using Spring Cloud
    Stream.
  prefs: []
  type: TYPE_NORMAL
- en: BrownField Airline's PSS microservices are now deployable on the Internet scale.
    Other Spring Cloud components such as Hyterix, Sleuth, and so on will be covered
    in [Chapter 7](ch07.html "Chapter 7. Logging and Monitoring Microservices"), *Logging
    and Monitoring Microservices*. The next chapter will demonstrate autoscaling features,
    extending the BrownField PSS implementation.
  prefs: []
  type: TYPE_NORMAL
