- en: Chapter 10 – Unit testing with the Python standard library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we build programs of even minor complexity, there are countless ways for
    defects to creep into our code. This can happen when we initially write the code,
    but we’re just as likely to introduce defects when we make modifications to it.
    To help get a handle on defects and keep our code quality high, it’s often very
    useful to have a set of tests that you can run that will tell if you if the code
    is acting as you expect.
  prefs: []
  type: TYPE_NORMAL
- en: To help make such tests, the Python standard library includes the [`unittest`
    module](https://docs.python.org/3/library/unittest.html). Despite what its name
    suggests, this module helps with more than just unit testing. It is, in fact,
    a flexible framework for automating tests of all sorts, from acceptance tests
    to integration tests to unit tests. Its key feature, like many testing frameworks
    in many languages, is that it helps you make *automated* and *repeatable* tests.
    With tests like these, you can cheaply and easily verify the behavior of your
    code at any time.
  prefs: []
  type: TYPE_NORMAL
- en: Test cases
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `unittest` module is built around a handful of key concepts, at the center
    of which is the notion of a *test case*. A test case — embodied in the [`unittest.TestCase`
    class](https://docs.python.org/3/library/unittest.html#unittest.TestCase) — groups
    together a set of related test methods, and it is the basic unit of test organization
    in the `unittest` framework. The individual test methods, as we’ll see later,
    are implemented as methods on a `unittest.TestCase` subclass.
  prefs: []
  type: TYPE_NORMAL
- en: Fixtures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The next important concept is that of *fixtures*. Fixtures are pieces of code
    which run before and/or after every test method. Fixtures serve two main purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Set-up* fixtures ensure that the test environment is in an expected state
    before a test is run.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Tear-down* fixtures clean up the environment after a test has been run, generally
    by freeing up resources.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For example, a set-up fixture might create a specific entry in a database prior
    to running a test. Similarly, a tear-down fixture might remove database entries
    created by a test. Fixtures are not required for tests, but they are very common,
    and they are often critical for making tests repeatable.
  prefs: []
  type: TYPE_NORMAL
- en: Assertions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The final key concept is that of *assertions*. Assertions are specific checks
    inside test methods which ultimately determine whether a test passes or fails.
    Among other things, assertions can:'
  prefs: []
  type: TYPE_NORMAL
- en: make simple boolean checks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: perform object equality tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: verify that the proper exceptions are thrown
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If an assertion fails, then a test method fails, so assertions represent the
    lowest level of testing you can perform. You can find a [full list of assertions
    in the `unittest` documentation](https://docs.python.org/3/library/unittest.html#assert-methods).
  prefs: []
  type: TYPE_NORMAL
- en: 'Unit testing example: text analysis'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'With those concepts in mind, let’s see how we can actually use the `unittest`
    module in practice. For this example, we’ll use *test-driven development*^([29](chap21.xhtml#fn-test-driven-development))
    to write a simple text-analysis function. This function will take a file name
    as its only parameter. It will then read that file and calculate:'
  prefs: []
  type: TYPE_NORMAL
- en: the number of lines in the file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the number of characters in the file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'TDD is an iterative development process, so rather than work at the REPL we’ll
    put the code for our tests in a file named `text_analyzer.py`. To start with,
    we’ll create our first test^([30](chap21.xhtml#fn-no-actual-test)) with just enough
    supporting code to actually run it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Ths first thing we do is import the `unittest` module. We then create our test
    case by defining a class – `TextAnalysisTests` – which derives from `unittest.TestCase`.
    This is how you create test cases with the `unittest` framework.
  prefs: []
  type: TYPE_NORMAL
- en: To define individual test methods in a test case, you simply create methods
    on your `TestCase` subclasses that start with “`test_`”. The `unittest` framework
    automatically discovers methods like this at execution time, so you don’t need
    to explicitly register your test methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case we define the simplest possible test: we check whether the `analyze_text()`
    function runs at all! Our test doesn’t make any explicit checks, but rather it
    relies on the fact that a test method will fail if it throws any exceptions. In
    this case, our test will fail if `analyze_text()` isn’t defined.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we define the idiomatic “main” block which calls `unittest.main()`
    when this module is executed. `unittest.main()` will search for all `TestCase`
    subclasses in a module and execute all of their test methods.
  prefs: []
  type: TYPE_NORMAL
- en: Running the initial tests
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Since we’re using test-driven design, we expect our tests to fail at first^([31](chap21.xhtml#fn-tdd-fail-edit-pass)).
    And indeed our test fails spectacularly for the simple reason that we haven’t
    yet defined `analyze_text()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, `unittest.main()` produces a simple report telling us how many
    tests were run and how many failed. It also shows us *how* the tests failed, in
    this case showing us that we got a `NameError` when we tried to run the non-existent
    function `analyze_text()`.
  prefs: []
  type: TYPE_NORMAL
- en: Making the test pass
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let’s fix our failing test by defining `analyze_text()`. Remember that in test-driven
    development we only write enough code to satisfy our tests, so all we do right
    now is create an empty function. For simplicity’s sake we’ll put this function
    in `text_analyzer.py`, though normally your test code and implementation code
    will be in different modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Put this function at module scope. Running the test again, we find that they
    now pass:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We’ve completed a single TDD cycle, but of course our code doesn’t really do
    anything yet. We’ll iteratively improve our tests and implementation to arrive
    at a real solution.
  prefs: []
  type: TYPE_NORMAL
- en: Using fixtures to create temporary files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The next thing want to do is be able to pass a filename to `analyze_text()`
    so that it knows what to process. Of course, for `analyze_text()` to work this
    filename should refer to a file that actually exists! To make sure that a file
    exists for our tests, we’re going to define some fixtures.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first fixture we can define is the method `TestCase.setUp()`. If defined,
    this method is run before each test method in the `TestCase`. In this case, we’ll
    use `setUp()` to create a file for us and remember the filename as a member of
    the `TestCase`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The second fixture available to us is `TestCase.tearDown()`.^([32](chap21.xhtml#fn-unittest-naming-conventions))
    The `tearDown()` method is run after each test method in the `TestCase`, and in
    this case we’re going to use it to delete the file we created in `setUp()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Note that since we’re using the `os` module in `tearDown()` we need to import
    it at the top of the file.
  prefs: []
  type: TYPE_NORMAL
- en: Also notice how `tearDown()` swallows any exceptions thrown by `os.remove()`.
    We do this because `tearDown()` can’t actually be certain that the file exists,
    so it tries to remove the file and assumes that any exception can safely be ignored.
  prefs: []
  type: TYPE_NORMAL
- en: Using the new fixtures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'With our two fixtures in place, we now have a file that is created before each
    test method and which is deleted after each test method. This means that each
    test method is starting in a stable, known state. This is critical to making reproducible
    tests. Let’s pass this filename to `analyze_text()` by modifying our existing
    test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Remember that our `setUp()` stored the filename on `self.filename`. Since the
    `self` argument passed to the fixtures is the same instance as that passed to
    the test methods, our test can access the filename using that attribute.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, when we run our test we see that this test fails because `analyze_text()`
    doesn’t accept any arguments yet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We can fix this by adding a parameter to `analyze_text()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'And if we run our tests again, we see that we’re once again passing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: We still don’t have an implementation that does anything useful, but you can
    start to see how the tests drive the implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Using assertions to test behavior
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now that we’re satisfied that `analyze_text()` exists and accepts the right
    number of arguments, let’s see if we can make it do real work. The first thing
    we want is for the function to return the number of lines in the file, so let’s
    define that test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we see our first example of an assertion. The `TestCase` class has [many
    assertion methods](https://docs.python.org/3/library/unittest.html#assert-methods),
    and in this case we used `assertEqual()` to check that the number of lines counted
    by our function is equal to four. If the value returned by `analyze_text()` is
    not equal to four, this assertion will cause the test method to fail. And if we
    run our new test, we see that this is precisely what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Here we see that we’re now running two tests, that one of them passes, and that
    the new one fails with an `AssertionError`.
  prefs: []
  type: TYPE_NORMAL
- en: Counting lines
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let’s break from the TDD rules and move a bit faster now. First we’ll update
    the function to return the number of lines in the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This change indeed gives us the results we want ^([33](chap21.xhtml#fn-bypassing-tdd)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Counting characters
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'So let’s add a test for the other feature we want, which is to count the number
    of characters in the file. Since `analyze_text()` is now supposed to return two
    values, we’ll have it return a tuple with line count in the first position and
    character count in the second. Our new test looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'And it fails as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This result is telling us that it can’t index into the integer returned by
    `analyze_text()`. So let’s fix `analyze_text()` to return the proper tuple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This fixes our new test, but we find we’ve broken an old one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Fortunately that’s easy enough to fix because all we need to do is account
    for the new return type in our earlier test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now everything is passing again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Testing for exceptions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Another thing we want to test for is that `analyze_text()` raises the correct
    exception when it is passed a non-existent file name, which we can test like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Here we use the `TestCase.assertRaises()` assertion. This assertion checks that
    the specified exception type — in this case `IOError` — is thrown from the body
    of the with-block.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since `open()` raises `IOError` for non-existent files, our test already passes
    with no further implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Testing for file existence
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, we can see one more very useful type of assertion by writing a test
    to verify that `analyze_text()` doesn’t delete the file — a reasonable requirement
    for the function!:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '`TestCase.assertTrue()` checks that the value passed to it evaluates to `True`.
    There is an equivalent `assertFalse()` which does the same test for false values.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you probably expect, this test passes already as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: So now we’ve got a useful, passing set of tests! This example is small, but
    it demonstrates many of the important parts of the `unittest` module. There are
    [many more parts to the `unittest` module](https://docs.python.org/3/library/unittest.html),
    but you can get quite far using just the techniques we’ve seen here.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Moment of zen
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![](images/m10----zen-in-the-face-of-ambiguity-refuse-the-temptation-to-guess.png)'
  prefs: []
  type: TYPE_IMG
- en: The temptation to guess, or to ignore ambiguity with wishful thinking, can lead
    to short term gains. But it can often lead to confusion in the future, and to
    bugs which are difficult to understand and fix. Before you make that next quick
    fix, ask yourself what information you need to do it correctly.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `unittest` module is a framework for developing reliable automated tests.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You define *test cases* by subclassing from `unittest.TestCase`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `unittest.main()` function is useful for running all of the tests in a module.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `setUp()` and `tearDown()` fixtures are used to run code before and after
    each test method.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test methods are defined by creating method names that start with `test_` on
    test case objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The various `TestCase.assert...` methods can be used to make a test method fail
    when the right conditions aren’t met.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use `TestCase.assertRaises()` in a with-statement to check that the right exceptions
    are thrown in a test.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
