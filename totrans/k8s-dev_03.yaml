- en: Interacting with Your Code in Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last chapter, we walked through making container images, and created
    simple examples using Python and Node.js. In this chapter, we will expand on the
    brief introduction to interacting with your running code, and dig into further
    details on how to see how your code is operating, run additional commands, and
    get debugging from those Pods.
  prefs: []
  type: TYPE_NORMAL
- en: 'The sections for this chapter are:'
  prefs: []
  type: TYPE_NORMAL
- en: Practical notes for writing your software to run in a Pod
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting logs from your containers and Pods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interaction with a running Pod
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes Concepts—labels and selectors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes Resource—service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discovering services from your Pod
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Practical notes for writing software to run in a container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To use Kubernetes in your development process, one of the foundational requirements
    is running your code in a container. As you've seen, this adds a few steps to
    your development process. It also places a few more constraints around how you
    structure your code and interact with it, primarily so you can take advantage
    of the constraints to let Kubernetes do the work of running the processes, connecting
    them together, and coordinating any output. This is very different from many developers'
    habits of running one or more processes together, even with additional services
    needed for your application – such as databases or caches—on your local development
    machine.
  prefs: []
  type: TYPE_NORMAL
- en: This section provides some tips and suggestions on how to work with containers
    more effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Getting options for your executable code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Aside from the `ENTRYPOINT` and `CMD` defined when you create your container,
    a container image can also define environment variables, usually via the `ENV`
    command when creating the container image. The `ENTRYPOINT`, `CMD`, and the environment
    variables can be overwritten or updated at execution time or when defining a deployment.
    Environment variables therefore become one of the most common ways of passing
    in configuration to your container.
  prefs: []
  type: TYPE_NORMAL
- en: Writing your software to utilize these environment variables will be important.
    As you create your software, make sure that you can take advantage of environment
    variables as well as command-line arguments in your code. Most languages have
    a library that will support options as either command-line arguments or environment
    variables.
  prefs: []
  type: TYPE_NORMAL
- en: In our next chapter, we will see how to set up configurations and pass them
    to your container at deployment time.
  prefs: []
  type: TYPE_NORMAL
- en: Practical notes for building container images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are suggestions and practical advice for maintaining your container
    images:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Keep a Dockerfile in your source repository.  If your application source is
    by itself in a Git repository, then including a Dockerfile in the repository along
    with it makes a great deal of sense. You can reference files to COPY or ADD from
    the relative directory of where your source is located. It’s not uncommon to see
    a Dockerfile in the root of a repository, or if you''re working from a monorepo
    with many projects, consider a Docker directory in the same directory as  your
    project’s source code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you want to take advantage of an automatic Docker build on Docker Hub, Quay,
    or another container repository, the automated system expects the Dockerfile to
    be in the root of your Git repository.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maintain a separate script (if needed) for creating the container image. Or
    more specifically, don’t mix the process of creating your container image with
    code generation, compilation, testing, or validation. This keeps a clear separation
    of concerns from development tasks that you may need, depending on your language
    and framework. This will allow you to include it when and where you want to in
    an automation pipeline.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It will be very tempting to add in additional tools to your base image to enable
    debugging, support new or additional diagnostic work, and so on. Make an explicit
    and conscious choice of what additional tooling you will (and won’t) include within
    the image. I advise minimal additional tools, not just because they cause the
    image to be larger, but often the same tools that are so effective at debugging
    present an option for easier exploitation from hackers:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you find you must add debugging tools into your image, consider making a
    second Dockerfile in a subdirectory that adds to the first and only includes the
    debugging tools you want to add. If you do this, I recommend you add a name `-debug` to
    the name of the image to make it clear that the image has the additional tooling
    installed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When you build your container image, build it with production usage in mind,
    and as a default. With containers, this is often represented with default values
    for environment variables that are made available in the container. In general,
    try not to include the dependencies needed for unit testing, development tasks,
    and so on in your container image:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the case of Node.js, use the environment variable `ENV=PROD`, so that `npm`
    doesn’t include development dependencies, or explicitly strip them away with a
    command line `npm install —production`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Treat the entire container you create as a read-only filesystem after you’ve
    created it. If you want to have some place to write local files, identify that
    location explicitly and set up a volume in your container for it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sending output from your program
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`kubectl logs` (as well as the Docker equivalent: `docker logs`) defaults to
    combining `stdout` and `stderr` and passing anything presented as logs for the
    container. You may have also had experience with creating specific logging capabilities
    in your code to write logs to a file location on disk. In general, writing logs
    to a filesystem location is not encouraged for software running within a container,
    as to include it in general logging means that something has to read it again,
    which unnecessarily increases disk I/O.'
  prefs: []
  type: TYPE_NORMAL
- en: If you want to have a means of supporting aggregated logging in your application,
    then you will typically want to have something external to your container and/or
    Pod defined to help capture, transport, and process those logs.
  prefs: []
  type: TYPE_NORMAL
- en: In general, if you write your programs to log to `stdout` and `stderr`, then
    containers and Kubernetes running those containers will generally help you to
    get access to those details more easily.
  prefs: []
  type: TYPE_NORMAL
- en: Logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most common method of getting information about how your code is working
    is generally through logs. Every language and development environment has its
    own pattern of how to expose those details, but at the very basics, it can be
    as simple as a print statement sending a line of text that will mean something
    to you to `stdout`. It is without a doubt the most consistent means across all
    programming languages of quick and simple debugging. When you deploy and run your
    code in Kubernetes, it maintains access to the logs from each Pod and container—where
    logs, in this case, are sending data to `stdout` and `stderr`.
  prefs: []
  type: TYPE_NORMAL
- en: If your existing pattern of development writes output to a specific file location,
    and maybe your framework includes the capability of rotating those log files as
    they grow, you may want to consider just sending data to `stdout` and/or `stderr`
    so that Kubernetes can make this coordination work.
  prefs: []
  type: TYPE_NORMAL
- en: Pods with more than one container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our examples have been simple so far, with a single container in a Pod. A Pod
    can have more than one container at a time, and the command to get the logs can
    specify which container to use. If there is only one container, you don’t need
    to specify which one to use.
  prefs: []
  type: TYPE_NORMAL
- en: If you need to specify a specific container, you can do so with either the `-c`
    option, or by adding it onto the `logs` command. For example, if you had a Pod
    named `webapp `with two containers, `flask` and `background`, and you wanted to
    see the logs from the `background` container, you could use the `kubectl logs
    webapp background` or `kubectl logs webapp -c background` commands.
  prefs: []
  type: TYPE_NORMAL
- en: 'Likewise, there''s a shortcut for defining Pods and containers within a deployment.
    Rather than specifying the full Pod name based on the names assigned through Kubernetes,
    you can prefix the name of the Pod with just the deployment name. For example,
    if we had created a deployment with the `kubectl run flask image=…` command from
    our earlier examples, we could use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This is rather than looking up the specific Pod name and then asking for the
    logs based on that name.
  prefs: []
  type: TYPE_NORMAL
- en: Streaming the logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A common desire is to see a continuously flowing set of logs from your container,
    updated as the container provides the information. You can enable this with the
    `-f` option. For example, to see the updated logs from the Pod associated with
    the `flask` deployment, you can run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As you interact with that service, or that service writes to `stdout` and does
    its normal logging, you will see the output streamed to your console.
  prefs: []
  type: TYPE_NORMAL
- en: Previous logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The logs are generally specific to an active container. However, there is a
    common need to see what might have been in the logs if a container fails, or perhaps
    if you rolled out an update and something didn't work as expected. Kubernetes
    maintains a reference to the previous container for any Pod (if it exists), so
    that you can get this information when you need it. You can do this with the `-p`
    option, as long as the logs are available to Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Timestamps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Timestamps are also available for the log output, although not by default.
    You can get the log messages prefixed by a timestamp by adding the `--timestamps`
    option. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'You then may see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: It is worthwhile to note that the timestamps are from the hosts that are running
    the containers, not your local machine, so the time zone on those logs will often
    not be the same time zone in which you reside. The timestamps all include full-time
    zone detail (typically set to the UTC-0 time zone) so the values can be converted
    easily.
  prefs: []
  type: TYPE_NORMAL
- en: More debugging techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are several debugging techniques to work with your code deployed into
    an existing cluster. These include:'
  prefs: []
  type: TYPE_NORMAL
- en: Interactive deployment of a container image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attaching to a running Pod
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running a second command within an existing Pod
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interactive deployment of an image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can also use the `kubectl run` command to start an interactive session with
    a Pod. This can be exceptionally useful to log in and see what is available in
    a container image, or within the context of the software you've copied into a
    container image.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if you wanted to run a shell to look around inside the base Alpine
    container image that I used for the Python example, you could run the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The `-i` option is what tells it to make the session interactive, and the `-t`
    option (which is almost always used with the `-i` option) indicates that it should
    allocate a TTY session (a Terminal session) for the interactive output. The trailing
    `-- sh` is an override to provide a specific command to be invoked with this session,
    in this case `sh`, asking to execute the shell.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you invoke this command, it still sets up a deployment, and when you exit
    the interactive shell, the output will tell you how can you reattach to that same
    interactive shell. The output will look something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to kill that deployment, you will need to run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This technique is immensely useful for getting a container image up and running
    within the Kubernetes cluster, and giving you shell access to interact with it.
    If you are used to using Python, Node.js, or similar dynamic languages, then the
    ability to get your libraries all loaded and a REPL active for you to interrogate
    or interact with to interactively poke at the running environment can be incredibly
    useful.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, we can do this with the same Python image that we used for our
    Flask application. To bring it up as an interactive session that you can later
    delete, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This command can take a little time to complete, as it will wait while Kubernetes
    downloads the image and starts it, using the command we put in (`/bin/sh`) instead
    of the entrypoint that we defined for it originally. In a short while, you should
    see some output in your Terminal window akin to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, you can invoke Python and interact with the Python REPL directly,
    loading code and doing whatever you need. The following are some example commands
    to show you how this might work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Once you are done interacting with this deployment, you can exit the shell by
    pressing *Ctrl* + *D* or by typing `exit`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This is leaving the deployment running, so you can reattach to it using the
    preceding command, or you can delete the deployment and recreate it again when/if
    you want it. To delete it, you would use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Attaching to a running Pod
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If your pod is up and running, and you want to run some commands from within
    the context of that container image, you can attach an interactive session to
    it. You do this via the `kubectl attach` command. A Pod must be active for this
    command to work, so if you’re trying to figure out why a Pod didn’t start properly,
    this command probably won’t help.
  prefs: []
  type: TYPE_NORMAL
- en: 'Attaching to a Pod will connect `stdin` into your process, and take anything
    from `stdout` and `stderr` and present it on the screen, so it’s more like an
    interactive version of the `kubectl logs -f` command. Whatever you specified for
    the container will need to take `stdin` in order for this to be useful. You will
    also need to explicitly enable the TTY in order to connect to it. If you do not,
    you will frequently see the following as a first line of the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'If you had created a deployment from the `nodejs` example earlier using the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You could attach to this Pod using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This will return a warning message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: And thereafter, when you interact with the service, you will see `stdout` streamed
    in the Terminal window.
  prefs: []
  type: TYPE_NORMAL
- en: This is most effective if your application prints its logs to `stdout` and you
    want to watch those logs while you interact with your code, for example by using
    a web browser. To use a web browser to interact with your running Pod, remember
    to use either the `kubectl proxy` or `kubectl port-forward` commands, typically
    from another Terminal window, to route access from your laptop to your Pod within
    the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, you will be better served by using the `kubectl logs` command
    that we described earlier with the `-f` option. The primary difference is if you
    have enabled your application to react to input from `stdin` and you ran it with
    `stdin` and a TTY defined, then you can interact with it directly by using the
    `kubectl attach` command.
  prefs: []
  type: TYPE_NORMAL
- en: Running a second process in a container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I frequently find it more useful to run an additional command in a Pod rather
    than attempting to attach to the Pod. You can do this with the `kubectl exec`
    command.
  prefs: []
  type: TYPE_NORMAL
- en: 'As of Kubernetes 1.8, `kubectl exec` doesn''t support the deployment/name shortcut
    that we have used for the logs or attach commands, so you will need to specify
    the specific Pod name you want to interact with. If you just want to open an interactive
    shell in the Pod, you could run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the name of the running pod, invoke `kubectl exec` to open an interactive
    shell within it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: You can also use this to invoke any command that’s built into your container.
    For example, if you had a script or process that collected and exported diagnostic
    data, you might invoke that. Or, you could use a command such as `killall -HUP
    python3`, which will send a `HUP` signal to all `python3` processes that are running.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes concepts – labels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the first example, you saw how creating a deployment also created a ReplicaSet
    and related pods, in order to run your software.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes has a very flexible mechanism for connecting and referencing objects
    that it manages. Rather than having a very strict hierarchy of what can be connected,
    the Kubernetes project uses short, definitive key/value pairs as set of tags on
    resources, called labels. There is a matching mechanism to query and find related
    labels, called Selectors.
  prefs: []
  type: TYPE_NORMAL
- en: Labels are fairly strictly defined in format, and are intended to group together
    resources in Kubernetes. They are not intended to identify a single or unique
    resource. They can be used to describe relevant information about a set of Kubernetes
    resources, be that a Pod, ReplicaSet, Deployment, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned earlier, labels are key-value structures. The keys in labels
    are limited in size and may include an optional prefix, followed by a / character,
    and then the rest of the key. Prefixes, if supplied, are expected to be a DNS
    domain. Internal components and plugins to Kubernetes are expected to use prefixes
    to group and segregate their labels, and the prefix `kubernetes.io` is reserved
    for Kubernetes internal labels. If a prefix is not defined, then it is considered
    entirely under user control, and you need to maintain your own rules about consistency
    of what non-prefixed labels mean.
  prefs: []
  type: TYPE_NORMAL
- en: If you do want to use a prefix, it needs to be 253 characters or less. The key
    beyond the prefix has a maximum length of 63 characters. Keys can also only be
    specified with alphanumeric characters, as well as `-`, `_`, and `.`. Unicode
    and non-alpha-numeric characters aren’t supported as labels.
  prefs: []
  type: TYPE_NORMAL
- en: 'Labels are intended to represent semantic information about a resource, and
    having multiple labels is not only acceptable, but expected. You will see labels
    used extensively in Kubernetes examples for a wide variety of purposes. Most common
    are dimensions of interest, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Version
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tier of service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They can also be used to track any grouping that you’re interested in based
    on your organization or development needs. Team, area of responsibility, or other
    semantic attributes are fairly common.
  prefs: []
  type: TYPE_NORMAL
- en: Organization of labels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Grouping your resources when you have more than "just a few" is critical to
    maintaining understanding of your system, as well as allowing you to think about
    the resources by their responsibility rather than individual names or IDs.
  prefs: []
  type: TYPE_NORMAL
- en: 'You should consider making and maintaining a living document with labels you
    use and their meaning and intentions. I prefer to do this in a `README.md` in
    the deploy directory where I keep the Kubernetes declarations, and find that whatever
    conventions you set are critical to understand, especially when you are working
    as part of a team. Even if you work alone, this is an excellent practice: what
    is obvious to you today may be completely obscure to *future you* in six months
    or even longer.'
  prefs: []
  type: TYPE_NORMAL
- en: It is also your responsibility to keep clear the meaning of your own labels.
    Kubernetes does nothing to prevent you from confusing or reusing simplistic labels.
    A resource we will talk about later in this chapter called a service specifically
    uses labels to coordinate access to Pods, so keeping clear usage of those labels
    is very important. Reusing label keys across different Pods can lead to very unexpected
    results.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes concepts – selectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Selectors are used in Kubernetes to connect resources together based on the
    labels they have (or don’t have). A selector is meant to provide a means to retrieve
    a set of resources in Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Most of the `kubectl` commands support a `-l` option that allows you to provide
    a selector to filter what it finds.
  prefs: []
  type: TYPE_NORMAL
- en: A Selector can be equality-based to represent specific values, or set-based
    to allow filtering and selection based on multiple values. Equality selectors
    use `=` or `!=`. Set selectors use `in`, `notin`, and `exists`. You can combine
    these in a selector to create more complex filters and selection criteria by appending
    the selectors together with a `,` between them.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, you might use a label `app` to represent a grouping of Pods that
    provide service to a specific application - in this case using the value `flask`
    and `tier` to represent the values of `front-end`, `cache`, and `back-end` tiers.
    A selector that would return all resources related to the app might be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'And the selector that just returned the frontend resources supporting this
    application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'If you wanted to list all the Pods that matched the select `app=flask`, you
    could do so with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Viewing labels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The deployments we made earlier through the `kubectl run` commands put in place
    labels and used them as selectors. As you saw earlier, you can get all the underlying
    detail for a Kubernetes resource using the `kubectl get -o json` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'A similar command is `kubectl describe`, which is intended to provide a human-readable
    overview of a resource and its recent history:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This will provide output akin to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'You''ll notice two labels in there, `run` and `pod-template-hash`, and a selector
    as well, `app=flask`. You can query for these exact labels using the `kubectl
    get` command line, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'This will return the deployments matching that selector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: And the equivalent for pods, requesting by selector
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'This will return pods is matching the `app=flask` selector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Within this deployment, the Pod is referenced from the deployment using the
    selector `app=flask`.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**: You can use selectors along with `kubectl get` to request multiple
    kinds of resources at once. For example, if you tagged all the relevant resources
    with `app=flask`, then you could use a command such as `kubectl get deployment,pod
    -l app=flask` to see both deployments and pods.'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, there are some common label structures that are used implicitly
    when you create and run resources interactively. `kubectl run`, which creates
    deployments, uses the keys `run`, `pod-template-hash`, and `app` for specific
    meanings.
  prefs: []
  type: TYPE_NORMAL
- en: 'Labels can also be applied interactively to resources, after they already exist,
    using the `kubectl label` command. For example, to apply a label for enabled to
    a Pod, you might use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: This lets you interactively group resources together, or provide a consistent
    means of rolling out, updating, or even removing sets of resources.
  prefs: []
  type: TYPE_NORMAL
- en: Listing resources with labels using kubectl
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `kubectl get` commands will show you basic information by default, typically
    the name and status of the resources you're looking for. You can extend the columns
    that it displays to include specific labels, which can often make it much easier
    to find what you are looking for when dealing with large numbers of different
    Pods, deployments, and ReplicaSets. `kubectl` takes an `-L` option with a comma-separated
    list of label keys to show as headers.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you wanted to show the Pods along with the label keys `run` and `pod-template-hash`,
    the command would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'You then may see output like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Automatic labels and selectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes includes a number of imperative commands that automatically create
    a number of resources for you. As these commands create the resources, they also
    apply their own conventions for labels and use those labels to tie the resources
    together. A perfect example of this is the command we have used several times
    now: `kubectl run`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, when we used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: This created a deployment called `flask`. When the controller for the deployment
    was created, that in turn caused the creation of a ReplicaSet for that deployment,
    and the ReplicaSet controller in turn created a Pod. We saw earlier that the names
    of these resources were all related, and there are labels that relate them as
    well.
  prefs: []
  type: TYPE_NORMAL
- en: The deployment, `flask`, is created with the label `run=flask`, using the name
    of the `kubectl` command as the key, and the name we provided on the command line
    as a value. The deployment also has the selector `run=flask`, so that it can apply
    its controller rules to the relevant ReplicaSets and Pods that are created for
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the ReplicaSet that was created, you will see the `run=flask` label
    as well as a label that corresponds to the name that was created for the ReplicaSet
    with the key `pod-template-hash`. This ReplicaSet also includes the same selectors
    to reference the Pods that are created for it.
  prefs: []
  type: TYPE_NORMAL
- en: And finally, the Pod has these same selectors, which is how the ReplicaSet and
    deployment know which resources within Kubernetes to interact with when needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a table summarizing the labels and selectors that were automatically
    created with the preceding example:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Deployment | ReplicaSet | Pod |'
  prefs: []
  type: TYPE_TB
- en: '| Name | `flask` | `flask-1908233635` | `flask-1908233635-d6stj` |'
  prefs: []
  type: TYPE_TB
- en: '| Labels | `run=flask` | `pod-template-hash=1908233635` `run=flask` | `pod-template-hash=1908233635`
    `run=flask` |'
  prefs: []
  type: TYPE_TB
- en: '| Selectors | `run=flask` | `pod-template-hash=1908233635,run=flask` |  |'
  prefs: []
  type: TYPE_TB
- en: Kubernetes resources – service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, all the details we have explored have been related to a single container
    running within Kubernetes. The significant benefits of leveraging Kubernetes start
    to come into play when leveraging many containers running together. Being able
    to group together a set of Pods that all do the same thing, so that we can scale
    them and access them, is what the Kubernetes resource Service is all about.
  prefs: []
  type: TYPE_NORMAL
- en: A Service is the Kubernetes resource used to provide an abstraction through
    to your Pod (or Pods) that is agnostic of the specific instances that are running.
    Providing a layer between what one container (or set of containers) provides,
    such as a frontend web application, and another layer, such as a database, allows
    Kubernetes to scale them independently, update them, handle scaling issues, and
    more. A service also can contain a policy by which data should be transferred,
    so you might consider it a software load balancer within Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: A Service is also the key abstraction used to expose Pods to each other, or
    your container outside the Kubernetes cluster. A service is the heart of how Kubernetes
    manages the coordination between sets of Pods, as well as traffic in and out of
    them.
  prefs: []
  type: TYPE_NORMAL
- en: An advanced use of Service also allows you to define a service for a resource
    entirely outside the cluster. This can allow you to have a consistent means of
    using services, regardless of whether the endpoint you need to run is from within
    Kubernetes or external to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes includes an expose command that can create a service based on a
    resource that is already operating within the cluster. For example, we could expose
    the `flask` deployment example we used earlier with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Most services will define a ClusterIP, and Kubernetes will handle all the dynamics
    of linking up the resources as Pods are created and destroyed that match to the
    relevant selectors. You can think of this like a simple load-balancer construct
    within Kubernetes, and it will forward traffic internally as Pods are available,
    and stop sending traffic to Pods that are failed or unavailable.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you request the details of the service we just created with the `expose`
    command, you will see the ClusterIP listed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Defining a service resource
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Service specification is fairly simple, documented for version 1.8 at [https://kubernetes.io/docs/api-reference/v1.8/#service-v1-core](https://kubernetes.io/docs/api-reference/v1.8/#service-v1-core).
    All resources within Kubernetes can be defined declaratively, which we will look
    at in more depth in [Chapter 4](a210420d-4d80-43c1-9acb-531bc6b19b75.xhtml), *Declarative
    Infrastructure*. Resources can also be defined using YAML as well as JSON. To
    look at the details of what can be included with a Service resource, we will look
    at the YAML specification for it. The core of the specification includes a name,
    a selector for the Pods that provide the service, and ports associated with the
    services.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, a simple service declaration for our `flask` Pod might be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'This defines a service that selects the Pods to front using the selector `run:
    flask`, accepting any requests on TCP port `80` and forwarding them to port `5000`
    on the selected Pods. Services support both TCP and UDP. The default is TCP, so
    we didn’t strictly need to include it. Additionally, targetPort can be a string
    referring to the name of a port and not just a port number, allowing significantly
    greater flexibility between services and the ability to move around the specific
    backend ports as development teams desire without needing as much careful coordination
    to keep the overall system operational.'
  prefs: []
  type: TYPE_NORMAL
- en: A service can define (and redirect) multiple ports—for example, if you wanted
    to support both port `80` and `443` for access, you can define that on the service.
  prefs: []
  type: TYPE_NORMAL
- en: Endpoints
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A service does not require a selector, and a service without a selector is how
    Kubernetes represents a service that's outside of the cluster for the other resources
    within. To enable this, you create a service without a selector as well as a new
    resource, an Endpoint, which defines the network location of the remote service.
  prefs: []
  type: TYPE_NORMAL
- en: If you are migrating services into Kubernetes and have some of those services
    external to the cluster, this provides one way to represent the remote system
    as a service internally, and if you move it into Kubernetes later, you wouldn't
    have to change how internal Pods connect or utilize that resource. This is an
    advanced feature of services, and does not also account for authorization. Another
    option is to not represent external services as service resources, and simply
    reference them in Secrets, a feature we will look at in more depth in the next
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if you had a remote TCP service running on the internet at port
    `1976` at the IP address `1.2.3.4`, you could define a Service and Endpoint to
    reference that `external-to-kubernetes` system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'This would work with the following `Endpoints` definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Service type – ExternalName
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is a variant to the preceding Endpoint definition that simply provides
    a DNS reference, called an `ExternalName` service. Like the `Endpoint` oriented
    service, it doesn’t include a selector, but also does not include any port references.
    Instead, it simply defines an external DNS entry that can be used as a service
    definition.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example provides a Service interface inside Kubernetes to the
    external DNS entry `my.rest.api.example.com`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Unlike the other services, which provide TCP and UDP (Layer 4 on the ISO network
    stack) forwarding, the `ExternalName` only provides a DNS response and does not
    manage any port forwarding or redirection.
  prefs: []
  type: TYPE_NORMAL
- en: Headless service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is possible to create a service grouping that does not allocate an IP address
    or forward traffic, if there is a reason that you want to definitively control
    what specific pods you connect and communicate with. This kind of service is called
    a headless service. You can request this setup by explicitly setting ClusterIP
    to `None` within the service definition:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, a headless service might be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: For these services, DNS entries will be created that point to the Pods backing
    the service, and that DNS will be automatically updated as Pods matching the selector
    come online (or disappear).
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**: Be aware that DNS caching could end up getting in the way if using
    a headless service. You should always check DNS records before making connections.'
  prefs: []
  type: TYPE_NORMAL
- en: Discovering services from within your Pod
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are two means by which services are visible from within your Pods. The
    first is through environment variables that are added to all Pods in the same
    namespace as the service.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you add a service (using `kubectl create`, or `kubectl apply`), the service
    is registered within Kubernetes and thereafter any Pods that are started will
    get environment variables set that reference the services. For example, if we
    created the preceding first example service, and then ran:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'We would see the service listed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'If you looked inside that container, you would see environment variables associated
    with both services listed previously. Those environment variables are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: (The preceding output has been re-ordered to make it easier to see the values
    and some extraneous environment variables have been removed.)
  prefs: []
  type: TYPE_NORMAL
- en: For each service, there are environment variables defined that provide the IP
    address, port, and protocol with a couple of name variations. Note that this IP
    address is not the IP address of any underlying Pods, but an IP address within
    the Kubernetes cluster that the service is managing as a single endpoint for accessing
    the selected Pods.
  prefs: []
  type: TYPE_NORMAL
- en: '**WARNING**: Ordering is critical with services! If Pods exist prior to the
    Service being defined, then the environment variables for that service will not
    exist within those Pods. Restarting the Pods, or scaling them down to `0` and
    back up (forcing the containers to be killed and recreated) will resolve it, but
    in general it’s best to always define and apply your service declarations first.'
  prefs: []
  type: TYPE_NORMAL
- en: DNS for services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Not originally part of the core distribution, there is a cluster add-on that
    is now included for all clusters in version 1.3 (and later) that provides internal
    DNS services for Kubernetes. Minikube, for example, includes this add-on, and
    it is likely already running within your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: A DNS entry is created and coordinates with every service defined, so that you
    can request the DNS entry for `<service>` or  `<service>.<namespace>`, and the
    internal DNS services will provide you with a correct internal IP address.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if we exposed the `flask` deployment with the `expose` command,
    the service would be listed in DNS from our containers. We could open an interactive
    Terminal to an existing Pod and check on that DNS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The service gets an internal A record (address record in DNS) for every service
    at `<servicename>.<namespace>.svc.cluster.local`, and as a shortcut, they can
    generally be referenced within the Pods as `<servicename>.<namespace>.svc`, or
    more simply `<servicename>` for Pods that are all within the same namespace.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**: Tacking on a namespace should only be done when you are explicitly
    trying to refer to a service in another namespace. Leaving the namespace off makes
    your manifest inherently more reusable, since you can stamp out an entire stack
    of services with static routing configuration into arbitrary namespaces.'
  prefs: []
  type: TYPE_NORMAL
- en: Exposing services outside the cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Everything we have discussed so far has been about representing services inside
    the Kubernetes cluster. The service concept is also how applications are exposed
    outside of a cluster.
  prefs: []
  type: TYPE_NORMAL
- en: The default service type is ClusterIP, and we briefly touched upon the type
    `ExternalName`, which was added to Kubernetes 1.7 to provide an external DNS reference.
    There are two other types that are very common, `NodePort` and `LoadBalancer`,
    which are specifically oriented towards exposing a service outside of the Kubernetes
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Service type – LoadBalancer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `LoadBalancer` service type is not supported in all Kubernetes clusters.
    It is most commonly used with cloud providers such as Amazon, Google, or Microsoft,
    and coordinates with the cloud provider's infrastructure to set up an external
    `LoadBalancer` that will forward traffic into the service.
  prefs: []
  type: TYPE_NORMAL
- en: How you define these services is specific to your cloud provider, and slightly
    different between AWS, Azure, and Google. `LoadBalancer` service definitions may
    also include recommended annotations to help define how to handle and process
    SSL traffic. More details about the specifics for each provider can be found in
    the Kubernetes documentation. The documentation on the LoadBalancer definitions
    is available at [https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer](https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer).
  prefs: []
  type: TYPE_NORMAL
- en: Service type – NodePort
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you are using a Kubernetes cluster on premises, or in our case in a virtual
    machine on your development machine with Minikube, NodePort is a common service
    type used to expose your services. NodePort relies on the underlying hosts upon
    which you run Kubernetes to be accessible on your local network, and exposes the
    service definition through a high-numbered port on all of the Kubernetes cluster
    nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'These services are exactly like the default ClusterIP services, with the exception
    that they have a type of `NodePort`. If we wanted to create such a service with
    the `expose` command, we could add a `--type=Nodeport` option to our earlier command,
    for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in a definition that would look something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice `nodePort: 31501`. This is the port that the service is exposed on.
    With this enabled, where previously we had to use port-forward or a proxy to access
    our service, we can now do so directly through the service.'
  prefs: []
  type: TYPE_NORMAL
- en: Minikube service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Minikube has a service command to make it very easy to both get and access
    this service. While you could get the IP address for your `minikube` host with
    `minikube ip` and put that together with the previous port, you could also use
    the `minikube service` command to make a combined URL in one command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'This should return a value like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'And `minikube` has the helpful option of opening a browser window with your
    default if you use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: If you had a service enabled, but no Pods are backing that service, then you
    would see a connection refused message.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can list all the services exposed from your instance of `minikube` with
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'You would then see output like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Example service – Redis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will create an example service within Kubernetes, to show you how you can
    connect to services, and use them to architect your code. Redis ([https://redis.io](https://redis.io))
    is a super-flexible data store that you may already be familiar with, and it is
    easy to use from both Python and Node.js.
  prefs: []
  type: TYPE_NORMAL
- en: 'Redis is already available as a container, and it is easily found on the Docker
    Hub ([https://hub.docker.com/](https://hub.docker.com/)) as a container image.
    There are several options available, with the relevant tags listed on the Docker
    Hub web page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/d602d47e-f217-49d7-adeb-cd47a22afea8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can use this image with the `kubectl run` command to create a deployment,
    and then with the `kubectl expose` command to create a service to map to the Pods
    within the deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'We will create a deployment named `redis`, and through that deployment download
    the image and start running it. We can see the Pod operational:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'You can run an interactive shell within this Pod using the `kubectl exec` command
    and interrogate the running instance of `redis` directly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'We can expose this service both inside our cluster instance and outside of
    `minikube` using `NodePort`. The default port for `redis` is `6379`, so we will
    want to make sure to include that in our service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'If we then list the services available:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'We will see `redis` exposed on port `30336` using `NodePort`. The `minikube
    service` command won’t be immediately helpful here because redis isn’t an HTTP-based
    API, but using `minikube ip` we can put together a command to interact with `redis`
    through its command-line interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'To interact with `redis`, we can use the `redis-cli` command-line tool. If
    you don''t have the tool, you can follow along with this example by downloading
    it from [https://redis.io/download](https://redis.io/download):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: Finding the Redis service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'WIth the Redis service up and running, we can now use it from our own Pod.
    As we mentioned previously, there are two ways to locate the service: an environment
    variable with a name based on the service will be set with the host IP and port,
    or you can use a DNS entry based on the name of the service.'
  prefs: []
  type: TYPE_NORMAL
- en: The environment variables will only be set on Pods that are created after the
    service. If you still have the `flask` Pod up and running as per our previous
    example, then it will not show the environment variables. If we create a new Pod,
    even a temporary one, then it will include the service in the environment variables.
    This is because environment variables are set based on the state of Kubernetes
    at the time that the Pods are created and they are not updated during the life
    of the Pod.
  prefs: []
  type: TYPE_NORMAL
- en: DNS, however, is updated dynamically with the state of the cluster. While not
    instantaneous, this means that a DNS request will start returning as expected
    after the service is created. And because the DNS entries are predictable based
    on namespace and service name, they can easily be included in configuration data.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE:** Use DNS for service discovery, not environment variables, because
    DNS updates with your environment, but environment variables do not.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you still have a Flask or Node.js Pod running, get the Pod name and open
    a shell within it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'And then, we can look up the Redis service we just created in the default namespace,
    which should be listed as `redis.default`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: Using Redis from Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once we can access our Python Pod, we can invoke Python interactively and access
    Redis. Recall that when we created this Pod, we didn’t include any Python libraries
    for Redis. For this example, we can install them on the fly, but that change will
    only be relevant for this single Pod, and for the duration of this Pod’s life
    cycle. If the Pod dies, any changes (such as adding the Redis library) will be
    lost.
  prefs: []
  type: TYPE_NORMAL
- en: This makes a great tool for interactively and dynamically trying things out,
    but remember that you will need to incorporate any desired changes back into the
    process of creating the container as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Within the `flask` Pod, go to the code directory we set up and we can add the
    Redis library using PIP:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can interactively try Redis from the Python interpreter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: To match this and enable this library for our Python code, we will want to add
    it to the `requirements.txt` file that is used by the Docker build process to
    install all the dependencies. We would then want to rebuild the container and
    push it to the registry, and then recreate the Pods so that the new image was
    used.
  prefs: []
  type: TYPE_NORMAL
- en: Updating the Flask deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The steps to this update process are:'
  prefs: []
  type: TYPE_NORMAL
- en: Update the code or dependencies in source control
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build and tag a new Docker image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Push the Docker image to the container repository
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Update the deployment resource in Kubernetes to use this new image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An example of stepping through this will highlight how you can start to roll
    out code updates, either directly or by adding additional services, to your application.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this example, we will not change any code immediately, we just want to
    include the Redis Python library so that it''s available. To do this, we would
    normally use PIP to install the library we want. With our Python example, we are
    installing all the required libraries with PIP through the dependency listing
    `requirements.txt`, which gets invoked during the Docker build process:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Update the `requirements.txt` file to include Redis:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: Not specifying a specific version is an indicator to PIP that you want it to
    locate the most recent version and install it. If you know the version of the
    `redis` library already, or want to pin it explicitly, you can add it, such as
    `==2.10.6` (akin to what was added with Flask previously).
  prefs: []
  type: TYPE_NORMAL
- en: 'Rebuild the `docker` image:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, I am explicitly rebuilding without a tag, intending to add
    that one in a second step:'
  prefs: []
  type: TYPE_NORMAL
- en: Tag the `build`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To tag a `build`, use a command like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'The command I used for this example was:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: Once the build has the tag you'd like associated with it (in this case, we used
    `0.1.1`), you could tag this with more than one value if you wanted to reference
    the image in different ways. Once it is tagged, you need to make the images available
    to your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Push the container image:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: Container tags do not need to be in a dot version format. In this case, I chose
    a tag that was simple and contextual, but also explicit rather than reusing `latest`,
    which could lead to some confusion over which `latest` we were running.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**: Use tags that are meaningful, and avoid using `latest` as a tag when
    running Kubernetes. You will save yourself an immense amount of time debugging
    exactly which version is running if you use explicit tags at the start. Even something
    as simple as a Git hash or very explicit timestamp can be used as a tag.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can update the deployment to indicate that we want Kubernetes to use
    this new image we have created. Kubernetes supports several commands that will
    do what we want, such as `kubectl replace`, which will take a changed specification
    in YAML or JSON format, where you could change any of the values. There is an
    older command, `kubectl rolling-update`, but that only works with replication
    controllers.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**: Replication controllers were an early version of ReplicaSet, and
    have been replaced by ReplicaSets and Deployments.'
  prefs: []
  type: TYPE_NORMAL
- en: The `kubectl rolling-update` command has been replaced by a combination of `kubectl
    set` and `kubectl rollout`, which applies to deployments as well as some additional
    resources. The `kubectl set` command helps with frequent updates to some of the
    more common changes, such as changing an image in a deployment, environment variables
    defined within a deployment, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: The `kubectl apply` command is similar to `kubectl replace`, taking a file (or
    set of files) and dynamically applying differences to all the kubernetes resources
    referenced. We will look deeper into using the `kubectl apply` command in the
    next chapter, where we will also look into maintaining the definitions of your
    application and its structure alongside your code as declarative files, rather
    than relying on the ordering and invocation of interactive commands.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, there are a lot of options to choose from; all of which boil
    down to changing the resources that are defined within Kubernetes to let it perform
    some action.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take the most general option and use the `kubectl replace` command, stepping
    through the process to make it clear exactly what we are changing.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, get the deployment we are changing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, open the `flask_deployment.yaml` file in a text editor and find the line
    that specifies the image. The current image version can be found in the file under
    `template -> spec -> containers`, and should read something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Edit the file and change this to reference our updated tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'And now, we can use the `kubectl replace` command to tell Kubernetes to update
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: This change will initiate an update of the resources associated with the deployment,
    in this case doing a rolling update or rollout. The deployment controller will
    automatically create a new ReplicaSet and Pod for the deployment, and terminate
    the old one once it is available. This process will also maintain the scale, or
    number of replicas running, during this process, and can take some time.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**: You should also be aware of the command `kubectl edit`, which allows
    you to specify a resource, such as a deployment/flask, and edit the YAML declaration
    for it directly. When you save the editor window that was opened with `kubectl
    edit`, it does the actions as the `kubectl replace` command previously.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use `kubectl get pods` to get a view of this happening:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'Since there is only a single Pod with a single container, it will not take
    long to complete, and when it is done you will see something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'You may notice that the replica-set hash has changed, as well as the Pod’s
    unique identifier. If we now access this Pod with an interactive session, we can
    see that the library has been loaded. This time, we will use Python’s interactive
    REPL directly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: Deployments and rollouts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Changing the image within a deployment initiates a rollout. A deployment rollout
    is an asynchronous process that takes time to complete, and is controlled by values
    defined within the deployment. If you look at the resource file that we dumped
    into YAML and updated, you will see the defaults that were created for the deployment
    when we made it with the `kubectl run` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'Under `spec -> strategy`, you will see the default specification of how it
    will handle an update:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'As of Kubernetes 1.8, there are two strategies available: `Recreate` and `RollingUpdate`.
    `RollingUpdate` is the default, and is intended for the primary use case of maintaining
    service availability while doing code updates. Recreate operates differently:
    killing all existing pods before creating new pods with updated versions, which
    may result in a short outage.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `RollingUpdate` is controlled by two values: `maxUnavailable` and `maxSurge`,
    which serve to provide some controls so that you can have a minimum number of
    pods available to handle your service while the update rolls out. You can find
    details on these two controlling options in the documentation at [https://kubernetes.io/docs/concepts/workloads/controllers/deployment/](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/),
    along with some additional options that influence the rollout process.'
  prefs: []
  type: TYPE_NORMAL
- en: Rollout history
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes also maintains a history (the length of which can also be controlled)
    for rollouts. You can see the state of a rollout, as well as its history, through
    the `kubectl rollout` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, to see the status of the rollout that we just did:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'And you can view the history of the changes to the deployment with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: '`change-cause` is tracked as an annotation on the deployment resource, which
    (as of Kubernetes 1.8) does not exist, since we created the deployment with the
    default `kubectl run` command. There is a `--record=true` option, which can be
    used with `kubectl run`, `kubectl set`, and several other commands that explicitly
    set these annotations. We will discuss annotations, more detail in the next chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can go ahead and create an annotation to match what we just did with the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, if we look at the history, you will see the following displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'You can get more detailed information using the `--revision` option with the
    `history` command. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'This would return something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: You can see the annotation that we just created as well as the container image
    version that we changed.
  prefs: []
  type: TYPE_NORMAL
- en: Rollout undo
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The deployment resource includes the capability to revert back to a previous
    version. The simplest form of this is the `kubectl rollout undo` command. If you
    wanted to revert back to the Pods running at the previous image, you could use
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: This would reverse the process, doing the same steps except moving back to the
    earlier deployment resource configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have multiple versions, you can roll back to a specific version with
    the `--revision` option. You can also watch the process updates with the `rollout
    status` command and the `-w` option. For example, if you just invoked the `undo`
    command, you could watch the progress with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'The deployment history keeps rolling version numbers forward, even when you
    undo or roll back to a previous version. If you are familiar with using Git for
    source control, it is very similar to using the `git revert` command. If you looked
    at the history after an undo, you might see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: Updating with the kubectl set command
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Updating the container image is a very common task. You may also update that
    value directly with the `kubectl set` command, as we mentioned previously. If
    the deployment resource has the `change-cause` annotation added, then using the
    `kubectl set` command will update the annotation as you make changes. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: 'If you now look at the history, it will include the changes made with the `set`
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: As you create services and deployments with your code, you may find it convenient
    to quickly create deployments and update them with these commands.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**: Another reason to avoid using the `latest` tag when referencing container
    images: updates to deployments require a change to the deployment specification.
    If you were just updating the image behind the deployment, the deployment would
    never know when to update it.'
  prefs: []
  type: TYPE_NORMAL
- en: The rollouts that we have been describing so far are all idempotent and expect
    that you can change the containers seamlessly forward or back. This expects that
    the container images you are creating and deploying are stateless and don’t have
    to manage existing persistent data. That will not always be the case, and Kubernetes
    is actively adding support for handling these more complex needs with a feature
    called StatefulSets, which we will discuss further in a future chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we started with reviewing some practical notes about how to
    develop your code to run within a container. We reviewed options for getting logging
    from your program, and then some techniques for accessing the Pods when your code
    is running. We then reviewed the Kubernetes concepts of labels and selectors,
    showing how they are used on the commands we have used so far, and then looked
    at the Kubernetes service concept to expose sets of Pods (such as in a deployment)
    to each other, or external to a Kubernetes cluster. Finally, we ended the chapter
    by looking at deployment rollouts, and how you can roll out changes as well as
    see the history of those changes.
  prefs: []
  type: TYPE_NORMAL
