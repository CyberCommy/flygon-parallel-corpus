- en: Shaders and 2D Lighting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have already touched on shaders in [Chapter 3](dd4517c5-291a-49f5-9c7d-4070bb1fd062.xhtml),
    *Introduction to WebGL*. SDL, unfortunately, doesn't allow the user to customize
    its shaders without digging into the source code of the library and modifying
    them there. Those kinds of modifications are beyond the
  prefs: []
  type: TYPE_NORMAL
- en: scope of this book. It is not uncommon to use SDL in combination with OpenGL.
    SDL can be used to render the user interface for the game while OpenGL renders
    the game objects. This chapter will deviate from many of the earlier chapters
    in that we will not be mixing SDL and OpenGL directly in the game we have been
    writing. Updating the game to support an OpenGL 2D rendering engine would require
    a complete redesign of the game up to this point. However, I would like to provide
    a chapter for those interested in creating a more advanced 2D rendering engine
    to get their feet wet with combining OpenGL and SDL and writing shaders for that
    engine.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will need to include several images in your build to make this project
    work. Make sure that you include the `/Chapter15/sprites/` folder from this project''s
    GitHub repository. If you haven''t downloaded the GitHub project yet, you can
    get it online here: [https://github.com/PacktPublishing/Hands-On-Game-Development-with-WebAssembly](https://github.com/PacktPublishing/Hands-On-Game-Development-with-WebAssembly).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Recreate the app we made in [Chapter 3](https://cdp.packtpub.com/hands_on_game_development_with_webassembly/wp-admin/post.php?post=38&action=edit#post_26),
    *Introduction to WebGL*, using a combination of SDL and OpenGL for WebAssembly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn how to create a new shader that loads and renders multiple textures to
    a quad
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn about normal maps and how they can be used to create the illusion of depth
    on a 2D game object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn how to approximate the Phong lighting model in 2D using normal maps in
    OpenGL and WebAssembly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using OpenGL with WebAssembly
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Emscripten is capable of compiling C/C++ code that uses either OpenGL ES 2.0
    or OpenGL ES 3.0 by mapping those calls to WebGL or WebGL 2 calls, respectively.
    Because of this, Emscripten only supports a subset of the OpenGL ES commands that
    correspond to the commands available inside of the WebGL library you use. For
    instance, if you would like to use OpenGL ES 3.0, you will need to include WebGL
    2 when compiling by passing the `-s USE_WEBGL2=1` parameter to the Emscripten
    compiler. In this chapter, we will be using OpenGL ES 2.0 in combination with
    SDL to render sprites using shaders, and later we will be using SDL to render
    an icon that represents the location of a light source in our application. SDL
    provides many features that are absent from OpenGL, such as an audio library,
    an image loading library, and mouse and keyboard input libraries. In many ways,
    SDL is better suited to rendering the game's user interface as it renders objects
    to screen coordinates instead of to the OpenGL clip space. Behind the scenes,
    the WebAssembly version of SDL is also using the Emscripten OpenGL ES implementation,
    which relies on WebGL. So, having a better understanding of WebAssembly's OpenGL
    implementation can help us to take our game development skills to the next level,
    even if we will not be using those skills in the game we have developed for this
    book.
  prefs: []
  type: TYPE_NORMAL
- en: More about shaders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We briefly introduced the concept of shaders back in [Chapter 2](0c9c09be-1e03-4074-9718-7bc3bf9e70e2.xhtml),
    *HTML5 and WebAssembly*. Shaders are a critical part of modern 3D graphics rendering.
    Back in the early days of computer and video games, graphics were all 2D, and
    how fast graphics could render was a function of how fast the system could move
    pixels from one data buffer to another. This process is called *blitting*. One
    significant advance in these early days came when Nintendo added a **Picture Processing
    Unit** (**PPU**) to their Nintendo Entertainment System. This was an early piece
    of hardware that was designed to speed up graphics processing by moving pixels
    without using the game system's CPU. The Commodore Amiga was also a pioneer in
    these early 2D graphics coprocessors, and by the mid-1990s, hardware for blitting
    became a standard in the computer industry. In 1996, games such as Quake began
    to create a demand for consumer 3D graphics processing, and early graphics cards
    began to provide GPUs that had fixed function pipelines. This allowed applications
    to load geometry data and execute non-programmable texturing and lighting functions
    on that geometry. In the early 2000s, Nvidia introduced the GeForce 3\. This was
    the first GPU that supported a programmable pipeline. Eventually, these programmable
    pipeline GPUs began to standardize around a *unified shader model*, which allows
    programmers to write in a shading language such as GLSL for all graphics cards
    that support that language.
  prefs: []
  type: TYPE_NORMAL
- en: GLSL ES 1.0 and 3.0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The language we will be using to write our shaders is a subset of the GLSL shader
    language called GLSL ES. This shader language happens to work with WebGL and so
    is supported by the version of OpenGL ES that has been ported to WebAssembly.
    The code we are writing will run on both GLSL ES 1.0 and 3.0, which are the two
    versions of GLSL ES supported by WebAssembly.
  prefs: []
  type: TYPE_NORMAL
- en: If you are wondering why there is no support for GLSL ES 2.0, it's because it
    doesn't exist. OpenGL ES 1.0 used a fixed function pipeline and so it had no shader
    language associated with it. When the Khronos Group created OpenGL ES 2.0, they
    created GLSL ES 1.0 as the shader language to go with it. When they released OpenGL
    ES 3.0, they decided that they wanted the version number of the shader language
    to be the same number as the API. Therefore, all the new versions of OpenGL ES
    will come with a version of GLSL that bears the same version number.
  prefs: []
  type: TYPE_NORMAL
- en: 'GLSL is a language that is very similar to C. Each shader has a `main` function
    that is its entry point. GLSL ES 2.0 only supports two shader types: *vertex shaders*
    and *fragment shaders*. The execution of these shaders is highly parallel. If
    you are used to thinking along singleâ€”threaded lines, you will need to reorder
    your brain. Shaders are frequently processing thousands of vertices and pixels
    at the same time.'
  prefs: []
  type: TYPE_NORMAL
- en: I briefly discussed the definition of a vertex and a fragment in [Chapter 3](dd4517c5-291a-49f5-9c7d-4070bb1fd062.xhtml),
    *Introduction to WebGL*. A vertex is a point in space, and a collection of vertices
    define the geometry that our graphics card uses to render to the screen. A fragment
    is a pixel candidate. Multiple fragments usually go into determining the pixel
    output.
  prefs: []
  type: TYPE_NORMAL
- en: Each vertex of the geometry that's passed to a vertex shader is processed by
    that shader. Values are then passed using a *varying variable* to a large number
    of threads that are processing individual pixels through a fragment shader. The
    fragment shader receives a value that is interpolated between the output of more
    than one of the vertex shaders. A fragment shader's output is a *fragment*, which
    is a pixel candidate. Not all fragments become pixels. Some fragments are dropped,
    which means they won't render at all. Other fragments are blended to form a completely
    different pixel color. We created one vertex and one fragment shader in [Chapter
    3](dd4517c5-291a-49f5-9c7d-4070bb1fd062.xhtml), *Introduction to WebGL*, for our
    WebGL application. Let's walk through converting that application into an OpenGL/WebAssembly
    app. Once we have a working application, we can further discuss shaders and new
    ways we can write those shaders to improve our 2D WebAssembly game.
  prefs: []
  type: TYPE_NORMAL
- en: WebGL app redux
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will now walk through what it takes to rewrite the WebGL app we made in
    [Chapter 3](dd4517c5-291a-49f5-9c7d-4070bb1fd062.xhtml), *Introduction to WebGL*,
    using SDL and OpenGL. If you don''t remember, this was a very simple app that
    drew a spaceship to our canvas and moved it 2 pixels to the left and one pixel
    up every frame. The reason we made this app was that it was about the simplest
    thing I could think to do in WebGL that was more interesting than drawing a triangle.
    For this same reason, it will be the first thing we will do with OpenGL for WebAssembly.
    Go ahead and create a new file called `webgl-redux.c` and open it up. Now, let''s
    go ahead and start adding some code. The first chunk of code we need is our `#include`
    commands to pull in all of the libraries we will need for this app:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The first line includes the standard SDL2 library. The second library, `SDL_image.h`,
    is the library we are using to load our image files. The third line in this file
    that includes `SDL_opengl.h`, and is the library that will allow us to mix our
    SDL and OpenGL calls. Including `GLES2/gl2.h` gives us access to all of the OpenGL
    commands that we can use with OpenGL ES 2.0\. As always, we include `stdlib.h`
    to let us use the `printf` command, and `emscripten.h` provides us with the functions
    we need for compiling to target WebAssembly using the Emscripten compiler.
  prefs: []
  type: TYPE_NORMAL
- en: 'After our `#include` commands, we have a series of `#define` macros that define
    the constants we need for our game:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The first two define our canvas width and canvas height. The remaining `#define`
    calls are used to set up values we will be using when we define our vertex buffers.
    After these `#define` macros, we define the code for our shaders.
  prefs: []
  type: TYPE_NORMAL
- en: Shader code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following few blocks of code I am about to show you will define the shaders
    we need to create our 2D lighting effect. Here is the vertex shader code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This is the same shader code that we used when we created the WebGL version
    of this app. It looks a little different in C because JavaScript can use a multiline
    string that makes reading the code a little more clear. Like in the WebGL version,
    we use the precision call to set the floating-point precision to medium. We set
    up attributes to receive the position and UV texture coordinate data as vectors.
    We will pass in these vectors using a vertex buffer object. We define a uniform
    translate variable that will be the same value used for all vertices, which in
    general is not the way we would do this for a game, but will work just fine for
    this app. Finally, we define a varying `v_texcoord` variable. This variable will
    represent the texture coordinate value we pass from the vertex shader into the
    fragment shader. The `main()` function in this vertex shader is very simple. It
    adds the `u_translate` uniform variable translation value that's passed into the
    vertex shader to the attribute position of the vertex passed in via `a_position`,
    to get the final vertex position we set using the `gl_Position` variable. After
    that, we pass the texture coordinate of the vertex to the fragment shader by setting
    the `v_texcoord` varying variable to `a_texcoord`.
  prefs: []
  type: TYPE_NORMAL
- en: After defining our vertex shader, we create the string that defines our fragment
    shader. The fragment shader receives an interpolated version of `v_texcoord`,
    which is the varying variable that's passed out of our vertex shader. You will
    need to put on your parallel processing hat for a moment to understand how this
    works. When the GPU is processing our vertex shader and fragment shader, it is
    not doing this one at a time, but is likely processing thousands of vertices and
    fragments at once. The fragment shader is also not receiving the output from a
    single one of these threads, but a value that is mixed from more than one of the
    vertices that are currently being processed.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if your vertex shader has a varying variable as output called X,
    and your fragment is halfway between a vertex where X is 0 and a vertex where
    X is 10, then the value in the varying variable coming into your fragment will
    be 5\. This is because 5 is halfway between the two vertex values of 0 and 10\.
    Likewise, if the fragment is 30% of the way between your two points, the value
    in X will be 3.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the definition of our fragment shader code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As with our vertex shader, we start out by setting the precision. After that,
    we have a varying variable, which is an interpolated value for our texture coordinate.
    This value is stored in `v_texcoord` and will be used to map our texture to a
    pixel color. The last variable is a uniform variable of type `sampler2D`. This
    is a block of memory where we have loaded our texture. The only thing that the
    main function of this fragment shader does is use the built-in `texture2D` function
    to grab a pixel color out of our texture using the texture coordinates we passed
    into the fragment shader.
  prefs: []
  type: TYPE_NORMAL
- en: OpenGL global variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After defining our shaders, we need to define several variables in C that we
    will use to interact with them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: OpenGL uses reference variables to interact with the GPU. The first two of these
    variables are of type `GLuint`. A `GLuint` is an unsigned integer, and using the
    `GLuint` type is just an OpenGL type. Seeing `GLuint` instead of `unsigned int`
    is a nice way to give someone reading your code a hint that you are using this
    variable to interact with OpenGL. The program variable will eventually hold a
    reference to a program that will be defined by your shaders, and the texture variable
    will hold a reference to a texture that's been loaded into the GPU. After the
    references to program and texture, we have two variables that will be used to
    reference shader program attributes. The `a_texcoord_location` variable will be
    a reference to the `a_texcoord` shader attribute, and the `a_position_location`
    variable will be a reference to the `a_position` shader attribute value. The attribute
    references are followed up by two uniform variable references. If you are wondering
    what the difference between a uniform and attribute variable is, a uniform variable
    remains the same value for all vertices, whereas an attribute variable is vertex-specific.
    Finally, we have a reference to our vertex texture buffer in the `vertex_texture_buffer`
    variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'After we define these values, we need to define our quad. As you may remember,
    our quad is made up of six vertices. This is because it is made up of two triangles.
    I talked about why we set the vertex data this way in [Chapter 3](dd4517c5-291a-49f5-9c7d-4070bb1fd062.xhtml),
    *Introduction to WebGL*. If you find this confusing, you may want to go back to
    that chapter for a little review. Here is the definition of the `vertex_texture_data`
    array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: SDL global variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are still going to be using SDL to initialize our canvas for OpenGL rendering.
    We will also be using SDL to load our image data from the virtual filesystem.
    Because of this, we have the following SDL related global variables we need to
    define:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, we need variables to hold our sprite width and height values when
    we load an image using SDL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'When we draw the ship to the canvas, we will need `x` and `y` coordinates for
    that ship, so we will create a few global variables to hold those values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we are going to create a function prototype for our game loop. I want
    to define our game loop after we define our main function because I would like
    to step through our initialization first. Here is the function prototype for our
    game loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The main function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, we have come to our `main` function. There is quite a bit of initialization
    that we will need to do. We are not only initializing SDL, like we did when we
    were creating our game. We will also need to do several initialization steps for
    OpenGL. Here is the `main` function in its entirety:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let me break this into some more digestible pieces. The first thing we need
    to do in our `main` function is the standard SDL initialization stuff. We need
    to initialize the video module, create a renderer, and set the draw and clear
    colors. By now, this code should look pretty familiar to you:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to create and compile our vertex shader. This requires several
    steps. We need to create our shader, load the source code into the shader, compile
    the shader, then check to make sure there weren''t any errors when compiling.
    Basically, these steps take your code, compile it, and then load the compiled
    code into the video card to execute it later. Here are all the steps you need
    to perform to compile your vertex shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'After compiling the vertex shader, we need to compile the fragment shader.
    This is the same process. We start by calling `glCreateShader` to create a fragment
    shader. We then load our fragment shader source code using `glShaderSource`. After
    that, we call `glCompileShader` to compile our fragment shader. Finally, we call
    `glGetShaderiv` to see whether a compiler error occurred when we attempted to
    compile our fragment shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: For simplicity, I kept the error message vague for when of the shaders failed
    to compile. It only tells you which shader failed to compile. Later in this chapter,
    I will show you how to get a more detailed error message from the shader compiler.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have our shaders compiled, we need to link our shaders into a program,
    and then tell OpenGL that this is the program we want to use. If you are writing
    a game using OpenGL, there is a good chance you will be using more than one program.
    For example, you may want to have lighting effects on some objects in your game,
    but not others. Some game objects may require rotation and scaling, while others
    may not.
  prefs: []
  type: TYPE_NORMAL
- en: As you will learn in the next chapter, using multiple programs with WebGL has
    a significantly higher CPU hit than it does in a native OpenGL app. This has to
    do with the web browser's security checks.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this application, we will be using a single program, and we will use the
    following code to attach our shaders and link them to the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The `glCreateProgram` function creates a new program and returns a reference
    ID for it. We will store that reference ID in our program variable. We make two
    calls to `glAttachShader` that will attach our vertex and fragment shader to the
    program we just created. We then call `glLinkProgram` to link the program shaders
    together. We call `glGetProgramiv` to verify that the program linked successfully.
    Finally, we call `glUseProgram` to tell OpenGL that this is the program we would
    like to use.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we are using a specific program, we can retrieve the references to
    the attribute and uniform variables inside of that program with the following
    lines of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The first line retrieves a reference to the `u_texture` uniform variable, and
    the second line retrieves a reference to the `u_translate` uniform variable. We
    can use these references later to set these values inside of our shader. The two
    lines after that are used to retrieve references to the `a_position` position
    attribute and the `a_texcoord` texture coordinate attribute inside of our shaders.
    Like the uniform variables, we will be using these references to set the values
    in our shaders later on.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we will need to create and load data into a vertex buffer. The vertex buffer
    holds all of the attribute data for each vertex we will render. If we were rendering
    a 3D model, we would need to load it with model data that we retrieved externally.
    Luckily for us, all we need to render are some two-dimensional quads. Quads are
    simple enough that we were able to define them in an array earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we can load that data into a buffer, we will need to generate that buffer
    with a call to `glGenBuffers`. We will then need to *bind* the buffer using `glBindBuffer`.
    Binding a buffer is just the way you tell OpenGL which buffers you are currently
    working on. Here is the code to generate and then bind our vertex buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have a buffer selected, we can put data into that buffer using
    a call to `glBufferData`. We will pass in `vertex_texture_data` that we defined
    earlier. It defines both the `x` and `y` coordinates of our quad''s vertices and
    the UV mapping data for those vertices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'After buffering our data, we will use SDL to load a sprite surface. Then, we
    will create a texture from that surface, which we can use to find the width and
    height of the image we just loaded. After that, we call `glTexImage2D` to create
    an OpenGL texture from that SDL surface. Here is the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Most of the previous code should have looked pretty familiar. We have been using
    `IMG_Load` to load an SDL surface from the virtual filesystem for a while now.
    We then used `SDL_CreateTextureFromSurface` to create an SDL texture. Once we
    had the texture, we used `SDL_QueryTexture` to figure out what the image width
    and height are, and we stored those values in `sprite_width` and `sprite_height`.
    The next function call is new. The `GlTexImage2D` function is used to create a
    new OpenGL texture image. We pass in `sprite_surface` as our image data, which
    we had loaded a few lines earlier. The last line frees the surface using `SDL_FreeSurface`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then add two lines that enable alpha blending in our game:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'After enabling alpha blending, we have several lines that set up the attributes
    in our shaders:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The first two lines enable the `a_position` and `a_texcoord` attributes in our
    shaders. After that, we have two calls to `glVertexAttribPointer`. The calls to
    `glVertexAttribPointer` are used to tell our shader where the data that's assigned
    to each specific attribute is located in our vertex buffer. We filled our vertex
    buffer with 32-bit floating point variables. The first call to `glVertexAttribPointer`
    sets the location of the values assigned to the `a_position` attribute using the
    reference variable we created in `a_position_location`. We then pass in the number
    of values we use for this attribute. In the case of position, we pass in an `x`
    and a `y` coordinate, so this value is 2\. We pass in the data type for our buffer
    array, which is a floating-point data type. We tell the function we are not normalizing
    the data. The `stride` value is the second to last parameter. This is the number
    of bytes that are used for a vertex in this buffer. Because each vertex in the
    buffer is using four floating-point values, we pass in `4 * sizeof( float )` for
    our stride. Finally, the last value we pass in is the offset in bytes to the data
    we are using to populate this attribute. For the `a_position` attribute, this
    value is `0` because the position comes at the beginning. For the `a_texcoord`
    attribute, this value is `2 * sizeof(float)` because there are two floating-point
    values that we used for `a_position` that precede our `a_texcoord` data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final line in the `main` function sets the game loop callback:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The game loop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our game loop is pretty simple. In our game loop, we will use OpenGL to clear
    the canvas, move our ship, and render our ship to the canvas. Here is the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The first two lines of the game loop clear the canvas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, we have several lines that update the ship''s `x` and `y` coordinates,
    and then set the new coordinates in the shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the game loop uses `glDrawArrays` to draw our spaceship to the canvas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Compiling and running our code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You will want to download the sprites folder from the GitHub project so that
    you can include the image files that we need to compile and run this project.
    Once you have those images and have saved the code we just wrote into the `webgl-redux.c`
    file, we can compile and test this new application. If it is successful, it should
    look just like the [Chapter 3](dd4517c5-291a-49f5-9c7d-4070bb1fd062.xhtml), *Introduction
    to WebGL*, WebGL version. Run the following `emcc` command to compile the app:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'If the app runs successfully, you should have a spaceship that is moving from
    left to right and up the HTML canvas. Here is a screenshot of a working version
    of the app:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/57930775-44b4-4d64-a0ff-01e41f2688e0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.1: Screenshot of the OpenGL and SDL app'
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will learn how to blend textures from within a shader.
  prefs: []
  type: TYPE_NORMAL
- en: Mixing textures for a glow effect
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, we will spend some time learning how to load more than one texture into
    our program. We will add the colors of those two textures to create a pulsing
    glow effect. To do this, we will need to modify our fragment shader to receive
    a second texture and a time uniform variable. We will pass that variable into
    a sine wave function, which will use it to calculate the strength of our glowing
    engines. We will need to add some code to keep track of the time that has passed,
    as well as some new initialization code to load the second texture. We can begin
    by copying `webgl-redux.c` to a new file called `glow.c`. Now that we have the
    new `glow.c` file, we can walk through the changes we will need to make our glowing
    engine effect. The first code change is the addition of a new `#define` macro
    to define a value for `2Ï€`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use a value that cycles from `0` to `2Ï€` and feeds it into a sine wave
    function to create the pulsing effect on our engine glow. Here is the `#define`
    we should add near the beginning of our `glow.c` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Fragment shader changes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After that new macro, we will need to make some changes to our fragment shader
    code. Our vertex shader code will remain the same because the process of determining
    the position of our vertex will not be any different than it was in the previous
    version of the app. Here is the updated version of the fragment shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: We have added a new uniform variable called `u_time` that will be used to pass
    in a time-based variable that will cycle between `0` and `2Ï€`. We have also added
    a second `sampler2D` uniform variable called `u_glow` that will hold our new glow
    texture. The first line of our `main` function calculates a value between `0.0`
    and `1.0` based on the value in `u_time`. We retrieve the sampled values out of
    `u_texture` and `u_glow` using the built-in `texture2D` function. This time, instead
    of storing a value from the texture directly into `gl_FragColor`, we save those
    two values into `vec4` variables called `tex` and `glow`. We are going to be adding
    those two values together, so to keep things from getting too bright everywhere,
    we multiply the `rgb` (red green and blue) values in our `glow` sample color by
    the alpha channel. After that, we multiply all the values in our `glow` color
    by the `cycle` value we computed earlier.
  prefs: []
  type: TYPE_NORMAL
- en: The value in `cycle` will follow a sine wave oscillating between the values
    `0.0` and `1.0`. That will cause our `glow` value to cycle up and down over time.
    We then compute our fragment color by adding the `tex` color to the `glow` color.
    Then, we store the output value in `gl_FragColor`.
  prefs: []
  type: TYPE_NORMAL
- en: OpenGL global variable changes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next, we will need to update our OpenGL-related variables so that we can add
    three new global variables. We will need a new variable called `glow_tex`, which
    we will use to store a reference to the glow texture. We also need two new reference
    variables for our two new uniform variables in our shader, called `u_time_location`
    and `u_glow_location`. Here is what the new block of OpenGL variables will look
    like once we have added those three new lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Other global variable changes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After our OpenGL global variables, we will need to add a new block of time-related
    global variables. We need them to have our shader cycle through values for our
    engine glow. These time-related variables should look pretty familiar. We have
    used techniques similar to the one we are about to use in the game we have been
    developing. Here are those global time variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to add one more SDL-related global surface variable, which we will
    use to load our glow texture. Add the following line near the block of global
    variables that precedes the `main` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Changes to main()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will be making some significant modifications to the initialization we are
    doing in our `main` function. Let me start by showing you the entire function.
    Then, we will walk through all of the changes, one at a time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The first line in our `main` function is new. We use that line to set `last_frame_time`
    and `last_time` to the system time, which we retrieve using `SDL_GetTicks()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, we will not make any changes until we get to the section of code
    where we retrieve our uniform locations. We will need to retrieve two more uniform
    locations from our program, so right under our call to `glUseProgram`, we should
    make the following calls to get the uniform locations for `u_glow` and `u_time`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The following block of code must come after we call `SDL_FreeSurface` to free
    the `sprite_surface` variable. This code block will generate a new texture, activate
    it, bind it, and load the `glow.png` image into that texture. It will then free
    the SDL surface and generate mipmaps for our texture. Finally, we set the uniform
    locations for our textures using `glUniform1i`. Here is the code we use to load
    our new texture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: If you are not familiar with Mipmaps, you may be wondering what the `glGenerateMipmap(GL_TEXTURE_2D);`
    line does. When you scale textures using OpenGL, those textures take time to generate.
    Mipmaps are a way to speed up scaling by performing some power of two scaled versions
    of your images while the game is initializing. This will reduce the amount of
    time it will take to scale these images at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: Updating game_loop()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To cycle the glow effect on our spaceship''s engines, we will need to add some
    code to our game loop that will cycle from `0.0` through `2Ï€`. We will then pass
    this value into the shader as the `u_time` uniform variable. We need to add this
    new block of code to the beginning of the game loop function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: The first line uses `SDL_GetTicks()` to retrieve the current clock time. We
    then subtract the last time from the current time to get a value for the `diff_time`
    variable. This will tell us the number of milliseconds between this frame and
    the previous frame generated. After that, we calculate `delta_time`, which will
    be the fraction of a second between this frame and the previous frame. After we
    have calculated `diff_time` and `delta_time`, we set the `last_time` variable
    to `current_time`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We do this so that the next time we go through the game loop, we will have
    the time this frame ran. All of those lines have been in previous iterations of
    our code. Now, let''s get a value for `time_cycle`, which we will pass into the
    `u_time` uniform variable in our fragment shader. First, add `delta-time * 4`
    to time cycle with the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: You may be wondering why I multiply it by `4`. Initially, I hadn't added a multiple,
    which meant the engine glow cycled roughly every 6 seconds. This felt like the
    cycle was taking too long. Playing with the number, a multiple of 4 just felt
    right to me, but there is no reason you need to stick with this specific multiple
    if you would prefer your engines to cycle either faster or slower.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because we are using a sine function to cycle our glow level, we need to make
    sure that when our time cycle hits `TWOPI`, we subtract `TWOPI` from our `time_cycle`
    variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have calculated the value for our cycle, we set that value using
    the `u_time_location` reference variable using a call to `glUniform1f`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Compiling and running our code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have made all of the code changes we need, we can go ahead and
    compile and run the new version of our app. Compile the `glow.c` file by running
    the following `emcc` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'If the build is successful, running `glow.html` in your web browser should
    show the spaceship moving as it was before. However, now, there will be a glow
    effect on the engines. This glow will cycle up and down and look as follows when
    the engine is at maximum glow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b7146f36-42c8-4a69-860d-7d08556afe4f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.2: Screenshot of the glow shader app'
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will discuss the Phong 3D lighting model.
  prefs: []
  type: TYPE_NORMAL
- en: 3D lighting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I would like to briefly discuss 3D lighting because we will be approximating
    it with 2D lighting effects. The Phong lighting model is the standard for three-dimensional
    lighting models in computer graphics. It was a model for lighting created by Bui
    Tuong Phong at the University of Utah in 1975, but it was not until the late 1990s
    that desktop computers became fast enough to implement the model in games. Since
    then, the lighting model has become the standard for 3D game development. It combines
    ambient, diffuse, and specular lighting to render geometry. We won't be able to
    implement a proper version of the lighting model because we aren't writing a 3D
    game. However, we can implement an approximation of the model by using 2D sprites
    and normal maps to go along with those sprites.
  prefs: []
  type: TYPE_NORMAL
- en: Ambient light
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the real world, there is a certain amount of light that''s randomly reflected
    off of the surrounding surfaces. This creates lighting that will illuminate everything
    evenly. If it weren''t for ambient lighting, an object in the shadow of another
    object would be completely black. The amount of ambient lighting varies based
    on the environment. In a game, the amount of ambient lighting is usually decided
    based on the mood and look a game designer is attempting to achieve. For 2D games,
    ambient lighting may be effectively the only kind of lighting we have. In 3D games,
    relying entirely on ambient light produces models that look flat:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/312e7693-39ef-4252-9d53-dc284d0a7f31.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.3: A sphere with only ambient lighting'
  prefs: []
  type: TYPE_NORMAL
- en: Diffuse light
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Diffuse lighting is light that comes from a specific direction. If you look
    at a three-dimensional object in the real world, the side facing a light source
    will look brighter than the side facing away from that light source. This gives
    objects in a 3D environment an actual 3D appearance. In many 2D games, diffuse
    lighting is not created with a shader, but is included in the sprite by the artist
    that created it. In a platformer game, for instance, the artist may assume that
    there is a light source that comes from above the game objects. The artist would
    design the game objects to have a kind of diffuse lighting by changing the colors
    of the pixels in the artwork. For many 2D games, this will work perfectly fine.
    If you would, however, like to have a torch in your game that changes the look
    of the game objects as they move by, you need to design shaders that are capable
    of doing that work:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/26581e91-5ca6-408c-9fb6-319303979dee.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.4: Sphere with diffuse lighting'
  prefs: []
  type: TYPE_NORMAL
- en: Specular light
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Some objects are shiny and have reflective patches that create bright highlights.
    When light hits a surface, it has a reflective vector based on the angle that
    the light hits the surface, relative to the normal of the surface it is hitting.
    The intensity of specular highlights is based on the reflectivity of the surface,
    combined with the angle of view, relative to the reflected light angle. A specular
    highlight on a game object can make it appear smooth or polished. Not all game
    objects require this kind of lighting, but it looks great on objects you want
    to shine:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2e8a12b9-f654-49cb-b1bf-ce46a269680d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.5: Sphere with specular lighting'
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will discuss normal maps and how they are used in modern
    games.
  prefs: []
  type: TYPE_NORMAL
- en: Normal maps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Normal mapping is a method that's used for creating very detailed models using
    relatively low polygon counts in 3D games. The idea is that rather than creating
    a surface with a huge number of polygons, a game engine could use a low polygon
    model that had a normal map where each pixel in the normal map would contain the
    x, y, and z values of a normal using the red, green, and blue colors of the image.
    Inside of a shader, we could then sample the normal map texture in the same way
    we sample other texture maps. However, we could use the normal data to help us
    calculate the lighting effects on our sprites. If, in our game, we wanted our
    spaceships to always be lit relative to the star in the center of the gameplay
    area, we could create a normal map for our spaceships and create a light source
    in the center of our game. We will now create an app to demonstrate the use of
    normal maps for 2D lighting.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a 2D lighting demo app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can start our lighting app by creating a new C file called `lighting.c`.
    The macros at the beginning of `lighting.c` are the same macros we used in `glow.c`,
    but we can remove the `#define TWOPI` macro because it is no longer needed. Here
    are the macros we will have in our `lighting.c` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The vertex shader code in this file will be very similar to the vertex shader
    code we had in our `glow.c` file. The one change we will make is done by removing
    the `u_translate` uniform variable. We are doing this because we will be centering
    our shaded sprite image, and we will allow the user to move the light around the
    canvas. Here is the new version of the vertex shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Fragment shader updates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, we will need to create a new version of our fragment shader. This shader
    will load a normal map in addition to the original texture loaded. This normal
    map will be used to calculate lighting normals on our game object. This version
    of the shader will use a 2D form of the Phong lighting model, in that we will
    be calculating ambient, diffuse, and normal lighting for the sprite we are rendering.
    Here is the code for our new fragment shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s break down what is going on inside of the new version of the fragment
    shader. The first thing you will notice is that we have two `sampler2D` uniform
    variables; the second one is called `u_normal` and is used to sample the normal
    map for our image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'After our samplers, we need a `uniform vec3` variable that holds the position
    of our light. We we call this `u_light_pos`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'We will be using several constants in our new fragment shader. We will need
    factors for ambient and specular lighting, as well as the view position and the
    light color. We will be defining those constants in the following four lines of
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Inside of our `main` function, the first thing we will need to do is get the
    ambient fragment color. Determining the ambient color is pretty easy. All you
    need to do is multiply the texture color by the ambient factor, then multiply
    it again by the light color. Here is the code that computes the value for the
    ambient component of the fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'After calculating our ambient color component, we need to calculate the normal
    of our fragment from the normal map texture that we passed into the shader. The
    texture uses the red color to represent the normal''s `x` value. The green represents
    the `y` value. Finally, blue represents the `z` value. The colors are all floating
    points that go from `0.0` to `1.0`, so we will need to modify the normal''s `x`,
    `y`, and `z` components to go from `-1.0` to `+1.0`. Here is the code we use to
    define the normals:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'To convert the values in the `norm` vector from `0.0` into `1.0`, `-1.0`, and
    `+1.0`, we need to multiply the values in the normal vector by 2, and then subtract
    one. After calculating the value of the normal, we need to find the direction
    of our light source:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'We are normalizing the value with the normalize GLSL function because we won''t
    have any light falloff in this app. If you had a game with a torch, you might
    want a sharp falloff based on the square of the distance from the light source.
    For this app, we are assuming that the light source has an infinite range. For
    our specular lighting, we will need to calculate our view direction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'We set the `view_pos` vector to the center of our canvas, so our specular lighting
    should be the greatest when our light source is in the center of our canvas as
    well. You will be able to test this out when you compile the app. After calculating
    the view direction, we will need to calculate the reflection vector, which we
    will also use in our specular lighting calculation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then calculate the dot product of these two vectors, and raise them
    to the power of our specular factor (defined as 32 earlier) to calculate the amount
    of specular lighting we will need for this fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, we calculate the diffuse component for the fragment using the dot
    product of the normal and the light direction. We combine that with the light
    color to get our diffuse component value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we add all of those values together to find our fragment value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: OpenGL global variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After defining our fragment shader, we need to define a series of OpenGL-related
    global variables. These variables should be familiar to you from the previous
    two versions of this app. There are a few new variables that we should take note
    of. We will no longer have just one program ID. SDL uses its own program, and
    we will need an ID for that program as well. We will call this variable `sdl_program`.
    We will also need new references for our textures. In addition, we will need new
    references for the uniform variables that we pass into our shader. Here is the
    new version of our OpenGL global variable code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: SDL global variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Some of the SDL variables were the same as the ones we used in the previous
    apps we created for this chapter. The other variables for lighting and normals
    are new to this section. Here are the SDL-related global variables we will need
    for this app:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: We need to declare an `SDL_Texture` variable called `light_texture`, which we
    will use to hold the SDL texture for our light icon. We will be using SDL to draw
    our light icon instead of drawing it using OpenGL. We will use one surface pointer
    variable to load all of our textures, freeing that surface immediately after we
    create the texture. We need the width and height value to keep track of the width
    and height of our light icon. We will also need values to keep track of the `x`,
    `y`, and `z` coordinates of our light source.
  prefs: []
  type: TYPE_NORMAL
- en: Function prototypes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Because I would like to put the code for the `main` function before the code
    for our other functions, we will need a few function prototypes. In this app,
    we will have a game loop function, a function to retrieve mouse input through
    SDL, and a function to draw our light icon using SDL. Here is what those function
    prototypes look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: The main function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Like in the other apps we have created in this chapter, our `main` function
    will need to initialize both SDL and OpenGL variables. The beginning of the `main`
    function is the same as it was at the beginning of our glow app. It initializes
    SDL, then compiles and links the OpenGL shaders and creates a new OpenGL program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'After initializing SDL and creating the OpenGL shader program, we need to get
    uniform variable references for our OpenGL shader program. Two of these references
    are new to this version of the program. The `u_normal_location` variable will
    be a reference to the `u_normal` sampler uniform variable, and the `u_light_pos_location`
    variable will be a reference to the `u_light_pos` uniform variable. Here is the
    new version of our references:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'After grabbing the references to our uniform variables, we need to do the same
    for our attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'We then need to generate the vertex buffer, bind it, and buffer the data from
    the array we created earlier. This should be the same code that we had in the
    `glow.c` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will need to set up all of our textures. Two of them will be rendered
    using OpenGL, while the other will be rendered using SDL. Here is the initialization
    code for all three of the textures:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a fairly large block of code, so let me walk through it a piece at
    a time. The first three lines generate, activate, and bind the circle texture
    so that we can begin to update it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the circle texture ready to update, we can load the image
    file using SDL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to load that data into our bound texture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can activate that texture, generate mipmaps, and free the surface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'After doing this for our circle texture, we need to do the same series of steps
    for our normal map:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'We will handle the final texture differently because it will only be rendered
    using SDL. This should be pretty familiar to you by now. We need to load the surface
    from the image file, create a texture from the surface, query the size of that
    texture, and then free the original surface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have created our textures, we should set up our alpha blending:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'The last line of our `main` function uses Emscripten to call the game loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: The game_loop function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have our `main` function defined, we need to define our `game_loop`.
    Because the `game_loop` function is rendering using both SDL and OpenGL, we need
    to set our vertex attribute pointers each time through the loop before we render
    in OpenGL. We will also need to switch between more than one OpenGL program because
    SDL uses a different program for shading than the one we are using for OpenGL.
    Let me begin by showing you the entire function, and then we can walk through
    it one piece at a time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The first line of the game loop calls the `input` function. This function will
    use input from the mouse to set the light position. The second and third lines
    retrieve the SDL shader program and save it to the `sdl_program` variable. Then,
    it switches to the custom OpenGL shaders with a call to `glUseProgram`. Here are
    the two lines of code we call to save the current program and set a new one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, we call OpenGL to clear the canvas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to set our geometry:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'We then use a call to `glUniform3f` to set the `vec3 uniform u_light_pos` variable
    to the `light_x`, `light_y`, and `light_z` global variables we defined earlier.
    These light positions can be moved using the mouse. The code that allows the user
    to move the light will be defined later when we write the `input` function. After
    we set the values for our light positions, we can draw our triangles using OpenGL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we need to switch back to our SDL program and call the `draw_light_icon`
    function, which will draw our light icon using SDL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: The input function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have defined our game loop, we will need to write a function to
    capture our mouse input. I want to be able to click our canvas and have the light
    icon and light source move to the location I just clicked. I would also like to
    be able to hold the mouse button down and drag the light icon around the canvas
    to see how the shading works when the light is in different locations on the canvas.
    Most of this code will look very familiar. We use `SDL_PollEvent` to retrieve
    an event and look to see if the left mouse button is down, or if the user has
    moved the scroll wheel. If the user has turned the scroll wheel, the `light_z`
    variable is changed, which will, in turn, change the `z` position of our light
    source. We use the `static int mouse_down` variable to track whether or not the
    user pressed the mouse button. If the user pressed the mouse button, we would
    call `SDL_GetMouseState` to retrieve the `light_x` and `light_y` variables, which
    will modify the x and y positions of our light source. Here is the code for the
    input function in its entirety:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: The draw_light_icon function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The last function we need to define in our `lighting.c` file is the `draw_light_icon`
    function. This function will use SDL to draw our light icon based on the values
    in the `light_x` and `light_y` variables. We create an `SDL_Rect` variable called
    `dest` and set the `x`, `y`, `w`, and `h` attributes of that structure. We then
    call `SDL_RenderCopy` to render our light icon in the proper location. Here is
    the code for that function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: Compiling and running our lighting app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When we compile and run our lighting app, we should be able to click and drag
    our light around the canvas. We have a small circle that is associated with a
    normal map. Together with our shading and lighting, it should make that circle
    look more like a shiny button. Execute the following command on the command line
    to compile the `lighting.html` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, you should be able to serve the `lighting.html` file from a web server,
    or emrun. Here is what the app should look like if everything went well:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aade1966-f9f3-46d9-a525-75605d4672ca.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.6: Screenshot of the 2D lighting app'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we took a closer look at shaders after introducing the concept
    back in [Chapter 3](dd4517c5-291a-49f5-9c7d-4070bb1fd062.xhtml), *Introduction
    to WebGL*, when we built a WebGL app. It is helpful to have an understanding of
    WebGL when you are using OpenGL for WebAssembly because each call to OpenGL from
    WebAssembly is internally calling the corresponding WebGL functions. We started
    by rebuilding that WebGL app using a combination of OpenGL ES and SDL in C++ and
    compiled it to WebAssembly. We then learned how we could use OpenGL and shaders
    to mix different textures in interesting ways. We used this knowledge to create
    a pulsing glow around the spaceship's engines. Finally, we discussed 3D lighting
    and normal maps, and then developed a 2D lighting model and created an app that
    allows us to light a simple circle with that lighting model. This app demonstrates
    the possibilities in 2D lighting by allowing us to move our light around a 2D
    circle with a normal map, which is used to give that 2D surface the appearance
    of depth.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss debugging our WebAssembly application and
    the tools we can use for performance testing.
  prefs: []
  type: TYPE_NORMAL
