- en: Math for Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A machine learning user needs to have a fair understanding of machine learning
    concepts and algorithms. Familiarity with mathematics is an important aspect of
    machine learning. We learn to program by understanding the fundamental concepts
    and constructs of a language. Similarly, we learn machine learning by understanding
    concepts and algorithms using Mathematics, which is used to solve complex computational
    problems, and is a discipline for understanding and appreciating many computer
    science concepts. Mathematics plays a fundamental role in grasping theoretical
    concepts and in choosing the right algorithm. This chapter covers the basics of
    **linear algebra** and **calculus** for **machine learning**.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Linear algebra
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Environment setup
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up the Scala environment in Intellij
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up the Scala environment on the command line
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fields
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vectors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vector spaces
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vector types:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dense vector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sparse vector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vectors in Spark
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vector operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyperplanes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vectors in machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Matrices types:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dense matrix
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CSC matrix
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrix in Spark
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrix operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determinant
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eigenvalues and eigenvectors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singular value decomposition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrices in machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Definition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Function types:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linear functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Polynomial functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identity functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Constant functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Probability distribution functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gaussian functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Functional composition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hypothesis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gradient descent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prior, likelihood, and posterior
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculus
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Differential calculus
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integral calculus
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lagrange multipliers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plotting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linear algebra
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Linear algebra is the study of solving a system of linear equations and transformations.
    Vectors, matrices, and determinants are the fundamental tools of linear algebra.
    We will learn each of these in detail using **Breeze**. Breeze is the underlying
    linear algebra library used for numerical processing. Respective Spark objects
    are wrappers around Breeze, and act as a public interface to ensure the consistency
    of the Spark ML library even if Breeze changes internally.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the Scala environment in Intellij
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is best to use an IDE like IntelliJ to edit Scala code, which provides faster
    development tools and coding assistance. Code completion and inspection makes
    coding and debugging faster and simpler, ensuring you focus on the end goal of
    learning math for machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'IntelliJ 2016.3 brings Akka, Scala.meta, Memory view, Scala.js, and Migrators
    to the IntelliJ IDE as part of the Scala plugin. Now, let''s set up the Scala
    environment in Intellij as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to Under Preferences | Plugins, and verify if the Scala plugin is installed.
    SBT, which is a build tool for Scala, is configured by default as shown in the
    following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/image_02_001.png)'
  prefs: []
  type: TYPE_IMG
- en: Select File | New | Project from Existing resources | $GIT_REPO/Chapter_02/breeze
    or $GIT_REPO/Chapter_02/spark. Here, $GIT_REPO is the repository path where you
    have cloned the source code of the book.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import project by selecting the SBT option:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/image_02_002.png)'
  prefs: []
  type: TYPE_IMG
- en: Keep the default options of SBT, and click on Finish.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: SBT will take a while to import references from `build.sbt`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/image_02_003.png)'
  prefs: []
  type: TYPE_IMG
- en: Finally, right click on the source file and select Run 'Vector'.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/image_02_004.png)'
  prefs: []
  type: TYPE_IMG
- en: Setting up the Scala environment on the Command Line
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To set up the environment locally, follow the steps listed next:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to the root directory of `Chapter 2`, and choose the appropriate folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, choose the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Compile the code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Run the compiled code, and choose the program to run (classes shown depend on
    whether `sbt run` is executed in the Spark or Breeze folder).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Fields
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Fields are fundamental structures of mathematics defined in many different ways.
    We will now look at the most basic types.
  prefs: []
  type: TYPE_NORMAL
- en: Real numbers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A real number is any number we can think of; real numbers include whole numbers
    (0, 1, 2, 3), rational numbers (2/6, 0.768, 0.222..., 3.4), and irrational numbers
    (π, &Sqrt;3). Real numbers can be positive, negative, or zero. Imaginary numbers,
    on the other hand, are like &Sqrt;−1 (the square root of minus 1); note that infinity
    is not a real number.
  prefs: []
  type: TYPE_NORMAL
- en: Complex numbers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our understanding is that the square of a number can never be negative. In that
    case, how do we solve *x2* = *-9*? Sensibly, in math we have the concept of i,
    as a solution, that is, *x* = *3i*. Numbers such as i, -i, 3i, and 2.27i are called
    imaginary numbers. "A real number" + "an imaginary number" forms a "complex number".
  prefs: []
  type: TYPE_NORMAL
- en: '*Complex number = (real part) + (imaginary part) I*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following examples show complex number representation using the Breeze
    library for Mathematics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This preceding code gives us the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Vectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A vector is a mathematical object described as an ordered set of numbers. It
    is similar to a Set, except that order is maintained in vectors. All members are
    part of real numbers. A vector having dimension n is geometrically represented
    as a point in *n*-dimensional space. The origin of a vector starts from zero.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Vector spaces
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Linear algebra is well known as an algebra of vector spaces. Vector objects
    of field type real or complex can be added and scaled by multiplying the vector
    with the scalar number *α*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Vector space is a collection of vector objects, which can be added and multiplied
    together. Two vectors can be combined to produce a third vector or another object
    in a vector space. The axioms of vector space have useful properties. Space in
    vector space helps in studying the properties of physical space, for example,
    to find how near or far away an object is. One of the examples of vector space
    is a collection of vectors in a three-dimensional Euclidean space. Vector space
    *V* over field *F* has the following properties:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Vector addition: denoted by *v + w*, where *v* and *w* are element of space
    *V*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Scalar multiplication: denoted by *α * v*, where *α* is an element of *F*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Associativity: represented by *u + (v + w) = (u + v) + w*, where *u*, *v*,
    and *w* are elements of space *V*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Commutative: indicated by *v + w = w + v*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Distributive: denoted by *α * (v + w) = α * v + α * w*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In machine learning, features are the dimensions of vector space.
  prefs: []
  type: TYPE_NORMAL
- en: Vector types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In Scala, we will use the Breeze library to represent a vector. The vector can
    be represented as a dense or a sparse vector.
  prefs: []
  type: TYPE_NORMAL
- en: Vectors in Breeze
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Breeze uses two basic vector types-`breeze.linalg.DenseVector` and `breeze.linalg.SparseVector`-to
    represent the two vector types shown earlier.
  prefs: []
  type: TYPE_NORMAL
- en: '`DenseVector` is a wrapper around an array which supports numeric operations.
    Let''s first look at the dense vector computation; we will create a dense vector
    object using Breeze, and then update index three to a new value.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following result: `DenseVector (2.0, 0.0, 3.0, 6.0, -1.0)`'
  prefs: []
  type: TYPE_NORMAL
- en: '`SparseVector`is a vector with most of its values at zero, and supports numeric
    operations. Let''s look at the sparse vector computation; we will a create sparse
    vector object using Breeze, and then update the values by one.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following result: `SparseVector((0,2.0), (2,4.0), (4,6.0))`'
  prefs: []
  type: TYPE_NORMAL
- en: Vectors in Spark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Spark MLlib uses Breeze and JBlas for internal linear algebraic operations.
    It uses its own class to represent a vector defined using the `org.apache.spark.mllib.linalg.Vector`
    factory. A local vector has integer-typed and 0-based indices. Its values are
    stored as double-typed. A local vector is stored on a single machine, and cannot
    be distributed. Spark MLlib supports two types of local vectors, dense and sparse,
    created using factory methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet shows how to create basic sparse and dense vectors
    in Spark:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'There are various methods exposed by Spark for accessing and discovering vector
    values as shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Vector operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Vectors can be added together, subtracted, and multiplied by scalars. Other
    operations on vectors include finding the mean, normalization, comparison, and
    geometrical representation.
  prefs: []
  type: TYPE_NORMAL
- en: '**The Add operation**: This code shows an element-wise add operation on vector
    objects:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This last code gives us the result as follows: `DenseVector(4.0, 16.0, 11.1,
    6.3, 13.0)`'
  prefs: []
  type: TYPE_NORMAL
- en: '**Multiply and Dot operation**: It is an algebraic operation, which takes two
    sequences of an equal length of numbers, and returns a single number; algebraically,
    it is the sum of the products of the corresponding entries of the two sequences
    of numbers. It is mathematically represented as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/image_02_005.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This preceding code gives us the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The last code gives us the result as follows: `0.9024889161, 0.9024889161`'
  prefs: []
  type: TYPE_NORMAL
- en: '**Finding the** **Mean: **This operation returns the mean of the elements of
    the vector along the first array dimension, whose size does not equal `1`. It
    is mathematically represented as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the result as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`1.0`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the result as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '` (1.0,1.5)`'
  prefs: []
  type: TYPE_NORMAL
- en: '**Normalized vector**: Every vector has a magnitude, which is calculated using
    the Pythagoras theorem as *|v| = sqrt(x^2 + y^2 + z^2);* this magnitude is a length
    of a line from the origin point (`0,0,0`) to the point indicated by the vector.
    A vector is normal if its magnitude is `1`. Normalizing a vector means changing it
    so that it points in the same direction (beginning from the origin), but its magnitude
    is one. Hence, a normalized vector is a vector in the same direction, but with
    norm (length) `1`. It is denoted by ^X and is given by the following formula:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/image_02_006.png)'
  prefs: []
  type: TYPE_IMG
- en: Where ![](img/image_02_007.png) is the norm of ![](img/image_02_008.png). It
    is also called a unit vector.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '**Displaying the minimum and maximum element in a vector**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the result as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`4, 2, -1, 3`'
  prefs: []
  type: TYPE_NORMAL
- en: '**Compare operation**: This compares two vectors for equality and for less
    than, or greater than, operations:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '**Geometrical representation of a vector**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/image_02_009.png)'
  prefs: []
  type: TYPE_IMG
- en: Hyperplanes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Vectors of field type real numbers are difficult to visualize if *n* is not
    1,2, or 3\. Familiar objects like lines and planes make sense for any value of
    *n*. Line *L* along the direction defined by a vector *v*, through a point *P*
    labeled by a vector u, can be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*L = {u + tv | t* *&in; R}*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Given two non-zero vectors, *u* and *v*, they determine a plane if both the
    vectors are not in the same line, and one of the vectors is a scalar multiple
    of the other. The addition of two vectors is accomplished by laying the vectors
    head to tail in a sequence to create a triangle. If u and *v* lie in a plane,
    then their sum lies in the plane of *u* and *v*. The plane represented by two
    vectors *u* and *v* can be mathematically shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*{P + su + tv | s, t* *&in; R}*'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can generalize the notion of a plane as a set of *x + 1* vectors and *P,
    v1, . . . , vx* in *R*, n with *x ≤ n* determines a x-dimensional hyperplane:'
  prefs: []
  type: TYPE_NORMAL
- en: '*(P + X x i=1 λivi | λi* *&in; **R)*'
  prefs: []
  type: TYPE_NORMAL
- en: Vectors in machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Features in machine learning are represented using the n-dimensional vector.
    In machine learning, data objects are required to be represented in the numeric
    format to allow processing and statistic analysis. For example, images are represented
    using the pixel vector.
  prefs: []
  type: TYPE_NORMAL
- en: Matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A matrix over a field *F* is a two-dimensional array whose entries are elements
    of *F*. An example of a matrix over the field of real numbers is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*1 2 3*'
  prefs: []
  type: TYPE_NORMAL
- en: '*10 20 30*'
  prefs: []
  type: TYPE_NORMAL
- en: The previous matrix has two rows and three columns; we call it a *2 × 3* matrix.
    It is traditional to refer to the rows and columns by numbers. Row 1 is (*1 2
    3*), and row 2 is (*10 20 30*); column 1 is (*1 10*) , column 2 is (*2 20*), and
    column 3 is (*3 30*). In general, a matrix with m rows and n columns is called
    an *m × n* matrix. For matrix *A*, the element (*i, j*) is defined to be the element
    in the ith row and the jth column, and is indexed using the Ai, j or Aij notation.
    We will often use the pythonese notation, *A[i, j]*. Row *i* is the vector (*A[i,
    0], A[i, 1], A[i, 2], , A[i, m − 1]*) and column j is the vector (*A[0, j], A[1,
    j], A[2, j], , A[n − 1, j]*).
  prefs: []
  type: TYPE_NORMAL
- en: Types of matrices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In Scala, we will use the Breeze library to represent a matrix. A matrix can
    be represented as a dense or a CSC matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '**Dense matrix**: A dense matrix is created with a constructor method call.
    Its elements can be accessed and updated. It is a column major, and can be transposed
    to convert to row major.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '**Transposing a matrix**: Transposing a matrix means swapping its rows and
    columns. The transpose of a P × Q matrix, written MT, is a Q × P matrix such that
    (MT ) j, I = Mi, j for every I &in; P, j &in; Q. Vector transpose to create a
    matrix row.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding program is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '**CSC matrix: **The **CSC** matrix is known as the **Compressed Sparse Columns**
    matrix. Each column within the CSC matrix represents a sparse vector. The CSC
    matrix supports all matrix operations, and is constructed using `Builder`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Matrix in Spark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A local matrix in Spark has integer-typed row and column indices. Values are
    double-typed. All the values are stored on a single machine. MLlib supports the
    following matrix types:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dense matrices**: Matrices where entry values stored are in a single, double
    array in a column-major order.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sparse matrices**: Matrices where non-zero entry values are stored in the
    CSC format in a column-major order. For example, the following dense matrix is
    stored in a one-dimensional array [`2.0, 3.0, 4.0, 1.0, 4.0, 5.0`] for the matrix
    size (3, 2):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`2.0 3.0``4.0 1.0``4.0 5.0`'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is an example of a dense and sparse matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Distributed matrix in Spark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A distributed matrix has long-type row and column indices. It has double-typed
    values, stored distributively in one or more RDDs. Four different types of distributed
    matrices have been implemented in Spark. All of them are subclasses of `DistributedMatrix`.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_02_010.png)'
  prefs: []
  type: TYPE_IMG
- en: '`RowMatrix`: A `RowMatrix` is a row-oriented distributed matrix without meaningful
    row indices. (In a row-oriented matrix, consecutive elements of the rows of an
    array are contiguous in memory). `RowMatrix` is implemented as an RDD of its rows.
    Each row is a local vector. The number of columns must be less than or equal to
    *2^31* for a `RowMatrix` so that a single local vector is communicated to the
    driver, and can also be stored or operated on using a single node.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example shows how a row matrix (dense and sparse) is created
    from the `Vectors` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Output of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '`IndexedRowMatrix`: `IndexedRowMatrix` is similar to a `RowMatrix`, but with
    row indices, which can be used for identifying rows and executing joins. In the
    following code listing, we create a 4x3 `IndexedMatrix` with appropriate row indices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Output of the code listing above is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '`CoordinateMatrix`: This is a distributed matrix stored in a coordinate list
    (COO) format, backed by an RDD of its entries.'
  prefs: []
  type: TYPE_NORMAL
- en: The COO format stores a list of (row, column, value) tuples. Entries are sorted
    (row index, then column index) to improve random access times. This format is
    good for incremental matrix construction.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Matrix operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are different kinds of operations which can be performed on matrices.
  prefs: []
  type: TYPE_NORMAL
- en: '**Elementwise addition**: Given two matrices, a and b, addition of the two
    (a + b) means adding each element of two matrices.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Breeze
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the last code is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '**Elementwise multiplication**: In this operation, each element of the matrix
    *a* is multiplied by matrix'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Breeze
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '**Elementwise comparison**: In this operation, each element of a is compared
    with b. The code in Breeze is given as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Breeze
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The output for the preceding code is give as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '**Inplace addition**: This implies adding each element of a by 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Breeze
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the output of the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '**Element-wise sum**: This is used to add all the elements of a matrix. The
    code in Breeze is given as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Breeze
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output for the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '**Element-wise max**: To find the maximum value out of all the elements in
    a matrix, we use'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Breeze
  prefs: []
  type: TYPE_NORMAL
- en: 'The code in Breeze can be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '**Element-wise argmax**: This is used to get the position of the element with
    the maximum value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Breeze
  prefs: []
  type: TYPE_NORMAL
- en: 'Code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '**Ceiling**: This rounds off each element of the matrix to the next integer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Breeze
  prefs: []
  type: TYPE_NORMAL
- en: 'Code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '**Floor**: Floor rounds off the value of each element to the nearest integer
    of a lower value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Breeze
  prefs: []
  type: TYPE_NORMAL
- en: 'Code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Determinant
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `tr` M denotes the trace of a matrix *M*; it is the sum of the elements
    along the diagonal. The trace of a matrix is normally used as a measure of the
    "size" of a matrix. The determinant is known as the product of the elements along
    its diagonal.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_02_011.png)'
  prefs: []
  type: TYPE_IMG
- en: The determinant is majorly used in the system of linear equations; it indicates
    if the columns are linearly related, and it also helps to find the inverse of
    a matrix. For large matrices, the determinant is calculated using laplace expansion.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Eigenvalues and eigenvectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Ax = b* is a linear equation which emerges from static problems. Eigenvalues,
    on the other hand, are used for dynamic problems. Let''s consider A as a matrix
    with x as a vector; we will now solve the new equation in linear algebra, *Ax=
    λx*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As *A* multiplies *x*, the vector *x* changes its direction. But there are
    certain vectors in the same direction as *Ax*-these are known as **eigenvectors,**
    for which the following equation holds good:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Ax= λx*'
  prefs: []
  type: TYPE_NORMAL
- en: In the last equation, vector *Ax* is lambda times the vector *x*, and *λ* is
    known as eigenvalue. Eigenvalue *λ* gives the direction of a vector-if it is reversed,
    or is in the same direction.
  prefs: []
  type: TYPE_NORMAL
- en: '*Ax= λx* also conveys that *det(A - λI) = 0*, where *I* is the identity matrix.
    This determines *n* eigenvalues.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The eigenvalue problem is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*A x = λ x*'
  prefs: []
  type: TYPE_NORMAL
- en: '*A x-λ x = 0*'
  prefs: []
  type: TYPE_NORMAL
- en: '*A x-λ I x = 0*'
  prefs: []
  type: TYPE_NORMAL
- en: '*(A-λ I) x = 0*'
  prefs: []
  type: TYPE_NORMAL
- en: If x is non-zero, the preceding equation will have a solution only if *|A-λ
    I| = 0*. Using this equation, we can find eigenvalues.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'This last code gives us the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Singular value decomposition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Singular value decomposition of a matrix *M*: *m x n* (real or complex) is
    a factorization with the form *UΣV**, where *U* is an *m x R* matrix. *Σ* is an
    *R x R* rectangular diagonal matrix with non-negative real numbers on the diagonal,
    and *V* is an *n x r* unitary matrix. *r* is equal to the rank of the matrix *M*.'
  prefs: []
  type: TYPE_NORMAL
- en: The diagonal entries *Σii* of Sigma are known as the singular values of *M*.
    The columns of *U* and the columns of *V* are called the left-singular vectors
    and right-singular vectors of *M* respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of an SVD in Apache Spark:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: Matrices in machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Matrices are used as mathematical objects to represent images, datasets for
    real world machine learning applications like a face or text recognition, medical
    imaging, principal component analysis, numerical accuracy, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, eigen decomposition is explained here. Many mathematical objects
    can be understood better by breaking them into constituent parts, or by finding
    properties which are universal.
  prefs: []
  type: TYPE_NORMAL
- en: Like when integers are decomposed into prime factors, matrix decomposition is
    called eigen decomposition, where we decompose a matrix into eigenvectors and
    eigenvalues.
  prefs: []
  type: TYPE_NORMAL
- en: 'Eigenvector *v* of a matrix *A* is such that multiplication by *A* alters only
    the scale of *v*, as shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Av = λv*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The scalar *λ* is known as the eigenvalue corresponding to this eigenvector.
    The eigen decomposition of *A* is then given by the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*A = V diag(λ)V −1*'
  prefs: []
  type: TYPE_NORMAL
- en: The eigen decomposition of a matrix shares many facts about the matrix. The
    matrix is singular if and only if any of the eigenvalues is 0\. The eigen decomposition
    of a real symmetric matrix can also be used to optimize quadratic expressions
    and much more. Eigenvectors and eigenvalues are used for **Principal Component
    Analysis**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example shows how a `DenseMatrix` is used to get eigenvalues
    and eigen vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To define a mathematical object like a function, we must first understand what
    a set is.
  prefs: []
  type: TYPE_NORMAL
- en: A set is an unordered collection of objects like S = {-4, 4, -3, 3, -2, 2, -1,
    1, 0}. If a set S is not infinite, we use |S| to denote the number of elements,
    which is known as the Cardinality of the set. If *A* and *B* are finite sets,
    then *|A**&rarrb;**B|=|A|**&rarrb;**|B|*, which is known as the Cartesian product.
  prefs: []
  type: TYPE_NORMAL
- en: For each input element in a set A, a function assigns a single output element
    from another set B. A is called the domain of the function, and B, the codomain.
    A function is a set of pairs *(x, y)*, with none of these pairs having the same
    first element.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: The function with domain {1, 2, 3, . . .}, which doubles its input
    is the set {(1,2),(2,4),(3,6),(4,8),...}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: The function with domain {1, 2, 3, . . .} &rarrb; {1, 2, 3, . . .},
    which multiplies the numbers forming its input is {((1,1),1),((1,2),2)),...,((2,1),2),((2,2),4),((2,3),6),...
    ((3,1),3),((3,2),6),((3,3),9),...'
  prefs: []
  type: TYPE_NORMAL
- en: The output of a given input is known as the image of that input. The image of
    q under a function f is denoted by *f (q)*. If *f(q)=s*, we say q maps to s under
    f. We write this as *q->s*. The set from which all the outputs are chosen is a
    codomain.
  prefs: []
  type: TYPE_NORMAL
- en: 'We write this as *f: D -> F* when we want to say that f is a function with
    domain D and codomain *F*.'
  prefs: []
  type: TYPE_NORMAL
- en: Function types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Procedures versus Functions**:'
  prefs: []
  type: TYPE_NORMAL
- en: A procedure is a description of a computation that, given an input, produces
    an output.
  prefs: []
  type: TYPE_NORMAL
- en: Functions or computational problems don't indicate how to compute the output
    from the given input.
  prefs: []
  type: TYPE_NORMAL
- en: Many methods might exist for the same specification.
  prefs: []
  type: TYPE_NORMAL
- en: A computational problem may allow several possible outputs for each input.
  prefs: []
  type: TYPE_NORMAL
- en: We will write procedures in Breeze; often, these are called functions, but we
    will reserve that term for the mathematical objects.
  prefs: []
  type: TYPE_NORMAL
- en: '**One to One function**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*f : D -> F* is one-to-one if *f (x) = f (y)* implies *x = y;* that is, both
    *x* and *y* are in *D.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Onto function**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*F: D -> F* is onto if for every *z* element of *F*, there exists an element
    a in *D* such that *f (a) = z*.'
  prefs: []
  type: TYPE_NORMAL
- en: A function is invertible if it is one-to-one and onto.
  prefs: []
  type: TYPE_NORMAL
- en: '**Linear functions**: Linear functions are the functions whose graph is a straight
    line. A linear function has the form *z = f(x) = a + bx*. A linear function has
    one dependent variable, and one independent variable. The dependent variable is
    *z*, and the independent variable is *x*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/image_02_012.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Polynomial function**: A polynomial function involves only non-negative integer
    powers of x such as a quadratic, a cubic, a quartic, and so on. We can give a
    general definition of a polynomial, and define its degree. A polynomial of degree
    n is a function of the form *f(x) = anx n + an−1x n−1 + . . . + a2x 2 + a1x +
    a0*, where a''s are real numbers, also known as coefficients of polynomials.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example: *f(x) = 4x 3 − 3x 2 + 2*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_02_013.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Identity function**: For any domain *D*, *idD: D -> D* maps each domain element
    *d* to itself.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/image_02_014.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Constant function**: this is a special function represented as a horizontal
    line.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/image_02_015.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Probability distribution function **: This used to define the relative likelihood
    of different outcomes of a particular experiment. It assigns a probability to
    each potential outcome. Probabilities of all outcomes must sum equal to 1\. Often,
    probability distribution is a uniform distribution. That means, it assigns the
    same probability to each outcome. When we roll a die, the possible outcomes are
    1, 2, 3, 4, 5, and probabilities are defined as *Pr(1) = Pr(2) = Pr(3) = Pr(4)
    = Pr(5) = 1/5*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gaussian Function**: When the number of events is large, then the Gaussian
    function can be used to describe events. Gaussian distribution is described as
    a continuous function, also known as normal distribution. Normal distribution
    has the mean equal to median, and has symmetry about the center.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Functional composition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For functions *f: A -> B* and *g: B -> C*, the functional composition of function
    f and function *g* is the function *(g o f): A -> C*, defined by *(g o f)(x) =
    g(f(x))*. For example, if *f : {1,2,3} -> {A,B,C,D}* and *g : {A,B,C,D} -> {4,5}*,
    the composition of *g(y)=y2* and *f(x)=x+1* is *(g o f)(x)=(x+1)2*.'
  prefs: []
  type: TYPE_NORMAL
- en: Function composition is applying a function to the results of another function.
    So, in *(g o f)(x) = g(f(x))*, first apply *f()*, and then *g()*. Some functions
    can be decomposed into two (or more) simpler functions.
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*X* denotes the input variables, also called input features, and *y* denotes
    the output or target variable that we are trying to predict. The pair *(x, y)*
    is called a training example, and the dataset used to learn is a list of *m* training
    examples, where *{(x, y)}* is a training set. We will also use *X* to denote the
    space of input values, and *Y* to denote the space of output values. For a training
    set, to learn a function, *h: X → Y* so that *h(x)* is a predictor for the value
    of *y*. Function *h* is called a **hypothesis**.'
  prefs: []
  type: TYPE_NORMAL
- en: When the target variable to be predicted is continuous, we call the learning
    problem a regression problem. When *y* can take a small number of discrete values,
    we call it a classification problem.
  prefs: []
  type: TYPE_NORMAL
- en: Let's say we choose to approximate *y* as a linear function of *x*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The hypothesis function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_02_016.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this last hypothesis function, the *θi* ''s are parameters, also known as
    weights, which parameterize the space of linear functions mapping from *X* to
    *Y*. To simplify the notation, we also introduce the convention of letting *x0
    = 1* (this is the intercept term), such that:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_02_017.png)'
  prefs: []
  type: TYPE_IMG
- en: On the RHS, we view *θ* and *x* both as vectors, and n is the number of input
    variables.
  prefs: []
  type: TYPE_NORMAL
- en: Now before we proceed any further, it's important to note that we will now be
    transitioning from mathematical fundamentals to learning algorithms. Optimizing
    the cost function and learning *θ* will lay the foundation to understand machine
    learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Given a training set, how do we learn the parameters *θ*? One method that looks
    possible is to get *h(x)* close to *y* for the given training examples. We shall
    define a function that measures, for each value of the *θ*s, how close the *h(x(i))*s
    are to the corresponding *y (i)* s. We define this as a cost function.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_02_018.png)'
  prefs: []
  type: TYPE_IMG
- en: Gradient descent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An SGD implementation of gradient descent uses a simple distributed sampling
    of the data examples. Loss is a part of the optimization problem, and therefore,
    is a true sub-gradient.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_02_019.png)'
  prefs: []
  type: TYPE_IMG
- en: This requires access to the full dataset, which is not optimal.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_02_020.png)'
  prefs: []
  type: TYPE_IMG
- en: The parameter *miniBatchFraction* specifies the fraction of the full data to
    use. The average of the gradients over this subset
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_02_021.png)'
  prefs: []
  type: TYPE_IMG
- en: is a stochastic gradient. *S* is a sampled subset of size *|S|= miniBatchFraction*.
  prefs: []
  type: TYPE_NORMAL
- en: In the following code, we show how to use stochastic gardient descent on a mini
    batch to calculate the weights and the loss. The output of this program is a vector
    of weights and loss.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Prior, likelihood, and posterior
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Bayes theorem states the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Posterior = Prior * Likelihood*'
  prefs: []
  type: TYPE_NORMAL
- en: This can also be stated as *P (A | B) = (P (B | A) * P(A)) / P(B)* , where *P(A|B)*
    is the probability of *A* given *B*, also called posterior.
  prefs: []
  type: TYPE_NORMAL
- en: '**Prior**: Probability distribution representing knowledge or uncertainty of
    a data object prior or before observing it'
  prefs: []
  type: TYPE_NORMAL
- en: '**Posterior**: Conditional probability distribution representing what parameters
    are likely after observing the data object'
  prefs: []
  type: TYPE_NORMAL
- en: '**Likelihood**: The probability of falling under a specific category or class.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is represented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_02_022.png)'
  prefs: []
  type: TYPE_IMG
- en: Calculus
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Calculus is a mathematical tool which helps the study of how things change.
    It provides a framework for modeling systems in which there is change, and a way
    to deduce the predictions of such models.
  prefs: []
  type: TYPE_NORMAL
- en: Differential calculus
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the core of calculus lie derivatives, where the derivative is defined as
    the instantaneous rate of change of a given function with respect to one of its
    variables. The study of finding a derivative is known as differentiation. Geometrically,
    the derivative at a known point is given by the slope of a tangent line to the
    graph of the function, provided that the derivative exists, and is defined at
    that point.
  prefs: []
  type: TYPE_NORMAL
- en: Differentiation is the reverse of Integration. Differentiation has several applications;
    like in physics, the derivative of displacement is velocity, and the derivative
    of velocity is acceleration. Derivatives are mainly used to find maxima or minima
    of a function.
  prefs: []
  type: TYPE_NORMAL
- en: Within machine learning, we deal with the functions that operate on variables
    or features having hundreds or more dimensions. We calculate derivatives of the
    function in each dimension of the variable, and combine these partial derivatives
    into a vector, which gives us what is called a gradient. Similarly, taking the
    second-order derivative of a gradient gives us a matrix termed as **Hessian**.
  prefs: []
  type: TYPE_NORMAL
- en: The knowledge of gradients and hessians helps us define things like directions
    of descent and rate of descent, which tell us how we should travel in our function
    space in order to get to the bottom-most point, in order to minimize the function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of a simple objective function (linear regression
    with weights *x*, *N* data points, and *D* dimensions in a vectorized notation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_02_023.png)'
  prefs: []
  type: TYPE_IMG
- en: The method of Lagrange multipliers is a standard way in calculus to maximize
    or minimize functions when there are constraints involved.
  prefs: []
  type: TYPE_NORMAL
- en: Integral calculus
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Integral calculus joins (integrates) the granular pieces together to find the
    total. It is also known as anti-differential, where differential is to divide
    into small chunks and study how it changes as described in the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: Integral is often used to find the area underneath the graph of a function.
  prefs: []
  type: TYPE_NORMAL
- en: Lagranges multipliers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the math optimization problem, the method of Lagrange multipliers is used
    as a tool for finding the local minima and maxima of a function subject to equality
    constraints. An example involves finding the maximum entropy distribution subject
    to given constraints.
  prefs: []
  type: TYPE_NORMAL
- en: This is best explained with an example. Let's say we have to maximize *K (x,
    y) = -x2 -y2 subject to y = x + 1*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The constraint function is *g (x, y) = x-y+1=0*. The *L* multiplier then becomes
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_02_024.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Differentiating with respect to *x*, *y*, and lambda, and setting to *0* we
    get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_02_025.png)![](img/image_02_026.png)![](img/image_02_027.png)'
  prefs: []
  type: TYPE_IMG
- en: Solving the preceding equations, we get *x=-0.5*, *y=0.5*, *lambda=-1*.
  prefs: []
  type: TYPE_NORMAL
- en: Plotting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this segment, we will see how to use Breeze to create a simple line plot
    from the Breeze `DenseVector`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Breeze uses most of the functionality of Scala''s plotting facilities, although
    the API is different. In the following example, we create two vectors `x1` and
    `y` with some values, and plot a line and save it to a PNG file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code generates the following Line Plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_02_028.png)'
  prefs: []
  type: TYPE_IMG
- en: Breeze also supports histogram. This is drawn for various sample sizes `100,000`,
    and `100,0000` normally distributed random numbers into `100` buckets.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/image_02_029.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A Gaussian distribution with 1000000 elements is shown in this next image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_02_030.png)'
  prefs: []
  type: TYPE_IMG
- en: A Gaussian distribution with 100 elements
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learnt the basics of linear algebra, which is useful for
    machine learning, and the basic constructs like vectors and matrix. You also learnt
    how to use Spark and Breeze to do basic operations on these constructs. We looked
    at techniques like SVD to transform data. We also looked at the importance of
    the function types in linear algebra. In the end, you learnt how to plot basic
    charts using Breeze. In the next chapter, we will cover an overview of Machine
    Learning systems, components and architecture.
  prefs: []
  type: TYPE_NORMAL
