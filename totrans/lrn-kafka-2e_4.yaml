- en: Chapter 4. Writing Producers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Producers are applications that create messages and publish them to the Kafka
    broker for further consumption. These producers can be different in nature; for
    example, frontend applications, backend services, proxy applications, adapters
    to legacy systems, and producers for Hadoop. These producers can also be implemented
    in different languages such as Java, C, and Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will be focusing on the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The Kafka API for message producers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Java-based Kafka producers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Java-based producers using custom message partitioning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the end of the chapter, we will also explore a few important configurations
    required for the Kafka producer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s begin. The following diagram explains the high-level working of Kafka
    producers in producing the messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Writing Producers](img/3090OS_04_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The producer connects to any of the alive nodes and requests metadata about
    the leaders for the partitions of a topic. This allows the producer to put the
    message directly to the lead broker for the partition.
  prefs: []
  type: TYPE_NORMAL
- en: The Kafka producer API exposes the interface for semantic partitioning by allowing
    the producer to specify a key to partition by and using this to hash to a partition.
    Thus, the producer can completely control which partition it publishes messages
    to; for example, if customer ID is selected as a key, then all data for a given
    customer will be sent to the same partition. This also allows data consumers to
    make locality assumptions about customer data.
  prefs: []
  type: TYPE_NORMAL
- en: For high efficiency in Kafka, producers can also publish the messages in batches
    that work in asynchronous mode only. In asynchronous mode, the producer works
    either with a fixed number of messages or fixed latency defined by producer configuration,
    `queue.time` or `batch.size`, respectively for example, 10 seconds or 50 messages.
    Data is accumulated in memory at the producer's end and published in batches in
    a single request. Asynchronous mode also brings the risk of losing the data in
    the case of a producer crash with accumulated non-published, in-memory data.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For asynchronous producers, callback method functionality is proposed for future
    release; this would be used for registering handlers to catch sent errors.
  prefs: []
  type: TYPE_NORMAL
- en: In the next few sections, we will discuss the API provided by Kafka for writing
    Java-based custom producers.
  prefs: []
  type: TYPE_NORMAL
- en: The Java producer API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let us first understand the important classes that are imported to write Java-based
    basic producers for a Kafka cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Producer`: Kafka provides the `kafka.javaapi.producer.Producer` class (`class
    Producer<K, V>`) for creating messages for single or multiple topics with message
    partition as an optional feature. The default message partitioner is based on
    the hash of the key. Here, `Producer` is a type of Java generic ([http://en.wikipedia.org/wiki/Generics_in_Java](http://en.wikipedia.org/wiki/Generics_in_Java))
    written in Scala where we need to specify the type of parameters; `K` and `V`
    specify the types for the partition key and message value, respectively. The following
    is the class diagram and its explanation:![The Java producer API](img/3090OS_04_02.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`KeyedMessage`: The `kafka.producer.KeyedMessage` class takes the topic name,
    partition key, and the message value that need to be passed from the producer
    as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Here, `KeyedMessage` is a type of Java generic written in Scala where we need
    to specify the type of the parameters; `K` and `V` specify the type for the partition
    key and message value, respectively, and the topic is always of type `String`.
  prefs: []
  type: TYPE_NORMAL
- en: '`ProducerConfig`: The `kafka.producer.ProducerConfig` class encapsulates the
    values required for establishing the connection with the brokers such as the broker
    list, message partition class, serializer class for the message, and partition
    key.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Producer API wraps the low-level producer implementations for synchronous
    (default behavior) and asynchronous producers that are picked up based on the
    producer configuration `producer.type`. For example, in the case of asynchronous
    producers the `kafka.producer.Producer` class handles the buffering of the producer's
    data before the data is serialized and dispatched to the appropriate Kafka broker
    partition. Internally, the `kafka.producer.async.ProducerSendThread` instance
    dequeues the batch of messages and `kafka.producer.EventHandler` serializes and
    dispatches the data. The Kafka producer configuration `event.handler` also provides
    the ability to define custom event handlers.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: All the examples are developed and tested for a multi-broker cluster (either
    single or multiple nodes). For more information on how to set up a single node
    - multi-broker cluster, refer to [Chapter 2](ch02.html "Chapter 2. Setting Up
    a Kafka Cluster"), *Setting Up a Kafka Cluster*.
  prefs: []
  type: TYPE_NORMAL
- en: Simple Java producers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now we will start writing a simple Java-based producer to transmit the message
    to the broker. This `SimpleProducer` class is used to create a message for a specific
    topic and transmit it using the default message partitioning.
  prefs: []
  type: TYPE_NORMAL
- en: Importing classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As the first step, we need to import the following classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Defining properties
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As the next step in writing the producer, we need to define properties for
    making a connection with the Kafka broker and pass these properties to the Kafka
    producer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let us see the major properties mentioned in the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '`metadata.broker.list`: This property specifies the list of brokers (in the
    `[<node:port>, <node:port>]` format) that the producer needs to connect to. Kafka
    producers automatically determine the lead broker for the topic, partition it
    by raising a request for the metadata, and connect to the correct broker before
    it publishes any message.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`serializer.class`: This property specifies the `serializer` class that needs
    to be used while preparing the message for transmission from the producer to the
    broker. In this example, we will be using the string encoder provided by Kafka.
    By default, the `serializer` class for the key and message is the same, but we
    can also implement the custom `serializer` class by extending the Scala-based
    `kafka.serializer.Encoder` implementation. Producer configuration `key.serializer.class`
    is used to set the custom encoder.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`request.required.acks`: This property instructs the Kafka broker to send an
    acknowledgment to the producer when a message is received. The value `1` means
    the producer receives an acknowledgment once the lead replica has received the
    data. This option provides better durability as the producer waits until the broker
    acknowledges the request as successful. By default, the producer works in the
    "fire and forget" mode and is not informed in the case of message loss.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building the message and sending it
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As the final step, we need to build the message and send it to the broker as
    shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The complete program will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Before running this, make sure you have created the topic `kafkatopic` either
    using the API or from the command line, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Before compiling and running the Java-based Kafka program in the console, make
    sure you download the `slf4j-1.7.7.tar.gz` file from [http://www.slf4j.org/download.html](http://www.slf4j.org/download.html)
    and copy `slf4j-log4j12-1.7.7.jar` contained within `slf4j-1.7.7.tar.gz` to the
    `/opt/kafka_2.9.2-0.8.1.1/libs` directory. Add the `KAFKA_LIB` environment variable
    and also add all the libraries available in `/opt/kafka_2.9.2-0.8.1.1/libs` to
    the classpath using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Compile the preceding program using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the simple producer using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The `SimpleProducer` class takes two arguments; first, the topic name and second,
    the number of messages to be published. Once the producer is successfully executed
    and begins publishing the messages to the broker, run the command line consumer
    for consuming the messages as it subscribes to the topic created in the Kafka
    broker as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Creating a Java producer with custom partitioning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The previous example is a very basic example of a `Producer` class running
    on a single-node, multi-broker cluster with no explicit partitioning of messages.
    Jumping to the next level, let''s write another program that uses customized message
    partitioning. In this example, a log message for a website visit from any IP address
    is captured and published. This log message has three parts:'
  prefs: []
  type: TYPE_NORMAL
- en: The timestamp of the website hit
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The name of website itself
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The IP address from where the website is being accessed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's begin with the coding.
  prefs: []
  type: TYPE_NORMAL
- en: Importing classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First import the following classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Defining properties
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As the next step, we need to define properties for making a connection with
    the Kafka broker, as shown in the following code, and pass these properties to
    the Kafka producer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The only change in the previous property list is the addition of the `partitioner.class`
    configuration.
  prefs: []
  type: TYPE_NORMAL
- en: The `partitioner.class` property defines the class to be used for determining
    the partition in the topic where the message needs to be sent. If the key is null,
    Kafka uses the hash value of the key.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the Partitioner class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, we need to develop a custom partitioner class `SimplePartitioner` by
    implementing the `Partitioner` class (an abstract class written in Scala) that
    takes the key, which in this example is the IP address. It then finds the last
    octet and does a modulo operation on the number of partitions defined within Kafka
    for the topic. The following is the code for the `SimplePartitioner` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Building the message and sending it
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As the final step, we need to build the message and send it to the broker.
    The following is the complete listing of the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Before running this, make sure you have created the topic `website-hits` from
    the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, as specified in the beginning of the previous example, do the classpath
    settings if not already done. Now compile the partitioner class and the preceding
    producer program using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the custom partition producer using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The `CustomPartitionProducer` program takes two arguments; first, the topic
    name and second, the number of log messages to be published. Once the producer
    is successfully executed and begins publishing the messages to the broker, run
    the command line consumer for consuming the messages as it subscribes to the topic
    created in the Kafka broker:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, the benefit of using custom partitioning logic is
    that all the log messages that are generated for the same client IP address will
    end up going to the same partition. Also, the same partition may have batch log
    messages for different IP addresses.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The partitioning logic also needs to be known to the consumer so that the consumer
    can consume the messages published for the desired IPs. This part is covered in
    [Chapter 5](ch05.html "Chapter 5. Writing Consumers"), *Writing Consumers*.
  prefs: []
  type: TYPE_NORMAL
- en: The Kafka producer property list
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following table shows a list of a few important properties that can be configured
    for Kafka producer. The Scala class `kafka.producer.ProducerConfig` provides implementation-level
    details for producer configurations. For the complete list, visit [http://kafka.apache.org/documentation.html#producerconfigs](http://kafka.apache.org/documentation.html#producerconfigs).
  prefs: []
  type: TYPE_NORMAL
- en: '| Property name | Description | Default value |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `metadata.broker.list` | The producer uses this property to get metadata
    (topics, partitions, and replicas). The socket connections for sending the actual
    data will be established based on the broker information returned in the metadata.
    The format is `host1:port1,host2:port2`. |   |'
  prefs: []
  type: TYPE_TB
- en: '| `serializer.class` | This specifies the `serializer` class for the messages.
    The default encoder accepts a byte and returns the same byte. | `kafka.serializer.DefaultEncoder`
    |'
  prefs: []
  type: TYPE_TB
- en: '| `producer.type` | This property specifies how the messages will be sent:'
  prefs: []
  type: TYPE_NORMAL
- en: '`async` for asynchronous sending (used with message batching)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sync` for synchronous sending'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| `sync` |'
  prefs: []
  type: TYPE_TB
- en: '| `request.required.acks` | This value controls when the producer request is
    considered complete and whether the producer receives an acknowledgment from the
    broker:'
  prefs: []
  type: TYPE_NORMAL
- en: '`0` means the producer will never wait for an acknowledgment from the broker.
    This is used for the lowest latency, but with the weakest durability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`1` means the producer receives an acknowledgment once the lead replica has
    received the data. This option provides better durability as the client waits
    until the server acknowledges the request as successful.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-1` means the producer will receive an acknowledgment once all the in-sync
    replicas have received the data. This option provides the best durability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| `0` |'
  prefs: []
  type: TYPE_TB
- en: '| `key.serializer.class` | This specifies the serializer class for keys. |
    `${serializer.class}` |'
  prefs: []
  type: TYPE_TB
- en: '| `partitioner.class` | This is the partitioner class for partitioning messages
    among subtopics. The default partitioner is based on the hash value of the key.
    | `kafka.producer.DefaultPartitioner` |'
  prefs: []
  type: TYPE_TB
- en: '| `compression.codec` | This parameter specifies the compression codec for
    all data generated by this producer. Valid values are `none`, `gzip`, and `snappy`.
    | `none` |'
  prefs: []
  type: TYPE_TB
- en: '| `batch.num.messages` | This specifies the number of messages to be sent in
    one batch when using async mode. The producer will wait until this quantity of
    messages is ready to be sent or `queue.buffer.max.ms` is reached. | `200` |'
  prefs: []
  type: TYPE_TB
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter we have learned how to write basic producers and some advanced
    Java producers that use message partitioning. We have also covered the details
    of properties for Kafka producers.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn how to write Java-based consumers for message
    consumption.
  prefs: []
  type: TYPE_NORMAL
