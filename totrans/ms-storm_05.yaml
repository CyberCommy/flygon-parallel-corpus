- en: Trident Topology and Uses
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous chapter, we covered an overview of Trident. In this chapter,
    we are going to cover the development of a Trident topology. Here are the important
    points we are going to cover in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The Trident `groupBy` operation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Non-transactional topology
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trident hello world topology
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trident state
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Distributed RPC
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When to use Trident
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trident groupBy operation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `groupBy` operation doesn't involve any repartitioning. The `groupBy` operation
    converts the input stream into a grouped stream. The main function of the `groupBy`
    operation is to modify the behavior of subsequent aggregate functions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00037.gif)'
  prefs: []
  type: TYPE_IMG
- en: groupBy before partitionAggregate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If the `groupBy` operation is used before a `partitionAggregate`, then the `partitionAggregate`
    will run the `aggregate` on each group created within the partition.
  prefs: []
  type: TYPE_NORMAL
- en: groupBy before aggregate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If the `groupBy` operation is used before an `aggregate`, then input tuples
    is first repartition and then perform the `aggregate` operation on each group.
  prefs: []
  type: TYPE_NORMAL
- en: Non-transactional topology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In non-transactional topology, a spout emits a batch of tuples and doesn''t
    guarantee what''s in each batch. With a processing mechanism, we can divide the
    pipeline into two categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**At-most-once-processing**: In this type of topology, failed tuples are not
    retried. Hence, the spout does not wait for an acknowledgment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**At-least-once-processing**: Failed tuples are retried in the processing pipeline.
    Hence, this type of topology guarantees that every tuple that enters the processing
    pipeline must be processed at least once.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can write a non-transactional spout by implementing the `org.apache.storm.trident.spout.IBatchSpout`
    interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'This example shows how we can write a Trident spout:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The `FakeTweetSpout` class implements the `org.apache.storm.trident.spout.IBatchSpout`
    interface. The construct of `FakeTweetSpout(intbatchSize)` takes `batchSize` as
    an argument. If `batchSize` is `3`, then every batch emitted by `FakeTweetSpout`
    class contains three tuples. The `recordGenerator` method contains logic to generate
    the fake tweet. Here is the sample fake tweet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `getOutputFields` method returns two fields, `text` and `Country`. The `emitBatch(long
    batchId, TridentCollector collector)` method uses the `batchSize` variable to
    decide the number of tuples in each batch and emits a batch into the processing
    pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: The `batchesMap` collection contains `batchId` as a key and the batch of tuples
    as a value. All the batches emitted by `emitBatch(long batchId, TridentCollector
    collector)` will be added into `batchesMap`.
  prefs: []
  type: TYPE_NORMAL
- en: The `ack(long batchId)` method receives `batchId` as an acknowledgment, and
    will remove the corresponding batch from `batchesMap`.
  prefs: []
  type: TYPE_NORMAL
- en: Trident hello world topology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section explains how we can write a Trident hello world topology. Perform
    the following steps to create Trident hello world topology:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a Maven project by using `com.stormadvance` as the `groupId` and `storm_trident`
    as the `artifactId`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following dependencies and repositories to the `pom.xml` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `TridentUtility` class in a `com.stormadvance.storm_trident` package.
    This class contains the Trident filter and function that we are going to use in
    the Trident hello world example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `TridentUtility` class contains three inner classes: `Split`, `TweetFilter`,
    and `Print`.'
  prefs: []
  type: TYPE_NORMAL
- en: The `Split` class extends the `org.apache.storm.trident.operation.BaseFunction`
    class and contains the `execute(TridentTuple tuple, TridentCollector collector)`
    method. The `execute()` method takes comma-separated values as input, splits the
    input value, and emits multiple tuples as output.
  prefs: []
  type: TYPE_NORMAL
- en: The `TweetFilter` class extends the `org.apache.storm.trident.operation.BaseFilter`
    class and contains the `isKeep(TridentTuple tuple)` method. The `isKeep()` method
    takes a tuple as its input and checks whether the input tuple contains the value
    `#FIFA` in the `text` field or not. If the tuple contains `#FIFA` in the `text`
    field, then the method returns true. Otherwise, it returns false.
  prefs: []
  type: TYPE_NORMAL
- en: The `Print` class extends the `org.apache.storm.trident.operation.BaseFilter`
    class and contains the `isKeep(TridentTuple tuple)` method. The `isKeep()` method
    prints the input tuple and returns true.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a `TridentHelloWorldTopology` class in a `com.stormadvance.storm_trident`
    package. This class defines the hello world Trident topology:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Let's understand the code line by line. Firstly, we are creating an object of
    the `TridentTopology` class for defining the Trident computation.
  prefs: []
  type: TYPE_NORMAL
- en: The `TridentTopology` contains a method called `newStream()`, which will take
    an input source as an argument. In this example, we are using `FakeTweetSpout`
    created in the non-transactional topology section as an input source. Like Storm,
    Trident also maintains the state of each input source in ZooKeeper. Here, the
    `FakeTweetSpout` string specifies the node in ZooKeeper where Trident maintains
    the metadata.
  prefs: []
  type: TYPE_NORMAL
- en: The spout emits a stream that has two fields, `text` and `Country`.
  prefs: []
  type: TYPE_NORMAL
- en: We are repartitioning the batch of tuples emitted by the input source using
    the `shuffle` operation. The next line of the topology definition applies `TweetFilter`
    on each tuple. `TweetFilter` filters out all those tuples that do not contain
    the `#FIFA` keyword.
  prefs: []
  type: TYPE_NORMAL
- en: The output of `TweetFilter` is grouped by the `Country` field. Then, we applied
    the `Count` aggregator to count the tweets for each country. Finally, we are applying
    a `Print` filter to print the output of the `aggregate` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the console output of the `TridentHelloWorldTopology` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00038.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here is a diagram that shows the execution of the hello world Trident topology:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00039.gif)'
  prefs: []
  type: TYPE_IMG
- en: Trident state
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Trident provides an abstraction for reading from and writing results to stateful
    sources. We can maintain the state either internally to the topology (memory),
    or we can store it in external sources (Memcached or Cassandra).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider that we are maintaining the output of the preceding hello world
    Trident topology in a database. Every time you process the tuple, the count of
    country present in a tuple is increased in the database. We can''t achieve exactly-once
    processing by only maintaining a count in the database. The reason is that if
    any tuple failed during processing, then the failed tuple is retried. This gives
    us a problem while updating the state, because we are not sure whether the state
    of this tuple was updated previously or not. If the tuple has failed before updating
    the state, then retrying the tuple will increase the count in the database and
    make the state consistent. But if the tuple has failed after updating the state,
    then retrying the same tuple will again increase the count in the database and
    make the state inconsistent. Hence, by only maintaining a count in the database,
    we have no idea whether or not this tuple has been processed before. We need more
    details to take the right decision. We need to follow these steps to achieve the
    exactly-once processing semantics:'
  prefs: []
  type: TYPE_NORMAL
- en: Process the tuples in small batches.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assign a unique ID to each batch (transactional ID). If the batch is retried,
    it is given the same unique ID.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The state updates are ordered among batches. For example, the state update of
    batch 2 would not be possible until the state updates for batch 1 have completed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If we create a topology by using the preceding three semantics, then we can
    easily take a decision whether the tuple is processed before or not.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed RPC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Distributed RPC is used to query on and retrieve results from Trident topology
    on the fly. Storm has an in-built distributed RPC server. The distributed RPC
    server receives the RPC request from the client and passes it to the Storm topology.
    The topology processes the request and sends the result to the distributed RPC
    server, which is redirected by the distributed RPC server to the client.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can configure the distributed RPC server by using the following properties
    in the `storm.yaml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Here, `nimbus-node` is the IP of the distributed RPC server.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, run this command on the `nimbus-node` machine to start the distributed
    RPC server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s assume we are storing the count aggregation of hello world Trident topology
    in a database and want to retrieve the count for a given country on the fly. We
    would need to use the distributed RPC feature to achieve this. This example shows
    how we can incorporate the distributed RPC in the hello world Trident topology
    created in the previous section:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We are creating a `DistributedRPC` class that contains a `buildTopology()`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Let's understand the code line by line.
  prefs: []
  type: TYPE_NORMAL
- en: We are using `FakeTweetSpout` as an input source and the `TridentTopology` class
    to define the Trident computation.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next line, we are using the `persistentAggregate` function to represent
    the count aggregation of all the batches emitted. `MemoryMapState.Factory()` is
    used to maintain the count state. The `persistentAggregate` function knows how
    to store and update the aggregation in the source state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The memory database stores the country name as a key and the aggregation count
    as a value, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The `persistentAggregate` transforms the stream into a Trident `State` object.
    In this case, the Trident `State` object represents the count of each country
    so far.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next part of the topology defines a distributed query to get the count
    of each country on the fly. The distributed RPC query takes as input a comma-separated
    list of countries and returns the count of the each country. Here is the piece
    of code that defines the distributed query portion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The `Split` function is used to split the comma-separated list of countries.
    We have used a `stateQuery()` method to query the Trident `State` object that
    is defined in the first part of the topology. The `stateQuery()` takes in source
    of state--in this case, the countries count computed by the first part of the
    topology and a function for querying this function. We are using a `MapGet()`
    function, which gets the count for each country. Finally, the count of each country
    is returned as the query output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the piece of code that shows how we can pass input to a local distributed
    RPC:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We have created an instance of `backtype.storm.LocalDRPC` to simulate the distributed
    RPC.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are running the distributed RPC server, then we need to create an instance
    of a distributed RPC client to execute the query. Here is the piece of code that
    shows how we can pass input to the distributed RPC server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The Trident distributed RPC query executes like a normal RPC query, except these
    queries are run in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the console output of the `DistributedRPC` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00040.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: When to use Trident
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is very easy to achieve exactly-once processing using Trident topology and
    Trident meant for the same. On the other hand, it would be difficult to achieve
    the exactly-once processing in the case of vanilla Storm. Hence, Trident will
    be useful for that use case where we have require exactly-once processing.
  prefs: []
  type: TYPE_NORMAL
- en: Trident is not fit for all use cases, especially for high-performance use cases,
    because Trident adds complexity on Storm and manages the state.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we mainly concentrated on the Trident sample topology, the
    Trident `groupBy` operation, and the non-transactional topology. We also covered
    how we can query on the fly on a Trident topology using distributed RPC.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will cover the different types of Storm scheduler.
  prefs: []
  type: TYPE_NORMAL
