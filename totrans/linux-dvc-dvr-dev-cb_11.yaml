- en: 'Additional Information: Miscellaneous Kernel Internals'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here's some general information on dynamic memory allocation and I/O memory
    access methods.
  prefs: []
  type: TYPE_NORMAL
- en: While talking about dynamic memory allocation, we should keep in mind that we're
    programming in the C language inside the kernel, so it's really important to remember
    that each allocated memory chunk must be freed up when not used anymore. This
    is very important because in userspace, when a process ends its execution, the
    kernel (which actually knows all about memory chunks owned by the process) can
    easily get back all process-allocated memory; but this does not hold true for
    the kernel. In fact, a driver (or other kernel entity) that asks for a memory
    chunk must be sure to free it, otherwise, nobody will ask for it back and the
    memory chunk will be lost until the machine is restarted.
  prefs: []
  type: TYPE_NORMAL
- en: Regarding access to I/O memory, which is that area composed by the memory cells
    underlying peripheral registers, we must consider that we can't access them using
    their physical memory address; instead, we'll have to use the corresponding virtual
    one. In fact, Linux is an operating system that uses a **Memory Management Unit** (**MMU**)
    to virtualize and protect memory accesses, so we'll have to remap each peripheral's
    physical memory area to its corresponding virtual memory area to be able to read
    from and write to them.
  prefs: []
  type: TYPE_NORMAL
- en: This operation can be easily done by using the kernel functions presented in
    the code snippet in Chapter , but it is of paramount importance to point out that
    it must be done before any I/O memory access is attempted, or a segmentation fault
    will be triggered. This can terminate the process in user space, or possibly terminate
    the kernel itself for a bug in a device driver.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic memory allocation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most straightforward way to allocate memory is to use the `kmalloc()` function,
    and, to be on the safe side, it’s best to use routines that clear the allocated
    memory to zero, such as the `kzalloc()` function. On the other hand, if we need
    to allocate memory for an array, there are `kmalloc_array()` and `kcalloc()` dedicated
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some snippets containing memory allocation kernel functions (and the
    relative kernel memory deallocation functions) as reported in the header file, `linux/include/linux/slab.h`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'All the preceding functions expose two main differences between the userspace
    counterpart `malloc()` and other memory allocation functions:'
  prefs: []
  type: TYPE_NORMAL
- en: The maximum size of a chunk that can be allocated with `kmalloc()` and friends
    is limited. The actual limit depends on the hardware and the kernel configuration,
    but it is a good practice to use `kmalloc()` and other kernel helpers for objects
    smaller than a page size.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The number of bytes that make a page size is stated by defined `PAGE_SIZE` info
    kernel sources in the `linux/include/asm-generic/page.h` file; usually, it's 4096
    bytes for 32-bit systems and 8192 bytes for 64-bit systems. It can be explicitly
    chosen by the user via the usual kernel configuration mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kernel functions for dynamic memory allocation, such as `kmalloc()` and similar
    functions take an extra argument; the allocation flags are used to specify the
    behavior of `kmalloc()` in a number of ways, as reported in the snippet below
    from the `linux/include/linux/slab.h` file of kernel sources:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, there exist a lot of flags; however, a device driver developer
    will be interested mainly in `GFP_KERNEL` and `GFP_ATOMIC`.
  prefs: []
  type: TYPE_NORMAL
- en: It is clear that the main difference between the two flags is that the former
    can allocate normal kernel RAM and it may sleep, while the latter does the same
    without allowing the caller to sleep. This is a big difference between the two
    functions because it tells us which flag we have to use when we are in interrupt
    context or process context.
  prefs: []
  type: TYPE_NORMAL
- en: 'As seen in [Chapter 5](https://cdp.packtpub.com/linux_device_driver_development_cookbook/wp-admin/post.php?post=6&action=edit#post_28), *Managing
    Interrupts and Concurrency*,when we are in interrupt context we cannot sleep (as
    reported in the code above), in these situations, we must call `kmalloc()` and friends
    by specifying the `GFP_ATOMIC` flag, while the `GFP_KERNEL` flag can be used elsewhere,
    keeping in account that it can lead the caller to sleep and then the CPU may leave
    us to execute something else; therefore, we should avoid doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In fact, even if we're executing in the process context, executing a sleeping `kmalloc()` while
    holding a spinlock is considered evil! So, we must use the `GFP_ATOMIC` flag anyway
    in this case. Moreover, be aware that the maximum size for a successful `GFP_ATOMIC` allocation
    request tends to be smaller than a `GFP_KERNEL` request for the same reasons mentioned
    here clearly, related to physically-contiguous memory allocation and that the
    kernel keeps a limited pool of memory readily available for atomic allocation.
  prefs: []
  type: TYPE_NORMAL
- en: Regarding the first point above, on the limited size of an allocable memory
    chunk, for large allocations, we can alternatively consider using another class
    of functions: `vmalloc()` and `vzalloc()`, even if we have to underline the fact
    that memory allocated by `vmalloc()` and related functions are not physically
    contiguous and can't be used for **Direct Memory Access** (**DMA**) activities
    (while `kmalloc()` and friends, as stated previously, allocate contiguous memory
    areas in both virtual and physical addressing spaces).
  prefs: []
  type: TYPE_NORMAL
- en: Allocating memory for DMA activities is currently not addressed in this book;
    however, you may get further information regarding this issue in kernel sources
    within the `linux/Documentation/DMA-API.txt` and `linux/Documentation/DMA-API-HOWTO.txt` files.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following, there is the prototype of the `vmalloc()` function and friends
    definitions as reported in the `linux/include/linux/vmalloc.h` header file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: If we are not sure whether the allocation size is too large for `kmalloc()`,
    we can use `kvmalloc()` and its derivatives. This function will try to allocate
    memory with `kmalloc()`, and if the allocation fails it will fall back to `vmalloc()`.
  prefs: []
  type: TYPE_NORMAL
- en: Note that `kvmalloc()`may return memory that is not physically contiguous.
  prefs: []
  type: TYPE_NORMAL
- en: There are also restrictions on which `GFP_*` flags can be used with `kvmalloc()`, as reported
    in `kvmalloc_node()` documentation at [https://www.kernel.org/doc/html/latest/core-api/mm-api.html#c.kvmalloc_node](https://www.kernel.org/doc/html/latest/core-api/mm-api.html#c.kvmalloc_node).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are code snippets about `kvmalloc()`, `kvzalloc()`, `kvmalloc_array()`,
    `kvcalloc()`, and `kvfree()` as reported in the `linux/include/linux/mm.h`  header
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Kernel doubly linked lists
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When working with the Linux's **doubly linked list** interface, we should always
    bear in mind that these list functions perform no locking, so there is a possibility
    that our device driver (or other kernel entities) could attempt to perform concurrent
    operations on the same list. That's why we must be sure to implement a good locking
    scheme to protect our data against race conditions.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use the list mechanism, our driver must include the header file `linux/include/linux/list.h`;
    this file includes the header, `linux/include/linux/types.h`, where a simple structure
    of the `struct list_head` type is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, this structure contains two pointers (`prev` and `next`) to a `list_head` structure;
    these two pointers implement the doubly linked list functionality. However, the
    interesting thing is that `struct list_head` has no dedicated data field as it
    would in a canonical list implementation. In fact, in the Linux kernel list implementation,
    the data field is not embedded in the list element itself; rather it's the list
    structure that is meant to be enclosed in the related data structure. This may
    be confusing but, in reality, it is not; in fact, to use the Linux list facility
    in our code, we just need to embed a `struct list_head` inside the structure that
    makes use of the list.
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple example of how we can declare our object structure into our device
    driver is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'By doing this, we create a doubly linked list with custom data. Then, to effectively
    create our list, we just need to declare and initialize the list head using the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'As per other kernel structures, we have the compile time counterpart macro
    `LIST_HEAD()`, which can be used to do the same in case of non-dynamic list allocation.
    In our example, we can do as follows: `LIST_HEAD(data_list)`;'
  prefs: []
  type: TYPE_NORMAL
- en: Once the list head has been declared and properly initialized, we can use several
    functions, still from the `linux/include/linux/list.h` file, to add, remove, or
    do other list entry manipulation.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we take a look at the header file, we can see the following functions to
    add or remove an element from the list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The following function to replace an old entry by a new one are also visible:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This is just a subset of all available functions. You are encouraged to take
    a look at the `linux/include/linux/list.h` file to discover more.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, apart from the preceding functions, which can be used to add or remove
    an entry from the list, it is more interesting to see the macros used to create
    loops that iterate through lists. For example, if we wish to add a new entry in
    an ordered manner, we can do something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: By using the `list_for_each()` macro, we iterate the list and by using `list_entry()`, we
    obtain a pointer to our enclosing data. Note that we must pass to `list_entry()` the
    pointer to the current element `ptr`, our struct type, and then the name of the
    list entry within our struct (which is `list` in the preceding example).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we can add our new element at the right position using the `list_add_tail()`
    function.
  prefs: []
  type: TYPE_NORMAL
- en: Note that `list_entry()` simply uses the `container_of()` macro to do its job.
    The macro is explained in [Chapter 5](cbd6e9f7-f07c-46b8-b751-ece44101ca8b.xhtml)*,
    Managing Interrupts and Concurrency,* The container_of() macro section.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we take a look again at the `linux/include/linux/list.h` file, we can see
    more functions that we can use to get an entry from the list or to iterate all
    list elements in a different manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Some macros are also useful to iterate over the elements of each list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Again you should note that this is just a subset of all available functions,
    so you are encouraged to take a look at the `linux/include/linux/list.h` file to
    discover more.
  prefs: []
  type: TYPE_NORMAL
- en: Kernel hash tables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As stated previously, for linked lists, when working with the Linux's **hash
    table** interface, we should always bear in mind that these hashing functions
    perform no locking, so it is possible that our device driver (or other kernel
    entities) could attempt to perform concurrent operations on the same hash table.
    This is why we must be sure to also implement a good locking scheme to protect
    our data against race conditions.
  prefs: []
  type: TYPE_NORMAL
- en: 'As with kernel lists, we can declare and then initialize a hash table with
    a size of power-of-2 bits, using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: As per lists, we have the compile time counterpart macro `DEFINE_HASHTABLE()`,
    which can be used to do the same in case of a non-dynamic hash table allocation.
    In our example, we can use `DEFINE_HASHTABLE(data_hash, bits)`;
  prefs: []
  type: TYPE_NORMAL
- en: 'This creates and initializes a table named `data_hash` and a power-of-2 size
    based on bits. As just said, the table is implemented using buckets containing
    a kernel `struct hlist_head` type; this is due to the fact that kernel hash tables
    are implemented using a hash chain, whereas hash collisions are simply added to
    the head of the list. To better see this, we can refer to the `DECLARE_HASHTABLE()` macro
    definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Once that''s done, a structure containing a `struct hlist_node` pointer can
    be constructed to hold the data to be inserted, as we did before for lists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The `struct hlist_node` and its head, `struct hlist_head`, are defined in the `linux/include/linux/types.h` header
    file as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'A new node can then be added into the hash table using the `hash_add()` function
    as follows, where `&entry.node` is a pointer to `struct hlist_node` within the
    data structure, and `key` is the hashed key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The key can be whatever; however, usually it''s computed by using a special
    hash function applied to the data to be stored. For instance, having a hash table
    of 256 buckets, the key can be computed with the following `hash_func()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The opposite operation, which is deletion, can be done by using the `hash_del()` function
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'However, as for lists, the most interesting macros are the ones used to iterate
    the table. There exist two mechanisms; one iterates through the entire hash table,
    returning the entries in each bucket:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The other returns only the entries that correspond to the key''s hash bucket:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'By using this last macro, a procedure to delete a node from the hash table
    looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Note that this implementation just deletes the first matching entry.
  prefs: []
  type: TYPE_NORMAL
- en: By using `hash_for_each_possible()`, we can iterate the list into the bucket
    related to a key.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following, there are definitions of `hash_add()`, `hash_del()`, and
    `hash_for_each_possible()` as reported in the `linux/include/linux/hashtable.h`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: These are just a subset of all available functions to manage hash tables. You
    are encouraged to take a look at the `linux/include/linux/hashtable.h` file to
    see more.
  prefs: []
  type: TYPE_NORMAL
- en: Getting access to I/O memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To be able to effectively talk with a peripheral, we need to have a way to
    read and write within its registers and, to do that, we have two ways: by using **I/O
    ports** or by using **I/O memory**. The former mechanism is not covered in this
    book because it is not used so much in modern platforms (apart form x86 and x86_64
    ones), while the latter just uses normal memory areas to map each peripheral register
    and is the one that is commonly used in modern CPUs. In fact, I/O memory mapping
    is really common in **System-on-Chip** (**SoC**) systems, where the CPU can talk
    to its internal peripherals just by reading and writing into well-known physical
    addresses; in this scenario, each peripheral has its own reserved address and
    each one is connected to a register.'
  prefs: []
  type: TYPE_NORMAL
- en: To see a simple example of what I'm talking about, you can get the SAMA5D3 CPU's
    datasheet from [http://ww1.microchip.com/downloads/en/DeviceDoc/Atmel-11121-32-bit-Cortex-A5-Microcontroller-SAMA5D3_Datasheet_B.pdf](http://ww1.microchip.com/downloads/en/DeviceDoc/Atmel-11121-32-bit-Cortex-A5-Microcontroller-SAMA5D3_Datasheet_B.pdf); look
    up page 30, where a complete memory mapping of the whole CPU is reported.
  prefs: []
  type: TYPE_NORMAL
- en: 'This I/O memory mapping is then reported in the device tree files related to
    a platform. Just as an example, if we take a look at the definition of the UART
    controller of our ESPRESSObin''s CPU in the `linux/arch/arm64/boot/dts/marvell/armada-37xx.dtsi`
    file of the kernel sources, we can see the following settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'As explained in [Chapter 4](5f22a69e-e8b7-402e-8e67-72938d00c914.xhtml), *Using
    the Device Tree*, we can deduce that the UART0 controller is mapped at a physical
    address `0xd0012000`. This is also confirmed by the following kernel message we
    can see at boot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'OK, now we have to keep in mind that `0xd0012000` is the **physical address** of
    the UART controller, but our CPU knows **virtual addresses** because it uses its
    MMU to get access to RAM! So, how can we do the translation between the physical
    address `0xd0012000` and its virtual counterpart? The answer is: by memory remapping.
    This operation must be done in the kernel before every read or write operation
    on the UART controller''s registers, otherwise, a segmentation fault will be raised.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Just to have an idea about the difference between physical and virtual addresses
    and about how the remap operation behaves, we can have a look at the utility program
    named `devmem2`, which is downloadable within the ESPRESSObin via the `wget` program
    from [http://free-electrons.com/pub/mirror/devmem2.c](http://free-electrons.com/pub/mirror/devmem2.c):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'If we take a look at the code, we see the following operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'So the `devmem2` program just opens the `/dev/mem` device and then it calls
    the `mmap() `system call. This operation will cause the execution of the `mmap_mem()` method in
    the `linux/ drivers/char/mem.c `file , in kernel sources, where the `/dev/mem` char
    device is implemented:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Further information regarding these memory-remap operations and usage of the `remap_pfn_range()` functions
    and similar functions will be more clear in [Chapter 7](3a9fe19d-0ba6-4959-bc71-493d9f499cc4.xhtml),
    *Advanced Char Driver Operations*.
  prefs: []
  type: TYPE_NORMAL
- en: Well, the  `mmap_mem()`method conducts the memory remapping operation of the
    physical address `0xd0012000` into a virtual one suitable to be used by the CPU
    to access the UART controller's registers.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we try to compile the code with the following command on the ESPRESSObin,
    we get an executable suitable access from the user space to the UART controller''s
    registers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'You can safely ignore possible warning messages shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '`devmem2.c:104:33: warning: format ''%X'' expects argument of type ''unsigned
    int'',`'
  prefs: []
  type: TYPE_NORMAL
- en: '`but argument 2 has type ''off_t {aka long int}'' [-Wformat=]`'
  prefs: []
  type: TYPE_NORMAL
- en: '`printf("Value at address 0x%X (%p): 0x%X\n", target, virt_addr, read_result`'
  prefs: []
  type: TYPE_NORMAL
- en: '`);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`devmem2.c:104:44: warning: format ''%X'' expects argument of type ''unsigned
    int'',`'
  prefs: []
  type: TYPE_NORMAL
- en: '`but argument 4 has type ''long unsigned int'' [-Wformat=]`'
  prefs: []
  type: TYPE_NORMAL
- en: '`printf("Value at address 0x%X (%p): 0x%X\n", target, virt_addr, read_result`'
  prefs: []
  type: TYPE_NORMAL
- en: '`);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`devmem2.c:123:22: warning: format ''%X'' expects argument of type ''unsigned
    int'',`'
  prefs: []
  type: TYPE_NORMAL
- en: '`but argument 2 has type ''long unsigned int'' [-Wformat=]`'
  prefs: []
  type: TYPE_NORMAL
- en: '`printf("Written 0x%X; readback 0x%X\n", writeval, read_result);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`devmem2.c:123:37: warning: format ''%X'' expects argument of type ''unsigned
    int'',`'
  prefs: []
  type: TYPE_NORMAL
- en: '`but argument 3 has type ''long unsigned int'' [-Wformat=]`'
  prefs: []
  type: TYPE_NORMAL
- en: '`printf("Written 0x%X; readback 0x%X\n", writeval, read_result);`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, if we execute the program, we should get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the `devmem2` programs prints the remapping result as expected
    and the actual read is done using the virtual address, which, in turn, the MMU
    translates into the desired physical one at `0xd0012000`.
  prefs: []
  type: TYPE_NORMAL
- en: OK, now that it's clear that a memory remap is needed to access the peripheral's
    registers, we may suppose that once we have a virtual address physically mapped
    to a register, we can simply reference it to actually read or write data. Well
    this is wrong! In fact, despite the strong similarity between hardware registers
    mapped in memory and the usual RAM memory, when we get access to I/O registers,
    we must be careful to avoid being tricked by the CPU or compiler optimizations
    that can modify the expected I/O behavior.
  prefs: []
  type: TYPE_NORMAL
- en: The main difference between I/O registers and RAM is that I/O operations have
    side effects, while memory operations do not; in fact, when we write a value into
    RAM, we expect it to be unchanged by someone else, but for I/O memory, this is
    not true due to the fact that our peripheral may change some data in registers,
    even if we wrote a specific value into them. This is a really important fact to
    keep in mind, because, to attain good performance, RAM content can be cached and
    read/write instructions can be reordered by the CPU instruction pipeline; moreover,
    the compiler can autonomously decide to put data values in CPU registers without
    writing them to memory, and even if it finally stores them to memory, both write
    and read operations can operate on cache memory without ever reaching physical
    RAM. Even if it finally stores them to memory, both optimizations are not acceptable
    on I/O memory. In fact, these optimizations are transparent and benign when applied
    to conventional memory, but they can be fatal on I/O operations because a peripheral
    has a well-defined way of being programmed, and read and write operations on its
    registers can't be reordered or cached without causing malfunctions.
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the main reasons we can''t simply reference a virtual memory address
    to read and write data from a memory mapped peripheral. And a driver must, therefore,
    ensure that no caching is performed and no read or write reordering takes place
    when accessing registers; the solution is to use special functions that actually
    do read and write operations. In the `linux/include/asm-generic/io.h` header file, we
    can find these functions, as in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The preceding functions are to write data only; you are encouraged to take a
    look at the header file to see definitions of reading functions, such as `readb()`, `readw()`, `readl()`, and `readq()`.
  prefs: []
  type: TYPE_NORMAL
- en: Each function is defined to be used with a well-defined data type according
    to the size of the register to be operated on; also, each of them uses memory
    barriers to instruct the CPU to execute read and write operations in a well-defined
    order.
  prefs: []
  type: TYPE_NORMAL
- en: I'm not going to explain what memory barriers are in this book; if you're curious,
    you can always read more about it in the kernel documentation directory in the `linux/Documentation/memory-barriers.txt` file
  prefs: []
  type: TYPE_NORMAL
- en: 'As a simple example of the preceding functions, we can take a look at the `sunxi_wdt_start()`
    function within the `linux/drivers/watchdog/sunxi_wdt.c` file of Linux sources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Once the register's base address, `wdt_base`, and the register's mapping `regs` have
    been obtained, we can simply perform our read and write operations by using `readl()` and `writel()`, as
    shown in the preceding section, and we can rest assured that they will be executed
    properly.
  prefs: []
  type: TYPE_NORMAL
- en: Spending time in the kernel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [Chapter 5](cbd6e9f7-f07c-46b8-b751-ece44101ca8b.xhtml), *Managing Interrupts
    and Concurrency*, we saw how we can defer action at a later time; however, it
    may happen that we still have to wait some time between two operations on a peripheral,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'That is, if we have to write a value into a register, then wait for 100 microseconds,
    then write another value, these operations can be done by simply using functions
    defined in the `linux/include/linux/delay.h` header file (and other ones) instead
    of using techniques presented before (kernel timers and workqueues, and so on):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: All these functions are just used to delay for a specific amount of time expressed
    in nano, micro, or milliseconds (or just in seconds, as for `ssleep()`).
  prefs: []
  type: TYPE_NORMAL
- en: The first functions set (that is, the `*delay()` functions) can be used everywhere
    in both interrupt or process context, while the second set of functions must be
    used in the process context only due to the fact they may implicitly go to sleep.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, we see that, for instance, the `usleep_range()` function takes minimal
    and maximal sleep time to reduce power usage by allowing high-resolution timers
    to take advantage of an already scheduled interrupt, rather than scheduling a
    new one just for this sleep. The following is the function description in the `linux/kernel/time/timer.c` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, in the same file we see that the `msleep_interruptible()`is a variant
    of `msleep()`, which can be interrupted by a signal (in *Waiting for an event*
    recipe, in [Chapter 5](cbd6e9f7-f07c-46b8-b751-ece44101ca8b.xhtml), *Managing
    Interrupts and Concurrency,* we talked about this possibility) and the return
    value is simply the time in milliseconds not slept due to the interruption:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we should also notice the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`*delay()` functions use the jiffy estimation of clock speed (`loops_per_jiffy` value) and
    will busy wait for enough loop cycles to achieve the desired delay.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`*delay()` functions may return early in case of too low computed `loops_per_jiffy` (due
    to the time taken to execute the timer interrupt), or cache behavior affecting
    the time it takes to execute the loop function, or due to CPU clock rate changes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`udelay()` is the generally preferred API, and `ndelay()`''s level precision
    may not actually exist on many non-PC devices.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mdelay()` is a macro wrapper around `udelay()`, to account for possible overflow
    when passing large arguments to `udelay()`. That''s why the usage of `mdelay()` is
    discouraged and the code should be refactored to allow for the use of `msleep()`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
