- en: Serverless Considerations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the end of the last chapter, we touched upon securing our serverless installations—and
    the potential lack of security you get out of the box. In this chapter, we are
    going to approach that subject head-on and discuss what you should be looking
    out for when deploying your serverless function services on Kubernetes, as well
    as how to best monitor your clusters.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will be looking at:'
  prefs: []
  type: TYPE_NORMAL
- en: Security best practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do you monitor your Kubernetes cluster?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's make a start by discussing security.
  prefs: []
  type: TYPE_NORMAL
- en: Security best practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When talking about security best practices, our ultimate goal should be to ensure
    that no unauthorized third-party has to access to any part of either our application
    or infrastructure that we do not want them to have.
  prefs: []
  type: TYPE_NORMAL
- en: For example, I would want an end user to be able to run a script that calls
    one of my serverless functions via an HTTP request made directly, by a webpage
    or mobile application. However, I would not want that same user to be able to
    access my Kubernetes dashboard, for example.
  prefs: []
  type: TYPE_NORMAL
- en: Now, this may seem like a pretty obvious example, but, as we have seen over
    the past few years, out-of-the-box configurations do not always have this most
    basic security requirement in mind. A good example of this is MongoDB.
  prefs: []
  type: TYPE_NORMAL
- en: Back in January, June, and September 2017, it was reported by several major
    news outlets that around 99,000 MongoDB installations were exposed to the internet;
    these installations were either unpatched or badly configured. This resulted in
    third parties accessing, copying, and deleting data from them.
  prefs: []
  type: TYPE_NORMAL
- en: 'In some cases, criminals were copying data, deleting it from the source database,
    and then sending the database owners a ransom demand for *safe* return of the
    deleted data—other attackers simply deleted the database and replaced it with
    an empty database called `PWNED_SECURE_YOUR_STUFF_SILLY` or `DELETED_BECAUSE_YOU_DIDNT_PASSWORD_PROTECT_YOUR_MONGODB`.
    You can find an example of the ransoms attached to the following tweet: [https://twitter.com/nmerrigan/status/818034565700849664](https://twitter.com/nmerrigan/status/818034565700849664).'
  prefs: []
  type: TYPE_NORMAL
- en: Niall Merrigan, the researcher who posted the previous tweet, pointed out in
    another tweet that in a single morning the number of compromised MongoDB installations
    went from 12,000 to around 27,000.
  prefs: []
  type: TYPE_NORMAL
- en: 'Companies such as Microsoft started to push their own NoSQL database services
    such as Azure DocumentDB, with blog posts with headings such as *First and foremost,
    security is our priority*, and images such as the ones in the following link:
    [https://azure.microsoft.com/en-in/blog/dear-mongodb-users-we-welcome-you-in-azure-documentdb/](https://azure.microsoft.com/en-in/blog/dear-mongodb-users-we-welcome-you-in-azure-documentdb/),
    where Microsoft have taken their own DocumentDB logo and the MongoDB logo and
    put them on rusted locks and modern safe doors.'
  prefs: []
  type: TYPE_NORMAL
- en: So what does this have to do with securing our serverless functions? Well, to
    answer this we must first look at the root cause of the MongoDB problems.
  prefs: []
  type: TYPE_NORMAL
- en: A lot of the versions of MongoDB that were being targeted by the attacks were
    initially configured out of the box to bind to `0.0.0.0`, which meant that the
    service attached itself to all IP addresses on a server. Now, this is not a problem
    if your MongoDB installation was launched on a server that ran only on a private
    network, but this was not the case for the installations that were being attacked
    as they were being hosted in public clouds, some of which only provided external
    IP addresses.
  prefs: []
  type: TYPE_NORMAL
- en: Now, you may be thinking to yourself, surely you would need some sort of authentication
    to access the database? Well, you would be wrong; authentication, at the time
    when MongoDB was still being shipped listening on all network interfaces (`0.0.0.0`),
    was an additional configuration step. This meant that, according to the website
    Shodan in July 2015, there was a total of 595.2 TB of MongoDB data exposed on
    the public internet with no authentication.
  prefs: []
  type: TYPE_NORMAL
- en: Also, you read that date right, this was a problem in 2015, and a lot of installations
    remained unpatched and incorrectly configured.
  prefs: []
  type: TYPE_NORMAL
- en: So how can we avoid these basic configuration issues in our Kubernetes and server
    function service installations? Let's start by looking at Kubernetes itself.
  prefs: []
  type: TYPE_NORMAL
- en: Securing Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes is quite secure by default. Both of the cloud providers that provide
    Kubernetes, Google Cloud and Microsoft Azure, work in a similar way.
  prefs: []
  type: TYPE_NORMAL
- en: 'A management node is deployed alongside your nodes; this management node controls
    your entire cluster, and is by default exposed to both the public internet and
    the cloud provider. We can test what an unauthenticated user sees by launching
    a cluster with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, by default this command will launch the cluster, including the management
    node. All of the certificates used to authenticate your local copy of `kubectl`
    against the cluster are generated on the cloud, and then once the cluster has
    launched it will configure `kubectl` with all of the information needed to connect.
    If you have a look in the configuration file, which can be found at `~/.kube/config`,
    you should see something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, there is a certificate store in the `certificate-authority-data`
    section. This certificate is used to authenticate your cluster, meaning that whenever
    you run a command such as the following, it will return the list of nodes as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The nodes will appear as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/8e6ba5d4-4c2c-4ac3-8312-3fe9209e1a22.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, open your `~/.kube/config` file and remove the certificate from the `certificate-authority-data`
    section. This will basically create an invalid certificate, meaning that when
    you run the following command, you will get an error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The error will appear as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/d655c089-1b48-4488-a8fd-c4037c886e13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'So, unless you have a copy of the correct certificate, you cannot connect to
    the cluster. Don''t worry, you can still access your certificate by running the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ffb15955-c1fc-4a76-88ec-a5a539f45784.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This command will connect to your Google Cloud account, download the details,
    and update your `~/.kube/config` file with the certificate. You can test the freshly
    downloaded credentials by running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This will return details on all of your endpoints:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/2831a5e6-6aa9-488a-a67a-27355c7790fc.png)'
  prefs: []
  type: TYPE_IMG
- en: You may notice that the last URL in the list is for the Kubernetes dashboard.
    How is that secured?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try entering the URL into a browser and see. I entered `https://35.202.202.37/api/v1/namespaces/kube-system/services/kubernetes-dashboard/proxy`
    (that URL will not be accessible by the time you read this) into my browser, hit
    return and was instantly greeted by a certificate warning; after accepting the
    certificates I was shown the following message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This is great, as it is exactly what we want to see—we do not want unauthenticated
    users to be able to directly access our dashboard. But, how do we access it? We
    do not have a username and password, only a certificate—even if we did have a
    username and password, where would we enter them, given that we were never prompted
    for any authentication?
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes has a built-in proxy server. When launched, the proxy server makes
    a connection to your Kubernetes cluster using the certificate. Once connected,
    all traffic that is passed through the proxy is authenticated and you will be
    able to use the services. To start the proxy we simply need to run the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the proxy start as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/c1d57a71-4a02-4e16-8fba-932416a4261d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This will start the proxy process in the foreground. As you can see from the
    preceding Terminal output, the proxy is listening on your local machine on port
    `8001`. All we need to do is replace the public part of the URL and put that into
    our browser. So in my case, I update the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`https://35.202.202.37/api/v1/namespaces/kube-system/services/kubernetes-dashboard/proxy`'
  prefs: []
  type: TYPE_NORMAL
- en: 'I change it instead to read as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`http://127.0.0.1:8001/api/v1/namespaces/kube-system/services/kubernetes-dashboard/proxy`'
  prefs: []
  type: TYPE_NORMAL
- en: 'This will take you straight to the dashboard:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/e645d90a-5f4d-4d0d-bea5-2806ad93acd5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'So far, we have demonstrated that Kubernetes on Google Cloud is configured
    securely. Microsoft Azure clusters work in a similar way—for example, we run the
    following command to update our local credentials once the cluster had been deployed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: When deploying using `kubeadm` and `kube-aws`, certificates are generated and
    copied to our configuration file.
  prefs: []
  type: TYPE_NORMAL
- en: So, what we have learnt so far is that by default Kubernetes enforces certificate-based
    authentication to secure your installation, meaning that you would have to go
    to quite a lot of effort to misconfigure your installation to the point where
    your installation is exposed to the world. There is, however, one exception to
    this. It has nothing to do with your installation; it is more about how you manage
    your `kubectl` configuration file.
  prefs: []
  type: TYPE_NORMAL
- en: Never publish it anywhere (that is, check it into GitHub, for example, or share
    with colleagues). If it falls into the wrong hands then not only does someone
    have a copy of your certificate, they also have the rest of your cluster information,
    meaning that all they have to do is drop it in place on their local machine and
    they are free to then start launching applications. Additionally, as most cloud-based
    Kubernetes installations have access to your cloud providers to launch supporting
    services such as load balancers, storage, and potentially additional nodes, you
    could find yourself with quite a large bill as well as a compromised cluster.
  prefs: []
  type: TYPE_NORMAL
- en: The `kubectl` configuration I shared earlier in this section has been edited
    making it invalid—also the cluster it is configured to connect to has been terminated.
  prefs: []
  type: TYPE_NORMAL
- en: So, now that we know that our Kubernetes cluster should be secure, what about
    the serverless function services we have looked at?
  prefs: []
  type: TYPE_NORMAL
- en: Securing serverless services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have installed and connected each of our services on both our local Kubernetes
    cluster and the cloud. So far, though, we haven't really had to think about securing
    them—which is the question we raised at the end of the last chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The following sections will discuss how secure each tool is in its default configuration
    and what potential risks this configuration exposes you to. I won't be going into
    much detail about how to secure each tool, though where appropriate I will provide
    links to documentation.
  prefs: []
  type: TYPE_NORMAL
- en: OpenFaaS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s start by looking at OpenFaaS. I still have my Google Cloud cluster running,
    so I will deploy OpenFaaS there using the following command from within the `faas-netes`
    folder I cloned in the previous chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, this time I have used just `kubectl` rather than `helm`. We
    can check the services deployed by running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This will return the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/cd10893a-b139-4434-99a2-9277f02cb5f1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The one thing to notice is that by default OpenFaaS uses the `NodePort` rather
    than load balancer to expose the gateway service. No problem, you may be thinking
    to yourself; we can just use the following commands to find out the deployment''s
    name and expose it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we know that the deployment is called gateway, we can run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'After a minute or two, running the following command should give us the external
    IP address and port:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The results will appear as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/82c9e9da-b358-48d7-ad2b-de62e192315b.png)'
  prefs: []
  type: TYPE_IMG
- en: Going to the external IP address and port `8080` in a browser—in my case `http://35.224.135.38:8080/ui/`—unfortunately
    takes us straight to the OpenFaaS UI, no authentication needed. The same goes
    for using the command-line interface. So, how can you secure your OpenFaaS installation?
  prefs: []
  type: TYPE_NORMAL
- en: There are instructions on the OpenFaaS GitHub repository for using proxy services
    such as Traefik and Kong.
  prefs: []
  type: TYPE_NORMAL
- en: Kong is an open source API gateway that adds functionality such as traffic control,
    logging, the transformation of data, analytics, and most importantly, authentication.
    For more information on the Kong Community Edition, see [https://konghq.com/kong-community-edition/](https://konghq.com/kong-community-edition/).
  prefs: []
  type: TYPE_NORMAL
- en: Traefik (pronounced Traffic) is a reverse HTTP proxy which has been designed
    to work from the ground up with container orchestration tools like Kubernetes.
    It not only provides load balancing but also supports basic HTTP authentication
    and SSL termination. To find out more about Traefik, see its website at [https://traefik.io/](https://traefik.io/).
  prefs: []
  type: TYPE_NORMAL
- en: Both of these tools can be configured to sit in front of your OpenFaaS installation
    and intercept requests, and when configured, present the end user with a login
    prompt. The other way you can secure your OpenFaaS installation is by locking
    it down to your IP address using the networking tools within your public cloud
    service. The downside of this is that, depending on how your application calls
    the functions, you may not be able to lock it down completely.
  prefs: []
  type: TYPE_NORMAL
- en: So OpenFaaS, if just deployed, will expose parts of your Kubernetes cluster,
    meaning that a third party could potentially gain access to your resources if
    you do not secure them. For more information on securing your OpenFaaS cluster,
    see the official documentation at [https://github.com/openfaas/faas/tree/master/guide](https://github.com/openfaas/faas/tree/master/guide).
    Alternatively, you can use the openfaas-gke installation files by Stefan Prodan,
    which can be found at [https://github.com/stefanprodan/openfaas-gke/](https://github.com/stefanprodan/openfaas-gke/).
    It is also possible to access your OpenFaaS installation using the `kubectl proxy`
    command; however, this may limit its usefulness.
  prefs: []
  type: TYPE_NORMAL
- en: There is one more potential security problem with using OpenFaaS, and if you
    are already a Docker user it should be one you are familiar with. As OpenFaaS
    uses Docker images and the Docker Hub as its primary delivery method, you need
    to be careful whenever you push an image, as the image could potentially contain
    password details, API credentials, custom code, and other information you may
    not want to access through a public container image repository—the solution to
    this would be to use a private repository or a private Docker registry.
  prefs: []
  type: TYPE_NORMAL
- en: Please do not see any of this as a negative; OpenFaaS is an excellent piece
    of software, and I am sure that over time, changes will be introduced by the community
    to ensure that the steps detailed previously will not be needed as part of the
    initial configuration for the Kubernetes-hosted version.
  prefs: []
  type: TYPE_NORMAL
- en: Kubeless
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next up, let''s take a look at Kubeless. To deploy the latest version in my
    Google Cloud Kubernetes cluster, I ran the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Once deployed, I ran the following command to see what services had been exposed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from the following Terminal output, no services were publicly
    exposed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/c9c0fd91-d93f-4186-a348-85dfde326596.png)'
  prefs: []
  type: TYPE_IMG
- en: 'So far, so good. Let''s quickly launch a test function and expose it. From
    within the `/Chapter04/hello-world/` folder, I ran the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This created the function as expected. Running the following commands confirms
    that the function is available and running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Running the following command exposes the function to the world:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'After a short time, I can see an IP address for the `hello-lb` service when
    it is running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: So far, we haven't had to really do anything to lock our installation down,
    so how secure is it? The short answer to that question is very, but what makes
    the default installation of Kubeless more secure than the default installation
    of OpenFaaS?
  prefs: []
  type: TYPE_NORMAL
- en: 'On the face of it, both technologies are similar in architecture; their server
    components are deployed on our Kubernetes cluster and we interact with those components
    using a command-line interface from our local machine. For example, we used the
    following command for Kubeless:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'In the previous chapter, we used the following command to launch our function
    using OpenFaaS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: As you may have already spotted, at no point during our Kubeless configuration
    or use did we have to provide it with any of the details of our Kubernetes cluster,
    unlike OpenFaaS, where we had to explicitly tell the command-line interface the
    IP address and port of our OpenFaaS installation.
  prefs: []
  type: TYPE_NORMAL
- en: Kubeless knows exactly where our cluster is, and more importantly, it is authenticating
    whenever it needs to access it. As Kubeless is a native Kubernetes framework,
    rather than installing itself on top of Kubernetes, it is integrating itself into
    our cluster and adding additional functionality—in this case, functions—and is
    using other Kubernetes technologies, such as `kubectl` and custom resource definitions,
    to inject our function's code into the runtime on-demand, meaning that everything
    is contained within our Kubernetes cluster and all interaction with it is secure.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be demonstrated by removing the certificate from the `~/.kube/config`
    file and then trying to list the functions. You should see the following error:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/3f87d091-8396-4ce6-9758-9135ba882914.png)'
  prefs: []
  type: TYPE_IMG
- en: All of this means that your Kubeless installation is secure by default.
  prefs: []
  type: TYPE_NORMAL
- en: Funktion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Funktion, like Kubeless, is secure by default, as it tightly integrates itself
    with your Kubernetes cluster and adds additional functionality, and its command-line
    interface piggybacks its calls on top of `kubectl`.
  prefs: []
  type: TYPE_NORMAL
- en: Apache OpenWhisk
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Apache OpenWhisk, like OpenFaaS, installs itself on top of your Kubernetes
    cluster rather than fully integrating itself. However, as we covered in [Chapter
    7](b3e0a002-3751-4ac1-9fdc-8bf0778fdacb.xhtml), *Apache OpenWhisk and Kubernetes*,
    the CLI needs to be configured to authenticate itself against the installation
    once the service is exposed to the public internet. In that chapter, we ran the
    following commands to expose the service and authenticate the client against the
    API host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: So again, this service is secure by default, assuming that you do not publish
    or share the authentication key.
  prefs: []
  type: TYPE_NORMAL
- en: Fission
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'During the Fission installation, we have to set two environment variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'There is one variable for the `FISSION_URL` and one for the `FISSION_ROUTER`.
    This would indicate that potentially not everything is secure. First of all, let''s
    take a look at what we get when we access the `FISSION_URL`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/7da0005c-db13-44dd-a1c9-647d69ab2805.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, we get a response identifying the Fission API and the version
    number. Remove the certificates from the `~/.kube/config` file and run the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We can still interact with our Fission installation; this means that by default
    Fission has no authentication, and that when we use the recommended installation
    procedure, the API is exposed to the internet by default:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/983249ac-e7b1-4e91-bd31-1afc0ba9d089.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Work is on-going to ship Fission with a more secure default; you can follow
    its progress at the following GitHub issue: [https://github.com/fission/fission/issues/22/](https://github.com/fission/fission/issues/22/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Until then, it is recommend that you update the Helm chart to set the `serviceType`
    of `ClusterIP` for the controller service. As you can see from the following output,
    it is currently set to `LoadBalancer`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/0d8d0f86-b544-41d4-9871-66c2be3c1f23.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once you have configured the service to use `ClusterIP`, you can configure
    port forwarding from your localhost to the controller using the `kubectl` inbuilt
    proxy. The command to do this would look something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: This would mean that your `FISSION_URL` would be something like `http://localhost:1234`,
    as opposed to an externally accessible URL with no authentication. The Fission
    developers are in the process of building this solution into Fission and it should
    become the default configuration in one of the early 2018 releases.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you can see, we have a pretty mixed bag when it comes to securing our serverless
    installations—some of the solutions we have covered are secure by default, while
    others, such as the old default MongoDB configuration, need a little more work
    to secure them and make them production-ready. Before you permanently deploy any
    of the tools we have covered in this book, please ensure that you have reviewed
    exactly what each tool is exposing and how you can best lock it down.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we start to look at various ways we can monitor our Kubernetes cluster
    we should quickly talk about what we mean by monitoring when it comes to a tool
    with potentially a lot of moving parts.
  prefs: []
  type: TYPE_NORMAL
- en: Traditionally, monitoring servers has meant keeping a close eye on the availability
    of applications running on fixed servers. To do this, our monitoring tool would
    collate information on the CPU, RAM, and disk utilization, as well as which services
    were running, the number of processes, and also the availability of the services
    and the server itself.
  prefs: []
  type: TYPE_NORMAL
- en: We would set triggers at certain thresholds so that, for example, if there was
    an increase of CPU load, we could log in to the server and do some investigation
    before said CPU load starts to affect our application's performance.
  prefs: []
  type: TYPE_NORMAL
- en: As you can image, monitoring a Kubernetes cluster is a lot different to this.
    By design, the applications running with the cluster should be fault tolerant
    and also highly available—in fact, the functions we have been running in previous
    chapters sometimes only have a lifespan of the time it takes to execute the function.
  prefs: []
  type: TYPE_NORMAL
- en: This changes the way that we monitor our clusters, as we trust that a lot of
    the things we would traditionally be monitoring for will be handled by Kubernetes
    itself, rather than needing us to log in and take preventative actions.
  prefs: []
  type: TYPE_NORMAL
- en: With this in mind, we do not need to go too deep into the ins and outs of monitoring
    your Kubernetes clusters—that is probably a whole different book. Instead, we
    are going to take a quick look at some of the options for reviewing service metrics
    for our Kubernetes clusters using first the dashboard and then Google Cloud and
    Microsoft Azure, as these both natively support Kubernetes clusters.
  prefs: []
  type: TYPE_NORMAL
- en: The dashboard
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Kubernetes dashboard is not just a great resource for managing your cluster;
    it also gives you a great visual overview of what you have running and how it
    is currently performing.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, selecting All namespaces in the Namespaces drop-down menu and
    then clicking on Pods in the Workloads section of the left-hand side menu will
    give you a list of all the running pods, along with a breakdown of what each pod
    is currently using CPU and RAM-wise:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/09a8a4d1-f07c-44f0-839f-dbc6a1472b93.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Clicking on a pod—in this case, the heapster one—will give you a more detailed
    breakdown of the overall resources being used by the containers that make up that
    pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/259e480a-82b7-49bc-a65a-6e81050068b4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Scrolling down will show you the containers. In the case of heapster, there
    are three containers in the pod. From here, you can view the logs for each container
    in real time:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/854cc086-f346-4748-966a-422112ead94e.png)'
  prefs: []
  type: TYPE_IMG
- en: This is, as I am sure you can imagine, an extremely useful feature when it comes
    to debugging a problem with a running container.
  prefs: []
  type: TYPE_NORMAL
- en: However, you may have noticed when looking at the dashboard the CPU and RAM
    utilization that is being displayed is only for the last 15 minutes—you can not
    dig any deeper or go further back. Because of this, information on currently-running
    services is available through the dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: This makes the dashboard perfect for logging in and getting a very quick overview
    of your cluster—and what's good is that the dashboard is included with most Kubernetes
    clusters out of the box, making it very convenient.
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next up we have Google Cloud. On the face of it, the Kubernetes section of
    the Google Cloud Console appears pretty much like the Kubernetes dashboard:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/78f675a5-8bc9-46d2-9093-cdbc29c7fb9d.png)'
  prefs: []
  type: TYPE_IMG
- en: However, as you can see from the preceding screenshot, other than giving a status
    of OK it really doesn't tell you much about what is going on within your cluster.
    Instead, you need to use Stackdriver, which is accessible from the left-hand menu
    within the Google Cloud Console.
  prefs: []
  type: TYPE_NORMAL
- en: Google Stackdriver is a Google Cloud service which allows you to record metrics
    from several sources, including Google Cloud services, AWS, and also individual
    servers using an agent. The service is not free of charge; a detailed cost breakdown
    can be found at [https://cloud.google.com/stackdriver/pricing](https://cloud.google.com/stackdriver/pricing).
    We will be using the free trial, but if you have already used Google Stackdriver,
    the following steps may incur cost.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you first go to Stackdriver you will be asked several questions. Work
    through this process and at the end of it you should have a free trial up and
    collecting logs from your Kubernetes cluster. After a few minutes you should start
    to see information from your cluster starting to show in the metrics explorer.
    From here, you can start to build up dashboards such as the following one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/cf1ed8fe-3167-4432-a455-f67c5983083e.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from the preceding screenshot, we have the option to view more
    than 15 minutes worth of data—in fact, the dashboard is showing over an hour's
    worth of data, which is how old the cluster is.
  prefs: []
  type: TYPE_NORMAL
- en: 'Not only does Stackdriver give you access to metrics about your cluster, you
    can also access the logs from both your Kubernetes cluster and the containers
    themselves:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/8942f633-40a4-4015-ba36-0cecd4453267.png)'
  prefs: []
  type: TYPE_IMG
- en: As the logs and metrics are being stored away from your cluster, historical
    information about your containers is also accessible. If you are running a function
    in a container which is only live for a few seconds, you will not only be able
    to see the RAM and CPU utilization for that container, you will also have access
    to the entire life of the container.
  prefs: []
  type: TYPE_NORMAL
- en: Other features of Stackdriver are daily, weekly, and monthly email reports about
    your overall usage, as well as the option to configure triggers for when metric
    thresholds are crossed or when events appear in log files—you can be notified
    about these via SMS, email, or even chat products such as Slack or Campfire.
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft Azure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Compared to Google Cloud, Microsoft Azure''s out-of-the-box insights into your
    Kubernetes cluster are not that great. You do not have views into what is going
    on within your cluster, and while there are metrics available they are only the
    for the host machines—for example, you can see the CPU utilization as in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/de6fda7a-8693-4819-9b67-7cae6826832d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Along the same lines, you can launch the Kubernetes dashboard using the following
    command (making sure you replace the resource group and name with your own):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Fear not though, there is the Container Monitoring solution; this is an agent-based
    system that you can deploy on your Kubernetes cluster, which then feeds back information
    to the Azure portal.
  prefs: []
  type: TYPE_NORMAL
- en: To deploy it, you need to search for the Container Monitoring solution by Microsoft
    in the Azure Market, from within your Azure portal. Clicking on the Create button
    will ask you to create a workspace; I chose to create my workspace in the same
    resource group and region as my Kubernetes cluster. Make sure that Pin to dashboard
    is ticked and click on Deploy.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is where it gets a little complicated, as you need to get the WORKSPACE
    ID and PRIMARY KEY. These are buried quite deep inside a series of links. To get
    them, go to your dashboard and select your workspace—mine is labelled as Containers(russ-monitor).
    From there, click on OMS Workspace, and then Advanced settings. You should see
    something like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ff86ffce-445d-4808-8d6b-cc59aea78942.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Make a note of the WORKSPACE ID and PRIMARY KEY(mine are blurred out in the
    preceding screenshot). In the `Chapter10` folder of the repository that accompanies
    this book there is a file called `oms-daemonset.yaml`; make a copy of it and update
    it so that the values in the following `env` section are updated with your actual
    WORKSPACE ID and PRIMARY KEY:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you have updated the file, run the following command from the same folder
    where you saved the updated copy of the `oms-daemonset.yaml` file to deploy the
    `daemonset` into your cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Once deployed, you should be able to run the following command to confirm that
    everything is working as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see one `daemonset` for each node within your cluster. As my cluster
    has three nodes, the results look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/902d95a1-6141-4cfc-a12c-1feebcd0d2a9.png)'
  prefs: []
  type: TYPE_IMG
- en: Once deployed, after about 15 minutes you should be able to revisit your workspace
    and see stats starting to be recorded. The following screens give you an idea
    of the information being recorded.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first screen shows some basic information about the number of containers
    running within your Kubernetes cluster, with any errors and events recorded by
    Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/62732e0d-9d73-4dc9-ab39-b7deab0edbc3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Scrolling to the right will show you more details about your cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/4cb0cdb0-2be5-4155-ab9b-e18041dd8656.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, we have information pods running in the two namespaces my cluster
    has, and then we have nodes within the cluster. Following that, we have all of
    the images that have been downloaded, and details of all of the running containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scrolling right again will show you more information:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/73f72675-6667-4e59-a23a-f9ed6d020dbf.png)'
  prefs: []
  type: TYPE_IMG
- en: Here we can see the number of processes across all of our containers, the CPU
    and Memory performance over our chosen time frame, and finally, some example queries
    we can run on the data we are collecting. Clicking on the link will execute the
    sample queries, and from there, you will have the option of saving the results
    as a Microsoft Excel file or exporting the data to Microsoft's Power BI service.
  prefs: []
  type: TYPE_NORMAL
- en: Power BI is a business analytics service provided by Microsoft. It allows you
    to create dashboards and run some quite complex calculations on your datasets—one
    of which is the metric data being exported from your Kubernetes cluster into your
    Microsoft Azure workspace.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, we have gone from having very little information to being overwhelmed
    with stats and logs from our cluster. For more information on the Container Monitoring
    solution from Microsoft, see its product page at [https://docs.microsoft.com/en-us/azure/log-analytics/log-analytics-containers/](https://docs.microsoft.com/en-us/azure/log-analytics/log-analytics-containers/).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have discussed how our Kubernetes cluster is secured and
    how to secure the default configuration for each of the serverless tools we have
    looked at in the previous chapters. We have looked at three ways we can get real-time
    stats from our Kubernetes clusters using the Kubernetes dashboard and also looked
    at the monitoring tools provided by Google Cloud and Microsoft Azure for storing
    and querying metrics from your clusters.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, which is also the final chapter, we are going to be taking
    a look at how to best run your serverless workloads on Kubernetes, based on everything
    we have learnt in the previous chapters.
  prefs: []
  type: TYPE_NORMAL
