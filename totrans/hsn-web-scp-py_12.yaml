- en: Using Regex to Extract Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If these libraries don't exist in your current Python setup, refer to [Chapter
    2](b9919ebf-2d5c-4721-aa76-5c1378262473.xhtml), *Python and the Web – Using urllib
    and Requests*, the *Setting things up* section, for more information on their
    installation and how to set them up. So far, we have learned about web technologies,
    data finding techniques, and how to access web content using Python libraries.
  prefs: []
  type: TYPE_NORMAL
- en: '**Regular Expressions** (**Regex** or **regex**) is actually a pattern that''s
    built using predefined commands and formats to match the desired content. Regex provides
    a great value during data extraction when there is no particular layout or markup
    patterns to be chosen and can be applied with other techniques such as XPath,
    and CSS selectors.'
  prefs: []
  type: TYPE_NORMAL
- en: Complex web content and data in general text or character format might require
    the use of Regex to complete activities, such as matching and extraction, plus
    function replacing, splitting, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will learn about the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Overview of Regex
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Regex to extract data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A web browser (Google Chrome or Mozilla Firefox) is required for this chapter.
    We will be using the following Python libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '`requests`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`re`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bs4`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If these libraries don't exist in your current Python setup, refer to [Chapter
    2](b9919ebf-2d5c-4721-aa76-5c1378262473.xhtml), *Python and the Web – Using urllib
    and Requests**,* the* Setting things up *section, for more information on their
    installation and how to set them up.
  prefs: []
  type: TYPE_NORMAL
- en: The code files for this chapter are available in this book's GitHub repository: [https://github.com/PacktPublishing/Hands-On-Web-Scraping-with-Python/tree/master/Chapter09](https://github.com/PacktPublishing/Hands-On-Web-Scraping-with-Python/tree/master/Chapter09).
  prefs: []
  type: TYPE_NORMAL
- en: Those of you who are already using `re` can refer to the *Using regular expressions
    to extract data* section.
  prefs: []
  type: TYPE_NORMAL
- en: Overview of regular expressions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Regular expressions are used to match patterns found in text or strings. Regex can
    be used for testing and finding patterns as desired against text or web content.
    Regex contains various ways to define patterns and special notations, such as *escape
    codes* to apply some predefined rules. For more information on Regex, please refer
    to the *Further reading* section.
  prefs: []
  type: TYPE_NORMAL
- en: There are various cases where Regex can be quite effective and quick for obtaining
    the desired results. Regex can be applied to content (text or web sources) alone
    and can be used to target specific information patterns that aren't easily extractable
    while using XPath, CSS selectors, BS4*,* PyQuery, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, cases may arise that will demand Regex and XPath or CSS selectors
    to be used together in order to obtain the desired output. This output can then
    be tested using Regex in order to find patterns or to clean and manage data. Code
    editors, document writers, and readers also provide embedded Regex-based utilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Regex can be applied to any text or strings of characters, HTML sources, and
    so on that contain proper or improper formatting. Regex can be used for various
    applications, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Content based on a particular pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Page links
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image titles and links
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Texts inside links
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matching and validating email addresses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matching a postal code or zip code from address strings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Validating phone numbers, and so on
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using tools such as searching, finding, splitting, substituting, matching, and
    iterating, are applicable with or without other technology interference.
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we will be using the `re` Python module and exploring
    its methods, which we can then apply to Regex.
  prefs: []
  type: TYPE_NORMAL
- en: Regular expressions and Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`re` is a standard Python library that''s used to deal with Regex. Every default
    Python installation contains the `re` library. If the library doesn''t exist,
    please refer to [Chapter 2](b9919ebf-2d5c-4721-aa76-5c1378262473.xhtml), *Python
    and the Web – Using urllib and Requests**,* the *Setting things up* section, to
    learn how to set it up.'
  prefs: []
  type: TYPE_NORMAL
- en: '`>>>` in code represents the use of the Python IDE. It accepts the code or
    instructions it''s given and displays the output on the next line.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s begin by importing `re` using the Python IDE and listing its properties
    using the `dir()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output of the preceding command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see from the preceding output, there are various functions available
    in `re`. We will be using a few of these functions from a content extraction perspective,
    and we will explain the basics of Regex fundamentals by using examples such as
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '`sentence` we declared previously contains brief information regarding Python
    jobs and job descriptions. We will be using this sentence to explain basic Regex
    functionalities.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `split()` function explodes the string and returns the list of individual
    words, which are separated by the *space* character by default. We can also split
    the string object using `re.split()`. In this case, `split()` accepts the Regex
    pattern to split the sentence, for example, `re.split(r''\s+'',sentence)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The length of `sentence` and the Python `splitSentence` list object is obtained
    and printed using the preceding code. These counts of element and character will
    be helpful while comparing answers that are returned from the following examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '`re.findall()` accepts a pattern to search and the content to look for regarding
    the provided pattern. Normally, patterns can be provided directly to functions
    as an argument and as a *raw* string preceded with `r`, such as `r''([A-Z]+)''`,
    or a variable containing a *raw* string.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding code, we can see similar patterns with certain additional
    characters provided, but they differ in output. A general explanation is provided
    for some of these patterns, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`[A-Z]`: Square brackets in the pattern match a set of characters and are case-sensitive.
    Here, it matches characters from `A` to `Z` but not `a` to `z`. We can provide
    a set of characters such as `[A-Za-z0-9]`, which matches any characters from `A` to
    `Z` and `a` to `z`, as well as numeric characters from `0` to `9`. Additional
    characters, if required, can be passed inside the set as `[A-Z+]`; the `+` character
    can exist with `A` to `Z` of characters, for example, C++ or C.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`()`: Round brackets in the pattern hold the group of values that were matched.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`+` (used for repetition): Found outside of the character set, it matches one
    or more occurrences of the pattern it follows. `[A-Z]+` will match at least one
    or more combinations that''s found with the `A` to `Z` characters, for example, `R` and
    `MATLAB` from the preceding code. There are a few more characters for specifying
    repetition or occurrences, also known as Regex quantifiers:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`*` matches zero or more occurrences of the patterns'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`?` matches zero or one occurrence of the pattern'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`{m,n}` matches the minimum, `m`, and maximum, `n`, numbers of repetition,
    respectively:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`{2,5}`: Minimum 2 or maximum 5'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`{2,}`: Minimum 2 or could be more'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`{,5}`: Maximum 5'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`{3}`: 3 occurrences'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`\,` (comma): In Regex, characters other than `[A-Za-z0-9]` are normally written
    as escaped characters in order to mention that particular character (`\,` for
    comma, `\.` for period, `\?` for question mark, and so on).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Regex quantifiers are also categorized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Greedy quantifiers**: These match any element as many times as possible.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lazy or non-greedy quantifiers**: These match any element as few times as
    possible. Normally, a greedy quantifier is converted into a lazy quantifier by
    adding `?` to it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Patterns such as `([A-Z+]+)\,` match the set of characters from `A` to `Z` and
    `+` that can exist in at least one or more characters, followed by `,`. In `sentence` in
    the preceding code, we can find `R`, `MATLAB`, `SAS`, `Mathematica`, `Java`, `C`,
    `C++`, `VB`, and `JavaScript` (there's also `FORTRAN`), that is, names followed
    by `,` (but not in the case of `FORTRAN`; this is why it's been excluded in the
    output for provided patterns).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, we are trying to match`FORTRAN` that was found in `sentence`,
    which is being omitted with the patterns we tried in the code previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'As shown in the preceding code block, the Python library, `re`, possesses various
    functions, which are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`re.match()`: This matches a pattern provided at the start of the string and
    returns the matched object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`re.sub()`: This finds a pattern and substitutes it with the provided string.
    It works similar to find and replace in text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`re.search()`: This matches a pattern in the string and returns the matched
    object that''s found.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`\s`: This represents the *space*, *tab*, and *newline characters*. Here, `[\sorA-Z+]+\)` is
    matching one or more characters, including `A-Z`, `o`,`r`, `\s`, and `+`, followed
    by `\)` (closing parenthesis). There are a few more escape codes found in Regex,
    as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`\d`: Matches a digit'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`\D`: Matches a non-digit'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`\s`: Matches whitespace'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`\S`: Matches non-whitespace'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`\w`: Matches alphanumeric characters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`\W`: Matches non-alphanumeric characters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`\b`: Matches a word boundary'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`\B`: Matches a non-word boundary'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`^`: This matches the start of the string.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Note: `r''[^a-z]''` (the caret or `^`), when used inside a character set, acts
    as negation. Here, this means *except* or *exclude* `[a-z]`.'
  prefs: []
  type: TYPE_NORMAL
- en: '`$`: This matches the end of the string.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`|`: This implements the logical expression, `OR`, in the pattern. For example,
    `r''a|b''` will match any true expression, that is, `a` or `b`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code shows the use of some of these Regex patterns and the `findall()`
    function, along with their output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The following functions were found in the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '`re` functions also support an optional *flags* argument. There''s also an
    abbreviation for these flags (`i` for `re.IGNORECASE`, `s` for `re.DOTALL`, and
    `M` for `re.MULTILINE`). These can be used in patterns by including them at the
    beginning of the expressions. For example, `r''(?i)\s(MAT.*?)\,` will return [`MATLAB`,
    `Mathematica`]. The following are some other `re` functions that were found in
    the code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`re.IGNORECASE` : Ignores the case-sensitivity found in the pattern that''s
    provided'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`re.DOTALL` : Allows `.` (period) to match a newline, and works with strings
    containing multiple lines'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`re.MULTILINE` : Works with multiline strings and searches for patterns, including
    newline (`"\n"`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.` or period: This matches any single character but not the newline (`"\n"`).
    It''s used in patterns mostly with repetition characters. A period or `.` is required
    to be matched in the string, and should be used as `\.`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '`re.split()`: This splits the provided content based on the pattern and returns
    a list with results. A `split()` also exists, which can be used with a string
    to explode with the default or provided characters. It''s used in a similar fashion
    to `splitSentence`, from earlier in this section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You are suggested to compare the results of `matchesOne` and `matchesTwo` from
    this section**.**
  prefs: []
  type: TYPE_NORMAL
- en: 'In code below we are trying to apply the regex pattern for the value found
    inside datetime attribute. Pattern defined will be compiled and then used to search
    in the code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '`re.compile()`: This is used to compile a Regex pattern and receive a pattern
    object (`_sre.SRE_Pattern`). The object that''s received can be used with other
    Regex features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Group matches can be individually explored by using the `group()` method, as
    shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, though the pattern has been searched against multiline `timeDate`,
    it results in a single group; an individual group can be returned using the index
    too. An `re`-related match object contains the `groups()` and `group()`functions;
    `groups(0)` results in the same output as `groups()`. Individual elements in `groups()`
    will require an index starting from `1`.
  prefs: []
  type: TYPE_NORMAL
- en: '`re.finditer()`: This is used to iterate over resulting matches that are obtained
    for the pattern or pattern object found in the content that''s provided. It returns
    a match (`_sre.SRE_Match`) object that''s found from `re.match()`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`re.match()` returns an object that contains various functions and attributes
    that are used in code examples. These are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`start()`: Returns the starting character index that matches the expression'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end()`: Returns the ending character index that matches the expression'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`span()`: Returns the starting and ending character indexes of the matching
    expression'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lastindex`: Returns the index of the last matched expression'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`groupdict()`: Returns the matching group dictionary with a pattern string
    and matched values'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`groups()`: Returns all matching elements'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`group()`: Returns an individual group and can be accessed with the group name'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lastgroup`: Returns the name of the last group'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Patterns can also specify string names for the groups they are in; for example,
    `r'(?P<year>[0-9]{4})'` matches the `year` group. Using group-based patterns in
    Regex helps us to read the pattern and manage the output more accurately; this
    means that we don't have to worry about indexing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider the patterns `pDate` (implementing `group()`, `groupdict()`,
    `start()`, `end()`, `lastgroup`, and `lastindex`) with a group name and code that
    are exhibiting the outputs for date and time, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code shows the use of `pTime` (implementing `span()`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: In this section, we have covered a general introduction to Regex and the features
    of the `re` Python library, along with some practical examples. Please refer to
    the *Further reading* section for more information regarding Regex. In the next
    section, we will be applying Regex to extract data from web-based content.
  prefs: []
  type: TYPE_NORMAL
- en: Using regular expressions to extract data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we've covered the basics and had an overview of Regex, we will use
    Regex to scrape (extract) data in bulk in a similar manner to using XPath, CSS
    selectors, `pyquery`, `bs4`, and so on by choosing between the implementation
    of Regex, XPath, `pyquery`, and more. This depends on the requirements and feasibility
    of web access and the availability of the content.
  prefs: []
  type: TYPE_NORMAL
- en: It's not always a requirement that the content should be unstructured to apply
    Regex and extract data. Regex can be implemented for both structured and unstructured
    web content that's found in order to extract the desired data. In this section,
    we'll explore a few examples while using Regex and its various properties.
  prefs: []
  type: TYPE_NORMAL
- en: Example 1 – extracting HTML-based content
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this example, we will be using the HTML content from the `regexHTML.html` file
    and apply a Regex pattern to extract information such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: HTML elements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The element's attributes (`key` and `values`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The element's content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This example will provide you with a general overview of how we can deal with
    various elements, values, and so on that exist inside web content and how we can
    apply Regex to extract that content. The steps we will be applying in the following
    code will be helpful for processing HTML and similar content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code is the HTML page source we will be using. The content here
    is structured, and there are numerous ways that we can deal with it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, we will be using functions such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`read_file()`: This will read the HTML file and return the page source for
    further processing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`applyPattern()`: This accepts a `pattern` argument, that is, the Regex pattern
    for finding content, which is applied to the HTML source using `re.findall()`
    and prints information such as a list of searched elements and their counts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To begin with, let''s import `re` and `bs4`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, `page` is an HTML page source that''s read from an HTML file using `read_file()`.
    We have also imported `BeautifulSoup` in the preceding code to extract individual
    HTML tag names and just to compare the implementation of code and results found
    by using `soup.find_all()` and a Regex pattern that we will be applying:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: For finding all of the HTML tags that exist inside `page`, we used the `find_all()`
    method with `soup` as an object of `BeautifulSoup` using the `lxml` parser.
  prefs: []
  type: TYPE_NORMAL
- en: For more information on Beautiful Soup, please visit [Chapter 5](5869ee86-6c67-4e6f-8151-61093795d94f.xhtml),
    *Web Scraping using Scrapy and Beautiful Soup*, the *Web scraping using Beautiful
    Soup* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we are finding all HTML tag names that don''t have any attributes. `\w+` matches
    any word with one or more character:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Finding all HTML tags or elements that don''t end with *`>` *or contain some
    attributes can be found with the help of the space character, that is, `\s`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, by combining all of these patterns, we are listing all HTML tags that
    were found in the page source. The same result was also obtained in the previous
    code by using `soup.find_all()` and the `name` attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s find the attribute''s name, as found in the HTML element:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, there were only 10 attributes listed. In the HTML source, a few
    tags contain more than one attribute, such as `<a href="https://www.google.com"
    style="color:red;">Google</a>`, and only the first attribute was found using the
    provided pattern.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s rectify this. We can select words with the `=` character after them
    by using the `r''(\w+)=''` pattern, which will result in all of the attributes
    found in the page source being returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, let''s find all of the values for the attributes we''ve found. The
    following code lists the values of the attributes and compares the `18` attributes
    we listed previously. Only `9` values were found. With the pattern we used here, `r''=\"(\w+)\"''` will
    only find the word characters. Some of the attribute values contained non-word
    characters, such as `<a href="https://www.google.com" style="color:red;">`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Here, the complete attribute values are listed by using the proper pattern we
    analyzed. The content attribute values also contained non-word characters such
    as `;`, `/`, `:`, and `.`*.* In Regex, we can include such characters in the pattern
    individually, but this approach may not be appropriate in all cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the pattern that includes `\w` and the non-whitespace character, `\S`, fits
    perfectly, that is, `r''=\"([\w\S]+)\"`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let''s collect all of the text inside the HTML elements that are found
    in-between the opening and closing HTML tags:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: While applying Regex to the content, preliminary analysis for the type of content
    and the values to be extracted is compulsory. This will help to obtain the required
    results and can be done in one attempt.
  prefs: []
  type: TYPE_NORMAL
- en: Example 2 – extracting dealer locations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this example, we will be extracting content from [http://godfreysfeed.com/dealersandlocations.php](http://godfreysfeed.com/dealersandlocations.php).
    This website contains dealer locations information, which is shown in the screenshot
    that follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: For this and the other examples in this section, we will be using the `re` and
    `requests` libraries in order to retrieve the page source, that is, `pageSource`.
    Here, we will be using the `read_url()` function to do so.
  prefs: []
  type: TYPE_NORMAL
- en: 'The page contains HTML `<form>` elements so that we can search for dealers
    based on the `zipcode` entered. There''s also a geographic map with markers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/6a8edbca-0e35-4112-8341-44add5a180f2.png)'
  prefs: []
  type: TYPE_IMG
- en: Godfreysfeed Dealers front page
  prefs: []
  type: TYPE_NORMAL
- en: You can either perform form submission with `zipcode` or extract content from
    the map.
  prefs: []
  type: TYPE_NORMAL
- en: 'By analyzing the page source, we will find that there''s no HTML elements with
    dealers'' information. Implementing Regex fits this case perfectly. Here, dealers''
    information is found inside JavaScript code with variables such as `latLng` and
    `infoWindowContent`, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/5026c2bb-c5ec-42a4-ad46-e7d3c9d53192.png)'
  prefs: []
  type: TYPE_IMG
- en: Godfreysfeed Dealers page source
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now proceed with loading the page source for the desired URL and implementing
    Regex to find data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'With the page source obtained from `read_url()`, let''s do a basic analysis
    and build a pattern to collect latitude and longitude information. We will need
    two distinct patterns for the dealer''s address and coordinate values, respectively.
    Output from both patterns can be combined to obtain the final results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'By using the `pLatLng` pattern, a total of `55` coordinate values were found:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the dealer''s coordinates, let''s find out the dealer''s name,
    address, and more:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'There was also a total of `55` pieces of address-based information, which was
    found by using the `pDealers`pattern.Note that the dealer''s content is in HTML
    format and that further implementation of Regex will be required to obtain individual
    titles such as `name`, `address`, and `city`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have results from both `latlngs` and `dealers`, let''s collect
    the individual portions of the dealer''s address. Raw data for the dealers contains
    some HTML tags, and has been used to split and clean the dealer''s address information.
    Since `re.findall()` returns the Python list, indexing can also be useful for
    retrieving address components:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, `dataSet` will contain an individual dealer''s information that''s
    been merged from `dealers` and `latlngs` in the listing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we tried to extract data using different patterns and retrieved
    a dealer's information from the URL provided.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3 – extracting XML content
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this example, we will be extracting contents from the `sitemap.xml` file,
    which can be downloaded from **[https://webscraping.com/sitemap.xml](https://webscraping.com/sitemap.xml)**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/060d674a-0e48-4325-b8a3-720edd7f4a0a.png)'
  prefs: []
  type: TYPE_IMG
- en: The sitemap.xml file from https://webscraping.com
  prefs: []
  type: TYPE_NORMAL
- en: 'By analyzing the XML content, we can see that different types of URLs exist
    as child nodes, that is, `<loc>`. From these URLs, we will be extracting the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Blog URLs (URLs with a `/blog/` string, such as [https://webscraping.com/blog/Why-Python/](https://webscraping.com/blog/Why-Python/))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Titles obtained from the blog URLs (*Why-Python*)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Category URLs (URLs with a `/category/` string, such as [https://webscraping.com/blog/category/beautifulsoup](https://webscraping.com/blog/category/beautifulsoup))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Category titles obtained from category URLs (*beautifulsoup)*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blog titles and category titles that are obtained from code are retrieved from
    the URL or representations of the real content that's available from the URL.
    Actual titles might be different.
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin with, let''s import the `re` Python library and read the file''s contents,
    as well as create a few Python lists in order to collect relevant data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'From the XML content, that is, `page`, we need to find the URL pattern. `pattern`
    used in code matches and returns all of the URLs inside the `<loc>` node. `urlPatterns`
    (`<class ''list''>`) is a Python list object that contains searched URLs and is
    iterated to collect and process the desired information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Now, let's match a `url`, such as [https://webscraping.com/blog/Google-App-Engine-limitations/](https://webscraping.com/blog/Google-App-Engine-limitations/),
    which contains a `blog` string and append it to `dataSetBlogURL`. There are also
    few other URLs, such as [https://webscraping.com/blog/8/](https://webscraping.com/blog/8/),
    which will be ignored while we extract `blogTitle`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, any `blogTitle` that''s found as text equal to `category` will be ignored.
    The `r''blog/([A-Za-z0-9\-]+)` pattern matches alphabetical and numerical values
    with the `-` character:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s the output for `dataSetBlogURL`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '`dataSetBlog` will contain the following titles (URL portion). The `set()`
    method, when applied to `dataSetBlog`, will return unique elements from `dataSetBlog`.
    As shown in the following code, there''s no duplicate title inside `dataSetBlog`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s extract information that''s relevant to the URL by using `category`.
    The `r''.*category''` Regex pattern, which matches `url` from the iteration, is
    collected or appended to `datasetCategoryURL`. `categoryTitle` is extracted from
    `url` that matches the `r''category/([\w\s\-]+)` pattern and is added to `dataSetCategory`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '`dataSetCategoryURL` will result in the following values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the following output displays the title that was retrieved from `dataSetCategory`,
    as well as its counts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: From these example cases, we can see that, by using Regex, we can write patterns
    that target specific data from sources such as web pages, HTML, or XML.
  prefs: []
  type: TYPE_NORMAL
- en: Regex features such as searching, splitting, and iterating can be implemented
    with the help of various functions from the `re` Python library. Although Regex
    can be implemented on any type of content, unstructured content is preferred.
    Structured web content with elements that carry attributes are preferred when
    using XPath and CSS selectors.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about regular expressions and their implementation
    by using the `re` Python library.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we've learned about various scraping-based tools and techniques. Regex
    can provide more flexibility when it comes to extraction tasks and can be used
    with other tools.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will be learning about further steps and topics that
    could be beneficial in a learning context, such as managing scraped data, visualization
    and analysis, and an introduction to machine learning and data mining, as well
    as exploring some related resources.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Regular Expression HOWTO: [https://docs.python.org/2/howto/regex.html](https://docs.python.org/2/howto/regex.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regular Expressions – JavaScript: [https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python Regular Expressions: [https://developers.google.com/edu/python/regular-expressions](https://developers.google.com/edu/python/regular-expressions)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Online Regex Tester and Debugger: [https://regex101.com/](https://regex101.com/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Regular Expressions Cookbook: 2nd Edition, 2012* by Jan Goyvaerts and Steven
    Levithan'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regular Expressions References: [https://regexone.com/references/python](https://regexone.com/references/python)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regular Expressions – Information: [http://www.regular-expressions.info/python.html](http://www.regular-expressions.info/python.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
