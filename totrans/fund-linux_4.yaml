- en: Working with the Command Line
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we'll learn about more fundamental commands every Linux user
    should know, then we will learn how to install other important third-party Linux
    programs. We will also learn about processes and signals, introduce you to Bash
    shell scripting, and finally, show you how you can automate the execution of your
    Bash shell scripts.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll be covering the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Essential Linux commands
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additional programs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding processes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Signals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with Bash shell variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bash shell scripting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Essential Linux commands
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will learn more essential Linux Bash commands that every
    Linux user should know. Use the `cat` command to quickly cut columns out of text
    files. This is like a light version of awk.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll be discussing the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '`cat`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sort`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`awk`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tee`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tar`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other miscellaneous commands
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'First, let''s create a smaller version of the `passwd` file to work with the
    `cat` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/88408c56-6030-42df-ae10-e606d5343a63.png)'
  prefs: []
  type: TYPE_IMG
- en: '`-d` sets the field delimiter; by default it''s the tab character. `-f` uses
    a single field number or comma-separated list of field numbers that you want to
    extract. If using comma-separated lists also, the split input delimiter will be
    output, which can be changed using `-- output-delimiter`.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's create a smaller version of the `services` file without comments
    and empty lines. Using the `cat` command is very limited to the special use case
    that a file separator is a single character, such as a colon or the tab character.
    For splitting text files as multiple consecutive whitespace characters, which
    are often used in Linux config files, for example, in the `/etc/services` file,
    the `cat` command does not work. Also, when using the `cat` command, the field
    order must be fixed in every line or you will run into problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, you can see that the `services` file contains
    no tab separator, but multiple whitespace characters marked with the star character:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3d5e6dd5-5e05-4a45-a30d-19eb05bf2635.png)'
  prefs: []
  type: TYPE_IMG
- en: If you use `cat` on this file, it will produce nothing but garbage. To split
    files with multiple consecutive whitespaces, use `awk` instead. The `tr` command
    is like a lightweight version or subset of the set substitute mode. It translates
    a character set one into a character set two, reading from `stdin` and outputting
    to `stdout`. The syntax is self-explanatory. You can translate both single characters
    and ranges of characters. The character sets are similar to POSIX regular expression
    classes; read the manual to find out more.
  prefs: []
  type: TYPE_NORMAL
- en: Let's discuss the `sort` command. The `sort` command sorts the text file line
    by line. By default, it takes the whole line into account for sorting. The `-u`
    flag only prints out unique fields. If we take a file that has numbers instead
    of alphanumeric values, by default, `sort` expects alphanumeric values, so the
    sorting of numbers is wrong or unnatural. To fix this, use the `-n` option, which
    sorts using numbers. To sort values from bottom to top, use the `-r` flag. You
    can also influence the sort column if you need. `sort` always takes the whole
    line into account. To fix this, use the `-k 2.2` option to sort by the second
    column. There are many more sort options. Refer to the manual to find out more.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, in order to combine the power of `cat` or `awk`, `sort` and `unique`,
    let''s use these tools together to print the 10 most recurring service names from
    the `/etc/services` file while ignoring comments and empty lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bc2915cf-f480-4875-a2cc-c8450e975445.png)'
  prefs: []
  type: TYPE_IMG
- en: The second command should now be pretty self-explanatory. As you can see, `discard`,
    `exp1`, and `exp2` are the most recurring service names in the `/etc/services`
    file with four occurrences. To count all lines in the file, use the `wc` for the
    word count command. To extract the pure filename from a path, use the `basename`
    command, which is often used in scripts, as we will see later. If you know the
    extension of a file, you can also use the `basename` command to extract the filename
    from the extension. Similarly, to extract the path name, use the `dirname` command.
    To measure the time a command needs, execute the prefix of your command with the
    `time` command. To compare two files, use the `diff` command, which will print
    an empty output. If these files are identical, there will be no output. Otherwise,
    the changes between the files will be shown. The `diff` command can also be used
    for comparing two directories, file by file, using the recursive flag, which will
    go through all the files from A and compare them to the corresponding size files
    from B with the same name in folder B. The command that can be used to print out
    where a specific command is located in the filesystem is based on the `/path`
    variable, which we will see later.
  prefs: []
  type: TYPE_NORMAL
- en: '`tee` is a useful command, which can be used to store an `stdout` command in
    a file, as well as print it on the command line. It is useful for keeping a record
    of an output while also seeing what''s going on at the same time. Just give the
    `tee` command the filename you want to write to as an argument. To compress a
    single file, which means reduce the file size, use `gzip`. To uncompress, use
    the `gunzip` command.'
  prefs: []
  type: TYPE_NORMAL
- en: To compress a complete subdirectory, recursively use the `tar` command. Note
    that the `f` option must be the last option followed by the archive name you want
    to create as the first argument and then the directory you want to archive and
    compress as the second argument. To extract an archive to any following directory,
    use the `tar` command with the following flag, `-C` is the output directory. `hostname`
    prints out the hostname; `uptime` prints out how long the server computer is powered
    on, and `uname` prints system information such as the kernel version.
  prefs: []
  type: TYPE_NORMAL
- en: In the `/etc/redhat-release` file, you will find the version of Red Hat Enterprise
    that this CentOS 7 is based on. In the `/prog/meminfo` file, you will find memory
    information, for example, how much RAM you have. In `/proc/cpuinfo`, you will
    find information about your CPUs and cores. `free -m` prints out useful memory
    information, for example, how much free RAM you've got. `df` prints out information
    about the available disk space. `du -page` prints out how much space the files
    in the current directory take. If you use it with the `max-depth=1` option, you
    will also get a summary of the folder content. `users` print out all the users
    currently logged in to the system. The `whoami` command prints the name of the
    user who is currently using this Terminal.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we'll see some very useful commands. To print the current date and time,
    use the `date` command. Use `+%s` to generate a unique timestamp. To print out
    a calendar, use the `cal` command. To pause, interrupt the shell execution using
    the `sleep` command. The `dd` program, or disk dump, is a very essential tool
    every Linux user needs to know. It is used to copy data from an input file or
    device to an output file or device. We have used `dd` before, in the first section,
    to override the filesystem's free space with zeros so we can shrink our VM images,
    but there are many more use cases for the `dd` command. `dd` basic syntax uses
    `if` for input file and `of` for output file as arguments. Also, two options are
    very important, the block size and the count.
  prefs: []
  type: TYPE_NORMAL
- en: You will see that the block size, which means the amount of data read at once,
    is 1 MB, and the count is the amount of repetitions of the block size, so that,
    in our example, 1 MB multiplied by 1,024 equals exactly 1 GB. `dd` also supports
    reading from `stdin` and writing to `stdout` so that the command we just used
    can be rewritten as `dd if=/dev/zero of=/tmp/1gig_file.empty bs=1M count=1024`.
    You can use `dd` not only with device files, but also to copy normal files. Also,
    you can use it for creating images of whole partitions, for example, for backups.
    To access partitions, the root account is needed.
  prefs: []
  type: TYPE_NORMAL
- en: Additional programs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will show you some other very important Linux commands you
    don't want to miss. These programs are not included in the CentOS 7 minimal installation,
    so we first need to install it in order to install them. This section is about
    learning additional command-line programs. Additional because these tools are
    not included in the CentOS 7 minimal installation, so let's first install all
    of these programs using the CentOS 7 package manager, `yum`. In order to install
    new software, the root user is needed. So, first log in as `root`. Before we start,
    let's install the `epel` repository, which is an additional third-party repository
    for software that is not found in the official CentOS 7 sources, but is highly
    trustable and secure.
  prefs: []
  type: TYPE_NORMAL
- en: First, let's install some tools to make our user life easier. `rsync` is a file
    transfer program, `pv` is the pipe viewer; `git` is for version control; `net-tools`
    contains tools to display network information; `bind-utils` contain tools to query
    DNS information; `telnet` and `nmap` are for basic network troubleshooting; `nc`
    stands for netcat, `wget` is used to download files from the internet; and `links`
    is a command-line web browser.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's install some programs that give you a kind of life view on the system.
    This will install `htop`, `iotop`, and `iftop`. Finally, let's install some essential
    tools, which are screen, a calculator, `bc`, and `lsof`. First, let's introduce
    `rsync`. Every Linux user needs to know it as it's an awesome tool with many useful
    features. Basically, `rsync` is a file transfer program, but it does not simply
    copy files between a source and destination; instead, it synchronizes them, which
    means it only transfers a file if the source file is different from the destination
    qfile. This saves a lot of data overhead and time. I often use `rsync` with the
    `-rav` flags, which is the default to copy files verbosely and recursively with
    a common set of parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '`cp` copies the `olip-home` folder to a new location recursively. Now, if you
    change the source file and restart the copying process afterward, `rsync` first
    checks whether there are any differences in the source and destination files,
    and only transfers changes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a9ee4c73-daff-4518-9f4f-823242a6af94.png)'
  prefs: []
  type: TYPE_IMG
- en: As shown in the preceding screenshot, we touch the `bashrc` file in the `olip-home`
    directory, which means update the file's timestamp, and afterward `rsync` checks
    and sees that the `bashrc` file has an updated timestamp, so the file gets transferred
    to the destination again because it's different. To copy files remotely to another
    server running the SSH service, and `rsync` is installed, use the following syntax: `rsync
    -rav`. As you can see, the colon at the end of the IP address starts the destination.
    Here, we will copy the `olip-home` directory to the `/tmp` directory and the other
    way around, to copy remote files to the local server, using `rsync .rav /home/olip/
    /tmp/new-olip-home`. `rsync` has a lot of different features and is just awesome.
    You can refer to the manual to learn more about it. Another example of useful
    tools that I often use is the `-- progress` flag, which shows you the progress
    of the file transfer. `pv` is the pipe viewer, which is a very useful program
    to display traffic through `stdout`. For example, we can use it to display progress
    when piping big amounts of data streams, for example, using the `dd` command.
    `git` is a program for file version control, which can help you keep track of
    your file versions, as well as be used for installing programs from the Git repositories,
    such as the very popular GitHub service. For example, we can download the latest
    `pv` source code using the following command: `$ git clone https://github.com/icetee/pv.git`.
  prefs: []
  type: TYPE_NORMAL
- en: net-tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`net-tools` is a collection of important tools for displaying network-related
    information, such as `netstat` to print network information, or the `route` command
    to view the IP routing table. The `bind-utils` we just installed contain programs
    to browse DNS information, for example, to see whether a certain port is open
    on a domain, such as port `80` on [https://www.google.com](https://www.google.com);
    you will get some connection details. Type the *Esc* key to exit. `wget` is one
    of the most essential tools every system administrator needs to know. It can be
    used to download files from the internet. For example, to download a random programming
    command from HTTP to `stdout`, use the following command line: `wget -q0- http://whatthecommit.com/index.txt`,
    or type the following directly into a new file: `wget -0 /tmp/output.txt http://whatthecommit.com/index.txt`.'
  prefs: []
  type: TYPE_NORMAL
- en: Nmap
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Nmap is another very useful tool that can be used to troubleshoot or get information
    about your network. It scans the computer network and discovers and collects all
    kind of information about other hosts connected to it. Note that port scanning
    a network is a very controversial topic; since improperly using `nmap` can get
    you sued, fired, banned by your country, or even put in jail, we will only use
    it to retrieve very valuable information about our own private network here. For
    example, to scan the network for all available hosts and open ports, use the syntax: `nmap`
    network address.
  prefs: []
  type: TYPE_NORMAL
- en: You will see few IP addresses available that have various ports and services
    open. This can give you very important information about who is connected to your
    network and whether the services and computers are secure and not exposing unwanted
    details. `nc` or netcat is another very useful tool to help you debug and troubleshoot
    your server's network and firewall settings. For example, you can use it to see
    whether a certain port is open on a server. On the server, you want to verify
    the use, for example, the following command is used to open port `9999` and put
    a text file stream behind this port: `nc -l -p 9999 < /etc/redhat-release`. On
    any other server in this network, you could then try to access the server, for
    example, with the IP address `197`, then with the IP address `192.168.1.1.200`
    on port `9999` and stream this file back, using the following `nc` command: `nc
    192.168.1.200 9999 > /tmp/redhat-release`.
  prefs: []
  type: TYPE_NORMAL
- en: links
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this sub-section, we''ll learn about `links`—the command-line web browser.
    To open the DuckDuckGo search website using the links program, use the following
    command line: links [https://duckduckgo.com/](https://duckduckgo.com/). This will
    open the links web browser. Move the cursor up and down to reach the DuckDuckGo
    text search field. Now, you can type in your search term as you would on the normal
    DuckDuckGo website and then press *Enter* key to start your search. Again, use
    the up and down arrow keys to jump to the result of the search you want to browse
    to. Learning links navigation and shortcuts is outside of the scope of this book.
    Read the manual pages to find out more. Press the *q* key to exit links, and then
    confirm your choice by pressing the *Enter* key.'
  prefs: []
  type: TYPE_NORMAL
- en: iotop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To get a live view of the input and output, or short I/O, bandwidth usage of
    your system, type `iotop`. iotop needs to be started with the root user. You can
    use `iotop`, for example, to learn how fast your hard disk can read and write,
    then press the *q* key to exit. Read the manual section on `iotop` to learn more
    about its shortcuts, for example, for sorting columns.
  prefs: []
  type: TYPE_NORMAL
- en: iftop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's learn about the `iftop` program, which gets a live view on network traffic
    and network bandwidth usage and monitor. Again, this tool needs to be started
    with the root user account. As you can see, network traffic can be displayed with
    this tool, press the *q* key to quit the program. Read the manual section on `iftop`
    to learn more about its shortcuts.
  prefs: []
  type: TYPE_NORMAL
- en: htop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, let's start `htop`, which is similar to the famous top program to view
    processes interactively. `htop` is the improved version of the normal top program,
    which adds new features such as scrolling vertically and horizontally so that
    you can see all the processes running on your system along with the full command
    lines. The `htop` program shows you a lot of different information about your
    system. Press the *q* key to quit the program. There are a lot of different shortcut
    options to learn; read the manual pages to learn more.
  prefs: []
  type: TYPE_NORMAL
- en: lsof
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To print out a list of all open files, which means programs accessing files
    at the moment, use the `lsof` command. You'll get a long list; it's best to use
    it with `grep` to filter the content. To quickly do some math calculations on
    the command line, use the PC calculator. `screen` is a very useful command to
    detach from an SSH connection without actually disconnecting or exiting from it,
    which is very useful to pause your work and later go back to exactly the same
    point where you left, or to work from another computer. This can save a tremendous
    amount of time. First, in order to create a new detachable session, type `screen`.
    Now do your work, for example, type a text in VI. Now, imagine your day at work
    is over and you go home. Without the screen, you would now need to save your changes,
    close VI, and logout from the server. With a screen, just use the key combination
    *Ctrl* + *A* + *D* to detach from the current SSH session. If you have successfully
    detached from a session, a line will appear saying `detached from` and then the
    screen session ID. Now, in order to prove that we can reattach to this session,
    just log out from the server and then log back in to the server. Then, back on
    the server type screen -list to get a list of all the detached screens. To reattach
    to your screen, use the screen ID: `$ screen -r 23433.pts-l_localhost`. As you
    can see, we are exactly back where we left off. If you want to stop your screen
    session, type `exit`. Here, we showed you the most fundamental use cases for these
    programs.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding processes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will show you how processes work in Linux. Now, let's discuss
    everything about processes. Every program in a Linux system that is currently
    running is called a process. One single program can consist of multiple processes,
    and the process can start other processes. For example, as we already know, the
    Bash shell itself is a command, so, when started, it gets a process. Each command
    you start in this shell is a new process started by the shell process. So, for
    example, each time we execute the `la -al` command, the Bash shell process creates
    a new process in which the `ls -al` command is running. There are many, processes
    running all the time on every Linux system. If you have a multiprocessor CPU computer,
    some of those processes really are physically running in parallel all the time.
    Other processes, or if you have a single processor CPU, are running only semi-parallel,
    which means every process only runs for a few milliseconds on the CPU then pauses,
    which is also called being put to sleep, so the system can execute the next process
    for a small period of time. This system allows the execution of all processes
    seemingly in parallel, when in reality they are processed sequentially one after
    another.
  prefs: []
  type: TYPE_NORMAL
- en: All processes in a Linux system get created by another process so that every
    process has a parent process that created it. Only the first process does not
    have a parent, which in CentOS 7 is the `systemd` process. To get a list of all
    the running processes, run the `ps` command. Herem we use it with the `-ev` option
    and pipe its output into the `less` command as it does not fit the screen. You'll
    see that every process has a unique identifier, which is called the process identifier,
    or PID for short. The first process, the systemd process, has the PID of 1\. The
    subsequent ones are in increasing order. Every process has a user ID associated
    to it, and also every process has a parent denoted by the parent process ID column.
    You'll notice that the first two processes in the list have a parent PID of 0,
    which means they don't have a parent.
  prefs: []
  type: TYPE_NORMAL
- en: To get a better understanding of the parent-child process relationship, you
    can use the `pstree` command, which we first need to install using the `psmisc`
    package. Afterward, just start the `pstree` command. With it you get a better
    understanding of which parent process created which child process, and how the
    relationship between the processes is. As said before, the systemd process is
    the first process in the system, which created all the other processes in the
    system. Every process also has a state; type `man ps` and go to the state section.
    The most important states are `running`. This means the process is currently running
    and will get executed by the CPU, or is in the run queue, which means it's just
    about to be started. You will see `sleeping` if the process execution is interrupted
    in favor of the next process in the waiting queue, or `stopped`, and even `defunct`
    or `zombie`, which means that the process terminated but the parent process does
    not know about it yet.
  prefs: []
  type: TYPE_NORMAL
- en: As we have learned in the previous section, you can also use the `top` or `htop`
    command to get a dynamic or real-time view on the processes in your system. The
    state column shows you the state of the process, where `r` stands for running,
    `s` for sleeping, and so on. If a new process gets created, the parent process
    will be cloned or copied exactly to the child process, so it has exactly the same
    data and environment as the parent process. Only the PID will be different, but
    the parent and child process are completely independent from each other.
  prefs: []
  type: TYPE_NORMAL
- en: Cloning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cloning a process is also called **forking** in Linux. For example, if you execute
    a command, such as the `sleep` command in the shell, a new process gets created
    identical to the parent Bash shell process in which the `sleep` command gets executed.
    Normally, the parent process, in our example the Bash shell process, waits until
    the child process has been finished. That is why you don't get an interactive
    cursor as long as your subprocess is running. This is the normal behavior for
    every command you run in the shell. If your Bash command-line prompt is blocked,
    this is also called running a foreground job. To kill this foreground job, press
    *Ctrl* + *C*. You can also influence this foreground behavior by setting the ampersand
    symbol at the end of any command. So, let's rerun the last command with the ampersand
    sign. When using the ampersand sign at the end of the command, the parent process
    does not wait until the child process finishes, but both processes now run in
    parallel. This is also referred to as running a process in the background. You'll
    notice that running a process in the background returns the process ID of the
    child process, so we can reference it later. For example, for killing it, use
    `kill` command. In order to put the last background job into the foreground, again
    type `fg` and press the *Enter* key. Now, our `sleep` command is back in the foreground.
    To put it back into the background, press *Ctrl* + *Z*. This does not put our
    process running in the foreground directly into the background, but rather suspends
    the process. To put a suspended process into the background type `pg`, or in the
    foreground type `fg`. In order to kill any suspended or background job, you can
    use the `kill` command. Our processes running in the background are also called
    **jobs**. In order to list all the jobs you currently have in your Terminal, you
    can use the `jobs` command. If you have any running jobs in the background, the
    output will be shown from which you can reference it using the number in the brackets.
    In order to address such a job ID, you need to prefix it with a percentage sign.
    For example, to kill the job with the job ID number 1, type `kill %1`. Note that
    the `pg`, `fg`, and `kill` commands that we just used only work when you only
    have one single current background job in the Terminal. If you are working with
    multiple jobs in the current Terminal, you need to address them individually using
    the percentage sign.
  prefs: []
  type: TYPE_NORMAL
- en: Signals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Signals are used for communication between processes. If you start a new process,
    how can you communicate with it through your shell or any other program or process
    while it is running? Also, how does the parent process know when the child process
    is finishing? For example, how does your Bash know when the `ls -al` command is
    terminating? In Linux, this kind of notification and interprocess communication
    is done using signals. In Linux, if a process starts another process, the parent
    process is put to sleep until the child process command has finished, which will
    trigger a special signal and this will wake up the parent process. The parent
    process is put to sleep so that no active CPU time is needed for waiting. A popular
    signal is the seek or interrupt signal, which will be sent to the running process
    each time we press *Ctrl* + *C* in an active program. This will interrupt and
    stop the process immediately. Another signal we have already sent is the signal
    to trigger by pressing *Ctrl* + *Z* to suspend a process so that we can put it
    in the background. Instead of using key combinations to send a signal, you can
    also directly use the `kill` command to send various signals to a running process.
  prefs: []
  type: TYPE_NORMAL
- en: kill
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To get a list of all the available signals which one can send to a process
    use `kill -l`. For example, the standard signal to send to a program to kill it
    is the `SIGKILL` signal, which has the signal ID 9\. So, let''s first create a
    new process and then kill it; as an example, start a new sleep process in the
    background. As you already have learned, putting a process into the background
    prints out the process ID. Most of the time, we use the `kill` command to kill
    system processes, which usually are not started by our user. So a standard way
    to retrieve is using the `ps` option, `aux`, and then filter by the name of the
    process you want to kill. Using `ps` with the option `aux` prints out the full
    command line, which often is helpful to differentiate the right process because
    often there are multiple processes with the same command name in this list. In
    our example, we only have one sleep process running and we can confirm the right
    process ID. Now, in order to kill this process, use `kill -9` for sending the
    `SIGKILL` signal and then the process ID. Let''s confirm this using the `ps` command
    again:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e51b61bc-e449-4a4e-a70a-2319c1403587.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the `sleep` command has been successfully killed. In the previous
    section, we use the `kill` command with the percentage job ID, but what is the
    difference in  using the `kill` command with the PID instead of the job ID? Background
    and suspended processes are usually manipulated via the job number or job ID.
    This number is different from the process ID and is used because it is shorter.
    Killing processes using the PID is most often used to kill malfunctioning system
    processes using the root account. In addition, a job can consist of multiple processes
    running in a series or at the same time in parallel. Using the job ID is easier
    than tracking individual processes.
  prefs: []
  type: TYPE_NORMAL
- en: hang-up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finally, let's discuss the `SIGUP` signal, or the hang-up signal. In CentOS
    7, if you run a program in the background, like the `sleep` command, and log out
    of the system, then log in again, you'll see the command or process still running.
    So, in CentOS 7, we can easily run background processes and log out of the SSH
    session, which is useful to run programs that need to run all the time or to do
    some heavy calculations that take hours, days, or even months. In other Linux
    distributions, if you log out of the system, the kernel will send the hang-up
    signal, or in short `SIGUP`, to all running background processes and terminate
    them. In such systems, to disable the hang-up signal that is sent to your processes,
    use `nohup`; prefix your command with the `nohup` command, such as `nohup sleep
    1000 &`. This way you can safely log out of the system and your job will not stop
    running. But, as mentioned before, on a CentOS 7 system, you don't have to do
    this.
  prefs: []
  type: TYPE_NORMAL
- en: Working with Bash shell variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will introduce you to Linux Bash shell variables. Bash shell
    variables are a great way to give symbolic names to any dynamic values, so we
    can reference values by a name. This helps to create very flexible and convenient
    systems where you often only have to change a single value, and all processes
    on your computer accessing this value can change their behavior automatically.
    Using shell variables provides a simple way to share configuration settings between
    multiple applications and processes in Linux, as we will see in the next section.
    To define a new environment variable, use the following syntax `MY_VALUE=1`, name
    of the variable equals, then the value. All Bash shell variables must not contain
    spaces or special characters, and, by convention, often shell variables are all
    uppercase. To access the stored value of the shell variable, which is nothing
    more than a shell expansion of the stored value, prefix the variable with the
    dollar sign. You can also look at shell variables as containers for dynamic values.
    You can also change the value of a shell variable anytime if you want. You can
    also copy a shell variable's content to another variable using the following syntax: `MY_NEW_VALUE=$MY_VALUE`.
    To unset a shell variable's content, use the `unset` command. For assigning shell
    variables, the same quoting and escaping rules apply as for any other Bash topics
    we have learned in the shell quoting and globbing sections in the previous chapters.
    For example, first assign the string `b` to the shell variable `a`. Now, for embedding
    spaces in the string, quotes must be used. Other shell expansions such as other
    shell variables can also be expanded in the assignment of a string. For embedding
    double quotes in a string, use single quotes to surround. There are a number of
    predefined and global shell environment variables to configure system-wide settings,
    such as `home`, `path`, `shell`, and so forth.
  prefs: []
  type: TYPE_NORMAL
- en: While there are no official standard for most environment variables in Linux,
    a lot of programs are using common variable names. For example, if you set a value
    for the `PROXY` environment variable, all programs and services that make use
    of this variable can now access this new centralized information without the need
    for you to tell each program or service individually that something has changed.
    Another very important system environment variable is the `PATH` variable. It
    is used by the Bash shell itself. It contains all the paths separated by a colon
    where the Bash shell tries to look up places for executable files, so you don't
    have to provide the full path for a command, which is included in this path. For
    example, if we create a new script file in a new local script folder called `my-script.sh`,
    we need to provide its full name location in order to execute it; there is no
    other way we can execute a script. But we cannot run it, for example, from the
    `/tmp` directory because Bash cannot find it in its path. Now, if we add the script's
    location to the path environment variable, we are able to run our script from
    everywhere without having to provide the full path, and even autocomplete is working.
    But what is the difference between a Bash shell variable and an environment variable?
  prefs: []
  type: TYPE_NORMAL
- en: 'Normal shell variables are not part of the so-called process environment or,
    in other words, they are not visible in any sub or child process. This is because
    when executing a process, only the environment gets cloned, and not the local
    shell variables. You can test this by creating the following shell variable using
    `MYVAR=helloworld` and then use it in the script that we will run as a subprocess:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7b5b9eba-a6f7-4014-bc58-0402c11b383b.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, we create a new shell variable called `MYVAR`, and then create
    a script that references or tries to access this environment variable. What happens
    now if we execute this script? As you can see, the child process, or subprocess,
    is not able to access the `MYVAR` Bash shell variable from the parent, but you
    can change this behavior by defining our `MYVAR` shell variable as an environment
    variable. Any child process gets a copy of the parent's environment during process
    creation, including all environment variables, but not the local shell variables.
    If you prefix the shell variable with the word `export`, the child process can
    access this environment variable because the environment is being copied from
    the parent process to the child process when a new process is created. But even
    environment variables like shell variables don't survive logging out of the system,
    which means that if you close your SSH session, all your defined variables are
    gone.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to create a system-wide environment variable that is present for
    every user and survives logging out of the system, put your variable into the `/etc/environment` file
    using your root user account. You can also make a shell variable available for
    a child process using the following syntax by prefixing the shell variable name
    before running the command, such as `MYVAR=NEW_Helloworld ~/scripts/local_var.sh`.
    This way you don''t have to define a shell variable as an environment variable.
    Another very important rule is that a child process will never be able to change
    the parent''s environment variables, because the child and parent are independent
    of each other, and the child only has a local copy of the parent''s environment.
    To test this out, try the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9c5ff27f-be37-4490-b6e5-59ff3f1859c0.png)'
  prefs: []
  type: TYPE_IMG
- en: First, let's clear all the possible former values a local child Bash shell variable
    has. Next, create a script that creates a new environment variable called `CHILDVAR`
    with the value `Hello_from_child`. Now, what happens if we execute the script?
    If we execute the script, the `CHILDVAR` environment variable will be set in the
    child process, and this `CHILDVAR` environment variable is not visible for the
    parent process. In summary, any shell variable or environment variable that you
    define in a script can never be seen in the parent process. If you want to make
    shell variables available from a child process to a parent process, first you
    need to create a so-called source file in your child process where you define
    your environment variables in `vi ~/scripts/child.sh`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, execute the script in your child process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/97fcd181-08af-46a4-b269-99fc37ed054b.png)'
  prefs: []
  type: TYPE_IMG
- en: This creates the source file for the parent process. Now, in the parent process,
    first we check whether the `CHILDVAR` environment variable is available. If it's
    not, let's source it using the `source` command. Finally, let's recheck whether
    the `CHILDVAR` environment variable is now accessible. If it is, then this is
    a valid way to create environment variables in a child process and make them available.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Bash shell scripting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will introduce you to the core concept of Bash shell scripting.
    Another very important feature of Bash shell scripts are functions. We use functions
    excessively in Bash shell scripts to make reoccurring tasks or commands reusable.
    Functions encapsulate a task to make it more modular. Functions usually take in
    data, process it, and return a result. Once a function is written, it can be used
    over and over again, but we can also work with functions on the command line.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s discuss the general syntax of a function by creating one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The first word is the function name followed by opening and closing brackets,
    which are used to define a function, followed by a curly opening bracket; all
    the commands belonging to a function are defined within the open and closing brackets,
    which is also called the function body. Functions can have arguments as normal
    commands, which will be accessible to the function body from outside. To access
    a certain argument in the function, use the dollar number notation. So `$1` is
    the first argument, `$2` would be the second, and so on. Let's take a look at
    our `say_hello` function. If we call this function with one argument, the function
    will be executed with one argument, and this argument will be taken in the function
    body, where we can access the first argument with the `$1` variable, which is
    nothing more than a normal shell expansion.
  prefs: []
  type: TYPE_NORMAL
- en: 'Functions can also call other functions in their body. Now, let''s learn to
    put your shell commands in a shell script file. Script files are just plain text
    files which contain different Linux commands, control structures, loops, and so
    on. Usually, they are written to solve everyday computer problems and fit your
    own individual needs instead of having to execute single commands one by one manually.
    There are two ways to execute a text file as a shell script. The first way is
    to use it as an argument for the Bash command. Another way to execute it without
    using it as an argument for the Bash command is to first make the script executable
    and then put the so-called shebang line at the first line, which tells the command
    line that this file is a Bash script and should be started with the Bash interpreter.
    In our example, `#!/bin/bash` is the shebang line and tells Bash that this is
    a Bash shell script. Now, to start it with the shebang approach, make it executable
    and then you can just run it on the command line, as following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to using functions, we can also access command-line arguments in shell
    scripts, such as `$ vi /tmp/new-script.sh`. The first argument can be accessed
    using `$1`, the second argument `$2`, and so on. In shell scripts, you can also
    access the name of the shell script using the `$0`. The total number of arguments
    can be accessed using the `$#`. So, for example, to write a check that your script
    needs at least two arguments do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'So, what this script does is check whether the number of command-line arguments
    are at least two and, if this is not the case, then a usage format will be printed
    out stating that you need two parameters, press *Enter*, and then an exit value
    of `1` will be returned, which means that this script has thrown an error, because,
    as we already know, a script will return `0` on successful execution. Let''s test
    this script out:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e74aa248-dede-4c8d-b5a6-e0a0fc11d9b6.png)'
  prefs: []
  type: TYPE_IMG
- en: If we start the script with only one argument, it will print out the usage format.
    However, if we start it with two arguments, it will correctly work. When it comes
    to shell scripting, there is much more to learn and we could only show you the
    very basics to get you started. You can refer to the Bash manual or just start
    reading the various shell scripts that are shipped with your Cent0S 7 OS for free.
    Type the following command to get a list of all the `.sh` files: `su -c 'find
    / -name "*.sh"'`, which is the default extension for shell script files in your
    system. Just start by opening one of the available shell script files in your
    system and try to understand it, for example, `/usr/libexec/grepconf.sh`.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Bash shell scripting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Besides the logical `and` and `or` expressions that we used in the previous
    section, if we need to make a decision based on a command's exit status, variable
    value, command output, and so on, we need to understand the `if` statement or
    conditional branch. In plain words, the `if` statement means that, based on some
    condition, our script or command line should perform one action, otherwise it
    should perform something else.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s work with the exit code from the previous section again to demonstrate:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e85d9ae2-c58a-4d0b-ba90-360496cda0f2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this example, we issued the `ls` command to see the content of the `oiip`
    home directory. We stored the exit status of the `ls` command in the `EXIT` Bash
    variable. In the next line, we now state the if condition. This can be read as:
    `if` the Bash variable `EXIT` equals `0`, then print out two lines of text, and
    this `if` condition with the reverse if word, fi. As you see, the two lines have
    been printed out, which means the if condition was true, so the exit value was
    `0`. It''s important to note that you have to be very careful that you set the
    spaces and new lines exactly as I did in the preceding example, but you can also
    put the complete if statement in one line, which you can see if you press the
    up arrow key to show the last command in the history. As you can see, the shell
    internally uses a semicolon space instead of new lines to separate most of the
    expressions, which is a bit hard to read, especially if you''re writing more complex
    Bash shell script one-liners. To negate any if expression which means that the
    `if` statement evaluates to true if the condition is not met, use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, the if condition can be read as: if the exit value equals
    not `0`, then print out the text. In our example, this is true because the exit
    value is `1`. If conditions can include a lot of different tests, which are too
    much to demonstrate here. Here, follow the most important ones. To test for equality,
    use the `-eq` test as we have just seen. You can use it for numbers. For string
    comparisons, use the `==` operator instead. You can also use the logical `and`
    and `or` expressions as introduced in the last section, for example, to also test
    for alternatives. This example can be read as: if the password equals to `Hello_my_world_555`
    or if the password equals to `my_secret_pass`. In this example, the password is
    correct. You can also use regular expressions using the equals tilde operator.
    This statement can be read as: the if condition is true if the string matches
    at the beginning of the line, where the first two characters are variables, but
    then there must be an `rem`, which is true. For numeric values, you can also test
    for less than or greater than numbers using `-lt` and `-gt` instead of `-eq`,
    for example, to test for less than or to test for greater than.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another group of very important if conditions are file tests. There exist vast
    number of very powerful file tests to see if a file or directory meets a special
    property. There are a vast number of very powerful file tests to see whether a
    file or directory, for example to test whether the file exists, use the `-a` file
    test, or to check whether a directory exists use the `-d` file test. This is shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e90b6248-ed1b-4803-98db-85f1d17a014c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To learn more about all the existing file tests, as well as all available comparison
    operators, open the Bash manual and search for conditional expressions. The general
    syntax for the most simple if statements we have just learned is that, if the
    condition is true, all the commands between the beginning if and the ending `fi`
    are executed. Now, you can also incorporate an `else` branch, which will be executed
    if the condition is not true. The following screenshot shows the execution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/23e888b5-7f09-45cd-8940-0801ccb8f8a1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The else branch is introduced by the `else` keyword. In our example, the if
    condition is not true, so the else branch will be executed. If you have several
    independent conditions to check, you can also use the `elif` statement, which
    is better than writing multiple `if` statements one after another. So, instead
    of writing three single `if` statements to check for conditions equal to, less
    than, and greater than, you can use the more compact `elif` notations instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f565c1c7-4290-4328-9762-b4d442a7969f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, we''ll discuss loops. One of the most important loops in the Bash shell
    is the `for in` loop. It can be used to iterate over a series of words. The word
    delimiter can be a space or a new line. Now, if we use such a list of space or
    new line separated words with the `for` loop, it will iterate over every item
    in that list and we can use the current value in the body of the for loop, where
    we can also execute commands. This block will then be repeated as often as we
    have elements in this list. The name of the loop variable in our example, we have
    called it `count`, is free to choose:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/35e6cf55-b95c-4ec3-9643-437edd33597b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This example can be read as: for, go through the list of `1`, `2`, `3` and
    `4`, and in each iteration of it, save the current value in the count variable
    and then, in the body of the loop, print out its content. But what can we do with
    the `for in` loop? For example, the following Bash built-in expands to a list
    of consecutive numbers: `$ echo {1..20}`. You can also do the same with the `seq`
    command, but this produces a new line-separated list instead. So, if we need to
    run a loop, we can just do the following. New line-separated lists do all the
    work, but don''t forget to put the command in dollar bracket notation. As we already
    know, the shell globbing character outputs a list of all the files separated by
    a space, so we can also do so. An important use case for using files in the for
    in loop is to rename  multiple files, for example, in a directory with a different
    filename extension. Note that, in this example, we use the `basename` command
    and surround it with the dollar bracket notation to return the pure filename:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bc907652-f59f-4f97-8a58-0ab9bf7359a9.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, we created a new directory with five files having the extension
    `.txt`. Then, we loop over our five files using a `for each` loop, and, for every
    file, we move the file to a doc extension. There are other very important loops
    as well as the `while` loop. You can refer to the Bash manual and search for while.
  prefs: []
  type: TYPE_NORMAL
- en: Automating script execution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will show you how to automate Bash shell script execution.
    The cron system, which is available on every Linux system, allows for the automation
    of commands or scripts by enabling the administrator to determine a predefined
    schedule based on any hour, day, or even month. It is a standard component of
    the CentOS 7 operating system, and in this section we will introduce you to the
    concept of managing recurring tasks in order to take advantage of this invaluable
    tool.
  prefs: []
  type: TYPE_NORMAL
- en: First, let's create a new script, which will download an elegant and useful
    Linux command-line example from the incredible **Commandlinefu** web page and
    put it in the `motd`, or message of the day, file in the Linux system so that
    it is visible whenever a user logs into the system. The `motd` file is a simple
    text file from which the content will be displayed on successful login. We then
    run the script as a cron job so that the message of the day will be updated every
    day, which is very useful to learn a new and elegant command-line solution each
    day.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to do that, first log in as `root`, as the cron system is located
    in the system directories. Next, make a copy of the original `motd` file. Afterward,
    let''s create our script file to update the `motd` file in the system:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8d41cb92-dd19-490a-ad88-4d27d46abdd5.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This script is normal batch script and downloads a random Commandlinefu example
    from the web page, [http://www.commandlinefu.com/commands/random/plaintext](http://www.commandlinefu.com/commands/random/plaintext),
    using the `wget` program and saves the downloaded file as `/etc/motd`. So, we
    can directly see the content when we log in to the system. Now, let''s test drive
    our new script:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e22ea232-2309-486e-8922-c9e8bb155502.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, the script has been successfully downloading a Commandlinefu
    from the [http://www.commandlinefu.com/](http://www.commandlinefu.com/) web page.
    To test whether the Commandlinefu web page URL we use truly returns a random command-line
    example, let''s restart our script:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/72e3a481-291c-4e5d-977d-a438557e2864.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, the command-line example is different this time. Now, based
    on your own preferred schedule of script execution, you need to decide how often
    you want to execute the script. There are some special cron directories in the
    filesystem for execution of system-wide cron jobs, and you can access them using
    `# ls /etc/cron* -d`. The folders are called `cron.daily`, `cron.hourly`, `cron.weekly`,
    and `cron.monthly` and are in the `/etc` directory, and their names refer to the
    time point that they are run. So, if we want our new Commandlinefu script to be
    started on a daily basis, just drop the script file into the `cron.daily` directory
    or create a symbolic link to it using `cd /etc/cron* -d`. If you want to run it
    using a different schedule, just drop it into the `cron.hourly`, `cron.monthly`,
    or `cron.weekly` directories. Just remove the script or the symbolic link from
    the folder if you don''t want to execute it anymore. If you don''t want to run
    system-wide cron jobs, you can also use the `crontab` command as a normal user.
    You can read the `crontab` manual to learn more about this command. Finally, let''s
    test whether the `motd` file is working. Exit out of the SSH session and then
    log in again:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f57b53a4-dda2-498d-8433-45e31749d239.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, it's working beautifully. Based on the cron job we created,
    tomorrow there should be a different command-line example presented here.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we have introduced you to the Linux cron system for script
    automation.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we've discussed topics ranging from essential Linux commands,
    signals, processes and Bash shell scripting.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll cover advanced command-line concepts.
  prefs: []
  type: TYPE_NORMAL
