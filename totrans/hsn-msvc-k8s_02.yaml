- en: Getting Started with Microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, you learned what Kubernetes is all about, and how it
    is well suited as a platform for developing, deploying, and managing microservices,
    and even played a little with your own local Kubernetes cluster. In this chapter,
    we are going to talk about microservices in general and why they are the best
    way to build complex systems. We will also discuss various aspects, patterns,
    and approaches that address common problems in microservice-based systems and
    how they compare to other common architectures, such as monolith and large services.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover a lot of material in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Programming in the small – less is more
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making your microservice autonomous
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Employing interfaces and contracts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exposing your service via APIs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using client libraries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing dependencies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orchestrating microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Taking advantage of ownership
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding Conway's law
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Troubleshooting across multiple services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Utilizing shared service libraries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing a source control strategy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a data strategy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you'll see some code examples using Go. I recommend that you
    install Go and try to build and run the code examples yourself.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Go with Homebrew on macOS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'On macOS, I recommend using Homebrew:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, make sure the `go` command is available:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: To see all the options, just type `go`. Also, make sure that you define `GOPATH`
    in your  `.bashrc` file and add `$GOPATH/bin` to your path.
  prefs: []
  type: TYPE_NORMAL
- en: Go comes with the Go CLI that provides many capabilities, but you may want to
    install additional tools. Check out [https://awesome-go.com/](https://awesome-go.com/).
  prefs: []
  type: TYPE_NORMAL
- en: Installing Go on other platforms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: On other platforms, follow the official instructions here: [https://golang.org/doc/install.](https://golang.org/doc/install)
  prefs: []
  type: TYPE_NORMAL
- en: The code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can find the code for this chapter here: [https://github.com/PacktPublishing/Hands-On-Microservices-with-Kubernetes/tree/master/Chapter02](https://github.com/PacktPublishing/Hands-On-Microservices-with-Kubernetes/tree/master/Chapter02).
  prefs: []
  type: TYPE_NORMAL
- en: Programming in the small – less is more
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Think about the time you learned to program. You wrote little programs that
    accepted simple input, did a little processing, and produced some output. Life
    was good. You could hold the entire program in your head.
  prefs: []
  type: TYPE_NORMAL
- en: 'You understood every line of code. Debugging and troubleshooting was easy.
    For example, consider a program to convert temperatures between Celsius and Fahrenheit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This program is pretty simple. It does a decent job of validating its input
    and displaying usage information if something goes wrong. The actual computation
    the program does is just two lines of code that convert the temperature, but it
    is 45 lines long. There aren't even any comments. Yet, those 45 lines are pretty
    readable and easy to test. There aren't any third-party dependencies (just the
    Go standard library). There is no IO (files, databases, network). There is no
    need for authentication or authorization. There is no need to rate limit calls.
    There is no logging, no metrics collection. There is no versioning, health checks,
    or configuration. There is no deployment to multiple environments and no monitoring
    in production.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, consider integrating this simple program into a big enterprise system.
    You''ll have to take into account many of these aspects. Other parts of the system
    will start using the temperature conversion functionality. Suddenly, the simplest
    operations might have cascading impacts. Changes to other parts of the system
    might affect the temperature converter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/22d9b791-c406-4820-9c02-7d5de80d40bf.png)'
  prefs: []
  type: TYPE_IMG
- en: This jump in complexity is natural. Large enterprise systems have many requirements.
    The promise of microservices is that by following proper architectural guidelines
    and established patterns, the additional complexity can be neatly packaged and
    used across many small microservices that work together to accomplish the system
    goals. Ideally, service developers can be shielded from the encompassing system
    most of the time. However, it takes a lot of effort to provide the right degree
    of isolation and still also allow for testing and debugging in the context of
    the entire system.
  prefs: []
  type: TYPE_NORMAL
- en: Making your microservice autonomous
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the best ways to fight complexity is to make your microservice autonomous.
    An autonomous service is a service that doesn't depend on other services in the
    system or third-party services. An autonomous service manages its own state and
    can be largely unaware of the rest of the system.
  prefs: []
  type: TYPE_NORMAL
- en: I like to think of autonomous microservices as similar to immutable functions.
    Autonomous services never change the state of other components in the system. The
    benefit of such services is that their complexity remains the same, regardless
    of how the rest of the system evolves and however they are being used by other
    services.
  prefs: []
  type: TYPE_NORMAL
- en: Employing interfaces and contracts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Interfaces are one of the best tools a software engineer can use. Once you
    expose something as an interface, you can freely change the implementation behind
    it. Interfaces are a construct that''s being used within a single process. They
    are extremely useful for testing interactions with other components, which are
    plentiful in microservice-based systems. Here is one of the interfaces of our
    sample application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The `UserManager` interface defines a few methods, their inputs, and outputs.
    However, it doesn't specify the semantics. For example, what happens if the `Login()`
    method is called for an already logged-in user? Is it an error? Is the previous
    session terminated and a new session created? Is it returning the existing session
    without an error (idempotent approach)? These kinds of questions are answered
    by contracts. Contracts are difficult to specify fully and Go doesn't provide
    any support for contracts. But, contracts are important and they always exist,
    even if only implicitly.
  prefs: []
  type: TYPE_NORMAL
- en: Some languages don't support interfaces as a first-class syntactic construct
    of the language. However, it is very easy to accomplish the same effect. Languages
    with dynamic typing, such as Python, Ruby, and JavaScript, allow you to pass any
    object that satisfies the set of attributes and methods used by the caller. Static
    languages, such as C and C++, get by with sets of function pointers (C) or structs
    with only pure virtual functions (C++).
  prefs: []
  type: TYPE_NORMAL
- en: Exposing your service via APIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices interact with each other and sometimes with the outside world
    over the network. A service exposes its capabilities through an API. I like to
    think of APIs as over-the-wire interfaces. Programming language interfaces use
    the syntax of the language they are written in (for example, Go's interface type).
    Modern network APIs also use some high-level representation. The foundation is
    UDP and TCP. However, microservices will typically expose their capabilities over
    web transports, such as HTTP (REST, GraphQL, SOAP), HTTP/2 (gRPC), or, in some
    cases, WebSockets. Some services may imitate other wire protocols, such as memcached,
    but this is useful in special situations. In 2019, there is really no reason to
    build your own custom protocol directly over TCP/UDP or use proprietary and language-specific
    protocols. Approaches such as Java RMI, .NET remoting, DCOM, and CORBA are better
    left in the past, unless you need to support some legacy code base.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two categories of microservices, which are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Internal microservices are only accessible to other microservices running typically
    in the same network/cluster and those services can expose more specialized APIs
    because you're in control of both services and their clients (other services).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: External services are open to the world and often need to be consumed from web
    browsers or clients using multiple languages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The benefit of using standard network APIs over standard language-agnostic transports
    is that it enables the polyglot promise of microservices. Each service may be
    implemented in its own programming language (for example, one service in Go and
    another in Python) and they may even migrate to a completely different language
    later (Rust, anyone?) without disruption, as all these services interact through
    the network API. We will examine later the polyglot approach and its trade-offs.
  prefs: []
  type: TYPE_NORMAL
- en: Using client libraries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Interfaces are very convenient to work with. You operate within your programming
    language environments, calling methods with native data types. Working with network
    APIs is different. You need to use a network library, depending on the transport.
    You need to serialize your payload and responses and deal with network errors,
    disconnects, and timeouts. The client library pattern encapsulates the remote
    service and all these decisions and presents you with a standard interface that,
    as a client of the service, you just call. The client library behind the scenes
    will take care of all the ceremony involved with invoking a network API. The law
    of leaky abstractions ([https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/](https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/))
    says that you can't really hide the network. However, you can hide it pretty effectively
    from the consumer service and configure it properly with policies regarding timeouts,
    retries, and caching.
  prefs: []
  type: TYPE_NORMAL
- en: One of the greatest selling points of gRPC is that it generates a client library
    for you.
  prefs: []
  type: TYPE_NORMAL
- en: Managing dependencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Modern systems have a lot of dependencies. Managing them effectively is a big
    part of the **software development life cycle** (**SDLC**). There are two kinds
    of dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: Libraries/packages (linked to the running service process)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remote services (accessible over the network)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of these dependencies can be internal or third party. You manage libraries
    or packages through your language's package management system. Go had no official
    package management system for a long time and several solutions, such as Glide
    and Dep, came along. These days (Go 1.12), Go modules are the official solution.
  prefs: []
  type: TYPE_NORMAL
- en: You manage remote services through the discovery of endpoints and tracking API
    versions. The difference between internal dependencies and third-party dependencies
    is the velocity of change. Internal dependencies will change much faster. With
    microservices, you'll have other microservices you depend on. Versioning and keeping
    track of the contracts behind the APIs become very important aspects of development.
  prefs: []
  type: TYPE_NORMAL
- en: Coordinating microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When comparing a monolith system with a microservice-based system, one thing
    is clear. There is more of everything. The individual microservices are simpler
    and it's much easier to reason, modify, and troubleshoot individual services.
    But, understanding the whole system, making changes across multiple services,
    and debugging problems are more challenging. Many more interactions also happen
    over the network between separate microservices, where, with a monolith, these
    interactions would occur within the same process. It means that to benefit from
    microservices, you need a disciplined approach, you need to apply best practices,
    and have good tools at your disposal.
  prefs: []
  type: TYPE_NORMAL
- en: The uniformity versus flexibility trade-off
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s say you have a hundred microservices, but they are all very small and
    very similar. They all use the same data store (for example, the same type of
    relational database). They are all configured in the same way (for example, a
    configuration file). They all report errors and logs to a centralized log server.
    They are all implemented using the same programming language (for example, Go).
    Typically, the system will handle several use cases. Each use case will involve
    some subset of these hundred microservices. There will also be some generic microservices
    that are used in most use cases (for example, an authorization service). Then,
    it may not be that difficult to understand the system as a whole, given some good
    documentation. You can look at each use case separately and, when you extend the
    system and add more use cases, and maybe grow to a thousand microservices, the
    complexity remains bounded:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/5ff8b12e-29ea-47cf-827d-3ecab507da8c.png)'
  prefs: []
  type: TYPE_IMG
- en: A good analogy is files and directories. Suppose you organize your music by
    genre, artist, and song. Initially, you had three genres, 20 artists, and 200
    songs. Then, you expanded everything and now have 10 genres, 50 artists, and 3,000
    songs. The organization is still the same old hierarchy of genre/artist/song.
    It's true that at some point when you scale, the sheer scale can present new problems.
    For example, with music, when you have so much music that it doesn't fit on your
    hard disk, you need a qualitatively different solution (for example, keep it in
    the cloud). The same is true for microservices, but the divide and conquer approach
    works well. If you reach internet-scale—Amazon, Google, Facebook—then, yes, you'll
    need much more elaborate solutions for every aspect.
  prefs: []
  type: TYPE_NORMAL
- en: But, with uniform microservices, you sacrifice a number of benefits. For example,
    teams and developers may be forced to use a programming language that is not best
    for the task, or they'll have to abide by strict operational standards of logging
    and error reporting, even for small non-critical internal services.
  prefs: []
  type: TYPE_NORMAL
- en: You need to understand the pros and cons of uniform versus diverse microservices.
    There is a spectrum ranging from totally uniform microservices to a jungle of
    anything goes, where each microservice is a unique snowflake. Your responsibility
    is to find the sweet spot along this spectrum for your system.
  prefs: []
  type: TYPE_NORMAL
- en: Taking advantage of ownership
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since microservices are small. A single developer can own a whole microservice
    and understand it completely. Other developers may also be familiar with it, but
    even if just a single developer is familiar with a service, it should be relatively
    simple and painless for a new developer to take over because the scope is so limited
    and ideally similar.
  prefs: []
  type: TYPE_NORMAL
- en: Sole ownership can be very powerful. The developer needs to communicate with
    the other developers and teams though the service API, but can iterate very fast
    on the implementation. You may still want other developers on the team to review
    the internal design and implementation, but even in the extreme case that the
    owner works completely on their own with no supervision, the potential damage
    is limited because the scope of each microservice is small and it interacts with
    the rest of the system through well-defined APIs.
  prefs: []
  type: TYPE_NORMAL
- en: The differences in productivity can be jaw-dropping.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Conway's law
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Conway''s law is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '"Organizations which design systems ... are constrained to produce designs
    which are copies of the communication structures of these organizations."'
  prefs: []
  type: TYPE_NORMAL
- en: 'This means the structure of the system will reflect the structure of the team
    building it. A famous variation by Eric Raymond is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '"If you have four groups building a compiler you''ll get a 4-pass compiler."'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is very insightful and I''ve personally witnessed it time and again in
    many different organizations. This is very relevant to microservice-based systems.
    With lots of small microservices, you don''t need a dedicated team for each microservice.
    There will be some higher-level groups of microservices that work together to
    produce some aspect of the system. Now, the question is how to think about the
    high-level structure. There are three main options:'
  prefs: []
  type: TYPE_NORMAL
- en: Vertical
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Horizontal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrix
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Microservices can be very important in this regard. By being small autonomous
    components, they support all structures. But, what is even more important is when
    organizations need to transition from one approach to another. The usual trajectory
    is: horizontal | vertical | matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: The organization can perform those transitions with much less friction if the
    software follows a microservice-based architecture. It can even be a deciding
    factor. Even an organization that doesn't follow microservice-based architecture
    decides to stay with an inappropriate structure because the risk and effort of
    breaking the monolith is too high.
  prefs: []
  type: TYPE_NORMAL
- en: Vertical
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The vertical approach takes a slice of functionality of the system that comprises
    multiple microservices and a team is fully responsible for that functionality,
    from design to implementation, through deployment and maintenance. Teams operate
    as silos and communication between them is typically limited and formal. This
    approach favors aspects of microservices, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Polyglot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flexibility
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Independently moving pieces
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: End-to-end ownership
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Less formal contracts within the vertical slice
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Easy-to-scale to more vertical slices (just form another team)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Difficult to apply changes across vertical slices, especially as the number
    of vertical slices scales
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This approach is common in very large organizations due to its scalability advantages.
    It also requires a lot of creativity and effort to make improvements across the
    board. There will be duplication of effort between the silos. Aiming for complete
    reuse and coordination is futile. The trick with the vertical approach is to find
    the sweet spot, where common functionality is packaged in a way that can be used
    by multiple silos, but without requiring explicit coordination.
  prefs: []
  type: TYPE_NORMAL
- en: Horizontal
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The horizontal approach looks at the system as a layered architecture. The team
    structure is organized along those layers. There may be a frontend group, backend
    group, and a DevOps group. Each group is responsible for all the aspects in their
    layer. Vertical functionality is implemented by a collaboration between different
    groups across all layers. This approach is more suitable for smaller organizations
    with a small numbers of products (sometimes just one).
  prefs: []
  type: TYPE_NORMAL
- en: The nice thing about the horizontal approach is that the organization can build
    expertise and share knowledge across entire horizontal layers. Typically, organizations
    start with a horizontal organization and, as they grow and then expand to more
    products, or possibly spread across multiple geographic locations, they divide
    into a more vertical structure. Within each silo, the structure is usually horizontal.
  prefs: []
  type: TYPE_NORMAL
- en: Matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The matrix organization is the most complicated. You have your vertical silos,
    but the organization recognizes that the amount of duplication and variation between
    the silos waste resources and also makes transferring people between vertical
    silos challenging if they diversify too much. With a matrix organization, in addition
    to the vertical silos, there are also cross-cutting groups that work with all
    vertical silos and try to bring some level of consistency, uniformity, and order.
    For example, the organization may dictate that all vertical silos must deploy
    their software to the cloud on AWS. In this case, there may be a cloud platform
    group that is managed outside the vertical silos and provides guidance, tooling,
    and other shared services for all the vertical silos. Security is another good
    example. Many organizations consider security an area that must be managed centrally
    and can't be left to the whims of each silo.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting across multiple services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since most of the functions of the system will involve interactions between
    multiple microservices, it's important to be able to follow a request coming in
    across all those microservices and various data stores. One of the best ways to
    accomplish this is distributed tracing, where you tag each request and can follow
    it from beginning to end.
  prefs: []
  type: TYPE_NORMAL
- en: 'The subtleties of debugging distributed systems in general and microservice-based
    ones take a lot of expertise. Consider the following aspects along the path of
    a single request through the system:'
  prefs: []
  type: TYPE_NORMAL
- en: The microservices processing the request may use different programming languages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The microservices may expose APIs using different transports/protocols.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Requests may be part of asynchronous workflows that involve waiting in queues
    and/or periodical processing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The persistent state of the request may be spread across many independent data
    stores controlled by different microservices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you need to debug a problem across the entire swath of microservices in
    the system, the autonomous nature of each microservice becomes a hindrance. You
    must build explicit support to be able to gain system-level visibility by aggregating
    internal information from multiple microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing shared service libraries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you choose the uniform microservices approach, it is very useful to have
    a shared library (or several libraries) that all services use and implement many
    cross-cutting concerns, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Secret management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service discovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: API wrapping
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Distributed tracing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This library may implement whole workflows, such as authentication and authorization,
    that interact with other microservices or third-party dependencies and do the
    heavy lifting for each microservice. This way, the microservice is only responsible
    for using these libraries properly and implements its own functionality.
  prefs: []
  type: TYPE_NORMAL
- en: This approach can work even if you choose the polyglot path and support multiple
    languages. You can implement this library for all the supported languages and
    the services themselves can be implemented in different languages.
  prefs: []
  type: TYPE_NORMAL
- en: However, there are costs associated with the maintenance and evolution of shared
    libraries and the rate of adopting them by all microservices. A real danger is
    that different microservices will use many versions of the shared libraries and
    cause subtle (or not so subtle) problems when services using different versions
    of the shared library try to communicate.
  prefs: []
  type: TYPE_NORMAL
- en: The service mesh approach that we will explore later in the book can provide
    some answers to this issue.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a source control strategy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is a very interesting scenario. There are two main approaches: monorepo
    and multiple repos. Let''s explore the pros and cons of each.'
  prefs: []
  type: TYPE_NORMAL
- en: Monorepo
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the monorepo approach, your entire code base is in a single source control
    repository. It is very easy to perform operations over the entire code base. Whenever
    you make a change, it is reflected immediately in your entire code base. Versioning
    is pretty much off the table. That's great for keeping all your code in sync.
    But, if you do need to upgrade some parts of your systems incrementally, you'll
    need to come up with workarounds, such as creating a separate copy with your new
    changes. Also, the fact that your source code is always in sync doesn't mean that
    your deployed services are all using the latest version. If you always deploy
    all your services at once, you're pretty much building a monolith. Note that you
    may still have multiple repos if you contribute to third-party open source projects
    (even if you only use upstream versions after your changes were merged).
  prefs: []
  type: TYPE_NORMAL
- en: Another big issue with monorepo is that you might need a lot of custom tooling
    to manage your multi repo. Large companies, such as Google and Microsoft, use
    the multi-repo approach. They have special needs and the custom tooling aspect
    doesn't deter them. I'm on the fence if the multi-repo approach is appropriate
    for smaller organizations. However, I'll use a monorepo for the Delinkcious —the
    demo application—so, we will get to explore it together and form an opinion. A
    major downside is that many modern CI/CD tool chains use GitOps, which trigger
    changes in source control repos. When there is just one monorepo, you lose the
    one-to-one mapping between a source control repo and a microservice.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple repos
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The multiple repos approach is exactly the opposite. Each project, and often
    each library, has a separate source control repository. Projects consume each
    other just like third-party libraries. There are several advantages to this approach:'
  prefs: []
  type: TYPE_NORMAL
- en: Clear physical boundaries between projects and services.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One-to-one mapping of source control repositories and services or projects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is easy to map deployments of services to source control repositories.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uniform treatment of all dependencies—internal and third party.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, there are significant costs to this approach, especially as the number
    of services and projects grows and the dependency graphs between them become more
    complicated:'
  prefs: []
  type: TYPE_NORMAL
- en: Applying changes often requires changes across multiple repositories.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You often need to maintain multiple versions of a repository, as different services
    depend on different services.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is difficult to apply cross-cutting changes across all repositories.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hybrid
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The hybrid approach involves using a small number of repositories. Each repository
    contains multiple services and projects. Each repository is isolated from the
    other repositories, but within each repo, multiple services and projects can be
    developed in lockstep. This approach balances the pros and cons of monorepo and
    multiple repos. It may be useful when there are clear organizational boundaries
    and often geographical boundaries. For example, if a company has multiple product
    lines that are completely independent, it may be a good idea to break each product
    line into its own monorepo.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a data strategy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One the most important responsibilities of a software system is to manage data.
    There are many types of data, and most of the data, should survive any failure
    of the system or you should be able to reconstruct it. Data often has complex
    relationships with other data. This is very explicit with relational databases,
    but exists in other types of data, too. Monoliths typically use large data stores
    that keep all the related data and, as a result, can perform queries and transactions
    over the entire set of data. Microservices are different. Each microservice is
    autonomous and responsible for its data. However, the system as a whole needs
    to query and operate over data that is now stored in many independent data stores
    and managed by many different services. Let's examine how to address this challenge
    using best practices.
  prefs: []
  type: TYPE_NORMAL
- en: One data store per microservice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The one data store per microservice is a crucial element of the microservice
    architecture. The moment two microservices can access directly the same data store,
    they are tightly coupled and are no longer independent. There are a few important
    nuances to understand. It may be OK for multiple microservices to use the same
    database instance, but they must not share the same logical database.
  prefs: []
  type: TYPE_NORMAL
- en: The database instance is a resource provisioning concern. In some cases, the
    team developing the microservice is responsible for provisioning its data stores
    too. In this case, the wise move may be to have physically separate DB instances
    for each microservice and not just logical ones. Note that when using cloud data
    stores, the microservice developer is not in control and unaware of the physical
    configuration of the data store.
  prefs: []
  type: TYPE_NORMAL
- en: 'We agree that two microservices shouldn''t share the same data store. But,
    what about a single microservice managing two or more data stores? This is generally
    also frowned upon. If your design calls for two separate data stores, it''s better
    to dedicate a microservice to each one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/7138b4e0-3d48-4cae-9be7-551d2f68fc2f.png)'
  prefs: []
  type: TYPE_IMG
- en: There is one common exception—you may want to manage an in-memory data store
    (cache) and a persistent data store by the same microservice. The workflow is
    that the service is writing to the persistent store and the cache and serving
    queries from the cache. The cache is either refreshed periodically, or based on
    change notification, or when there is a cache miss.
  prefs: []
  type: TYPE_NORMAL
- en: But, even in this case, it may be a better design to have a separate centralized
    cache, such as Redis managed by a separate microservice. Remember that each microservice
    may have multiple instances in a large system that serves many users.
  prefs: []
  type: TYPE_NORMAL
- en: Another reason to abstract away the physical configuration and provisioning
    of data stores from the microservices themselves is that those configurations
    may be different in different environments. Your production environment may have
    physically separate data stores for each microservice, but, in your development
    environment, it may be better to have just one physical database instance with
    lots of small logical databases.
  prefs: []
  type: TYPE_NORMAL
- en: Running distributed queries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We agree that each microservice should have its own data store. This means that
    the overall state of the system will be distributed across multiple data stores,
    accessible only from their own microservices. Most interesting queries will involve
    data available in multiple data stores. Each consumer could just access all these
    microservices and aggregate all the data to satisfy their query. However, that
    is sub-optimal for several reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: Consumers are intimately aware of how data is managed by the system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consumers need to get access to each and every service that stores data relevant
    to the query.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changing the architecture might require changes to a lot of consumers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are two common solutions to address this issue: CQRS and API composition.
    The cool thing about it is that the services that enable both solutions have the
    same API, so it is possible to switch from one solution to another, or even mix
    and match without impacting users. This means that some queries will be serviced
    by CQRS and others by API composition, all implemented by the same service. Overall,
    I recommend to start with API composition and transition to CQRS only if the proper
    conditions exist and benefits are compelling, due to its much higher complexity.'
  prefs: []
  type: TYPE_NORMAL
- en: Employing Command Query Responsibility Segregation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With **Command Query Responsibility Segregation** (**CQRS**), the data from
    the various microservices is aggregated to a new read-only data store that is
    designed to answer specific queries. The meaning of the name is that you separate
    (segregate) the responsibility of updating data (commands) from the responsibility
    of reading data (queries). Different services are in charge of those activities.
    It is often implemented by watching for changes to all data stores and requires
    a change notification system in place. You could use polling too, but that's often
    undesirable. This solution shines when there are known queries that are used often.
  prefs: []
  type: TYPE_NORMAL
- en: Here is an illustration of CQRS in action. The CQRS service (responsible for
    queries) receives a change notification from the three microservices (responsible
    for updates) and aggregates them into its own data store.
  prefs: []
  type: TYPE_NORMAL
- en: 'When a query comes, the CQRS service responds by accessing its own aggregated
    view without hitting the microservices:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/e8fdf295-52a4-45a9-b42e-5c2a8c766feb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The pros are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Queries don't interfere with updating the primary data store.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The aggregator service exposes an API that is tailored to specific queries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's easier to change the way data is managed behind the scenes without impacting
    consumers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quick response time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The cons are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: It adds complexity to the system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It duplicates the data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Partial views require explicit treatment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Employing API composition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The API composition approach is much more lightweight. On the surface, it looks
    just like the CQRS solution. It exposes an API that can answer well-known queries
    across multiple microservices. The difference is that it doesn't keep its own
    data store. Whenever a request comes in, it will access the individual microservices
    that contain the data, compose the results, and return them. This solution shines
    when the system doesn't support event notification for data changes and when the
    load of running queries against the primary data store is acceptable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an illustration of API composition in action, where a query to an API
    composer service is translated under the covers to queries to three microservices:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/65e81c02-8545-4248-97cf-31ecae54831b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The pros are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Lightweight solution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The aggregator service exposes an API that is tailored to specific queries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Results are always up to date.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No architectural requirements, such as event notification.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The cons are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The failure of any service will fail the query. This requires policy decisions
    around retries and timeouts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A high number of queries might impact primary data stores.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using sagas to manage transactions across multiple services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The API composer and CQRS patterns provide adequate solutions for distributed
    queries when everything works well. However, maintaining distributed data integrity
    is a complex problem. If you store all your data in a single relational database
    and specify proper constraints in your schema, then you can rely on the database
    engine to take care of data integrity. The situation is very different with multiple
    microservices maintaining your data in isolated data stores (relational or non-relational).
    Data integrity is essential, but it must be maintained by your code. The saga
    pattern addresses this concern. Before diving into the saga pattern, let's understand
    data integrity in general.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding ACID
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A common measure of data integrity is that all transactions that modify data
    have the ACID properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Atomic**: All operations in the transaction succeed or they all fail.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consistent**: The state of the data complies with all constraints before
    and after the transaction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Isolated**: Concurrent transactions behave as if serialized.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Durable**: When a transaction completes successfully, the results are persisted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ACID properties are not specific to relational databases, but often used
    in that context, mostly because the relational schemas, with their formal constraints,
    provide a convenient measure of consistency. The isolation property often has
    serious performance implications and may be relaxed in some systems that prefer
    high-performance and eventual consistency.
  prefs: []
  type: TYPE_NORMAL
- en: 'The durability property is pretty obvious. There is no point going to all the
    trouble if your data can''t be safely persisted. There are different levels of
    persistence:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Persistence to disk**: Can survive restart of the node, but no disk failure'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Redundant memory on multiple nodes**: Can survive restart of a node and disk
    failure, but not temporary failure of all the nodes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Redundant disks**: Can survive the failure of a disk'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Geo-distributed replicas**: Can survive a whole data center being down'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Backups**: Cheaper to store a lot of information, but slower to restore and
    often lags behind real time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The atomicity requirement is also a no-brainer. Nobody likes partial changes,
    which can violate data integrity and break the system in unpredictable ways that
    are difficult to troubleshoot.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the CAP theorem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The CAP theorem states that a distributed system can''t have all three properties
    at the same time:'
  prefs: []
  type: TYPE_NORMAL
- en: Consistency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Availability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Partition resiliency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In practice, you get to pick if you want a CP system or AP system. A **CP**
    system (**consistent and partition resilient**) is always consistent and will
    not serve queries or make changes if there is a network partitioning between components.
    It will function only when the system is fully connected. This obviously means
    that you don't have availability. On the other hand, an **AP** system (**available
    and partition resilient**) is always available and can operate in split-brain
    fashion. When the system splits, each part may continue to operate normally, but
    the system will be inconsistent because each part is unaware of transactions happening
    in the other part.
  prefs: []
  type: TYPE_NORMAL
- en: AP systems are often referred to as eventually consistent systems because, when
    connectivity is restored, some reconciliation process ensures the entire system
    syncs up again. An interesting variant is frozen systems, where, when a network
    partitioning occurs, they degrade gracefully and both parts continue to serve
    queries, but reject all modifications to the system. Note that there is no guarantee
    that, at the moment of partitioning, both parts are consistent because some transactions
    in one part may still not be replicated to the other part. Often, it is good enough
    because the divergence between the split part is small and will not increase over
    time because new changes are rejected.
  prefs: []
  type: TYPE_NORMAL
- en: Applying the saga pattern to microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Relational databases can provide ACID compliance for distributed systems through
    algorithms, such as two-phase commit and control over all the data. The two-phase
    commit algorithm works in two phases: prepare and commit. However, the services
    that participate in the distributed transaction must share the same database.
    That doesn''t work for microservices that manage their own databases.'
  prefs: []
  type: TYPE_NORMAL
- en: Enter the saga pattern. The basic idea of the saga pattern is that there is
    centralized management of the operations across all the microservices and that,
    for each operation, there is a compensating operation that will be executed if,
    for some reason, the entire transaction can't be completed. This achieves the
    atomicity property of ACID. But, the changes on each microservice are visible
    immediately and not only at the end of the entire distributed transaction. This
    violates the consistency and isolation properties. This is not a problem if you
    design your system as AP, also known as, **eventually consistent**. But, it requires
    your code to be aware of it and be able to work with data that may be partially
    inconsistent or stale. In many cases, this is an acceptable compromise.
  prefs: []
  type: TYPE_NORMAL
- en: How does a saga work? A saga is a set of operations and corresponding compensating
    operations on microservices. When an operation fails, its compensating operation
    and the compensating operations of all the previous operations are called in reverse
    order to roll back the entire state of the system.
  prefs: []
  type: TYPE_NORMAL
- en: Sagas are not trivial to implement because the compensating operations might
    fail too. In general, the transient state must be persistent and marked as such
    and a lot of metadata must be stored to enable reliable rollback. A good practice
    is to have an out-of-band process run frequently and clean up failed sagas that
    didn't manage to complete all their compensating operations in real time.
  prefs: []
  type: TYPE_NORMAL
- en: A good way to think about sagas is as workflows. Workflows are cool because
    they enable long processes that even involve humans and not just software.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered a lot of ground. We discussed the basic principle
    of microservices—less is more—and how breaking down your system to many small
    and self-contained microservices can help it scale. We also discussed the challenges
    that face developers utilizing the microservices architecture. We provided a slew
    of concepts, options, best practices, and pragmatic advice on architecting microservice-based
    systems. At this point, you should appreciate the flexibility that microservices
    offer, but also be a little apprehensive of the many ways you can choose to utilize
    them.
  prefs: []
  type: TYPE_NORMAL
- en: In the rest of the book, we will explore the terrain in detail and together
    build a microservice-based system using some of the best available frameworks
    and tools and deploy it on Kubernetes. In the next chapter, you'll meet Delinkcious—our
    sample application—that will serve as a hands-on laboratory. You will also get
    a glimpse into Go-kit, a microservice-based framework for constructing Go microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you are interested in microservices, I recommend the following article as
    a starting point: [https://www.martinfowler.com/](https://www.martinfowler.com/)
  prefs: []
  type: TYPE_NORMAL
