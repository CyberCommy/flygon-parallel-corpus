- en: Chapter 3. Developing a Concurrent Strategy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we looked at the concurrency model that Go relies on
    to make your life as a developer easier. We also saw a visual representation of
    parallelism and concurrency. These help us to understand the differences and overlaps
    between serialized, concurrent, and parallel applications.
  prefs: []
  type: TYPE_NORMAL
- en: However, the most critical part of any concurrent application is not the concurrency
    itself but communication and coordination between the concurrent processes.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll look at creating a plan for an application that heavily
    factors communication between processes and how a lack of coordination can lead
    to significant issues with consistency. We'll look at ways we can visualize our
    concurrent strategy on paper so that we're better equipped to anticipate potential
    problems.
  prefs: []
  type: TYPE_NORMAL
- en: Applying efficiency in complex concurrency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When designing applications, we often eschew complex patterns for simplicity,
    with the assumption that simple systems are often the fastest and most efficient.
    It seems only logical that a machine with fewer moving parts will be more efficient
    than one with more.
  prefs: []
  type: TYPE_NORMAL
- en: The paradox here, as it applies to concurrency, is that adding redundancy and
    significantly more movable parts often leads to a more efficient application.
    If we consider concurrent schemes, such as goroutines, to be infinitely scalable
    resources, employing more should always result in some form of efficiency benefit.
    This applies not just to parallel concurrency but to single core concurrency as
    well.
  prefs: []
  type: TYPE_NORMAL
- en: If you find yourself designing an application that utilizes concurrency at the
    cost of efficiency, speed, and consistency, you should ask yourself whether the
    application truly needs concurrency at all.
  prefs: []
  type: TYPE_NORMAL
- en: When we talk about efficiency, we aren't just dealing with speed. Efficiency
    should also weigh the CPU and memory overhead and the cost to ensure data consistency.
  prefs: []
  type: TYPE_NORMAL
- en: For example, should an application marginally benefit from concurrency but require
    an elaborate and/or computationally expensive process to guarantee data consistency,
    it's worth re-evaluating the strategy entirely.
  prefs: []
  type: TYPE_NORMAL
- en: Keeping your data reliable and up to date should be paramount; while having
    unreliable data may not always have a devastating effect, it will certainly compromise
    the reliability of your application.
  prefs: []
  type: TYPE_NORMAL
- en: Identifying race conditions with race detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you've ever written an application that depends on the exact timing and sequencing
    of functions or methods to create a desired output, you're already quite familiar
    with race conditions.
  prefs: []
  type: TYPE_NORMAL
- en: These are particularly common anytime you deal with concurrency and far more
    so when parallelism is introduced. We've actually encountered a few of them in
    the first few chapters, specifically with our incrementing number function.
  prefs: []
  type: TYPE_NORMAL
- en: The most commonly used educational example of race conditions is that of a bank
    account. Assume that you start with $1,000 and attempt 200 $5 transactions. Each
    transaction requires a query on the current balance of the account. If it passes,
    the transaction is approved and $5 is removed from the balance. If it fails, the
    transaction is declined and the balance remains unchanged.
  prefs: []
  type: TYPE_NORMAL
- en: This is all well and good until the query happens at some point during a concurrent
    transaction (in most cases in another thread). If, for example, a thread asks
    "Do you have $5 in your account?" as another thread is in the process of removing
    $5 but has not yet completed, you can end up with an approved transaction that
    should have been declined.
  prefs: []
  type: TYPE_NORMAL
- en: Tracking down the cause of race conditions can be—to say the least—a gigantic
    headache. With Version 1.1 of Go, Google introduced a race detection tool that
    can help you locate potential issues.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a very basic example of a multithreaded application with race conditions
    and see how Golang can help us debug it. In this example, we'll build a bank account
    that starts with $1,000 and runs 100 transactions for a random amount between
    $0 and $25.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each transaction will be run in its own goroutine, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Depending on your environment (and whether you enable multiple processors),
    you might have the previous goroutine operate successfully with a $0 or more final
    balance. You might, on the other hand, simply end up with transactions that exceed
    the balance at the time of transaction, resulting in a negative balance.
  prefs: []
  type: TYPE_NORMAL
- en: So how do we know for sure?
  prefs: []
  type: TYPE_NORMAL
- en: 'For most applications and languages, this process often involves a lot of running,
    rerunning, and logging. It''s not unusual for race conditions to present a daunting
    and laborious debugging process. Google knows this and has given us a race condition
    detection tool. To test this, simply use the `–race` flag when testing, building,
    or running your application, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'When run on the previous code, Go will execute the application and then report
    any possible race conditions, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Here, Go is telling us there are two potential race conditions with data. It
    isn't telling us that these will surely create data consistency issues, but if
    you run into such problems, this may give you some clue as to why.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you look at the top of the output, you''ll get more detailed notes on what''s
    causing a race condition. In this example, the details are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We get a detailed, full trace of where our potential race conditions exist.
    Pretty helpful, huh?
  prefs: []
  type: TYPE_NORMAL
- en: The race detector is guaranteed to not produce false positives, so you can take
    the results as strong evidence that there is a potential problem in your code.
    The potential is stressed here because a race condition can go undetected in normal
    conditions very often—an application may work as expected for days, months, or
    even years before a race condition can surface.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We''ve mentioned logging, and if you aren''t intimately familiar with Go''s
    core language, your mind might go in a number of directions—stdout, file logs,
    and so on. So far we''ve stuck to stdout, but you can use the standard library
    to handle this logging. Go''s log package allows you to write to io or stdout
    as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This will produce the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: So, what's the advantage of the log package versus rolling your own? In addition
    to being standardized, this package is also synchronized in terms of output.
  prefs: []
  type: TYPE_NORMAL
- en: So what now? Well, there are a few options. You can utilize your channels to
    ensure data integrity with a buffered channel, or you can use the `sync.Mutex`
    struct to lock your data.
  prefs: []
  type: TYPE_NORMAL
- en: Using mutual exclusions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Typically, mutual exclusion is considered a low-level and best-known approach
    to synchronicity in your application—you should be able to address data consistency
    within communication between your channels. However, there will be instances where
    you need to truly block read/write on a value while you work with it.
  prefs: []
  type: TYPE_NORMAL
- en: At the CPU level, a mutex represents an exchange of binary integer values across
    registers to acquire and release locks. We'll deal with something on a much higher
    level, of course.
  prefs: []
  type: TYPE_NORMAL
- en: We're already familiar with the sync package from our use of the `WaitGroup`
    struct, but the package also contains the conditional variables `struct Cond`
    and `Once`, which will perform an action just one time, and the mutual exclusion
    locks `RWMutex` and `Mutex`. As the name `RWMutex` implies, it is open to multiple
    readers and/or writers to lock and unlock; there is more on this later in this
    chapter and in [Chapter 5](part0048_split_000.html#page "Chapter 5. Locks, Blocks,
    and Better Channels"), *Locks, Blocks, and Better Channels*.
  prefs: []
  type: TYPE_NORMAL
- en: All of these—as the package name implies—empower you to prevent race conditions
    on data that may be accessed by any number of goroutines and/or threads. Using
    any of the methods in this package does not ensure atomicity within data and structures,
    but it does give you the tools to manage atomicity effectively. Let's look at
    a few ways we can solidify our account balance in concurrent, threadsafe applications.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned previously, we can coordinate data changes at the channel level
    whether that channel is buffered or unbuffered. Let's offload the logic and data
    manipulation to the channel and see what the `–race` flag presents.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we modify our main loop, as shown in the following code, to utilize messages
    received by the channel to manage the balance value, we will avoid race conditions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, we let the channel manage the data entirely. Let''s look at what
    we''re doing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This still generates a random integer between 0 and 25, but instead of passing
    it to a function, we pass the data along the channel. Channels allow you to control
    the ownership of data neatly. We then see the select/listener, which largely mirrors
    our `transaction()` function defined earlier in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: To test whether we've averted a race condition, we can run `go run` with the
    `-race` flag again and see no warnings.
  prefs: []
  type: TYPE_NORMAL
- en: Channels can be seen as the sanctioned go-to way of handling synchronized `dataUse
    Sync.Mutex()`.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned, having a built-in race detector is a luxury not afforded to developers
    in most languages, and having it allows us to test methodologies and get real-time
    feedback on each.
  prefs: []
  type: TYPE_NORMAL
- en: We noted that using an explicit mutex is discouraged in favor of channels of
    goroutines. This isn't always exactly true because there is a right time and place
    for everything, and mutexes are no exclusion. What's worth noting is that mutexes
    are implemented internally by Go for channels. As was previously mentioned, you
    can use explicit channels to handle reads and writes and juggle the data between
    them.
  prefs: []
  type: TYPE_NORMAL
- en: However, this doesn't mean there is no use for explicit locks. An application
    that has many reads and very few writes might benefit from explicit locks for
    writes; this doesn't necessarily mean that the reads will be dirty reads, but
    it could result in faster and/or more concurrent execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the sake of demonstration, let''s remove our race condition using an explicit
    lock. Our `-race` flag tells us where it encounters read/write race conditions,
    as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The previous line is just one among several others we''ll get from the race
    detection report. If we look at line 62 in our code, we''ll find a reference to
    `balance`. We''ll also find a reference to `transactionNo`, our second race condition.
    The easiest way to address both is to place a mutual exclusion lock around the
    contents of the `transaction` function as this is the function that modifies the
    `balance` and `transactionNo` variables. The `transaction` function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We also need to define `mutex` as a global variable at the top of our application,
    as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: If we run our application now with the `-race` flag, we get no warnings.
  prefs: []
  type: TYPE_NORMAL
- en: The `mutex` variable is, for practical purposes, an alternative to the `WaitGroup`
    struct, which functions as a conditional synchronization mechanism. This is also
    the way that the channels operate—data that moves along channels is contained
    and isolated between goroutines. A channel can effectively work as a first-in,
    first-out tool in this way by binding goroutine state to `WaitGroup`; data accessed
    across the channel can then be provided safety via the lower-level mutex.
  prefs: []
  type: TYPE_NORMAL
- en: Another worthwhile thing to note is the versatility of a channel—we have the
    ability to share a channel among an array of goroutines to receive and/or send
    data, and as a first-class citizen, we can pass them along in functions.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring timeouts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another noteworthy thing we can do with channels is explicitly kill them after
    a specified amount of time. This is an operation that will be a bit more involved
    should you decide to manually handle mutual exclusions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The ability to kill a long-running routine through the channel is extremely
    helpful; consider a network-dependent operation that should not only be restricted
    to a short time period but also not allowed to run for a long period. In other
    words, you want to offer the process a few seconds to complete; but if it runs
    for more than a minute, our application should know that something has gone wrong
    enough to stop attempting to listen or send on that channel. The following code
    demonstrates using a timeout channel in a `select` call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: If we run the previous simple application, we'll see that our goroutine will
    be allowed to do nothing for exactly 10 seconds, after which we implement a timeout
    safeguard that bails us out.
  prefs: []
  type: TYPE_NORMAL
- en: You can see this as being particularly useful in network applications; even
    in the days of blocking and thread-dependent servers, timeouts like these were
    implemented to prevent a single misbehaving request or process to gum up the entire
    server. This is the very basis of a classic web server problem that we'll revisit
    in more detail later.
  prefs: []
  type: TYPE_NORMAL
- en: Importance of consistency
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In our example, we'll build an events scheduler. If we are available for a meeting
    and we get two concurrent requests for a meeting invite, we'll get double-booked
    should a race condition exist. Alternately, locked data across two goroutines
    may cause both the requests to be denied or will result in an actual deadlock.
  prefs: []
  type: TYPE_NORMAL
- en: We want to guarantee that any request for availability is consistent—there should
    neither be double-booking nor should a request for an event be blocked incorrectly
    (because two concurrent or parallel routines lock the data simultaneously).
  prefs: []
  type: TYPE_NORMAL
- en: Synchronizing our concurrent operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The word synchronization literally refers to temporal existence—things occurring
    at the same time. It seems then that the most apt demonstration of synchronicity
    will be something involving time itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we think about the ways time impacts us, it''s generally a matter of scheduling,
    due dates, and coordination. Going back to our preliminary example from the Preface,
    if one wishes to plan their grandmother''s birthday party, the following types
    of scheduled tasks can take several forms:'
  prefs: []
  type: TYPE_NORMAL
- en: Things that must be done by a certain time (the actual party)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Things that cannot be done until another task is completed (putting up decorations
    before they're purchased)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Things that can be done in any particular order without impacting the outcome
    (cleaning the house)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Things that can be done in any order but may well impact the outcome (buying
    a cake before finding out what cake your grandmother likes the most)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With these in mind, we'll attempt to handle some rudimentary human scheduling
    by designing an appointment calendar that can handle any number of people with
    one hour timeslots between 9 a.m. and 5 p.m.
  prefs: []
  type: TYPE_NORMAL
- en: The project – multiuser appointment calendar
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What do you do when you decide to write a program?
  prefs: []
  type: TYPE_NORMAL
- en: If you're like a lot of people, you think about the program; perhaps you and
    a team will write up a spec or requirements document, and then you'll get to coding.
    Sometimes, there will be a drawing representing some facsimile of the way the
    application will work.
  prefs: []
  type: TYPE_NORMAL
- en: Quite often, the best way to nail down the architecture and the inner workings
    of an application is to put pencil to paper and visually represent the way the
    program will work. For a lot of linear or serial applications, this is often an
    unnecessary step as things will work in a predictable fashion that should not
    require any specific coordination within the application logic itself (although
    coordinating third-party software likely benefits from specification).
  prefs: []
  type: TYPE_NORMAL
- en: 'You may be familiar with some logic that looks something like the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The project – multiuser appointment calendar](img/00012.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The logic here makes sense. If you remember from our Preface, when humans draw
    out processes, we tend to serialize them. Visually, going from step one to step
    two with a finite number of processes is easy to understand.
  prefs: []
  type: TYPE_NORMAL
- en: However, when designing a concurrent application, it's essential that we at
    least account for innumerable and concurrent requests, processes, and logic to
    make sure our application ends where we want, with the data and results we expect.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous example, we completely ignore the possibility that "Is User
    Available" could fail or report old or erroneous data. Does it make more sense
    to address such problems if and when we find them, or should we anticipate them
    as part of a control flow? Adding complexity to the model can help us reduce the
    odds of data integrity issues down the road.
  prefs: []
  type: TYPE_NORMAL
- en: Let's visualize this again, taking into account availability pollers that will
    request availability for a user with any given request for a time/user pair.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing a concurrent pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we have already discussed, we wish to create a basic blueprint of how our
    application should function as a starting point. Here, we''ll implement some control
    flow, which relates to user activity, to help us decide what functionality we''ll
    need to include. The following diagram illustrates how the control flow may look
    like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Visualizing a concurrent pattern](img/00013.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: In the previous diagram, we anticipate where data can be shared using concurrent
    and parallel processes to locate points of failure. If we design concurrent applications
    in such graphical ways, we're less likely to find race conditions later on.
  prefs: []
  type: TYPE_NORMAL
- en: While we talked about how Go helps you to locate these after the application
    has completed running, our ideal development workflow is to attempt to cut these
    problems off at the start.
  prefs: []
  type: TYPE_NORMAL
- en: Developing our server requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have an idea of how the scheduling process should work, we need
    to identify components that our application will need. In this case, the components
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A web server handler
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A template for output
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A system for determining dates and times
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Web server
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In our visualizing concurrency example from the previous chapter, we used Go''s
    built-in `http` package, and we''ll do the same here. There are a number of good
    frameworks out there for this, but they primarily extend the core Go functionality
    rather than reinventing the wheel. The following are a few of these functionalities,
    listed from lightest to heaviest:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Web.go: [http://webgo.io/](http://webgo.io/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Web.go is very lightweight and lean, and it provides some routing functionality
    not available in the `net`/`http` package.
  prefs: []
  type: TYPE_NORMAL
- en: 'Gorilla: [http://www.gorillatoolkit.org/](http://www.gorillatoolkit.org/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gorilla is a Swiss army knife to augment the `net`/`http` package. It's not
    particularly heavy, and it is fast, utilitarian, and very clean.
  prefs: []
  type: TYPE_NORMAL
- en: 'Revel: [http://robfig.github.io/revel/](http://robfig.github.io/revel/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Revel is the heaviest of the three, but it focuses on a lot of intuitive code,
    caching, and performance. Look for it if you need something mature that will face
    a lot of traffic.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 6](part0054_split_000.html#page "Chapter 6. C10K – A Non-blocking
    Web Server in Go"), *C10K – A Non-blocking Web Server in Go*, we'll roll our own
    web server and framework with the sole goal of extreme high performance.
  prefs: []
  type: TYPE_NORMAL
- en: The Gorilla toolkit
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'For this application, we''ll partially employ the Gorilla web toolkit. Gorilla
    is a fairly mature web-serving platform that fulfills a few of our needs here
    natively, namely the ability to include regular expressions in our URL routing.
    (Note: Web.Go also extends some of this functionality.) Go''s internal HTTP routing
    handler is rather simplistic; you can extend this, of course, but we''ll take
    a shortcut down a well-worn and reliable path here.'
  prefs: []
  type: TYPE_NORMAL
- en: We'll use this package solely for ease of URL routing, but the Gorilla web toolkit
    also includes packages to handle cookies, sessions, and request variables. We'll
    examine this package a little closer in [Chapter 6](part0054_split_000.html#page
    "Chapter 6. C10K – A Non-blocking Web Server in Go"), *C10K – A Non-blocking Web
    Server in Go*.
  prefs: []
  type: TYPE_NORMAL
- en: Using templates
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As Go is intended as a system language, and as system languages often deal with
    the creation of servers with clients, some care was put into making it a well-featured
    alternative to create web servers.
  prefs: []
  type: TYPE_NORMAL
- en: Anyone who's dealt with a "web language" will know that on top of that you'll
    need a framework, ideally one that handles the presentation layer for the web.
    While it's true that if you take on such a project you'll likely look for or build
    your own framework, Go makes the templating side of things very easy.
  prefs: []
  type: TYPE_NORMAL
- en: 'The template package comes in two varieties: `text` and `http`. Though they
    both serve different end points, the same properties—affording dynamism and flexibility—apply
    to the presentation layer rather than strictly the application layer.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `text` template package is intended for general plaintext documents, while
    the `http` template package handles the generation of HTML and related documents.
  prefs: []
  type: TYPE_NORMAL
- en: These templating paradigms are all too common these days; if you look at the
    `http`/`template` package, you'll find some very strong similarities to Mustache,
    one of the more popular variants. While there is a Mustache port in Go, there's
    nothing there that isn't handled by default in the template package.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For more information on Mustache, visit [http://mustache.github.io/](http://mustache.github.io/).
  prefs: []
  type: TYPE_NORMAL
- en: 'One potential advantage to Mustache is its availability in other languages.
    If you ever feel the need to port some of your application logic to another language
    (or existing templates into Go), utilizing Mustache could be advantageous. That
    said, you sacrifice a lot of the extended functionality of Go templates, namely
    the ability to take out Go code from your compiled package and move it directly
    into template control structures. While Mustache (and its variants) has control
    flows, they may not mirror Go''s templating system. Take the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Given the familiarity with Go's logic structures, it makes sense to keep them
    consistent in our templating language as well.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We won't show all the specific templates in this thread, but we will show the
    output. If you wish to peruse them, they're available at [mastergoco.com/chapters/3/templates](http://mastergoco.com/chapters/3/templates).
  prefs: []
  type: TYPE_NORMAL
- en: Time
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We're not doing a whole lot of math here; time will be broken into hour blocks
    and each will be set to either occupied or available. At this time, there aren't
    a lot of external `date`/`time` packages for Go. We're not doing any heavy-date
    math, but it doesn't really matter because Go's `time` package should suffice
    even if we were.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, as we have literal hour blocks from 9 a.m. to 5 p.m., we just set these
    to the 24-hour time values of 9-17, and invoke a function to translate them into
    linguistic dates.
  prefs: []
  type: TYPE_NORMAL
- en: Endpoints
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''ll want to identify the REST endpoints (via `GET` requests) and briefly
    describe how they''ll work. You can think of these as modules or methods in the
    model-view-controller architecture. The following is a list of the endpoint patterns
    we''ll use:'
  prefs: []
  type: TYPE_NORMAL
- en: '`entrypoint/register/{name}`: This is where we''ll go to add a name to the
    list of users. If the user exists, it will fail.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`entrypoint/viewusers`: Here, we''ll present a list of users with their timeslots,
    both available and occupied.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`entrypoint/schedule/{name}/{time}`: This will initialize an attempt to schedule
    an appointment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each will have an accompanying template that will report the status of the intended
    action.
  prefs: []
  type: TYPE_NORMAL
- en: Custom structs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''ll deal with users and responses (web pages), so we need two structs to
    represent each. One struct is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The other struct is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: We will keep the page as simple as possible. Rather than doing a lot of iterative
    loops, we will produce the HTML within the code for the most part.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our endpoints for requests will relate to our previous architecture, using
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: A multiuser Appointments Calendar
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we''ll quickly look at our sample Appointments Calendar application,
    which attempts to control consistency of specific elements to avoid obvious race
    conditions. The following is the full code, including the routing and templating:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Note that we seeded our application with a user, Bill. If you attempt to hit
    `/register/bill|bill@example.com`, the application will report that the user exists.
  prefs: []
  type: TYPE_NORMAL
- en: As we control the most sensitive data through channels, we avoid any race conditions.
    We can test this in a couple of ways. The first and easiest way is to keep a log
    of how many successful appointments are registered, and run this with Bill as
    the default user.
  prefs: []
  type: TYPE_NORMAL
- en: We can then run a concurrent load tester against the action. There are a number
    of such testers available, including Apache's ab and Siege. For our purposes,
    we'll use JMeter, primarily because it permits us to test against multiple URLs
    concurrently.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although we're not necessarily using JMeter for load testing (rather, we use
    it to run concurrent tests), load testers can be extraordinarily valuable ways
    to find bottlenecks in applications at scales that don't yet exist.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if you built a web application that had a blocking element and
    had 5,000-10,000 requests per day, you may not notice it. But at 5 million-10
    million requests per day, it might result in the application crashing.
  prefs: []
  type: TYPE_NORMAL
- en: In the dawn of network servers, this is what happened; servers scaled until
    one day, suddenly, they couldn't scale further. Load/stress testers allow you
    to simulate traffic in order to better detect these issues and inefficiencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given that we have one user and eight hours in a day, we should end our script
    with no more than eight total successful appointments. Of course, if you hit the
    `/register` endpoint, you will see eight times as many users as you''ve added.
    The following screenshot shows our benchmark test plan in JMeter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A multiuser Appointments Calendar](img/00014.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'When you run your application, keep an eye on your console; at the end of our
    load test, we should see the following message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Had we designed our application as per the initial graphical mockup representation
    in this chapter (with race conditions), it's plausible—and in fact likely—that
    we'd register far more appointments than actually existed.
  prefs: []
  type: TYPE_NORMAL
- en: 'By isolating potential race conditions, we guarantee data consistency and ensure
    that nobody is waiting on an appointment with an otherwise occupied attendee.
    The following screenshot is the list we present of all the users and their available
    appointment times:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A multiuser Appointments Calendar](img/00015.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The previous screenshot is our initial view that shows us available users and
    their available time slots. By selecting a timeslot for a user, we'll attempt
    to book them for that particular time. We'll start with Nathan at 5 p.m.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows what happens when we attempt to schedule with
    an available user:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A multiuser Appointments Calendar](img/00016.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'However, if we attempt to book again (even simultaneously), we''ll be greeted
    with a sad message that Nathan cannot see us at 5 p.m, as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A multiuser Appointments Calendar](img/00017.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: With that, we have a multiuser calendar app that allows for creating new users,
    scheduling, and blocking double-bookings.
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at a few interesting new points in this application.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you will notice that we use a template called `generic.txt` for most
    parts of the application. There''s not much to this, only a page title and body
    filled in by each handler. However, on the `/users` endpoint, we use `users.txt`
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We mentioned the range-based functionality in templates, but how does `{{.FormatAvailableTimes}}`
    work? In any given context, we can have type-specific functions that process the
    data in more complex ways than are available strictly in the template lexer.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the `User` struct is passed to the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This line of code then performs some conditional analysis and returns a string
    with some time conversion.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, you can use either a channel to control the flow of `User.times`
    or an explicit mutex as we have here. We don''t want to limit all locks, unless
    absolutely necessary, so we only invoke the `Lock()` function if we''ve determined
    the request has passed the tests necessary to modify the status of any given user/time
    pair. The following code shows where we set the availability of a user within
    a mutual exclusion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The outer evaluation checks that a user by that name (key) exists. The second
    evaluation checks that the time availability exists (true). If it does, we lock
    the variable, set it to `false`, and then move onto output rendering.
  prefs: []
  type: TYPE_NORMAL
- en: Without the `Lock()` function, many concurrent connections can compromise the
    consistency of data and cause the user to have more than one appointment in a
    given hour.
  prefs: []
  type: TYPE_NORMAL
- en: A note on style
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You''ll note that despite preferring camelCase for most of our variables, we
    have some uppercase variables within structs. This is an important Go convention
    worth mentioning: any struct variable that begins with a capital letter is **public**.
    Any variable that begins with a lowercase letter is **private**.'
  prefs: []
  type: TYPE_NORMAL
- en: If you attempt to output a private (or nonexistent) variable in your template
    files, template rendering will fail.
  prefs: []
  type: TYPE_NORMAL
- en: A note on immutability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Note that whenever possible, we'll avoid using the string type for comparative
    operations, especially in multithreaded environments. In the previous example,
    we use integers and Booleans to decide availability for any given user. In some
    languages, you may feel empowered to assign the time values to a string for ease
    of use. For the most part, this is fine, even in Go; but assuming that we have
    an infinitely scalable, shared calendar application, we run the risk of introducing
    memory issues if we utilize strings in this way.
  prefs: []
  type: TYPE_NORMAL
- en: 'The string type is the sole immutable type in Go; this is noteworthy if you
    end up assigning and reassigning values to a string. Assuming that memory is yielded
    after a string is converted to a copy, this is not a problem. However, in Go (and
    a couple of other languages), it''s entirely possible to keep the original value
    in memory. We can test this using the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'When run in Ubuntu, this takes approximately 1.0 MB of memory; some of that
    no doubt overhead, but a useful reference point. Let''s up the ante a bit—though
    having 1,000 relatively small pointers won''t have much impact—using the following
    line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Now, having gone through 100 million memory assignments, you can see the impact
    on memory (it doesn't help that the string itself is at this point longer than
    the initial, but it doesn't account for the full effect). Garbage collection takes
    place here too, which impacts CPU. On our initial test here, both CPU and memory
    spiked. If we substitute this for an integer or a Boolean assignment, we get much
    smaller footprints.
  prefs: []
  type: TYPE_NORMAL
- en: This is not exactly a real-world scenario, but it's worth noting in a concurrent
    environment where garbage collection must happen so we can evaluate the properties
    and types of our logic.
  prefs: []
  type: TYPE_NORMAL
- en: It's also entirely possible, depending on your current version of Go, your machine(s),
    and so on, and this could run as efficiently in either scenario. While that might
    seem fine, part of our concurrent strategy planning should involve the possibility
    that our application will scale in input, output, physical resources, or all of
    them. Just because something works well now doesn't mean it's not worth implementing
    efficiencies that will keep it from causing performance problems at a 100x scale.
  prefs: []
  type: TYPE_NORMAL
- en: If you ever encounter a place where a string is logical, but you want or could
    benefit from a mutable type, consider a byte slice instead.
  prefs: []
  type: TYPE_NORMAL
- en: A constant is, of course, also immutable, but given that's the implied purpose
    of a constant variable, you should already know this. A mutable constant variable
    is, after all, an oxymoron.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has hopefully directed you towards exploring methods to plan and
    chart out your concurrent applications before delving in. By briefly touching
    on race conditions and data consistency, we attempted to highlight the importance
    of anticipatory design. At the same time, we utilized a few tools for identifying
    such issues, should they occur.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a robust script flowchart with concurrent processes will help you locate
    possible pitfalls before you create them, and it will give you a better sense
    of how (and when) your application should be making decisions with logic and data.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll examine data consistency issues and look at advanced
    channel communication options in an effort to avoid needless and often expensive
    mitigating functions, mutexes, and external processes.
  prefs: []
  type: TYPE_NORMAL
