- en: '*Chapter 11*: Undefined Behavior and Performance'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has a dual focus. On the one hand, it explains the dangers of the
    kinds of undefined behavior that programmers often ignore when attempting to squeeze
    the most performance from their code. On the other hand, it explains how to take
    advantage of the undefined behavior to improve performance and how to properly
    specify and document such situations. Overall, the chapter offers a somewhat unusual
    but more relevant way to understand the issue of the undefined behavior compared
    to the usual "*anything can happen.*"
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding undefined behavior and why it exists
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the truth versus the myths about undefined behavior
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which undefined behavior is dangerous and must be avoided
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to take advantage of undefined behavior
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning the connection between undefined behavior and efficiency and how to
    exploit it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will learn to recognize undefined behavior when it is encountered in (somebody
    else's) code and understand how undefined behavior is related to performance.
    This chapter also teaches you how to use undefined behavior for good by intentionally
    allowing it, documenting it, and placing safeguards around it.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As before, you will need a C++ compiler. In this chapter, we use GCC and Clang,
    but any modern compiler will do. The code accompanying this chapter can be found
    at [https://github.com/PacktPublishing/The-Art-of-Writing-Efficient-Programs/tree/master/Chapter11](https://github.com/PacktPublishing/The-Art-of-Writing-Efficient-Programs/tree/master/Chapter11).
    You will also need a way to examine the assembly code generated by the compiler.
    Many development environments have an option to display assembly code, GCC and
    Clang can write out the assembly code instead of the object code, debuggers and
    other tools can generate assembly code from the object code (disassemble it);
    it's a matter of personal preference which tool you use.
  prefs: []
  type: TYPE_NORMAL
- en: What is undefined behavior?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The concept of `comp.std.c` warns, *"When the compiler encounters (an undefined
    construct), it is legal for it to make demons fly out of your nose."* Launching
    nuclear missiles and neutering your cat (even if you don''t own a cat) have been
    mentioned in a similar context. One of the tangential goals of this chapter is
    to demystify UB: while the ultimate goal is to explain the relationship between
    UB and performance and to show how to take advantage of UB, we cannot do that
    until we can discuss the concept rationally.'
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, what is UB in the context of C++ (or any other programming language)?
    There are specific places in the standard where the words *the behavior is undefined*
    or *the program is ill-formed* are used. The standard further says that if the
    behavior is undefined, the standard *imposes no requirements* on the results.
    The corresponding situations are referred to as UB. For example, refer to the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The standard says that the result of the preceding code is undefined if the
    addition causes integer overflow (that is, if `k` is greater than `INT_MAX-10`).
  prefs: []
  type: TYPE_NORMAL
- en: 'When UB is mentioned, the discussion tends to go toward one of the two extremes.
    The first one we have just seen. The exaggerated language may be well-intentioned
    as a warning against the danger of UB, but it is also a barrier to a rational
    explanation. Your nose is quite safe from the wrath of the compiler, and so is
    your cat. The compiler will, in the end, generate some code from your program,
    and you will run this code. It is not going to give your computer any superpowers:
    anything this program does, you could accomplish intentionally, for example, by
    writing an identical sequence of instructions by hand in assembler. If there is
    no way for you to execute machine instructions that result in launching nuclear
    missiles, your compiler will be unable to do that, UB or no UB (of course, if
    you are programming the missile launch controller, it''s a different game altogether).
    The bottom line is, when your program''s behavior is undefined, according to the
    standard, the compiler can generate code you do not expect, but this code cannot
    do anything that you could not do already.'
  prefs: []
  type: TYPE_NORMAL
- en: 'While overstating the dangers of UB is not helpful, on the flip side, there
    is a tendency to *reason* about UB, which is also an unfortunate practice. For
    example, consider this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: While the C++ standards have progressively tightened the rules on executing
    this kind of expression, the result of this particular one remains undefined in
    C++17\. Many programmers underestimate the danger of this situation. They say,
    *"the compiler will either evaluate k++ first or evaluate k + k first."* To explain
    why this is wrong and dangerous, we have to first split some hairs in the standard.
  prefs: []
  type: TYPE_NORMAL
- en: 'The C++ Standard has three related and often confused categories of behavior:
    `k++ + k` must take place (that would be unspecified behavior, which is not what
    the standard says). The standard says that the entire program is ill-formed and
    imposes no restrictions on its outcome (but before you panic and fear for your
    nose, remember that the result is restricted to some executable code).'
  prefs: []
  type: TYPE_NORMAL
- en: 'A counter-argument is often made stating that whatever the compiler does when
    it compiles the line with UB, it still has to handle the rest of the code in a
    Standard-mandated way, so (the argument goes) the damage is limited to one of
    the possible outcomes from that particular line. Just like it is important to
    not overstate the danger, it is important to understand why this argument is wrong.
    The compiler is written on the assumption that the program is well defined and
    is required to produce the correct results in this case and only in this case.
    There are no preconceptions of what happens if the assumption is violated. One
    way to describe the situation is to say that the compiler is not required to condone
    the UB. Let us go back to our first example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Since the program is ill-defined for a large enough `k` to cause an integer
    overflow, the compiler is allowed to assume that this will never happen. What
    if it does happen? Well, if you compile this function by itself (in a separate
    compilation unit), the compiler will generate some code that produces correct
    results for all `k <= INT_MAX-10`. If there are no whole-program transformations
    in your compiler and linker, the same code will *probably* execute for a larger
    `k`, and the result will be whatever your hardware does in this case. The compiler
    could insert a check for `k`, but it probably won't (with some compiler options,
    it might, though).
  prefs: []
  type: TYPE_NORMAL
- en: 'What if the function is a part of a larger compilation unit? That is where
    things get interesting: the compiler now knows that the input argument to the
    `f()` function is restricted. That knowledge can be used for optimization. For
    example, refer to the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'If the definition of the `f()` function is visible to the compiler, the compiler
    can deduce that the printout never happens: if `k` is large enough for this program
    to print, then the entire program is ill-formed and the standard does not require
    it to print anything. If the value of `k` is within the bounds of defined behavior,
    the program will never print anything. Either way, printing nothing is a valid
    result according to the standard. Note that just because your compiler does not
    currently do this optimization, it does not mean that it never will: this type
    of optimization is becoming more aggressive in newer compilers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So what about our second example? The result of the expression `k++ + k` is
    always undefined for any value of `k`. What can the compiler do with that? Again,
    remember: the compiler is not required to condone UB. The only way this program
    can remain well defined is if this line is never executed. The compiler is allowed
    to assume that this is the case and then reason backward: the function containing
    this code is never called, any conditions necessary for that to happen must be
    true, and so on, up to, possibly, the conclusion that the entire program will
    never be executed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you think that *real compilers don''t do that sort of stuff*, I have a surprise
    for you:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The natural expectation for this program is to print `Before` and hang forever.
    When compiled with GCC (version 9, optimization O3), that is precisely what it
    does. When compiled with Clang (version 13, also O3), it prints `Before`, then
    `After`, and then terminates immediately without any errors (it doesn't crash,
    it just exits). Both outcomes are valid because the results of a program that
    encounters an infinite loop are undefined (unless certain conditions are met,
    none of which apply here).
  prefs: []
  type: TYPE_NORMAL
- en: The preceding example is very instructive for understanding why we have UB at
    all. In the next section, we are going to lift the veil and explain the reasons
    for UB.
  prefs: []
  type: TYPE_NORMAL
- en: Why have undefined behavior?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The obvious question that arises from the last section is, why does the standard
    have UB at all? Why doesn''t it specify the result for every situation? A slightly
    subtler question that acknowledges the reality that C++ is used on a wide variety
    of hardware with very different properties is this: why doesn''t the standard
    fall back on implementation-defined behavior instead of leaving it undefined?'
  prefs: []
  type: TYPE_NORMAL
- en: 'The last example from the previous section provides us with a perfect demonstration
    vehicle for the rationale behind the existence of UB. The statement is that an
    infinite loop is UB; another way of saying that is that the standard does not
    require a specific outcome from a program that enters an infinite loop (the standard
    is more nuanced than that, and some forms of infinite loops will cause the program
    to hang, but these details are not important at the moment). To understand why
    the rule is there, consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The loops are identical, so we are paying the overhead of the loop (increment
    of the loop variable and comparison) twice. The compiler clearly should do the
    following optimization by folding the loops together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Note, however, that this transformation is valid only if the first loop terminates;
    otherwise, the count `n2` should never be incremented at all. It is impossible
    to know during compilation whether the loop terminates – it depends on the value
    of `n`. If `n` is odd, the loop runs forever (unlike signed integer overflow,
    incrementing the unsigned type `size_t` past its maximum value is well defined,
    and the value rolls over back to zero). In general, it is not possible for the
    compiler to prove that a particular loop eventually terminates (this is a known
    NP-complete problem). The decision was made to assume that every loop eventually
    terminates and to allow the optimizations that would otherwise be invalid. Because
    these optimizations can make a program with an infinite loop invalid, such loops
    are considered UB, meaning the compiler does not have to preserve the behavior
    of a program with an infinite loop.
  prefs: []
  type: TYPE_NORMAL
- en: To avoid oversimplifying the issue, we must mention that not all types of UB
    defined in the C++ Standard have similar reasoning behind them. Some UB is introduced
    because the language has to be supported on different types of hardware, and some
    of these cases can be considered obsolete today. As this is a book on performance,
    we will focus on examples of UB that exist for reasons of efficiency or that can
    be used to improve certain optimizations.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will see more examples of how the compiler can use UB
    to its (and your) advantage.
  prefs: []
  type: TYPE_NORMAL
- en: Undefined behavior and C++ optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have just seen one example in the previous section, where, by assuming that
    every loop in the program eventually terminates, the compiler is able to optimize
    certain loops and the code containing these loops. The fundamental logic used
    by the optimizer is always the same: first, we assume that the program does not
    exhibit UB. Then, we deduce the conditions that must be true in order for this
    assumption to hold and assume that these conditions are indeed always true. Finally,
    any optimization that is valid under such assumptions may proceed. The code generated
    by the optimizer will do *something* if the assumptions are violated, but we have
    no way of knowing what it will be (beyond the already mentioned restrictions that
    it''s still the same computer executing some sequence of instructions).'
  prefs: []
  type: TYPE_NORMAL
- en: Almost every case of UB documented in the standard can be converted into an
    example of a possible optimization (whether a particular compiler takes advantage
    of this is a different matter). We are going to see several more examples now.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we have already mentioned, the result of overflowing a signed integer is
    undefined. The compiler is allowed to assume that this never happens and that
    incrementing a signed integer by a positive number always results in a greater
    integer. Do the compilers actually perform this optimization? Let''s find out.
    Compare these two functions, `f()` and `g()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Within the realm of well-defined behavior, these functions are identical. We
    could try to benchmark them to determine whether the compiler optimizes away the
    entire expression in `f()` but, as we have seen in the previous chapter, there
    is a more reliable way. If both functions generate the same machine code, they
    are definitely identical.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1 – x86 assembly output generated by GCC9 for the f() (left) and
    g() (right) functions'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.1_B16229.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.1 – x86 assembly output generated by GCC9 for the f() (left) and g()
    (right) functions
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Figure 11.1*, we can see that with optimization turned on, GCC indeed generates
    the same code for both functions (so does Clang). The names of the functions that
    show up in the assembly are so-called mangled names: since C++ allows functions
    with different parameter lists to have the same name, it has to generate a unique
    name for each of such functions. It does so by encoding the types of all parameters
    into the name that is actually used in the object code.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to validate that this code indeed does not have any trace of the
    `?:` operator, the easiest way is to compare the `f()` function with a function
    that does the same computation using unsigned integers. Refer to the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Overflow of unsigned integers is well defined, and it is, in general, not true
    that `i + 1` is always greater than `i`.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.2 – X86 assembly output generated by GCC9 for the f() (left) and
    h() (right) functions'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.2_B16229.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.2 – X86 assembly output generated by GCC9 for the f() (left) and h()
    (right) functions
  prefs: []
  type: TYPE_NORMAL
- en: The `h()` function produces different code, and you can guess that the `cmp`
    instruction does a comparison even if you are not fluent in X86 assembly. On the
    left, the function `f()` loads the constant value of `0x1`, otherwise known as
    `true` for Booleans, into the register EAX that is used to return the result.
  prefs: []
  type: TYPE_NORMAL
- en: 'This example also demonstrates the danger of trying to reason about UB or treat
    it as implementation-defined: if you were to say that the program will do *some
    kind of addition* for the integers and if it overflows, the particular hardware
    would do whatever it does, and you would be very wrong. A compiler may, and some
    do, generate code with no increment instructions at all.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We now, finally, have enough knowledge to fully elucidate the mystery whose
    seeds were planted all the way at the beginning of the book, in [*Chapter 2*](B16229_02_Epub_AM.xhtml#_idTextAnchor026),
    *Performance Measurements*. In that chapter, we observed an unexpected performance
    difference between two almost identical implementations of the same function.
    The function''s job was to compare two strings, character by character, and return
    `true` if the first string is lexicographically greater. This was our most compact
    implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This function was used to sort strings, so the benchmark measured the time
    of sorting a particular input set of strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.3 – Sorting benchmark using the compare1() function for string
    comparison'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.4_B16229.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.3 – Sorting benchmark using the compare1() function for string comparison
  prefs: []
  type: TYPE_NORMAL
- en: 'The comparison implementation is as compact as it gets; there is nothing unnecessary
    in this code. However, the surprising result was that this was one of the worst-performing
    versions of the code. The best-performing version was almost the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The only difference is the type of the loop variable: `unsigned int` in `compare1()`
    versus `int` in `compare2()`. Since the indices are never negative, this should
    make no difference whatsoever, but it does:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.4 – Sorting benchmark using the compare2() function for string
    comparison'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.5_B16229.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.4 – Sorting benchmark using the compare2() function for string comparison
  prefs: []
  type: TYPE_NORMAL
- en: 'The reason for this significant performance difference again has to do with
    UB. To understand what is going on, we will have to examine the assembly code
    again. *Figure 11.5* shows the code generated by GCC for both functions (only
    the most relevant part, the string comparison loop, is shown):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.5 – X86 assembly generated for the compare1() (left) and compare2()
    (right) functions'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.5_B16229.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.5 – X86 assembly generated for the compare1() (left) and compare2()
    (right) functions
  prefs: []
  type: TYPE_NORMAL
- en: 'The code looks pretty similar, with one exception: on the right (`compare2()`),
    you can see the `add` instruction, which is used to increment the loop index by
    1 (the compiler optimized the code by replacing two loop variables with just one).
    On the left, there is nothing that looks like an addition or increment. Instead,
    there is the `lea` instruction, which stands for Load and Extend Address, but
    is used here to increment the index variable by 1 (the same optimization is done;
    there is only one loop variable).'
  prefs: []
  type: TYPE_NORMAL
- en: 'With everything you have learned up to now, you should be able to guess why
    the compiler has to generate different code: while the programmer expects the
    index to never overflow, the compiler, in general, cannot make this assumption.
    Note that both versions use 32-bit integers, but the code is generated for a 64-bit
    machine. If a 32-bit signed `int` overflows, the result is undefined, so in this
    case, the compiler does make the assumption that the overflow never happens. If
    the operation does not overflow, the `add` instruction produces the correct result.
    For `unsigned int`, the compiler has to allow for the possibility of the overflow:
    incrementing `UINT_MAX` should give 0\. It turns out that the `add` instruction
    on x86-64 does not have these semantics. Instead, it extends the result to become
    a 64-bit integer. The best option for 32-bit unsigned integer arithmetic on X86
    is the `lea` instruction; it does the job but is much slower.'
  prefs: []
  type: TYPE_NORMAL
- en: This example demonstrates how, by reasoning backward from the assumption that
    the program is well defined and UB never happens, the compiler can enable a very
    effective optimization that ends up making the entire sort operation several times
    faster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we understand what is going on in our code, we can explain the behavior
    of several other versions of the code. First of all, using 64-bit integers, signed
    or unsigned, will give us the same fast performance as the 32-bit signed integers:
    in all cases, the compiler will use `add` (for 64-bit unsigned values, it does
    have the correct overflow semantics). Second, if the maximum index, or the string
    length, is used, the compiler will deduce that the index cannot overflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The unnecessary comparison with the length makes this version slightly slower
    than the best variant. The most reliable way to avoid accidentally running into
    this problem is to always use signed loop variables or use the unsigned integer
    of the size native to the hardware (so, avoid doing `unsigned int` math on 64-bit
    processors unless you really need it).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can construct similar demonstrations using almost any other situation described
    as undefined behavior in the standard (although there is no guarantee that a particular
    compiler will take advantage of a possible optimization). Here is one more example
    that uses pointer dereference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a simplification of a pretty common situation where the programmer
    has coded pointer checks to protect against null pointers, but hasn''t done so
    everywhere. The second line (the increment) is UB if the input argument is a null
    pointer. This means the entire program''s behavior is undefined, so the compiler
    can assume it never happens. Examination of the assembly code shows that, indeed,
    the comparison in the third line is eliminated:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.6 – X86 assembly generated for the f() function with (left) and
    without (right) the ?: operator'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.6_B16229.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.6 – X86 assembly generated for the f() function with (left) and without
    (right) the ?: operator'
  prefs: []
  type: TYPE_NORMAL
- en: 'The same happens if we do the pointer check first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, an examination of the assembly code will show that the pointer comparison
    is eliminated, even though the program behavior up to this point is well defined.
    The reasoning is the same: if the pointer `p` is not null, the comparison is redundant
    and can be omitted. If `p` is null, the behavior of the program is undefined,
    which means the compiler can do whatever it wants, and what it wants is to omit
    the comparison. The end result is, whether `p` is null or not, the comparison
    can be eliminated.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the last chapter, when we studied compiler optimizations, we devoted a great
    deal of time to the analysis of what optimizations are possible because the compiler
    can prove that they are safe. We are going to revisit this issue because, first,
    it is absolutely essential for understanding compiler optimizations, and second,
    there is a connection with UB. We have just seen that when the compiler deduces
    some information from a particular statement (such as `p is non-null` deduced
    from the `return` statement), that knowledge is used to optimize not just following
    but also preceding code. The limitations on propagating such knowledge arise from
    what else the compiler can prove with certainty. To demonstrate, let''s modify
    the previous example slightly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the compiler will not eliminate the pointer check, which can
    be seen in the produced assembly code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.7 – X86 assembly generated for the f() function with (left) and
    without (right) the pointer check'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.7_B16229.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.7 – X86 assembly generated for the f() function with (left) and without
    (right) the pointer check
  prefs: []
  type: TYPE_NORMAL
- en: The `test` instruction does a comparison with null (zero) and is followed by
    a conditional jump – this is what the `if` statement looks like in assembly.
  prefs: []
  type: TYPE_NORMAL
- en: Why didn't the compiler optimize away the check? To answer this question, you
    have to figure out under what conditions this optimization would have changed
    the *well-defined* behavior of the program.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following two things are needed to make the optimization invalid:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, the `g()` function must know whether the pointer `p` is null. This is
    possible: for example, `p` could also be stored in a global variable by the caller
    of `f()`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Second, if `p` is null, the `return` statement must not be executed. This is
    also possible: `g()` may throw an exception if `p` is null.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For our final example of C++ optimizations that are strongly related to UB,
    we are going to look at something very different: the effect of the `const` keyword
    on the optimization. Again, this will teach us just as much about why the compiler
    cannot optimize certain code as it does with successful optimizations. We are
    going to start with the code fragment we saw earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'An optimizing compiler will, as we have seen, eliminate all the code from this
    function and replace it with `return true`. Now we will make the function do some
    more work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The same optimization is, of course, possible, since the code can be rewritten
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The call to `g()` must be made, but the function still returns `true`: the
    comparison cannot produce anything else without lapsing into undefined behavior.
    Again, most compilers will do this optimization. We can confirm this by comparing
    the assembly generated from our original code with that generated from the fully
    hand-optimized code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The only reason the optimization is possible is because the `g()` function
    does not change its argument. In the same code, if `g()` takes the argument by
    reference, the optimization is no longer possible:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Now the `g()` function could change the value of `y`, so the comparison has
    to be made every time. If the intent for the function `g()` is not to change its
    arguments, we could, of course, just pass them by value (as we have already seen).
    The other option is to pass by `const` reference; while there is no reason to
    do so for small types, such as integers, template code often generates such functions.
    In this case, our code looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'A quick examination of the assembler shows that the `return` statement is not
    optimized: it still does the comparison. Of course, the fact that a particular
    compiler does not do a certain optimization proves nothing: no optimizer is perfect.
    But in this case, there is a reason for it. Despite what the code says, the C++
    Standard does not guarantee that the `g()` function does not change its argument!
    Here is an entirely Standard-compliant implementation that elucidates the issue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Yes, a function is allowed to cast away `const`. The result is well defined
    and is specified in the standard (which does not make it a *good* code, just a
    valid one). There is one exception, however: casting away `const` from an object
    that was declared `const` at the point of its creation is UB. To illustrate, this
    is well defined (but ill-advised):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This is UB:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'We can try to take advantage of this by declaring the intermediate variable
    `y` as `const`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Now the compiler can assume that the function always returns `true`: the only
    way to change that is to invoke UB, and the compiler is not required to condone
    UB. At the time of the writing of this book, we are not aware of any compiler
    that actually does this optimization.'
  prefs: []
  type: TYPE_NORMAL
- en: With this in mind, what can be recommended with regard to the use of `const`
    to promote optimization?
  prefs: []
  type: TYPE_NORMAL
- en: If a value is not changing, declare it as `const`. While correctness is the
    main benefit, this does enable some optimizations, especially when the compiler
    can propagate the `const` by evaluating expressions at compile time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even better for the optimization, if the value is known at compile-time, declare
    it `constexpr`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Passing parameters by `const` reference to functions does next to nothing for
    optimization since the compiler has to assume that the function may cast away
    `const` (if the function is inlined, the compiler knows exactly what's going on,
    but then it doesn't matter how the parameters are declared). On the other hand,
    this is the only way you can pass a `const` object to a function, so yes, declare
    references to be `const` whenever possible (the more important result is the clarity
    of the intent).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For small types, pass-by-value can be more efficient than pass-by-reference
    (this does not apply to inlined functions). This is difficult to reconcile with
    generic functions generated by templates (don't assume that the templates are
    always inlined; large template functions often aren't). There are ways to force
    pass-by-value for specific types, but they make your template code much more cumbersome.
    Never start by writing such code; do it only if the measurements show that, for
    a particular piece of code, the effort is justified.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have explored in detail how UB in C++ affects the optimization of C++ code.
    It is now time to turn the tables and learn how to take advantage of UB in your
    own programs.
  prefs: []
  type: TYPE_NORMAL
- en: Using undefined behavior for efficient design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to talk about UB not as it is specified by the
    standard and applies to C++, but as it is specified by you, the programmer, and
    applies to your software. To get there, it is helpful first to consider UB from
    a different point of view.
  prefs: []
  type: TYPE_NORMAL
- en: All the examples of UB that we have seen so far can be divided into two kinds.
    The first kind is code such as `++k + k`. These are bugs, since such code has
    no defined behavior at all. The second kind is code such as `k + 1`, where `k`
    is a signed integer. This code is everywhere, and most of the time, it works just
    fine. Its behavior is well defined except for certain values of the variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'In other words, the code has implicit preconditions: as long as these preconditions
    are satisfied, the program is well behaved. Note that in the larger context of
    the program, these preconditions may or may not be implicit: the program may validate
    the inputs or intermediate results and guard against values that would cause UB.
    Either way, the programmer has defined a contract with the user: if the inputs
    obey certain restrictions, the results are guaranteed to be correct; in other
    words, the program behaves in a well-defined way.'
  prefs: []
  type: TYPE_NORMAL
- en: What happens when the restrictions are violated?
  prefs: []
  type: TYPE_NORMAL
- en: 'There are the following two possibilities:'
  prefs: []
  type: TYPE_NORMAL
- en: First, the program may detect that the inputs are out of contract and handle
    the error. This behavior is still well defined and is a part of the specification.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second, the program may fail to detect that the contract is violated and proceed
    as it usually does. Since the contract was essential to guarantee the correct
    result, the program now operates in uncharted territory, and there is, generally,
    no way to predict what is going to happen.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We just described UB.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand that UB is simply the behavior of the program that is
    operating outside of the specified contract, let's think about how it applies
    to our software.
  prefs: []
  type: TYPE_NORMAL
- en: Most programs that are complex enough have preconditions on their inputs, a
    contract with the user. One could argue that these preconditions should always
    be checked and any errors reported. However, this can be a very expensive requirement.
    Again, let's consider an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'We want to write a program that scans an image drawn on a piece of paper (or
    etched on a printed circuit board) and converts it to a graph data structure.
    The input to the program may look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.8 – Graph drawing is an input to the graph construction program'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.8_B16229.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.8 – Graph drawing is an input to the graph construction program
  prefs: []
  type: TYPE_NORMAL
- en: The program acquires the image, recognizes rectangles, creates graph nodes from
    each one, recognizes the lines, for each line figures out which two rectangles
    it connects, and creates a corresponding edge in the graph.
  prefs: []
  type: TYPE_NORMAL
- en: Let's assume that we have an image acquisition and analysis library that gives
    us a set of shapes (rectangles and lines) with all their coordinates. All we have
    to do now is figure out which lines connect which rectangles. We have all the
    coordinates, so it's pure geometry from now on. One of the simplest ways to represent
    this graph is as a table of edges. We can use any container (say, a vector) for
    the table, and if we assign each node a unique numeric ID, an edge is just a pair
    of numbers. We can use any number of computational geometry algorithms to detect
    intersections between lines and rectangles and construct this table (and, with
    it, the graph itself) edge by edge.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sounds simple enough, and we have a natural representation of the data that
    is fairly compact and easy to work with. Unfortunately, we also have an implicit
    contract with the user: we ask that every line intersects exactly two rectangles
    (also, that rectangles do not intersect each other, but one mess at a time).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.9 – Invalid input for the graph recognition program'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.9_B16229.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.9 – Invalid input for the graph recognition program
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Figure 11\. 9*, we see an example of input that violates the contract:
    one of the lines connects three rectangles, while the other touches just one.
    As we discussed earlier, we have two options: we can detect and report the input
    errors, or we can ignore them. The first option makes our program robust but carries
    a significant performance penalty: our original program could stop looking for
    rectangles connected to a given edge after it found the second such rectangle
    and just ignore the edge from then on. The gain from this optimization turns out
    to be considerable: for a graph that looks like *Figure 11.8* (but much larger),
    it may cut the run time by half. Enforcing input validation wastes a lot of time
    if the input ends up being correct and frustrates the users who have other ways
    of ensuring that the input is valid. Not validating the input leads to UB: if
    we have a line connecting three rectangles, the algorithm will stop after finding
    the first two in whatever order it processes them (and this order may be data-dependent,
    so all you can really say about this situation is that an edge will be created
    between two of the nodes involved).'
  prefs: []
  type: TYPE_NORMAL
- en: 'If the performance difference was insignificant (or the overall runtime was
    so short that doubling it doesn''t matter), the best solution would be clear:
    validate the inputs. But in this and many other cases, validation is easily as
    expensive as finding the solution. What should be done in such cases?'
  prefs: []
  type: TYPE_NORMAL
- en: First and foremost, we must be clear about the contract we are imposing on the
    user. We should clearly specify and document what constitutes a valid input. After
    that, the best practice for performance-critical programs is to deliver the best
    performance. A broader contract (the one that imposes fewer restrictions) is always
    better than a narrow contract, so if there are some invalid inputs we can easily
    detect and handle with minimal overhead, this should be done. Beyond that, all
    we can do is document the conditions when the behavior of the program is undefined,
    just like it is done in the C++ Standard.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is some extra effort that we can make: we can offer our users an input
    validation tool, either as an optional step in the program or as a separate piece
    of software. Running it will take time, but if the user is getting strange results
    from the main program, they can check to make sure the inputs are valid. This
    is highly preferable to simply describing when the behavior is undefined (however,
    there are cases where such validation is too expensive to be practical).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Wouldn''t it be nice if the C++ compiler developers made the same extra effort
    for us, the programmers, and gave us an optional tool to detect UB in our code?
    As it turns out, the developers thought so too: many compilers today have an option
    to enable the UB sanitizer (often called **UBSan**). This is how it works. Let''s
    start with some code that can result in UB:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Write a program that calls this function with a large enough argument (greater
    than `INT_MAX-10`) and compile it with the UBSan enabled. For Clang or GCC, the
    option is `-fsanitize=undefined`. Here''s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the program, and you will see something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Just like in our graph example, UB detection takes time and makes the program
    slower, so this is something you should do in testing and debugging. Make sanitized
    runs part of your regular regression testing, and do take the reported errors
    seriously: just because your program produces correct results today does not mean
    that the next compiler will not generate some very different code and change the
    results.'
  prefs: []
  type: TYPE_NORMAL
- en: We have learned about UB, why it is sometimes a necessary evil, and how to take
    advantage of it to improve performance. Before you flip the page, let's recap
    what we have learned.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have a whole chapter dedicated to the subject of UB in C++ and in programs
    in general. Why? Because this subject is inextricably linked to performance.
  prefs: []
  type: TYPE_NORMAL
- en: First of all, understand that UB occurs when the program receives an input that
    is outside of the contract that specifies the program's behavior. In addition,
    the specification also says that the program is not required to detect such input
    and issue a diagnostic. This is true for the UB as defined by the C++ Standard
    and for the UB of your own program.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, the reason the specification (or the standard) does not cover all possible
    inputs and defining the results is mostly related to performance: UB is often
    introduced when it would be very expensive to produce a specific result reliably.
    For UB in C++, the variety of processor and memory architectures also leads to
    cases that are difficult to handle uniformly. Without a viable way to guarantee
    a specific result, the standard leaves the outcome undefined.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the reason the program is not required to at least detect, if not
    handle, the invalid input is that such detection may also be very costly: sometimes
    it takes longer to confirm that the input is valid than to compute the result.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You should keep these considerations in mind when designing software: it is
    always desirable to have a broad contract that defines the outcome for any or
    almost any input. But doing so can impose performance overhead on users who only
    provide the typical or "normal" input. When offered a choice between faster execution
    of a task the user wants to do and reliable execution of a task the user never
    wants to solve in the first place, most users will choose performance. As a compromise,
    you can offer the users a way to validate the inputs; if this validation is costly,
    it should be optional.'
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to UB laid out by the C++ Standard, the tables are turned, and
    you are the user. It is essential to understand that if a program includes code
    with UB, the entire program is ill-defined, not just the one line in question.
    This is because the compiler can assume that UB never happens at runtime and reason
    backward from that to make the corresponding optimizations to your code. Modern
    compilers all do that to some extent, and future compilers will only be more aggressive
    in their deductions.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, many compiler developers also offer validation tools that can detect
    undefined behavior at run time – UB sanitizers. Just like a validator for the
    input of your own program, these tools take time to run, which is why the sanitizer
    is an optional tool. You should take advantage of it in your software testing
    and development process.
  prefs: []
  type: TYPE_NORMAL
- en: We are almost at the end of the book; in the next, which is the final chapter,
    we will review everything we have learned with an eye for the implications and
    lessons for designing software.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is undefined behavior?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why can't we define the results for any situation the program may encounter?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If I write code the standard labels as UB, test the result, and verify that
    the code works, I'm OK, right?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why would I want to intentionally design a program that has documented undefined
    behavior?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
