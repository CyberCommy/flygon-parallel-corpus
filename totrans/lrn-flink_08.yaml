- en: Chapter 8. Distributed Data Processing with Flink and Hadoop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apache Hadoop has become a core and essential part of data processing and analytics
    infrastructures over the last couple of years. With Hadoop 1.X, the community
    learnt the distributed data processing using the MapReduce framework, whereas
    the next version of Hadoop, 2.X taught us the efficient use of resources and scheduling
    using the YARN framework. The YARN framework is a core part of Hadoop data processing,
    where it handles complex tasks such as job executions, distribution, resource
    allocation, scheduling, and so on. It allows for multi-tenancy, scalability, and
    high availability.
  prefs: []
  type: TYPE_NORMAL
- en: The best part about YARN is that it is not just a framework but more like a
    complete operating system where developers are free to develop and execute applications
    of their choice. It gives abstraction by letting developers only focus on application
    development and forget the pain of data and execution distribution in parallel.
    YARN sits on top of the Hadoop Distributed File System and can also read data
    from filesystems such as AWS S3.
  prefs: []
  type: TYPE_NORMAL
- en: The YARN application framework has been built so well that it can host any distributed
    processing engine. In recent times, there has been a significant rise in new distributed
    data processing engines such as Spark, Flink, and so on. As they are built to
    be executed on a YARN cluster, it becomes very easy for people to try new things
    in parallel on the same YARN cluster. This means we can run Spark as well as Flink
    jobs on the same cluster using YARN. In this chapter, we are going to see how
    we can make use of existing Hadoop/YARN clusters to execute our Flink job in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: So let's get started.
  prefs: []
  type: TYPE_NORMAL
- en: Quick overview of Hadoop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most of you will be already aware of Hadoop and what it does but for those who
    are new to the world of distributed computing, let me try to give a brief introduction
    to Hadoop.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hadoop is a distributed, open source data processing framework. It consists
    of two important parts: one data storage unit, **Hadoop Distributed File System**
    (**HDFS**) and the resource management unit, **Yet Another Resource Negotiator**
    (**YARN**). The following diagram shows a high-level overview of the Hadoop ecosystem:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Quick overview of Hadoop](img/image_08_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: HDFS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: HDFS, as the name suggests, is a highly available, distributed filesystem used
    for data storage. These days, this is one of the core frameworks of most companies.
    HDFS consists of a master-slave architecture, with daemons such as NameNode, secondary
    NameNode, and DataNode.
  prefs: []
  type: TYPE_NORMAL
- en: In HDFS, NameNode stores metadata about the files to be stored while DataNode
    stores the actual block comprising a file. Data blocks are by default three-fold
    replicated in order to achieve high availability. A secondary NameNode is used
    for backing up the filesystem metadata stored on NameNode.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Here is a link where you can read more about HDFS at [http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html).
  prefs: []
  type: TYPE_NORMAL
- en: YARN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Prior to YARN, MapReduce was the data processing framework which ran on top
    of HDFS. But people started realizing its limitation of number of task trackers
    a job tracker can handle. This gave rise to YARN. The fundamental idea behind
    YARN is to separate the resource management and scheduling tasks. YARN has the
    global resource manager and per application--the application master. The resource
    manager works on master nodes whereas it has a per worker node agent--the node
    manager, which is responsible for managing containers, monitoring their usage
    (CPU, disk, memory) and reporting back to the resource manager.
  prefs: []
  type: TYPE_NORMAL
- en: The resource manager has two important components--**scheduler** and **applications
    manager**. Scheduler is responsible for scheduling applications in the queue while
    applications manager takes care of accepting job submissions, negotiating first
    container to the application specific application master. It is also responsible
    for restarting the **application master** in case of failure.
  prefs: []
  type: TYPE_NORMAL
- en: Because of operating systems like nature, YARN provides API which can be extended
    to build applications. **Spark** and **Flink** are great examples of this.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Here is a link where you can read more about YARN at [http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html).
  prefs: []
  type: TYPE_NORMAL
- en: Now let's look at how we can use Flink on YARN.
  prefs: []
  type: TYPE_NORMAL
- en: Flink on YARN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Flink has been built-in supported to be execution-ready on YARN. Any application
    build using Flink APIs can be executed on YARN without much effort. Users don''t
    need to set up or install anything if they already have a YARN cluster. Flink
    expects the following requirements to be met:'
  prefs: []
  type: TYPE_NORMAL
- en: Hadoop version should be 2.2 or above
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HDFS should be up-and-running
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configurations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to run Flink on YARN, the following configurations needs to be done.
    First of all, we need to download the Hadoop compatible version of the Flink distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The binaries are available for download at [http://flink.apache.org/downloads.html](http://flink.apache.org/downloads.html).
    You have to choose from the following options.
  prefs: []
  type: TYPE_NORMAL
- en: '![Configurations](img/image_08_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Let's assume we are running Hadoop 2.7 and Scala 2.11\. We will download the
    specific binary and store it on a node where Hadoop is installed and running.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once downloaded, we need to extract the `tar` files as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Starting a Flink YARN session
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once the binaries are extracted, we can start the Flink session. A Flink session
    is a session which starts all required Flink services (Job Manager and Task Managers)
    on respective nodes so that we can start executing Flink jobs. To start the Flink
    session, we have the following executable with the given options:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We have to make sure that the `YARN_CONF_DIR` and `HADOOP_CONF_DIR` environment
    variables are set so that Flink can find the required configurations. Now let's
    start the Flink session by providing information.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how we start the Flink session by giving the details about the number
    of task managers, memory for each task manager, and slots to be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: If the configuration directories are not set properly, you will get an error
    mentioning the same. In that case, first you can set the configuration directories
    and then start the Flink YARN session.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following command sets the configuration directories:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can also check the Flink Web UI as by hitting the following URL: `http://host:8088/proxy/application_<id>/#/overview.`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the screenshot of the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Starting a Flink YARN session](img/image_08_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Similarly, we can also check the YARN application UI at `http://myhost:8088/cluster/app/application_1478079131011_0107`.
  prefs: []
  type: TYPE_NORMAL
- en: '![Starting a Flink YARN session](img/image_08_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Submitting a job to Flink
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have a Flink session connected to YARN, we are all set to submit
    a Flink job to YARN.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the following command with options to submit the Flink job:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We can execute the Flink job using the run action. We have the following options
    in run:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Option** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `-c`, `--class <classname>` | Class with the program entry point (`main()`
    method or `getPlan()` method). Only needed if the JAR file does not specify the
    class in its manifest. |'
  prefs: []
  type: TYPE_TB
- en: '| `-C`, `--classpath <url>` | Adds a URL to each user code classloader on all
    nodes in the cluster. The paths must specify a protocol (for example, `file://`)
    and be accessible on all nodes (for example, by means of an NFS share). You can
    use this option multiple times for specifying more than one URL. The protocol
    must be supported by `{@link java.net.URLClassLoader}`. This can be used in case
    you wish to use certain third-party libraries with Flink YARN session. |'
  prefs: []
  type: TYPE_TB
- en: '| `-d`, `--detached` | If present, runs the job in detached mode. Detached
    mode can be useful when you don''t want to keep running the Flink YARN session
    all the time. In this case, Flink client will only submit the job and will detach
    itself. We cannot stop detached Flink YARN session using Flink commands. To do
    so, we have to kill the application using YARN commands `yarn application -kill
    <appId>` |'
  prefs: []
  type: TYPE_TB
- en: '| `-m`, `--jobmanager <host:port>` | Address of the Job Manager (master) in
    which to connect. Use this flag to connect to a different Job Manager than the
    one specified in the configuration. |'
  prefs: []
  type: TYPE_TB
- en: '| `-p`, `--parallelism <parallelism>` | The parallelism with which to run the
    program. Optional flag to override the default value specified in the configuration.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `-q`, `--sysoutLogging` | If present, suppresses logging output to standard
    `OUT`. |'
  prefs: []
  type: TYPE_TB
- en: '| `-s`, `--fromSavepoint <savepointPath>` | Path to a save point to reset the
    job back to, for example `file:///flink/savepoint-1537`. Savepoints are externally
    stored states of a Flink program. They are snapshots which are stored to a certain
    location. If Flink program fails, we can resume it from its last stored save point.
    More details on save points [https://ci.apache.org/projects/flink/flink-docs-release-1.2/setup/savepoints.html](https://ci.apache.org/projects/flink/flink-docs-release-1.2/setup/savepoints.html)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `-z`, `--zookeeperNamespace <zookeeperNamespace>` | Namespace to create the
    Zookeeper sub-paths for high availability mode |'
  prefs: []
  type: TYPE_TB
- en: 'The following options are available for the `yarn-cluster` mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Option** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `-yD <arg>` | Dynamic properties |'
  prefs: []
  type: TYPE_TB
- en: '| `yd`, `--yarndetached` | Start detached |'
  prefs: []
  type: TYPE_TB
- en: '| `-yid`, `--yarnapplicationId <arg>` | Attach to running YARN session |'
  prefs: []
  type: TYPE_TB
- en: '| `-yj`, `--yarnjar <arg>` | Path to Flink jar file |'
  prefs: []
  type: TYPE_TB
- en: '| `-yjm`, `--yarnjobManagerMemory <arg>` | Memory for Job Manager container
    (in MB) |'
  prefs: []
  type: TYPE_TB
- en: '| `-yn`, `--yarncontainer <arg>` | Number of YARN containers to allocate (=
    number of task managers) |'
  prefs: []
  type: TYPE_TB
- en: '| `-ynm`, `--yarnname <arg>` | Sets a custom name for the application on YARN
    |'
  prefs: []
  type: TYPE_TB
- en: '| `-yq`, `--yarnquery` | Displays available YARN resources (memory, cores)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `-yqu`, `--yarnqueue <arg>` | Specifies YARN queue |'
  prefs: []
  type: TYPE_TB
- en: '| `-ys`, `--yarnslots <arg>` | Number of slots per Task Manager |'
  prefs: []
  type: TYPE_TB
- en: '| `-yst`, `--yarnstreaming` | Starts Flink in streaming mode |'
  prefs: []
  type: TYPE_TB
- en: '| `-yt`, `--yarnship <arg>` | Ships files in the specified director (t for
    transfer) |'
  prefs: []
  type: TYPE_TB
- en: '| `-ytm`, `--yarntaskManagerMemory <arg>` | Memory per TaskManager ontainer
    (in MB) |'
  prefs: []
  type: TYPE_TB
- en: '| `-yz`, `--yarnzookeeperNamespace <arg>` | Namespace to create the Zookeeper
    sub-paths for high availability mode |'
  prefs: []
  type: TYPE_TB
- en: Now let's try to run a sample word count example on YARN. The following are
    the steps to do so.
  prefs: []
  type: TYPE_NORMAL
- en: 'First let''s have input file stored on HDFS as input to the word count program.
    Here we are going to run the word count on Apache License text. The following
    is the way we download and store it on HDFS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we will submit the example word count job:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This will invoke the Flink job which would get executed on the YARN cluster.
    You should see the console as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The following are the screenshots of the job execution from the Flink application
    master UI. Here is the screenshot of the Flink execution plan:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Submitting a job to Flink](img/image_08_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Next we can see the screenshot of the steps getting executed for this job:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Submitting a job to Flink](img/image_08_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'And at last we have the screenshot of the timeline of the Flink job execution.
    The timeline shows all the steps that can be executed in parallel and what needs
    to be executed sequentially:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Submitting a job to Flink](img/image_08_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Stopping Flink YARN session
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once the processing is done, you can stop the Flink YARN session in two ways.
    First you can simple do a *Cltr*+*C* on the console where you started the YARN
    session. This will send the termination signal and stop the YARN session.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second way is to execute the following command to stop the session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see immediately the Flink YARN application get killed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Running a single Flink job on YARN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can also run a single Flink job on YARN without blocking the resources for
    the YARN session. This is a good option if you only wish to run a single Flink
    job on YARN. In the earlier case, when we start the Flink session on YARN, it
    blocks the resources and cores until we stop the session whereas in this case
    the resources are blocked till the job is executing and they are freed up as soon
    as the job is complete. The following command shows how we execute a single Flink
    job on YARN without a session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see similar results as we saw in the earlier case. We can also track
    its progress and debugging using the YARN application UI. The following is a sample
    screenshot of the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Running a single Flink job on YARN](img/image_08_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Recovery behavior for Flink on YARN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Flink on YARN provides the following configuration parameters for tuning the
    recovery behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Parameter** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `yarn.reallocate-failed` | Sets whether Flink should reallocate failed task
    manager containers. The default is `true`. |'
  prefs: []
  type: TYPE_TB
- en: '| `yarn.maximum-failed-containers` | Sets the maximum number of failed containers
    the application master accepts before failing the YARN session. The default is
    number of task managers requested during initiation. |'
  prefs: []
  type: TYPE_TB
- en: '| `yarn.application-attempts` | Sets the number of application master attempts.
    The default is `1`, which means if complete, the YARN session will fail if the
    application master fails. |'
  prefs: []
  type: TYPE_TB
- en: These configurations need to be in either `conf/flink-conf.yaml` or can be set
    during the session initiation using the `-D` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Working details
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous sections, we looked at how we can use Flink on YARN. Now let''s
    try to understand how it works internally:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Working details](img/image_08_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding diagram shows the internal workings of Flink on YARN. It goes
    through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Checks if the Hadoop and YARN configuration directories are set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If yes, contacts HDFS and stores the JAR and configuration on HDFS.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Contacts the node manager for allocating the application master.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the application master is allocated, initiates the Flink Job Manager.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Later, initiates the Flink task managers based on the configuration parameters
    given.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now we are all set to submit the Flink job on YARN.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we talked about how to use existing YARN clusters to execute
    Flink jobs in a distributed mode. We looked at the step-by-step details and understood
    some practical examples for the same.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to see how to execute Flink jobs in the cloud
    environment.
  prefs: []
  type: TYPE_NORMAL
