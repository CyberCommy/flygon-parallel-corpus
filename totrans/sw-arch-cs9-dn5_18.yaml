- en: '18'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing Your Code with Unit Test Cases and TDD
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When developing software, it is essential to ensure that an application is bug-free
    and that it satisfies all requirements. This can be done by testing all the modules
    while they are being developed, or when the overall application has been either
    completely or partially implemented.
  prefs: []
  type: TYPE_NORMAL
- en: Performing all the tests manually is not a feasible option since most of the
    tests must be executed each time the application is modified and, as explained
    throughout this book, modern software is being continuously modified to adapt
    the applications to the needs of a fast-changing market. This chapter discusses
    all the types of tests needed to deliver reliable software, and how to organize
    and automate them.
  prefs: []
  type: TYPE_NORMAL
- en: 'More specifically, this chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding unit and integration tests and their usage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the basics of **Test-Driven Development** (**TDD**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining C# test projects in Visual Studio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use case â€“ Automating unit tests in DevOps Azure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we'll see which types of tests are worth implementing, and
    what unit tests are. We'll see the different types of projects available and how
    to write unit tests in them. By the end of the chapter, the book use case will
    help us to execute our tests in Azure DevOps during the **Continuous Integration/Continuous
    Delivery** (**CI/CD**) cycle of our applications automatically.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter requires the Visual Studio 2019 free Community Edition or better
    with all database tools installed. It also requires a free Azure account. If you
    have not already created one, refer to the *Creating an Azure account* section
    in *Chapter 1*, *Understanding the Importance of Software Architecture*.
  prefs: []
  type: TYPE_NORMAL
- en: All concepts in this chapter are clarified with practical examples based on
    the WWTravelClub book use case. The code for this chapter is available at [https://github.com/PacktPublishing/Software-Architecture-with-C-9-and-.NET-5](https://github.com/PacktPublishing/Hands-On-Software-Architecture-with-C-9-and-.NET-5).
  prefs: []
  type: TYPE_NORMAL
- en: Understanding unit and integration tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Delaying the application testing until immediately after most of its functionalities
    have been completely implemented must be avoided for the following reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: If a class or module has been incorrectly designed or implemented, it might
    have already influenced the way other modules were implemented. Therefore, at
    this point, fixing the problem might have a very high cost.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The possible combination of input that is needed to test all possible paths
    that execution can take grows exponentially with the number of modules or classes
    that are tested together. Thus, for instance, if the execution of a class method
    `A` can take three different paths, while the execution of another method `B`
    can take four paths, then testing `A` and `B` together would require 3 x 4 different
    inputs. In general, if we test several modules together, the total number of paths
    to test is the product of the number of paths to test in each module. If modules
    are tested separately, instead, the number of inputs required is just the sum
    of the paths needed to test each module.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a test of an aggregate made of *N* modules fails, then locating the origin
    of the bug among the *N* modules is usually a very time-consuming activity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When *N* modules are tested together, we have to redefine all tests involving
    the *N* modules, even if just one of the *N* modules changes during the application's
    CI/CD cycle.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These considerations show that it is more convenient to test each module method
    separately. Unluckily, a battery of tests that verifies all methods independently
    from their context is incomplete because some bugs may be caused by incorrect
    interactions between modules.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, tests are organized into two stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Unit tests**: These verify that all execution paths of each module behave
    properly. They are quite complete and usually cover all possible paths. This is
    feasible because there are not many possible execution paths of each method or
    module compared to the possible execution paths of the whole application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integration tests**: These are executed once the software passes all its
    unit tests. Integration tests verify that all modules interact properly to get
    the expected results. Integration tests do not need to be complete since unit
    tests will have already verified that all execution paths of each module work
    properly. They need to verify all patterns of interaction, that is, all the possible
    ways in which the various modules may cooperate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Usually, each interaction pattern has more than one test associated with it:
    a typical activation of a pattern, and some extreme cases of activation. For instance,
    if a whole pattern of interaction receives an array as input, we will write a
    test for the typical size of the array, a test with a `null` array, a test with
    an empty array, and a test with a very big array. This way, we verify that the
    way the single module was designed is compatible with the needs of the whole interaction
    pattern.'
  prefs: []
  type: TYPE_NORMAL
- en: With the preceding strategy in place, if we modify a single module without changing
    its public interface, we need to change the unit tests for that module.
  prefs: []
  type: TYPE_NORMAL
- en: If, instead, the change involves the way some modules interact, then we also
    have to add new integration tests or to modify existing ones. However, usually,
    this is not a big problem since most of the tests are unit tests, so rewriting
    a large percentage of all integration tests does not require too big an effort.
    Moreover, if the application was designed according to the **Single Responsibility**,
    **Open/Closed**, **Liskov Substitution**, **Interface Segregation**, or **Dependency
    Inversion** (**SOLID**) principles, then the number of integration tests that
    must be changed after a single code modification should be small since the modification
    should affect just a few classes that interact directly with the modified method
    or class.
  prefs: []
  type: TYPE_NORMAL
- en: Automating unit and integration tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At this point, it should be clear that both unit tests and integration tests
    must be reused during the entire lifetime of the software. That is why it is worth
    automating them. Automation of unit and integration tests avoids possible errors
    of manual test execution and saves time. A whole battery of several thousand automated
    tests can verify software integrity after each small modification in a few minutes,
    thereby enabling the frequent changes needed in the CI/CD cycles of modern software.
  prefs: []
  type: TYPE_NORMAL
- en: As new bugs are found, new tests are added to discover them so that they cannot
    reappear in future versions of the software. This way, automated tests always
    become more reliable and protect the software more from bugs added as a result
    of new changes. Thus, the probability of adding new bugs (that are not immediately
    discovered) is greatly reduced.
  prefs: []
  type: TYPE_NORMAL
- en: The next section will give us the basics for organizing and designing automated
    unit and integration tests, as well as practical details on how to write a test
    in C# in the *Defining* *C# Test Projects* section.
  prefs: []
  type: TYPE_NORMAL
- en: Writing automated (unit and integration) tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Tests are not written from scratch; all software development platforms have
    tools that help us to both write tests and launch them (or some of them). Once
    the selected tests have been executed, all tools show a report and give the possibility
    to debug the code of all failed tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'More specifically, all unit and integration test frameworks are made of three
    important parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Facilities for defining all tests**: They verify whether the actual results
    correspond to expected results. Usually, a test is organized into test classes,
    where each test call tests either a single application class or a single class
    method. Each test is split into three stages:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test preparation**: The general environment needed by the test is prepared.
    This stage only prepares the global environment for tests, such as objects to
    inject in class constructors or simulations of database tables; it doesn''t prepare
    the individual inputs for each of the methods we''re going to test. Usually, the
    same preparation procedure is used in several tests, so test preparations are
    factored out into dedicated modules.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Test execution**: The methods to test are invoked with adequate input and
    all results of their executions are compared with expected results with constructs
    such as `Assert.Equal(x, y)` and `Assert.NotNull(x)`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Tear-down**: The whole environment is cleaned up to avoid the execution of
    a test influencing other tests. This step is the converse of *step 1*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Mock facilities**: While integration tests use all (or almost all) classes
    involved in a pattern of object cooperation, in unit tests, the use of other application
    classes is forbidden. Thus, if a class under test, say, `A`, uses a method of
    another application class, `B`, that is injected in its constructor in one of
    its methods, `M`, then in order to test `M`, we must inject a fake implementation
    of `B`. It is worth pointing out that only classes that do some processing are
    not allowed to use another class during unit tests, while pure data classes can.
    Mock frameworks contain facilities to define implementations of interfaces and
    interface methods that return data that can be defined in tests. Typically, mock
    implementations are also able to report information on all mock method calls.
    Such mock implementations do not require the definition of actual class files,
    but are done online in the test code by calling methods such as `new Mock<IMyInterface>()`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Execution and reporting tool**: This is a visual configuration-based tool
    that the developer may use to decide which tests to launch and when to launch
    them. Moreover, it also shows the final outcome of the tests as a report containing
    all successful tests, all failed tests, each test''s execution time, and other
    information that depends on the specific tool and on how it was configured. Usually,
    execution and reporting tools that are executed in development IDEs such as Visual
    Studio also give you the possibility of launching a debug session on each failed
    test.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since only interfaces allow a complete mock definition of all their methods,
    we should inject interfaces or pure data classes (that don't need to be mocked)
    in class constructors and methods; otherwise, classes could not be unit tested.
    Therefore, for each cooperating class that we want to inject into another class,
    we must define a corresponding interface.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, classes should use instances that are injected in their constructors
    or methods, and not class instances available in the public static fields of other
    classes; otherwise, the hidden interactions might be forgotten while writing tests,
    and this might complicate the *preparation* step of tests.
  prefs: []
  type: TYPE_NORMAL
- en: The following section describes other types of tests used in software development.
  prefs: []
  type: TYPE_NORMAL
- en: Writing acceptance and performance tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Acceptance tests define the contract between the project stakeholders and the
    development team. They are used to verify that the software developed actually
    behaves as agreed with them. Acceptance tests verify not only functional specifications,
    but also constraints on the software usability and user interface. Since they
    also have the purpose of showing how the software appears and behaves on actual
    computer monitors and displays, they are never completely automatic, but consist
    mainly of lists of recipes and verifications that must be followed by an operator.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, automatic tests are developed to verify just the functional specifications,
    but such tests usually bypass the user interface and inject the test input directly
    in the logic that is immediately behind the user interface. For instance, in the
    case of an ASP.NET Core MVC application, the whole website is run in a complete
    environment that includes all the necessary storage filled with test data. Input
    is not provided to HTML pages, but is injected directly in the ASP.NET Core controllers.
    Tests that bypass the user interface are called subcutaneous tests. ASP.NET Core
    supplies various tools to perform subcutaneous tests and also tools that automate
    interaction with HTML pages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Subcutaneous tests are usually preferred in the case of automated tests, while
    full tests are executed manually for the following reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: No automatic test can verify how the user interface appears and how usable it
    is.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automating the actual interaction with the user interface is a very time-consuming
    task.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User interfaces are changed frequently to improve their usability and to add
    new features, and small changes in a single application screen may force a complete
    rewrite of all tests that operate on that screen.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a few words, user interface tests are very expansive and have low reusability,
    so it's rarely worth automating them. However, ASP.NET Core supplies the `Microsoft.AspNetCore.Mvc.Testing`
    NuGet package to run the whole website in a testing environment. Using it together
    with the `AngleSharp` NuGet package, which parses HTML pages into DOM trees, you
    can write automated full tests with an acceptable programming effort. The automated
    ASP.NET Core acceptance tests will be described in detail in *Chapter 22*, *Automation
    for Functional Tests*.
  prefs: []
  type: TYPE_NORMAL
- en: Performance tests apply a fake load to an application to see whether it is able
    to handle the typical production load, to discover its load limits, and to locate
    bottlenecks. The application is deployed in a staging environment that is a copy
    of the actual production environment in terms of hardware resources.
  prefs: []
  type: TYPE_NORMAL
- en: Then, fake requests are created and applied to the system, and response times
    and other metrics are collected. Fake request batches should have the same composition
    as the actual production batches. They can be generated from the actual production
    request logs if they are available.
  prefs: []
  type: TYPE_NORMAL
- en: If response times are not satisfactory, other metrics are collected to discover
    possible bottlenecks (low memory, slow storage, or slow software modules). Once
    located, a software component that is responsible for the problem can be analyzed
    in the debugger to measure the execution time of the various method calls involved
    in a typical request.
  prefs: []
  type: TYPE_NORMAL
- en: Failures in the performance tests may lead either to a redefinition of the hardware
    needed by the application or to the optimization of some software modules, classes,
    or methods.
  prefs: []
  type: TYPE_NORMAL
- en: Both Azure and Visual Studio offer tools to create fake loads and to report
    execution metrics. However, they have been declared obsolete and will be discontinued,
    and so we will not describe them. As an alternative, there are both open source
    and third-party tools that can be used. Some of them are listed in the *Further
    reading* section.
  prefs: []
  type: TYPE_NORMAL
- en: The next section describes a software development methodology that gives a central
    role to tests.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding test-driven development (TDD)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Test-driven development** (**TDD**) is a software development methodology
    that gives a central role to unit tests. According to this methodology, unit tests
    are a formalization of the specifications of each class, so they must be written
    before the code of the class. Actually, a full test that covers all code paths
    univocally defines the code behavior, so it can be considered a specification
    for the code. It is not a formal specification that defines the code behavior
    through some formal language, but a specification based on examples of behavior.'
  prefs: []
  type: TYPE_NORMAL
- en: The ideal way to test software would be to write formal specifications of the
    whole software behavior and to verify with some wholly automatic tools whether
    the software that was actually produced conforms to them. In the past, some research
    effort was spent defining formal languages for describing code specifications,
    but expressing the behavior the developer has in mind with similar languages was
    a very difficult and error-prone task. Therefore, these attempts were quickly
    abandoned in favor of approaches based on examples. At that time, the main purpose
    was the automatic generation of code.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, automatic code generation has been substantially abandoned and survives
    in small application areas, such as the creation of device drivers. In these areas,
    the effort of formalizing the behavior in a formal language is worth the time
    saved in trying to test difficult-to-reproduce behaviors of parallel threads.
  prefs: []
  type: TYPE_NORMAL
- en: Unit tests were initially conceived as a way to encode example-based specifications
    in a completely independent way, as part of a specific agile development methodology
    called **Extreme Programming**. However, nowadays, TDD is used independently of
    Extreme Programming and is included as an obligatory prescription in other agile
    methodologies.
  prefs: []
  type: TYPE_NORMAL
- en: While it is undoubtedly true that unit tests refined after finding hundreds
    of bugs act as reliable code specifications, it is not obvious that developers
    can easily design unit tests that can be immediately used as reliable specifications
    for the code to be written. In fact, generally, you need an infinite or at least
    an immense number of examples to univocally define a code's behavior if examples
    are chosen at random.
  prefs: []
  type: TYPE_NORMAL
- en: 'The behavior can be defined with an acceptable number of examples only after
    you have understood all possible execution paths. In fact, at this point, it is
    enough to select a typical example for each execution path. Therefore, writing
    a unit test for a method after that method has been completely coded is easy:
    it simply requires selecting a typical instance for each execution path of the
    already existing code. However, writing unit tests this way does not protect from
    errors in the design of the execution paths themselves. Arguably, writing the
    tests beforehand doesn''t prevent someone from forgetting to test a value, or
    combination of values â€“ no one is perfect! It does, however, force you to think
    about them explicitly prior to implementation, which is why you''re less likely
    to accidentally omit a test case.'
  prefs: []
  type: TYPE_NORMAL
- en: We may conclude that, while writing unit tests, the developer must somehow forecast
    all execution paths by looking for extreme cases and by possibly adding more examples
    than strictly needed. However, the developer can make mistakes while writing the
    application code, and he or she can also make mistakes in forecasting all possible
    execution paths while designing the unit tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have identified the main drawback of TDD: unit tests themselves may be wrong.
    That is, not only application code, but also its associated TDD unit tests, may
    be incoherent with the behavior the developer has in mind. Therefore, in the beginning,
    unit tests can''t be considered software specifications, but rather a possibly
    wrong and incomplete description of the software behavior. Therefore, we have
    two descriptions of the behavior we have in mind: the application code itself
    and its TDD unit tests that were written before the application code.'
  prefs: []
  type: TYPE_NORMAL
- en: What makes TDD work is that the probability of making exactly the same error
    while writing the tests and while writing the code is very low. Therefore, whenever
    a test fails, there is an error either in the tests or in the application code,
    and, conversely, if there is an error either in the application code or in the
    test, there is a very high probability that a test will fail. That is, the usage
    of TDD ensures that most of the bugs are immediately found!
  prefs: []
  type: TYPE_NORMAL
- en: 'Writing a class method or a chunk of code with TDD is a loop composed of three
    stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Red stage**: In this stage, the developer writes empty methods that either
    throw `NotImplementedException` or have empty bodies and designs new unit tests
    for them that must necessarily fail because, at this time, there is no code that
    implements the behavior they describe.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Green stage**: In this stage, the developer writes the minimum code or makes
    the minimum modifications to existing code that are necessary to pass all unit
    tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Refactoring stage**: Once the test is passed, code is refactored to ensure
    good code quality and the application of best practices and patterns. In particular,
    in this stage, some code can be factored out in other methods or in other classes.
    During this stage, we may also discover the need for other unit tests because
    new execution paths or new extreme cases are discovered or created.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The loop stops as soon as all tests pass without writing new code or modifying
    the existing code.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, it is very difficult to design the initial unit tests because it
    is quite difficult to imagine how the code might work and the execution paths
    it might take. In this case, you can get a better understanding of the specific
    algorithm to use by writing an initial sketch of the application code. In this
    initial stage, we need to focus just on the main execution path, completely ignoring
    extreme cases and input verifications. Once we get a clear picture of the main
    ideas behind an algorithm that should work, we can enter the standard three-stage
    TDD loop.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will list all test projects available in Visual Studio
    and describe xUnit in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Defining C# test projects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Visual Studio contains project templates for three types of unit testing frameworks,
    namely, MSTest, xUnit, and NUnit. Once you start the new project wizard, in order
    to visualize the version of all of them that is adequate for .NET Core C# applications,
    set **Project type** as **Test**, **Language** as **C#**, and **Platform** as
    **Linux**, since .NET Core projects are the only ones that can be deployed on
    Linux.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the selection that should appear:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16756_18_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.1: Adding a test project'
  prefs: []
  type: TYPE_NORMAL
- en: All the preceding projects automatically include the NuGet package for running
    all the tests in the Visual Studio test user interface (Visual Studio test runner).
    However, they do not include any facility for mocking interfaces, so you need
    to add the `Moq` NuGet package, which contains a popular mocking framework.
  prefs: []
  type: TYPE_NORMAL
- en: All test projects must contain a reference to the project to be tested.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will describe xUnit, since it is probably the most popular
    of the three frameworks. However, all three frameworks are quite similar and differ
    mainly in the names of the assert methods and in the names of the attributes used
    to decorate various testing classes and methods.
  prefs: []
  type: TYPE_NORMAL
- en: Using the xUnit test framework
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In xUnit, tests are methods decorated with either the `[Fact]` or `[Theory]`
    attributes. Tests are automatically discovered by the test runner that lists all
    of them in the user interface so the user can run either all of them or just a
    selection of them.
  prefs: []
  type: TYPE_NORMAL
- en: A new instance of the test class is created before running each test, so the
    *test preparation* code contained in the class constructor is executed before
    each test of the class. If you also require *tear-down* code, the test class must
    implement the `IDisposable` interface so that the tear-down code can be included
    in the `IDisposable.Dispose` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'The test code invokes the methods to be tested and then tests the results with
    methods from the `Assert` static class, such as `Assert.NotNull(x)`, `Assert.Equal(x,
    y)`, and `Assert.NotEmpty(IEnumerable x)`. There are also methods that verify
    whether a call throws an exception of a specific type, for instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: When an assertion fails, an exception is thrown. A test fails if a not-intercepted
    exception is thrown either by the test code or by an assertion.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of a method that defines a single test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `[Fact]` attribute is used when a method defines just one test, while the
    `[Theory]` attribute is used when the same method defines several tests, each
    on a different tuple of data. Tuples of data can be specified in several ways
    and are injected in the test as method parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'The previous code can be modified to test `MethodToTest` on several inputs,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Each `InlineData` attribute specifies a tuple to be injected in the method
    parameters. Since just simple constant data can be included as attribute arguments,
    xUnit also gives you the possibility to take all data tuples from a class that
    implements `IEnumerable`, as shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The type of the class that provides the test data is specified with the `ClassData`
    attribute.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is also possible to take data from a static method of a class that returns
    an `IEnumerable` with the `MemberData` attribute, as shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The `MemberData` attribute is passed the method name as the first parameter,
    and the class type in the `MemberType` named parameter. If the static method is
    part of the same test class, the `MemberType` parameter can be omitted.
  prefs: []
  type: TYPE_NORMAL
- en: The next section shows how to deal with some advanced preparation and tear-down
    scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced test preparation and tear-down scenarios
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes, the preparation code contains very time-consuming operations, such
    as opening a connection with a database, that don't need to be repeated before
    each test, but that can be executed once before all the tests contained in the
    same class. In xUnit, this kind of test preparation code can't be included in
    the test class constructor; since a different instance of the test class is created
    before every single test, it must be factored out in a separate class called a
    fixture class.
  prefs: []
  type: TYPE_NORMAL
- en: If we also need a corresponding tear-down code, the fixture class must implement
    `IDisposable`. In other test frameworks, such as NUnit, the test class instances
    are created just once instead, so they don't need the fixture code to be factored
    out in other classes. However, test frameworks, such as NUnit, that do not create
    a new instance before each test may suffer from bugs because of unwanted interactions
    between test methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of an xUnit fixture class that opens and closes
    a database connection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Since a fixture class instance is created just once before all tests associated
    with the fixture are executed and the same instance is disposed of immediately
    after the tests, then the database connection is created just once when the fixture
    class is created and is disposed of immediately after the tests when the fixture
    object is disposed of.
  prefs: []
  type: TYPE_NORMAL
- en: 'The fixture class is associated with each test class by letting the test class
    implement the empty `IClassFixture<T>` interface, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: A fixture class instance is automatically injected in the test class constructor
    in order to make all data computed in the fixture test preparation available for
    the tests. This way, for instance, in our previous example, we can get the database
    connection instance so that all test methods of the class can use it.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to execute some test preparation code on all tests contained in
    a collection of test classes instead of a single test class, we must associate
    the fixture class with an empty class that represents the collection of test classes,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `CollectionDefinition` attribute declares the name of the collection, and
    the `IClassFixture<T>` interface has been replaced with `ICollectionFixture<T>`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we declare that a test class belongs to the previously defined collection
    by applying it to the `Collection` attribute with the name of the collection,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The `Collection` attribute declares which collection to use, while the `DataBaseFixture`
    argument in the test class constructor provides an actual fixture class instance,
    so it can be used in all class tests.
  prefs: []
  type: TYPE_NORMAL
- en: The next section shows how to mock interfaces with the `Moq` framework.
  prefs: []
  type: TYPE_NORMAL
- en: Mocking interfaces with Moq
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Mocking capabilities are not included in any of the test frameworks we listed
    in this section as they are not included in xUnit. Therefore, they must be provided
    by installing a specific NuGet package. The `Moq` framework available in the `Moq`
    NuGet package is the most popular mock framework available for .NET. It is quite
    easy to use and will be briefly described in this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we''ve installed the NuGet package, we need to add a `using Moq` statement
    in our test files. A mock implementation is easily defined, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The behavior of the mock dependency on specific inputs of the specific method
    can be defined with the `Setup/Return` method pair as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We can add several `Setup/Return` instructions for the same method. This way,
    we can specify an indefinite number of input/output behaviors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of specific input values, we may also use wildcards that match a specific
    type as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have configured the mock dependency, we may extract the mocked instance
    from its `Object` property and use it as if it were an actual implementation,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: However, mocked methods are usually called by the code under test, so we just
    need to extract the mocked instance and use it as an input in our tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'We may also mock properties and async methods as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: With async methods, `Returns` must be replaced by `ReturnsAsync`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each mocked instance records all calls to its methods and properties, so we
    may use this information in our tests. The following code shows an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The preceding statement asserts that `MyMethod` has been invoked with the given
    arguments at least twice. There are also `Times.Never`, and `Times.Once` (which
    asserts that the method was called just once), and more.
  prefs: []
  type: TYPE_NORMAL
- en: The Moq documentation summarized up to now should cover 99% of the needs that
    may arise in your tests, but Moq also offers more complex options. The *Further
    reading* section contains the link to the complete documentation.
  prefs: []
  type: TYPE_NORMAL
- en: The next section shows how to define unit tests in practice and how to run them
    both in Visual Studio and in Azure DevOps with the help of the book use case.
  prefs: []
  type: TYPE_NORMAL
- en: Use case â€“ Automating unit tests in DevOps Azure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we add some unit test projects to the example application we
    built in *Chapter 15*, *Presenting ASP.NET Core MVC*. If you don't have it, you
    can download it from the *Chapter 15*, *Presenting ASP.NET Core MVC*, section
    of the GitHub repository associated with the book.
  prefs: []
  type: TYPE_NORMAL
- en: As a first step, let's make a new copy of the solution folder and name it `PackagesManagementWithTests`.
    Then, open the solution and add it to an xUnit .NET Core C# test project named
    `PackagesManagementTest`. Finally, add a reference to the ASP.NET Core project
    (`PackagesManagement`), since we will test it, and a reference to the latest version
    of the `Moq` NuGet package, since we require mocking capabilities. At this point,
    we are ready to write our tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, we will write unit tests for the `Edit` method decorated with
    `[HttpPost]` of the `ManagePackagesController` controller, which is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Before writing our test methods, let's rename the test class that was automatically
    included in the test project as `ManagePackagesControllerTests`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first test verifies that in case there are errors in `ModelState`, the
    action method renders a view with the same model it received as an argument so
    that the user can correct all errors. Let''s delete the existing test method and
    write an empty `DeletePostValidationFailedTest` method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The method must be `async` and the return type must be `Task` since the `Edit`
    method that we have to test is `async`. In this test, we don''t need mocked objects
    since no injected object will be used. Thus, as a preparation for the test, we
    just need to create a controller instance, and we must add an error to `ModelState`
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we invoke the method, injecting `ViewModel` and a `null` command handler
    as its arguments, since the command handler will not be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'In the verification stage, we verify that the result is `ViewResult` and that
    it contains the same model that was injected in the controller:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we also need a test to verify that in case there are no errors, the command
    handler is called, and then the browser is redirected to the `Index` controller
    action method. We call the `DeletePostSuccessTest` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This time the preparation code must include the preparation of a command handler
    mock, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the handler `HandleAsync` method returns no `async` value, we can''t
    use `ReturnsAsync`, but we have to return just a completed `Task` (`Task.Complete`)
    with the `Returns` method. The method to test is called with both `ViewModel`
    and the mocked handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the verification code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: As the first step, we verify that the command handler has actually been invoked
    once. A better verification should also include a check that it was invoked with
    a command that includes `ViewModel` passed to the action method. We will take
    it up as an exercise.
  prefs: []
  type: TYPE_NORMAL
- en: Then we verify that the action method returns `RedirectToActionResult` with
    the right action method name and with no controller name specified.
  prefs: []
  type: TYPE_NORMAL
- en: Once all the tests are ready, if the test window does not appear on the left
    bar of Visual Studio, we may simply select the **Run all tests** item from the
    Visual Studio **Test** menu. Once the test window appears, further invocations
    can be launched from within this window.
  prefs: []
  type: TYPE_NORMAL
- en: If a test fails, we can add a breakpoint to its code, so we can launch a debug
    session on it by right-clicking on it in the test window and then selecting **Debug
    selected tests**.
  prefs: []
  type: TYPE_NORMAL
- en: Connecting to an Azure DevOps repository
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Tests play a fundamental role in the application CI/CD cycle, and specifically
    in continuous integration. They must be executed at least each time the master
    branch of the application repository is modified in order to verify that changes
    don't introduce bugs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps show how to connect our solution to an Azure DevOps repository,
    and we will define an Azure DevOps pipeline that builds the project and launches
    its tests. In this way, every day after all developers have pushed their changes,
    we can launch the pipeline to verify that the repository code compiles and passes
    all the tests:'
  prefs: []
  type: TYPE_NORMAL
- en: 'As a first step, we need a free DevOps subscription. If you don''t already
    have one, please create one by clicking the **Start free** button on this page:
    [https://azure.microsoft.com/en-us/services/devops/](https://azure.microsoft.com/en-us/services/devops/).
    Here, let''s define an organization but stop before creating a project, since
    we will create the project from within Visual Studio.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure you are logged in to Visual Studio with your Azure account (the same
    used in the creation of the DevOps account). At this point, you may create a DevOps
    repository for your solution by right-clicking on the solution and by selecting
    **Configure continuous delivery to Azure...**. In the window that appears, an
    error message will inform you that you have no repository configured for your
    code:![](img/B16756_18_02.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 18.2: No repository error message'
  prefs: []
  type: TYPE_NORMAL
- en: Click the **Add to source control now** link. After that, the DevOps screen
    will appear in the Visual Studio **Team Explorer** tab:![](img/B16756_18_03.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 18.3: Publish repository to DevOps panel'
  prefs: []
  type: TYPE_NORMAL
- en: As shown in *Chapter 3*, *Documenting Requirements with Azure DevOps*, Team
    Explorer is being replaced by Git Changes, but if this automatic wizard takes
    you to Team Explorer, use it to create your repository. Then you can use the Git
    Changes window.
  prefs: []
  type: TYPE_NORMAL
- en: Once you click the **Publish Git Repo** button, you will be prompted to select
    your DevOps organization and a name for the repository. After you successfully
    publish your code to a DevOps repository, the DevOps screen should change as follows:![](img/B16756_18_04.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 18.4: DevOps button after publication'
  prefs: []
  type: TYPE_NORMAL
- en: The DevOps screen shows a link to your online DevOps project. In future, when
    you open your solution, if the link does not appear, please click the DevOps screen
    **Connect** button or the **Manage connections** link (whichever appears) to select
    and connect your project.
  prefs: []
  type: TYPE_NORMAL
- en: Click this link to go to the online project. Once there, if you click the **Repos**
    item, on the left-hand menu, you will see the repository you just published.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, click the **Pipelines** menu item to create a DevOps pipeline to build
    and test your project. In the window that appears, click the button to create
    a new pipeline:![](img/B16756_18_05.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 18.5: Pipeline page'
  prefs: []
  type: TYPE_NORMAL
- en: You will be prompted to select where your repository is located:![](img/B16756_18_06.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 18.6: Repository selection'
  prefs: []
  type: TYPE_NORMAL
- en: Select **Azure Repos Git** and then your repository. Then you will be prompted
    about the nature of the project:![](img/B16756_18_07.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 18.7: Pipeline configuration'
  prefs: []
  type: TYPE_NORMAL
- en: Select **ASP.NET Core**. A pipeline for building and testing your project will
    be automatically created for you. Save it by committing the newly created `.yaml`
    file to your repository:![](img/B16756_18_08.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 18.8: Pipeline properties'
  prefs: []
  type: TYPE_NORMAL
- en: The pipeline can be run by selecting the **Queue** button, but since the standard
    pipeline scaffolded by DevOps has a trigger on the master branch of the repository,
    it is automatically launched each time changes to this branch are committed and
    each time the pipeline is modified. The pipeline can be modified by clicking the
    **Edit** button:![](img/B16756_18_09.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 18.9: Pipeline code'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once in edit mode, all pipeline steps can be edited by clicking the **Settings**
    link that appears above each of them. New pipeline steps can be added as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write `- task:` where the new step must be added and then accept one of the
    suggestions that appear while you are typing the task name.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you have written a valid task name, a **Settings** link appears above the
    new step. Click it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Insert the desired task parameters in the window that appears and then save.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In order to have our test working, we need to specify the criteria to locate
    all assemblies that contain tests. In our case, since we have a unique `.dll`
    file containing the tests, it is enough to specify its name. Click the **Settings**
    link of the `VSTest@2` test task, and replace the content that is automatically
    suggested for the **Test files** field with the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Then click **Add** to modify the actual pipeline content. As soon as you confirm
    your changes in the **Save and run** dialog, the pipeline is launched, and if
    there are no errors, test results are computed. The results of tests launched
    during a specific build can be analyzed by selecting the specific build in the
    pipeline **History** tab and by clicking the **Tests** tab on the page that appears.
    In our case, we should see something like the following screenshot:![](img/B16756_18_10.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 18.10: Test results'
  prefs: []
  type: TYPE_NORMAL
- en: If you click the **Analytics** tab of the pipeline page, you will see analytics
    relating to all builds, including analytics about the test results:![](img/B16756_18_11.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 18.11: Build analytics'
  prefs: []
  type: TYPE_NORMAL
- en: Clicking the test area of the **Analytics** page gets us a detailed report about
    all pipeline test results.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summing up, we created a new Azure DevOps repository, published the solution
    to the new repository, and then created a build pipeline that executes our tests
    after each build. The build pipeline is executed as soon as we save it and will
    be executed each time someone commits to the master branch.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explained why it is worth automating software tests, and
    then we focused on the importance of unit tests. We also listed all types of tests
    and their main features, focusing mainly on unit tests. We analyzed the advantages
    of TDD, and how to use it in practice. With this knowledge, you should be able
    to produce software that is both reliable and easy to modify.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we analyzed all test tools available for .NET Core projects, focusing
    on the description of xUnit and Moq, and showed how to use them in practice, both
    in Visual Studio and in Azure DevOps, with the help of the book's use case.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter looks at how to test and measure the quality of the code.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why is it worth automating unit tests?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the main reason why TDD is able to discover most bugs immediately?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between the `[Theory]` and `[Fact]` attributes of xUnit?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which xUnit static class is used in test assertions?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which methods allow the definition of the Moq mocked dependencies?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is it possible to mock async methods with Moq? If yes, how?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While the documentation on xUnit included in this chapter is quite complete,
    it doesn't include the few configuration options offered by xUnit. The full xUnit
    documentation is available at [https://xunit.net/](https://xunit.net/). Documentation
    for MSTest and NUnit can be found at [https://github.com/microsoft/testfx](https://github.com/microsoft/testfx)
    and [https://github.com/nunit/docs/wiki/NUnit-Documentation](https://github.com/nunit/docs/wiki/NUnit-Documentation),
    respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Full Moq documentation is available at [https://github.com/moq/moq4/wiki/Quickstart](https://github.com/moq/moq4/wiki/Quickstart).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some links to performance test frameworks for web applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://jmeter.apache.org/](https://jmeter.apache.org/) (free and open source)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.neotys.com/neoload/overview](https://www.neotys.com/neoload/overview)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.microfocus.com/en-us/products/loadrunner-load-testing/overview](https://www.microfocus.com/en-us/products/loadrunner-load-testing/overview)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.microfocus.com/en-us/products/silk-performer/overview](https://www.microfocus.com/en-us/products/silk-performer/overview)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
