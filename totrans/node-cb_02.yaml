- en: Chapter 2. Exploring the HTTP Object
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Processing POST data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling file uploads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Node as an HTTP client
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing download throttling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we used the `http` module to create a web server. Now
    we're going to look into some associated use cases beyond simply pushing content
    from server to client. The first three recipes will explore how to receive data
    via client-initiated HTTP POST (and PUT) requests, and in the final recipe we'll
    demonstrate how to throttle a stream of outbound data.
  prefs: []
  type: TYPE_NORMAL
- en: Processing POST data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If we want to be able to receive POST data, we have to instruct our server on
    how to accept and handle a POST request. In PHP we could access our POST values
    seamlessly with `$_POST['fieldname']`, because it would block until an array value
    was filled. By contrast, Node provides low-level interaction with the flow of
    HTTP data allowing us to interface with the incoming message body as a stream,
    leaving it entirely up to the developer to turn that stream into usable data.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s create a `server.js` file ready for our code, and an HTML file called
    `form.html`, containing the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For our purposes, we'll place `form.html` in the same folder as `server.js`,
    though this is not generally a recommended practice. Usually, we should place
    our public code in a separate folder from our server code.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We'll provision our server for both GET and POST requests. Let's start with
    GET by requiring the `http` module and loading `form.html` for serving through
    `createServer:`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We are synchronously loading `form.html` at initialization time instead of
    accessing the disk on each request. If we navigate to `localhost:8080`, we''ll
    be presented with a form. However, if we fill out our form nothing happens because
    we need to handle POST requests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the form is completed and submitted, the browser and console will output
    the raw query string sent from the client. Converting `postData` into an object
    provides an easy way to interact with and manipulate the submitted information.
    The `querystring` module has a `parse` method which transforms query strings into
    objects, and since form submission arrives in query string format, we can use
    it to objectify our data as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Notice the `util` module. We require it to use its `inspect` method for a simple
    way to output our `postDataObject` to the browser.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we're going to protect our server from memory overload exploits.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Protecting a POST server**'
  prefs: []
  type: TYPE_NORMAL
- en: V8 (and therefore Node) has virtual memory limitations, based upon the processor
    architecture and operating system constraints. These limitations far exceed the
    demands of most use cases. Nevertheless, if we don't restrict the amount of data
    our POST server will accept, we could leave ourselves open for a type of Denial
    of Service attack. Without protection, an extremely large POST request could cause
    our server to slow down significantly or even crash.
  prefs: []
  type: TYPE_NORMAL
- en: To achieve this, we'll set a variable for the maximum acceptable data size and
    check it against the growing length of our `postData` variable.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once we know a POST request has been made of our server (by checking `request.method)`,
    we aggregate our incoming data into our `postData` variable via the `data` event
    listener on the `request` object. However, if we find that the submitted data
    exceeds our `maxData` limit, we will clear our `postData` variable and `pause`
    the incoming stream preventing any further data arriving from the client. Using
    `stream.destroy` instead of `stream.pause` seems to interfere with our response
    mechanism. Once a stream has been paused for a while it is automatically removed
    from memory by v8's garbage collector.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we send a `413 Request Entity Too Large` HTTP header. In the `end` event
    listener, as long as `postData` hasn''t been cleared for exceeding `maxData` (or
    wasn''t blank in the first place), we use `querystring.parse` to turn our POST
    message body into an object. From this point, we could perform any number of interesting
    activities: manipulate, analyze, pass it to a database, and so on. However, for
    the example, we simply output `postDataObject` to the browser and `postData` to
    the console.'
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we want our code to look a little more elegant, and we're not so concerned
    about handling POST data as a stream, we can employ a user land (non-core) module
    to get a little sugar on our syntax.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing POST data with connect.bodyParser
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Connect is an excellent middleware framework for Node providing a method framework
    that assimilates a higher level of abstraction for common server tasks. Connect
    is actually the basis of the Express web framework, which will be discussed In
    [Chapter 6](ch06.html "Chapter 6. Accelerating Development with Express"), *Accelerating
    Development with Express*
  prefs: []
  type: TYPE_NORMAL
- en: One piece of middleware that comes bundled with Connect is `bodyParser`. By
    chaining `connect.bodyParser` to a normal callback function, we suddenly have
    access to the POST data via `request.body` (when data is sent by the POST request
    it is held in the message body). `request.body` turns out to be exactly the same
    object as `postDataObject` we generated in our recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s make sure we have Connect installed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We require `connect` in place of `http` since it provides us with the `createServer`
    capabilities. To access the `createServer` method, we can use `connect.createServer`,
    or the shorthand version, which is simply `connect`. Connect allows us to combine
    multiple pieces of middleware together by passing them in as parameters to the
    `createServer` method. Here''s how to implement similar behavior, as in the recipe
    using Connect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Notice we are no longer using the `http` module directly. We pass `connect.limit`
    in as our first parameter to achieve the same `maxData` restriction implemented
    in the main example.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we pass in `bodyParser`, allowing `connect` to retrieve our POST data
    for us, objectifying the data into `request.body`. Finally, there's our callback
    function, with all the former POST functionality stripped out except the code
    to echo our data object (which is now `request.body)` to console and browser.
    This is where we deviate slightly from our original recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the recipe we return the raw `postData` to the console, though we return
    the `request.body` object here. To output raw data with Connect would either take
    pointless deconstruction of our object to reassemble the raw query string or an
    extension of the `bodyParser` function. This is the tradeoff with using third-party
    modules: we can only easily interact with information the module author expects
    us to interact with.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look under the hood for a moment. If we fire up an instance of `node`
    without any arguments, we can access the REPL (Read-Eval-Print-Loop) which is
    the Node command-line environment. In the REPL, we can write:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: If we look at the output, we'll see its `connect.bodyParser` function code and
    should be able to easily identify the essential elements from our recipe at work
    in the `connect.bodyParser` code.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Handling file uploads* discussed in this chapter'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Browser-server transmission via AJAX* discussed In [Chapter 3](ch03.html "Chapter 3. Working
    with Data Serialization"), *Working with Data Serialization*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Initializing and using a session* discussed In [Chapter 6](ch06.html "Chapter 6. Accelerating
    Development with Express"), *Accelerating Development with Express*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling file uploads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We cannot process an uploaded file in the same way we process other POST data.
    When a file input is submitted in a form, the browser processes the file into
    a **multipart message.**
  prefs: []
  type: TYPE_NORMAL
- en: Multipart was originally developed as an email format allowing multiple pieces
    of mixed content to be combined into one message. If we intuitively attempted
    to receive the upload as a stream and write it to a file, we would have a file
    filled with multipart data instead of the file or files themselves. We need a
    multipart parser, the writing of which is more than a recipe can cover. So instead
    we'll be using the well-known and battle-tested `formidable` module to convert
    our upload data into files.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's create a new `uploads` directory for storing uploaded files and get ready
    to make modifications to our `server.js` file from the previous recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll also need to install `formidable` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we''ll make some changes to our `form.html` from the last recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: We've included an `enctype` attribute of `multipart/form-data` to signify to
    the browser that the form will contain upload data and we've replaced the text
    inputs with file inputs.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s see what happens when we use our modified form to upload a file to the
    server from the last recipe. Let''s upload `form.html` itself as our file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/7188-02-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Our POST server simply logs the raw HTTP message body to the console, which
    in this case is multipart data. We had two file inputs on the form. Though we
    only uploaded one file, the second input is still included in the multipart request.
    Each file is separated by a predefined boundary that is set in a secondary attribute
    of the `Content-Type` HTTP headers. We'll need to use `formidable` to parse this
    data, extracting each file contained therein.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Our POST server has now become an upload server.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We create a new instance of the `formidable IncomingForm` class and tell it
    where to upload files. In order to provide feedback to the user, we can listen
    to our `incoming` instance. The `IncomingForm` class emits its own higher level
    events, so rather than listening to the `request` object for events and processing
    data as it comes, we wait for `formidable` to parse the files out of the multipart
    message and then notify us through its custom `file` event.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `file` event callback provides us with two parameters: `field` and `file`.
    The `file` parameter is an object containing information about the uploaded file.
    We use this to filter out empty files (usually caused by empty input fields) and
    grab the filename which we show to users as confirmation. When `formidable` has
    finished parsing the multipart message, it sends an `end` event in which we end
    the response.'
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can post more than simple form fields and values from a browser. Let's take
    a look at transferring files from browser to server.
  prefs: []
  type: TYPE_NORMAL
- en: Using formidable to accept all POST data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`formidable` doesn''t just handle uploaded files, it will also process general
    POST data. All we have to do is add a listener for the `field` event to process
    forms containing both files and user data.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: There's no need to manually implement field data size limits as `formidable`
    takes care of this for us. However, we can change the defaults with `incoming.maxFieldsSize`,
    which allows us to limit the total byte count for the sum of all fields. This
    limit doesn't apply to file uploads.
  prefs: []
  type: TYPE_NORMAL
- en: Preserving filenames with formidable
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When `formidable` places our files into the `uploads` directory, it assigns
    them a name consisting of a randomly generated hexadecimal number. This prevents
    files of the same name from being overwritten. But what if we want to know which
    files are which and yet still retain the unique filename advantage? We can alter
    the way `formidable` names each file during its `fileBegin` event as shown in
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We've appended the original filename onto the end of the random filename assigned
    by `formidable`, separating them with a dash. Now we can easily identify our files.
    However, for many scenarios this may not be necessary as we would likely be outputting
    file information to a database and cross referencing it to randomly generated
    names.
  prefs: []
  type: TYPE_NORMAL
- en: Uploading via PUT
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It's also possible to upload files via an HTTP PUT request. While we can only
    send one file per request, we don't need to do any parsing on the server side
    since the file will simply stream directly to our server, which means less server-side
    processing overhead. It would be magnificent if we could achieve this by changing
    our form's `method` attribute from `POST` to `PUT` but alas, no. However, thanks
    to the up and coming `XMLHttpRequest Level 2` (xhr2), we can now transfer binary
    data via JavaScript in some browsers (see [http://www.caniuse.com/#search=xmlhttprequest%202)](http://www.caniuse.com/#search=xmlhttprequest%202)).
    We grab a file pointer using a `change` event listener on the input file element,
    then we open a PUT request and send the file. The following is for use in `form.html`,
    which we'll save as `put_upload_form.html:`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '`Id` is added to the form and file inputs while `method` and `enctype` attributes
    have been removed. We''re using just one file element because we can only send
    one file per request, although the example could be extended to asynchronously
    stream multiple files to our server at once.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our script attaches a `change` listener to the file input element. When the
    user selects a file we are able to capture a pointer to the file. As the form
    is submitted, we prevent default behavior, check if a file is selected, initialize
    an `xhr` object, open a PUT request to our server, set a custom header so we can
    grab the filename later, and send the file to our server. Our server looks like
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Our PUT server follows a similar pattern to the simple POST server in the *Processing
    POST data* recipe. We listen to the data event and piece the chunks together.
    However, rather than string concatenate our data, we must throw our chunks into
    a buffer because a buffer can handle any data type including binary, whereas a
    string object will always coerce non-string data into string format. This changes
    the underlying binary resulting in corrupted files. Once the `end` event has triggered,
    we generate a random file name similar to the naming convention of `formidable`
    and write the file to our `uploads` folder.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This *Uploading via PUT* demonstration will not work in older browsers, so an
    alternative fall back should be provided in a production environment. Browsers
    that will support this method are IE 10 and above, Firefox, Chrome, Safari, iOS
    5+ Safari, and Android browsers. However, due to browser vendors differing implementations
    of the same functionality, the example may need some tweaking for cross-browser
    compatibility.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Sending email discussed in* [Chapter 8](ch08.html "Chapter 8. Integrating
    Network Paradigms"), *Integrating Network Paradigms*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Using Node as an HTTP client* discussed in this chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Node as an HTTP client
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The HTTP object doesn't just provide server capabilities, it also affords us
    with client functionality. In this task, we're going to use `http.get` with `process`
    to fetch external web pages dynamically via the command line.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are not creating a server, so in the naming convention we should use a different
    name for our new file, let's call it `fetch.js`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`http.request` allows us to make requests of any kind (for example, GET, POST,
    DELETE, OPTION, and so on), but for GET requests we can use the short-hand `http.get`
    method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Essentially we're done.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run the preceding command, our console will output the HTML of `nodejs.org`.
    However, let''s pad it out a bit with some interactivity and error handling as
    shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can use our script like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`http.get` takes an object which defines the criteria of our desired request.
    We defined a variable called `urlOpts` for this purpose and set our host to [www.nodejs.org](http://www.nodejs.org).
    We use the `process.argv` property to check if a web address has been specified
    via the command line. Like `console, process` is a global variable that is always
    available within a Node runtime environment. `process.argv[2]` is the third command-line
    argument, with `node` and `fetch.js` being allocated to `[0]` and `[1]` respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: If `process.argv[2]` exists (that is, if an address has been specified) we append
    `http://`. If it isn't there (`url.parse` requires it), then replace the object
    in our default `urlOpts` with the output from `url.parse`. Happily, `url.parse`
    returns an object with the same properties `http.get` requires.
  prefs: []
  type: TYPE_NORMAL
- en: As a client, we are interacting with the server's response to us, rather than
    the client's request from us. So inside the `http.get` callback, we listen for
    the `data` event on `response` instead of (as with our server examples) `request`.
    As the `response` data stream arrives, we output the chunks to the console.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's explore some of the possibilities of the underlying `http.request` method
    of `http.get`.
  prefs: []
  type: TYPE_NORMAL
- en: Sending POST requests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We'll need to fire up our `server.js` app from the *Processing POST data* recipe
    to receive our POST requests. Let's make a new file and call it `post.js`, which
    we'll use to send POST requests to our POST server.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: As we're using the more general `http.request`, we've had to define our HTTP
    verb in the `urlOpts` variable. Our `urlOpts` variable also specifies the server
    as `localhost:8080` (we must ensure that our POST server is running in order for
    this code to work).
  prefs: []
  type: TYPE_NORMAL
- en: As before, we set up an event listener in our callback for `data` on the `response`
    object. `http.request` returns a `clientRequest` object which we load into a variable
    called `request`. This is a newly declared variable, which holds the returned
    `clientRequest` object from our `http.request` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'After our event listeners, we loop through the command-line arguments using
    the Ecmascript 5 `forEach` method (which is safe to use in Node but not yet in
    browsers). In running this script, `node` and `post.js` would be the 0th and 1st
    arguments, so we check that our array index is greater than 1 before sending any
    arguments as POST data. We use `request.write` to send data similar to how we
    would use `response.write` if we were building a server. Even though it uses a
    callback, `forEach` is not asynchronous (it blocks until completion), so only
    after every element is processed is our POST data written and our request ended.
    This is how we use it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Multipart file upload as a client
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We'll use our upload server from *Handling File Uploads* to receive the files
    from our uploading client. To achieve this, we have to deal with the multipart
    data format. To inform a server of the client's intentions of sending multipart
    data, we set the `content-type` header to `multipart/form-data` with an additional
    attribute called `boundary`, which is a custom named delimiter, separating files
    in the multipart data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: We've required the `fs` module here too as we'll be needing that later to load
    our files.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ve set our `boundary` to the current Unix time (milliseconds since midnight,
    January 1, 1970). We won''t need `boundary` again in this format, so let''s update
    it with the required multipart double dash (`--`) prefix and set up our `http.request`
    call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We want to be able to stream multipart data to the server, which may be compiled
    from multiple files. If we streamed these files while simultaneously attempting
    to compile them together into the multipart format, the data would likely be mashed
    together from different file streams in an unpredictable order becoming impossible
    to parse. So we need a way to preserve the data order.
  prefs: []
  type: TYPE_NORMAL
- en: We could build it all in one go and afterwards send it to the server. However,
    a more efficient (and Node-like) solution is to build the multipart message by
    progressively assembling each file into the multipart format as the file is streamed
    in, while instantly streaming the multipart data as it's being built.
  prefs: []
  type: TYPE_NORMAL
- en: To achieve this, we can use a self-iterating function, calling each recursion
    from within the `end` event callback to ensure each stream is captured separately
    and in order.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'This is also a self-calling function because we''ve changed it from a declaration
    to an expression by wrapping parenthesis around it. Then we''ve called it by appending
    parenthesis, also passing in the command-line arguments, which specify what files
    to upload:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: We use `splice` on the `process.argv` array to remove the first two arguments
    (which would be `node` and `upload.js)`. The result is passed into our `multipartAssembler`
    function as our `files` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside our function we immediately shift the first file off of the `files`
    array and load it into the variable `f`, which is passed into `createReadStream`.
    Once it''s finished reading, we pass any remaining files back through our `multipartAssembler`
    function and repeat the process until the array is empty. Now let''s flesh out
    our self-iterating function with multipart goodness as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: We specify a part with the predefined boundary initially set in the `content-type`
    header. Each part needs to begin with a header, we latch on to the `open` event
    to send this header out.
  prefs: []
  type: TYPE_NORMAL
- en: '`content-disposition` has three parts. In this scenario, the first part will
    always be `form-data`. The second part defines the name of the field (for instance,
    the `name` attribute of a file input), and the original filename. The `content-type`
    can be set to whatever mime is relevant. However, by setting all files to `application/octet-stream`
    and `content-transfer-encoding` to `binary`, we can safely treat all files the
    same way if all we''re doing is saving to disk without any interim processing.
    We finish each multipart header with a double CRLF (`\r\n\r\n`) at the end of
    our `request.write`.'
  prefs: []
  type: TYPE_NORMAL
- en: Also, notice we've assigned a new `progress` variable at the top of the `multipartAssembler`
    function. We use this to determine the relative percent of the upload by dividing
    the chunks received so far (`progress`), by the total file size (`fSize`). This
    calculation is performed in our `data` event callback, where we also stream each
    chunk to the server.
  prefs: []
  type: TYPE_NORMAL
- en: In our `end` event, if there are no more files to process, we end the request
    with the final multipart boundary which is the same as other boundary partitions
    except it has leading and trailing slashes.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Working with real data: fetching trending tweets* discussed In [Chapter 3](ch03.html
    "Chapter 3. Working with Data Serialization"), *Working with Data Serialization*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing download throttling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For incoming streams, Node provides `pause` and `resume` methods, but not so
    for outbound streams. Essentially, this means we can easily throttle upload speeds
    in Node but download throttling requires a more creative solution.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We'll need a new `server.js` along with a good-sized file to serve. With the
    `dd` command-line program, we can generate a file for testing purposes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: This will create a 50 MB file named `50meg` which we'll be serving.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For a similar Windows tool that can be used to generate a large file, check
    out [http://www.bertel.de/software/rdfc/index-en.html](http://www.bertel.de/software/rdfc/index-en.html).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To keep things as simple as possible our download server will serve just one
    file, but we'll implement it in a way which would allow us to easily plug in some
    router code to serve multiple files. First, we will require our modules and set
    up an `options` object for file and speed settings.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: If we were serving multiple files, our `options` object would be largely redundant.
    However, we're using it here to emulate the concept of a user-determined file
    choice. In a multifile situation, we would be loading file specifics based upon
    the requested URL instead.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To see how this recipe could be configured to serve and throttle more than one
    file, check out the routing recipes In [Chapter 1](ch01.html "Chapter 1. Making
    a Web Server"), *Making a Web Server*
  prefs: []
  type: TYPE_NORMAL
- en: The `http` module is for the server while the `fs` module is for creating a
    `readStream` and grabbing the size of our file.
  prefs: []
  type: TYPE_NORMAL
- en: We're going to restrict how much data is sent out at once, but we first need
    to get the data in. So let's create our server and initialize a `readStream`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ve created our server and specified a new object called `download`, which
    inherits from our `options` object. We add two properties to our request-bound
    `download` object: a `chunks` property that collects the file chunks inside the
    `readStream` data event listener and a `bufferOffset` property that will be used
    to keep track of the amount of bytes loaded from disk.'
  prefs: []
  type: TYPE_NORMAL
- en: All we have to do now is the actual throttling. To achieve this, we simply apportion
    out the specified number of kilobytes from our buffer every second, thus achieving
    the specified kilobytes per second. We'll make a function for this, which will
    be placed outside of `http.createServer` and we'll call our function `throttle`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '`throttle` interacts with the `download` object created on each server request
    to measure out each chunk according to our predetermined `options.kbps` speed.
    For the second parameter (`cb`), `throttle` accepts a functional callback. `cb`
    in turn takes one parameter, which is the chunk of data that `throttle` has determined
    to send. Our `throttle` function returns a convenience function that can be used
    to end the loop on abort, avoiding infinite looping. We initialize download throttling
    by calling our `throttle` function in the server callback when the `readStream`
    opens.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The key to this recipe is our `throttle` function. Let's walk through it. To
    achieve the specified speed, we send a chunk of data of a certain size every second.
    The size is determined by the desired amount of kilobytes per second. So, if `download.kbps`
    is 32, we'll send 32 KB chunks every second.
  prefs: []
  type: TYPE_NORMAL
- en: Buffers work in bytes, so we set a new variable called `chunkOutSize` and multiply
    `download.kbps` by 1024 to realize the appropriate chunk size in bytes. Next,
    we set a `timer` variable which is passed into `setTimeout`. It is first set to
    `0` on two accounts. For one, it eliminates an unnecessary initial 1000 millisecond
    overhead, allowing our server the opportunity to immediately send the first chunk
    of data, if available. Secondly, if the `download.chunks` buffer is not full enough
    to accommodate the demand of `chunkOutSize`, the embedded `loop` function recurses
    without changing `timer`. This causes the CPU to cycle in real time until the
    buffer loads enough data to deliver a whole chunk (a process which should take
    less than a second).
  prefs: []
  type: TYPE_NORMAL
- en: Once we have enough data for the first chunk, `timer` is set to 1000 because
    from here on out we want to push a chunk every second.
  prefs: []
  type: TYPE_NORMAL
- en: '`loop` is the guts of our throttling engine. It''s a self-recursive function
    which calls itself with one parameter: `bytesSent`. The `bytesSent` parameter
    allows us to keep track of how much data has been sent so far, and we use it to
    determine which bytes to slice out of our `download.chunks` buffer using `Buffer.slice.
    Buffer.slice` takes two parameters, `start` and `end`. These two parameters are
    fulfilled with `bytesSent` and `bytesOut` respectively. `bytesOut` is also used
    against `download.bufferOffset` to ensure we have enough data loaded for a whole
    chunk to be sent out.'
  prefs: []
  type: TYPE_NORMAL
- en: If there is enough data, we proceed to set the `timer` to 1000 to initiate our
    chunk per second policy, then pass the result of `download.chunks.slice` into
    `cb` which becomes our `send` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Back inside our server, our `send` parameter is passed to `response.write` within
    our `throttle` callback, so each chunk is streamed to the client. Once we've passed
    our sliced chunk to `cb` we call `loop(bytesOut)` for a new iteration (thus `bytesOut`
    transforms into `bytesSent)`, then we return from the function to prevent any
    further execution.
  prefs: []
  type: TYPE_NORMAL
- en: The third and final place `bytesOut` appears is in the second conditional statement
    of the `setTimeout` callback, where we use it against `download.chunks.length`.
    This is important for handling the last chunk of data. We don't want to loop again
    after the final chunk has been sent, and if `options.kbps` doesn't divide exactly
    into the total file size, the final `bytesOut` would be larger than the size of
    the buffer. If passed into the `slice` method unchecked, this would cause an object
    out of bounds (`oob`) error.
  prefs: []
  type: TYPE_NORMAL
- en: So if `bytesOut` equals, or is greater than, the memory allocated to the `download.chunks`
    buffer (that is, the size of our file), we `slice` the remaining bytes from our
    `download.chunks` buffer and return from the function without calling `loop`,
    effectively terminating recursion.
  prefs: []
  type: TYPE_NORMAL
- en: To prevent infinite looping when the connection is closed unexpectedly (for
    instance during connection failure or client abort) `throttle` returns another
    function, which is caught in the `handleAbort` variable and called in the `close`
    event of `response`. The function simply adds a property to the `download` object
    to say the download has been aborted. This is checked on each recursion of the
    `loop` function. As long as `download.aborted` isn't `true` it continues to iterate,
    otherwise the looping stops short.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are (configurable) limits on operating systems defining how many files
    can be opened at once. We would probably want to implement caching in a production
    download server to optimize file system access. For file limits on Unix systems,
    see [http://www.stackoverflow.com/questions/34588/how-do-i-change-the-number-of-open-files-limit-in-linux](http://www.stackoverflow.com/questions/34588/how-do-i-change-the-number-of-open-files-limit-in-linux).
  prefs: []
  type: TYPE_NORMAL
- en: Enabling resumes from broken downloads
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If a connection breaks, or a user accidentally aborts a download, the client
    may initiate a resume request by sending a `Range` HTTP header to the server.
    A `Range` header would look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'When a server agrees to handle a `Range` header, it sends a `206 Partial Content`
    status and adds a `Content-Range` header in the response. Where the entire file
    is 1 MB, a `Content-Range` reply to the preceding `Range` header might look as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Notice that there is no equals sign (=) after `bytes` in a `Content-Range` header.
    We can pass an object into the second parameter of `fs.createReadStream`, which
    specifies where to start and end reading. Since we are simply handling resumes,
    we only need to set the `start` property.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: By adding some properties to `download`, and using them to conditionally respond
    to a `Range` header, we can now handle resume requests.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Setting up a router* discussed in [Chapter 1](ch01.html "Chapter 1. Making
    a Web Server"), *Making a Web Server*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Caching content in memory for immediate delivery* discussed In [Chapter 1](ch01.html
    "Chapter 1. Making a Web Server"), *Making a Web Server*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Communicating via TCP* discussed In [Chapter 8](ch08.html "Chapter 8. Integrating
    Network Paradigms"), *Integrating Networking Paradigms*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
