- en: Chapter 2. Exploring the HTTP Object
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter we will cover:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: Processing POST data
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling file uploads
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Node as an HTTP client
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing download throttling
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we used the `http` module to create a web server. Now
    we're going to look into some associated use cases beyond simply pushing content
    from server to client. The first three recipes will explore how to receive data
    via client-initiated HTTP POST (and PUT) requests, and in the final recipe we'll
    demonstrate how to throttle a stream of outbound data.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Processing POST data
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If we want to be able to receive POST data, we have to instruct our server on
    how to accept and handle a POST request. In PHP we could access our POST values
    seamlessly with `$_POST['fieldname']`, because it would block until an array value
    was filled. By contrast, Node provides low-level interaction with the flow of
    HTTP data allowing us to interface with the incoming message body as a stream,
    leaving it entirely up to the developer to turn that stream into usable data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s create a `server.js` file ready for our code, and an HTML file called
    `form.html`, containing the following code:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Tip
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For our purposes, we'll place `form.html` in the same folder as `server.js`,
    though this is not generally a recommended practice. Usually, we should place
    our public code in a separate folder from our server code.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We'll provision our server for both GET and POST requests. Let's start with
    GET by requiring the `http` module and loading `form.html` for serving through
    `createServer:`
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We are synchronously loading `form.html` at initialization time instead of
    accessing the disk on each request. If we navigate to `localhost:8080`, we''ll
    be presented with a form. However, if we fill out our form nothing happens because
    we need to handle POST requests:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Once the form is completed and submitted, the browser and console will output
    the raw query string sent from the client. Converting `postData` into an object
    provides an easy way to interact with and manipulate the submitted information.
    The `querystring` module has a `parse` method which transforms query strings into
    objects, and since form submission arrives in query string format, we can use
    it to objectify our data as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Notice the `util` module. We require it to use its `inspect` method for a simple
    way to output our `postDataObject` to the browser.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we're going to protect our server from memory overload exploits.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Protecting a POST server**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: V8 (and therefore Node) has virtual memory limitations, based upon the processor
    architecture and operating system constraints. These limitations far exceed the
    demands of most use cases. Nevertheless, if we don't restrict the amount of data
    our POST server will accept, we could leave ourselves open for a type of Denial
    of Service attack. Without protection, an extremely large POST request could cause
    our server to slow down significantly or even crash.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: To achieve this, we'll set a variable for the maximum acceptable data size and
    check it against the growing length of our `postData` variable.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: How it works...
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once we know a POST request has been made of our server (by checking `request.method)`,
    we aggregate our incoming data into our `postData` variable via the `data` event
    listener on the `request` object. However, if we find that the submitted data
    exceeds our `maxData` limit, we will clear our `postData` variable and `pause`
    the incoming stream preventing any further data arriving from the client. Using
    `stream.destroy` instead of `stream.pause` seems to interfere with our response
    mechanism. Once a stream has been paused for a while it is automatically removed
    from memory by v8's garbage collector.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we send a `413 Request Entity Too Large` HTTP header. In the `end` event
    listener, as long as `postData` hasn''t been cleared for exceeding `maxData` (or
    wasn''t blank in the first place), we use `querystring.parse` to turn our POST
    message body into an object. From this point, we could perform any number of interesting
    activities: manipulate, analyze, pass it to a database, and so on. However, for
    the example, we simply output `postDataObject` to the browser and `postData` to
    the console.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we want our code to look a little more elegant, and we're not so concerned
    about handling POST data as a stream, we can employ a user land (non-core) module
    to get a little sugar on our syntax.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Accessing POST data with connect.bodyParser
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Connect is an excellent middleware framework for Node providing a method framework
    that assimilates a higher level of abstraction for common server tasks. Connect
    is actually the basis of the Express web framework, which will be discussed In
    [Chapter 6](ch06.html "Chapter 6. Accelerating Development with Express"), *Accelerating
    Development with Express*
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: One piece of middleware that comes bundled with Connect is `bodyParser`. By
    chaining `connect.bodyParser` to a normal callback function, we suddenly have
    access to the POST data via `request.body` (when data is sent by the POST request
    it is held in the message body). `request.body` turns out to be exactly the same
    object as `postDataObject` we generated in our recipe.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s make sure we have Connect installed:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We require `connect` in place of `http` since it provides us with the `createServer`
    capabilities. To access the `createServer` method, we can use `connect.createServer`,
    or the shorthand version, which is simply `connect`. Connect allows us to combine
    multiple pieces of middleware together by passing them in as parameters to the
    `createServer` method. Here''s how to implement similar behavior, as in the recipe
    using Connect:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Notice we are no longer using the `http` module directly. We pass `connect.limit`
    in as our first parameter to achieve the same `maxData` restriction implemented
    in the main example.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Next, we pass in `bodyParser`, allowing `connect` to retrieve our POST data
    for us, objectifying the data into `request.body`. Finally, there's our callback
    function, with all the former POST functionality stripped out except the code
    to echo our data object (which is now `request.body)` to console and browser.
    This is where we deviate slightly from our original recipe.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: 'In the recipe we return the raw `postData` to the console, though we return
    the `request.body` object here. To output raw data with Connect would either take
    pointless deconstruction of our object to reassemble the raw query string or an
    extension of the `bodyParser` function. This is the tradeoff with using third-party
    modules: we can only easily interact with information the module author expects
    us to interact with.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look under the hood for a moment. If we fire up an instance of `node`
    without any arguments, we can access the REPL (Read-Eval-Print-Loop) which is
    the Node command-line environment. In the REPL, we can write:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: If we look at the output, we'll see its `connect.bodyParser` function code and
    should be able to easily identify the essential elements from our recipe at work
    in the `connect.bodyParser` code.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: See also
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Handling file uploads* discussed in this chapter'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Browser-server transmission via AJAX* discussed In [Chapter 3](ch03.html "Chapter 3. Working
    with Data Serialization"), *Working with Data Serialization*'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Initializing and using a session* discussed In [Chapter 6](ch06.html "Chapter 6. Accelerating
    Development with Express"), *Accelerating Development with Express*'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling file uploads
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We cannot process an uploaded file in the same way we process other POST data.
    When a file input is submitted in a form, the browser processes the file into
    a **multipart message.**
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Multipart was originally developed as an email format allowing multiple pieces
    of mixed content to be combined into one message. If we intuitively attempted
    to receive the upload as a stream and write it to a file, we would have a file
    filled with multipart data instead of the file or files themselves. We need a
    multipart parser, the writing of which is more than a recipe can cover. So instead
    we'll be using the well-known and battle-tested `formidable` module to convert
    our upload data into files.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's create a new `uploads` directory for storing uploaded files and get ready
    to make modifications to our `server.js` file from the previous recipe.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll also need to install `formidable` as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Finally, we''ll make some changes to our `form.html` from the last recipe:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We've included an `enctype` attribute of `multipart/form-data` to signify to
    the browser that the form will contain upload data and we've replaced the text
    inputs with file inputs.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s see what happens when we use our modified form to upload a file to the
    server from the last recipe. Let''s upload `form.html` itself as our file:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/7188-02-1.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
- en: Our POST server simply logs the raw HTTP message body to the console, which
    in this case is multipart data. We had two file inputs on the form. Though we
    only uploaded one file, the second input is still included in the multipart request.
    Each file is separated by a predefined boundary that is set in a secondary attribute
    of the `Content-Type` HTTP headers. We'll need to use `formidable` to parse this
    data, extracting each file contained therein.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Our POST server has now become an upload server.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We create a new instance of the `formidable IncomingForm` class and tell it
    where to upload files. In order to provide feedback to the user, we can listen
    to our `incoming` instance. The `IncomingForm` class emits its own higher level
    events, so rather than listening to the `request` object for events and processing
    data as it comes, we wait for `formidable` to parse the files out of the multipart
    message and then notify us through its custom `file` event.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: 'The `file` event callback provides us with two parameters: `field` and `file`.
    The `file` parameter is an object containing information about the uploaded file.
    We use this to filter out empty files (usually caused by empty input fields) and
    grab the filename which we show to users as confirmation. When `formidable` has
    finished parsing the multipart message, it sends an `end` event in which we end
    the response.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can post more than simple form fields and values from a browser. Let's take
    a look at transferring files from browser to server.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Using formidable to accept all POST data
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`formidable` doesn''t just handle uploaded files, it will also process general
    POST data. All we have to do is add a listener for the `field` event to process
    forms containing both files and user data.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: There's no need to manually implement field data size limits as `formidable`
    takes care of this for us. However, we can change the defaults with `incoming.maxFieldsSize`,
    which allows us to limit the total byte count for the sum of all fields. This
    limit doesn't apply to file uploads.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Preserving filenames with formidable
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When `formidable` places our files into the `uploads` directory, it assigns
    them a name consisting of a randomly generated hexadecimal number. This prevents
    files of the same name from being overwritten. But what if we want to know which
    files are which and yet still retain the unique filename advantage? We can alter
    the way `formidable` names each file during its `fileBegin` event as shown in
    the following code:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We've appended the original filename onto the end of the random filename assigned
    by `formidable`, separating them with a dash. Now we can easily identify our files.
    However, for many scenarios this may not be necessary as we would likely be outputting
    file information to a database and cross referencing it to randomly generated
    names.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Uploading via PUT
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It's also possible to upload files via an HTTP PUT request. While we can only
    send one file per request, we don't need to do any parsing on the server side
    since the file will simply stream directly to our server, which means less server-side
    processing overhead. It would be magnificent if we could achieve this by changing
    our form's `method` attribute from `POST` to `PUT` but alas, no. However, thanks
    to the up and coming `XMLHttpRequest Level 2` (xhr2), we can now transfer binary
    data via JavaScript in some browsers (see [http://www.caniuse.com/#search=xmlhttprequest%202)](http://www.caniuse.com/#search=xmlhttprequest%202)).
    We grab a file pointer using a `change` event listener on the input file element,
    then we open a PUT request and send the file. The following is for use in `form.html`,
    which we'll save as `put_upload_form.html:`
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '`Id` is added to the form and file inputs while `method` and `enctype` attributes
    have been removed. We''re using just one file element because we can only send
    one file per request, although the example could be extended to asynchronously
    stream multiple files to our server at once.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: 'Our script attaches a `change` listener to the file input element. When the
    user selects a file we are able to capture a pointer to the file. As the form
    is submitted, we prevent default behavior, check if a file is selected, initialize
    an `xhr` object, open a PUT request to our server, set a custom header so we can
    grab the filename later, and send the file to our server. Our server looks like
    the following code:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Our PUT server follows a similar pattern to the simple POST server in the *Processing
    POST data* recipe. We listen to the data event and piece the chunks together.
    However, rather than string concatenate our data, we must throw our chunks into
    a buffer because a buffer can handle any data type including binary, whereas a
    string object will always coerce non-string data into string format. This changes
    the underlying binary resulting in corrupted files. Once the `end` event has triggered,
    we generate a random file name similar to the naming convention of `formidable`
    and write the file to our `uploads` folder.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This *Uploading via PUT* demonstration will not work in older browsers, so an
    alternative fall back should be provided in a production environment. Browsers
    that will support this method are IE 10 and above, Firefox, Chrome, Safari, iOS
    5+ Safari, and Android browsers. However, due to browser vendors differing implementations
    of the same functionality, the example may need some tweaking for cross-browser
    compatibility.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: See also
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Sending email discussed in* [Chapter 8](ch08.html "Chapter 8. Integrating
    Network Paradigms"), *Integrating Network Paradigms*'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Using Node as an HTTP client* discussed in this chapter.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Node as an HTTP client
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The HTTP object doesn't just provide server capabilities, it also affords us
    with client functionality. In this task, we're going to use `http.get` with `process`
    to fetch external web pages dynamically via the command line.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are not creating a server, so in the naming convention we should use a different
    name for our new file, let's call it `fetch.js`.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`http.request` allows us to make requests of any kind (for example, GET, POST,
    DELETE, OPTION, and so on), but for GET requests we can use the short-hand `http.get`
    method as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Essentially we're done.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'If we run the preceding command, our console will output the HTML of `nodejs.org`.
    However, let''s pad it out a bit with some interactivity and error handling as
    shown in the following code:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now we can use our script like this:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: How it works...
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`http.get` takes an object which defines the criteria of our desired request.
    We defined a variable called `urlOpts` for this purpose and set our host to [www.nodejs.org](http://www.nodejs.org).
    We use the `process.argv` property to check if a web address has been specified
    via the command line. Like `console, process` is a global variable that is always
    available within a Node runtime environment. `process.argv[2]` is the third command-line
    argument, with `node` and `fetch.js` being allocated to `[0]` and `[1]` respectively.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: If `process.argv[2]` exists (that is, if an address has been specified) we append
    `http://`. If it isn't there (`url.parse` requires it), then replace the object
    in our default `urlOpts` with the output from `url.parse`. Happily, `url.parse`
    returns an object with the same properties `http.get` requires.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: As a client, we are interacting with the server's response to us, rather than
    the client's request from us. So inside the `http.get` callback, we listen for
    the `data` event on `response` instead of (as with our server examples) `request`.
    As the `response` data stream arrives, we output the chunks to the console.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's explore some of the possibilities of the underlying `http.request` method
    of `http.get`.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Sending POST requests
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We'll need to fire up our `server.js` app from the *Processing POST data* recipe
    to receive our POST requests. Let's make a new file and call it `post.js`, which
    we'll use to send POST requests to our POST server.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As we're using the more general `http.request`, we've had to define our HTTP
    verb in the `urlOpts` variable. Our `urlOpts` variable also specifies the server
    as `localhost:8080` (we must ensure that our POST server is running in order for
    this code to work).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: As before, we set up an event listener in our callback for `data` on the `response`
    object. `http.request` returns a `clientRequest` object which we load into a variable
    called `request`. This is a newly declared variable, which holds the returned
    `clientRequest` object from our `http.request` method.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'After our event listeners, we loop through the command-line arguments using
    the Ecmascript 5 `forEach` method (which is safe to use in Node but not yet in
    browsers). In running this script, `node` and `post.js` would be the 0th and 1st
    arguments, so we check that our array index is greater than 1 before sending any
    arguments as POST data. We use `request.write` to send data similar to how we
    would use `response.write` if we were building a server. Even though it uses a
    callback, `forEach` is not asynchronous (it blocks until completion), so only
    after every element is processed is our POST data written and our request ended.
    This is how we use it:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Multipart file upload as a client
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We'll use our upload server from *Handling File Uploads* to receive the files
    from our uploading client. To achieve this, we have to deal with the multipart
    data format. To inform a server of the client's intentions of sending multipart
    data, we set the `content-type` header to `multipart/form-data` with an additional
    attribute called `boundary`, which is a custom named delimiter, separating files
    in the multipart data.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We've required the `fs` module here too as we'll be needing that later to load
    our files.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ve set our `boundary` to the current Unix time (milliseconds since midnight,
    January 1, 1970). We won''t need `boundary` again in this format, so let''s update
    it with the required multipart double dash (`--`) prefix and set up our `http.request`
    call:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We want to be able to stream multipart data to the server, which may be compiled
    from multiple files. If we streamed these files while simultaneously attempting
    to compile them together into the multipart format, the data would likely be mashed
    together from different file streams in an unpredictable order becoming impossible
    to parse. So we need a way to preserve the data order.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: We could build it all in one go and afterwards send it to the server. However,
    a more efficient (and Node-like) solution is to build the multipart message by
    progressively assembling each file into the multipart format as the file is streamed
    in, while instantly streaming the multipart data as it's being built.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: To achieve this, we can use a self-iterating function, calling each recursion
    from within the `end` event callback to ensure each stream is captured separately
    and in order.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This is also a self-calling function because we''ve changed it from a declaration
    to an expression by wrapping parenthesis around it. Then we''ve called it by appending
    parenthesis, also passing in the command-line arguments, which specify what files
    to upload:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We use `splice` on the `process.argv` array to remove the first two arguments
    (which would be `node` and `upload.js)`. The result is passed into our `multipartAssembler`
    function as our `files` parameter.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside our function we immediately shift the first file off of the `files`
    array and load it into the variable `f`, which is passed into `createReadStream`.
    Once it''s finished reading, we pass any remaining files back through our `multipartAssembler`
    function and repeat the process until the array is empty. Now let''s flesh out
    our self-iterating function with multipart goodness as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: We specify a part with the predefined boundary initially set in the `content-type`
    header. Each part needs to begin with a header, we latch on to the `open` event
    to send this header out.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '`content-disposition` has three parts. In this scenario, the first part will
    always be `form-data`. The second part defines the name of the field (for instance,
    the `name` attribute of a file input), and the original filename. The `content-type`
    can be set to whatever mime is relevant. However, by setting all files to `application/octet-stream`
    and `content-transfer-encoding` to `binary`, we can safely treat all files the
    same way if all we''re doing is saving to disk without any interim processing.
    We finish each multipart header with a double CRLF (`\r\n\r\n`) at the end of
    our `request.write`.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Also, notice we've assigned a new `progress` variable at the top of the `multipartAssembler`
    function. We use this to determine the relative percent of the upload by dividing
    the chunks received so far (`progress`), by the total file size (`fSize`). This
    calculation is performed in our `data` event callback, where we also stream each
    chunk to the server.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: In our `end` event, if there are no more files to process, we end the request
    with the final multipart boundary which is the same as other boundary partitions
    except it has leading and trailing slashes.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: See also
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Working with real data: fetching trending tweets* discussed In [Chapter 3](ch03.html
    "Chapter 3. Working with Data Serialization"), *Working with Data Serialization*'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing download throttling
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For incoming streams, Node provides `pause` and `resume` methods, but not so
    for outbound streams. Essentially, this means we can easily throttle upload speeds
    in Node but download throttling requires a more creative solution.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We'll need a new `server.js` along with a good-sized file to serve. With the
    `dd` command-line program, we can generate a file for testing purposes.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This will create a 50 MB file named `50meg` which we'll be serving.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For a similar Windows tool that can be used to generate a large file, check
    out [http://www.bertel.de/software/rdfc/index-en.html](http://www.bertel.de/software/rdfc/index-en.html).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To keep things as simple as possible our download server will serve just one
    file, but we'll implement it in a way which would allow us to easily plug in some
    router code to serve multiple files. First, we will require our modules and set
    up an `options` object for file and speed settings.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: If we were serving multiple files, our `options` object would be largely redundant.
    However, we're using it here to emulate the concept of a user-determined file
    choice. In a multifile situation, we would be loading file specifics based upon
    the requested URL instead.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To see how this recipe could be configured to serve and throttle more than one
    file, check out the routing recipes In [Chapter 1](ch01.html "Chapter 1. Making
    a Web Server"), *Making a Web Server*
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: The `http` module is for the server while the `fs` module is for creating a
    `readStream` and grabbing the size of our file.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: We're going to restrict how much data is sent out at once, but we first need
    to get the data in. So let's create our server and initialize a `readStream`.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We''ve created our server and specified a new object called `download`, which
    inherits from our `options` object. We add two properties to our request-bound
    `download` object: a `chunks` property that collects the file chunks inside the
    `readStream` data event listener and a `bufferOffset` property that will be used
    to keep track of the amount of bytes loaded from disk.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: All we have to do now is the actual throttling. To achieve this, we simply apportion
    out the specified number of kilobytes from our buffer every second, thus achieving
    the specified kilobytes per second. We'll make a function for this, which will
    be placed outside of `http.createServer` and we'll call our function `throttle`.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '`throttle` interacts with the `download` object created on each server request
    to measure out each chunk according to our predetermined `options.kbps` speed.
    For the second parameter (`cb`), `throttle` accepts a functional callback. `cb`
    in turn takes one parameter, which is the chunk of data that `throttle` has determined
    to send. Our `throttle` function returns a convenience function that can be used
    to end the loop on abort, avoiding infinite looping. We initialize download throttling
    by calling our `throttle` function in the server callback when the `readStream`
    opens.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: How it works...
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The key to this recipe is our `throttle` function. Let's walk through it. To
    achieve the specified speed, we send a chunk of data of a certain size every second.
    The size is determined by the desired amount of kilobytes per second. So, if `download.kbps`
    is 32, we'll send 32 KB chunks every second.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Buffers work in bytes, so we set a new variable called `chunkOutSize` and multiply
    `download.kbps` by 1024 to realize the appropriate chunk size in bytes. Next,
    we set a `timer` variable which is passed into `setTimeout`. It is first set to
    `0` on two accounts. For one, it eliminates an unnecessary initial 1000 millisecond
    overhead, allowing our server the opportunity to immediately send the first chunk
    of data, if available. Secondly, if the `download.chunks` buffer is not full enough
    to accommodate the demand of `chunkOutSize`, the embedded `loop` function recurses
    without changing `timer`. This causes the CPU to cycle in real time until the
    buffer loads enough data to deliver a whole chunk (a process which should take
    less than a second).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: Once we have enough data for the first chunk, `timer` is set to 1000 because
    from here on out we want to push a chunk every second.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '`loop` is the guts of our throttling engine. It''s a self-recursive function
    which calls itself with one parameter: `bytesSent`. The `bytesSent` parameter
    allows us to keep track of how much data has been sent so far, and we use it to
    determine which bytes to slice out of our `download.chunks` buffer using `Buffer.slice.
    Buffer.slice` takes two parameters, `start` and `end`. These two parameters are
    fulfilled with `bytesSent` and `bytesOut` respectively. `bytesOut` is also used
    against `download.bufferOffset` to ensure we have enough data loaded for a whole
    chunk to be sent out.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: If there is enough data, we proceed to set the `timer` to 1000 to initiate our
    chunk per second policy, then pass the result of `download.chunks.slice` into
    `cb` which becomes our `send` parameter.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有足够的数据，我们继续将`timer`设置为1000，以启动我们的每秒一个块的策略，然后将`download.chunks.slice`的结果传递给`cb`，这将成为我们的`send`参数。
- en: Back inside our server, our `send` parameter is passed to `response.write` within
    our `throttle` callback, so each chunk is streamed to the client. Once we've passed
    our sliced chunk to `cb` we call `loop(bytesOut)` for a new iteration (thus `bytesOut`
    transforms into `bytesSent)`, then we return from the function to prevent any
    further execution.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 回到服务器内部，我们的`send`参数被传递到`throttle`回调中的`response.write`，因此每个块都被流式传输到客户端。一旦我们将切片的块传递给`cb`，我们调用`loop(bytesOut)`进行新的迭代（因此`bytesOut`变成`bytesSent`），然后我们从函数中返回，以防止进一步执行。
- en: The third and final place `bytesOut` appears is in the second conditional statement
    of the `setTimeout` callback, where we use it against `download.chunks.length`.
    This is important for handling the last chunk of data. We don't want to loop again
    after the final chunk has been sent, and if `options.kbps` doesn't divide exactly
    into the total file size, the final `bytesOut` would be larger than the size of
    the buffer. If passed into the `slice` method unchecked, this would cause an object
    out of bounds (`oob`) error.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '`bytesOut`第三次出现的地方是在`setTimeout`回调的第二个条件语句中，我们将其与`download.chunks.length`进行比较。这对于处理最后一块数据很重要。我们不希望在最后一块数据发送后再次循环，如果`options.kbps`不能完全整除总文件大小，最后的`bytesOut`将大于缓冲区的大小。如果未经检查地传递给`slice`方法，这将导致对象越界（`oob`）错误。'
- en: So if `bytesOut` equals, or is greater than, the memory allocated to the `download.chunks`
    buffer (that is, the size of our file), we `slice` the remaining bytes from our
    `download.chunks` buffer and return from the function without calling `loop`,
    effectively terminating recursion.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果`bytesOut`等于或大于分配给`download.chunks`缓冲区的内存（即我们文件的大小），我们将从`download.chunks`缓冲区中切片剩余的字节，并在不调用`loop`的情况下从函数中返回，有效地终止递归。
- en: To prevent infinite looping when the connection is closed unexpectedly (for
    instance during connection failure or client abort) `throttle` returns another
    function, which is caught in the `handleAbort` variable and called in the `close`
    event of `response`. The function simply adds a property to the `download` object
    to say the download has been aborted. This is checked on each recursion of the
    `loop` function. As long as `download.aborted` isn't `true` it continues to iterate,
    otherwise the looping stops short.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止连接意外关闭时出现无限循环（例如在连接失败或客户端中止期间），`throttle`返回另一个函数，该函数在`handleAbort`变量中捕获并在`response`的`close`事件中调用。该函数简单地向`download`对象添加一个属性，表示下载已中止。这在`loop`函数的每次递归中都会进行检查。只要`download.aborted`不是`true`，它就会继续迭代，否则循环会提前停止。
- en: Note
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: There are (configurable) limits on operating systems defining how many files
    can be opened at once. We would probably want to implement caching in a production
    download server to optimize file system access. For file limits on Unix systems,
    see [http://www.stackoverflow.com/questions/34588/how-do-i-change-the-number-of-open-files-limit-in-linux](http://www.stackoverflow.com/questions/34588/how-do-i-change-the-number-of-open-files-limit-in-linux).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统上有（可配置的）限制，定义了可以同时打开多少文件。我们可能希望在生产下载服务器中实现缓存，以优化文件系统访问。有关Unix系统上的文件限制，请参阅[http://www.stackoverflow.com/questions/34588/how-do-i-change-the-number-of-open-files-limit-in-linux](http://www.stackoverflow.com/questions/34588/how-do-i-change-the-number-of-open-files-limit-in-linux)。
- en: Enabling resumes from broken downloads
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 启用断点续传
- en: 'If a connection breaks, or a user accidentally aborts a download, the client
    may initiate a resume request by sending a `Range` HTTP header to the server.
    A `Range` header would look something like this:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 如果连接中断，或用户意外中止下载，客户端可以通过向服务器发送`Range` HTTP头来发起恢复请求。`Range`头可能如下所示：
- en: '[PRE31]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'When a server agrees to handle a `Range` header, it sends a `206 Partial Content`
    status and adds a `Content-Range` header in the response. Where the entire file
    is 1 MB, a `Content-Range` reply to the preceding `Range` header might look as
    follows:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 当服务器同意处理`Range`头时，它会发送`206 Partial Content`状态，并在响应中添加`Content-Range`头。如果整个文件大小为1
    MB，对先前的`Range`头的`Content-Range`回复可能如下所示：
- en: '[PRE32]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Notice that there is no equals sign (=) after `bytes` in a `Content-Range` header.
    We can pass an object into the second parameter of `fs.createReadStream`, which
    specifies where to start and end reading. Since we are simply handling resumes,
    we only need to set the `start` property.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在`Content-Range`头中`bytes`后面没有等号（=）。我们可以将对象传递给`fs.createReadStream`的第二个参数，指定从哪里开始和结束读取。由于我们只是处理恢复，因此只需要设置`start`属性。
- en: '[PRE33]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: By adding some properties to `download`, and using them to conditionally respond
    to a `Range` header, we can now handle resume requests.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 通过向`download`添加一些属性，并使用它们有条件地响应`Range`头，我们现在可以处理恢复请求。
- en: See also
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: '*Setting up a router* discussed in [Chapter 1](ch01.html "Chapter 1. Making
    a Web Server"), *Making a Web Server*'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*设置路由器*讨论在[第1章](ch01.html "第1章。制作Web服务器")中，*制作Web服务器*'
- en: '*Caching content in memory for immediate delivery* discussed In [Chapter 1](ch01.html
    "Chapter 1. Making a Web Server"), *Making a Web Server*'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在内存中缓存内容以进行即时交付*讨论在[第1章](ch01.html "第1章。制作Web服务器")中，*制作Web服务器*'
- en: '*Communicating via TCP* discussed In [Chapter 8](ch08.html "Chapter 8. Integrating
    Network Paradigms"), *Integrating Networking Paradigms*'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通过TCP通信*讨论在[第8章](ch08.html "第8章。集成网络范式")中，*集成网络范式*'
