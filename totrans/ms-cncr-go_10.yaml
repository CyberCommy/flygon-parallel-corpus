- en: Chapter 10. Advanced Concurrency and Best Practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you're comfortable with the basic and intermediate usage of concurrency
    features in Go, you may find that you're able to handle the majority of your development
    use cases with bidirectional channels and standard concurrency tools.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 2](part0021_split_000.html#page "Chapter 2. Understanding the Concurrency
    Model"), *Understanding the Concurrency Model*, and [Chapter 3](part0032_split_000.html#page
    "Chapter 3. Developing a Concurrent Strategy"), *Developing a Concurrent Strategy*,
    we looked at the concurrency models, not just of Go but of other languages as
    well, and compared the way they—and distributed models—can work. In this chapter,
    we'll touch on those and some higher level concepts with regard to designing and
    managing your concurrent application.
  prefs: []
  type: TYPE_NORMAL
- en: In particular, we're going to look at central management of goroutines and their
    associated channels—out of the box you may find goroutines to be a set-it-and-forget-it
    proposition; however, there are cases where we might want more granular control
    of a channel's state.
  prefs: []
  type: TYPE_NORMAL
- en: We've also looked quite a bit at testing and benchmarking from a high level,
    but we'll look at some more detailed and complex methods for testing. We'll also
    explore a primer on the Google App Engine, which will give us access to some specific
    testing tools we haven't yet used.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we'll touch upon some general best practices for Go, which will surely
    pertain not just to concurrent application design but your future work in general
    with the language.
  prefs: []
  type: TYPE_NORMAL
- en: Going beyond the basics with channels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've talked about quite a few different channel implementations—channels of
    different type (interfaces, functions, structs, and channels)—and touched upon
    the differences in buffered and unbuffered channels. However, there's still a
    lot more we can do with the design and flow of our channels and goroutines.
  prefs: []
  type: TYPE_NORMAL
- en: By design, Go wants you to keep things simple. And that's fantastic for 90 percent
    of what you'll do with Go. But there are other times where you'll need to dig
    a little deeper for a solution, or when you'll need to save resources by preserving
    the amount of open goroutine processes, channels, and more.
  prefs: []
  type: TYPE_NORMAL
- en: You may, at some point, want some hands on control of the size and state, and
    also the control of a running or closed goroutine, so we'll look at doing that.
  prefs: []
  type: TYPE_NORMAL
- en: Just as importantly, designing your goroutines to work in concert with the application
    design as a whole can be critical to unit testing, which is a topic we'll touch
    on in this final chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Building workers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Earlier in this book, we talked about concurrency patterns and a bit about workers.
    We even brought the workers concept into play in the previous chapter, when we
    were building our logging systems.
  prefs: []
  type: TYPE_NORMAL
- en: Truly speaking, "worker" is a fairly generic and ambiguous concept, not just
    in Go, but in general programming and development. In some languages, it's an
    object/instantiated class, and in others it's a concurrent actor. In functional
    programming languages, worker is a graduated function return passed to another.
  prefs: []
  type: TYPE_NORMAL
- en: If we go back to the preface, we will see that we have literally used the Go
    gopher as an example of a worker. In short, a worker is something more complex
    than a single function call or programmatic action that will perform a task one
    or more times.
  prefs: []
  type: TYPE_NORMAL
- en: So why are we talking about it now? When we build our channels, we are creating
    a mechanism to do work. When we have a struct or an interface, we're combining
    methods and values at a single place, and then doing work using that *object*
    as both a mechanism for the work as well as a place to store information about
    that work.
  prefs: []
  type: TYPE_NORMAL
- en: This is particularly useful in application design, as we're able to delegate
    various elements of an application's functionality to distinct and well-defined
    workers. Consider, for example, a server pinging application that has specific
    pieces doing specific things in a self-contained, compartmentalized manner.
  prefs: []
  type: TYPE_NORMAL
- en: We'll attempt to check for server availability via the HTTP package, check the
    status code and errors, and back off if we find problems with any particular server.
    You can probably see where this is going—this is the most basic approach to load
    balancing. But an important design consideration is the way in which we manage
    our channels.
  prefs: []
  type: TYPE_NORMAL
- en: We'll have a master channel, where all important global transactions should
    be accumulated and evaluated, but each individual server will also have its own
    channels for handling tasks that are important only to that individual struct.
  prefs: []
  type: TYPE_NORMAL
- en: 'The design in the following code can be considered as a rudimentary pipeline,
    which is roughly akin to the producer/consumer model we talked about in the previous
    chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code gives the configuration part of the application, setting
    scope on how frequently to check servers, the maximum amount of time for backing
    off, and the maximum amount of retries before giving up entirely.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `DELAY_INCREMENT` value represents how much time we will add to our server
    checking process each time we discover a problem. Let''s take a look at how to
    create a server in the following section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we design the basic server (using the following code), which contains
    its current status, the last time it was checked, the present delay between checks,
    its own channel for evaluating statuses and establishing the new status, and updated
    retry delay:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The `checkServerStatus()` method is the meat and potatoes of our application
    here. We pass all of our servers through this method in the `main()` function
    to our `cycleServers()` loop, after which it becomes self-fulfilling.
  prefs: []
  type: TYPE_NORMAL
- en: If our `Status` is set to `true`, we send the state to the console as `OK` (otherwise
    `down`) and set our `Server` status code with `s.StatusCode` as either the HTTP
    code or `0` if there was a network or other error.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, set the last-checked time of `Server` to `Now()` and pass `Server`
    through the `serverChan` channel. In the following code, we''ll demonstrate how
    we''ll rotate through our available servers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This is our initial loop, called from main. It simply loops through our available
    servers and initializes its listening goroutine as well as sending the first `checkServerStatus`
    request.
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s worth noting two things here: first, the channel invoked by `Server`
    will never actually die, but instead the application will stop checking the server.
    That''s fine for all practical purposes here, but if we have thousands and thousands
    of servers to check, we''re wasting resources on what essentially amounts to an
    unclosed channel and a map element that has not been removed. Later, we''ll broach
    the concept of manually killing goroutines, something we''ve only been able to
    do through abstraction by stopping the communication channel. Let''s now take
    a look at the following code that controls a server''s status and its next steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This is where each `Server` will listen for changes in its status, as reported
    by `checkServerStatus()`. When any given `Server` struct receives a message that
    a change in status has been reported via our initial loop, it will evaluate that
    message and act accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: If the `Status` is set to `false`, we know that the server was inaccessible
    for some reason. The `Server` reference itself will then add a delay to the next
    time it's checked. If it's set to `true`, the server was accessible and the delay
    will either be set or reset to the default retry value of `INIT_DELAY`.
  prefs: []
  type: TYPE_NORMAL
- en: 'It finally sets a sleep mode on that goroutine before reinitializing the `checkServerStatus()`
    method on itself, passing the `serverChan` reference along in the initial goroutine
    loop in the `main()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'One quick note here—in our slice of `Servers`, we intentionally introduced
    a typo in the last element. You''ll notice `amazon.zom`, which will provoke an
    HTTP error in the `checkServerStatus()` method. The following is the function
    to cycle through servers to find an appropriate match:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is an example of the output with the typo included:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We'll be taking the preceding code for one last spin through some concurrency
    patterns later in this chapter, turning it into something a bit more practical.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing nil channel blocks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the bigger problems in designing something like a pipeline or producer/consumer
    model is there's somewhat of a black hole when it comes to the state of any given
    goroutine at any given time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following loop, wherein a producer channel creates an arbitrary
    set of consumer channels and expects each to do one and only one thing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Given a random amount of consumers to produce, we attach a channel to each and
    pass a message upstream to the `Producer` via that consumer's channel. We send
    just a single message (which we could handle with a buffered channel), but we
    simply close the channel after.
  prefs: []
  type: TYPE_NORMAL
- en: Whether in a multithreaded application, a distributed application, or a highly
    concurrent application, an essential attribute of a producer-consumer model is
    the ability for data to move across a queue/channel in a steady, reliable fashion.
    This requires some modicum of mutual knowledge to be shared between both the producer
    and consumers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlike environments that are distributed (or multicore), we do possess some
    inherent awareness of the status on both ends of that arrangement. We''ll next
    look at a listening loop for producer messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The primary issue is that one of the `Producer` channel doesn't know much about
    any given `Consumer`, including when it's actively running. If we uncommented
    the `// consumer <- 1` line, we'll get a panic, because we're attempting to send
    a message on a closed channel.
  prefs: []
  type: TYPE_NORMAL
- en: As a message is passed across a secondary goroutine's channel, upstream to the
    channel of the `Producer`, we get an appropriate reception, but cannot detect
    when the downstream goroutine is closed.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing when a goroutine has terminated is in many cases inconsequential, but
    consider an application that spawns new goroutines when a certain number of tasks
    are complete, effectively breaking a task into mini tasks. Perhaps each chunk
    is dependent on the total completion of the last chunk, and a broadcaster must
    know the status of the current goroutines before moving on.
  prefs: []
  type: TYPE_NORMAL
- en: Using nil channels
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the earlier versions of Go, you could communicate across uninitialized, thus
    nil or 0-value channels without a panic (although your results would be unpredictable).
    Starting from Go Version 1, communication across nil channels produced a consistent
    but sometimes confusing effect.
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s vital to note that within a select switch, transmission on a nil channel
    on its own will still cause a deadlock and panic. This is something that will
    most often creep up when utilizing global channels and not ever properly initializing
    them. The following is an example of such transmission on a nil channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'As the channel is set to its `0` value (nil, in this case), it blocks perpetually
    and the Go compiler will detect this, at least in more recent versions. You can
    also duplicate this outside of a `select` statement, as shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code will block forever without the panic, due to the default
    in the `select` statement keeping the main loop active while waiting for communication
    on the channel. If we initialize the channel, however, the application runs as
    expected.
  prefs: []
  type: TYPE_NORMAL
- en: With these two fringe cases—closed channels and nil channels—we need a way for
    a master channel to understand the state of a goroutine.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing more granular control over goroutines with tomb
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As with many such problems—both niche and common—there exists a third-party
    utility for grabbing your goroutines by the horns.
  prefs: []
  type: TYPE_NORMAL
- en: Tomb is a library that provides diagnostics to go along with any goroutine and
    channel—it can tell a master channel if another goroutine is dead or dying.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, it allows you to explicitly kill a goroutine, which is a bit more
    nuanced than simply closing the channel it is attached to. As previously mentioned,
    closing the channel is effectively neutering a goroutine, although it could ultimately
    still be active.
  prefs: []
  type: TYPE_NORMAL
- en: You are about to find a simple fetch-and-grab body script that takes a slice
    of URL structs (with status and URI) and attempts to grab the HTTP response for
    each and apply it to the struct. But instead of just reporting information from
    the goroutines, we'll have the ability to send "kill messages" to each of a "master"
    struct's child goroutines.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we''ll run the script for 10 seconds, and if any of the goroutines
    fail to do their job in that allotted time, it will respond that it was unable
    to get the URL''s body due to a kill send from the master struct that invoked
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the minimum necessary structure required to create a parent or a master
    struct for all of your spawned goroutines. The `tomb.Tomb` struct is simply a
    mutex, two channels (one for dead and dying), and a reason error struct. The structure
    of the `URL` struct looks like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Our `URL` struct is fairly basic—`Status`, set to `false` by default and `true`
    when the body has been retrieved. It consists of the `URI` variable—which is the
    reference to the URL—and the `Body` variable for storing the retrieved data. The
    following function allows us to execute a "kill" on a `GoTomb` struct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding method invokes `tomb.Kill` on our `GoTomb` struct. Here, we have
    set the sole parameter to `nil`, but this can easily be changed to a more descriptive
    error, such as `errors.New("Time to die, goroutine")`. Here, we''ll show the listener
    for the `GoTomb` struct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We invoke `TombListen` attached to our `GoTomb`, which sets a select that listens
    for the `Dying()` channel, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'When we invoke `Fetch()`, we also set the tomb to `TombListen()`, which receives
    those "master" messages across all spawned goroutines. We impose an intentionally
    long wait to ensure that our last few attempts to `Fetch()` will come after the
    `Kill()` command. Finally, our `main()` function, which handles the overall setup:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: By setting `time.Sleep` to `10` seconds and then killing our goroutines, we
    guarantee that the 5 second delays between `Fetch()` prevent the last of our goroutines
    from successfully finishing before being killed.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For the tomb package, go to [http://godoc.org/launchpad.net/tomb](http://godoc.org/launchpad.net/tomb)
    and install it using the `go get launchpad.net/tomb` command.
  prefs: []
  type: TYPE_NORMAL
- en: Timing out with channels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One somewhat critical point with channels and `select` loops that we haven't
    examined particularly closely is the ability—and often necessity—to kill a `select`
    loop after a certain timeout.
  prefs: []
  type: TYPE_NORMAL
- en: Many of the applications we've written so far are long-running or perpetually-running,
    but there are times when we'll want to put a finite time limit on how long goroutines
    can operate.
  prefs: []
  type: TYPE_NORMAL
- en: The `for { select { } }` switch we've used so far will either live perpetually
    (with a default case) or wait to be broken from one or more of the cases.
  prefs: []
  type: TYPE_NORMAL
- en: There are two ways to manage interval-based tasks—both as part of the time package,
    unsurprisingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `time.Ticker` struct allows for any given operation after the specified
    period of time. It provides C, a blocking channel that can be used to detect activity
    sent after that period of time; refer to the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We can extend this to end channels and concurrent execution after a certain
    amount of time. Take a look at the following modifications:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Building a load balancer with concurrent patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we built our server pinging application earlier in this chapter, it was
    probably pretty easy to imagine taking this to a more usable and valuable space.
  prefs: []
  type: TYPE_NORMAL
- en: Pinging a server is often the first step in a health check for a load balancer.
    Just as Go provides a usable out-of-the-box web server solution, it also presents
    a very clean `Proxy` and `ReverseProxy` struct and methods, which makes creating
    a load balancer rather simple.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, a round-robin load balancer will need a lot of background work, specifically
    on checking and rechecking as it changes the `ReverseProxy` location between requests.
    We'll handle these with the goroutines triggered with each request.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, note that we have some dummy URLs at the bottom in the configuration—changing
    those to production URLs should immediately turn the server that runs this into
    a working load balancer. Let''s look at the main setup for the application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'In the previous code, we defined our constants, much like we did previously.
    We have a `MAX_RETRIES`, which limits how many failures we can have, `MAX_TIMEOUT_SECONDS`,
    which defines the longest amount of time we''ll wait before trying again, and
    our `TIMEOUT_INCREMENT` for changing that value between failures. Next, let''s
    look at the basic construction of our `Server` struct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: As we can see in the previous code, we have a generic `Server` struct that maintains
    the present state, the last status code, and information on the last time the
    server was checked.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that we also have a `Recheck` channel that triggers the delayed attempt
    to check the `Server` again for availability. Each Boolean passed across this
    channel will either remove the server from the available pool or reannounce that
    it is still in service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the instantiated method that listens on each server for messages delivered
    on the availability of a server at any given time. While running a goroutine,
    we keep a perpetually listening channel open to listen to Boolean responses from
    `checkStatus()`. If the server is available, the next delay is set to default;
    otherwise, `TIMEOUT_INCREMENT` is added to the delay. If the server has failed
    too many times, it''s taken out of rotation by setting its `InService` property
    to `false` and no longer invoking the `checkStatus()` method. Let''s next look
    at the method for checking the present status of `Server`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Our `checkStatus()` method should look pretty familiar based on the server
    ping example. We look for the server; if it is available, we pass `true` to our
    `Recheck` channel; otherwise `false`, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Our `healthCheck` function simply kicks off the loop of each server checking
    (and re-checking) its status. It''s run only one time, and initializes the `Recheck`
    channel via the `make` statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The `roundRobin` function first checks the next available `Server` in the queue—if
    that server happens to be down, it loops through the remaining to find the first
    available `Server`. If it loops through all, it will reset to `0`. Let''s look
    at the global configuration variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'These are our global variables—our `Servers` slice of `Server` structs, the
    `nextServerIndex` variable, which serves to increment the next `Server` to be
    returned, `ServersAvailable` and `ServerChan`, which start the load balancer only
    after a viable server is available, and then our `Proxy` variables, which tell
    our `http` handler where to go. This requires a `ReverseProxy` method, which we''ll
    look at now in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that we''re operating on a `ReverseProxy` struct here, which is different
    from our previous forays into serving webpages. Our next function executes the
    round robin and gets our next available server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The `setProxy` function is called after every request, and you can see it as
    the first line in our handler. Next we have the general listening function that
    looks out for requests we''ll be reverse proxying:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: With this application, we have a simple but extensible load balancer that works
    with the common, core components in Go. Its concurrency features keep it lean
    and fast, and we wrote it in a very small amount of code using exclusively standard
    Go.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing unidirectional and bidirectional channels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the purpose of simplicity, we've designed most of our applications and sample
    code with bidirectional channels, but of course any channel can be set unidirectionally.
    This essentially turns a channel into a "read-only" or "write-only" channel.
  prefs: []
  type: TYPE_NORMAL
- en: If you're wondering why you should bother limiting the direction of a channel
    when it doesn't save any resources or guarantee an issue, the reason boils down
    to simplicity of code and limiting the potential for panics.
  prefs: []
  type: TYPE_NORMAL
- en: 'By now we know that sending data on a closed channel results in a panic, so
    if we have a write-only channel, we''ll never accidentally run into that problem
    in the wild. Much of this can also be mitigated with `WaitGroups`, but in this
    case that''s a sledgehammer being used on a nail. Consider the following loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Since we're abruptly closing our `ch` channel one digit before the goroutine
    can finish, any writes to it cause a runtime error.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, we are invoking a read-only command, but it's in the `select`
    loop. We can safeguard this a bit more by allowing only specific actions to be
    sent on unidirectional channels. This application will always work up to the point
    where in the channel is closed prematurely, one shy of the `TOTAL_RANDOMS` constant.
  prefs: []
  type: TYPE_NORMAL
- en: Using receive-only or send-only channels
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we limit the direction or the read/write capability of our channels, we
    also reduce the potential for closed channel deadlocks if one or more of our processes
    inadvertently sends on such a channel.
  prefs: []
  type: TYPE_NORMAL
- en: So the short answer to the question "When is it appropriate to use a unidirectional
    channel?" is "Whenever you can."
  prefs: []
  type: TYPE_NORMAL
- en: Don't force the issue, but if you can set a channel to read/write only, it may
    preempt issues down the road.
  prefs: []
  type: TYPE_NORMAL
- en: Using an indeterminate channel type
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One trick that can often come in handy, and we haven't yet addressed, is the
    ability to have what is effectively a typeless channel.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you''re wondering why that might be useful, the short answer is concise
    code and application design thrift. Often this is a discouraged tactic, but you
    may find it useful from time to time, especially when you need to communicate
    one or more disparate concepts across a single channel. The following is an example
    of an indeterminate channel type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Using Go with unit testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As with many of the basic and intermediate development and deployment requirements
    you may have, Go comes with a built-in application for handling unit tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic premise behind testing is that you create your package and then create
    a testing package to run against the initial application. The following is a very
    basic example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: A simple Go test in that subdirectory will give you the response you're looking
    for. While this was admittedly simple—and purposefully flawed—you can probably
    see how easy it is to break apart your code and test it incrementally. This is
    enough to do very basic unit tests out of the box.
  prefs: []
  type: TYPE_NORMAL
- en: 'Correcting this would then be fairly simple—the same test would pass on the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The testing package is somewhat limited; however, as it provides basic pass/fails
    without the ability to do assertions. There are two third-party packages that
    can step in and help in this regard, and we'll explore them in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: GoCheck
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**GoCheck** extends the basic testing package primarily by augmenting it with
    assertions and verifications. You''ll also get some basic benchmarking utility
    out of it that works a little more fundamentally than anything you''d need to
    engineer using Go.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For more details on GoCheck visit [http://labix.org/gocheck](http://labix.org/gocheck)
    and install it using `go get gopkg.in/check.v1`.
  prefs: []
  type: TYPE_NORMAL
- en: Ginkgo and Gomega
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This allows testing to be as granular as unit testing, but also expands the
    way we handle application usage in verbose and explicit behaviors.
  prefs: []
  type: TYPE_NORMAL
- en: If BDD is something you or your organization is interested in, this is a fantastic,
    mature package for implementing deeper unit testing.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For more information on Ginkgo go to [https://github.com/onsi/ginkgo](https://github.com/onsi/ginkgo)
    and install it using `go get github.com/onsi/ginkgo/ginkgo`.
  prefs: []
  type: TYPE_NORMAL
- en: For more information on dependency, refer to `go get github.com/onsi/gomega`.
  prefs: []
  type: TYPE_NORMAL
- en: Using Google App Engine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you're unfamiliar with Google App Engine, the short version is it's a cloud
    environment that allows for simple building and deployment of **Platform-As-A-Service**
    (**paas**) solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Compared to a lot of similar solutions, Google App Engine allows you to build
    and test your applications in a very simple and straightforward way. Google App
    Engine allows you to write and deploy in Python, Java, PHP, and of course, Go.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the most part, Google App Engine provides a standard Go installation that
    makes it easy to dovetail off of the `http` package. But it also gives you a few
    noteworthy additional packages that are unique to Google App Engine itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Package | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `appengine/memcache` | This provides a distributed memcache installation
    unique to Google App Engine |'
  prefs: []
  type: TYPE_TB
- en: '| `appengine/mail` | This allows you to send e-mails through an SMTP-esque
    platform |'
  prefs: []
  type: TYPE_TB
- en: '| `appengine/log` | Given your storage may be more ephemeral here, it formalizes
    a cloud version of the log |'
  prefs: []
  type: TYPE_TB
- en: '| `appengine/user` | This opens both identity and OAuth capabilities |'
  prefs: []
  type: TYPE_TB
- en: '| `appengine/search` | This gives your application the power of Google search
    on your own data via datastore |'
  prefs: []
  type: TYPE_TB
- en: '| `appengine/xmpp` | This provides Google Chat-like capabilities |'
  prefs: []
  type: TYPE_TB
- en: '| `appengine/urlfetch` | This is a crawler functionality |'
  prefs: []
  type: TYPE_TB
- en: '| `appengine/aetest` | This extends unit testing for Google App Engine |'
  prefs: []
  type: TYPE_TB
- en: While Go is still considered beta for Google App Engine, you can expect that
    if anyone was able to competently deploy it in a cloud environment, it would be
    Google.
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing best practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The wonderful thing with Go when it comes to best practices is that even if
    you don't necessarily do everything right, either Go will yell at you or provide
    you with the tools necessary to fix it.
  prefs: []
  type: TYPE_NORMAL
- en: If you attempt to include code and not use it, or if you attempt to initialize
    a variable and not use it, Go will stop you. If you want to clean up your code's
    formatting, Go enables it with `go fmt`.
  prefs: []
  type: TYPE_NORMAL
- en: Structuring your code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the easiest things you can do when building a package from scratch is
    to structure your code directories in an idiomatic way. The standard for a new
    package would look something like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Setting up your Go code like this is not just helpful for your own organization,
    but allows you to distribute your package more easily.
  prefs: []
  type: TYPE_NORMAL
- en: Documenting your code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For anyone who has worked in a corporate or collaborative coding environment,
    documentation is sacrosanct. As you may recall earlier, using the `godoc` command
    allows you to quickly get information about a package at the command line or via
    an ad hoc localhost server. The following are the two basic ways you may use `godoc`:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Using godoc | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `godoc fmt` | This brings `fmt` documentation to the screen |'
  prefs: []
  type: TYPE_TB
- en: '| `godoc -http=:3000` | This hosts the documentation on port `:3030` |'
  prefs: []
  type: TYPE_TB
- en: 'Go makes it super easy to document your code, and you absolutely should. By
    simply adding single-line comments above each identifier (package, type, or function),
    you''ll append that to the contextual documentation, as shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: When installed, this will allow anyone to run the `godoc` documentation on your
    package and get as much detailed information as you're willing to supply.
  prefs: []
  type: TYPE_NORMAL
- en: You'll often see more robust examples of this in the Go core code itself, and
    it's worth reviewing that to compare your style of documentation to Google's and
    the Go community's.
  prefs: []
  type: TYPE_NORMAL
- en: Making your code available via go get
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Assuming you've kept your code in a manner consistent with the organizational
    techniques as listed previously, making your code available via code repositories
    and hosts should be a cinch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using GitHub as the standard, here''s how we might design our third-party application:'
  prefs: []
  type: TYPE_NORMAL
- en: Make sure you stick to the previous structural format.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Keep your source files under the directory structures they'll live in remotely.
    In other words, expect that your local structure will reflect the remote structure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perhaps obviously, commit only the files you wish to share in the remote repository.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assuming your repository is public, anyone should be able to get (`go get`)
    and then install (`go install`) your package.
  prefs: []
  type: TYPE_NORMAL
- en: Keeping concurrency out of your packages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One last point that might seem somewhat out of place given the context of the
    book—if you're building separate packages that will be imported, avoid including
    concurrent code whenever possible.
  prefs: []
  type: TYPE_NORMAL
- en: This is not a hard-and-fast rule, but when you consider potential usage, it
    makes sense—let the main application handle the concurrency unless your package
    absolutely needs it. Doing so will prevent a lot of hidden and difficult-to-debug
    behavior that may make your library less appealing.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is my sincere hope that you've been able to explore, understand, and utilize
    the depths of Go's powerful abilities with concurrency through this book.
  prefs: []
  type: TYPE_NORMAL
- en: We've gone over a lot, from the most basic, channel-free concurrent goroutines
    to complex channel types, parallelism, and distributed computing, and we've brought
    some example code along at every step.
  prefs: []
  type: TYPE_NORMAL
- en: By now, you should be fully equipped to build anything your heart desires in
    code, in a manner that is highly concurrent, fast, and error-free. Beyond that,
    you should be able to produce well-formed, properly-structured, and documented
    code that can be used by you, your organization, or others to implement concurrency
    where it is best utilized.
  prefs: []
  type: TYPE_NORMAL
- en: Concurrency itself is a vague concept; it's one that means slightly different
    things to different people (and across multiple languages), but the core goal
    is always fast, efficient, and reliable code that can provide performance boosts
    to any application.
  prefs: []
  type: TYPE_NORMAL
- en: Armed with a full understanding of both the implementation of concurrency in
    Go as well as its inner workings, I hope you continue your Go journey as the language
    evolves and grows, and similarly implore you to consider contributing to the Go
    project itself as it develops.
  prefs: []
  type: TYPE_NORMAL
