- en: Targeting Other Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AWS offers a wide variety of services and they are constantly updating those
    services, along with releasing new ones. There are so many that it would be impossible
    to cover them all in this book, but this chapter aims to cover a few less mainstream
    services and how they can be abused for our benefit as an attacker.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that every single AWS service has the potential for
    some sort of exploitation when looking at it like an attacker, and that just because
    it is not covered in this book, it doesn't mean you shouldn't investigate it.
    There are a variety of security problems that can arise in every service, so the
    best thing to do is to look at a service and determine how it would be used in
    the real world, then look for common mistakes, insecure defaults, or just bad
    practices that are followed to benefit yourself.
  prefs: []
  type: TYPE_NORMAL
- en: The four different services we will look at in this chapter include Route 53,
    a scalable DNS/domain management service; **Simple Email Service** (**SES**),
    a managed email service; CloudFormation, an infrastructure-as-code service; and
    **Elastic Container Registry** (**ECR**), a managed Docker container registry.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Route 53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SES
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CloudFormation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ECR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Route 53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Route 53 is a great service to spend some time looking at for a few different
    reasons. The main reason would be reconnaissance, as it allows us to associate
    IPs and host names and discover domains and sub-domains, which is what we are
    going to cover here. It is also a very fruitful service for some more malicious
    attacks that we aren't going to be going into in-depth because they are not useful
    to us as penetration testers, but we will cover them at the end to make you aware
    of what a real malicious hacker might try and do once gaining access.
  prefs: []
  type: TYPE_NORMAL
- en: Hosted zones
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first thing we will want to do is get a list of hosted zones in Route 53\.
    We can gather this information with the following AWS CLI command (we can leave
    the `--region` argument out for Route 53):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'So, we found one public hosted zone (we can see that `"PrivateZone"` is set
    to `false`), and that it has five record sets created in it (because `"ResourceRecordSetCount"`
    is `5`). Next, we can use the `ListResourceRecordSets` command to check out what
    records have been set for the `"test.com"` hosted zone:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The response will likely be somewhat long, depending on how many record sets
    there are. It should include a list of `"ResourceRecordSets"` that have a name,
    type, **Time-To-Live** (**TTL**), and a list of resource records. These records
    can be any sort of DNS record, such as A records, **C****anonical Name** (**CNAME**)
    records, and **Mail Exchanger **(MX) record. This list of record sets can be compared
    against known IP addresses from something like EC2, so that you can discover the
    hostname associated with certain servers you can access, or even discover unknown
    IPs, domains, and subdomains.
  prefs: []
  type: TYPE_NORMAL
- en: This is useful because many web servers won't load correctly when visiting the
    server's IP address directly, as it requires the hostname, which we can use Route
    53 to figure out and resolve correctly.
  prefs: []
  type: TYPE_NORMAL
- en: This is also useful when looking at private hosted zones in Route 53 to help
    you discover what hosts and IPs are available to you on the internal network side
    of things, once you have gained access.
  prefs: []
  type: TYPE_NORMAL
- en: There are many malicious attacks that can take place in Route 53, so it is important
    that access to this service is highly restricted. These kinds of attacks will
    likely not be used in penetration tests, but it is good to be aware of for your
    and your client's security. The simplest attack would be to just change the IP
    addresses associated with A records, so any user who visits the domain (such as
    `test.com`), gets directed to your own attacker IP address, where you could then
    try phishing or a variety of other attacks. The same attack could work for CNAME
    records as well, by just pointing a subdomain of your target to your own attacker
    hosted web site. There are endless possibilities when you are in control of a
    website's DNS records, but be careful not to mess them up and cause a large issue
    for the AWS environment you are testing against.
  prefs: []
  type: TYPE_NORMAL
- en: Domains
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Route 53 supports registering new domains for a variety of TLDs. As an attacker,
    you could theoretically use the target AWS account to register a new domain, then
    transfer that domain to another provider for management, where you could essentially
    have a throwaway website for whatever you want. This would likely never be performed
    during a penetration test and would only be used for malicious purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Resolvers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Route 53 DNS resolvers can be used to route DNS queries between different networks
    and VPCs that are in use. As an attacker, this may provide us with insight into
    other networks that are not hosted within AWS or possibly services within VPCs,
    but generally any actual attacks against these services would be for malicious
    use only and not what we would want as a penetration tester.
  prefs: []
  type: TYPE_NORMAL
- en: Simple Email Service (SES)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: SES is a small, but useful service that allows the management of sending and
    receiving emails from domains and email accounts that you own, but as an attacker
    with access to SES, we can use this service for information gathering and social
    engineering. Depending on your compromised users' access to SES and the associated
    setup for the different verified domains/email accounts that are registered, it
    can allow for some serious phishing and social engineering against both employees
    and clients of our target company.
  prefs: []
  type: TYPE_NORMAL
- en: Phishing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''re going to assume the account we compromised has full access to SES so
    that we can go over all of the attacks, but that may need to be adjusted, depending
    on what kind of access you find yourself with in a real-life scenario. The first
    thing we will want to do is look for verified domains and/or email address. These
    may be isolated to a single region or separated between a few different regions,
    so it is important to check each region when running these API calls. We can discover
    these verified domains/email addresses for the `us-west-2` region by running the
    following AWS CLI command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will contain both domains and email addresses that have been added
    to that region, regardless of their status. A domain/email addresses status states
    whether it is verified, pending verification, failed verification, and so on,
    and a domain/email address must be verified before it can be used with the rest
    of the features that SES offers. This is to confirm that the person setting it
    up owns whatever it is that they are signing up. The output of that command should
    look something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: If an email address is set up and verified through SES, then that means it alone
    can be used for email sending/receiving, but if an entire domain gets set up and
    verified, that means any email address across any subdomain of that domain can
    be used. This means that if `test.com` is set up and verified, emails could be
    sent from `admin@test.com`, `admin@subdomain.test.com`, `test@test.com`, or any
    other variation ([https://docs.aws.amazon.com/ses/latest/DeveloperGuide/verify-domains.html](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/verify-domains.html)).
    This is what we like to see as attackers, because we can really customize our
    phishing attack with that flexibility. This information can be helpful because
    we might be able to discover emails/domains that we were not aware of before,
    making it much easier to formulate a phishing attack that looks realistic.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, once we have found a domain and/or email address that has been verified,
    we will want to make sure that email sending is enabled in that same region. We
    can check this with the following AWS CLI command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This should return `True` or `False`, depending on whether email sending is
    enabled or disabled in the `us-west-2` region. If sending is disabled, there are
    no other regions with verified domains/email accounts, and we have the `"ses:UpdateAccountSendingEnabled"`
    permission, we can use that permission to re-enable sending to allow us to perform
    our phishing attack. The following command will do just that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Be careful when running this in someone else's environment, though, because
    sending may be disabled for a very specific reason and enabling it again could
    cause unknown problems. If this command was successful, the AWS CLI won't respond
    with anything; otherwise, you will see an error that explains what the problem
    was.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will want to confirm that the domain/email address in this region
    is verified, which can be done with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We should receive a response back that indicates whether `"admin@example.com"`
    and `"test.com"` are verified. That should look like the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, `"test.com"` is still pending verification, so we cannot use
    it for sending out emails, but `admin@example.com` has been successfully verified.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, we have found an identity that has been successfully verified in a region
    with sending enabled; now we need to check the identity policy of it. We can do
    this with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'If an empty list of policy names comes back, then that means no policy has
    been applied to this identity and that means good news for us, because there are
    no restrictions on the use of this identity. If there is a policy applied, its
    name will show up in the response, which means we then need to follow up with
    a `GetIdentityPolicies` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This should return a JSON document that specifies who can do what with the
    identity we specified (`admin@example.com`). Like we have seen in the past, this
    JSON policy will be returned to us as an escaped string within another JSON object.
    That policy should look something like this (after converting it from an escaped
    string in to a real JSON object for easier viewing):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This shows us that the IAM user with the  `"arn:aws:iam::000000000000:user/ExampleAdmin"` ARN is
    the only entity that can use the `admin@example.com` email to send emails. This
    is an example of a scenario where we need to escalate our permissions by modifying
    this policy, because even if we have the `"ses:SendEmail"` permission, this policy
    is preventing us from using it (because we are assuming that we are not the `ExampleAdmin`
    IAM user).
  prefs: []
  type: TYPE_NORMAL
- en: 'To make this happen, we need to modify that policy to add our own user as a
    trusted principal. To add ourselves in, we just need to change the value of the
    Principal | AWS key to an array, where we then add our own user''s ARN in as a
    trusted principal. After we do that, the policy should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In this policy, we have granted access to the `"CompromisedUser"` IAM user,
    which we are assuming is the user we have compromised in a pentest. Another option
    would to allow access to your own AWS account, because SES identity policies support
    cross-account email sending, so you wouldn't even need credentials for the target
    account after you add the ARN of your other account ([https://aws.amazon.com/about-aws/whats-new/2015/07/amazon-ses-now-supports-cross-account-sending/](https://aws.amazon.com/about-aws/whats-new/2015/07/amazon-ses-now-supports-cross-account-sending/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can update this policy by using the SES `PutIdentityPolicy` API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The `ses-policy-document.json` file includes the JSON we previously added our
    compromised user trust to. There should be no output if the update was successful;
    otherwise, an error will explain what happened.
  prefs: []
  type: TYPE_NORMAL
- en: If that was successful, then we have essentially escalated our SES identity
    permissions by adding ourselves as a trusted entity. Now that the policy allows
    us to send emails and we have the `ses:SendEmail` permission, we are almost ready
    to get to phishing.
  prefs: []
  type: TYPE_NORMAL
- en: The one last thing that we need to think about is whether the current account
    is still in the SES sandbox. There currently isn't a great way to determine this
    from the AWS CLI without just attempting to send an email, but if you have AWS
    web console access, then you will be able to find this information out. The SES
    sandbox restricts sending emails to any email account/domain that is outside your
    list of verified email accounts/domains. Normally, you are only able to send emails
    from verified email accounts/domains in SES, but if your account is still in the
    SES sandbox, then you can only send emails from and to verified email accounts/domains.
    This means that, in our demo account, if it was still in the SES sandbox, we could
    only send emails from `admin@example.com` to `admin@example.com`. This restriction
    must be manually requested to be lifted, so if you encounter an account that is
    using SES, you are likely to find they are already out of the SES sandbox for
    their own business needs.
  prefs: []
  type: TYPE_NORMAL
- en: If you find an account that is still in the SES sandbox but has a verified domain
    identity, that means you can still send emails from any email account at that
    domain to any email account at that domain, which means you can likely still abuse
    this access for internal phishing of employees.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have AWS web console access with your compromised account, you can check
    for sandbox access by visiting the Sending Statistics page of the SES console.
    You''ll want to check each region you find a verified identity in, just in case
    one region is still in the sandbox, but another isn''t. If the account is still
    in the sandbox, you will see the message in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b7df4642-48dd-4555-9868-db947bf04b0a.png)'
  prefs: []
  type: TYPE_IMG
- en: The AWS account in this screenshot is still restricted to the sandbox in us-west-2
  prefs: []
  type: TYPE_NORMAL
- en: 'When you''re ready to start sending off your phishing emails, it is worth checking
    out any email templates that the target might have saved in their SES configuration.
    This could give you an idea on the format that this email account usually uses
    when sending emails out, as well as what type of content is usually sent out.
    You won''t always find templates saved in SES, but when you do, they can be very
    useful. We can find any existing templates with the `ListTemplates` API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we can use the `GetTemplate` API to review the content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Then, we can build our phishing email around a template that looks promising.
  prefs: []
  type: TYPE_NORMAL
- en: 'When all of that is said and done, we can finally use the SES `SendEmail` API
    to send off our phishing emails. For more information on setting up the CLI to
    send an email, refer to this guide in the SES documentation: [https://docs.aws.amazon.com/cli/latest/reference/ses/send-email.html](https://docs.aws.amazon.com/cli/latest/reference/ses/send-email.html).
    Now we have successfully sent out phishing emails from legitimate domains, using
    legitimate templates, which are near guaranteed to trick some end users/employees
    into disclosing sensitive information.'
  prefs: []
  type: TYPE_NORMAL
- en: Other attacks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even if we can't use the SES `SendEmail` API or we don't want to attract unwanted
    attention from a defender, we can still abuse SES for phishing if they are using
    email templates. We can use the SES `UpdateTemplate` API to update the text/HTML
    of an email template that is already created in SES. As an attacker, we can use
    this to basically establish backdoor phishing emails. Let's say Example Co. uses
    SES templates to send out marketing emails. We, as the attacker, can go in and
    modify that specific template, where we could insert malicious links and content.
    Then, every time `Example Co.` sends out their marketing emails, our malicious
    links and content will be included, increasing the chances of our attack working
    by a large amount.
  prefs: []
  type: TYPE_NORMAL
- en: Another attack that could be performed would be to set up a receipt rule that
    determines what happens with incoming emails to those verified emails/domains.
    By using the SES `CreateReceiptRule` API, we could set up a receipt rule that
    sends all incoming messages to our own S3 bucket in our attacker account, where
    we could then read for sensitive contents, or a variety of other options supported
    by receipt rules, such as triggering Lambda functions.
  prefs: []
  type: TYPE_NORMAL
- en: Attacking all of CloudFormation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CloudFormation is an extremely useful service that has been maturing quite a
    bit recently. It essentially lets you write code that is then translated into
    AWS resources, allowing you to easily spin up and down your resources and track
    those resources from a central location. CloudFormation seems to suffer from some
    of the same issues regular source code does, including hardcoded secrets, overly
    permissive deployments, and more, which we will cover here.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many things to look at when pentesting CloudFormation. The following
    list is what we will cover in this section:'
  prefs: []
  type: TYPE_NORMAL
- en: Stack parameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stack output values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stack termination protection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deleted stacks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stack exports
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stack templates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Passed roles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For this section, we have spun up a simple LAMP stack, based off the simple
    LAMP stack CloudFormation sample template, but with a few modifications.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we are going to want to do is use the CloudFormation `DescribeStacks` API
    to gather some information on the stacks across each region. Again, these APIs
    are per-region, so they may need to be run across each region to ensure that all
    stacks are discovered. We can do this by running the following AWS CLI command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The nice thing about this command is that it will return multiple things we
    want to look at for each stack.
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first interesting piece of information we will want to inspect is what is
    stored under `"Parameters"`. Available parameters are defined in the stacks template,
    then the values are passed in when using that template to create a new stack.
    The names and values of these parameters are stored along with the associated
    stack and show up under the `"Parameters"` key of the `DescribeStacks` API call
    response.
  prefs: []
  type: TYPE_NORMAL
- en: We are hoping to find some sensitive information being passed in to parameters,
    where we could then use it to gain further access to the environment. If best
    practices are being followed, then we ideally should not be able to find any sensitive
    information in the values of the parameters for a stack, but we have found that
    best practices aren't always followed and that certain sensitive values will sneak
    by occasionally. Best practice is to use the `NoEcho` property when defining a
    parameter in a CloudFormation template, which prevents the value passed to that
    parameter from being echoed back to anyone running the `DescribeStacks` API call.
    If `NoEcho` is used and set to `true`, then that parameter will still show up
    under `Parameters` when describing stacks, but its value will be censored with
    a few `"*"` characters.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the stack we created for this demo, the following parameters are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: There are a few different things we can take away from this information. Some
    basic information gathering lets us see that there is an SSH key named `"MySSHKey"`
    being used, SSH access is allowed from `"0.0.0.0/0"`, there is a database named
    `"CustomerDatabase"`, and there is an EC2 instance of the `"t2.small"` type. In
    addition to all of that, we see a few database passwords and a database username.
  prefs: []
  type: TYPE_NORMAL
- en: We can see that `"DBUser"` has a value of `"****"`, which likely means that
    the `DBUser` parameter had `"NoEcho"` set to `true`, so that its value would be
    censored when trying to read from it. It is also possible that the value of `DBUser`
    is actually `"****"`, but that can be confirmed easily by checking out the template
    for the stack, where we can review the constraints and properties set for the
    `DBUser` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Due to `cleartext` values being under `"DBPassword"` and `"DBRootPassword"`,
    we know that whoever designed this CloudFormation template made a few mistakes.
    They forgot to set `"NoEcho"` for those two parameters, so the `cleartext` passwords
    are returned anytime anyone describes the current stack. This is good for us attackers,
    because now we have the `cleartext` password for the regular database user and
    the root database user for a database. We can analyse the template again to find
    where this database might be or how we can access it, but we will get there in
    a little bit.
  prefs: []
  type: TYPE_NORMAL
- en: Beyond the `cleartext` passwords, we also see that `"SSHLocation"` is set to
    `"0.0.0.0/0"`, which we can assume means some server was set up to allow SSH access
    from that IP range, which means that anyone on the internet can access the SSH
    server, because `0.0.0.0/0` is a representation of all IPv4 addresses that exist.
    That is good information for us as well, because maybe we will be able to exploit
    some out-of-date SSH software on the server to gain access or something like that.
  prefs: []
  type: TYPE_NORMAL
- en: Output values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next, we will want to check out the values under `"Outputs"` when we described
    the CloudFormation stacks earlier. We are looking at something essentially the
    same as what was in `"Parameters"`, but these values are ones that were generated
    during the creation of the stack. Again, we want to look for sensitive information.
    There may not be any output values for some stacks, so there won''t be anything
    to look at for this part of the demo if that is the case you have run into. In
    our demo, this is what showed up under the `Outputs` section of our stack when
    describing it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, there isn''t anything *too* sensitive in here, but it does give
    us the public endpoint of an EC2 instance that was likely created during the creation
    of the stack. Given the `"SSHLocation"` parameter being set to `0.0.0.0/0`, we
    should likely find an open SSH port (`22`) on this server. We can use `nmap` to
    run a service scan to (`-sV`) verify this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/91e1c7a2-d9ea-45cd-b312-41f4989f5af2.png)'
  prefs: []
  type: TYPE_IMG
- en: Port 22 is found to be open and running OpenSSH version 7.4
  prefs: []
  type: TYPE_NORMAL
- en: We have verified that there is an open SSH port on that server, like we expected.
    Just by looking at the output values of this CloudFormation stack, we were able
    to identify the public endpoint of this EC2 instance, which has port `22` `open`,
    running an SSH server.
  prefs: []
  type: TYPE_NORMAL
- en: It is possible for the output values to include sensitive information, such
    as credentials or API keys. An example of this might be when a template needs
    to create a new IAM user along with a set of access keys for that user. Those
    access keys would then likely be shown in the output values of the stack, as there
    needs to be some way for a user to access them after creating the stack ([https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/quickref-iam.html#scenario-iam-accesskey](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/quickref-iam.html#scenario-iam-accesskey)).
    Those keys might be able to grant us further access to the environment in hopes
    of escalating privileges higher than we already have.
  prefs: []
  type: TYPE_NORMAL
- en: Bonus – discovering the values of NoEcho parameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Like we discussed earlier, using the `NoEcho` property on a parameter prevents
    its value from being shown when using the DescribeStacks API so that sensitive
    values aren't exposed to any user who can make that API call. Sometimes (most
    of the time), values with the `"NoEcho"` property set to `true` would be useful
    to us as attackers, because often they would be passwords or API keys. All is
    not lost, though, because with the right permissions, you can uncover the values
    that were used for those parameters to deploy CloudFormation stacks that exist
    in the account.
  prefs: []
  type: TYPE_NORMAL
- en: To do this, you are required to have the `cloudformation:UpdateStack` permission
    at the minimum. If we wanted to uncover the `NoEcho` parameter `DBUser` from our
    previously mentioned demo stack, we would first download the template for that
    stack with the `GetTemplate` API command. If we didn't have the `GetTemplate`
    permissions, we could create our own template, but that would effectively delete
    every resource that the stack created, and we did not include in our custom template,
    so we won't be covering that.
  prefs: []
  type: TYPE_NORMAL
- en: 'Save the template to `template.json` in your current directory, then just like
    the previous section, create `params.json` with the following data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This is so that we can update the template of the stack without modifying the
    values of parameters that were already passed in, including `"DBUser"`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then all that needs to be done is to remove the `"NoEcho"` property on the
    `DBUser` parameter or set it to `false`. At this point, if we try to update the
    stack, we''ll likely receive this message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This is because CloudFormation is not recognizing the removal/change of the
    `"NoEcho"` parameter for `DBUser`. The easiest thing to do would be to just change
    some string somewhere in the template. Make sure it won''t cause any problems,
    such as adding a space to a comment in some code or something like that. Make
    sure not to insert it into some configuration that would cause any problems when
    redeploying that resource. Then, we can run the same command as before to update
    the stack with this new template:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, once the stack is done updating, we should be able to DescribeStacks again
    and have access to the uncensored value that was previously input when the stack
    was created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: As we can see from this partial output from running DescribeStacks, the value
    of `"DBUser"` has been unmasked and it shows us that it is set to the value of
    `"admin"`. We did all of that and discovered that secret value without causing
    any disruption to the environment either, so that is a win-win for us.
  prefs: []
  type: TYPE_NORMAL
- en: Termination protection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Termination protection is a setting that can be enabled that blocks a CloudFormation
    stack from being deleted. To delete a stack with termination protection enabled,
    you would first need to disable it, then try to delete the stack, which requires
    a different set of permissions that you might not have. It''s generally a best
    practice to enable termination protection on CloudFormation stacks, so although
    it doesn''t directly affect us as attackers (unless we are trying to delete everything),
    it is good to check each stack for termination protection and note it as a potential
    misconfiguration in the environment. To check this value, we still use the `DescribeStacks`
    API, but it requires that we name the stacks specifically in the API call. Our
    demo stack is named `Test-Lamp-Stack`, so to determine the termination protection
    setting for that stack, we could run the following AWS CLI command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The results should be like what we have seen previously, but they will include
    the `EnableTerminationProtection` key, which is set to `true` or `false`, which
    specifies whether termination protection is enabled or not.
  prefs: []
  type: TYPE_NORMAL
- en: Deleted stacks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'CloudFormation also allows you to inspect stacks that have been deleted, but
    it is a little bit of a different process on the CLI. From the AWS web console
    CloudFormation stacks page, there is a drop-down box that allows you to show all
    deleted stacks, like what is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f3304abb-0eb9-4acf-922e-32450f27eb84.png)'
  prefs: []
  type: TYPE_IMG
- en: Listing deleted CloudFormation stacks on the AWS web console
  prefs: []
  type: TYPE_NORMAL
- en: 'From the CLI, we first need to run the CloudFormation `ListStacks` command,
    which looks like this using the AWS CLI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This command will provide similar output to the `DescribeStacks` command, but
    it is a little less verbose. The `ListStacks` command also includes deleted CloudFormation
    stacks, which can be identified by looking at the StackStatus key for a particular
    stack, where the value will be `DELETE_COMPLETE`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get more details on deleted stacks, we must then explicitly pass them into
    the `DescribeStacks` command. Unlike active stacks, deleted stacks cannot be referred
    to by their name, only their unique stack ID. A unique stack ID is just the value
    under the `"StackId"` key of the output from `ListStacks`. It will be an ARN,
    formatted similarly to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then run the `DescribeStacks` command and pass that value into the `--stack-name`
    parameter, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The output of that command should look familiar, where we can now review the
    parameter values and output values associated with that deleted stack. It is important
    to check deleted stacks for secrets for many reasons, one being that the reason
    that stack was deleted could be because a developer made a mistake that accidentally
    exposed sensitive information or something along those lines.
  prefs: []
  type: TYPE_NORMAL
- en: Exports
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'CloudFormation exports allow you to share output values between different stacks
    without having to worry about referencing those other stacks. Any value that is
    exported will also be stored under `"outputs"` of the stack that exported it,
    so if you review the output values of every active and deleted stacks, you will
    have already viewed the exports. It might be useful to look at the aggregated
    list of exports though, to see what kind of information is available to each stack.
    This might make it easier to learn more about the target environment and/or use
    cases of the CloudFormation stacks. To retrieve this data, we can use the `ListExports`
    command from the AWS CLI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The output will tell you the name and value of each export and what stack exported
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Templates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we want to look at the actual templates that were used to create the CloudFormation
    stacks that we see. We can do this with the CloudFormation `GetTemplate` command.
    This command works like the `DescribeStacks` command, where we can pass in a template
    name to the `--stack-name` parameter to retrieve the template for that specific
    stack. It also works the same in the way that, if you are looking to retrieve
    the template of a deleted stack, you need to specify the unique stack ID instead
    of the name. To get the template of our demo stack, we can run the following AWS
    CLI command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The response should include the JSON/YAML template that was used to create the
    stack we named.
  prefs: []
  type: TYPE_NORMAL
- en: Now there are a few things we can do, but manual inspection of the template
    is the most effective. Before we start manual inspection though, it might be useful
    to run a security scanner against the template itself to try and discover any
    security risks in the assets specified in it. Some of the tools created for this
    purpose are meant to be set up and used in **Continuous Integration** (**CI**)/**Continuous
    Deployment** (**CD**) environments, such as `"cfripper"` by Skyscanner ([https://github.com/Skyscanner/cfripper/](https://github.com/Skyscanner/cfripper/)).
    For this example, we'll use `"cfn_nag"` by Stelligent ([https://github.com/stelligent/cfn_nag](https://github.com/stelligent/cfn_nag)),
    which can also be run against individual files/directories containing CloudFormation
    templates. These tools generally won't catch everything, but they can be a big
    help in identifying certain insecure configurations.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use `cfn_nag` (at the time of writing, this may change as the tool updates),
    we will assume we have Ruby 2.2.x installed, so we can install the `cfn_nag` gem
    with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can save the template we retrieved from the AWS API to a file, such
    as `template.json` or `template.yaml`, depending on the type of template you have.
    For our demo, we saved it to `template.json`, so we can run the following command
    to scan the template:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a11cae28-0155-45b8-a8db-b01b880f804b.png)'
  prefs: []
  type: TYPE_IMG
- en: The results of scanning our CloudFormation template with cfn_nag
  prefs: []
  type: TYPE_NORMAL
- en: The output shows that the template we scanned output `1` failure and `2` warnings.
    All three are associated with `"WebServerSecurityGroup"` and its inbound/outbound
    rule sets. The two warnings are about overly permissive inbound rules allowed
    through that security group, but if that security group is also defining the SSH
    inbound rules, then it makes sense that those two warnings showed up. This is
    because we know that inbound access to SSH is allowed from the `0.0.0.0/0` range ,
    which is not a `/32` IP range, and that it means the world is allowed access.
    Even with that information, it is still worth checking out manually.
  prefs: []
  type: TYPE_NORMAL
- en: The failure that `cfn_nag` reported will likely be irrelevant until we find
    a way to compromise the EC2 instance behind the security group—then we will start
    caring about what outbound access rules are set up. Given that no rules are specified
    (according to `cfn_nag`), that means all outbound internet access is allowed and
    that we won't need to worry about it.
  prefs: []
  type: TYPE_NORMAL
- en: After scanning the template, it is most likely time for manual inspection. Manual
    inspection will provide us with a lot of information about the resources the template
    sets up and it is possible we could find other sensitive information stored throughout.
    After opening the template in our favorite text editor, we can browse through
    with a few things in mind. We should check out the parameters again to see whether
    there are any hardcoded sensitive default values, but also because we can possibly
    get a description of exactly what that parameter is.
  prefs: []
  type: TYPE_NORMAL
- en: Like we expected earlier, looking at the `"SSHLocation"` parameter, we can see
    that there is a description that says the IP address range that can be used to
    SSH to the EC2 instances. Our guess earlier was correct, but this is a good way
    to confirm those kinds of things. The `"Default"` key contains the `"0.0.0.0/0"` value, which
    means that the stack we have been looking at is using the default value for the `"SSHLocation"`
    parameter. Maybe we can find default passwords or IP addresses hardcoded into
    the templates in some situations.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will want to check out the resources defined in this template. In here,
    there are all kinds of possibilities of things we could encounter. One example
    of this would be startup scripts for EC2 instances that are created. We can read
    through those looking for anything sensitive, while gaining knowledge about the
    setup/architecture of the environment that this stack has deployed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The template that we used for our stack has a few setup scripts that seem to
    set up a MySQL database and a PHP web server. Ideally, we gain access to one or
    both of those, so we can scroll down to the `"WebServerSecurityGroup"` that `cfn_nag`
    flagged previously, and we see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'This tells us that the web server security group allows inbound access to port
    `80` from any IP address (`0.0.0.0/0`) and inbound access to port `22` from the
    `"SSHLocation"` parameter, which we know was also set to `0.0.0.0/0`. Now we can
    go back to the output values that we checked out earlier for this stack to get
    the hostname of the server again, where we now know port `80` is open. If we navigate
    to that URL ([http://ec2-34-221-86-204.us-west-2.compute.amazonaws.com/](http://ec2-34-221-86-204.us-west-2.compute.amazonaws.com/))
    in our browser, we are presented with the following page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3613329d-d857-41a2-bf26-7bde19fd1f85.png)'
  prefs: []
  type: TYPE_IMG
- en: The web server hosted on the EC2 instance deployed by the CloudFormation stack
  prefs: []
  type: TYPE_NORMAL
- en: Beyond what we have just done, CloudFormation templates can be inspected to
    determine the setup of the various resources that the stack deployed, which could
    help us to identify resources, misconfigurations, hardcoded secrets, and more,
    all without the requirement of having AWS permissions that grant access to those
    actual resources.
  prefs: []
  type: TYPE_NORMAL
- en: Passed roles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When a CloudFormation stack is created, there is the option to pass an IAM role
    to it for the deployment process. If a role is passed, the stack will be created
    using that role, but if a role is not passed, then CloudFormation just uses the
    current user privileges to deploy the stack. This opens the possibility of privilege
    escalation through stacks that have already been passed roles when they were created.
  prefs: []
  type: TYPE_NORMAL
- en: Let's say that a user we compromised has `"cloudformation:*"` permissions, but
    not `"iam:PassRole"`. This means that we cannot escalate our privileges by creating
    a new stack and passing it a role with higher privileges than what we have (because
    that requires the `"iam:PassRole"` permission), but it does mean that we can modify
    existing stacks.
  prefs: []
  type: TYPE_NORMAL
- en: To determine which, if any, CloudFormation stacks have had roles passed to them,
    we can go back to the output from the `DescribeStacks` command. If a stack has
    the `"RoleARN"` key with the value of an IAM role's ARN, then that stack has been
    passed a role. If that key does not show up, then that stack was not passed a
    role when it was created. The demo stack we created was passed a role.
  prefs: []
  type: TYPE_NORMAL
- en: Now, if we have the necessary IAM permissions, we could use the IAM API to figure
    out what permissions the role passed to that stack has, but if we don't, we can
    infer based off a few different things. First, the name of the role could be a
    small hint, such as if it includes `"EC2FullAccessForCloudFormation"`, it is safe
    to assume the role has full access to EC2\. The more reliable, but not necessarily
    complete, set of permissions can be assumed based on what resources the stack
    deployed. If a certain stack deployed an EC2 instance, created a security group
    for it, created an S3 bucket, and set up an RDS database, it would be safe to
    assume that the role has access to do all of those things. In our case, that's
    more access to the AWS APIs than just `"cloudformation:*"`, so we could abuse
    that stack to gain further access to the environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few ways we can check that, including just looking at the raw CloudFormation
    template we looked at earlier, or we can use the `DescribeStackResources` command
    to list out what resources were created by that stack, then make our access assumptions
    from there. This can be done by running the following command from the AWS CLI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The output from our demo stack looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: We can see here that an EC2 instance and an EC2 security group were created,
    so we can assume the role attached to this stack at least has access to do those
    two things. To then take advantage of these permissions and escalate our own privileges,
    we can use the `UpdateStack` command. This allows us to update/change the template
    associated with the stack we are targeting, allowing us to add/remove resources
    to the list. To cause less of a disturbance in the environment, we could pull
    the existing template from the stack and then just add resources to it, to cause
    as little disruption as possible. This is because existing resources that have
    not been changed will not be modified, so we won't cause a denial of service.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, the next steps depend quite a bit on the situation. If you find
    out that a stack has IAM permissions, add some IAM resources to the template that
    allow you to escalate your access, or if you find out that a stack has EC2 permissions,
    like we did here, add a bunch of EC2 instances with your own SSH key or something
    like that. If we went ahead and added some more EC2 instances to our demo stack,
    we could possibly gain access to the internal side of the VPC that they are using
    for these resources, which then could possibly grant us further, more-privileged
    access to the environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'An example command to perform this attack might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The `template.json` file would include your updated CloudFormation template
    and `params.json` would include something that instructs the stack to use all
    of the already supplied parameters, instead of new ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Now the stack will update and create your new resources, and you will have successfully
    used the passed roles' permissions to perform an API action in AWS, effectively
    escalating your own privileges.
  prefs: []
  type: TYPE_NORMAL
- en: Elastic Container Registry (ECR)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ECR is described as a fully managed Docker container registry that makes it
    easy for developers to store, manage, and deploy Docker container images ([https://aws.amazon.com/ecr/](https://aws.amazon.com/ecr/)).
    The permissions model that it uses can allow for some nasty misconfigurations
    if a repository isn't set up correctly, mainly because, by design, ECR repositories
    can be made public or shared with other accounts. This means that, even if we
    only have a small amount of access, a misconfigured repository could grant us
    large amounts of access to an environment, depending on what is stored in the
    Docker images it is hosting.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we are targeting public repositories in another account, then the main piece
    of information we need is the account ID of where the repositories are. There
    are a few ways of getting it. If you have credentials for the account you are
    targeting, the easiest way is to use the **Simple Token Service** (**STS**) `GetCallerIdentity`
    API, which will provide you with some information that includes your account ID.
    That command would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: The problem with this is that it is logged to CloudTrail and clearly shows that
    you are trying to gather information about your user/the account you're in, which
    could raise some red flags for a defender. There are other methods as well, particularly
    based around research from Rhino Security Labs, where they released a script to
    enumerate a small amount of information about the current account without ever
    touching CloudTrail. This was done through verbose error messages that certain
    services disclose, and those services aren't supported by CloudTrail yet, so there
    was no record of the API call being made, but the user gathered some information,
    including the account ID ([https://rhinosecuritylabs.com/aws/aws-iam-enumeration-2-0-bypassing-cloudtrail-logging/](https://rhinosecuritylabs.com/aws/aws-iam-enumeration-2-0-bypassing-cloudtrail-logging/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are targeting repositories in the account that you have compromised
    and are using those credentials for these API calls, then the account ID won''t
    matter, because it will default to the current account automatically in most cases.
    The first thing we will want to do is list out the repositories in the account.
    This can be done with the following command (if you are targeting a different
    account, pass the account ID in to the `--registry-id` argument):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'This should list out the repositories in the current region, including their
    ARN, registry ID, name, URL, and when they were created. Our example returned
    the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then fetch all of the images stored in that repository with the `ListImages`
    command. That will look something like this for the `example-repo` we found previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'This command will give us a list of images, including their digest and image
    tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can (hopefully) pull this image to our local machine and run it, so
    that we can see what''s inside. We can do this by running the following command
    (again, specify an external account ID in the `--registry-id` parameter if needed):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The AWS command returns the required docker command to log you into the target
    registry, and the `$()` around it will automatically execute that command and
    log you in. You should see `Login Succeeded` printed to the console after running
    it. Next, we can use Docker to pull the image, now that we are authenticated with
    the repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Now the Docker image should get pulled and should be available if you run `docker
    images` to list the Docker images:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fb01c6a4-ae68-4a3d-ab65-c791365784b7.png)'
  prefs: []
  type: TYPE_IMG
- en: Listing the example-repo Docker image after pulling it down
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will want to run this image and drop ourselves into a bash shell within
    it, so then we can explore the filesystem and look for any goodies. We can do
    this with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Now our shell should switch from the local machine to the Docker container
    as the root user:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5ff3cb4e-29ca-4692-b0fd-11a27c8c55f9.png)'
  prefs: []
  type: TYPE_IMG
- en: Using the Docker run command to enter a bash shell in the container we are launching
  prefs: []
  type: TYPE_NORMAL
- en: This is where you can employ your normal penetration testing techniques for
    searching around the operating system. You should be looking for things such as
    source code, configuration files, logs, environment files, or anything that sounds
    interesting, really.
  prefs: []
  type: TYPE_NORMAL
- en: 'If any of those commands failed due to authorization issues, we could go ahead
    and check the policy associated with the repository we are targeting. This can
    be done with the `GetRepositoryPolicy` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The response will be an error if no policy has been created for the repository;
    otherwise, it will return a JSON policy document that specifies what AWS principals
    can execute what ECR commands against the repository. You might find that only
    certain accounts or users are able to access the repository, or you might find
    that anyone can access it (such as if the `"*"` principal is allowed).
  prefs: []
  type: TYPE_NORMAL
- en: If you have the correct push permissions to ECR, another attack worth trying
    would be to implant malware in one of the existing images, then push an update
    to the repository so that anyone who then uses that image will launch it with
    your malware running. Depending on the workflow the target uses behind the scenes,
    it may take a long time to discover this kind of backdoor in their images if done
    correctly.
  prefs: []
  type: TYPE_NORMAL
- en: If you are aware of applications/services being deployed with these Docker images,
    such as through Elastic Container Service (ECS), then it might be worth looking
    for vulnerabilities within the container that you might be able to externally
    exploit, to then gain access to those servers. To help with this, it might be
    useful to do static vulnerability analysis on the various containers using tools
    such as Anchore Engine ([https://github.com/anchore/anchore-engine](https://github.com/anchore/anchore-engine)),
    Clair ([https://github.com/coreos/clair](https://github.com/coreos/clair)), or
    any others of the many available online. The results from those scans could help
    you identify known vulnerabilities that you might be able to take advantage of.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When attacking an AWS environment, it is important to come up with a definitive
    list of what AWS services they are using, as it allows you to formulate your attack
    plan better. Along with that, it is important to look at the configuration and
    setup that is deployed across all of these services to find misconfigurations
    and features to abuse and hopefully chain together to gain full access to the
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: No service is too small to look at, as there are likely attack vectors across
    every single AWS service if you have the permissions to interact with them. This
    chapter aimed to show some attacks on some less common AWS servers (compared to
    EC2, S3, and so on), and attempted to show that many services have policy documents
    that handle permissions in one way or another, such as SES identity policies or
    ECR repository policies. These services can all be abused in similar ways with
    misconfigured policies or by updating them ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will take a look CloudTrail, which is the AWS central
    API logging service. We will look at how to securely configure your trails and
    how to go about attacking them as a pentester for information gathering and to
    avoid being logged while trying to stay under the radar.
  prefs: []
  type: TYPE_NORMAL
