- en: Working with Randomness and Probability
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will discuss randomness and probability. We will start by
    briefly exploring the fundamentals of probability by selecting elements from a
    set of data. Then, we will learn how to generate (pseudo) random numbers using
    Python and NumPy, and how to generate samples according to a specific probability
    distribution. We will conclude the chapter by looking at a number of advanced
    topics covering random processes and Bayesian techniques, and using Markov chain
    Monte Carlo methods to estimate parameters on a simple model.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: Probability is a quantification of the likelihood of a specific event occurring.
    We use probabilities intuitively all of the time, although sometimes the formal
    theory can be quite counterintuitive. Probability theory aims to describe the
    behavior of *random variables*, whose value is not known, but where the probabilities
    of the value of this random variable taking some (range of) values is known. These
    probabilities are usually in the form of one of several probability distributions.
    Arguably, the most famous such probability distribution is normal distribution
    which, for example, can describe the spread of a certain characteristic over a
    large population.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: We will see probability again in a more applied setting in [Chapter6](87b0f91d-3086-41a9-995d-27fe7d364e8b.xhtml),
    *Working with Data and Statistics*, where we discuss statistics. Here, we will
    put probability theory to use to quantify errors and build a systematic theory
    of analyzing data.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Selecting items at random
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating random data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changing the random number generator
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating normally distributed random numbers
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with random processes
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyzing conversion rates with Bayesian techniques
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Estimating parameters with Monte Carlo simulations
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, we require the standard scientific Python packages, NumPy,
    Matplotlib, and SciPy. We will also require the PyMC3 package for the final recipe.
    You can install this using your favorite package manager, such as `pip`:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This command will install the most recent version of PyMC3, which, at the time
    of writing, was 3.9.2\. This package provides facilities for probabilistic programming,
    which involves performing many calculations driven by randomly generated data
    to understand the likely distribution of a solution to a problem.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: The code for this chapter can be found in the `Chapter 04` folder of the GitHub
    repository at [https://github.com/PacktPublishing/Applying-Math-with-Python/tree/master/Chapter%2004](https://github.com/PacktPublishing/Applying-Math-with-Python/tree/master/Chapter%2004).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action: [https://bit.ly/2OP3FAo](https://bit.ly/2OP3FAo).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Selecting items at random
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the core of probability and randomness is the idea of selecting an item from
    some kind of collection. As we know, the probability of selecting an item from
    a collection quantifies the likelihood of that item being selected. Randomness
    describes the selection of items from a collection according to the probabilities
    without any additional bias. The opposite of a random selection might be described
    as a *deterministic* selection. In general, it is very difficult to replicate
    a purely random process using a computer, because computers and their processing
    are inherently deterministic. However, we can generate sequences of pseudo-random
    numbers that, when properly constructed, demonstrate a reasonable approximation
    of randomness.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will select items from a collection and learn some of the
    key terminology associated with probability and randomness that we will need throughout
    this chapter.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Python Standard Library contains a module for generating (pseudo) random
    numbers called `random`, but in this recipe, and throughout this chapter, we will
    instead use the NumPy `random` module. The routines in the NumPy `random` module
    can be used to generate arrays of random numbers and are slightly more flexible
    than their standard library counterparts. As usual, we import NumPy under the
    alias `np`.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Python标准库包含一个用于生成（伪）随机数的模块称为`random`，但在这个示例中，以及本章的其他地方，我们将使用NumPy的`random`模块。NumPy的`random`模块中的例程可以用来生成随机数数组，比标准库中的例程更灵活。和往常一样，我们使用别名`np`导入NumPy。
- en: Before we can proceed, we need to fix some terminology. A *sample space* is
    a set (a collection with no repeated elements), and an *event* is a subset of
    the sample space. The *probability* that an event *A* occurs is denoted as *P*(*A*),
    and is a number between 0 and 1\. A probability of 0 indicates that the event
    can never occur, while a probability of 1 indicates that an event will certainly
    occur. The probability of the whole sample space must be 1.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，我们需要确定一些术语。*样本空间*是一个集合（一个没有重复元素的集合），*事件*是样本空间的子集。事件*A*发生的*概率*表示为*P*(*A*)，是0到1之间的数字。概率为0表示事件永远不会发生，而概率为1表示事件一定会发生。整个样本空间的概率必须为1。
- en: When the sample space is discrete, then probabilities are just numbers between
    0 and 1 associated with each of the elements, where the sum of all these numbers
    is 1\. This gives meaning to the probability of selecting a single item (an event
    consisting of a single element) from a collection. We will consider methods for
    selecting items from a discrete collection here and deal with the *continuous*
    case in the *Generating normally distributed random numbers* recipe.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当样本空间是离散的时，概率就是与每个元素相关的0到1之间的数字，所有这些数字的总和为1。这赋予了从集合中选择单个项目（由单个元素组成的事件）的概率以意义。我们将在这里考虑从离散集合中选择项目的方法，并在“生成正态分布随机数”示例中处理*连续*情况。
- en: How to do it...
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'Perform the following steps to select items at random from a container:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤从容器中随机选择项目：
- en: 'The first step is to set up the random number generator. For the moment, we
    will use the default random number generator for NumPy, which is recommended in
    most cases. We can do this by calling the `default_rng`routine from the NumPy
    `random`module, which will return an instance of a random number generator. We
    will usually call this function without a seed, but for this recipe, we will add
    the seed `12345` so that our results are repeatable:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是设置随机数生成器。目前，我们将使用NumPy的默认随机数生成器，在大多数情况下这是推荐的。我们可以通过调用NumPy的`random`模块中的`default_rng`例程来实现这一点，这将返回一个随机数生成器的实例。通常情况下，我们会不带种子地调用这个函数，但是在这个示例中，我们将添加种子`12345`，以便我们的结果是可重复的：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, we need to create the data and probabilities that we will select from.
    This step can be skipped if you already have the data stored or if you want to
    select elements with equal probabilities:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要创建数据和概率，我们将从中进行选择。如果您已经存储了数据，或者希望以相等的概率选择元素，则可以跳过此步骤：
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As a quick sanity test, we can use an assertion to check that these probabilities
    do indeed sum to 1:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个快速的健全性测试，我们可以使用断言来检查这些概率确实相加为1：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, we can use the `choice`method on the random number generator, `rng`, to
    select the samples from `data`according to the probabilities just created. For
    this selection, we want to turn the replacement on, so calling the method multiple
    times can select from the whole of `data`:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用随机数生成器`rng`上的`choice`方法，根据刚刚创建的概率从`data`中选择样本。对于这种选择，我们希望打开替换，因此调用该方法多次可以从整个`data`中选择：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To select multiple items from `data`, we can also supply the `size`argument,
    which specifies the shape of the array to be selected. This plays the same role
    as the `shape`keyword argument to many of the other NumPy array creation routines.
    The argument given to `size`can be either an integer or a tuple of integers:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要从`data`中选择多个项目，我们还可以提供`size`参数，该参数指定要选择的数组的形状。这与许多其他NumPy数组创建例程的`shape`关键字参数起着相同的作用。给定`size`的参数可以是整数或整数元组：
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: How it works...
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: The `default_rng` routine creates a new **pseudo random number generator** (**PRNG**)
    instance (with or without a seed) that can be used to generate random numbers
    or, as we saw in the recipe, select items at random from predefined data. NumPy
    also has an **implicit state**-based interface for generating random numbers using
    routines directly from the `random` module. However, it is generally advisable
    to create the generator explicitly, using `default_rng` or create a `Generator`
    instance yourself. Being more explicit in this way is more Pythonic, and should
    lead to more reproducible results (in some sense).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`default_rng`例程创建一个新的**伪随机数生成器**（**PRNG**）实例（带有或不带有种子），可以用来生成随机数，或者如我们在示例中看到的，从预定义数据中随机选择项目。NumPy还具有基于**隐式状态**的接口，可以直接使用`random`模块中的例程生成随机数。然而，通常建议显式地创建生成器，使用`default_rng`或自己创建`Generator`实例。以这种方式更加明确更符合Python的风格，并且应该会导致更可重现的结果（在某种意义上）。'
- en: A **seed** is a value that is passed to a random number generator in order to
    generate the values. The generator generates a sequence of numbers in a completely
    deterministic way based only on the seed. This means that two instances of the
    same PRNGs provided with the same seed will generate the same sequence of random
    numbers. If no seed is provided, the generators typically produce a seed that
    depends on the user's system.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**种子**是传递给随机数生成器以生成值的值。生成器以完全确定的方式基于种子生成一系列数字。这意味着给定相同种子的相同PRNG的两个实例将生成相同的随机数序列。如果没有提供种子，生成器通常会产生一个依赖于用户系统的种子。'
- en: The `Generator` class from NumPy is a wrapper around a low-level pseudo random
    bit generator, which is where the random numbers are actually generated. In recent
    versions of NumPy, the default PRNG algorithm is the 128-bit *permuted congruential
    generator.* By contrast, Python's built-in `random` module uses a Mersenne Twister
    PRNG. More information about the different options for PRNG algorithms is given
    in the *Changing the random number generator* recipe.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy的`Generator`类是低级伪随机比特生成器的包装器，这是实际生成随机数的地方。在最近的NumPy版本中，默认的PRNG算法是128位*置换同余生成器*。相比之下，Python内置的`random`模块使用Mersenne
    Twister PRNG。有关不同PRNG算法的更多信息，请参阅*更改随机数生成器*示例。
- en: The `choice` method on a `Generator` instance performs selections according
    to random numbers generated by the underlying `BitGenerator`. The optional `p`
    keyword argument specifies the probability associated with each item from the
    data provided. If this argument isn't provided, then a *uniform probability* is
    assumed, where each item has equal probability of being selected. The `replace`
    keyword argument specifies whether selections should be made with or without a
    replacement. We turned replacement on so that the same element can be selected
    more than once. The `choice` method uses the random numbers given by the generator
    to make the selections, which means that two PRNGs of the same type using the
    same seed will select the same items when using the `choice` method.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`Generator`实例上的`choice`方法根据底层`BitGenerator`生成的随机数执行选择。可选的`p`关键字参数指定与提供的数据中的每个项目相关联的概率。如果没有提供此参数，则假定*均匀概率*，其中每个项目被选择的概率相等。`replace`关键字参数指定是否应进行带或不带替换的选择。我们打开了替换，以便可以多次选择相同的元素。`choice`方法使用生成器给出的随机数进行选择，这意味着使用相同种子的相同类型的两个PRNG在使用`choice`方法时将选择相同的项目。'
- en: There's more...
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The `choice` method can also be used to create random samples of a given size
    by passing `replace=False` as an argument. This guarantees the selection of distinct
    items from the data, which is good for generating a random sample. This might
    be used, for example, to select users to test a new version of an interface from
    the whole group of users; most sample statistical techniques rely on randomly
    selected samples.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`choice`方法也可以通过将`replace=False`作为参数来创建给定大小的随机样本。这保证了从数据中选择不同的项目，这对于生成随机样本是有利的。例如，这可能用于从整个用户组中选择用户来测试界面的新版本；大多数样本统计技术依赖于随机选择的样本。'
- en: Generating random data
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成随机数据
- en: Many tasks involve generating large quantities of random numbers, which, in
    their most basic form, are either integers or floating-point numbers (double precision)
    lying in the range 0 ≤ *x* < 1\. Ideally, these numbers should be selected uniformly,
    so that if we draw a large quantity of such numbers, they should be distributed
    roughly evenly across the range 0 ≤ *x* < 1.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 许多任务涉及生成大量的随机数，这些随机数在它们最基本的形式下要么是整数，要么是浮点数（双精度），位于范围0 ≤ *x* < 1\. 理想情况下，这些数字应该是均匀选择的，这样如果我们绘制大量这样的数字，它们应该大致均匀地分布在范围0
    ≤ *x* < 1之间。
- en: In this recipe, we will see how to generate large quantities of random integers
    and floating-point numbers using NumPy, and show the distribution of these numbers
    using a histogram.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将看到如何使用NumPy生成大量的随机整数和浮点数，并使用直方图显示这些数字的分布。
- en: Getting ready
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Before we start, we need to import the `default_rng` routine from the NumPy
    `random` module and create an instance of the default random number generator
    to use in the recipe:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，我们需要从NumPy的`random`模块中导入`default_rng`例程，并创建默认随机数生成器的实例以在示例中使用：
- en: '[PRE6]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We have discussed this process in the *Selecting items at random* recipe.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在*随机选择项目*示例中讨论了这个过程。
- en: We also import the Matplotlib `pyplot` module under the alias `plt`.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将Matplotlib的`pyplot`模块导入为别名`plt`。
- en: How to do it...
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Perform the following steps to generate uniform random data and plot a histogram
    to understand its distribution:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤生成均匀随机数据并绘制直方图以了解其分布：
- en: 'To generate random floating-point numbers between 0 and 1, including 0 but
    not 1, we use the `random` method on the `rng` object:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要生成0到1之间的随机浮点数，包括0但不包括1，我们使用`rng`对象上的`random`方法：
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To generate random integers, we use the `integers` method on the `rng` object.
    This will return integers in the specified range:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要生成随机整数，我们使用`rng`对象上的`integers`方法。这将返回指定范围内的整数：
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To examine the distribution of the random floating-point numbers, we first
    need to generate a large array of random numbers, just as we did in *Step 1*.
    While this is not strictly necessary, a larger sample will be able to show the
    distribution more clearly. We generate these numbers as follows:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了检查随机浮点数的分布，我们首先需要生成一个大数组的随机数，就像我们在*步骤1*中所做的那样。虽然这并不是严格必要的，但更大的样本将能够更清楚地显示分布。我们生成这些数字如下：
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'To show the distribution of the numbers we have generated, we plot a *histogram*
    of the data:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了显示我们生成的数字的分布，我们绘制了数据的*直方图*：
- en: '[PRE10]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The resulting plot is shown in *Figure 4.1*. As we can see, the data is roughly
    evenly distributed across the whole range:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图表显示在*图4.1*中。正如我们所看到的，数据大致均匀地分布在整个范围内：
- en: '![](assets/ec4fd1ac-8e09-462c-90f1-62d20e668fa6.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ec4fd1ac-8e09-462c-90f1-62d20e668fa6.png)'
- en: 'Figure 4.1: Histogram of randomly generated random numbers between 0 and 1'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1：在0和1之间生成的随机数的直方图
- en: How it works...
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `Generator` interface provides three simple methods for generating basic
    random numbers, not including the `choice` method that we discussed in the *Selecting
    items at random* recipe. In addition to the `random` method, for generating random
    floating-point numbers, and the `integers` method, for generating random integers,
    there is also a `bytes` method for generating raw random bytes. Each of these
    methods calls a relevant method on the underlying `BitGenerator` instance. Each
    of these methods also enables the data type of the generated numbers to be changed,
    for example, from double to single precision floating-point numbers.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`Generator`接口提供了三种简单的方法来生成基本的随机数，不包括我们在*随机选择项目*示例中讨论的`choice`方法。除了`random`方法用于生成随机浮点数，`integers`方法用于生成随机整数，还有一个`bytes`方法用于生成原始的随机字节。这些方法中的每一个都调用底层`BitGenerator`实例上的相关方法。这些方法还允许生成的数字的数据类型进行更改，例如，从双精度到单精度浮点数。'
- en: There's more...
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The `integers` method on the `Generator` class combines the functionality of
    the `randint` and `random_integers` methods on the old `RandomState` interface
    through the addition of the `endpoint` optional argument. (In the old interface,
    the `randint` method excluded the upper end point, whereas the `random_integers`
    method included the upper end point.) All of the random data generating methods
    on `Generator` allow the data type of the data they generate to be customized,
    which was not possible using the old interface. (This interface was introduced
    in NumPy 1.17.)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`Generator`类上的`integers`方法通过添加`endpoint`可选参数，结合了旧的`RandomState`接口上的`randint`和`random_integers`方法的功能。（在旧接口中，`randint`方法排除了上限点，而`random_integers`方法包括了上限点。）`Generator`上的所有随机数据生成方法都允许自定义生成的数据类型，而在旧接口中是不可能的。（这个接口是在NumPy
    1.17中引入的。）'
- en: In *Figure 4.1*, we can see that the histogram of the data that we generated
    is approximately uniform over the range 0 ≤ *x* < 1\. That is, all of the bars
    are approximately level. (They are not completely level due to the random nature
    of the data.) This is what we expect from uniformly distributed random numbers,
    such as those generated by the `random` method. We will explain distributions
    of random numbers in greater detail in the *Generating normally distributed random
    numbers* recipe.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图4.1*中，我们可以看到我们生成的数据的直方图在范围0 ≤ *x* < 1上大致均匀。也就是说，所有的柱状图大致是水平的。（由于数据的随机性，它们并不完全水平。）这是我们从`random`方法生成的均匀分布的随机数所期望的。我们将在*生成正态分布随机数*的示例中更详细地解释随机数的分布。
- en: Changing the random number generator
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更改随机数生成器
- en: The `random` module in NumPy provides several alternatives to the default PRNG,
    which uses a 128-bit permutation congruential generator. While this is a good
    general-purpose random number generator, it might not be sufficient for your particular
    needs. For example, this algorithm is very different from the one used in Python’s
    internal random number generator. We will follow the guidelines for best practice
    set out in the NumPy documentation for running repeatable, but suitably random,
    simulations.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy中的`random`模块提供了几种替代默认PRNG的选择，它使用了128位置换同余生成器。虽然这是一个很好的通用随机数生成器，但对于您的特定需求可能不够。例如，这个算法与Python内部的随机数生成器使用的算法非常不同。我们将遵循NumPy文档中为运行可重复但适当随机的模拟设置的最佳实践指南。
- en: In this recipe, we will show you how to change to an alternative pseudo random
    number generator, and how to use seeds effectively in your programs.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将向您展示如何切换到另一种伪随机数生成器，并如何在程序中有效地使用种子。
- en: Getting ready
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'As usual, we import NumPy under the alias `np`. Since we will be using multiple
    items from the `random` package, we import that module from NumPy, too, using
    the following code:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，我们使用别名`np`导入NumPy。由于我们将使用`random`包中的多个项目，我们也从NumPy中导入该模块，使用以下代码：
- en: '[PRE11]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: You will need to select one of the alternative random number generators that
    are provided by NumPy (or define your own; refer to the *There's more...* section
    in this recipe). For this recipe, we will use the MT19937 random number generator,
    which uses a Mersenne Twister-based algorithm like the one used in Python's internal
    random number generator.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要选择NumPy提供的替代随机数生成器之一（或者定义自己的；请参阅本示例中的*还有更多...*部分）。在本示例中，我们将使用MT19937随机数生成器，它使用了类似于Python内部随机数生成器中使用的Mersenne
    Twister算法。
- en: How to do it...
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'The following steps show how to generate seeds and different random number
    generators in a reproducible way:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤展示了如何以可重现的方式生成种子和不同的随机数生成器：
- en: 'We will generate a `SeedSequence` object that can reproducibly generate new
    seeds from a given source of entropy. We can either provide our own entropy as
    an integer, very much like how we provide the seed to `default_rng`, or we can
    let Python gather entropy from the operating system. We will use the latter case
    here, to demonstrate its use. For this, we do not provide any additional arguments
    to create the `SeedSequence` object:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将生成一个`SeedSequence`对象，可以从给定的熵源可重现地生成新的种子。我们可以像为`default_rng`提供种子一样提供我们自己的熵，或者让Python从操作系统中收集熵。在这里，我们将使用后者，以演示其用法。为此，我们不提供任何额外的参数来创建`SeedSequence`对象：
- en: '[PRE12]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now that we have a means to generate the seeds for random number generators
    for the rest of the session, we next log the entropy so that we can reproduce
    this session later, if necessary. The following is an example of what the entropy
    should look like; your results will inevitably differ somewhat:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了一种方法来为会话的其余部分生成随机数生成器的种子，接下来我们记录熵，以便以后如果需要的话可以重现这个会话。以下是熵应该看起来的示例；您的结果必然会有些不同：
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now, we can create the underlying `BitGenerator` instance that will provide
    the random numbers for the wrapping `Generator` object:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以创建底层的`BitGenerator`实例，为包装的`Generator`对象提供随机数：
- en: '[PRE14]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Next, we create the wrapping `Generator` object around this `BitGenerator`
    instance to create a usable random number generator:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们创建包装`Generator`对象以围绕此`BitGenerator`实例创建可用的随机数生成器：
- en: '[PRE15]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: How it works...
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'As mentioned in the *Selecting items at random* recipe, the `Generator` class
    is a wrapper around an underlying `BitGenerator` that implements a given pseudo
    random number algorithm. NumPy provides several implementations of pseudo random
    number algorithms through the various subclasses of the `BitGenerator` class:
    `PCG64` (default); `MT19937` (as seen in this recipe); `Philox`; and `SFC64`.
    These bit generators are implemented in Cython.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如*随机选择项目*配方中所述，`Generator`类是围绕实现给定伪随机数算法的基础`BitGenerator`的包装器。NumPy通过`BitGenerator`类的各种子类提供了几种伪随机数算法的实现：`PCG64`（默认）；`MT19937`（在此配方中看到）；`Philox`；和`SFC64`。这些位生成器是用Cython实现的。
- en: The `PCG64` generator should provide high-performance random number generation
    with good statistical quality. (This might not be the case on 32 bit systems.)
    The `MT19937` generator is slower than more modern PRNGs and does not produce
    random numbers with good statistical properties. However, this is the random number
    generator algorithm that is used by the Python Standard Library `random` module.
    The `Philox` generator is relatively slow, but produces random numbers of very
    high quality, and the `SFC64` generator is fast and of good quality, but lacks
    some features available in other generators.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`PCG64`生成器应该提供具有良好统计质量的高性能随机数生成。 （在32位系统上可能不是这种情况。）`MT19937`生成器比更现代的PRNG慢，不会产生具有良好统计特性的随机数。然而，这是Python标准库`random`模块使用的随机数生成器算法。`Philox`生成器相对较慢，但产生非常高质量的随机数，而`SFC64`生成器速度快，质量良好，但缺少其他生成器可用的一些功能。'
- en: The `SeedSequence` object created in this recipe is a means to create seeds
    for random number generators in an independent and reproducible manner. In particular,
    this is useful if you need to create independent random number generators for
    several parallel processes, but still need to be able to reconstruct each session
    later to debug or inspect results. The entropy stored on this object is a 128-bit
    integer that was gathered from the operating system, and serves as a source of
    random seeds.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在此配方中创建的`SeedSequence`对象是以独立且可重现的方式为随机数生成器创建种子的一种方法。特别是，如果您需要为几个并行进程创建独立的随机数生成器，但仍然需要能够稍后重建每个会话以进行调试或检查结果，这将非常有用。存储在此对象上的熵是从操作系统中收集的128位整数，它作为随机种子的来源。
- en: The `SeedSequence` object allows us to create a separate random number generator
    for each process/thread that are independent of one another, which eliminates
    any data race problems that might make results unpredictable. It also generates
    seed values that are very different from one another, which can help avoid problems
    with some PRNGs (such as MT19937, which can produce very similar streams with
    two similar 32-bit integer seed values). Obviously having two independent random
    number generators producing the same or very similar values will be problematic
    when we are depending on the independence of these values.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '`SeedSequence`对象允许我们为每个独立的进程/线程创建一个独立的随机数生成器，这些生成器彼此独立，消除了可能使结果不可预测的数据竞争问题。它还生成非常不同的种子值，这可以帮助避免一些PRNG（例如MT19937，它可以使用两个相似的32位整数种子值产生非常相似的流）的问题。显然，当我们依赖这些值的独立性时，有两个独立的随机数生成器产生相同或非常相似的值将是有问题的。'
- en: There's more...
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The `BitGenerator` class serves as a common interface for generators of raw
    random integers. The classes mentioned previously are those that are implemented
    in NumPy with the `BitGenerator` interface. You can also create your own `BitGenerator`
    subclasses, although this needs to be implemented in Cython.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`BitGenerator`类充当原始随机整数生成器的通用接口。先前提到的类是NumPy中使用`BitGenerator`接口实现的类。您也可以创建自己的`BitGenerator`子类，尽管这需要在Cython中实现。'
- en: Refer to the NumPy documentation at [https://numpy.org/devdocs/reference/random/extending.html#new-bit-generators](https://numpy.org/devdocs/reference/random/extending.html#new-bit-generators)
    for more information.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 有关更多信息，请参阅NumPy文档[https://numpy.org/devdocs/reference/random/extending.html#new-bit-generators](https://numpy.org/devdocs/reference/random/extending.html#new-bit-generators)。
- en: Generating normally distributed random numbers
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成正态分布的随机数
- en: In the *Generating random data* recipe, we generated random floating-point numbers
    following a uniform distribution between 0 and 1, but not including 1\. However,
    in most cases where we require random data, we need to instead follow one of several
    different **distributions**. Roughly speaking, a **distribution function** is
    a function *f*(*x*) that describes the probability that a random variable has
    a value that is below *x*. In practical terms, the distribution describes the
    spread of the random data over a range. In particular, if we create a histogram
    of data that follows a particular distribution, then it should roughly resemble
    the graph of the distribution function. This is best seen by example.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在*生成随机数据*配方中，我们生成了在0和1之间遵循均匀分布的随机浮点数，但不包括1。然而，在大多数需要随机数据的情况下，我们需要遵循几种不同的**分布**之一。粗略地说，**分布函数**是一个描述随机变量具有低于*x*值的概率的函数*f*(*x*)。在实际情况下，分布描述了随机数据在范围内的分布。特别是，如果我们创建遵循特定分布的数据的直方图，那么它应该大致类似于分布函数的图形。这最好通过示例来看。
- en: One of the most common distributions is **normal distribution**, which appears
    frequently in statistics and forms the basis for many statistical methods that
    we will see in [Chapter 6](87b0f91d-3086-41a9-995d-27fe7d364e8b.xhtml), *Working
    with Data and Statistics*. In this recipe, we will demonstrate how to generate
    data following the normal distribution, and plot a histogram of this data to see
    the shape of the distribution.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As in the *Generating random data* recipe, we import the `default_rng` routine
    from the NumPy `random` module and create a `Generator` instance with a seeded
    generator for demonstration purposes:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: As usual, we have the Matplotlib `pyplot` module imported as `plt`, and NumPy
    imported as `np`.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the following steps, we generate random data that follows a normal distribution:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the `normal` method on our `Generator` instance to generate the random
    data according to the `normal` distribution. The normal distribution has two *parameters*,
    *location* and *scale.* There is also an optional `size` argument that specifies
    the shape of the generated data. (See the *Generating random data* recipe for
    more information on the `size` argument.) We generate an array of 10,000 values
    to get a reasonably sized sample:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Next, we plot a histogram of this data. We have increased the number of `bins`
    in the histogram. This isn''t strictly necessary as the default number (10) is
    perfectly adequate, but it does show the distribution slightly better:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Next, we create a function that will generate the expected density for a range
    of values. This is given by multiplying the probability density function for normal
    distribution by the number of samples (10,000):'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Finally, we plot our expected distribution over the histogram of our data:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The result is shown in *Figure 4.2*. We can see here that the distribution
    of our sampled data closely follows the expected distribution from the normal
    distribution curve:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/9499ac0a-e1ba-40bd-a8a1-039e42ed3d24.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.2: Histogram of data drawn from a normal distribution centered at
    5 with a scale of 3, with the expected density overlaid'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Normal distribution has a probability density function defined by the following
    formula:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/6198a9a0-658b-480f-a42a-abcb58c27969.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
- en: 'This is related to the normal distribution function *F*(*x*) according to the
    following formula:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/c351a1d8-481f-48c8-a1ba-6f8c1c5128ab.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
- en: This probability density function peaks at the mean value, which coincides with
    the location parameter, and the width of the "bell shape" is determined by the
    scale parameter. We can see in *Figure 4.2* that the histogram of the data generated
    by the `normal` method on the `Generator` object fits the expected distribution
    very closely.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: The `Generator` class uses a 256-step Ziggurat method to generate normally distributed
    random data, which is fast compared to the Box-Muller or inverse CDF implementations
    that are also available in NumPy.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The normal distribution is one example of a *continuous* probability distribution,
    in that it is defined for real numbers and the distribution function is defined
    by an integral (rather than a sum). An interesting feature of normal distribution
    (and other continuous probability distributions) is that the probability of selecting
    any given real number is 0\. This is reasonable, because it only makes sense to
    measure the probability that a value selected in this distribution lies within
    a given range. (It shouldn't make sense that the probability of selecting a specific
    value should be not zero.)
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: The normal distribution is important in statistics, mostly due to the *central
    limit theorem.* Roughly speaking, this theorem states that sums of **independent
    and identically distributed** (**IID**) random variables, with a common mean and
    variance, are eventually like normal distribution with the common mean and variance.
    This holds, regardless of the actual distribution of these random variables. This
    allows us to use statistical tests based on normal distribution in many cases
    even if the actual distribution of the variables is not necessarily normal. (We
    do, however, need to be extremely cautious when appealing to the central limit
    theorem.)
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many other continuous probability distributions aside from normal
    distribution. We have already encountered *uniform* distribution over the range
    0 to 1\. More generally, uniform distribution over the range *a* *≤ x**≤ b* has
    a probability density function given by the following equation:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/b90f2536-cab6-4685-947a-581c0281f2d4.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
- en: Other common examples of continuous probability density functions include *exponential*
    distribution, *beta* distribution, and *gamma* distribution*.* Each of these distributions
    has a corresponding method on the `Generator` class that generates random data
    from that distribution. These are typically named according to the name of the
    distribution, all in lowercase letters. So, for the aforementioned distributions,
    the corresponding methods are `exponential`, `beta`, and `gamma`. These distributions
    each have one or more *parameters*, like location and scale for normal distribution,
    that determine the final shape of the distribution. You may need to consult the
    NumPy documentation ([https://numpy.org/doc/1.18/reference/random/generator.html#numpy.random.Generator](https://numpy.org/doc/1.18/reference/random/generator.html#numpy.random.Generator))
    or other sources to see what parameters are required for each distribution. The
    NumPy documentation also lists the probability distributions from which random
    data can be generated.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Working with random processes
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Random processes exist everywhere. Roughly speaking, a random process is a system
    of related random variables, usually indexed with respect to time *t ≥ 0*, for
    a continuous random process, or by natural numbers *n = 1, 2, …*, for a discrete
    random process. Many (discrete) random processes satisfy the **Markov property**,
    which makes them a **Markov chain***.* The Markov property is the statement that
    the process is *memoryless*, in that only the current value is important for the
    probabilities of the next value.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: 'In this recipe, we will examine a simple example of a random process that models
    the number of bus arrivals at a stop over time. This process is called a **Poisson
    process**. A Poisson process *N*(*t*) has a single parameter, *λ*, which is usually
    called the *intensity* or *rate*, and the probability that *N*(*t*) takes the
    value *n* at a given time *t* is given by the following formula:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/106772d7-94ec-4fa7-b32a-d60d705df5cc.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
- en: This equation describes the probability that *n* buses have arrived by time
    *t*. Mathematically, this equation means that *N*(*t*) has a Poisson distribution
    with the parameter *λt*. There is, however, an easy way to construct a Poisson
    process by taking sums of inter-arrival times that follow an exponential distribution.
    For instance, let *X[i]* be the time between the (*i-1*)-st*arrival and the *i*-th
    arrival, which are exponentially distributed with parameter *λ*. Now, we take
    the following equation:*
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '*![](assets/8c051194-080f-40e5-82a4-cad043e6dcd6.png)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Here, the number *N(t)* is the maximum *n* such that *T_n <= t*. This is the
    construction that we will work through in this recipe. We will also estimate the
    intensity of the process by taking the mean of the inter-arrival times.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we start, we import the `default_rng` routine from NumPy''s `random`
    module and create a new random number generator with a seed for the purpose of
    demonstration:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In addition to the random number generator, we also import NumPy as `np` and
    the Matplotlib `pyplot` module as `plt`. We also need to have the SciPy package
    available.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps show how to model the arrival of buses using a Poisson
    process:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: 'Our first task is to create the sample inter-arrival times by sampling data
    from an exponential distribution. The `exponential` method on the NumPy `Generator`
    class requires a `scale` parameter, which is *1/λ*, where *λ* is the rate. We
    choose a rate of 4, and create 50 sample inter-arrival times:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Next, we compute the actual arrival times by using the `accumulate` method
    of the NumPy `add` universal function. We also create an array containing the
    integers 0 to 49, representing the number of arrivals at each point:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Next, we plot the arrivals over time using the `step` plotting method:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The result is shown in *Figure 4.3*, where the length of each horizontal line
    represents the inter-arrival times:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/1ff070ea-f4f3-49fd-b260-be6acd827068.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.3: Arrivals over time, where inter-arrival times are exponentially
    distributed, which makes the number of arrivals at a time a Poisson process'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we define a function that will evaluate the probability distribution
    of the counts at a time, which we will take as `1` here. This uses the formula
    for the Poisson distribution that we gave in the introduction to this recipe:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now, we plot the probability distribution over the count per unit of time,
    since we chose `time=1` in the previous step. We will add to this plot later:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, we move on to estimate the rate from our sample data. We do this by computing
    the mean of the inter-arrival times, which, for exponential distribution, is an
    estimator of the scale *1/λ*:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Finally, we plot the probability distribution with this estimated rate for the
    counts per unit of time. We plot this on top of the true probability distribution
    that we produced in *Step 5:*
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The resulting plot is given in *Figure 4.4*, where we can see that, apart from
    a small discrepancy, the estimated distribution is very close to the true distribution:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/59f7bc51-399f-4b12-93d9-6193c357c47d.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.4: Poisson distribution of the number of arrivals per time unit, the
    true distribution, and the distribution estimated from the sampled data'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A Poisson process is a counting process that counts the number of events (bus
    arrivals) that occur in an amount of time if the events are randomly spaced (in
    time) with an exponential distribution with a fixed parameter. We constructed
    the Poisson process by sampling inter-arrival times from exponential distribution,
    following the construction we described in the introduction. However, it turns
    out that this fact (that the inter-arrival times are exponentially distributed)
    is a property of all Poisson processes when they are given their formal definition
    in terms of probabilities.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we sampled 50 points from an exponential distribution with a
    given `rate` parameter. We had to do a small conversion because the NumPy `Generator`
    method for sampling from an exponential distribution uses a related `scale` parameter,
    which is `1` over the `rate`. Once we have these points, we create an array that
    contains cumulative sums of these exponentially distributed numbers. This creates
    our arrival times. The actual Poisson process is that displayed in *Figure 4.3*,
    and is a combination of the arrival times with the corresponding number of events
    that had occurred at that time.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: The mean (expected value) of an exponential distribution coincides with the
    scale parameter, so the mean of a sample drawn from an exponential distribution
    is one way to estimate the scale (rate) parameter. This estimate will not be perfect,
    since our sample is relatively small. This is why there is a small discrepancy
    between the two plots in *Figure 4.4*.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are many types of random processes describing a wide variety of real-world
    scenarios. In this recipe, we modeled arrival times using a Poisson process. A
    Poisson process is a continuous random process, meaning that it is parameterized
    by a continuous variable, *t* ≥ 0, rather than a discrete variable, *n*=1,2,….
    Poisson processes are actually Markov chains, under a suitably generalized definition
    of a Markov chain, and also an example of a *renewal process*. A renewal process
    is a process that describes the number of events that occur within a period of
    time. The Poisson process described here is an example of a renewal process.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: 'Many Markov chains also satisfy some properties in addition to their defining
    Markov property. For example, a Markov chain is *homogeneous* if the following
    equality holds for all *n*, *i*, and *j* values:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/2d2f34e4-b2c4-4759-8708-732d78597133.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
- en: In simple terms, this means that the probabilities of moving from one state
    to another over a single step does not change as we increase the number of steps.
    This is extremely useful for examining the long-term behavior of a Markov chain.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: It is very easy to construct simple examples of homogeneous Markov chains. Suppose
    that we have two states, *A* and *B*. At any given step, we could be either at
    state *A* or at state *B.* We move between states according to a probability.
    For instance, let's say that the probability of transitioning from state *A*to
    state *A* is 0.4, and that theprobability of transitioning from *A*to *B*is 0.6.*Similarly,
    let's say that the probability of transitioning from *B* to *B*is 0.2, and transitioning
    from *B*to *A* is 0.8\. Notice that both the probability of switching plus the
    probability of staying the same sum to 1 in both cases. We can represent the probability
    of transitioning from each state in matrix form given, in this case, by the following
    equation:*
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '*![](assets/7b1faeb6-1ed9-4eac-98c4-98e68a4d9bac.png)'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: 'This matrix is called the *transition matrix*. The idea here is that the probability
    of being in a particular state after a step is given by multiplying the vector
    containing the probability of being in state *A* and *B* (position 0 and 1, respectively).
    For example, if we start in state *A* then the probability vector will contain
    a 1 at index 0 and 0 at index 1\. Then, the probability of being in state *A*
    after 1 step is given by 0.4, and the probability of being in state *B* is 0.6\.
    This is what we expect, given the probabilities we outlined previously. However,
    we could also write this calculation using the matrix formula:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/0c516c06-936a-46cc-a55c-ea87ff1cdfa9.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
- en: 'To get the probability of being in either state after two steps, we multiply
    the right-hand side vector again by the transition matrix, *T*, to obtain the
    following:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ee656e40-e42a-4549-91ee-498b80325245.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
- en: We can continue this process *ad infinitum* to obtain a sequence of state vectors,
    which constitute our Markov chain. This construction can be applied, with more
    states if necessary, to model many simple, real-world problems.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing conversion rates with Bayesian techniques
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bayesian probability allows us to systematically update our understanding (in
    a probabilistic sense) of a situation by considering data. In more technical language,
    we update the *prior* distribution (our current understanding) using data to obtain
    a *posterior* distribution. This is particularly useful, for example, when examining
    the proportion of users who go on to buy a product after viewing a website. We
    start with our prior belief distribution. For this we will use the *beta* distribution,
    which models the probability of success given numbers of successes (completed
    purchases) against failures (no purchases). For this recipe, we will assume that
    our prior belief is that we expect 25 successes from 100 views (75 fails). This
    means that our prior belief follows a beta (25, 75) distribution. Let's say that
    we wish to calculate the probability that the true rate of success is at least
    33%.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Our method is roughly divided into three steps. We first need to understand
    our prior belief for the conversion rate, which we have decided follows a beta
    (25, 75) distribution. We compute the probability that the conversion rate is
    at least 33% by integrating (numerically) the probability density function for
    the prior distribution from 0.33 to 1\. The next step is to apply the Bayesian
    reasoning to update our prior belief with new information. Then, we can perform
    the same integration with the posterior belief to examine the probability that
    the conversion rate is at least 33% given this new information.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will see how to use Bayesian techniques to update a prior
    belief based on new information for our hypothetical website.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As usual, we will need the NumPy and Matplotlib packages imported as `np` and
    `plt`, respectively. We will also require the SciPy package, imported as `sp`.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps show how to estimate and update conversion rate estimations
    using Bayesian reasoning:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to set up the prior distribution. For this we use the `beta`
    distribution object from the SciPy `stats` module, which has various methods for
    working with the beta distribution. We import the `beta` distribution from the
    `stats` module under the alias `beta_dist` and then create a convenience function
    for the probability density function:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Next, we need to compute the probability, under the prior belief distribution,
    that the success rate is at least 33%. To do this, we use the `quad` routine from
    the SciPy `integrate` module, which performs numerical integration of a function.
    We use this to integrate the probability density function for the beta distribution,
    imported in *Step 1*, with our prior parameters. We print the probability according
    to our prior distribution to the console:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now, suppose we have received some information about successes and failures
    over a new period of time. For example, we observed 122 successes and 257 failures
    over this period. We create new variables to reflect these values:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'To obtain the parameter values for the posterior distribution with a beta distribution,
    we simply add the observed successes and failures to the `prior_alpha` and `prior_beta`
    parameters, respectively:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now, we repeat our numerical integration to compute the probability that the
    success rate is now above 33% using the posterior distribution (with our new parameters
    computed earlier). Again, we print this probability in the terminal:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We can see here that the new probability, given the updated posterior distribution,
    is 13% as opposed to the prior 3%. This is a significant difference, although
    we are still not confident that the conversion rate is above 33% given these values.
    Now, we plot the prior and posterior distribution to visualize this increase in
    probability. To start with, we create an array of values and evaluate our probability
    density function based on these values:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Finally, we plot the two probability density functions computed in *Step 6*
    onto a new plot:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The resulting plot is shown in *Figure 4.5*, where we can see that the posterior
    distribution is much more narrow and centered to the right of the prior:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/6f4a1bb6-f47b-4b3a-b93e-73c8dd97dfe9.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.5: Prior and posterior distributions of a success rate following a
    beta distribution'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Bayesian techniques work by taking a prior belief (probability distribution)
    and using *Bayes' theorem* to combine the prior belief with the likelihood of
    our data given this prior belief to form a posterior belief. This is actually
    similar to how we might understand things in real life. For example, when you
    wake up on a given day, you might have the belief (from a forecast or otherwise)
    that there is a 40% chance of rain outside. Upon opening the blinds, you see that
    it is very cloudy outside, which might indicate that rain is more likely, so we
    update our belief according to this new data, to say a 70% chance of rain.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand how this works, we need to understand *conditional probability*.
    Conditional probability deals with the probability that one event will occur *given
    that* another event has already occurred. In symbols, the probability of event
    *A* given that event *B* has occurred is written as follows:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/5a3c0d70-ca6f-414e-bb4f-e1f05232bd59.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
- en: 'Bayes'' theorem is a powerful tool that can be written (symbolically) as follows:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/66cca2d1-4176-43e5-aa37-302a06dd800f.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
- en: 'The probability *P*(*A*) represents our prior belief. The event *B* represents
    the data that we have gathered, so that *P*(*B* | *A*) is the likelihood that
    our data arose given our prior belief. The probability *P*(*B*) represents the
    probability that our data arose, and *P*(*A* | *B*) represents our posterior belief
    given the data. In practice, the probability *P*(*B*) can be difficult to calculate
    or otherwise estimate, so it is quite common to replace the strong equality above
    with a proportional version of Bayes'' theorem:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ebdc2354-2595-40dc-b038-949ee0ca5fe0.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
- en: 'In the recipe, we assumed that our prior was beta distributed. The beta distribution
    has a probability density function given by the following equation:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/a78a4ebb-bebe-49fe-89cb-908ef5f74e07.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
- en: 'Here, *Γ*(*α*) is the gamma function. The likelihood is binomially distributed,
    which has a probability density function given by the following equation:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/8535466c-882c-4283-a838-58a01e26e23c.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
- en: Here, *k* is the number of observations, and *j* is one of those that was successful.
    In the recipe, we observed *m = 122* successes and *n* = 257 failures, which gives
    *k = m + n = 379* and *j = m = 122*. To calculate the posterior distribution,
    we can use the fact that the beta distribution is a conjugate prior for the binomial
    distribution to see that the right-hand side of the proportional form of Bayes'
    theorem is beta distributed with parameters *α + m**and *β +* *n**.**This is what
    we used in the recipe. The fact that the beta distribution is a conjugate prior
    for binomial random variables makes them useful in Bayesian statistics.**
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '**The method we demonstrated in this recipe is a rather basic example of using
    a Bayesian method, but it is still useful for updating our prior beliefs given
    new data in a systematic way.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Bayesian methods can be used for a wide variety of tasks, making it a powerful
    tool. In this recipe, we used a Bayesian approach to model the success rate of
    a website based on our prior belief of how it performs and additional data gathered
    from users. This is a rather complex example since we modeled our prior belief
    on a beta distribution. Here is another example of using Bayes' theorem to examine
    two competing hypotheses using only simple probabilities (numbers between 0 and
    1).
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose you place your keys in the same place every day when you return home,
    but one morning you wake up to find that they are not in this place. After searching
    for a short time, you cannot find them and so conclude that they must have vanished
    from existence. Let''s call this hypothesis *H[1]*. Now, *H[1]* certainly explains
    the data, *D*, that you cannot find your keys, hence the likelihood *P*(*D* |
    *H[1]*) = 1\. (If your keys vanished from existence, then you could not possibly
    find them.) An alternative hypothesis is that you simply placed them somewhere
    else when you got home the night before. Let''s call this hypothesis *H[2]*. Now
    this hypothesis also explains the data, so *P*(*D* | *H[2]*) = 1, but in reality,
    *H[2]* is far more plausible than *H[1]*. Let''s say that the probability that
    your keys completely vanished from existence is 1 in 1 million – this is a huge
    overestimation, but we need to keep the numbers reasonable – while you estimate
    that the probability that you placed them elsewhere the night before is 1 in 100\.
    Computing the posterior probabilities, we have the following:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/2fd79ac1-310f-49a9-b24b-a1c5643b1e75.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
- en: This highlights the reality that it is 10,000 times more likely that you simply
    misplaced your keys as opposed to the fact that they simply vanished. Sure enough,
    you soon find your keys already in your pocket, because you had picked them up
    earlier that morning.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: Estimating parameters with Monte Carlo simulations
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Monte Carlo methods broadly describe techniques that use random sampling to
    solve problems. These techniques are especially powerful when the underlying problem
    involves some kind of uncertainty. The general method involves performing large
    numbers of simulations, each sampling different inputs according to a given probability
    distribution, and then aggregating the results to give a better approximation
    of the true solution than any individual sample solution.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '**Markov Chain Monte Carlo** (**MCMC**) is a specific kind of Monte Carlo simulation
    in which we construct a Markov chain of successively better approximations of
    the true distribution that we seek. This works by accepting or rejecting a proposed
    state, sampled at random, based on carefully selected *acceptance probabilities*
    at each stage, with the aim of constructing a Markov chain whose unique stationary
    distribution is precisely the unknown distribution that we wish to find.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will use the PyMC3 package and MCMC methods to estimate the
    parameters of a simple model. The package will deal with most of the technical
    details of running simulations, so we don't need to go any further into the details
    of how the different MCMC algorithms actually work.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As usual, we import the NumPy package and Matplotlib `pyplot` module as `np`
    and `plt`, respectively. We also import and create a default random number generator,
    with a seed for the purpose of demonstration, as follows:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We will also need a module from the SciPy package for this recipe as well as
    the PyMC3 package, which is a package for probabilistic programming.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following steps to use Markov chain Monte Carlo simulations to
    estimate the parameters of a simple model using sample data:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: 'Our first task is to create a function that represents the underlying structure
    that we wish to identify. In this case, we will be estimating the coefficients
    of a quadratic (a polynomial of degree 2). This function takes two arguments,
    which are the points in the range, which is fixed, and the variable parameters
    that we wish to estimate:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Next, we set up the `true` parameters and a `size` parameter that will determine
    how many points are in the sample that we generate:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We generate the sample that we will use to estimate the parameters. This will
    consist of the underlying data, generated by the `underlying` function we defined
    in *Step 1*, plus some random noise that follows a normal distribution. We first
    generate a range of *x* values, which will stay constant throughout the recipe,
    and then use the `underlying` function and the `normal` method on our random number
    generator to generate the sample data:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'It is a good idea to plot the sample data, with the underlying data overlaid,
    before we begin the analysis. We use the `scatter` plotting method to plot only
    the data points (without connecting lines), and then plot the underlying quadratic
    structure using a dashed line:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The result is *Figure 4.6*, where we can see that the shape of the underlying
    model is still visible even with the noise, although the exact parameters of this
    model are no longer obvious:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/c8c9b89d-be0d-4861-b5ce-7bb06bef685d.png)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.6: Sampled data with the underlying model overlaid'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: 'We are ready to start our analysis, so we now import the PyMC3 package under
    the alias `pm` as follows:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The basic object of PyMC3 programming is the `Model` class, which is usually
    created using the context manager interface. We also create our prior distributions
    for the parameters. In this case, we will assume that our prior parameters are
    normally distributed with a mean of 1 and a standard deviation of 1\. We need
    3 parameters, so we provide the `shape` argument. The `Normal` class creates random
    variables that will be used in the Monte Carlo simulations:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We create a model for the underlying data, which can be done by passing the
    random variable, `param`, that we created in *Step 6* into the `underlying` function
    that we defined in *Step 1*. We also create a variable that handles our observations.
    For this we use the `Normal` class, since we know that our noise is normally distributed
    around the underlying data, `y`. We set a standard deviation of `2`, and pass
    our observed `sample` data into the `observed` keyword argument (this is also
    inside the `Model` context):'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'To run the simulations, we need only call the `sample` routine inside the `Model`
    context. We pass the `cores` argument to speed up the calculations, but leave
    all of the other arguments at the default values:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: These simulations should take a short time to execute.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we plot the posterior distributions that use the `plot_posterior` routine
    from PyMC3\. This routine takes the `trace` result from the sampling step that
    performed the simulations. We create our own figure and axes using the `plt.subplots`
    routine in advance, but this isn''t strictly necessary. We are using three subplots
    on a single figure, and we pass the `axs2`tuple of `Axes` to the plotting routing
    under the `ax` keyword argument:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The resulting plot is shown in *Figure 4.7*, where you can see that each of
    these distributions is approximately normal, with a mean that is similar to the
    true parameter values:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/f1707e92-3bf1-4e86-8ba7-42786c9002b8.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.7: Posterior distributions of estimated parameters'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: 'Now retrieve the mean of each of the estimated parameters from the trace by
    using the `mean` method on the `params` item from the trace, which is simply a
    NumPy array. We pass the `axis=0` argument because we want the mean of each of
    the rows of the matrix of parameter estimates. We print these estimated parameters
    in the terminal:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Finally, we use our estimated parameters to generate our estimated underlying
    data by passing the *x* values and the estimated parameters to the `underlying`
    function defined in *Step 1*. We then plot this estimated underlying data together
    with the true underlying data on the same axes:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The resulting plot is in *Figure 4.8*, where there is only a small difference
    between these two models on this range:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/e6a65709-18f5-4568-8c9f-42cb68ac02c1.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.8: True model and estimated model plotted on the same axes. There
    is a small discrepancy between the estimated parameters and the true parameters'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  id: totrans-263
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The interesting part of the code in this recipe can be found in the `Model`
    context manager. This object keeps track of the random variables, orchestrates
    the simulations, and keeps track of the state. The context manager gives us a
    convenient way to separate the probabilistic variables from the surrounding code.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: We start by proposing a prior distribution for the distribution of the random
    variables representing our parameters, of which there are three. We proposed a
    normal distribution since we know that the parameters cannot stray too far from
    the value 1\. (We can tell this by looking at the plot that we generated in *Step
    4*, for example.) Using a normal distribution will give a higher probability to
    the values that are close to the current values. Next, we add the details relating
    to the observed data, which is used to calculate the acceptance probabilities
    that are used to either accept or reject a state. Finally, we start the sampler
    using the `sample` routine. This constructs the Markov chain and generates all
    of the step data.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: The `sample` routine sets up the sampler based on the types of variables that
    will be simulated. Since the normal distribution is a continuous variable, the
    `sample` routine selected the **No U-turn sampler** (**NUTS**). This is a reasonable
    general-purpose sampler for continuous variables. A common alternative to NUTS
    is the Metropolis sampler, which is less reliable but faster than NUTS in some
    cases. The PyMC3 documentation recommends using NUTS whenever possible.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: Once the sampling is complete, we plotted the posterior distribution of the
    trace (the states given by the Markov chain) to see the final shape of the approximations
    we generated. We can see here that all three of our random variables (parameters)
    are normally distributed around approximately the correct value.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: Under the hood, PyMC3 uses Theano to speed up its calculations. This makes it
    possible for PyMC3 to perform computations on a **Graphics Processing Unit** (**GPU**)
    rather than on the **Central Processing Unit** (**CPU**) for a considerable boost
    to computation speed. Theano also supports the dynamic generation of C code to
    improve computation speeds further.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Monte Carlo method is very flexible, and the example we gave here is one
    particular case where it can be used. A more typical basic example of where the
    Monte Carlo method is applied is in estimating the value of integrals, commonly,
    Monte Carlo integration. A really interesting case of Monte Carlo integration
    is estimating the value of π ≈ 3.1415\. Let's briefly look at how this works.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: First, we take the unit disk, whose radius is 1 and therefore has an area, π.
    We can enclose this disk inside a square with vertices at the points (1, 1), (-1,
    1), (1, -1), and (-1, -1). This square has an area 4, since the edge length is
    2\. Now we can generate random points uniformly over this square. When we do this,
    the probability that any one of these random points lies inside a given region
    is proportional to the area of that region. Thus, the area of a region can be
    estimated by multiplying the proportion of randomly generated points that lie
    within the region by the total area of the square. In particular, we can estimate
    the area of the disk by simply multiplying the number of randomly generate points
    that lie within the disk by 4, and dividing by the total number of points we generated.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: 'We can easily write a function in Python that performs this calculation, which
    might be the following:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Running this function just once will give a reasonable approximation of π:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We can improve the accuracy of our estimation by using more points, but we
    could also run this a number of times and average the results. Let''s run this
    simulation 100 times and average the results (we''ll use concurrent futures to
    parallelize this so that we can run larger numbers of samples if we want):'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Running this code once prints the estimated value of π as 3.1415752, which is
    an even better estimate of the true value.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: See also
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The PyMC3 package has many features that are documented by numerous examples
    ([https://docs.pymc.io/](https://docs.pymc.io/)). There is also another probabilistic
    programming library based on TensorFlow ([https://www.tensorflow.org/probability](https://www.tensorflow.org/probability)).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A good, comprehensive reference for probability and random processes is the
    following book:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '*Grimmett, G. and Stirzaker, D. (2009). Probability and random processes*.
    3rd ed. Oxford: Oxford Univ. Press*.*'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An easy introduction to Bayes'' theorem and Bayesian statistics is the following:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '*Kurt, W. (2019).Bayesian statistics the fun way*. San Francisco, CA: No Starch
    Press, Inc*.*****'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
