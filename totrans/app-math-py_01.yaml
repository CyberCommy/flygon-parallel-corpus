- en: Basic Packages, Functions, and Concepts
  prefs: []
  type: TYPE_NORMAL
- en: Before getting started on any practical recipes, we'll use this opening chapter
    to introduce several core mathematical concepts and structures and their Python
    representations. In particular, we'll look at basic numerical types, basic mathematical
    functions (trigonometric functions, the exponential function, and logarithms),
    and matrices. Matrices are fundamental in most computational applications because
    of the connection between matrices and solutions of systems of linear equations.
    We'll explore some of these applications in this chapter, but matrices will play
    an important role throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll cover the following main topics in this order:'
  prefs: []
  type: TYPE_NORMAL
- en: Python numerical types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basic mathematical functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NumPy arrays
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, and throughout this book, we will use Python version 3.8,
    which is the most recent version of Python at the time of writing. Most of the
    code in this book will work on recent versions of Python from 3.6\. We will use
    features that were introduced in Python 3.6 at various points, including f-strings.
    This means that you may need to change `python3.8`, which appears in any terminal
    commands to match your version of Python. This might be another version of Python,
    such as `python3.6` or `python3.7`, or a more general command such as `python3`
    or `python`. For the latter commands, you need to check that the version of Python
    is at least 3.6 by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Python has built-in numerical types and basic mathematical functions that suffice
    for small applications that involve only small calculations. The NumPy package
    provides a high performance array type and associated routines (including basic
    mathematical functions that operate efficiently on arrays). This package will
    be used in many of the recipes in this chapter and the remainder of this book.
    We will also make use of the SciPy package in the latter recipes of this chapter.
    Both can be installed using your preferred package manager, such as `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'By convention, we import these package under a shorter alias. We import `numpy`
    as `np` and `scipy` as `sp` using the following `import` statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: These conventions are used in the official documentation for these packages,
    along with many tutorials and other materials that use these packages.
  prefs: []
  type: TYPE_NORMAL
- en: The code for this chapter can be found in the `Chapter 01` folder of the GitHub
    repository at [https://github.com/PacktPublishing/Applying-Math-with-Python/tree/master/Chapter%2001](https://github.com/PacktPublishing/Applying-Math-with-Python/tree/master/Chapter%2001).
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action: [https://bit.ly/3g3eBXv](https://bit.ly/3g3eBXv).'
  prefs: []
  type: TYPE_NORMAL
- en: Python numerical types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python provides basic numerical types such as arbitrarily sized integers and
    floating-point numbers (double precision) as standard, but it also provides several
    additional types that are useful in specific applications where precision is especially
    important. Python also provides (built-in) support for complex numbers, which
    are useful for some more advanced mathematical applications.
  prefs: []
  type: TYPE_NORMAL
- en: Decimal type
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For applications that require decimal digits with accurate arithmetic operations,
    use the`Decimal` type from the`decimal` module in the Python Standard Library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Performing this calculation with float objects gives the result 2.6630000000000003,
    which includes a small error arising from the fact that certain numbers cannot
    be represented exactly using a finite sum of powers of 2\. For example, 0.1 has
    a binary expansion 0.000110011..., which does not terminate. Any floating-point
    representation of this number will therefore carry a small error. Note that the
    argument to `Decimal` is given as a string rather than a float.
  prefs: []
  type: TYPE_NORMAL
- en: The `Decimal` type is based on the IBM General Decimal Arithmetic Specification
    ([http://speleotrove.com/decimal/decarith.html](http://speleotrove.com/decimal/decarith.html)),
    which is an alternative specification for floating-point arithmetic that represents
    decimal numbers exactly by using powers of 10 rather than powers of 2\. This means
    that it can be safely used for calculations in finance where the accumulation
    of rounding errors would have dire consequences. However, the `Decimal` format
    is less memory efficient, since it must store decimal digits rather than binary
    digits (bits), and are more computationally expensive than traditional floating-point
    numbers.
  prefs: []
  type: TYPE_NORMAL
- en: 'The`decimal` package also provides a`Context` object, which allows fine-grained
    control over the precision, display, and attributes of`Decimal` objects. The current
    (default) context can be accessed using the`getcontext` function from the `decimal`
    module. The`Context` object returned by`getcontext` has a number of attributes
    that can be modified. For example, we can set the precision for arithmetic operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: When we set the precision to `4`, rather than the default `28`, we see that
    the fourth power of 1.1 is rounded to 4 significant figures.
  prefs: []
  type: TYPE_NORMAL
- en: 'The context can even be set locally by using the`localcontext`function, which
    returns a context manager that restores the original environment at the end of
    the `with` block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This means that the context can be freely modified inside the `with` block,
    and will be returned to the default at the end.
  prefs: []
  type: TYPE_NORMAL
- en: Fraction type
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Alternatively, for working with applications that require accurate representations
    of integer fractions, such as when working with proportions or probabilities,
    there is the `Fraction` type from the `fractions` module in the Python Standard
    Library. The usage is similar, except that we typically give the numerator and
    denominator of the fraction as arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The `Fraction` type simply stores two integers, the numerator and the denominator,
    and arithmetic is performed using the basic rules for the addition and multiplication
    of fractions.
  prefs: []
  type: TYPE_NORMAL
- en: Complex type
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Python also has support for complex numbers, including a literal character
    to denote the complex unit `1j` in code. This might be different from the idiom
    for representing the complex unit that you are familiar with from other sources
    on complex numbers. Most mathematical texts will often use the symbol *i* to represent
    the complex unit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Special "complex number" - aware mathematical functions are provided in the
    `cmath` module of the Python Standard Library.
  prefs: []
  type: TYPE_NORMAL
- en: Basic mathematical functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Basic mathematical functions appear in many applications. For example, logarithms
    can be used to scale data that grows exponentially to give linear data. The exponential
    function and trigonometric functions are common fixtures when working with geometric
    information, the *gamma function* appears in combinatorics, and the *Gaussian
    error function* is important in statistics*.*
  prefs: []
  type: TYPE_NORMAL
- en: 'The `math` module in the Python Standard Library provides all of the standard
    mathematical functions, along with common constants and some utility functions,
    and it can be imported using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Once it''s imported, we can use any of the mathematical functions that are
    contained in this module. For instance, to find the square root of a non-negative
    number, we would use the `sqrt` function from `math`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Attempting to use the `sqrt` function with a negative argument will raise a
    ValueError. The square root of a negative number is not defined for this `sqrt`
    function, which deals only with *real numbers*. The square root of a negative
    number—this will be a complex number—can be found using the alternative `sqrt`
    function from the `cmath` module in the Python Standard Library.
  prefs: []
  type: TYPE_NORMAL
- en: 'The trigonometric functions, sine, cosine, and tangent, are available under
    their common abbreviations `sin`, `cos`, and `tan`, respectively, in the `math`
    module. The`pi` constant holds the value of π, which is approximately 3.1416:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The inverse trigonometric functions are named `acos`, `asin`, and `atan` in
    the `math` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The `log` function in the `math` module performs logarithms. It has an optional
    argument to specify the base of the logarithm (note that the second argument is
    positional only). By default, without the optional argument, it is the *natural
    logarithm* with base *e*. The *e*constant can be accessed using `math.e`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The `math` module also contains the function `gamma`, which is the gamma function,
    and the function `erf`, the Gaussian error function, which is important in statistics.
    Both of these functions are defined by integrals. The gamma function is defined
    by the integral
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/cce1e648-6fc9-4ba8-8bda-370d76d95bc6.png)'
  prefs: []
  type: TYPE_IMG
- en: and the error function is defined by
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/a942862a-1ef4-40bd-8a6c-1bd93716ea47.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The integral in the definition of the error function cannot be evaluated using
    calculus, and instead must be computed numerically:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to standard functions such as trigonometric functions, logarithms,
    and exponential functions, the `math` module contains various number of theoretic
    and combinatorial functions. These include the functions `comb` and `factorial`,
    which are useful in a variety of applications. The `comb` function called with
    arguments *n* and *k* returns the number of ways to choose *k* items from a collection
    of *n* without repeats if order is not important. For example, picking 1 then
    2 is the same as picking 2 then 1\. This number is sometimes written *^nC[k]*.
    The factorial called with argument *n* returns the factorial *n! = n(n-1)(n-2)*…1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Applying the factorial to a negative number raises a `ValueError`. The factorial
    of an integer *n,* coincides with the value of the gamma function at *n + 1*;
    that is,
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/07b31532-3dc5-4e0e-bda5-374fc8eb499e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `math` module also contains a function that returns the *greatest common
    divisor* of its arguments called `gcd`. The greatest common divisor of *a* and
    *b* is the largest integer *k* such that *k* divides both *a* and *b* exactly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'There are also a number of functions for working with floating-point numbers.
    The `fsum` function performs addition on an iterable of numbers and keeps track
    of the sums each step to reduce the error in the result. This is nicely illustrated
    by the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The `isclose`functionreturns`True` if the difference between the arguments is
    smaller than the tolerance. This is especially useful in unit tests, where there
    may be small variations in results based on machine architecture or data variability.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the `floor` and `ceil`functionsfrom`math` provide the floor and ceiling
    of their argument. The*floor* of a number *x*is the largest integer*f* with*f
    ≤ x*, and the*ceiling* of*x* is the smallest integer*c* with*x ≤ c*. These functions
    are useful when converting between a float obtained by dividing one number by
    another and an integer.
  prefs: []
  type: TYPE_NORMAL
- en: The `math` module contains functions that are implemented in C (assuming you
    are running CPython), and so are much faster than those implemented in Python.
    This module is a good choice if you need to apply a function to a relatively small
    collection of numbers. If you want to apply these functions to a large collection
    of data simultaneously, it is better to use their equivalents from the NumPy package,
    which are more efficient for working with arrays.​ In general, if you have imported
    the NumPy package already, then it is probably best to always use NumPy equivalents
    of these functions to limit the chance of error.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy arrays
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: NumPy provides high performance array types and routines for manipulating these
    arrays in Python. These arrays are useful for processing large datasets where
    performance is crucial. NumPy forms the base for the numerical and scientific
    computing stack in Python. Under the hood, NumPy makes use of low-level libraries
    for working with vectors and matrices, such as the **Basic Linear Algebra Subprograms**
    (**BLAS**) package, and the **Linear Algebra Package** (**LAPACK**)contains more
    advanced routines for linear algebra.
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditionally, the NumPy package is imported under the shorter alias `np`,
    which can be accomplished using the following `import` statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In particular, this convention is used in the NumPy documentation and in the
    wider scientific Python ecosystem (SciPy, Pandas, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic type provided by the NumPy library is the `ndarray` type (henceforth
    referred to as a NumPy array). Generally, you won''t create your own instances
    of this type, and will instead use one of the helper routines such as `array`
    to set up the type correctly. The `array` routine creates NumPy arrays from an
    array-like object, which is typically a list of numbers or a list of lists (of
    numbers). For example, we can create a simple array by providing a list with the
    required elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The NumPy array type (`ndarray`) is a Python wrapper around an underlying C
    array structure. The array operations are implemented in C and optimized for performance.
    NumPy arrays must consist of homogeneous data (all elements have the same type),
    although this type could be a pointer to an arbitrary Python object. NumPy will
    infer an appropriate data type during creation if one is not explicitly provided
    using the`dtype` keyword argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Under the hood, a NumPy array of any shape is a buffer containing the raw data
    as a flat (one-dimensional) array, and a collection of additional metadata that
    specifies details such as the type of the elements.
  prefs: []
  type: TYPE_NORMAL
- en: 'After creation, the data type can be accessed using the`dtype` attribute of
    the array. Modifying the`dtype` attribute will have undesirable consequences since
    the raw bytes that constitute the data in the array will simply be reinterpreted
    as the new data type. For example, if we create an array using Python integers,
    NumPy will convert those to 64-bit integers in the array. Changing the `dtype`
    value will cause NumPy to reinterpret these 64-bit integers to the new data type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Each 64-bit integer has been re-interpreted as two 32-bit, floating-point numbers,
    which clearly gives nonsense values. Instead, if you wish to change the data type
    after creation, use the`astype` method to specify the new type. The correct way
    to change the data type is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: NumPy also provides a number of routines for creating various standard arrays.
    The`zeros` routine creates an array, of the specified shape, in which every element
    is `0`, and the`ones` routine creates an array in which every element is `1`.
  prefs: []
  type: TYPE_NORMAL
- en: Element access
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'NumPy arrays support the `getitem` protocol, so elements in an array can be
    accessed as if it were a list and support all of the arithmetic operations, which
    are performed component-wise. This means we can use the index notation and the
    index to retrieve the element from the specified index as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This also includes the usual slice syntax for extracting an array of data from
    an existing array. A slice of an array is again an array, containing the elements
    specified by the slice. For example, we can retrieve an array containing the first
    two elements of `ary`, or an array containing the elements at even indexes, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The syntax for a slice is `start:stop:step`. We can omit either, or both, of
    `start` and `stop` to take from the beginning or the end, respectively, of all
    elements. We can also omit the `step` parameter, in which case we also drop the
    trailing `:`. The `step` parameter describes the elements from the chosen range
    that should be selected. A value of `1` selects every element or, as in the recipe,
    a value of `2` selects every second element (starting from `0` gives even-numbered
    elements). This syntax is the same as for slicing Python lists.
  prefs: []
  type: TYPE_NORMAL
- en: Array arithmetic and functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: NumPy provides a number of *universal functions* (ufunc), which are routines
    that can operate efficiently on NumPy array types. In particular, all of the basic
    mathematical functions discussed in the *Basic mathematical functions* section
    have analogues in NumPy that can operate on NumPy arrays. Universal functions
    can also perform *broadcasting*, to allow them to operate on arrays of different—but
    compatible—shapes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The arithmetic operations on NumPy arrays are performed component-wise. This
    is best illustrated by the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the arrays must be the same shape, which means have the same length.
    Using an arithmetic operation on arrays of different shapes will result in a `ValueError`.
    Adding, subtracting, multiplying, or dividing by a number will result in array
    where the operation has been applied to each component. For example, we can multiply
    all elements in an array by `2` by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Useful array creation routines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To generate arrays of numbers at regular intervals between two given end points,
    you can use either the`arange` routine or the`linspace` routine. The difference
    between these two routines is that`linspace` generates a number (the default is
    50) of values with equal spacing between the two end points, including both endpoints,
    while`arange` generates numbers at a given step size up to, but not including,
    the upper limit. The `linspace` routine generates values in the closed interval
    *a ≤ x ≤ b* and the `arange` routine generates values in the half-open interval
    *a≤ x < b*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Note that the array generated using `linspace` has exactly 5 points, specified
    by the third argument, including the two end points, `0` and `1`. The array generated
    by `arange` has 4 points, and does not include the right end point, `1`; an additional
    step of 0.3 would equal 1.2, which is larger than 1.
  prefs: []
  type: TYPE_NORMAL
- en: Higher dimensional arrays
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'NumPy can create arrays with any number of dimensions, which are created using
    the same `array` routine as simple one-dimensional arrays. The number of dimensions
    of an array is specified by the number of nested lists provided to the `array`
    routine. For example, we can create a two-dimensional array by providing a list
    of lists, where each member of the inner list is a number, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: NumPy arrays have a `shape`*attribute, which describes the arrangement of the
    elements in each dimension. For a two-dimensional array, the shape can be interpreted
    as the number of rows and the number of columns of the array.*
  prefs: []
  type: TYPE_NORMAL
- en: '*NumPy stores the shape as the `shape` attribute on the array object, which
    is a tuple. The number of elements in this tuple is the number of dimensions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the data in a NumPy array is stored in a flat (one-dimensional) array,
    an array can be reshaped with little cost by simply changing the associated metadata.
    This is done using the`reshape` method on a NumPy array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Note that the total number of elements must remain unchanged. The matrix`mat`
    originally has shape`(2, 2)` with a total of 4 elements, and the latter is a one-dimensional
    array with shape`(4,)`, which again has a total of 4 elements. Attempting to reshape
    when there is a mismatch in the total number of elements will result in a`ValueError`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create an array of higher dimensions, simply add more levels of nested lists.
    To make this clearer, in the following example, we separate out the lists for
    each element in the third dimension before we construct the array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Note that the first element of the shape is the outermost, and the last element
    is the innermost.
  prefs: []
  type: TYPE_NORMAL
- en: This means that adding an additional dimension to an array is a simple matter
    of providing the relevant metadata. Using the `array` routine, the `shape` metadata
    is described by the length of each list in the argument. The length of the outermost
    list defines the corresponding `shape` parameter for that dimension, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: The size in memory of a NumPy array does not significantly depend on the number
    of dimensions, but only on the total number of elements, which is the product
    of the `shape` parameters. However, note that th e total number of elements tends
    to be larger in higher dimensional arrays.
  prefs: []
  type: TYPE_NORMAL
- en: 'To access an element in a multi-dimensional array, you use the usual index
    notation, but rather than providing a single number, you need to provide the index
    in each dimension. For a 2 × 2 matrix, this means specifying the row and column
    for the desired element:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The index notation also supports slicing in each dimension, so we can extract
    all members of a single column by using the slice `mat[:, 0]` like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Note that the result of the slice is a one-dimensional array.
  prefs: []
  type: TYPE_NORMAL
- en: The array creation functions, `zeros` and `ones`, can create multi-dimensional
    arrays by simply specifying a shape with more than one dimension parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Matrices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: NumPy arrays also serve as *matrices*, which are fundamental in mathematics
    and computational programming. A *matrix* is simply a two-dimensional array. Matrices
    are central in many applications, such as geometric transformations and simultaneous
    equations, but also appear as useful tools in other areas such a statistics. Matrices
    themselves are only distinctive (compared to any other array) once we equip them
    with *matrix arithmetic*. Matrices have element-wise addition and subtraction
    operations, just as for NumPy arrays, a third operation called *scalar multiplication*,
    where we multiply every element of the matrix by a constant number, and a different
    notion of *matrix multiplication*. Matrix multiplication is fundamentally different
    from other notions of multiplication, as we will see later.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most important attributes of a matrix is its shape, defined exactly
    as for NumPy arrays. A matrix with *m* rows and *n* columns is usuallydescribed
    as an *m × n* matrix. A matrix that has the same number of rows as columns is
    said to be a *square* matrix, and these matrices play a special role in the theory
    of vectors and matrices.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *identity matrix* (of size*n*) is the*n ×**n* matrix where the (*i*,*i*)-th
    entry is 1, and the (*i*, *j*)-th entry is zero for*i* ≠ *j*. There is an array
    creation routine that gives an*n × n* identity matrix for a specified*n* value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Basic methods and properties
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are a large number of terms and quantities associated with matrices. We
    only mention two such properties here, since they will be useful later. These
    are the *transpose* of a matrix, where rows and columns are interchanged, and
    the *trace* of a square matrix, which is the sum of the elements along the *leading
    diagonal*. The leading diagonal consists of the elements *a[ii]* along the line
    from the top left of the matrix to the bottom right.
  prefs: []
  type: TYPE_NORMAL
- en: 'NumPy arrays can be easily transposed by calling the `transpose`method on the
    `array` object. In fact, since this is such a common operation, arrays have a
    convenience property`T` that returns the transpose of the matrix. The transposition
    reverses the order of the shape of a matrix (array), so that rows become columns
    and columns become rows. For example, if we start with a 3 × 2 matrix (3 rows,
    2 columns), then its transpose will be a 2 × 3 matrix, such as in the following
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Another quantity associated with matrices that is occasionally useful is the
    *trace*. Thetrace of a square matrix*A*, with entries as in the preceding code,
    is defined to be the sum of the elements along the*leading diagonal, which consists
    of the elements starting from the top left diagonally to the bottom right. The
    formula for the trace is given as*
  prefs: []
  type: TYPE_NORMAL
- en: '*![](assets/e8eaa631-c006-4401-853f-b474da2c9319.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'NumPy arrays have a `trace` method that returns the trace of a matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The trace can also be accessed using the `np.trace` function, which is not bound
    to the array.
  prefs: []
  type: TYPE_NORMAL
- en: Matrix multiplication
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Matrix multiplication is an operation performed on two matrices, which preserves
    some of the structure and character of both matrices. Formally, if *A* is an *l
    × m* matrix, and *B* is an *m × n* matrix, say
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/76bace88-ee7c-41ba-b7a5-d20ce18c1cca.png)'
  prefs: []
  type: TYPE_IMG
- en: then the matrix product *C* of *A* and *B* is an *l × n* matrix whose (*p*,
    *q*)-th entry is given by
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/9b077bba-836c-4376-acf6-177457bb7e62.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Note that the number of columns of the first matrix **must** match the number
    of rows of the second matrix in order for matrix multiplication to be defined.
    We usually write *AB* for the matrix product of *A* and *B,* if it is defined.
    Matrix multiplication is a peculiar operation. It is not *commutative* like most
    other arithmetic operations: even if *AB* and *BA* can both be computed, there
    is no need for them to be equal. In practice, this means that the order of multiplication
    matters for matrices. This arises from the origins of matrix algebras as representations
    of linear maps, where multiplication corresponds to the composition of functions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Python has an operator reserved for matrix multiplication`@`, which was added
    in Python 3.5\. NumPy arrays implement the operator to perform matrix multiplication.
    Note that this is fundamentally different from the component-wise multiplication
    of arrays`*`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The identity matrix is a *neutral element* under matrix multiplication. That
    is, if *A* is any *l × m* matrix, and *I* is the *m* × *m* identity matrix, then
    *AI = A*. This can be easily checked for specific examples using NumPy arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Determinants and inverses
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *determinant* of a square matrix is important in most applications because
    of its strong link with finding the inverse of a matrix. A matrix is *square*
    if the number of rows and columns are equal. In particular, a matrix that has
    a non-zero determinant has a (unique) inverse, which translates to unique solutions
    of certain systems of equations. The determinant of a matrix is defined recursively.
    For a 2 × 2 matrix
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/33bf7b70-0248-45b7-8576-937cb4ef8186.png)'
  prefs: []
  type: TYPE_IMG
- en: the *determinant* of *A* is defined by the formula
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/16497d22-d726-4c2e-877a-ddc3f766124c.png)'
  prefs: []
  type: TYPE_IMG
- en: For a general *n* × *n* matrix
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/b9423b8e-3454-4283-bdba-97469ed68558.png)'
  prefs: []
  type: TYPE_IMG
- en: where *n* > 2, we define the submatrix *A[i,j]* for 1 ≤ *i*, *j*≤*n*, to be
    the result of deleting the *i*th row and *j*th column from *A*. The submatrix
    *A[i,j]* is an *(n-1) ×* (*n*-1) matrix, and so we can compute the determinant.
    We then define the determinant of *A* to be the quantity
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/6d24b037-4dcf-4bb0-9da9-ed1338f1e34b.png)'
  prefs: []
  type: TYPE_IMG
- en: In fact, the index 1 that appears in the preceding equation can be replaced
    by any 1 ≤ i≤ *n* and the result will be the same.
  prefs: []
  type: TYPE_NORMAL
- en: 'The NumPy routine for computing the determinant of a matrix is contained in
    a separate module called `linalg`. This module contains many common routines for
    *linear algebra*, which is the branch of mathematics that covers vector and matrix
    algebra. The routine for computing the determinant of a square matrix is the `det`
    routine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Note that a floating-point rounding error has occurred in the calculation of
    the determinant.
  prefs: []
  type: TYPE_NORMAL
- en: The SciPy package, if installed, also offers a`linalg` module that extends NumPy's`linalg`.
    The SciPy version not only includes additional routines, but it is also always
    compiled with BLAS and LAPACK support, while for the NumPy version, this is optional.
    Thus, the SciPy variant may be preferable, depending on how NumPy was compiled,
    if speed is important.
  prefs: []
  type: TYPE_NORMAL
- en: The*inverse* of an*n ×**n* matrix*A* is the (necessarily unique) *n ×**n*matrix*B*,
    such that*AB*=*BA*=*I*, where*I*denotes the *n ×**n* identity matrix and the multiplication
    performed here is matrix multiplication. Not every square matrix has an inverse;
    those that do not are sometimes called*singular* matrices. In fact, a matrix is
    non-singular (that is, has an inverse) if, and only if, the determinant of that
    matrix is not 0\. When*A* has an inverse, it is customary to denote it by*A^(-1)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `inv` routine from the `linalg` module computes the inverse of a matrix,
    if it exists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'We can check that the matrix given by the `inv` routine is indeed the matrix
    inverse of `A` by matrix multiplying (on either side) by the inverse and checking
    that we get the 2 × 2 identity matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: There will be a floating-point error in these computations, which has been hidden
    away behind the `Approximately` comment, due to the way that matrix inverses are
    computed.
  prefs: []
  type: TYPE_NORMAL
- en: The `linalg` package also contains a number of other methods such as `norm`,
    which computes various norms of a matrix. It also contains functions for decomposing
    matrices in various ways and solving systems of equations.
  prefs: []
  type: TYPE_NORMAL
- en: There are also the matrix analogues of the exponential function `expm`, the
    logarithm `logm`, sine `sinm`, cosine `cosm`, and tangent `tanm`. Note that these
    functions are not the same as the standard `exp`, `log`, `sin`, `cos`, and `tan`
    functions in the base NumPy package, which apply the corresponding function on
    an element by element basis. In contrast, the matrix exponential function is defined
    using a "power series" of matrices
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/3ca5b8f2-59d4-40cd-b789-e6a3561dde62.png)'
  prefs: []
  type: TYPE_IMG
- en: where *A* is an *n × n* matrix and *A^k* is the *k*th *matrix power* of *A*;
    that is, the *A* matrix multiplied by itself *k* times. Note that this "power
    series" always converges in an appropriate sense. By convention, we take *A⁰*
    = *I*, where *I* is the *n × n* identity matrix. This is completely analogous
    to the usual power series definition of the exponential function for real or complex
    numbers, but with matrices and matrix multiplication in place of numbers and (regular)
    multiplication. The other functions are defined in a similar fashion, but we will
    skip the details.
  prefs: []
  type: TYPE_NORMAL
- en: Systems of equations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Solving systems of (linear) equations is one of the main motivations for studying
    matrices in mathematics. Problems of this type occur frequently in a variety of
    applications. We start with a system of linear equations written as
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/4ebf6e1d-e0bd-4f8c-a95f-58b5dd15d391.png)'
  prefs: []
  type: TYPE_IMG
- en: where *n* is at least two, *a[i,j]*[and *b[i]* are known values, and the *x[i]*
    values are the unknown values that we wish to find.]
  prefs: []
  type: TYPE_NORMAL
- en: Before we can solve such a system of equations, we need to convert the problem
    into a matrix equation. This is achieved by collecting together the coefficients
    *a[i,j]* into an *n × n* matrix and using the properties of matrix multiplication
    to relate this matrix to the system of equations. So, let
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/0bf397b7-5253-4e69-a7f5-d6b81502427a.png)'
  prefs: []
  type: TYPE_IMG
- en: be the matrix containing the coefficients taken from the equations. Then, if
    we take **x** to be the unknown (column) vector containing the *x[i]* values and
    **b** to be the (column) vector containing the known values *b[i]*, then we can
    rewrite the system of equations as the single matrix equation
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/08d03070-dc5f-4c12-999d-3e555762c0ae.png)'
  prefs: []
  type: TYPE_IMG
- en: 'which we can now solve using matrix techniques. In this situation, we view
    a column vector as an *n × 1* matrix, so the multiplication in the preceding equation
    is matrix multiplication. To solve this matrix equation, we use the `solve` routine
    in the `linalg` module. To illustrate the technique, we will solve the following
    system of equations as an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/47b1fa6c-38f1-4b2d-9a9a-9b78774dcc02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'These equations have three unknown values, *x[1]*, *x[2]*, and *x[3]*. First,
    we create the matrix of coefficients and the vector **b**. Since we are using
    NumPy as our means of working with matrices and vectors, we create a two-dimensional
    NumPy array for the matrix *A* and a one-dimensional array for **b**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the solution to the system of equations can be found using the `solve`
    routine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: This is indeed the solution to the system of equations, which can be easily
    verified by computing `A @ x` and checking the result against the `b`array. There
    may be a floating-point rounding error in this computation.
  prefs: []
  type: TYPE_NORMAL
- en: The `solve` function expects two inputs, which are the matrix of coefficients
    *A* and the right-hand side vector **b**. It solves the system of equations using
    LAPACK routines that decompose matrix *A* into simpler matrices to quickly reduce
    to an easier problem that can be solved by simple substitution. This technique
    for solving matrix equations is extremely powerful and efficient, and is less
    prone to the floating-point rounding errors that dog some other methods. For instance,
    the solution to a system of equations could be computed by multiplying (on the
    left) by the inverse of the matrix *A*, if the inverse is known. However, this
    is generally not as good as using the `solve` routine since it may be slower or
    result in larger numerical errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the example we used, the coefficient matrix *A* was square. That is, there
    are the same number of equations as there are unknown values. In this case, the
    system of equations has a unique solution if (and only if) the determinant of
    this matrix *A* is not 0\. In cases where the determinant of *A* is 0, one of
    two things can happen: the system can have no solution, in which case we say that
    the system is *inconsistent*; or there can be infinitely many solutions. The difference
    between a consistent and inconsistent system is usually determined by the vector
    **b**. For example, consider the following systems of equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/01c4d5b9-99a5-4ca5-a7e4-b3deb5cc1190.png)'
  prefs: []
  type: TYPE_IMG
- en: The left-hand system of equations is consistent and has infinitely many solutions;
    for instance, taking *x* = 1 and *y = 1* or *x = 0* and *y = 2* are both solutions.
    The right-hand system of equations is inconsistent, and there are no solutions.
    In both of the above, the `solve` routine will fail because the coefficient matrix
    is singular.
  prefs: []
  type: TYPE_NORMAL
- en: The coefficient matrix does not need to be square for the system to be solvable.
    For example, if there are more equations than there are unknown values (a coefficient
    matrix has more rows than columns). Such a system is said to be *over-specified*
    and, provided that it is consistent, it will have a solution. If there are fewer
    equations than there are unknown values, then the system is said to be *under-specified.*
    Under-specified systems of equations generally have infinitely many solutions
    if they are consistent, since there is not enough information to uniquely specify
    all the unknown values. Unfortunately, the `solve` routine will not be able to
    find solutions for systems where the coefficient matrix is not square, even if
    the system does have a solution.
  prefs: []
  type: TYPE_NORMAL
- en: Eigenvalues and eigenvectors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Consider the matrix equation *A***x** = λ**x**, where *A* is a square (*n ×
    n*) matrix, **x** is a vector, and λ is a number. Numbers λ for which there is
    an **x** that solves this equation are called *eigenvalues*, and the corresponding
    vectors **x** are called *eigenvectors.* Pairs of eigenvalues and corresponding
    eigenvectors encode information about the matrix *A*, and are therefore important
    in many applications where matrices appear.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will demonstrate computing eigenvalues and eigenvectors using the following
    matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/192ad11a-26cd-4dd1-a9d6-21df5cb79e7e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We must first define this as a NumPy array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The `eig` routine in the `linalg` module is used to find the eigenvalues and
    eigenvectors of a square matrix. This routine returns a pair `(v, B)` where `v`
    is a one-dimensional array containing the eigenvalues and `B` is a two-dimensional
    array whose columns are the corresponding eigenvectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: It is perfectly possible for a matrix with only real entries to have complex
    eigenvalues and eigenvectors. For this reason, the return type of the `eig` routine
    will sometimes be a complex number type such as `complex32` or `complex64`. In
    some applications, complex eigenvalues have a special meaning, while in others
    we only consider the real eigenvalues.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can extract an eigenvalue/eigenvector pair from the output of `eig` using
    the following sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The eigenvectors returned by the `eig` routine are *normalized* so that they
    have norm (length) 1\. (The *Euclidean norm* is defined to be the square root
    of the sum of the squares of the members of the array.) We can check that this
    is the case by evaluating in the norm of the vector using the `norm` routine from
    `linalg`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can check that these values do indeed satisfy the definition of
    an eigenvalue/eigenvector pair by computing the product `A @ x0` and checking
    that, up to floating-point precision, this is equal to `lambda0*x0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: The norm computed here represents the "distance" between the left-hand side
    `lhs` and the right-hand side `rhs` of the equation *A***x** = λ**x**. Since this
    distance is extremely small (0 to 14 decimal places), we can be fairly confident
    that they are actually the same. The fact that this is not zero is likely due
    to floating-point precision error.
  prefs: []
  type: TYPE_NORMAL
- en: The `eig` routine is a wrapper around the low-level LAPACK routines for computing
    eigenvalues and eigenvectors. The theoretical procedure for finding eigenvalues
    and eigenvectors is to first find the eigenvalues by solving the equation
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/29520bb2-fc2e-42af-bbb9-e3236ea9936a.png)'
  prefs: []
  type: TYPE_IMG
- en: where *I* is the appropriate identity matrix, to find the values λ. The equation
    determined by the left-hand side is a polynomial in λ and is called the *characteristic
    polynomial* of *A*. The corresponding eigenvectors can then be found by solving
    the matrix equation
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/a8e09b6c-ef9b-406f-980b-cfacf87b2969.png)'
  prefs: []
  type: TYPE_IMG
- en: where λ*[j]*is one of the eigenvalues already found. In practice, this process
    is somewhat inefficient, and there are alternative strategies for computing eigenvalues
    and eigenvectors numerically more efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: One key application of eigenvalues and eigenvectors is in *principal component
    analysis*, which is a key technique for reducing a large, complex dataset to better
    understand the internal structure.
  prefs: []
  type: TYPE_NORMAL
- en: We can only compute eigenvalues and eigenvectors for square matrices; for non-square
    matrices, the definition does not make sense. There is a generalization of eigenvalues
    and eigenvalues to non-square matrices called *singular values*.
  prefs: []
  type: TYPE_NORMAL
- en: Sparse matrices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Systems of linear equations such as those discussed earlier are extremely common
    throughout mathematics and, in particular, in mathematical computing. In many
    applications, the coefficient matrix will be extremely large, with thousands of
    rows and columns, and will likely be obtained from an alternative source rather
    than simply entering by hand. In many cases, it will also be a *sparse* matrix,
    where most of the entries are 0.
  prefs: []
  type: TYPE_NORMAL
- en: A matrix is *sparse* if a large number of the elements are zero. The exact number
    of elements that need to be zero in order to call a matrix sparse is not well
    defined. Sparse matrices can be represented more efficiently, for example, by
    simply storing the indexes (*i*, *j*) and the values *a[i,j]* that are non-zero.
    There are entire collections of algorithms for sparse matrices that offer great
    improvements in performance, assuming the matrix is indeed sufficiently sparse.
  prefs: []
  type: TYPE_NORMAL
- en: Sparse matrices appear in many applications, and often follow some kind of pattern.
    In particular, several techniques for solving **partial differential equations**
    (**PDEs**) involve solving sparse matrix equations (see [Chapter 3](1a62e7c6-06f5-4ee3-8f63-5bb14f6db553.xhtml),
    *Calculus and Differential Equations)*, and matrices associated with networks
    are often sparse. There are additional routines for sparse matrices associated
    with networks (graphs) contained in the `sparse.csgraph` module. We will discuss
    these further in [Chapter 5](c1a2f2ae-682f-469a-a00e-32c848bd1f38.xhtml), *Working
    with Trees and Networks*.
  prefs: []
  type: TYPE_NORMAL
- en: The `sparse` module contains several different classes representing the different
    means of storing a sparse matrix. The most basic means of storing a sparse matrix
    is to store three arrays, two containing integers representing the indices of
    non zero elements, and the third the data of the corresponding element. This is
    the format of the `coo_matrix` class. Then there are the compressed column CSC
    (`csc_matrix`) and the compressed row CSR (`csr_matrix`) formats, which provide
    efficient column or row slicing, respectively.There are three additional sparse
    matrix classes in `sparse`, including `dia_matrix`, which efficiently stores matrices
    where the non-zero entries appear along a diagonal band.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `sparse` module from SciPy contains routines for creating and working with
    sparse matrices. We import the `sparse` module from SciPy using the following
    `import` statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: A sparse matrix can be created from a full (dense) matrix, or some other kind
    of data structure. This is done using the constructor for the specific format
    in which you wish to store the sparse matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, we can take a dense matrix and store it in CSR format by using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'If you are generating a sparse matrix by hand, the matrix probably follows
    some kind of pattern, such as the following *tridiagonal* matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/0d9a6f28-5695-48e2-b5eb-606945aaddf9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, the non-zero entries appear on the diagonal and on either side of the
    diagonal, and the non-zero entries in each row follow the same pattern. To create
    such a matrix, we could use one of the array creation routines in `sparse` such
    as `diags`, which is a convenience routine for creating matrices with diagonal
    patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'This will create the matrix *T* as described previously and store it as a sparse
    matrix in compressed sparse row CSR format. The first argument specifies the values
    that should appear in the output matrix, and the second argument is the positions
    relative to the diagonal position in which the values should be placed. So the
    0 index in the tuple represents the diagonal entry, -1 is to the left of the diagonal
    in the row, and +1 is to the right of the diagonal in the row. The `shape` keyword
    argument gives the dimensions of the matrix produced, and the `format` specifies
    the storage format for the matrix. If no format is provided using the optional
    argument, then a reasonable default will be used. The array `T` can be expanded
    to a full (*dense*) matrix using the `toarray` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: When the matrix is small (as it is here), there is little difference in performance
    between the sparse solving routine and the usual solving routines.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once a matrix is stored in a sparse format, we can use the sparse solving routines
    in the `linalg` submodule of `sparse`. For example, we can solve a matrix equation
    using the `spsolve` routine from this module. The `spsolve` routine will convert
    the matrix into CSR or CSC, which may add additional time to the computation if
    it is not provided in one of these formats:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: The `sparse.linalg` module also contains many of the routines that can be found
    in the `linalg` module of NumPy (or SciPy) that accept sparse matrices instead
    of full NumPy arrays, such as `eig` and `inv`.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python offers built-in support for mathematics with some basic numerical types,
    arithmetic, and basic mathematical functions. However, for more serious computations
    involving large arrays of numerical values, you should use the NumPy and SciPy
    packages. NumPy provides high-performance array types and basic routines, while
    SciPy provides more specific tools for solving equations and working with sparse
    matrices (among many other things).
  prefs: []
  type: TYPE_NORMAL
- en: NumPy arrays can be multi-dimensional. In particular, two-dimensional arrays
    have matrix properties that can be accessed using the `linalg` module from either
    NumPy or SciPy (the former is a subset of the latter). Moreover, there is a special
    operator in Python for matrix multiplication, `@`, which is implemented for NumPy
    arrays.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll get started looking at some recipes.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are many mathematical textbooks describing the basic properties of matrices
    and linear algebra, which is the study of vectors and matrices. A good introductory
    text is *Blyth, T. and Robertson, E. (2013). Basic Linear Algebra**. London: Springer
    London, Limited*.'
  prefs: []
  type: TYPE_NORMAL
- en: NumPy and SciPy are part of the Python mathematical and scientific computing
    ecosystem, and have extensive documentation that can be accessed from the official
    website, [https://scipy.org](https://scipy.org). We will see several other packages
    from this ecosystem throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'More information about the BLAS and LAPACK libraries that NumPy and SciPy use
    behind the scenes can be found at the following links: BLAS: [https://www.netlib.org/blas/](https://www.netlib.org/blas/)
    and LAPACK: [https://www.netlib.org/lapack/](https://www.netlib.org/lapack/).**'
  prefs: []
  type: TYPE_NORMAL
