- en: Multi-Document ACID Transactions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MongoDB introduced multi-document **atomicity**, **consistency**, **isolation**,
    and **durability** (**ACID**) transactions in version 4.0, which was released
    in July 2018\. Transactions are an integral part of relational databases. Every
    **relational database management system** (**RDBMS**) from the very early days
    relied on transactions to achieve ACID. Getting these in a non-relational database
    is a breakthrough that can fundamentally change the way developers and database
    architects design software systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the previous chapter, we learned how to query MongoDB using Ruby, Python,
    and PHP drivers and frameworks. In this chapter, we will learn about the following
    topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Multi-document ACID transactions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using transactions with Ruby and Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Background
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MongoDB is a non-relational database and provides few guarantees around ACID.
    Data modeling in MongoDB is not focused around BCNF, 2NF, and 3NF normalization, but
    rather, quite the opposite direction.
  prefs: []
  type: TYPE_NORMAL
- en: In MongoDB, many times, the best approach is to embed our data into subdocuments,
    resulting in more self-contained documents than a single row of data in an RDBMS.
    This means that a logical transaction can affect a single document many times.
    Single-document transactions are ACID-compliant in MongoDB, meaning that multi-document
    ACID transactions have not been essential for MongoDB development.
  prefs: []
  type: TYPE_NORMAL
- en: However, there are a few reasons why getting multi-document transactions is
    a good idea. Over the years, MongoDB has grown from being a niche database to
    a multi-purpose database that is used everywhere – from startups to major Fortune
    500 companies. Across many different use cases, there are inevitably a few corner
    cases where data modeling can't, or shouldn't, fit data in subdocuments and arrays.
    Also, even when the best solution for a data architect today is to embed data,
    they can't be sure this will always be the case. This makes choosing the right
    database layer difficult.
  prefs: []
  type: TYPE_NORMAL
- en: RDBMS data modeling has been around for over 40 years and is a well-known and
    understood data modeling process. Helping data architects work in a familiar way
    is always an added bonus.
  prefs: []
  type: TYPE_NORMAL
- en: Before multi-document transactions were introduced, the only workaround was
    implementing them in a customized way in the application layer. This was both
    time consuming and prone to error. Implementing a 2-phase commit process in the
    application layer could also be slower and lead to increased database locks.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will focus on using the native MongoDB transactions, as
    it is now strongly recommended by MongoDB Inc.
  prefs: []
  type: TYPE_NORMAL
- en: ACID
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ACID stands for atomicity, consistency, isolation, and durability. In the following
    sections, we will explain what each of these means for our database design and
    architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Atomicity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Atomicity refers to the concept that transactions need to be atomic. Either
    it succeeds and its results are visible to every subsequent user reading them,
    or it fails and every change is rolled back to the point it was at before it started.
    Either all actions in a transaction occur, or none at all.
  prefs: []
  type: TYPE_NORMAL
- en: A simple example to understand atomicity is by transferring money from account
    *A* to account *B*. Money needs to be credited from account *A* and then debited
    into account *B*. If the operation fails midway, then both accounts *A* and *B*
    need to be reverted to their state before the operation started.
  prefs: []
  type: TYPE_NORMAL
- en: In MongoDB, operations in a single document are always atomic even if the operation
    spans multiple subdocuments or arrays within the document.
  prefs: []
  type: TYPE_NORMAL
- en: Operations spanning multiple documents need to use MongoDB transactions to be
    made atomic.
  prefs: []
  type: TYPE_NORMAL
- en: Consistency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Consistency refers to the database always being in a consistent state. Every
    database operation may complete successfully, fail, or abort; however, in the
    end, our database must be in a state where its data is consistent.
  prefs: []
  type: TYPE_NORMAL
- en: Database constraints must be respected at all times. Any future transaction
    must also be able to view data updated by past transactions. The consistency model
    most commonly used in practice for distributed data systems is eventual consistency.
  prefs: []
  type: TYPE_NORMAL
- en: Eventual consistency guarantees that once we stop updating our data, all future
    reads will eventually read the latest committed write value. In distributed systems,
    this is the only acceptable model in terms of performance, as data needs to be
    replicated over the network across different servers.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, the least popular model of strong consistency guarantees that every
    future read will always read the write value that was committed last. This implies
    that every update is propagated and committed to every server before the next
    read comes in, which will cause a huge strain on performance for these systems.
  prefs: []
  type: TYPE_NORMAL
- en: MongoDB falls somewhere in between eventual and strict consistency. In fact,
    MongoDB adopts a causal consistency model. With causal consistency, any transaction
    execution sequence is the same as if all causally-related read/write ops were
    executed in an order that reflects their causality.
  prefs: []
  type: TYPE_NORMAL
- en: What this means in practice is that concurrent operations may be seen in different
    orders, and reads correspond to the latest value written with regard to the writes
    that they are causally dependent on.
  prefs: []
  type: TYPE_NORMAL
- en: Eventually, it's a trade-off between how many concurrent operations can happen
    at once and the consistency of data being read by the application.
  prefs: []
  type: TYPE_NORMAL
- en: Isolation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Isolation refers to the visibility of transaction operations to other operations
    happening in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: 'An example of why isolation levels are essential is described in the following
    scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: Transaction *A* updates user 1's account balance from 50 to 100, but does not
    commit the transaction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transaction *B* reads user 1's account balance as 100.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transaction *A* is rolled back, reverting user 1's account balance to 50.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transaction *B* thinks that user 1 has 100 pounds, whereas they only have 50.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transaction *B* updates user 2's value, by adding 100 pounds. User 2 receives
    100 pounds out of thin air from user 1, since user 1 only has 50 pounds in their
    account. Our imaginary bank is in trouble.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Isolation typically has four levels, with the most to the least strict, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Serializable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Repeatable read
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Read committed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Read uncommitted
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The problems we can run into from the least to the most serious, and depending
    on the isolation level, are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Phantom reads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Non-repeatable reads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dirty reads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lost updates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Losing data about an operational update is the worst thing that can happen in
    any database, because this would render our database unusable and make it a store
    of data that cannot be trusted. That's why, in every isolation level, even read
    uncommitted isolation will not lose data.
  prefs: []
  type: TYPE_NORMAL
- en: However, the other three issues may also arise. We will briefly explain what
    these are in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Phantom reads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A phantom read occurs when, during the course of a transaction, another transaction
    modifies its result set by adding or deleting rows that belong to its result set.
    An example of this would be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Transaction *A* queries for all users. 1,000 users are returned but the transaction
    does not commit.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transaction *B* adds another user; 1,001 users are now in our database.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transaction *A* queries for all users for a second time. 1,001 users are now
    returned. Transaction *A* now commits.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Under a strict serializable isolation level, transaction *B* should be blocked
    from adding the new user until transaction *A* commits its transaction. This can,
    of course, cause huge contention in the database and contention in the database
    and lead to performance degradation, as every update operation needs to wait for
    reads to commit their transactions. This is why, typically, serializable is rarely
    used in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Non-repeatable reads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A non-repeatable read occurs when, during a transaction, a row is retrieved
    twice and the row's values are different with every read operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following the previous money transfer example, we can illustrate a non-repeatable
    read in a similar way:'
  prefs: []
  type: TYPE_NORMAL
- en: Transaction *B* reads user 1's account balance as 50.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transaction *A* updates user 1's account balance from 50 to 100, and commits
    the transaction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transaction *B* reads user 1's account balance again and gets the new value,
    100, and then commits the transaction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The problem here is that transaction *B* has got a different value in the course
    of its transaction because it was affected by transaction *A*'s update. This is
    a problem because transaction *B* is getting different values within its own transaction.
    However, in practice, it solves the issue of transferring money between users
    when they don't exist.
  prefs: []
  type: TYPE_NORMAL
- en: This is why a read committed isolation level, which does not prevent non-repeatable
    reads but does prevent dirty reads, is the most commonly-used isolation level
    in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Dirty reads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous example, where we made money out of thin air and ended up transferring
    100 pounds out of an account that only had 50 pounds in balance, is a classic
    example of dirty reads.
  prefs: []
  type: TYPE_NORMAL
- en: A read uncommitted isolation level does not protect us from dirty reads and
    that is why it is rarely used in production level systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the isolation levels versus potential issues:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Isolation level** | **Lost updates** | **Dirty reads** | **Non-repeatable
    reads** | **Phantoms** |'
  prefs: []
  type: TYPE_TB
- en: '| Read uncommitted | Don''t occur | May occur | May occur | May occur |'
  prefs: []
  type: TYPE_TB
- en: '| Read committed | Don''t occur | Don''t occur | May occur | May occur |'
  prefs: []
  type: TYPE_TB
- en: '| Repeatable read | Don''t occur | Don''t occur | Don''t occur | May occur
    |'
  prefs: []
  type: TYPE_TB
- en: '| Serializable | Don''t occur | Don''t occur | Don''t occur | Don''t occur
    |'
  prefs: []
  type: TYPE_TB
- en: PostgreSQL uses a default (and configurable) isolation level of read committed.
    As MongoDB is not inherently an RDBMS, using transactions for every operation
    makes the situation is more complicated.
  prefs: []
  type: TYPE_NORMAL
- en: The equivalent isolation level in these terms is read uncommitted. This may
    look scary based on the examples previously given, but on the other hand, in MongoDB,
    there is (again, in general) no concept of transactions or rolling them back.
    Read uncommitted refers to the fact that changes will be made visible before they
    are made durable. More details on the made durable part are provided in the following
    section on durability.
  prefs: []
  type: TYPE_NORMAL
- en: Durability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Durability in relational database systems refers to the property that every
    transaction that has successfully committed will survive in the face of failure.
    This usually refers to writing the contents of the committed transaction in persistent
    storage (such as a hard disk or SDD). RDBMSes are always following the durability
    concept by writing every committed transaction to a transaction log or **write-ahead
    log** (**WAL**). MongoDB, using the WiredTiger storage engine, is committing writes
    using WAL to its persistent storage-based journal every 60 msec and is, for all
    practical purposes, durable. As durability is important, every database system
    prefers relaxing other aspects of ACID first, and durability usually gets relaxed
    last.
  prefs: []
  type: TYPE_NORMAL
- en: When do we need ACID in MongoDB ?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Existing atomicity guarantees, for single-document operations, that MongoDB can
    meet the integrity needs for most real-world applications. However, there are
    some use cases that have traditionally benefited from ACID transactions; modeling
    them in MongoDB could be significantly more difficult than using the well-known
    ACID paradigm.
  prefs: []
  type: TYPE_NORMAL
- en: Unsurprisingly, many of these cases come from the financial industry. Dealing
    with money and stringent regulation frameworks means that each and every operation
    needs to be stored, sometimes in strict execution order, logged, verified, and
    be able to be audited if requested. Building a digital bank requires interaction
    between multiple accounts that could be represented as documents in MongoDB.
  prefs: []
  type: TYPE_NORMAL
- en: Managing high volumes of financial transactions, either by users or algorithms
    executing high-frequency trading, also requires verifying each and every single
    one of them. These transactions may span multiple documents, as they would again
    refer to multiple accounts.
  prefs: []
  type: TYPE_NORMAL
- en: The general pattern for using multi-document ACID transactions is when we can
    have an unbounded number of entities, sometimes to the millions. In this case,
    modeling entities in subdocuments and arrays cannot work, as the document would
    eventually outgrow the built-in 16 MB document size limit present in MongoDB.
  prefs: []
  type: TYPE_NORMAL
- en: Building a digital bank using MongoDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most common use cases for multi-document ACID transactions come from the
    financial sector. In this section, we will model a digital bank using transactions
    and go through progressively more complicated examples of how we can use transactions
    for our benefit.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic functionality that a bank must provide is accounts and transferring
    monetary amounts between them. Before transactions were introduced, MongoDB developers
    had two options. The first option – the MongoDB way of doing it – is to embed
    data in a document, either as a subdocument or as an array of values. In the case
    of accounts, this could result in a data structure like the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: However, even in this simple format, it will quickly outgrow the fixed 16 MB
    document limit in MongoDB. The advantage of this approach is that since we have
    to deal with a single document, all operations will be atomic, resulting in strong
    consistency guarantees when we transfer money from one account to another.
  prefs: []
  type: TYPE_NORMAL
- en: The only viable alternative, except for using a relational database, is to implement
    guarantees in the application level that will simulate a transaction with the
    appropriate code in place to undo parts, or the whole, of a transaction in case
    of an error. This can work, but will result in a longer time to market and is
    more prone to error.
  prefs: []
  type: TYPE_NORMAL
- en: 'MongoDB''s multi-document ACID transactions approach is similar to how we would
    work with transactions in a relational database. Taking the most simple example
    from MongoDB Inc.''s white paper, *MongoDB Multi-Document ACID Transactions,*
    published in June, 2018, the generic transaction in MongoDB will look like the
    following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'However, the same transaction in MySQL will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: That said, in modern web application frameworks, most of the time transactions
    are hidden in the **object-relational mapping** (**ORM**) layer and not immediately
    visible to the application developer. The framework ensures that web requests
    are wrapped in transactions to the underlying database layer. This is not yet
    the case for ODM frameworks, but you would expect that this could now change.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up our data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are going to use a sample `init_data.json` file with two accounts. Alex
    has 100 of the hypnotons imaginary currency, whereas Mary has 50 of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the following Python code, we can insert these values into our database
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in our `mongo_bank` database having the following documents in
    our `accounts` collection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Transferring between accounts – part 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As a MongoDB developer, the most familiar approach to model a transaction is
    to implement basic checks in the code. With our sample account documents, you
    may be tempted to implement an account transfer as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Calling this method in Python will transfer 300 hypnotons from account 1 to
    account 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The problem here isn't the checks on `updated_source_balance` and `updated_target_balance`.
    Both of these values reflect the new values of `-200` and `350`, respectively.
    The problem isn't the `abort_transaction()` operation either. Instead, the problem
    is that we are not using the session.
  prefs: []
  type: TYPE_NORMAL
- en: The single most important thing to learn about transactions in MongoDB is that
    we need to use the session object to wrap operations in a transaction; but, all
    the while, we can still perform operations outside the transaction scope within
    a transaction code block.
  prefs: []
  type: TYPE_NORMAL
- en: 'What happened here is that we initiated a transaction session, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'And then completely ignored it by doing all of our updates in a non-transactional
    way. Then we invoked `abort_transaction`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The transaction to be aborted was essentially void and didn't have anything
    to roll back.
  prefs: []
  type: TYPE_NORMAL
- en: Transferring between accounts – part 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The correct way to implement a transaction is to use the session object in
    each and every operation that we want to either commit or roll back at the end
    of it, as you can see from the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The only difference now is that we are passing `session=ses` in both of our
    update statements. In order to validate whether we have enough funds to actually
    make the transfer, we wrote a helper method, `__validate_transfer`, with its arguments
    being the source and target account IDs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Unfortunately, this attempt will also *fail*. The reason is the same as before.
    When we are inside a transaction, we make changes to the database that follow
    the ACID principles. Changes inside a transaction are not visible to any queries
    outside of it, until they are committed.
  prefs: []
  type: TYPE_NORMAL
- en: Transferring between accounts – part 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The correct implementation to the transfer problem will look like the following
    code (the full code sample is attached with the code bundle):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In this case, by passing the session object's `ses` value, we ensure that we
    can both make changes in our database using `update_one()` and also view these
    changes using `find_one()`, before doing either an `abort_transaction()` operation
    or a `commit_transaction()` operation.
  prefs: []
  type: TYPE_NORMAL
- en: Transactions cannot perform **data definition language** (**DDL**) operations,
    so `drop()`, `create_collection()`, and other operations that can affect MongoDB's
    DDL will fail inside a transaction. This is why we are setting `w='majority'`
    in our `MongoClient` object, to make sure that, when we drop a collection right
    before we start our transaction, this change will be visible to the transaction.
  prefs: []
  type: TYPE_NORMAL
- en: Even if we explicitly take care not to create or remove collections during a
    transaction, there are operations that will implicitly do so.
  prefs: []
  type: TYPE_NORMAL
- en: We need to make sure that the collection exists before we attempt to insert
    or upsert (update and insert) a document.
  prefs: []
  type: TYPE_NORMAL
- en: In the end, using transactions if we need to rollback, we don't need to keep
    track of the previous account balance values, as MongoDB will discard all of the
    changes that we made inside the transaction scope.
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuing with the same example using Ruby, we have the following code for
    part 3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Alongside all of the points raised in the example in Python, we find that we
    can also customize `read_concern` and `write_concern` per transaction.
  prefs: []
  type: TYPE_NORMAL
- en: 'The available `read_concern` levels for multi-document ACID transactions are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`majority`: A majority of the servers in a replica set have acknowledged the
    data. For this to work as expected in transactions, they must also use `write_concern`
    to `majority`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`local`: Only the local server has acknowledged the data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`snapshot`: The default `read_concern` levels for transactions as of MongoDB
    4.0\. If the transaction commits with `majority` as `write_concern`, all transaction
    operations will have read from a snapshot of majority committed data, otherwise
    no guarantee can be made.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Read concern for transactions is set in the transaction level or higher (session
    or, finally, client). Setting read concern in individual operations is not supported
    and is generally discouraged.
  prefs: []
  type: TYPE_NORMAL
- en: The available `write_concern` levels for multi-document ACID transactions are
    the same as everywhere else in MongoDB, except for `w:0` (no acknowledgement),
    which is not supported at all.
  prefs: []
  type: TYPE_NORMAL
- en: E-commerce using MongoDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For our second example, we are going to use a more complex use case on a transaction
    with three different collections.
  prefs: []
  type: TYPE_NORMAL
- en: We are going to simulate a shopping cart and payment transaction process for
    an e-commerce application using MongoDB. Using the sample code that we'll provide
    at the end of this section, we will initially populate the database with the following
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our first collection is the `users` collection with one document per user:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we have the `carts` collection with one document per cart, which is linked
    via the `user_id` to our users:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The `payments` collection holds any completed payment that has gone through,
    storing the `cart_id` and the `item_id` to link to the cart that it belonged to
    and the item that has been paid:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the `inventories` collection holds a count of the number of items
    (by `item_id`) that we have currently available, along with their price and a
    short description:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we are going to demonstrate using MongoDB's schema validation
    functionality. Using JSON schemata, we can define a set of validations that will
    be checked against the database level every time a document is inserted or updated.
    This is a fairly new feature as it was introduced in MongoDB 3.6\. In our case,
    we are going to use it to make sure that we always have a positive number of items
    in our inventory.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `validator` object in the MongoDB shell format is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'JSON schemata can be used to implement many of the validations that we would
    usually have in our models in Rails or Django. We can define these keywords as
    in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Keyword** | **Validates on type** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `enum` | All | The enum of allowed values in a field. |'
  prefs: []
  type: TYPE_TB
- en: '| `type` | All | The enum of allowed types in a field. |'
  prefs: []
  type: TYPE_TB
- en: '| `minimum`/`maximum` | Numeric | The minimum and maximum values for a numeric
    field. |'
  prefs: []
  type: TYPE_TB
- en: '| `minLength`/`maxLength` | String | The minimum and maximum length allowed
    for a string field. |'
  prefs: []
  type: TYPE_TB
- en: '| `pattern` | String | The regex pattern that the string field must match.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `required` | Objects | The document must contain all the strings defined
    in the required property array. |'
  prefs: []
  type: TYPE_TB
- en: '| `minItems`/`maxItems` | Arrays | The minimum and maximum length of items
    in the array. |'
  prefs: []
  type: TYPE_TB
- en: '| `uniqueItems` | Arrays | If set to true, all items in the array must have
    unique values. |'
  prefs: []
  type: TYPE_TB
- en: '| `title` | N/A | A descriptive title for the developer''s use. |'
  prefs: []
  type: TYPE_TB
- en: '| `description` | N/A | A description for the developer''s use. |'
  prefs: []
  type: TYPE_TB
- en: Using JSON schema, we can offload validations from our models to the database
    layer and/or use MongoDB validations as an additional layer of security on top
    of web application validations.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use a JSON schema, we have to specify it at the time that we are creating
    our collection, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Returning to our example, our code will simulate having an inventory of five
    bull bearings and placing two orders; one by user Alex for two bull bearings,
    followed by a second order by user Barbara for another four bull bearings.
  prefs: []
  type: TYPE_NORMAL
- en: 'As expected, the second order will not go through because we don''t have enough
    ball bearings in our inventory to fulfill it. We will see this in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We will break down the preceding example into the interesting parts, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The `add_to_cart()` method doesn't use transactions. The reason is that because
    we are updating one document at a time, these are guaranteed to be atomic operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, in the `place_order()` method, we start the session, and then subsequently,
    a transaction within this session. Similar to the previous use case, we need to
    make sure that we add the `session=ses` parameter at the end of every operation
    that we want to be executed in the transaction context:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: In this method, we are using the retry able transaction pattern. We start by
    wrapping the transaction context in a `while True` block, essentially making it
    loop forever. Then we enclose our transaction in a `try` block that will listen
    for exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: An exception of type `transient transaction`, which has the `TransientTransactionError`
    error label, will result in continued execution in the `while True` block, essentially
    retrying the transaction from the very beginning. On the other hand, a failed
    validation or any other error will reraise the exception after logging it.
  prefs: []
  type: TYPE_NORMAL
- en: The `session.commitTransaction()` and `session.abortTransaction()` operations
    will be retried once by MongoDB, no matter if we retry the transaction or not.
  prefs: []
  type: TYPE_NORMAL
- en: We don't need to explicitly call `abortTransaction()` in this example, as MongoDB
    will abort it in the face of exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the end, our database looks like the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The payment that we just made does not have the name field, in contrast to
    the sample payment that we inserted in our database before rolling our transactions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Our inventory has the correct number of bull bearings, three (five minus the
    two that Alex ordered), as shown in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Our carts have the correct quantities. Alex's cart (`cart_id=1`) has zero items,
    whereas Barbara's cart (`cart_id=2`) still has four, since we don't have enough
    bull bearings to fulfill her order. Our payments collection does not have an entry
    for Barbara's order and the inventory still has three bull bearings in place.
  prefs: []
  type: TYPE_NORMAL
- en: Our database state is consistent and saving lots of time by implementing the
    abort transaction and reconciliation data logic in our application level.
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuing with the same example in Ruby, we have the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to the Python code sample, we are passing the `session: session` parameter
    along each operation to make sure that we are operating inside the transaction.'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we are not using the retry able transaction pattern. Regardless, MongoDB
    will retry committing or aborting a transaction once before throwing an exception.
  prefs: []
  type: TYPE_NORMAL
- en: The best practices and limitations of multi-document ACID transactions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are currently some limitations and best practices when developing using
    MongoDB transactions in version 4.0.3:'
  prefs: []
  type: TYPE_NORMAL
- en: The transaction timeout is set to 60 seconds.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a best practice, any transaction should not try to modify more than 1,000
    documents. There is no limitation in reading documents during a transaction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The oplog will record a single entry for a transaction, meaning that this is
    subject to the 16 MB document size limit. This is not such a big problem with
    transactions that update documents, as only the delta will be recorded in the
    oplog. It can, however, be an issue when transactions insert new documents, in
    which case the oplog will record the full contents of the new documents.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We should add application logic to cater for failing transactions. These could
    include using retryable writes, or executing some business logic-driven action
    when the error cannot be retried or we have exhausted our retries (usually, this
    means a custom 500 error).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DDL operations such as modifying indexes, collections, or databases will get
    queued up behind active transactions. Transactions trying to access the namespace
    while a DDL operation is still pending will immediately abort.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transactions only work in replica sets. Starting from MongoDB 4.2, transactions
    will also be available for sharded clusters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use sparingly; maybe the most important point to consider when developing using
    MongoDB transactions is that they are not meant as a replacement for good schema
    design. They should only be used when there is no other way to model our data
    without them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about textbook relational database theory on ACID
    in the context of MongoDB.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we focused on multi-document ACID transactions and applied them in two
    use cases using Ruby and Python. We learned about when to use MongoDB transactions
    and when not to use them, how to use them, their best practices, and their limitations.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will deal with one of the most commonly-used features
    of MongoDB – aggregation.
  prefs: []
  type: TYPE_NORMAL
