- en: Chapter 2. Configuring and Monitoring Docker Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Verifying host-level settings that impact Docker networking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connecting containers in bridge mode
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exposing and publishing ports
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connecting containers to existing containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connecting containers in host mode
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring service-level settings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker makes consuming container technology easier than it's ever been before.
    Known for its ease of use, Docker offers many advanced features but installs with
    a sane set of defaults that make it easy to quickly start building containers.
    And while network configuration is typically the one area that requires additional
    attention before use, Docker makes it easy to get your containers up and on the
    network.
  prefs: []
  type: TYPE_NORMAL
- en: Verifying host-level settings that impact Docker networking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker relies on the host being capable of performing certain functions to make
    Docker networking work. Namely, your Linux host must be configured to allow IP
    forwarding. In addition, since the release of Docker 1.7, you may now choose to
    use hairpin **Network Address Translation** (**NAT**) rather than the default
    Docker user land proxy. In this recipe, we'll review the requirement for the host
    to have IP forwarding enabled. We'll also talk about NAT hairpin and discuss the
    host-level requirements for that option as well. In both cases, we'll show Docker's
    default behavior with regard to its settings as well as how you can alter them.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You'll need access to a Linux host running Docker and the ability to stop and
    restart the service. Since we'll be modifying system-level kernel parameters,
    you'll also need root-level access to the system.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we saw in [Chapter 1](ch01.html "Chapter 1. Linux Networking Constructs"),
    *Linux Networking Constructs*, a Linux host must have IP forwarding enabled to
    be able to route traffic between interfaces. Since Docker does just that, IP forwarding
    must be enabled for Docker networking to function as desired. If Docker detects
    that IP forwarding is disabled, it will warn you of the issue when you attempt
    to run a container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Most Linux distributions default the IP forward value to `disabled` or `0`.
    Fortunately for us, in a default configuration, Docker takes care of updating
    this setting to the correct value when the Docker service starts. For instance,
    let''s take a look at a freshly rebooted host that doesn''t have the Docker service
    enabled at boot time. If we check the value of the setting before starting Docker,
    we can see that it''s disabled. Starting the Docker engine automatically enables
    the setting for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This default behavior in Docker can be changed by passing `--ip-forward=false`
    as a runtime option to the Docker service.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The configuration of Docker-specific parameters varies widely based on the **init
    system** used. At the time of writing, many newer Linux operating systems use
    `systemd` as their init system. Always consult the Docker documentation to see
    its recommendation for service configuration based on the operating system you
    are using. Docker service configuration and options are talked about in greater
    detail as part of an upcoming recipe in this chapter. In this recipe, just focus
    on the impact changing these settings has on both Docker and the host itself.
  prefs: []
  type: TYPE_NORMAL
- en: Further discussion on the kernel IP forward parameter can be found in the recipe
    *Configuring Linux host routing* in [Chapter 1](ch01.html "Chapter 1. Linux Networking
    Constructs"), *Linux Networking Constructs*. There you'll find how to update the
    parameter yourself as well as how to make the setting persistent through reboots.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another recent feature of Docker that relies on a kernel-level parameter is
    the hairpin NAT functionality. Earlier versions of Docker implemented, and relied
    on, what''s known as the Docker **userland proxy** to facilitate intercontainer
    and published port communication. By default, any containers exposing ports did
    so through the userland proxy process. For instance, if we start an example container
    we can see that in addition to the Docker process itself, we also now have a `docker-proxy`
    process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Every published port will start a new `docker-proxy` process on the Docker host.
    As an alternative to the userland proxy, you have the option to have Docker use
    hairpin NAT rather than userland proxies. Hairpin NAT relies on the host system
    being configured to enable routing on the host's local loopback interfaces. Again,
    the Docker service takes care of updating the correct host parameter to enable
    this functionality when the Docker service starts if it's told to do so.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hairpin NAT relies on the kernel parameter `net.ipv4.conf.docker0.route_localnet`
    being enabled (set to `1`) in order for the host machine to access container services
    through the hosts loopback interface. This can be achieved in the same way as
    we described with the IP forward parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `sysctl` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'By querying the `/proc/` filesystem directly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: If the returned value is `0`, it's likely that Docker is in its default configuration
    and is relying on the userland proxy. Since you have the option to run Docker
    in either mode, we need to do more than change the kernel parameters in order
    to make the change to hairpin NAT. We also need to tell Docker to change the way
    it publishes ports by passing the option `--userland-proxy=false` as a runtime
    option to the Docker service. Doing so will enable hairpin NAT and also tell Docker
    to update the kernel parameter to the correct setting for hairpin NAT to work.
    Let's enable hairpin NAT to validate that Docker is doing what it should be doing.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s check the value of the kernel parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s currently disabled. Now we can tell Docker to disable the userland proxy
    by passing the `--userland-proxy=false` as a parameter to the Docker service.
    Once the Docker service is told to disable the userland proxy, and the service
    is restarted, we should see that the parameter is enabled on the host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Running a container with a mapped port at this point will not create additional
    `docker-proxy` process instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition, we are still able to access the container through the host''s
    local interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Disabling the parameter once again causes this connection to fail:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Connecting containers in bridge mode
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we mentioned earlier, Docker comes with a set of sensible defaults to get
    your containers communicating on the network. From a network perspective, the
    Docker default is to attach any spawned container to the `docker0` bridge. In
    this recipe, we'll show how to connect containers in the default bridge mode and
    explain how network traffic leaving and destined for the container is handled.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You''ll need access to a Docker host and an understanding of how your Docker
    host is connected to the network. In our example, we''ll be using a Docker host
    that has two physical network interfaces, like the one shown in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](graphics/B05453_02_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: You'll want to make sure that you have access to view `iptables` rules to verify
    **netfilter** policies. If you wish to download and run example containers, your
    Docker host will also need access to the Internet. In some cases, the changes
    we make may require you to have root-level access to the system.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After installing and starting Docker, you should notice the addition of a new
    Linux bridge named `docker0`. By default, the `docker0` bridge has an IP address
    of `172.17.0.1/16`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Docker will place any containers that are started without specifying a network
    on the `docker0` bridge. Now, let''s look at an example container running on this
    host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: By running the container in interactive mode, we can examine what the container
    believes its network configuration to be. In this case, we can see that the container
    has a single non-loopback network adapter (`eth0`) with an IP address of `172.17.0.2/16`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, we can see that the container believes its default gateway is
    the `docker0` bridge interface on the Docker host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: By running some basic tests, we can see that the container has access to physical
    interface of the Docker host as well as Internet-based resources.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Internet-based access for the container itself is predicated on the fact that
    the Docker host has access to the Internet.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Given that the network the container lives on was created by Docker, we can
    safely assume that the rest of network is not aware of it. That is, the outside
    network has no knowledge of the `172.17.0.0/16` network since it''s local to the
    Docker host. That being said, it seems curious that the container is able to reach
    resources that live beyond the `docker0` bridge. Docker makes this work by hiding
    container''s IP addresses behind the Docker host''s IP interfaces. The traffic
    flow is shown in the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](graphics/B05453_02_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Since the containers'' traffic is seen on the physical network as the Docker
    host''s IP address, other network resources know how to return the traffic to
    the container. To perform this outbound NAT, Docker uses the Linux netfilter framework.
    We can see these rules using the netfilter command-line tool `iptables`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we have a rule in the `POSTROUTING` chain that masquerades or
    hides, anything sourced from our `docker0` bridge (`172.17.0.0/16`) behind the
    host's interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although outbound connectivity is configured and allowed by default, Docker
    does not by default provide a means to access services in the containers from
    outside the Docker host. In order to do this, we must pass Docker additional flags
    at container runtime. Specifically, we can pass the `-P` flag when we run the
    container. To examine this behavior, let''s look at a container image that exposes
    a port:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This tells Docker to map a random port to any ports that the container image
    exposes. In the case of this demo container, the image exposes port `80`. After
    running the container, we can see the host port mapped to the container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, the containers port `80` has been mapped to host port `32768`.
    This means that we can access the service running on port `80` of the container
    through the host''s interfaces at port `32768`. Much like the outbound container
    access, inbound connectivity also uses netfilter to create the port mapping. We
    can see this by checking the NAT and filter table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the connectivity is being exposed on all interfaces (`0.0.0.0`), our
    inbound diagram will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](graphics/B05453_02_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: If not defined otherwise containers that live on the same host, and hence the
    same `docker0` bridge, can inherently communicate with each other by their assigned
    IP address on any port, which is bound to a service. Allowing this communication
    is the default behavior and can be changed as we'll see in a later chapters when
    we discuss **Inter-Container Communication** (**ICC**) configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It should be noted that this is the default behavior for containers that are
    run without specifying any additional network parameters, that is, containers
    that use the Docker default bridge network. Later chapters will introduce other
    options that allow you to place containers living on the same host on different
    networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Communication between containers that live on different hosts requires using
    a combination of both the previously discussed flows. To test this out, let''s
    expand our lab by adding a second host named `docker2`. Let''s assume container
    `web2` on the host `docker2` wishes to access the container `web1` living on host
    `docker1`, which is hosting a service on port `80`. The flow will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](graphics/B05453_02_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Let's walk through the flow at each step and show what the packets look like
    as they hit the wire in each step. In this case, the container `web1` is exposing
    port `80`, which has been published to port `32771` on the host `docker1`.
  prefs: []
  type: TYPE_NORMAL
- en: Traffic leaves the container `web2` destined for the exposed port (`32771`)
    on the `10.10.10.101` interface of host `docker1`:![How to do it…](graphics/B05453_02_05.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Traffic arrives at the container's default gateway, which is the IP interface
    of the `docker0` bridge (`172.17.0.1`). The host does a route lookup and determines
    that the destination lives out of its `10.10.10.102` interface, so it hides the
    container's real source IP behind that interface's IP address:![How to do it…](graphics/B05453_02_06.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Traffic arrives at the `docker1` host and is examined by the netfilter rules.
    `docker1` has a rule that exposes the service port of container 1 (`80`) on port
    `32271` of the host:![How to do it…](graphics/B05453_02_07.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The destination port is changed from `32771` to `80` and passed along to the
    `web1` container, which receives the traffic on the correct port `80`:![How to
    do it…](graphics/B05453_02_08.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To try this out for ourselves, let''s first run the `web1` container and check
    what port the service is exposed on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Now let's run a second container called web2 on the host docker2 and attempt
    to access web1's service on port 32771…
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Exposing and publishing ports
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we've seen in the previous examples, exposing services living in containers
    to the outside world is a critical component of Docker. Up until this point, we've
    let the images and the Docker engine do the heavy lifting for us in terms of the
    actual port mapping. To do this, Docker uses a combination of metadata from container
    images as well as a built-in system for tracking port allocations. In this recipe,
    we'll walk through the process for defining ports to be exposed as well as options
    for publishing ports.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You'll need access to a Docker host and an understanding of how your Docker
    host is connected to the network. In this recipe, we'll be using the `docker1`
    host that we used in previous recipes. You'll want to make sure that you have
    access to view `iptables` rules to verify netfilter policies. If you wish to download
    and run example containers, your Docker host will also need access to the Internet.
    In some cases, the changes we make may require you to have root-level access to
    the system.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While often confused, exposing ports and publishing ports are two totally different
    actions. Exposing ports is really just a way of documenting what ports a container
    might offer services on. These definitions are stored in the container metadata
    as part of the image and can be read by the Docker engine. Publishing ports is
    the actual process of mapping a container port to a host port. This can either
    be done automatically using the exposed port definitions, or it can be done manually
    without the use of exposed ports.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s first discuss how ports are exposed. The most common mechanism for exposing
    ports is to define them in an image''s **Dockerfile**. When you build a container
    image, you''re given the opportunity to define ports to be exposed. Consider this
    Dockerfile definition that I used to build some of the demo containers for this
    book:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: As part of the Dockerfile, I can define ports I wish to expose. In this case,
    I know that Apache will, by default, offer its web server on port `80` so that's
    the port I wish to expose.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that, by default, Docker always assumes the ports you're referring to are
    TCP. If you wish to expose UDP ports, you can do so by including the `/udp` flag
    at the end of the port definition. For instance, `EXPOSE 80/udp`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s run a container built with this Dockerfile to see what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, despite having a defined port to expose, Docker has not actually
    mapped any ports between the host and the container. If you recall from earlier
    recipe where a container provided a service, we included the `-P` flag in the
    `docker run` command syntax. The `-P` flag tells Docker to publish all exposed
    ports. Let''s try running this container with the `-P` flag set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see that Docker has now automatically mapped the exposed port to
    a random high port on the host. Port `80` will now be considered published.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to exposing ports through the image Dockerfile, we can also expose
    them at container runtime. Any ports that are exposed in this manner are combined
    with the ports exposed in the Dockerfile. For example, let''s run the same container
    again and expose port `80` UDP as part of the `docker run` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we have published not only the port from the Dockerfile (`80/tcp`)
    but also the port from the `docker run` command (`80/udp`).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Exposing ports at container runtime allows you some extra flexibility as you
    can define port ranges to be exposed. This is not currently possible during image
    creation with the Dockerfile `expose` syntax. When exposing a wide range of ports,
    you can filter the output of the `docker port` command by adding the container
    port you are looking for to the end of the command.
  prefs: []
  type: TYPE_NORMAL
- en: 'While the expose method is certainly handy, it doesn''t solve all of our needs.
    For cases where you want more control over ports and interfaces used, you can
    bypass `expose` and directly publish ports when starting a container. While passing
    the `-P` flag publishes all exposed ports, passing the `-p` flag allows you to
    specify specific ports and interfaces to use when mapping ports. The `-p` flag
    can take several different forms with the syntax looking like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Any of the options may be omitted with the only required field being the container
    port. For example, here are a couple of different ways you could use this syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Specify the host port and container port:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Specify the host interface, host port, and container port:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Specify the host interface, have Docker choose a random host port, and specify
    the container port:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Specify only a container port and have Docker use a random host port:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: All the published ports we've seen up until this point have used a destination
    IP address of (`0.0.0.0`), which means that they are bound to all IP interfaces
    of the Docker host. By default, the Docker service always binds published ports
    to all host interfaces. However, as we'll see in the following recipe of this
    chapter, we can tell Docker to use a specific interface by passing the Docker
    service the `--ip` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given that we can also define which interface to bind published ports to as
    part of the `docker run` command, we need to know which option takes priority.
    The general rule is that any option defined at container runtime wins. For instance,
    let''s look at an example where we tell the Docker service to bind to the `192.168.10.101`
    IP address of the `docker1` host by passing the following option to the service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s run a container in a couple of different ways and see the outcome:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, we see the expected behavior. Ports that are published
    are bound to the IP address specified in the service level `--ip` option (`10.10.10.101`).
    However, if we specify an IP address at container runtime, we can override the
    service-level settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s possible that you won''t find a use for exposed ports and instead rely
    solely on manually publishing them. The `EXPOSE` command is not a requirement
    of the Dockerfile for image creation. Container images that don''t define an exposed
    port can be directly published as shown in the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, the container image `jonlangemak/web_server_noexpose`
    is a container that does not expose any ports as part of its definition.
  prefs: []
  type: TYPE_NORMAL
- en: Connecting containers to existing containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker network connectivity up until this point has relied on exposing individual
    services hosted in a container to the physical network. However, what if you want
    to expose a service from one container to another without exposing it to the Docker
    host? In this recipe we'll walk through how to map services between two containers
    running on the same Docker host.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You'll need access to a Docker host and an understanding of how your Docker
    host is connected to the network. In this recipe, we'll be using the `docker1`
    host that we used in previous recipes. You'll want to make sure that you have
    access to view `iptables` rules to verify netfilter policies. If you wish to download
    and run example containers, your Docker host will also need access to the Internet.
    In some cases, the changes we make may require you to have root-level access to
    the system.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Mapping services from one container to another is sometimes referred to as
    mapped container mode. Mapped container mode allows you to start a container that
    utilizes an existing, or primary, container''s network configuration. That is,
    a mapped container will use the same IP and port configuration as the primary
    container. For the sake of example, let''s consider running the following container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Running this container starts the container in bridge mode and attaches it to
    the `docker0` bridge as we would expect.
  prefs: []
  type: TYPE_NORMAL
- en: 'The topology will look pretty standard at this point, something like what is
    shown in the following topology:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](graphics/B05453_02_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now run a second container on the same host, but this time specify that the
    network should be that of the primary container `web4`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Our topology now looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](graphics/B05453_02_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Note how the container `web3` is now depicted as being attached directly to
    `web4` rather than to the `docker0` bridge. By looking at the networking configuration
    of each container, we can validate that this is actually the case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the interfaces are identical both in IP configuration as well
    as MAC addresses. Using the syntax of `--net:container<container name/ID>` in
    the `docker run` command joins the new container to the same network construct
    that the referenced container is in. This means that the mapped container has
    the same network configuration as the primary container.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a limitation to this configuration that is worth noting. A container
    that joins another container''s network cannot publish any of its own ports. So
    while this means that we can''t publish ports of mapped containers to the host,
    we can consume them locally. Going back to our example, this means that we can''t
    publish port `8080` of container `web3` to the host. However, container `web4`
    can consume nonpublished services of the container `web3` locally. For instance,
    each of the containers in this example hosts a web service:'
  prefs: []
  type: TYPE_NORMAL
- en: '`web3` hosts a web server running on port `8080`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`web4` hosts a web server running on port `80`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'From an external host perspective, there is no way to access the web service
    of the container `web3`. We can however, access these services through the container
    `web4`. The container `web4` is hosting a PHP script named `test.php` that pulls
    the index pages of its own web server as well as that of a web server running
    on port `8080`. The script is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The script lives in the web server''s root hosting directory (`/var/www/`),
    so we can access the port by browsing to the `web4` container''s published port
    followed by `test.php`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the script is able to pull the index page from both containers.
    Let''s stop the container `web3` and run this test again to prove that it''s really
    the one providing this index page response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we no longer get the response from the mapped container. Mapped
    container mode is useful for scenarios where you need to provide a service to
    an existing container, but don't need to publish any of the mapped container's
    ports directly to the Docker host or outside network. Although there is a limitation
    that mapped containers cannot publish any of their own ports, this does not mean
    we can't publish them ahead of time.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, we could expose port `8080` when we run the primary container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Because we published the port for the mapped container when we ran the primary
    container (`web4`), we don''t need to publish it when we run our mapped container
    (`web3`). We should now be able to access each service directly through its published
    port:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Care should be taken in mapped container mode to not attempt to expose or publish
    the same port on different containers. Since the mapped containers share the same
    network construct as the primary container, this would cause a port conflict.
  prefs: []
  type: TYPE_NORMAL
- en: Connecting containers in host mode
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the configurations we have done up until this point have relied on using
    the `docker0` bridge to facilitate connectivity between containers. We've had
    to consider port mappings, NATing, and container connection points. These considerations
    had to be made because of the nature of how we connect and address containers
    and to ensure a flexible deployment model. Host mode takes a different approach
    and binds containers directly to the Docker host's interfaces. This not only removes
    the need for inbound and outbound NAT but also restricts how we can deploy containers.
    Since the containers will be in the same network construct as the physical host,
    we cannot overlap service ports as this would cause a conflict. In this recipe,
    we'll walk through deploying a container in host mode and describe the pros and
    cons of this approach.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You'll need access to a Docker host and an understanding of how your Docker
    host is connected to the network. In this recipe, we'll be using the `docker1`
    and `docker2` hosts that we used in previous recipes. You'll want to make sure
    that you have access to view `iptables` rules to verify netfilter policies. If
    you wish to download and run example containers, your Docker host will also need
    access to the Internet. In some cases, the changes we make may require you to
    have root-level access to the system.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deploying containers in this mode is rather easy from a Docker point of view.
    Much like mapped container mode where we put one container into another's network
    construct; host mode puts a container directly into the Docker host's network
    construct. Ports no longer need to be published and exposed since you're mapping
    the container directly onto the host's network interfaces. This means that container
    processes can do certain privileged actions such as open lower level ports on
    the host. For this reason, this option should be used with caution as the container
    will have more access to the system in this configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'This also means that Docker is not aware of what port your container is using
    and is unable to prevent you from deploying containers that have overlapping ports.
    Let''s deploy a test container in host mode, so you can see what I mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: To achieve host mode, we pass the `--net=host` flag at container runtime. In
    this case, you can see that without any port mapping, we can still access the
    service living in the container. Docker is simply binding the container to the
    Docker host, which means that any services the container offers are automatically
    mapped to the Docker host's interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we try to run another container offering services on port `80`, we''ll see
    that Docker doesn''t try and stop us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'While that looks like a successful container start from a Docker perspective,
    the container actually died right after being spawned. If we check the logs for
    container `web2`, we''ll see that it ran into a conflict and was unable to start:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Deploying containers in host mode limits the number of services you can run
    unless your containers are built to offer the same service on different ports.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the configuration of the service and what ports it consumes are the responsibility
    of the container, there is a means by which we can deploy multiple containers
    each using the same service port. Take for example our earlier example of two
    Docker hosts, each with two network interfaces:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](graphics/B05453_02_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In a scenario where your Docker host has multiple network interfaces, you can
    have containers binding to the same port but on different interfaces. Again, since
    this is the responsibility of the container, Docker doesn't have any visibility
    into how you achieve this as long as you don't try to bind the same port to multiple
    interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution is to change how services bind to the interfaces. Most services
    bind to all interfaces (`0.0.0.0`) when the service starts. For instance, we can
    see that our container `web1` is bound to `0.0.0.0:80` on the Docker host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Rather than having the service bind to all interfaces, we can limit the scope
    of the service by having it bind to a specific interface. If we can bind a container
    service to only one interface, we can bind the same port to a different interface
    without causing conflict. For the purpose of this example, I''ve created two container
    images that allow you to pass them an environmental variable (`$APACHE_IPADDRESS`).
    The variable is referenced in the Apache configuration and specifies which interface
    the service should bind to. We can test this by deploying two containers in host
    mode to the same host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that in each case, I pass the container a different IP address for it
    to bind to. A quick look at port bindings on the host should confirm the containers
    are no longer binding to all interfaces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that Apache is no longer binding to all interfaces and that we have two
    Apache processes, one bound to each interface of the Docker host. A test from
    the other Docker host will prove that each container is serving Apache on its
    respective interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: While there are some limitations to host mode, it is also less complicated and
    likely offers higher performance because of the lack of NAT and the use of the
    `docker0` bridge.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Keep in mind that since Docker isn't involved in host mode that you may need
    to manually open firewall ports if you have a host-based firewall that is enforcing
    policy in order for the containers to be reachable.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring service-level settings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While many settings can be configured at container runtime, there are some settings
    that must be configured as part of starting the Docker service. That is, they
    need to be defined as a Docker option in the service configuration. In earlier
    recipes, we were exposed to some of these service-level options, such as `--ip-forward`,
    `--userland-proxy`, and `--ip`. In this recipe, we'll cover how you can pass service-level
    parameters to the Docker service as well as discuss the functionality of a few
    key parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You'll need access to a Docker host and an understanding of how your Docker
    host is connected to the network. In this recipe, we'll be using the `docker1`
    and `docker2` hosts that we used in previous recipes. You'll want to make sure
    that you have access to view `iptables` rules to verify netfilter policies. If
    you wish to download and run example containers, your Docker host will also need
    access to the Internet.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to pass runtime options or parameters to the Docker, we need to modify
    the service configuration. In our case, we''re using Ubuntu version 16.04, which
    uses `systemd` to manage services running on the Linux host. The recommended approach
    to passing parameters to Docker is to use a `systemd` drop in file. To create
    the drop in file we can follow these steps to create a service directory and a
    Docker configuration file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Insert the following lines into the `docker.conf` configuration file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'If you wish to pass any parameters to Docker service, you can do so by appending
    them to the third line. For instance, if I wanted to disable Docker automatically
    enabling IP forwarding on the host when the service starts, my file would look
    like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'After making changes to system-related files, you need to ask `systemd` to
    reload the configuration. This is done with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'And finally, you can restart the service for the settings to take effect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Each time you change the configuration, you will need to reload the `systemd`
    configuration as well as restart the service.
  prefs: []
  type: TYPE_NORMAL
- en: docker0 bridge addressing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As we saw earlier, the IP address of the `docker0` bridge is by default `172.17.0.1/16`.
    However, if you wish, you can change this IP address using the `--bip` configuration
    flag. For example, you might wish to change the `docker0` bridge subnet to be
    `192.168.127.1/24`. This can be done by passing the following option to the Docker
    service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'When changing this setting make sure that you configure the IP address (`192.168.127.1/24`)
    rather than the subnet (`192.168.127.0/24`) you wish to define. Previous versions
    of Docker required the host to be rebooted or the existing bridge be manually
    deleted before a new bridge IP could be assigned. In newer versions, you simply
    reload the `systemd` configuration and restart the service for the new bridge
    IP to be assigned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to changing the IP address of the `docker0` bridge, you may also
    define which IP addresses Docker can assign to containers. This is done by using
    the `--fixed-cidr` configuration flag. For instance, assume the following configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'In this scenario, the `docker0` bridge interface itself lives in the `192.168.127.0/24`
    subnet, but we are telling Docker to only assign container IP addresses out of
    the subnet `192.168.127.128/25`. If we add this configuration and once again reload
    `systemd` and restart the service, we can see that Docker will assign the first
    container an IP address of `192.168.127.128`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Since the containers use the defined `docker0` bridge IP address as their default
    gateway, the fixed CIDR range must be a smaller subnet of the one defined on the
    `docker0` bridge itself.
  prefs: []
  type: TYPE_NORMAL
- en: Docker interface binding for published ports
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In some scenarios, you may have a Docker host that has multiple network interfaces
    that live in different network segments. For instance, consider the example where
    you have two hosts that both have two network interfaces:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Docker interface binding for published ports](graphics/B05453_02_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Consider the case where we start a container providing a web service on the
    host `docker1` using this syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, we''ve passed the `-P` flag telling Docker to publish any exposed
    ports present in the image to the Docker host on a random port. If we examine
    the port mapping, we note that while there''s a dynamic port assignment, there
    is not a host IP address assignment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Rather than specifying a specific IP address, Docker specifies all interfaces
    with `0.0.0.0`. This means that the service in the container can be accessed on
    port `32768` on any of the Docker host''s IP interfaces. We can prove this by
    testing from the `docker2` host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'If we wish to limit the interface Docker publishes ports on by default, we
    can pass the `--ip` option to the Docker service. To continue the example, my
    options could now look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Passing these options to the Docker service, and rerunning our container, will
    cause ports to only be mapped to the defined IP address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'And if we run our test from the `docker2` host a second time, we should see
    that the service is only exposed on the `192.168.10.101` interface and not on
    the `10.10.10.101` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Keep in mind that this setting only applies to published ports. This does not
    impact the interface a container might use for outbound connectivity. That is
    dictated by the host's routing table.
  prefs: []
  type: TYPE_NORMAL
- en: Container interface MTU
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In some cases, it may be necessary to change the MTU of the container''s network
    interface. This can be done by passing the `--mtu` option to the Docker service.
    For instance, we may wish to lower the MTU of the container''s interface to `1450`
    to account for some type of encapsulation. To do this, you could pass the following
    flag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'After adding this option, you might examine the `docker0` bridge MTU and find
    it unchanged as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'This is actually expected behavior. Linux bridges, by default, automatically
    use the lowest MTU of any slave interface associated with it. When we told Docker
    to use a MTU of `1450`, we were really telling it to start any containers with
    a MTU of `1450`. Since we have no containers running at this point, the MTU of
    the bridge is unchanged. Let''s start a container to validate this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that the container has the correct MTU of `1450`. Checking the Docker
    host we should see that the MTU of the bridge is now also lower:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: Starting the container with a lower MTU automatically impacted the bridge MTU
    as we expected.
  prefs: []
  type: TYPE_NORMAL
- en: Container default gateway
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By default, Docker sets the default gateway of any containers to that of the
    `docker0` bridge IP address. This makes sense because the containers need to route
    through the `docker0` bridge to reach the outside network. It is, however, possible
    to override this setting and have Docker set the default gateway to another IP
    address on the `docker0` bridge network.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, we can change the default gateway to `192.168.127.50` by passing
    the Docker service these configuration options.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'If we add these settings, restart the service, and spawn a container, we can
    see that the new container has a default gateway of `192.168.127.50` as configured:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: Keep in mind that at this point, this container has no connectivity off it's
    current subnet because that gateway does not currently exist. In order for the
    container to have connectivity off its local subnet `192.168.127.50` would need
    to be reachable from the containers and have connectivity to the outside network.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are other options configured at the service level such as `--iptables`
    and `--icc`. Those will be discussed in later chapters as we discuss their relevant
    use cases.
  prefs: []
  type: TYPE_NORMAL
