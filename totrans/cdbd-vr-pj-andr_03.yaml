- en: Chapter 3. Cardboard Box
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Remember when you were a kid and happy to just play in a cardboard box? This
    project might even be more fun than that! Our first Cardboard project will be
    a simple scene with a box (a geometric cube), a triangle, and a bit of user interaction.
    Let's call it "CardboardBox." Get it?
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, we're going to create a new project, build a simple app that just
    draws a triangle, then enhance the app to draw a shaded 3D cube, and illustrate
    some user interactions by highlighting the cube when you look at it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will be:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a new Cardboard project
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding a triangle object to the scene, including geometry, simple shaders, and
    render buffers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a 3D camera, perspective, and head rotation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using model transformations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making and drawing a cube object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding a light source and shading
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spinning the cube
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding a floor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Highlighting the object that the user is looking at
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The project in this chapter is derived from an example application provided
    by the Google Cardboard team called *Treasure Hunt*. Originally, we considered
    instructing you to simply download Treasure Hunt, and we'd walk you through the
    code explaining how it works. Instead, we decided to build a similar project from
    scratch, explaining as we go along. This also mitigates the possibility that Google
    changes or even replaces that project after this book is published.
  prefs: []
  type: TYPE_NORMAL
- en: The source code for this project can be found on the Packt Publishing website
    and on GitHub at [https://github.com/cardbookvr/cardboardbox](https://github.com/cardbookvr/cardboardbox)
    (with each topic as a separate commit).
  prefs: []
  type: TYPE_NORMAL
- en: The Android SDK version is important to your finished app, but your desktop
    environment can also be set up in a number of ways. We mentioned earlier that
    we used Android Studio 2.1 to build the projects in this book. We also used the
    Java SDK Version 8 (1.8). It will be important for you to have this version installed
    (you can have many versions installed side by side) in order to import the projects.
    As with any development environment, any changes made to Java or Android Studio
    may "break" the import process in the future, but the actual source code should
    compile and run for many years to come.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a new project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you''d like more details and explanation about these steps, refer to the
    *Creating a new Cardboard project* section in [Chapter 2](ch02.html "Chapter 2. The
    Skeleton Cardboard Project"), *The Skeleton Cardboard Project*, and follow along
    there:'
  prefs: []
  type: TYPE_NORMAL
- en: With Android Studio opened, create a new project. Let's name it `CardboardBox`
    and target **Android 4.4 KitKat (API 19)** with an **Empty Activity**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the Cardboard SDK `common.aar` and `core.aar` library files to your project
    as new modules, using **File** | **New** | **New Module...**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the library modules as dependencies to the project app, using **File** |
    **Project Structure**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Edit the `AndroidManifest.xml` file as explained in [Chapter 2](ch02.html "Chapter 2. The
    Skeleton Cardboard Project"), *The Skeleton Cardboard Project*, being careful
    to preserve the `package` name for this project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Edit the `build.gradle` file as explained in [Chapter 2](ch02.html "Chapter 2. The
    Skeleton Cardboard Project"), *The Skeleton Cardboard Project*, to compile against
    SDK 22.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Edit the `activity_main.xml` layout file as explained in [Chapter 2](ch02.html
    "Chapter 2. The Skeleton Cardboard Project"), *The Skeleton Cardboard Project*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Edit the `MainActivity` Java class so that it `extends` `CardboardActivity`
    and `implement``s` `CardboardView.StereoRenderer`. Modify the class declaration
    line as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Add the stub method overrides for the interface (using intellisense implement
    methods or pressing *Ctrl* + *I*).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'At the top of the `MainActivity` class, add the following comments as placeholders
    for variables that we will be creating in this project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, edit `onCreate()` by adding the `CardboadView` instance as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Hello, triangle!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's add a triangle to the scene. Yeah, I know that a triangle isn't even a
    box. However, we're going to start with super simple tips. Triangles are the building
    blocks of all 3D graphics and the simplest shapes that OpenGL can render (that
    is, in triangle mode).
  prefs: []
  type: TYPE_NORMAL
- en: Introducing geometry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before moving on, let's talk a little about geometry.
  prefs: []
  type: TYPE_NORMAL
- en: Virtual reality is largely about creating 3D scenes. Complex models are organized
    as three-dimensional data with vertices, faces, and meshes, forming objects that
    can be hierarchically assembled into more complex models. For now, we're taking
    a really simple approach—a triangle with three vertices, stored as a simple Java
    array.
  prefs: []
  type: TYPE_NORMAL
- en: The triangle is composed of three vertices (that's why, it's called a **tri-angle**!).
    We're going to define our triangle as top (0.0, 0.6), bottom-left (-0.5, -0.3),
    bottom-right (0.5, -0.3). The first vertex is the topmost point of the triangle
    and has *X=0.0*, so it's at the center and *Y=0.6* up.
  prefs: []
  type: TYPE_NORMAL
- en: 'The order of the vertices, or triangle winding, is very important as it indicates
    the front-facing direction of the triangle. OpenGL drivers expect it to wind in
    a counter-clockwise direction, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Introducing geometry](img/B05144_03_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: If the vertices are defined clockwise, the shader will assume that the triangle
    is facing the other direction, away from the camera, and will thus not be visible
    and rendered. This is an optimization called **culling**, which allows the rendering
    pipeline to readily throw away geometry that is on the back side of an object.
    That is, if it is not visible to the camera, don't even bother trying to draw
    it. Having said this, you can set various culling modes to choose to only render
    front faces, back faces, or both.
  prefs: []
  type: TYPE_NORMAL
- en: Refer to the creative commons source at [http://learnopengl.com/#!Advanced-OpenGL/Face-culling](http://learnopengl.com/#!Advanced-OpenGL/Face-culling).
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*The OpenGL Programming Guide* by Dave Shreiner, Graham Sellers, John M. Kessenich,
    Bill Licea-Kane, "*By convention, polygons whose vertices appear in a counter-clockwise
    order on the screen are called front-facing*." This is determined by a global
    state mode, and the default value is `GL_CCW` ([https://www.opengl.org/wiki/Face_Culling](https://www.opengl.org/wiki/Face_Culling)).'
  prefs: []
  type: TYPE_NORMAL
- en: Three-dimensional points, or vertices, are defined with *x*, *y*, and *z* coordinate
    values. A triangle, for example, in 3D space is made up of three vertices, each
    having an *x*, *y*, and *z* value.
  prefs: []
  type: TYPE_NORMAL
- en: Our triangle lies on a plane parallel to the screen. When we add 3D viewing
    to the scene (later in this chapter), we'll need a *z* coordinate to place it
    in 3D space. In anticipation, we'll set the triangle on the *Z=-1* plane. The
    default camera in OpenGL is at the origin (0,0,0) and looks down at the negative
    *z* axis. In other words, objects in the scene are looking up the positive *z*
    axis at the camera. We put the triangle one unit away from the camera so that
    we can see it at *Z=-1.0*.
  prefs: []
  type: TYPE_NORMAL
- en: Triangle variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Add the following code snippet to the top of the `MainActivity` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Our triangle coordinates are assigned to the `triCoords` array. All the vertices
    are in 3D space with three coordinates (*x*, *y*, and *z*) per vertex (`COORDS_PER_VERTEX`).
    The `triVertexCount` variable, precalculated as the length of the triangle's `triCoords`
    array, is divided by `COORDS_PER_VERTEX`. We also define an arbitrary `triColor`
    value for our triangle, which is composed of R, G, B, and A values (red, green,
    blue, and alpha (transparency)). The `triVerticesBuffer` variable will be used
    in the draw code.
  prefs: []
  type: TYPE_NORMAL
- en: For those who are new to Java programming, you might also wonder about the variable
    types. Integers are declared `int` and floating point numbers are declared `float`.
    All the variables here are being declared `private`, which means that they'll
    only be visible and used within this class definition. The ones that are declared
    `static` will share their data across multiple instances of the class. The ones
    that are declared `final` are immutable and are not expected to change once they
    are initialized.
  prefs: []
  type: TYPE_NORMAL
- en: onSurfaceCreated
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The purpose of this activity code is to draw stuff on the Android device display.
    We do this through the OpenGL graphics library, which draws onto a surface, a
    memory buffer onto which you can draw graphics via a rendering pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: After the activity is created (`onCreate`), a surface is created and `onSurfaceCreated`
    is called. It has several responsibilities, including initializing the scene and
    compiling the shaders. It also prepares for rendering by allocating memory for
    vertex buffers, binding textures, and initializing the render pipeline handles.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the method, which we''ve broken into several private methods that we''re
    going to write next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'There''s nothing to initialize in the scene at this point:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Let's move on to the shaders and rendering discussions.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing OpenGL ES 2.0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now is a good time to introduce the *graphics pipeline*. When a Cardboard app
    draws 3D graphics on the screen, it hands the rendering to a separate graphics
    processor (GPU). Android and our Cardboard app uses the OpenGL ES 2.0 standard
    graphics library.
  prefs: []
  type: TYPE_NORMAL
- en: OpenGL is a specification for how applications interact with graphics drivers.
    You could say that it's a long list of function calls that do things in graphics
    hardware. Hardware vendors write their drivers to conform to the latest specification,
    and some intermediary, in this case Google, creates a library that hooks into
    driver functions in order to provide method signatures that you can call from
    whatever language you're using (generally, Java, C++, or C#).
  prefs: []
  type: TYPE_NORMAL
- en: OpenGL ES is the mobile, or **Embedded Systems**, version of OpenGL. It follows
    the same design patterns as OpenGL, but its version history is very different.
    Different versions of OpenGL ES and even different implementations of the same
    version will require different approaches to drawing 3D graphics. Thus, your code
    might differ greatly between OpenGL ES 1.0, 2.0, and 3.0\. Thankfully, most major
    changes happened between Version 1 and 2, and the Cardboard SDK is set up to use
    2.0\. The `CardboardView` interface also varies slightly from a normal `GLSurfaceView`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To draw graphics on the screen, OpenGL needs two basic things:'
  prefs: []
  type: TYPE_NORMAL
- en: The graphics programs, or *shaders* (sometimes used interchangeably), which
    define how to draw shapes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The data, or *buffers*, which define what is being drawn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are also some parameters that specify transformation matrices, colors,
    vectors, and so on. You might be familiar with the concept of a game loop, which
    is a basic pattern to set up the game environment and then initiate a loop that
    runs some game logic, renders the screen, and repeats at a semi-regular interval
    until the game is paused or the program exits. The `CardboardView` sets up the
    game loop for us, and basically, all that we have to do is implement the interface
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'A bit more on shaders: at the bare minimum, we need a vertex shader and a fragment
    shader. The vertex shader is responsible for transforming the vertices of an object
    from world space (where they are in the world) to screen space (where they should
    be drawn on the screen).'
  prefs: []
  type: TYPE_NORMAL
- en: The fragment shader is called on each pixel that the shape occupies (determined
    by the raster function, a fixed part of the pipeline) and returns the color that
    is drawn. Every shader is a single function, accompanied by a number of attributes
    that can be used as inputs.
  prefs: []
  type: TYPE_NORMAL
- en: A collection of functions (that is, a vertex and a fragment) is compiled by
    OpenGL into a program. Sometimes, whole programs are referred to as shaders, but
    this is a colloquialism that assumes the basic knowledge that more than one function,
    or *shader*, is required to fully draw an object. The program and the values for
    all its parameters will sometimes be referred to as a *material*, given that it
    completely describes the material of the surface that it draws.
  prefs: []
  type: TYPE_NORMAL
- en: Shaders are cool. However, they don't do anything until your program sets up
    the data buffers and makes a bunch of draw calls.
  prefs: []
  type: TYPE_NORMAL
- en: A draw call consists of a **Vertex Buffer Object** (**VBO**), the shaders that
    will be used to draw it, a number of parameters that specify the transformation
    applied to the object, the texture(s) used to draw it, and any other shader parameters.
  prefs: []
  type: TYPE_NORMAL
- en: The VBO refers to any and all data used to describe the shape of an object.
    A very basic object (for example, a triangle) only needs an array of vertices.
    The vertices are read in order, and every three positions in space define a single
    triangle. Slightly more advanced shapes use an array of vertices and an array
    of indices, which define which vertices to draw in what order. Using an index
    buffer, multiple vertices can be re-used.
  prefs: []
  type: TYPE_NORMAL
- en: While OpenGL can draw a number of shape types (a point, line, triangle, and
    quad), we will assume that all are triangles. This is both a performance optimization
    and a matter of convenience. If we want a quad, we can draw two triangles. If
    we want a line, we can draw a really long, skinny quad. If we want a point, we
    can draw a tiny triangle. This way, not only can we leave OpenGL in triangle mode,
    but we can also treat all VBOs in exactly the same manner. Ideally, you want your
    render code to be completely agnostic to what it is rendering.
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize:'
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of the OpenGL graphics library is to give us access to the GPU hardware,
    which then paints pixels on the screen based on the geometry in a scene. This
    is achieved through a rendering pipeline, where data is transformed and passed
    through a series of shaders.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A shader is a small program that takes certain inputs and generates corresponding
    outputs, depending on the stage of the pipeline.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a program, shaders are written in a special C-like language. The source code
    is compiled to be run very efficiently on the Android device's GPU.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, a *vertex shader* handles processing individual vertices, outputting
    a transformed version of each one. Another step rasterizes the geometry, after
    which a *fragment shader* receives a raster fragment and outputs colored pixels.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We'll be discussing the OpenGL rendering pipeline later on, and you can read
    about it at [https://www.opengl.org/wiki/Rendering_Pipeline_Overview](https://www.opengl.org/wiki/Rendering_Pipeline_Overview).
  prefs: []
  type: TYPE_NORMAL
- en: You can also review the Android OpenGL ES API Guide at [http://developer.android.com/guide/topics/graphics/opengl.html](http://developer.android.com/guide/topics/graphics/opengl.html).
  prefs: []
  type: TYPE_NORMAL
- en: For now, don't worry too much about it and let's just follow along.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: GPU drivers actually implement the entire OpenGL library on a per-driver
    basis. This means that someone at NVIDIA (or in this case, probably Qualcomm or
    ARM) wrote the code that compiles your shaders and reads your buffers. OpenGL
    is a specification for how this API should work. In our case, this is the GL class
    that''s part of Android.'
  prefs: []
  type: TYPE_NORMAL
- en: Simple shaders
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Presently, we''ll write a couple of simple shaders. Our shader code will be
    written in a separate file, which is loaded and compiled by our app. Add the following
    functions at the end of the `MainActivity` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We will call `loadShader` to load a shader program (via `readRawTextFile`) and
    compile it. This code will be useful in other projects as well.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we'll write a couple of simple shaders in the `res/raw/simple_vertex.shader`
    and `res/raw/simple_fragment.shader` files.
  prefs: []
  type: TYPE_NORMAL
- en: In the **Project Files** hierarchy view, on the left-hand side of Android Studio,
    locate the `app/res/` resource folder, right-click on it, and go to **New** |
    **Android Resource Directory**. In the **New Resource Directory** dialog box,
    from **Resource Type:**, select **Raw**, and then click on **OK**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Right-click on the new `raw` folder, go to **New** | **File**, and name it
    `simple_vertex.shader`. Add the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, for the fragment shader, right-click on the `raw` folder, go to
    **New** | **File**, and name it `simple_fragment.shader`. Add the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Basically, these are identity functions. The vertex shader passes through the
    given vertex, and the fragment shader passes through the given color.
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice the names of the parameters that we declared: an attribute named `a_Position`
    in `simple_vertex` and a uniform variable named `u_Color` in `simple_fragment`.
    We''ll set these up from the `MainActivity onSurfaceCreated` method. Attributes
    are properties of each vertex, and when we allocate buffers for them, they must
    all be arrays of equal length. Other attributes that you will encounter are vertex
    normals, texture coordinates, and vertex colors. Uniforms will be used to specify
    information that applies to the whole material, such as in this case, the solid
    color applied to the whole surface.'
  prefs: []
  type: TYPE_NORMAL
- en: Also, note that the `gl_FragColor` and `gl_Position` variables are built-in
    variable names that OpenGL is looking for you to set. Think of them as the returns
    on your shader function. There are other built-in output variables, which we will
    see later.
  prefs: []
  type: TYPE_NORMAL
- en: The compileShaders method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We're now ready to implement the `compileShaders` method that `onSurfaceCreated`
    calls.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following variables on top of `MainActivity`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement `compileShaders`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The prepareRenderingTriangle method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `onSurfaceCreated` method prepares for rendering by allocating memory for
    vertex buffers, creating OpenGL programs, and initializing the render pipeline
    handles. We will do this for our triangle shape now.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following variables on top of `MainActivity`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s a skeleton of the function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to prepare some memory buffers that will be passed to OpenGL when each
    frame is rendered. This is the first go-round for our triangle and simple shaders;
    we now only need a vertex buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'These five lines of code result in the setting up of the `triVerticesBuffer`
    value, which are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A `ByteBuffer` is allocated that is big enough to hold our triangle coordinate
    values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The binary data is arranged to match the hardware's native byte order
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The buffer is formatted for a floating point and assigned to our `FloatBuffer`
    vertex buffer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The triangle data is put into it, and then we reset the buffer cursor position
    to the beginning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, we build the OpenGL ES program executable. Create an empty OpenGL ES
    program using `glCreateProgram`, and assign its ID as `triProgram`. This ID will
    be used in other methods as well. We attach any shaders to the program, and then
    build the executable with `glLinkProgram`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we get a handle on the render pipeline. A call to `glGetAttribLocation`
    on `a_Position` retrieves the location of the vertex buffer parameter, `glEnableVertexAttribArray`
    gives permission to access it, and a call to `glGetUniformLocation` on `u_Color`
    retrieves the location of the color components. We''ll be happy that we did this
    once we get to `onDrawEye`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: So, we've isolated the code needed to prepare a drawing of the triangle model
    in this function. First, it sets up buffers for the vertices. Then, it creates
    a GL program, attaching the shaders it'll use. Then, we get handles to the parameters
    in the shaders that we'll use to draw.
  prefs: []
  type: TYPE_NORMAL
- en: onDrawEye
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Ready, Set, and Go!* If you think of what we''ve written so far as the "Ready
    Set" part, now we do the "Go" part! That is, the app starts and creates the activity,
    calling `onCreate`. The surface is created and calls `onSurfaceCreated` to set
    up the buffers and shaders. Now, as the app runs, for each frame, the display
    is updated. Go!'
  prefs: []
  type: TYPE_NORMAL
- en: The `CardboardView.StereoRenderer` interface delegates these methods. We can
    handle `onNewFrame` (and will later on). For now, we'll just implement the `onDrawEye`
    method, which will draw the contents from the point of view of an eye. This method
    gets called twice, once for each eye.
  prefs: []
  type: TYPE_NORMAL
- en: 'All that `onDrawEye` needs to do for now is render our lovely triangle. Nonetheless,
    we''ll split it into a separate function (that''ll make sense later):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We need to specify which shader program we are using by calling `glUseProgram`.
    A call to `glVertexAttribPointer` sets our vertex buffer to the pipeline. We also
    set the color using `glUniform4fv` (`4fv` refers to the fact that our uniform
    is a vector with four floats). Then, we actually draw using `glDrawArrays`.
  prefs: []
  type: TYPE_NORMAL
- en: Building and running
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: That's it. *Yee haa!* That wasn't so bad, was it? Actually, if you're familiar
    with Android development and OpenGL, you might have breezed through this.
  prefs: []
  type: TYPE_NORMAL
- en: Let's build and run it. Go to **Run** | **Run 'app'**, or simply use the green
    triangle **Run** icon on the toolbar.
  prefs: []
  type: TYPE_NORMAL
- en: Gradle will do its build thing. Select the **Gradle Console** tab at the bottom
    of the Android Studio window to view the Gradle build messages. Then, assuming
    that all goes well, the APK file will be installed on your connected phone (it's
    connected and turned on, right?). Select the **Run** tab at the bottom to view
    the upload and launch messages.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what it displays:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Building and running](img/B05144_03_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Actually, it kind of looks like a Halloween pumpkin carving! *Spooky*. But in
    VR you'll see just a single triangle.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that while the triangle vertex coordinates define edges with straight
    lines, the `CardboardView` renders it with barrel distortion to compensate for
    the lens optics in the headset. Also, the left image is different from the right,
    one for each eye. When you insert the phone in a Google Cardboard headset, the
    left and right stereoscopic views appear as one triangle floating in space with
    straight edges.
  prefs: []
  type: TYPE_NORMAL
- en: That's great! We just built a simple Cardboard app for Android from scratch.
    Like any Android app, there are a number of different pieces that need to be defined
    just to get a basic thing going, including the `AndroidManifest.xml`, `activity_main.xml`,
    and `MainActivity.java` files.
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully everything went as planned. Like a good programmer, you've probably
    been building and running the app after making incremental changes to the account
    for syntax errors and unhandled exceptions. A little bit later, we will call the
    GLError function to check error information from OpenGL. As always, pay close
    attention to errors in logcat (try filtering for the running application) and
    to variable names. You might have a syntax error in your shader, causing its compiling
    to fail, or you might have a typo in the attribute/uniform name when trying to
    access the handles. These kind of things will not result in any compile-time errors
    (shaders are compiled at runtime), and your app will run but may not render anything
    as a result.
  prefs: []
  type: TYPE_NORMAL
- en: 3D camera, perspective, and head rotation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As awesome as this is (*ha ha*), our app is kind of boring and not very Cardboard-like.
    Specifically, it's stereoscopic (dual views) and has lens distortion, but it's
    not yet a 3D perspective view and it doesn't move with your head. We're going
    to fix this now.
  prefs: []
  type: TYPE_NORMAL
- en: Welcome to the matrix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can't talk about developing for virtual reality without talking about matrix
    mathematics for 3D computer graphics.
  prefs: []
  type: TYPE_NORMAL
- en: What is a matrix? The answer is out there, Neo, and it's looking for you, and
    it will find you if you want it to. That's right, it's time to learn about the
    matrix. Everything will be different now. Your perspective is about to change.
  prefs: []
  type: TYPE_NORMAL
- en: We're building a three-dimensional scene. Each location in space is described
    by the X, Y, and Z coordinates. Objects in the scene may be constructed from X,
    Y, and Z vertices. An object can be transformed by moving, scaling, and/or rotating
    its vertices. This transformation can be represented mathematically with a matrix
    of 16 floating point values (four rows of four floats each). How it works mathematically
    is cool, but we won't get into it here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Matrices can be combined by multiplying them together. For example, if you
    have a matrix that represents how much to resize an object (scale) and another
    matrix to reposition (translate), then you could make a third matrix, representing
    both the resizing and repositioning by multiplying the two together. You can''t
    just use the primitive `*` operator though. Also, note that unlike a simple scalar
    multiplication, matrix multiplication is not commutative. In other words, we know
    that *a * b = b * a*. However, for matrices A and B, *AB ≠ BA*! The Matrix Android
    class library provides functions for doing matrix math. Here''s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Note that due to the way in which matrix multiplication works, multiplying a
    vector by the result matrix will have the same effect as first multiplying it
    by the scale matrix (right-hand side), and then multiplying it by the translate
    matrix (left-hand side). This is the opposite of what you might expect.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The documentation of the Matrix API can be found at [http://developer.android.com/reference/android/opengl/Matrix.html](http://developer.android.com/reference/android/opengl/Matrix.html).
  prefs: []
  type: TYPE_NORMAL
- en: This matrix stuff will be used a lot. Something that is worth mentioning here
    is precision loss. You might get a "drift" from the actual values if you repeatedly
    scale and translate that combined matrix because floating point calculations lose
    information due to rounding. It's not just a problem for computer graphics but
    also for banks and Bitcoin mining! (Remember the movie *Office Space*?)
  prefs: []
  type: TYPE_NORMAL
- en: One fundamental use of this matrix math, which we need immediately, is to transform
    a scene into a screen image (projection) as viewed from the user's perspective.
  prefs: []
  type: TYPE_NORMAL
- en: In a Cardboard VR app, to render the scene from a particular viewpoint, we think
    of a camera that is looking in a specific direction. The camera has X, Y, and
    Z positions like any other object and is rotated to its view direction. In VR,
    when you turn your head, the Cardboard SDK reads the motion sensors in your phone,
    determines the current head pose (the view direction and angles), and gives your
    app the corresponding transformation matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, in VR for each frame, we render two slightly different perspective
    views: one for each eye, offset by the actual distance between one''s eyes (the
    interpupillary distance).'
  prefs: []
  type: TYPE_NORMAL
- en: Also, in VR, we want to render the scene using a perspective projection (versus
    isometric) so that objects closer to you appear larger than the ones further away.
    This can be represented with a 4 x 4 matrix as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can combine each of these transformations by multiplying them together to
    get a `modelViewProjection` matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: A complete `modelViewProjection` (MVP) transformation matrix is a combination
    of any model transforms (for example, scaling or positioning the model in the
    scene) with the camera eye view and perspective projection.
  prefs: []
  type: TYPE_NORMAL
- en: When OpenGL goes to draw an object, the vertex shader can use this `modelViewProjection`
    matrix to render the geometry. The whole scene gets drawn from the user's viewpoint,
    in the direction his head is pointing, with a perspective projection for each
    eye to appear stereoscopically through your Cardboard viewer. VR MVP FTW!
  prefs: []
  type: TYPE_NORMAL
- en: The MVP vertex shader
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The super simple vertex shader that we wrote earlier doesn't transform each
    vertex; it just passed it through the next step in the pipeline. Now, we want
    it to be 3D-aware and use our `modelViewProjection` (MVP) transformation matrix.
    Create a shader to handle it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the hierarchy view, right-click on the `app/res/raw` folder, go to **New**
    | **File**, enter the name, `mvp_vertex.shader`, and click on **OK**. Write the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This shader is almost the same as `simple_vertex` but transforms each vertex
    by the `u_MVP` matrix. (Note that while multiplying matrices and vectors with
    `*` does not work in Java, it does work in the shader code!)
  prefs: []
  type: TYPE_NORMAL
- en: 'Replace the shader resource in the `compleShaders` function to use `R.raw.mvp_vertex`
    instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Setting up the perspective viewing matrices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To add the camera and view to our scene, we define a few variables. In the
    `MainActivity.java` file, add the following code to the beginning of the `MainActivity`
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The `Z_NEAR` and `Z_FAR` constants define the depth planes used later to calculate
    the perspective projection for the camera eye. `CAMERA_Z` will be the position
    of the camera (for example, at X=0.0, Y=0.0, and Z=0.01).
  prefs: []
  type: TYPE_NORMAL
- en: The `triMVPMatrixParam` variable will be used to set the model transformation
    matrix in our improved shader.
  prefs: []
  type: TYPE_NORMAL
- en: The `camera`, `view`, and `modelViewProjection` matrices will be 4 x 4 matrices
    (an array of 16 floats) used for perspective calculations.
  prefs: []
  type: TYPE_NORMAL
- en: 'In `onCreate`, we initialize the `camera`, `view`, and `modelViewProjection`
    matrices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'In `prepareRenderingTriangle`, we initialize the `triMVPMatrixParam` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The default camera in OpenGL is at the origin (0,0,0) and looks down at the
    negative *Z* axis. In other words, objects in the scene are facing toward the
    positive *Z* axis at the camera. To place them in front of the camera, give them
    a position with some negative Z value.
  prefs: []
  type: TYPE_NORMAL
- en: There is a longstanding (and pointless) debate in the 3D graphics world about
    which axis is up. We can somehow all agree that the *X* axis goes left and right,
    but does the *Y* axis go up and down, or is it Z? Plenty of software picks Z as
    the up-and-down direction, and defines Y as pointing in and out of the screen.
    On the other hand, the Cardboard SDK, Unity, Maya, and many others choose the
    reverse. If you think of the coordinate plane as drawn on graph paper, it all
    depends on where you put the paper. If you think of the graph as you look down
    from above, or draw it on a whiteboard, then *Y* is the vertical axis. If the
    graph is sitting on the table in front of you, then the *missing* *Z* axis is
    vertical, pointing up and down. In any case, the Cardboard SDK, and therefore
    the projects in this book, treat Z as the *forward and backward* axis.
  prefs: []
  type: TYPE_NORMAL
- en: Render in perspective
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With things set up, we can now handle redrawing the screen for each frame.
  prefs: []
  type: TYPE_NORMAL
- en: First, set the camera position. It can be defined once, like in `onCreate`.
    But, often in a VR application, the camera position in the scene can change, so
    we'll reset it for each frame.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing to do is reset the camera matrix at the start of a new frame
    to a generic front-facing direction. Define the `onNewFrame` method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note, as you write `Matrix`, Android Studio will want to auto-import the package.
    Ensure that the import you choose is `android.opengl.Matrix`, and not some other
    matrix library, such as `android.graphic.Matrix`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, when it''s time to draw the scene from the viewpoint of each eye, we calculate
    the perspective view matrix. Modify `onDrawEye` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The first two lines that we added reset the OpenGL depth buffer. When 3D scenes
    are rendered, in addition to the color of each pixel, OpenGL keeps track of the
    distance the object occupying that pixel is from the eye. If the same pixel is
    rendered for another object, the depth buffer will know whether it should be visible
    (closer) or ignored (further away). (Or, perhaps the colors get combined in some
    way, for example, transparency). We clear the buffer before rendering any geometry
    for each eye. The color buffer, which is the one you actually see on screen, is
    also cleared. Otherwise, in this case, you would end up filling the entire screen
    with a solid color.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's move on to the viewing transformations. `onDrawEye` receives the
    current `Eye` object, which describes the stereoscopic rendering details of the
    eye. In particular, the `eye.getEyeView()` method returns a transformation matrix
    that includes head tracking rotation, position shift, and interpupillary distance
    shift. In other words, where the eye is located in the scene and what direction
    it's looking. Though Cardboard does not offer positional tracking, the positions
    of the eyes do change in order to simulate a virtual head. Your eyes don't rotate
    on a central axis, but rather your head pivots around your neck, which is a certain
    distance from the eyes. As a result, when the Cardboard SDK detects a change in
    orientation, the two virtual cameras move around the scene as though they were
    actual eyes in an actual head.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need a transformation that represents the perspective view of the camera
    at this eye''s position. As mentioned earlier, this is calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: We multiply the `camera` by the eye view transform (`getEyeView`), then multiply
    the result by the perspective projection transform (`getPerspective`). Presently,
    we do not transform the triangle model itself and leave the `modelTransform` matrix
    out.
  prefs: []
  type: TYPE_NORMAL
- en: The result (`modelViewProjection`) is passed to OpenGL to be used by the shaders
    in the rendering pipeline (via `glUniformMatrix4fv`). Then, we draw our stuff
    (via `glDrawArrays` as written earlier).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we need to pass the view matrix to the shader program. In the `drawTriangle`
    method, add it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Building and running
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's build and run it. Go to **Run** | **Run 'app'**, or simply use the green
    triangle **Run** icon on the toolbar. Now, moving the phone will change the display
    synchronized with your view direction. Insert the phone in a Google Cardboard
    viewer and it's like VR (*kinda sorta*).
  prefs: []
  type: TYPE_NORMAL
- en: Note that if your phone is lying flat on the table when the app starts, the
    camera in our scene will be facing straight down rather than forward at our triangle.
    What's worse, when you pick up the phone, the neutral direction may not be facing
    straight in front of you. So, each time you run apps in this book, pick up the
    phone first, so you look forward in VR, or keep the phone propped up in position
    (personally, I use a Gekkopod, which is available at [http://gekkopod.com/](http://gekkopod.com/)).
  prefs: []
  type: TYPE_NORMAL
- en: Also, in general, make sure that your phone is not set to **Lock Portrait**
    in the **Settings** dialog box.
  prefs: []
  type: TYPE_NORMAL
- en: Repositioning the triangle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our matrix-fu has really gotten us places. Let's go further.
  prefs: []
  type: TYPE_NORMAL
- en: I want to move the triangle out of the way. We'll do this by setting up another
    transformation matrix and then using it on the model when it's time to draw.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add two new matrices named `triTransform` and `triView`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Initialize them in `onCreate` as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s set the model matrix that positions the triangle in the `initializeScene`
    method (called by `onSurfaceCreated`). We''ll offset it by 5 units in X and backwards
    5 units in Z. Add the following code to `initializeScene`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we use the model matrix to build the `modelViewProjection` matrix in
    `onDrawEye`. Modify `onDrawEye`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Build and run it. You will now see the triangle further away and off to the
    side.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To summarize one more time: the `modelViewProjection` matrix is a combination
    of the triangle''s position transform (`triTransform`), the camera''s location
    and orientation (`camera`), the current eye''s viewpoint from `CardboardView`
    based on the phone''s motion sensors (`eye.getEyeView`), and the `perspective`
    projection. This MVP matrix is handed to the vertex shader to determine its actual
    location when drawing the triangle on the screen.'
  prefs: []
  type: TYPE_NORMAL
- en: Hello, cube!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A flat triangle floating in 3D space may be amazing, but it''s nothing compared
    to what we''re going to do next: a 3D cube!'
  prefs: []
  type: TYPE_NORMAL
- en: The cube model data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The triangle, with just three vertices, was declared in the `MainActivity` class
    to keep the example simple. Now, we will introduce more complex geometry. We'll
    put it in a class named `Cube`.
  prefs: []
  type: TYPE_NORMAL
- en: Okay, it's just a cube that is composed of eight distinct vertices, forming
    six faces, right?
  prefs: []
  type: TYPE_NORMAL
- en: Well, GPUs prefer to render triangles rather than quads, so subdivide each face
    into two triangles; that's 12 triangles in total. To define each triangle separately,
    that's a total of 36 vertices, with proper winding directions, defining our model,
    as shown in `CUBE_COORDS`. Why not just define eight vertices and reuse them?
    We'll show you how to do this later.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Remember that we always need to be careful of the winding order of the vertices
    (counter-clockwise) so that the visible side of each triangle is facing outward.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Android Studio, in the Android project hierarchy pane on the left-hand side,
    find your Java code folder (such as `com.cardbookvr.cardboardbox`). Right-click
    on it, and go to **New** | **Java Class**. Then, set **Name: Cube**, and click
    on **OK**. Then, edit the file, as follows (remember that the code for the projects
    in this book are available for download from the publisher''s website and from
    the book''s public GitHub repositories):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Cube code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Returning to the `MainActivity` file, we'll just copy/paste/edit the triangle
    code and reuse it for the cube. Obviously, this isn't ideal, and once we see a
    good pattern, we can abstract out some of this into reusable methods. Also, we'll
    use the same shaders as those of the triangle, and then in the next section, we'll
    replace them with a better lighting model. That is to say, we'll implement lighting
    or what a 2D artist might call **shading**, which we haven't done so far.
  prefs: []
  type: TYPE_NORMAL
- en: 'Like the triangle, we declare a bunch of variables that we are going to need.
    The vertex count, obviously, should come from the new `Cube.CUBE_COORDS` array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following code to `onCreate`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following code to `onSurfaceCreated`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Write the `prepareRenderingCube` method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'We will position the cube 5 units away and rotate it 30 degrees on a diagonal
    axis of (1, 1, 0). Without the rotation, we''ll just see the square of the front
    face. Add the following code to `initializeScene`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following code to `onDrawEye` to calculate the MVP matrix, including
    the `cubeTransform` matrix, and then draw the cube:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Write the `drawCube` method, which is very similar to the `drawTri` method,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Build and run it. You will now see a 3D view of the cube, as shown in the following
    screenshot. It needs shading.
  prefs: []
  type: TYPE_NORMAL
- en: '![Cube code](img/B05144_03_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Lighting and shading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We need to introduce a light source into the scene and provide a shader that
    will use it. For this, the cube needs additional data, defining normal vectors
    and colors at each vertex.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Vertex colors aren't always required for shading, but in our case, the gradient
    is very subtle, and the different color faces will help you distinguish the edges
    of the cube. We will also be doing shading calculations in the vertex shader,
    which is a faster way to do it (there are fewer vertices than raster pixels),
    but works less well for smooth objects, such as spheres. To do vertex lighting,
    you need vertex colors in the pipeline, so it also makes sense to do something
    with those colors. In this case, we choose a different color per face of the cube.
    Later in this book, you will see an example of per-pixel lighting and the difference
    it makes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll now build the app to handle our lighted cube. We''ll do this by performing
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Write and compile a new shader for lighting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generate and define cube vertex normal vectors and colors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Allocate and set up data buffers for rendering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define and set up a light source for rendering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generate and set up transformation matrices for rendering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding shaders
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's write an enhanced vertex shader that can use a light source and vertex
    normals from a model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Right-click on the `app/res/raw` folder in the project hierarchy, go to **New**
    | **File**, and name it `light_vertex.shader`. Add the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Without going through the details of writing a lighting shader, you can see
    that the vertex color is calculated based on a formula related to the angle between
    the light ray and the surface and how far the light source is from the vertex.
    Note that we are also bringing in the `ModelView` matrix as well as the MVP matrix.
    This means that you will need to have access to both steps of the process, and
    you can't overwrite/throw away the MV matrix after you're done with it.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that we used a small optimization. Numeric literals (for example, `1.0`)
    use uniform space, and on certain hardware, this can cause problems, so we declare
    constants instead (refer to [http://stackoverflow.com/questions/13963765/declaring-constants-instead-of-literals-in-vertex-shader-standard-practice-or](http://stackoverflow.com/questions/13963765/declaring-constants-instead-of-literals-in-vertex-shader-standard-practice-or)).
  prefs: []
  type: TYPE_NORMAL
- en: There are more variables to be set in this shader, as compared to the earlier
    simple one, for the lighting calculations. We'll send these over to the draw methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also need a slightly different fragment shader. Right-click on the `raw`
    folder in the project hierarchy, go to **New** | **File**, and name it `passthrough_fragment.shader`.
    Add the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: The only difference in the fragment shader from the simple one is that we replace
    uniform `vec4 u_Color` with varying `vec4 v_Color` because colors are now passed
    in from the vertex shader in the pipeline. And the vertex shader now gets an array
    buffer of colors. This is a new issue that we'll need to address in our setup/draw
    code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, in `MainActivity`, add these variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Compile the shader in the `compileShaders` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Cube normals and colors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Each face of a cube faces outwards in a different direction that's perpendicular
    to the face. A vector is an XYZ coordinate. One that is normalized to a length
    of 1 can be used to indicate this direction, and is called a **normal vector**.
  prefs: []
  type: TYPE_NORMAL
- en: The geometry we pass to OpenGL is defined as vertices, not faces. Therefore,
    we need to provide a normal vector for each vertex of the face, as shown in the
    following diagram. Strictly speaking, not all vertices on a given face have to
    face the same direction. This is used in a technique called **smooth shading**,
    where the lighting calculations give the illusion of a curved face instead of
    a flat one. We will be using the same normal for each face (**hard edges**), which
    also saves us time while specifying the normal data. Our array only needs to specify
    six vectors, which can be expanded into a buffer of 36 normal vectors. The same
    applies to color values.
  prefs: []
  type: TYPE_NORMAL
- en: '![Cube normals and colors](img/B05144_03_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Each vertex also has a color. Assuming that each face of the cube is a solid
    color, we can assign each vertex of that face the same color. In the `Cube.java`
    file, add the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: For each face of the cube, we defined a solid color (`CUBE_COLORS_FACES`) and
    a normal vector (`CUBE_NORMALS_FACES`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, write a reusable method, `cubeFacesToArray`, to generate the float arrays
    actually needed in `MainActivity`. Add the following code to your `Cube` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Add this data to `MainActivity` with the other variables, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: You can also delete the declaration of `private float cubeColor[]`, as it's
    not needed now.
  prefs: []
  type: TYPE_NORMAL
- en: Armed with a normal and color, the shader can calculate the values of each pixel
    occupied by the object.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the vertex buffers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The rendering pipeline requires that we set up memory buffers for the vertices,
    normals, and colors. We already have vertex buffers from before, we now need to
    add the others.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the variables, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Prepare the buffers, and add the following code to the `prepareRenderingCube`
    method (called from `onSurfaceCreated`). (This is the first half of the full `prepareRenderingCube`
    method):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Preparing the shaders
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Having defined the `lighting_vertex` shader, we need to add the param handles
    to use it. At the top of the `MainActivity` class, add four more variables to
    the lighting shader params:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `prepareRenderingCube` method (which is called by `onSurfaceCreated`),
    attach the `lightVertexShader` and `passthroughFragmentShader` shaders instead
    of the simple ones, get the shader params, and enable the arrays so that they
    now read as follows. (This is the second half of `prepareRenderingCube`, continuing
    from the preceding section):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: If you refer to the shader code that we wrote earlier, you'll notice that these
    calls to `glGetUniformLocation` and `glGetAttribLocation` correspond to the `uniform`
    and `attribute` parameters declared in those scripts, including the change of
    `cubeColorParam` from `u_Color` to now `a_Color`. This renaming is not required
    by OpenGL, but it helps us distinguish between vertex attributes and uniforms.
  prefs: []
  type: TYPE_NORMAL
- en: Shader attributes that reference array buffers must be enabled.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a light source
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next, we'll add a light source to our scene and tell the shader its position
    when we draw. The light will be positioned just above the user.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the top of `MainActivity`, add variables to the light position:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Calculate the position of the light by adding the following code to `onDrawEye`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Note that we're using the `view` matrix (the eye `view *` `camera`) to transform
    the light position into the current view space using the `Matrix.multiplyMV` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we just tell the shader about the light position and the viewing matrices
    it needs. Modify the `drawCube` method (called by `onDrawEye`), as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Building and running the app
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We are now ready to go. When you build and run the app, you will see a screen
    similar to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Building and running the app](img/B05144_03_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Spinning the cube
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next step is a quick one. Let''s make the cube spin. This is achieved by
    rotating the `cubeTransform` matrix a little bit for each frame. We can define
    a `TIME_DELTA` value for this. Add the static variable, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, modify `cubeTransform` for each frame, and add the following line of
    code to the `onNewFrame` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: The `Matrix.rotateM` function applies a rotation to a transformation matrix
    based on an angle and an axis. In this case, we are rotating by an angle of `TIME_DELTA`
    around the axis vector (0.5, 0.5, 1). Strictly speaking, you should provide a
    normalized axis, but all that matters is the direction of the vector and not the
    magnitude.
  prefs: []
  type: TYPE_NORMAL
- en: Build and run it. Now the cube is spinning. *Animazing!*
  prefs: []
  type: TYPE_NORMAL
- en: Hello, floor!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having a sense of being grounded can be important in virtual reality. It can
    be much more comfortable to feel like you're standing (or sitting) than to be
    floating in space like a bodyless eyeball. So, let's add a floor to our scene.
  prefs: []
  type: TYPE_NORMAL
- en: This should be much more familiar now. We'll have a shader, model, and rendering
    pipeline similar to the cube. So, we'll just do it without much explanation.
  prefs: []
  type: TYPE_NORMAL
- en: Shaders
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The floor will use our `light_shader` with a small modification and a new fragment
    shader.
  prefs: []
  type: TYPE_NORMAL
- en: 'Modify the `light_vertex.shader` by adding a `v_Grid` variable, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a new shader in `app/res/raw` named `grid_fragment.shader`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: It may seem complicated, but all that we are doing is drawing some grid lines
    on a solid color shader. The `if` statement will detect whether we are within
    0.1 units of a multiple of 10\. If so, we draw a color that is somewhere between
    white (1, 1, 1, 1) and `v_Color`, based on the depth of that pixel, or its distance
    from the camera. `gl_FragCoord` is a built-in value that gives us the position
    of the pixel that we are rendering in window space as well as the value in the
    depth buffer (`z`), which will be within the range [0, 1]. The fourth parameter,
    `w`, is essentially the inverse of the camera's draw distance and, when combined
    with the depth value, gives the world-space depth of the pixel. The `v_Grid` variable
    has actually given us access to the world-space position of the current pixel,
    based on the local vertex position and the model matrix that we introduced in
    the vertex shader.
  prefs: []
  type: TYPE_NORMAL
- en: 'In `MainActivity`, add a variable for the new fragment shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Compile the shader in the `compileShaders` method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Floor model data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Create a new Java file named `Floor` in the project. Add the floor plane coordinates,
    normals, and colors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Add all the variables that we need to `MainActivity`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: onCreate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Allocate the matrices in `onCreate`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: onSurfaceCreated
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Add a call to `prepareRenderingFloor` in `onSufraceCreated`, which we''ll write
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: initializeScene
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Set up the `floorTransform` matrix in the `initializeScene` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: prepareRenderingFloor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here''s the complete `prepareRenderingFloor` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: onDrawEye
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Calculate MVP and draw the floor in `onDrawEye`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: drawFloor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Define a `drawFloor` method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Build and run it. It will now look like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![drawFloor](img/B05144_03_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Woot!*'
  prefs: []
  type: TYPE_NORMAL
- en: Hey, look at this!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last part of the project, we add a feature that detects when you're looking
    at an object (the cube) and highlights it with a different color.
  prefs: []
  type: TYPE_NORMAL
- en: This is accomplished with the help of the `CardboardView` interface method,
    `onNewFrame`, which passes the current head transformation information.
  prefs: []
  type: TYPE_NORMAL
- en: The isLookingAtObject method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s start with the most interesting part. We''ll borrow the `isLookingAtObject`
    method from Google''s Treasure Hunt demo. It checks whether the user is looking
    at an object by calculating where the object is in the eye space and returns true
    if the user is looking at the object. Add the following code to `MainActivity`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'The method takes two arguments: the `modelView` and `modelTransform` transformation
    matrices of the object we want to test. It also references the `headView` class
    variable, which we''ll set in `onNewFrame`.'
  prefs: []
  type: TYPE_NORMAL
- en: A more precise way to do this might be to cast a ray from the camera into the
    scene in the direction in which the camera is looking and determines whether it
    intersects any geometry in the scene. This will be very effective but also very
    computationally expensive.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, this function takes a simpler approach and doesn't even use the geometry
    of the object. It rather uses the object's view transform to determine how far
    the object is from the center of the screen and tests whether the angle of that
    vector is within a narrow range (`PITCH_LIMIT` and `YAW_LIMIT`). *Yeah I know,
    people get PhDs to come up with this stuff!*
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s define the variables that we need as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Allocate `headView` in `onCreate`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Get the current `headView` value on each new frame. Add the following code
    to `onNewFrame`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, modify `drawCube` to check whether the user is looking at the cube and
    decide which colors to use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '*That''s it!* Except for one (minor) detail: we need a second set of vertex
    colors for the highlight mode. We''ll highlight the cube by drawing all the faces
    with the same yellow color. There are a few changes to be made in order to make
    this happen.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In `Cube`, add the following RGBA values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'In `MainActivity`, add these variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following code to the `prepareRenderingCube` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: Build and run it. When you look directly at the cube, it gets highlighted.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It may be more fun and challenging if the cubes weren't so close. Try setting
    `cubeDistance` to something like *12f*.
  prefs: []
  type: TYPE_NORMAL
- en: Like the Treasure Hunt demo, try setting a new set of random values for the
    cube position every time you look at it. Now, you have a game!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we built a Cardboard Android app from scratch, starting with
    a new project and adding Java code a little bit at a time. In our first build,
    we had a stereoscopic view of a triangle that you can see in a Google Cardboard
    headset.
  prefs: []
  type: TYPE_NORMAL
- en: We then added the model transformation, 3D camera views, perspective and head
    rotation transformations, and discussed a bit about matrix mathematics. We built
    a 3D model of a cube, and then created shader programs to use a light source to
    render the cube with shading. We also animated the cube and added a floor grid.
    Lastly, we added a feature that highlights the cube when the user is looking at
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Along the way, we enjoyed good discussions of 3D geometry, OpenGL, shaders,
    matrix math for 3D perspective viewing, geometric normals, and data buffers for
    the rendering pipeline. We also started thinking about the ways in which you can
    abstract common patterns in the code into reusable methods.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will take a different approach to stereoscopic rendering
    using Android layout views to build a useful "virtual lobby" that can be used
    as a 3D menu system or portal into other worlds.
  prefs: []
  type: TYPE_NORMAL
