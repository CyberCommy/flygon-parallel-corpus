- en: Chapter 2. Managing Lots of Threads – Executors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When you implement a simple concurrent application, you create and execute
    a thread per concurrent task. This approach can have some important issues. Since
    **Java version 5**, the Java concurrency API includes the **executor framework**
    to improve the performance of concurrent applications with a lot of concurrent
    tasks. In this chapter, we will cover the following:'
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to executors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first example – the k-nearest neighbors algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second example – concurrency in a client/server environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An introduction to executors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The basic mechanism to implement a concurrent application in Java is:'
  prefs: []
  type: TYPE_NORMAL
- en: '**A class that implements the Runnable interface**: This is the code you want
    to implement in a concurrent way'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**An instance of the Thread class**: This is the thread that is going to execute
    the code in a concurrent way'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this approach, you're responsible for creating and manning the `Thread`
    objects and implementing the mechanisms of synchronization between the threads.
    However, it can have some problems, especially with those applications with a
    lot of concurrent tasks. If you create too many threads, you can degrade the performance
    of your application or even hang the entire system.
  prefs: []
  type: TYPE_NORMAL
- en: Java 5 included the executor framework, to solve these problems and provide
    an efficient solution, which would be easier for the programmers to use than the
    traditional concurrency mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will introduce the basic characteristics of the executor
    framework by implementing the following two examples using that framework:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The k-nearest neighbors algorithm**: This is a basic **machine-learning**
    algorithm used in classification. It determines the tag of a test example based
    on the tag of the *k* most similar examples in the train dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Concurrency in a client/server environment**: Applications that serve information
    to thousands or millions of clients are critical nowadays. It is essential to
    implement the server side of the system in an optimal way.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In [Chapter 3](part0028_split_000.html#QMFO1-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 3. Getting the Maximum from Executors"), *Getting the Maximum from Executors*,
    and [Chapter 4](part0033_split_000.html#VF2I1-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 4. Getting Data from the Tasks – The Callable and Future Interfaces"),
    *Getting Data from the Tasks – The Callable and Future Interfaces*, we will introduce
    more advanced aspects of executors.
  prefs: []
  type: TYPE_NORMAL
- en: Basic characteristics of executors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The main characteristics of executors are:'
  prefs: []
  type: TYPE_NORMAL
- en: You don't need to create any `Thread` object. If you want to execute a concurrent
    task, you only create an instance of the task (for example, a class that implements
    the `Runnable` interface) and send it to the executor. It will manage the thread
    that will execute the task.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Executors reduce the overhead introduced by thread creation reusing the threads.
    Internally, it manages a pool of threads named **worker-threads**. If you send
    a task to the executor and a worker-thread is idle, the executor uses that thread
    to execute the task.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's easy to control the resources used by the executor. You can limit the maximum
    number of worker-threads of your executor. If you send more tasks than worker-threads,
    the executor stores them in a queue. When a worker-thread finishes the execution
    of a task, it takes another from the queue.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You have to finish the execution of an executor explicitly. You have to indicate
    to the executor that it has to finish its execution and kill the created threads.
    If you don't do this, it won't finish its execution and your application won't
    end.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Executors have more interesting characteristics that make them very powerful
    and flexible.
  prefs: []
  type: TYPE_NORMAL
- en: Basic components of the executor framework
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The executor framework has various interfaces and classes that implement all
    the functionality provided by executors. The basic components of the framework
    are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Executor interface**: This is the basic interface of the executor framework.
    It only defines a method that allows the programmer to send a `Runnable` object
    to an executor.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The ExecutorService interface**: This interface extends the `Executor` interface
    and includes more methods to increase the functionality of the framework, such
    as the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Execute tasks that return a result: The `run()` method provided by the `Runnable`
    interface doesn''t return a result, but with executors, you can have tasks that
    return a result'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Execute a list of tasks with a single method call
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finish the execution of an executor and wait for its termination
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The ThreadPoolExecutor class**: This class implements the `Executor` and
    `ExecutorService` interfaces. In addition, it includes some additional methods
    to get the status of the executor (number of worker-threads, number of executed
    tasks, and so on), methods to establish the parameters of the executor (minimum
    and maximum number or worker-threads, time that idle threads will wait for new
    tasks, and so on) and methods that allow programmers to extends and adapt its
    functionality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The Executors class**: This class provides utility methods to create `Executor`
    objects and other related classes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First example – the k-nearest neighbors algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The k-nearest neighbors algorithm is a simple machine-learning algorithm used
    for supervised classification. The main components of this algorithm are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**A train dataset**: This dataset is formed by instances with one or more attributes
    that define every instance and a special attribute that determines the example
    or label of the instance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A distance metric**: This metric is used to determine the distance (or similarity)
    between the instances of the train dataset and the new instances you want to classify'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A test dataset**: This dataset is used to measure the behavior of the algorithm'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When it has to classify an instance, it calculates the distance against this
    instance and all the instances of the train dataset. Then, it takes the k-nearest
    instances and looks at the tag of those instances. The tag with the most instances
    is the tag assigned to the input instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to work with the **Bank Marketing** dataset of
    the **UCI Machine Learning Repository**, which you can download from [http://archive.ics.uci.edu/ml/datasets/Bank+Marketing](http://archive.ics.uci.edu/ml/datasets/Bank+Marketing).
    To measure the distance between instances, we are going to use the **Euclidean
    distance**. With this metric, all the attributes of our instances must have numerical
    values. Some of the attributes of the Bank Marketing dataset are categorical (that
    is to say, they can take one of some predefined values), so we can''t use the
    Euclidean distance directly with this dataset. It''s possible to assign ordinal
    numbers to each categorical value; for example, for marital status, 0 would be
    *single*, 1 would be *married*, and 2 would be *divorced*. However, this would
    imply that the *divorced* person is closer to *married* than to *single*, which
    is disputable. To make all the categorical values equally distant, we create separate
    attributes such as *married*, *single*, and *divorced*, which have only two values:
    0 (*no*) and 1 (*yes*).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our dataset has 66 attributes and two possible tags: *yes* and *no*. We also
    divided the data in two subsets:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The train dataset**: With 39,129 instances'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The test dataset**: With 2,059 instances'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we explained in [Chapter 1](part0014_split_000.html#DB7S2-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 1. The First Step – Concurrency Design Principles"), *The First Step
    – Concurrency Design Principles*, we first implemented a serial version of the
    algorithm. Then, we looked for the parts of the algorithm that could be parallelized,
    and we used the executor framework to execute the concurrent tasks. In the following
    sections, we explain the serial implementation of the k-nearest neighbors algorithm
    and two different concurrent versions. The first one has a concurrency with very
    fine-grained granularity, whereas the second one has coarse-grained granularity.
  prefs: []
  type: TYPE_NORMAL
- en: K-nearest neighbors – serial version
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have implemented the serial version of the algorithm in the `KnnClassifier`
    class. Internally, this class stores the train dataset and the number `k` (the
    number of examples that we will use to determine the tag of an instance):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The `KnnClassifier` class only implements a method named `classify` that receives
    an `Sample` object with the instance we want to classify, and it returns a string
    with the tag assigned to that instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This method has three main parts—first, we calculate the distances between
    the input example and all the examples of the train dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we sort the examples from lower to higher distance, using the `Arrays.sort()`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we count the tag with most instances in the k-nearest examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'To calculate the distance between two examples, we can use the Euclidean distance
    implemented in an auxiliary class. This is the code of that class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We have also used the `Distance` class to store the distance between the `Sample`
    input and an instance of the train dataset. It only has two attributes: the index
    of the example of the train dataset and the distance to the input example. In
    addition, it implements the `Comparable` interface to use the `Arrays.sort()`
    method. Finally, the `Sample` class stores an instance. It only has an array of
    doubles and a string with the tag of that instance.'
  prefs: []
  type: TYPE_NORMAL
- en: K-nearest neighbors – a fine-grained concurrent version
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you analyze the serial version of the k-nearest neighbors algorithm, you
    can find the following two points where you can parallelize the algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The computation of the distances**: Every loop iteration that calculates
    the distance between the input example and one of the examples of the train dataset
    is independent of the others'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The sort of the distances**: Java 8 has included the `parallelSort()` method
    in the `Arrays` class to sort arrays in a concurrent way'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the first concurrent version of the algorithm, we are going to create a task
    per distance between examples that we're going to calculate. We are also going
    to make it possible to produce a concurrent sort of array of distances. We have
    implemented this version of the algorithm in a class named `KnnClassifierParrallelIndividual`.
    It stores the train dataset, the `k` parameter, the `ThreadPoolExecutor` object
    to execute the parallel tasks, an attribute to store the number of worker-threads
    we want to have in the executor, and an attribute to store if we want to make
    a parallel sort.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to create an executor with a fixed number of threads so that we
    can control the resources of the system that this executor is going to use. This
    number will be the number of processors available in the system we obtain with
    the `availableProcessors()` method of the `Runtime` class multiplied by the value
    of a parameter of the constructor named `factor`. Its value will be the number
    of threads you will have from the processor. We will always use the value `1`,
    but you can test with other values and compare the results. This is the constructor
    of the classification:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: To create the executor, we have used the `Executors` utility class and its `newFixedThreadPool()`
    method. This method receives the number of worker-threads you want to have in
    the executor. The executor will never have more worker-threads than the number
    you specified in the constructor. This method returns an `ExecutorService` object,
    but we cast it to a `ThreadPoolExecutor` object to have access to methods provided
    but the class and not included in the interface.
  prefs: []
  type: TYPE_NORMAL
- en: This class also implements the `classify()` method that receives an example
    and returns a string.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we create a task for every distance we need to calculate and send them
    to the executor. Then, the main thread has to wait for the end of the execution
    of those tasks. To control that finalization, we have used a synchronization mechanism
    provided by the Java concurrency API: the `CountDownLatch` class. This class allows
    a thread to wait until other threads have arrived at a determined point of their
    code. It''s initialized with the number of threads you want to wait for. It implements
    two methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`getDown()`: This method decreases the number of threads you have to wait for'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`await()`: This method suspends the thread that calls it until the counter
    reaches zero'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In this case, we initialize the `CountDownLatch` class with the number of tasks
    we are going to execute in the executor. The main thread calls the `await()` method
    and calls the `getDown()` method for every task, when it finishes its calculation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Then, depending on the value of the `parallelSort` attribute, we call the `Arrays.sort()`
    or `Arrays.parallelSort()` methods.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we calculate the tag assigned to the input examples. This code is the
    same as in the serial version.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `KnnClassifierParallelIndividual` class also includes a method to shutdown
    the executor calling its `shutdown()` method. It you don''t call this method,
    your application will never end because threads created by the executor are still
    alive and waiting for the new tasks to do. Previously submitted tasks are executed,
    and newly submitted tasks are rejected. The method doesn''t wait for the finalization
    of the executor, it returns immediately:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'A critical part of this example is the `IndividualDistanceTask` class. This
    is the class that calculates the distance between the input example and an example
    of the train dataset as a concurrent task. It stores the full array of distances
    (we are going to establish the value of one of its positions only), the index
    of the example of the train dataset, both examples, and the `CountDownLatch` object
    used to control the end of the tasks. It implements the `Runnable` interface,
    so it can be executed in the executor. This is the constructor of the class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The `run()` method calculates the distance between the two examples using the
    `EuclideanDistanceCalculator` class explained before and stores the result in
    the corresponding position of the distances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that although all the tasks share the array of distances, we don't need
    to use any synchronization mechanism because each task will modify a different
    position of the array.
  prefs: []
  type: TYPE_NORMAL
- en: K-nearest neighbors – a coarse-grained concurrent version
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The concurrent solution presented in the previous section may have a problem.
    You are executing too many tasks. If you stop to think, in this case, we have
    more than 29,000 train examples, so you're going to launch 29,000 tasks per example
    you want to classify. On the other hand, we have created an executor with a maximum
    of `numThreads` worker-threads, so another option is to launch only `numThreads`
    tasks and split the train dataset in `numThreads` groups. We executed the examples
    with a quad-core processor, so each task will calculate the distances between
    the input example and approximately 7,000 train examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have implemented this solution in the `KnnClassifierParallelGroup` class.
    It''s very similar to the `KnnClassifierParallelIndividual` class with two main
    differences. First, the first part of the `classify()` method. Now, we will only
    have `numThreads` tasks, and we have to split the train dataset in `numThreads`
    subsets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We calculate the number of samples per task in the length variable. Then, we
    assign to each thread the start and end indexes of the samples they have to process.
    For all the threads except the last one, we add the length value to the start
    index to calculate the end index. For the last one, the last index is the size
    of the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Second, this class uses `GroupDistanceTask` instead of `IndividualDistanceTask`.
    The main difference between those classes is that the first one processes a subset
    of the train dataset, so it stores the full train dataset and the first and last
    positions of the dataset it has to process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The `run()` method processes a set of examples instead of only one example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Comparing the solutions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s compare the different versions of the k-nearest neighbors algorithms
    we have implemented. We have the following five different versions:'
  prefs: []
  type: TYPE_NORMAL
- en: The serial version
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The fine-grained concurrent version with serial sorting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The fine-grained concurrent version with concurrent sorting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The coarse-grained concurrent version with serial sorting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The coarse-grained concurrent version with concurrent sorting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To test the algorithm, we have used 2,059 test instances, which we take from
    the Bank Marketing dataset. We have classified all those examples using the five
    versions of the algorithm using the values of k as 10, 30, and 50, and measured
    their execution time. We have used the **JMH framework** ([http://openjdk.java.net/projects/code-tools/jmh/](http://openjdk.java.net/projects/code-tools/jmh/))
    which allows you to implement microbenchmarks in Java. Using a framework for benchmarking
    is a better solution that simply measures time using the `currentTimeMillis()`
    or `nanoTime()` methods. These are the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Algorithm | K | Execution time (seconds) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Serial | 10 | 100.296 |'
  prefs: []
  type: TYPE_TB
- en: '| 30 | 99.218 |'
  prefs: []
  type: TYPE_TB
- en: '| 50 | 99.458 |'
  prefs: []
  type: TYPE_TB
- en: '| Fine-grained serial sort | 10 | 108.150 |'
  prefs: []
  type: TYPE_TB
- en: '| 30 | 105.196 |'
  prefs: []
  type: TYPE_TB
- en: '| 50 | 109.797 |'
  prefs: []
  type: TYPE_TB
- en: '| Fine-grained concurrent sort | 10 | 84.663 |'
  prefs: []
  type: TYPE_TB
- en: '| 30 | 85,392 |'
  prefs: []
  type: TYPE_TB
- en: '| 50 | 83.373 |'
  prefs: []
  type: TYPE_TB
- en: '| Coarse-grained serial sort | 10 | 78.328 |'
  prefs: []
  type: TYPE_TB
- en: '| 30 | 77.041 |'
  prefs: []
  type: TYPE_TB
- en: '| 50 | 76.549 |'
  prefs: []
  type: TYPE_TB
- en: '| Coarse-grained concurrent sort | 10 | 54,017 |'
  prefs: []
  type: TYPE_TB
- en: '| 30 | 53.473 |'
  prefs: []
  type: TYPE_TB
- en: '| 50 | 53.255 |'
  prefs: []
  type: TYPE_TB
- en: 'We can draw the following conclusions:'
  prefs: []
  type: TYPE_NORMAL
- en: The selected values of the K parameter (10, 30, and 50) don't affect the execution
    time of the algorithm. The five versions present similar results for the three
    values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As it was expected, the use of the concurrent sort with the `Arrays.parallelSort()`
    method gives a great improvement in performance in the fine-grained and the coarse-grained
    concurrent versions of the algorithms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The fine-grained version of the algorithm gives the same or slightly worse results
    than the serial algorithm. The overhead introduced by the creation and management
    of concurrent tasks provokes these results. We execute too many tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The coarse-grained version, on the other hand, offers a great improvement of
    performance, with serial or parallel sorting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, the best version of the algorithm is the coarse-grained solution using
    parallel sorting. If we compare it with the serial version calculating the speedup:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Comparing the solutions](img/00007.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: This example shows how a good election of a concurrent solution can give us
    a great improvement, and a bad election can give us a bad performance.
  prefs: []
  type: TYPE_NORMAL
- en: The second example – concurrency in a client/server environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **client/server model** is a software architecture in which applications
    are split into two parts: the server part that provides resources (data, operations,
    printer, storage, and so on) and the client part that uses the resources provided
    by the server. Traditionally, this architecture was used in the enterprise world,
    but with the boom of the Internet, it is still an actual topic. You can see a
    web application as a client/server application where the server part is the backend
    part of the application that is executed in a web server and the web navigator
    executes the client part of the application. **SOA** (short for **Service-Oriented
    Architecture**) is an other example of client/server architecture where the web
    services exposed are the server part and the different clients that consume them
    are the client part.'
  prefs: []
  type: TYPE_NORMAL
- en: In a client/server environment, we usually have one server and a lot of clients
    that use the services provided by the server, so the performance of the server
    is a critical aspect when you have to design one of these systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will implement a simple client/server application. It will
    make a search of data over the **World Development Indicators** of the **World
    Bank**, which you can download from here: [http://data.worldbank.org/data-catalog/world-development-indicators](http://data.worldbank.org/data-catalog/world-development-indicators).
    This data contains the values of different indicators over all the countries in
    the world from 1960 to 2014.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The main characteristics of our server will be:'
  prefs: []
  type: TYPE_NORMAL
- en: The client and the server will connect using sockets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The client will send its queries in a string, and the server will respond to
    the results in another string
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The server can respond with three different queries:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Query**: The format of this query is `q;codCountry;codIndicator;year` where
    `codCountry` is the code of the country, `codIndicator` is the code of the indicator,
    and `year` is an optional parameter with the year you want to query. The server
    will respond with the information in a single string.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Report**: The format of this query is `r;codIndicator` where `codIndicator`
    is the code of the indicator you want to report. The server will respond with
    the mean value of that indicator for all countries over the years in a single
    string.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stop**: The format of this query is `z;`. The server stops its execution
    when it receives this command.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In other cases, the server returns an error message.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As in the previous example, we will show you how to implement a serial version
    of this client/server application. Then, we will show you how to implement a concurrent
    version using an executor. Finally, we will compare the two solutions to view
    the advantages of the use of concurrency in this case.
  prefs: []
  type: TYPE_NORMAL
- en: Client/server – serial version
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The serial version of our server application has three main parts:'
  prefs: []
  type: TYPE_NORMAL
- en: The **DAO** (short for **Data Access Object**) part, responsible for access
    to the data and obtaining the results of the query
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The command part, formed by a command per kind of query
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The server part, which receives the queries, calls the corresponding command,
    and returns the results to the client
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's see in detail each of these parts.
  prefs: []
  type: TYPE_NORMAL
- en: The DAO part
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we mentioned before, the server will make a search of data over the world
    development indicators of the World Bank. This data is in a CSV file. The DAO
    component in the application loads the entire file into a `List` object in memory.
    It implements a method per query it will attend that goes over the list looking
    for the data.
  prefs: []
  type: TYPE_NORMAL
- en: We don't include the code of this class here because it's simple to implement
    and it's not the main purpose of this book.
  prefs: []
  type: TYPE_NORMAL
- en: The command part
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The command part is an intermediary between the DAO and the server parts. We
    have implemented a base abstract `Command` class to be the base class of all the
    commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we have implemented a command for each query. The query is implemented
    in the `QueryCommand` class. The `execute()` method is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The report is implemented in `ReportCommand`. The `execute()` method is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The stop query is implemented in the `StopCommand` class. Its `execute()` method
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the error situations are processed by the `ErrorCommand` class. Its
    `execute()` method is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The server part
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, the server part is implemented in the `SerialServer` class. First
    of all, it initializes the DAO calling the `getDAO()` method. The main objective
    is that the DAO loads all the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'After this, we have a loop that will be executed until the server receives
    a stop query. This loop does the following four steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Receives a query for a client
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parses and splits the elements of the query
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calls the corresponding command
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns the results to the client
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These four steps are shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Client/server – parallel version
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The serial version of the server has a very important limitation. While it is
    processing one query, it can't attend to other queries. If the server needs an
    important amount of time to respond to every request, or to certain requests,
    the performance of the server will be very low.
  prefs: []
  type: TYPE_NORMAL
- en: We can obtain a better performance using concurrency. If the server creates
    a thread when it receives a request, it can delegate to the thread all the processes
    of the query and it can attend new request. This approach can also have some problems.
    If we receive a high number of queries, we can saturate the system creating too
    many threads. But if we use an executor with a fixed number of threads, we can
    control the resources used by our server and obtain a better performance than
    the serial version.
  prefs: []
  type: TYPE_NORMAL
- en: To convert our serial server to a concurrent one using an executor, we have
    to modify the server part. The DAO part is the same, and we have changed the names
    of the classes that implement the command part, but their implementation is almost
    the same. Only the stop query changes because now it has more responsibilities.
    Let's see the details of the implementation of the concurrent server part.
  prefs: []
  type: TYPE_NORMAL
- en: The server part
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The concurrent server part is implemented in the `ConcurrentServer` part. We
    have added two elements not included in the serial server: a cache system, implemented
    in the `ParallelCache` class and a log system, implemented in the `Logger` class.
    First of all, it initializes the DAO part calling the `getDAO()` method. The main
    objective is that the DAO loads all the data and creates a `ThreadPoolExecutor`
    object using the `newFixedThreadPool()` method of the `Executors` class. This
    method receives the maximum number of worker-threads we want in our server. The
    executor will never have more than those worker-threads. To get the number of
    worker-threads, we get the number of cores of our system using the `availableProcessors()`
    method of the `Runtime` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The `stopped` Boolean variable is declared as volatile because it will be changed
    from another thread. The `volatile` keyword ensures that when the `stopped` variable
    is set to `true` by another thread, this change will be visible in the main method.
    Without the `volatile` keyword, the change cannot be visible due to CPU caching
    or compiler optimizations. Then, we initialize `ServerSocket` to listen for the
    requests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We can't use a try-with-resources statement to manage the server socket. When
    we receive a `stop` command, we need to shut down the server, but the server is
    waiting in the `accept()` method of the `serverSocket` object. To force the server
    to leave that method, we need to explicitly close the server (we'll do that in
    the `shutdown()` method), so we can't leave the try-with-resources statement close
    the socket for us.
  prefs: []
  type: TYPE_NORMAL
- en: 'After this, we have a loop that will be executed until the server receives
    a stop query. This loop does three steps, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Receives a query for a client
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creates a task to process that query
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sends the task to the executor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These three steps are shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, once the server has finished its execution (leaving the loop), we
    have to wait for the finalization of the executor using the `awaitTermination()`
    method. This method will block the main thread until the executor has finished
    its `execution()` method. Then, we shut down the cache system and wait for a message
    to indicate the end of the execution of the server, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We have added two additional methods: the `getExecutor()` method, which returns
    the `ThreadPoolExecutor` object that is used to execute the concurrent tasks,
    and the `shutdown()` method, which is used to finish in an ordered way the executor
    of the server. It calls the `shutdown()` method of the executor and closes `ServerSocket`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'In the concurrent server, there is an essential part: the `RequestTask` class
    which processes every request of the clients. This class implements the `Runnable`
    interface, so it can be executed in an executor in a concurrent way. Its constructor
    receives the `Socket` parameter which will be used to communicate to the client:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The `run()` method does the same things that are done by the serial server
    to respond to every requests:'
  prefs: []
  type: TYPE_NORMAL
- en: Receives a query for a client
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parses and splits the elements of the query
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calls the corresponding command
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns the results to the client
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is its code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The command part
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the command part, we have renamed all the classes as you can see in the
    previous fragment of code. The implementation is the same except in the `ConcurrentStopCommand`
    class. Now, it calls the `shutdown()` method of the `ConcurrentServer` class to
    terminate the execution of the server in an ordered way. This is the `execute()`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Also, now the `Command` class contains a new `isCacheable()` Boolean method
    that returns `true` if the command result is stored in the cache and `false` otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: Extra components of the concurrent server
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We have implemented some extra components in the concurrent server: a new command
    to return information about the status of the server, a cache system to store
    the results of the commands, time saving when a request is repeated, and a log
    system to write error and debug information. The following sections describe each
    of these components.'
  prefs: []
  type: TYPE_NORMAL
- en: The status command
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'First of all, we have a new possible query. It has the format `s;` and is processed
    by the `ConcurrentStatusCommand` class. It gets `ThreadPoolExecutor` used by the
    server and obtains information about the status of the executor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The information we obtain from the server is:'
  prefs: []
  type: TYPE_NORMAL
- en: '`getActiveCount()`: This returns the approximate number of tasks that execute
    our concurrent tasks. There can be more threads in the pool, but they can be idle.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`getMaximumPoolSize()`: This returns the maximum number of worker-threads the
    executor can have.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`getCorePoolSize()`: This returns the core number of worker-threads the executor
    will have. This number determines the minimum number of threads the pool will
    have.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`getPoolSize()`: This returns the current number of threads in the pool.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`getLargestPoolSize()`: This returns the maximum number of threads of the pool
    during its execution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`getCompletedTaskCount()`: This returns the number of tasks the executor has
    executed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`getTaskCount()`: This returns the approximate number of tasks that have ever
    been scheduled for execution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`getQueue().size()`: This returns the number of tasks that are waiting in the
    queue of tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we have created our executor using the `newFixedThreadPool()` method of the
    `Executor` class, our executor will have the same maximum and core worker-threads.
  prefs: []
  type: TYPE_NORMAL
- en: The cache system
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We have included a cache system in our parallel server to avoid the data search
    that has recently been made. Our cache system has three elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The CacheItem class**: This class represents every element stored in the
    cache. It has four attributes:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The command stored in the cache. We will store the `query` and `report` commands
    in the cache.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The response generated by that command.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The creation date of the item in the cache.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The last time this item was accessed in the cache.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The CleanCacheTask class**: If we store all the commands in the cache but
    never delete the elements stored in it, the cache will increase its size indefinitely.
    To avoid this situation, we can have a task that deletes elements in the cache.
    We are going to implement this task as a `Thread` object. There are two options:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can have the maximum size in the cache. If the cache has more elements than
    the maximum size, you can delete the elements that have been accessed less recently.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can delete from the cache the elements that haven't been accessed in a predefined
    period of time. We are going to use this approach.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The ParallelCache class**: This class implements the operations to store
    and retrieve elements in the cache. To store the data in the cache, we have used
    a `ConcurrentHashMap` data structure. As the cache will be shared between all
    the tasks of the server, we have to use a synchronization mechanism to protect
    the access to the cache avoiding data race conditions. We have three options:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can use a non-synchronized data structure (for example, a `HashMap`) and
    add the necessary code to synchronize the types of access to this data structure,
    for example, with a lock. You can also convert a `HashMap` into a synchronized
    structure using the `synchronizedMap()` method of the `Collections` class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use a synchronized data structure, for example, `Hashtable`. In this case, we
    don't have data race conditions, but the performance can be better.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use a concurrent data structure, for example, a `ConcurrentHashMap` class, which
    eliminates the possibility of data race conditions and it's optimized to work
    in a high concurrent environment. This is the option we're going to implement
    using an object of the `ConcurrentHashMap` class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code of the `CleanCacheTask` class is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The class has a `ParallelCache` object. Every 10 seconds, it executes the `cleanCache()`
    method of the `ParallelCache` instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ParallelCache` class has five different methods. First, the constructor
    of the class that initializes the elements of the cache. It creates the `ConcurrentHashMap`
    object and starts a thread that will execute the `CleanCacheTask` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, there are two methods to store and retrieve an element in the cache.
    We use the `put()` method to insert the element in the `HashMap` and the `get()`
    method to retrieve the element from the `HashMap`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, the method to clean the cache used by the `CleanCacheTask` class is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the method to shut down the cache that interrupts the thread executing
    the `CleanCacheTask` class and the method that returns the number of elements
    stored in the cache is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The log system
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In all the examples of this chapter, we write information in the console using
    the `System.out.println()` method. When you implement an enterprise application
    that is going to execute in a production environment, it''s a better idea to use
    a log system to write debug and error information. In Java, `log4j` is the most
    popular log system. In this example, we are going to implement our own log system
    implementing the producer/consumer concurrency design pattern. The tasks that
    will use our log system will be the producer, and a special task (executed as
    a thread) that will write the log information into a file will be the consumer.
    The components of this log system are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**LogTask**: This class implements the log consumer that after every 10 seconds
    reads the log messages stored in the queue and writes them to a file. It will
    be executed by a `Thread` object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logger**: This is the main class of our log system. It has a queue where
    the producer will store the information and the consumer will read it. It also
    includes the method to add a message into the queue and a method to get all the
    messages stored in the queue and write them to disk.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To implement the queue, as happens with the cache system, we need a concurrent
    data structure to avoid any data inconsistency errors. We have two options:'
  prefs: []
  type: TYPE_NORMAL
- en: Use a **blocking data structure**, which blocks the thread when the queue is
    full (in our case, it will never be full) or empty
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use a **non-blocking data structure**, which returns a special value if the
    queue is full or empty
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have chosen a non-blocking data structure, the `ConcurrentLinkedQueue` class,
    which implements the `Queue` interface. We use the `offer()` method to insert
    elements in the queue and the `poll()` method to get elements from it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `LogTask` class code is very simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: The class implements the `Runnable` interface and, in the `run()` method, calls
    the `writeLogs()` method of the `Logger` class every 10 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Logger` class has five different static methods. First of all, a static
    block of code that initializes and starts a thread that executes the `LogTask`
    and creates the `ConcurrentLinkedQueue` class used to store the log data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, there is a `sendMessage()` method that receives a string as a parameter
    and stores that message in the queue. To store the message, it uses the `offer()`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'A critical method of this class is the `writeLogs()` class. It obtains and
    deletes all the log messages stored in the queue using the `poll()` method of
    the `ConcurrentLinkedQueue` class and writes them to a file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, two methods: one to truncate the log file and another to finish the
    executor of the log system, which interrupts the thread that is executing `LogTask`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Comparing the two solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now it''s time to test the serial and concurrent servers and see which has
    a better performance. We have automatized the tests implementing four classes
    that make queries to the servers. These classes are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`SerialClient`: This implements a possible client of the serial server. It
    makes nine requests using the query message and a query using the report message.
    It repeats the process 10 times, so it request 90 queries and 10 reports.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MultipleSerialClients`: This class simulates the existence of several clients
    at the same time. For this, we create a thread per `SerialClient` and execute
    them at the same time to see the performance of the server. We have tested from
    one to five concurrent clients.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ConcurrentClient`: It is analogue to the `SerialClient` class, but it calls
    the concurrent server instead of the serial one.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MultipleConcurrentClients`: It is analogue to the `MultipleSerialClients`
    class, but it calls the concurrent server instead of the serial one.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To test the serial server, you can follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Launch the serial server and wait for its initialization.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Launch the `MultipleSerialClients` class, which launches one, then two, three,
    four, and finally, five `SerialClient` classes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You can follow a similar process with the concurrent server:'
  prefs: []
  type: TYPE_NORMAL
- en: Launch the concurrent server and wait for its initialization.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Launch the `MultipleConcurrentClients` class, which launches one, two, three,
    four, and finally, five `ConcurrentClient` classes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To compare the execution times of both versions, we have implemented a microbenchmark
    using the JMH framework ([http://openjdk.java.net/projects/code-tools/jmh/](http://openjdk.java.net/projects/code-tools/jmh/)).
    We have implemented two executions based in the `SerialClient` and `ConcurrentClient`
    tasks. We have repeated this process 10 times calculating the mean time per number
    of concurrent clients. We launched the tests in a computer with a processor with
    four cores, so it can execute four parallel tasks at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the results of all these executions:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Concurrent clients | Serial server | Concurrent server | Speedup |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 7.404 | 5.144 | 1.43 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 9.344 | 4.491 | 2.08 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 19.641 | 9.308 | 2.11 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 29.180 | 12.842 | 2.27 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 30.542 | 16.322 | 1.87 |'
  prefs: []
  type: TYPE_TB
- en: 'The contents of the cells are the mean time of each client in seconds. We can
    draw the following conclusions:'
  prefs: []
  type: TYPE_NORMAL
- en: The performance of both kinds of servers is affected by the number of concurrent
    clients that send requests to our server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In all cases, the execution times of the concurrent version are much lower than
    the execution times of the serial one
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other methods of interest
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout the pages of this chapter, we have used some classes of the Java
    concurrency API to implement basic functionalities of the executor framework.
    These classes also have other interesting methods. In this section, we collate
    some of them.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Executors` class provides other methods to create `ThreadPoolExecutor`
    objects. These methods are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`newCachedThreadPool()`: This method creates a `ThreadPoolExecutor` object
    that reuses a worker-thread if it''s idle, but it creates a new one if it''s necessary.
    There is no maximum number of worker-threads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`newSingleThreadExecutor()`: This method creates a `ThreadPoolExecutor` object
    that uses only a single worker-thread. The tasks you send to the executor are
    stored in a queue until the worker-thread can execute them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `CountDownLatch` class provides the following additional methods:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`await(long timeout, TimeUnit unit)`: It waits till the internal counter arrives
    to zero of pass the time specified in the parameters. If the time passes, the
    method returns the `false` value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`getCount()`: This method returns the actual value of the internal counter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are two types of concurrent data structures in Java:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Blocking data structures**: When you call a method and the library can''t
    do that operation (for example, you try to obtain an element, and the data structure
    is empty), they block the thread until the operation can be done.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Non-blocking data structures**: When you call a method and the library can''t
    do that operation (because the structure is empty or full), the method returns
    a special value or throws an exception.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are data structures that implement both behaviors and data structures
    that implement only one. Usually, blocking data structures also implement the
    methods with non-blocking behavior, and non-blocking data structures don't implement
    the blocking methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'The methods that implement the blocking operations are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`put()`, `putFirst()`, `putLast()`: These insert an element in the data structure.
    If it''s full, it blocks the thread until there is space.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`take()`, `takeFirst()`, `takeLast()`: These return and remove an element of
    the data structure. If it''s empty, it blocks the thread until there is an element
    in it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The methods that implement the non-blocking operations are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`add()`, `addFirst()`, `addLast()`: These insert an element in the data structure.
    If it''s full, the method throws an `IllegalStateException` exception.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`remove()`, `removeFirst()`, `removeLast()`: These return and remove an element
    from the data structure. If it''s empty, the method throws an `IllegalStateException`
    exception.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`element()`, `getFirst()`, `getLast()`: These return but don''t remove an element
    from the data structure. If it''s empty, the method throws an `IllegalStateException`
    exception.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`offer()`, `offerFirst()`, `offerLast()`: These insert an element value in
    the data structure. If it''s full, they return the `false` Boolean value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`poll()`, `pollFirst()`, `pollLast()`: These return and remove an element from
    the data structure. If it''s empty, they return the null value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`peek()`, `peekFirst()`, `peekLast()`: These return but don''t remove an element
    from the data structure. If it''s empty, they return the null value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In [Chapter 9](part0056_split_000.html#1LCVG2-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 9. Diving into Concurrent Data Structures and Synchronization Utilities"),
    *Diving into Concurrent Data Structures and Synchronization Utilities*, we will
    describe concurrent data structures in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In simple concurrent applications, we execute concurrent tasks using the `Runnable`
    interface and the `Thread` class. We create and manage the threads and control
    their execution. We can't follow this approach in big concurrent applications
    because it can cause us many problems. For these cases, the Java concurrency API
    has introduced the executor framework. In this chapter, we presented the basic
    characteristics and components that form this framework. First of all, the `Executor`
    interface, which defines the basic method to send a `Runnable` task to an executor.
    This interface has a subinterface, the `ExecutorService` interface, which includes
    methods to send to the executor tasks that return a result (these tasks implement
    the `Callable` interface, as we will see in [Chapter 4](part0033_split_000.html#VF2I1-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 4. Getting Data from the Tasks – The Callable and Future Interfaces"),
    *Getting Data from the Tasks – The Callable and Future Interfaces*) and a list
    of tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ThreadPoolExecutor` class is the basic implementation of both interfaces:
    adding additional methods to get information about the status of the executor
    and the number of threads or tasks that are executing. The easiest way to create
    an object of this class is by using the `Executors` utility class, which includes
    methods to create different kinds of executors.'
  prefs: []
  type: TYPE_NORMAL
- en: We showed you how to use executors and convert serial algorithms to concurrent
    ones using executors implementing two real-world examples. The first example is
    the k-nearest neighbors algorithm, applying it to the Bank Marketing dataset of
    the UCI machine learning repository. The second example is a client/server application
    to make queries over the World Development Indicators of the World Bank.
  prefs: []
  type: TYPE_NORMAL
- en: In both cases, the use of executors gave us a great improvement of performance.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will describe how to implement advanced techniques with
    executors. We are going to complete our client/server application adding the possibility
    of cancelling and executing tasks with higher priority before the tasks with a
    lower priority. We will also show you how to implement tasks that will execute
    periodically, implementing an RSS news reader.
  prefs: []
  type: TYPE_NORMAL
