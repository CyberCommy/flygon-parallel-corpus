- en: Chapter 10. Spring Cache
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Spring cache has come into action since the Spring 3.1 versions. Spring has
    also added annotations to support the caching mechanism. The caching abstraction
    layer provides a lot of support to use different caching solutions. In this chapter,
    we shall explore Spring caching. We shall see how to set up a Spring cache. You
    can ideally tie your caching code with a business logic.
  prefs: []
  type: TYPE_NORMAL
- en: Caching avoids re-computing. Ideally, you don't have to repeat the same process
    again to fetch the same values. Cache stores the values in the memory. You can
    always choose what you would like to cache and what you don't like to. It's a
    part of architectural design. Once the data is cached, it's retrieved from the
    cached memory, thus saving computational time.
  prefs: []
  type: TYPE_NORMAL
- en: Spring annotations for caching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Spring has come up with two main annotations for caching; we will be using
    these throughout the chapter. The following are the two annotations:'
  prefs: []
  type: TYPE_NORMAL
- en: '`@Cacheable`: This can be used to mark the method and return values that will
    be stored in the cache. This can be applied at the method or type level.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When applied at the method level, the annotated method's return value is cached
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When applied at type level, the return value of every method is cached
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`@CacheEvict`: This is used for releasing objects from cache memory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '@Cacheable usage'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let us look at small implementation of using `@Cacheable` annotations applied
    at type level. We are thinking of simple DAO class, with two methods with different
    names. We have used the `@Cacheabl`e annotation, which takes three arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: Value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Key
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Condition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'No we can implement it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, Spring cache by default will assign a cache key, with
    an annotated signature.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also provide a customized key. Using SpEL expressions, the following
    is the demonstration for providing custom keys for cache:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also perform conditional caching. Let us do conditional caching of products
    with a price greater than 1000:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The @CacheEvict usage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let us look at using `@CacheEvict` for flushing single objects and multiple
    objects from the cache. The `productId` will have new cached values every time
    and the user adds a rating. The previous rating will get evicted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The following is the `@CacheEvict` usage for flushing all the cached objects.
    You can see that multiple objects are flushed at one time.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Spring caching repository
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The cache repository is where the actual objects are saved. Spring supports
    two types of repositories:'
  prefs: []
  type: TYPE_NORMAL
- en: Using `ConcurrentMap` is also an option for implementing caching in the application.
    The repository has little (if any) effect on the code, and switching between repositories
    should be very easy. Our objects will be cached within a ConcurrentMap.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can configure the ConcurrentMap as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The Ehcache popular library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This cache is used by a lot of popular frameworks to handle caching in an application.
    The ehcache is used by a hibernate framework to handle caching in the DAO (Date
    access) layer of the application.
  prefs: []
  type: TYPE_NORMAL
- en: We can have more than one repository. Note that, the name of this repository
    must be same as the name used in the annotation.
  prefs: []
  type: TYPE_NORMAL
- en: Spring CacheManager
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s look at the core interfaces and implementation classes that are used
    for configuring caching in a Spring caching framework. Spring CacheManager is
    actually an interface in the Spring''s caching framework. The following is the
    list of classes that implement the CacheManager interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '`AbstractCacheManager`: This abstract class implements the `CacheManager` interface.
    It is useful for static environments, where the backing caches do not change.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CompositeCacheManager`: This is the composite `CacheManager` implementation
    that iterates over a given collection of `CacheManager` instances. It allows `NoOpCacheManager`
    to be automatically added to the list for handling the cache declarations without
    a backing store.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ConcurrentMapCacheManager`: This is the `CacheManager` implementation that
    lazily builds `ConcurrentMapCache` instances for each `getCache(java.lang.String)`
    request. It also supports a static mode where the set of cache names is predefined
    through `setCacheNames(java.util.Collection)`, with no dynamic creation of further
    cache regions at runtime.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ehCacheCacheManager`: `CacheManager` backed by an EhCache `CacheManager`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`NoOpCacheManager`: A basic, no operation CacheManager implementation suitable
    for disabling caching, typically used for backing cache declarations without an
    actual backing store. It will simply accept any items into the cache, without
    actually storing them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SimpleCacheManager`: The Simple CacheManager works against a given collection
    of caches. This is useful for testing or simple caching declarations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maven dependency for Spring with caching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you are using Maven as a build tool, ensure that you add the ehcache dependency
    in the `pom.xml` file. Below is the Maven dependency for using cache with spring''s
    caching framework:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Declarative configuration of ehcache
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the following section, we can see how we can configure the cache storage
    declaratively. The `ecache.xml` file is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s also look at what each of the following properties used in the `echace.xml`
    mean, so that it will aid in their proper usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '`maxBytesLocalHeap`: This defines how many bytes the cache may use from the
    VM''s heap. If a CacheManager `maxBytesLocalHeap` has been defined, this cache''s
    specified amount will be subtracted from the CacheManager. Other caches will share
    the remainder. This attribute''s values are given as `<number>k|K|m|M|g|G` for
    kilobytes (k|K), megabytes (m|M), and gigabytes (g|G). For example, `maxBytesLocalHeap="2g"`
    allots 2 gigabytes of heap memory. If you specify a `maxBytesLocalHeap`, you can''t
    use the `maxEntriesLocalHeap` attribute. `maxEntriesLocalHeap` can''t be used
    if a CacheManager `maxBytesLocalHeap` is set.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Set at the highest level, this property defines the memory allocated for all
    the defined caches. You have to divide it afterwards with the individual caches.
  prefs: []
  type: TYPE_NORMAL
- en: '`eternal`: This sets whether the elements are eternal. If eternal, timeouts
    are ignored and the element is never expired.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timeToIdleSeconds`: This sets the time to idle for an element before it expires.
    That is, the maximum amount of time between accesses before an element expires.
    It is only used if the element is not eternal. Optional attribute. A value of
    `0` means that an element can idle for infinity. The default value is `0`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timeToLiveSeconds`: This sets the time to live for an element before it expires
    which is the maximum time between creation time and when an element expires. It
    is only used if the element is not eternal. Optional attribute. A value of `0`
    means that an element can live for infinity. The default value is 0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`memoryStoreEvictionPolicy`: The policy would be enforced upon reaching the
    `maxEntriesLocalHeap` limit. The default policy is **Least Recently Used** (**LRU**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you want take some load off your database, you could also use the `localTempSwap`
    persistence strategy, and in that case, you can use `maxEntriesLocalDisk` or `maxBytesLocalDisk`
    at either the cache or CacheManager level to control the size of the disk tier.
  prefs: []
  type: TYPE_NORMAL
- en: Two of the configured caches, reference Data and `newestAndRecommendedPodcasts`
    are pinned in the local memory (`<pinning store="localMemory"/>`), which means
    that the data will remain in the cache at all times. To unpin the data from the
    cache you have to clear the cache.
  prefs: []
  type: TYPE_NORMAL
- en: Spring MVC with caching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, let us develop a simple MVC application to demonstrate simple
    spring caching. Let us start with the configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'To enable caching, we need to add the following configuration to the application
    `context.xml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '`<cache:annotation-driven />` will recognize the spring cache annotations `@Cacheable`
    and `@CacheEvict`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us demonstrate an application `context.xml` file with a simple caching
    configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Next let us demonstrate the `ehchace.xml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we shall see a simple POJO class `Author.java`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we shall write a simple controller with the injected Author pojo:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we shall write a `.jsp` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: When we run the application with `http://localhost:8080/springcachedemo/index.htm?id=1`,
    the data gets cached and the second time we access the URL you will be able to
    observe that the value is retrieved from cache.
  prefs: []
  type: TYPE_NORMAL
- en: Now update the ID in the URL `id=2.Access http://localhost:8080/springcachedemo/index.htm?id=2`,
    the data is not retrieved from cache, but it gets cached.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing your own caching algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, let us start by implementing a simple cache algorithm and see
    its draw backs, and then show how spring caching can be used to solve the problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s draw a simple flow chart to look at the caching scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Implementing your own caching algorithm](img/7320OS_10_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Let's see how we can implement caching in a simple way. Think of generating
    a Fibonacci number. A Fibonacci number is generated by adding its previous two
    Fibonacci numbers. So we can compute a simple class in java and see how we can
    use caching here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a map to cache the objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This approach is not thread safe and the same value is computed more than once.
    When two threads run over the class, they end up caching the same value.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can overcome this by implementing concurrent hash maps. The preceding code
    can be rewritten as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code will make the algorithm thread safe, preventing the re-computation
    of the same values. But this design cannot be used for other algorithms. If we
    have to find whether the next Fibonacci number is odd or prime, this wouldn't
    be supported.
  prefs: []
  type: TYPE_NORMAL
- en: Let us tackle this using Future, Callable ExecutorService, and Concurrent HashMap.
    We will also see what Future callable and executor Service means.
  prefs: []
  type: TYPE_NORMAL
- en: '**ExecutorService** provides options to create thread pool. ExecutorService
    is an interface in concurrency package. `ThreadPoolExecutor` and `ScheduledThreadPoolExecutor`
    are the two classes that implement the `ExecutorService`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few different ways to delegate tasks for execution to a `ExecutorService`:'
  prefs: []
  type: TYPE_NORMAL
- en: execute (Runnable)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: submit (Runnable)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: submit (Callable)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: invokeAny (...)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: invokeAll (...)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Callable** is an interface similar to Runnable. It is a task that returns
    a result and may throw an exception. Implementors define a single method with
    no arguments called `call`.'
  prefs: []
  type: TYPE_NORMAL
- en: The Callable interface is similar to Runnable, in that, both are designed for
    classes whose instances are potentially executed by another thread. A Runnable,
    however, does not return a result and cannot throw a checked exception.
  prefs: []
  type: TYPE_NORMAL
- en: The Executors class contains utility methods to convert from other common forms
    to Callable classes.
  prefs: []
  type: TYPE_NORMAL
- en: Let us create a generic class; `MyCache`, this class instance accepts the Key
    and Value pair. It uses a concurrent `HashMap`.
  prefs: []
  type: TYPE_NORMAL
- en: Let's call the `getter` and `setter` methods on condition; if the value is already
    in the cache, then just get the value, and set it only if it is absent.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to use the cache algorithm in our Fibonacci series code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see in the preceding example, the modifications required were minimal.
    All caching code is encapsulated within the caching algorithm and our code simply
    interacts with it. The caching algorithm is thread safe and since all the state
    is saved by the caching algorithm, our class is inherently thread safe. Using
    this new approach, we can have this class (`MyFibonacci`) focusing on its business
    logic, that is, computing the Fibonacci sequence. Each Fibonacci number is evaluated
    only once. All the other times, this was retrieved from the cache. In the following
    example, we will see how to use the same cache algorithm in another context. Think
    of a long learning task which needs to use a cache. We shall use a Spring Stop
    Watch class found in the `org.spring.framework.util.StopWatch` package. The class
    has two constructors:'
  prefs: []
  type: TYPE_NORMAL
- en: '`StopWatch()`: This constructs a new stop watch'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`StopWatch(String id)`: This constructs a new stop watch with the given ID'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The simple stop watch allows for timing a number of tasks, exposing a total
    running time, and giving a running time for each named task. It conceals the use
    of `System.currentTimeMillis()`, improving the readability of the application
    code, and reducing the likelihood of calculation errors.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that this object is not designed to be thread safe, and does not use synchronization
    or threading. Therefore it is safe to invoke it from EJBs.
  prefs: []
  type: TYPE_NORMAL
- en: This class is normally used to verify performance during proof of concepts and
    in development, rather than as part of production applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Output for the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: No changes were required to the caching algorithm and implementing it was quite
    easy. The preceding code will produce something similar to the following code.
    As shown in the preceding output, once the first value is computed and saved in
    cache, all other retrievals happen instantly without introducing any noticeable
    delays.
  prefs: []
  type: TYPE_NORMAL
- en: Let's go further and implement the preceding log running task and cache the
    computational value using spring cache.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will create two simple classes: `Worker` and `Main`. The `Worker` class
    has two methods which are called from the `main` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: You can observe that the Longtask has passed the same value to be recomputed.
    We can tackle this with the `@Cacheable` annotation. The preceding code can be
    rewritten, as follows. This will prevent the recompilation of Longtask for the
    same value.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we saw how we can implement our own caching algorithm and how
    to make a generic algorithm. We looked at Spring support for caching, and different
    kinds of caching repositories in the Spring caching framework. We have demonstrated
    how caching can be used with annotations in the Spring MVC application. We have
    also discussed the scenario of removing cache and when is it ideal to opt for
    caching. Lastly, we also discussed the classes and interface that supports the
    caching mechanism in Spring framework.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapters, we shall look at Spring with the thymeleaf framework integration
    and Spring Webservices.
  prefs: []
  type: TYPE_NORMAL
