- en: Big Data With Hadoop
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hadoop has become the de facto standard in the world of big data, especially
    over the past three to four years. Hadoop started as a subproject of Apache Nutch
    in 2006 and introduced two key features related to distributed filesystems and
    distributed computing, also known as MapReduce, that caught on very rapidly among
    the open source community. Today, there are thousands of new products that have
    been developed leveraging the core features of Hadoop, and it has evolved into
    a vast ecosystem consisting of more than 150 related major products. Arguably,
    Hadoop was one of the primary catalysts that started the big data and analytics
    industry.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will discuss the background and core concepts of Hadoop,
    the components of the Hadoop platform, and delve deeper into the major products
    in the Hadoop ecosystem. We will learn about the core concepts of distributed
    filesystems and distributed processing and optimizations to improve the performance
    of Hadoop deployments. We''ll conclude with real-world hands-on exercises using
    the **Cloudera Distribution of Hadoop** (**CDH**). The topics we will cover are:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The basics of Hadoop
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The core components of Hadoop
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hadoop 1 and Hadoop 2
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Hadoop Distributed File System
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Distributed computing principles with MapReduce
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Hadoop ecosystem
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overview of the Hadoop ecosystem
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hive, HBase, and more
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hadoop Enterprise deployments
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In-house deployments
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud deployments
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hands-on with Cloudera Hadoop
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using HDFS
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Hive
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MapReduce with WordCount
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The fundamentals of Hadoop
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In 2006, Doug Cutting, the creator of Hadoop, was working at Yahoo!. He was
    actively engaged in an open source project called Nutch that involved the development
    of a large-scale web crawler. A web crawler at a high level is essentially software
    that can browse and index web pages, generally in an automatic manner, on the
    internet. Intuitively, this involves efficient management and computation across
    large volumes of data. In late January of 2006, Doug formally announced the start
    of Hadoop. The first line of the request, still available on the internet at [https://issues.apache.org/jira/browse/INFRA-700,](https://issues.apache.org/jira/browse/INFRA-700)
    was *The Lucene PMC has voted to split part of Nutch into a new subproject named
    Hadoop*. And thus, Hadoop was born.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: 'At the onset, Hadoop had two core components : **Hadoop Distributed File System**
    (**HDFS**) and MapReduce. This was the first iteration of Hadoop, also now known
    as Hadoop 1\. Later, in 2012, a third component was added known as **YARN** (**Yet
    Another Resource Negotiator**) which decoupled the process of resource management
    and job scheduling. Before we delve into the core components in more detail, it
    would help to get an understanding of the fundamental premises of Hadoop:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5dbca749-d341-4994-ad32-89f3820278d2.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
- en: Doug Cutting's post at [https://issues.apache.org/jira/browse/NUTCH-193](https://issues.apache.org/jira/browse/NUTCH-193)
    announced his intent to separate **Nutch Distributed FS** (**NDFS**) and MapReduce
    to a new subproject called Hadoop.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: The fundamental premise of Hadoop
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The fundamental premise of Hadoop is that instead of attempting to perform a
    task on a single large machine, the task can be subdivided into smaller segments
    that can then be delegated to multiple smaller machines. These so-called smaller
    machines would then perform the task on their own portion of the data. Once the
    smaller machines have completed their tasks to produce the results on the tasks
    they were allocated, the individual units of results would then be aggregated
    to produce the final result.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: 'Although, in theory, this may appear relatively simple, there are various technical
    considerations to bear in mind. For example:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Is the network fast enough to collect the results from each individual server?
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can each individual server read data fast enough from the disk?
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If one or more of the servers fail, do we have to start all over?
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If there are multiple large tasks, how should they be prioritized?
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果有多个大任务，应该如何设置优先级？
- en: There are many more such considerations that must be considered when working
    with a distributed architecture of this nature.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理这种性质的分布式架构时，还有许多其他考虑因素。
- en: The core modules of Hadoop
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hadoop的核心模块
- en: 'The core modules of Hadoop consist of:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop的核心模块包括：
- en: '**Hadoop Common**: Libraries and other common helper utilities required by
    Hadoop'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Hadoop Common**：Hadoop所需的库和其他常见的辅助工具'
- en: '**HDFS**: A distributed, highly-available, fault-tolerant filesystem that stores
    data'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HDFS**：存储数据的分布式、高可用、容错的文件系统'
- en: '**Hadoop MapReduce**: A programming paradigm involving distributed computing
    across commodity servers (or nodes)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Hadoop MapReduce**：涉及跨商品服务器（或节点）的分布式计算的编程范式'
- en: '**Hadoop YARN**: A framework for job scheduling and resource management'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Hadoop YARN**：作业调度和资源管理的框架'
- en: Of these core components, YARN was introduced in 2012 to address some of the
    shortcomings of the first release of Hadoop. The first version of Hadoop (or equivalently,
    the first model of Hadoop) used HDFS and MapReduce as its main components. As
    Hadoop gained in popularity, the need to use facilities beyond those provided
    by MapReduce became more and more important. This, along with some other technical
    considerations, led to the development of YARN.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些核心组件中，YARN于2012年推出，以解决Hadoop首次发布的一些缺点。Hadoop的第一个版本（或者等效地说是Hadoop的第一个模型）使用HDFS和MapReduce作为其主要组件。随着Hadoop的流行，使用MapReduce提供的设施之外的设施的需求变得越来越重要。这，再加上一些其他技术考虑因素，导致了YARN的开发。
- en: Let's now look at the salient characteristics of Hadoop as itemized previously.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下之前列举的Hadoop的显著特点。
- en: Hadoop Distributed File System - HDFS
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hadoop分布式文件系统 - HDFS
- en: The HDFS forms the underlying basis of all Hadoop installations. Files, or more
    generally data, is stored in HDFS and accessed by the nodes of Hadoop.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: HDFS构成了所有Hadoop安装的基础。文件，或者更一般地说是数据，存储在HDFS中，并由Hadoop的节点访问。
- en: 'HDFS performs two main functions:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: HDFS执行两个主要功能：
- en: '**Namespaces**: Provides namespaces that hold cluster metadata, that is, the
    location of data in the Hadoop cluster'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**命名空间**：提供保存集群元数据的命名空间，即Hadoop集群中数据的位置'
- en: '**Data storage**: Acts as storage for data used in the Hadoop cluster'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据存储**：作为Hadoop集群中使用的数据的存储'
- en: The filesystem is termed as distributed since the data is stored in chunks across
    multiple servers. An intuitive understanding of HDFS can be gained from a simple
    example, as follows. Consider a large book that consists of Chapters A - Z. In
    ordinary filesystems, the entire book would be stored as a single file on the
    disk. In HDFS, the book would be split into smaller chunks, say a chunk for Chapters
    A - H, another for I - P, and a third one for Q - Z. These chunks are then stored
    in separate racks (or bookshelves as with this analogy). Further, the chapters
    are replicated three times, such that there are three copies of each of the chapters.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 文件系统被称为分布式，因为数据存储在多台服务器上的块中。可以通过一个简单的例子直观地理解HDFS。考虑一本由A-Z章组成的大书。在普通文件系统中，整本书将作为一个单独的文件存储在磁盘上。在HDFS中，这本书将被分割成更小的块，比如A-H章的一个块，I-P章的另一个块，以及Q-Z章的第三个块。这些块然后存储在不同的机架（或者用这个类比来说是书架）上。此外，每一章都会被复制三次，这样每一章都会有三个副本。
- en: 'Suppose, further, the size of the entire book is 1 GB, and each chapter is
    approximately 350 MB:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 假设整本书的大小是1GB，每一章大约是350MB：
- en: '![](img/46a63885-0e9f-4d87-a5d3-c9edb3be3e6a.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/46a63885-0e9f-4d87-a5d3-c9edb3be3e6a.png)'
- en: A bookshelf analogy for HDFS
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: HDFS的书架类比
- en: 'Storing the book in this manner achieves a few important objectives:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式存储书籍实现了一些重要的目标：
- en: Since the book has been split into three parts by groups of chapters and each
    part has been replicated three times, it means that our process can read the book
    in parallel by querying the parts from different servers. This reduces I/O contention
    and is a very fitting example of the proper use of parallelism.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于这本书已经被分成了三部分，每部分都被章节组复制了三次，这意味着我们的进程可以通过从不同服务器查询部分来并行读取书。这减少了I/O争用，非常适合并行使用的一个很好的例子。
- en: If any of the racks are not available, we can retrieve the chapters from any
    of the other racks as there are multiple copies of each chapter available on different
    racks.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果任何一个机架不可用，我们可以从任何其他机架检索章节，因为每个章节在不同机架上都有多个副本。
- en: If a task I have been given only requires me to access a single chapter, for
    example, Chapter B, I need to access only the file corresponding to Chapters A-H.
    Since the size of the file corresponding to Chapters A-H is a third the size of
    the entire book, the time to access and read the file would be much smaller.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我被分配的任务只需要访问单独的一章，比如说B章，我只需要访问对应A-H章的文件。由于对应A-H章的文件大小是整本书的三分之一，访问和读取文件的时间会更短。
- en: Other benefits, such as selective access rights to different chapter groups
    and so on, would also be possible with such a model.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他好处，比如对不同章节组的选择性访问权限等，也是可能的。
- en: 'This may be an over-simplified analogy of the actual HDFS functionality, but
    it conveys the basic principle of the technology - that large files are subdivided
    into blocks (chunks) and spread across multiple servers in a high-availability
    redundant configuration. We''ll now look at the actual HDFS architecture in a
    bit more detail:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是对实际HDFS功能的过度简化的类比，但它传达了这项技术的基本原则 - 大文件被分割成块（块），并以高可用性冗余配置分布在多台服务器上。现在我们将更详细地看一下实际的HDFS架构：
- en: '![](img/a9eace37-f3d1-4033-9f6c-9b85130a311b.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a9eace37-f3d1-4033-9f6c-9b85130a311b.png)'
- en: 'The HDFS backend of Hadoop consists of:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop的HDFS后端包括：
- en: '**NameNode**: This can be considered the master node. The NameNode contains
    cluster metadata and is aware of what data is stored in which location - in short,
    it holds the namespace. It stores the entire namespace in RAM and when a request
    arrives, provides information on which servers hold the data required for the
    task. In Hadoop 2, there can be more than one NameNode. A secondary NameNode can
    be created that acts as a helper node to the primary. As such, it is not a backup
    NameNode, but one that helps in keeping cluster metadata up to date.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NameNode**：这可以被认为是主节点。NameNode包含集群元数据，并知道存储在哪个位置的数据 - 简而言之，它持有命名空间。它将整个命名空间存储在RAM中，当请求到达时，提供有关哪些服务器持有所需任务的数据的信息。在Hadoop
    2中，可以有多个NameNode。可以创建一个辅助节点作为辅助节点。因此，它不是备用NameNode，而是帮助保持集群元数据最新的节点。'
- en: '**DataNode**: The DataNodes are the individual servers that are responsible
    for storing chunks of the data and performing compute operations when they receive
    a new request. These are primarily commodity servers that are less powerful in
    terms of resource and capacity than the NameNode that stores the cluster metadata.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DataNode**：DataNodes是负责存储数据块并在收到新请求时执行计算操作的单独服务器。这些主要是低性能的商品服务器，资源和容量比存储集群元数据的NameNode要低。'
- en: Data storage process in HDFS
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HDFS中的数据存储过程
- en: 'The following points should give a good idea of the data storage process:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 以下几点应该能很好地说明数据存储过程：
- en: All data in HDFS is written in blocks, usually of size 128 MB. Thus, a single
    file of say size 512 MB would be split into four blocks (4 * 128 MB). These blocks
    are then written to DataNodes. To maintain redundancy and high availability, each
    block is replicated to create duplicate copies. In general, Hadoop installations
    have a replication factor of three, indicating that each block of data is replicated
    three times.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: HDFS中的所有数据都是以块的形式写入的，通常大小为128 MB。因此，一个大小为512 MB的单个文件将被分成四个块（4 * 128 MB）。然后将这些块写入DataNodes。为了保持冗余和高可用性，每个块都会被复制以创建副本。一般来说，Hadoop安装的复制因子为3，表示每个数据块都会被复制三次。
- en: This guarantees redundancy such that in the event one of the servers fails or
    stops responding, there would always be a second and even a third copy available.
    To ensure that this process works seamlessly, the DataNode places the replicas
    in independent servers and can also ensure that the blocks are placed on servers
    in different racks in a data center. This is due to the fact that even if all
    the replicas were on independent servers, but all the servers were on the same
    rack, a rack power failure would mean that no replica would be available.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这样可以保证冗余性，以便在其中一个服务器失败或停止响应时，始终有第二个甚至第三个副本可用。为了确保这个过程能够无缝运行，DataNode将副本放在独立的服务器上，并且还可以确保数据中心不同机架上的服务器上放置块。这是因为即使所有副本都在独立的服务器上，但所有服务器都在同一个机架上，机架电源故障将意味着没有副本可用。
- en: 'The general process of writing data into HDFS is as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据写入HDFS的一般过程如下：
- en: The NameNode receives a request to write a new file to HDFS.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NameNode收到一个请求，要求将新文件写入HDFS。
- en: Since the data has to be written in blocks or chunks, the HDFS client (the entity
    that made the request) begins caching data into a local buffer and once the buffer
    reaches the allocated chunk size (for example, 128 MB), it informs the NameNode
    that it is ready to write the first block (chunk) of data.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于数据必须以块或分块的形式写入，HDFS客户端（发出请求的实体）开始将数据缓存到本地缓冲区，一旦缓冲区达到分配的块大小（例如128 MB），它会通知NameNode准备好写入第一个数据块（分块）。
- en: The NameNode, based on information available to it about the state of the HDFS
    cluster, responds with information on the destination DataNode where the block
    needs to be stored.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据其对HDFS集群状态的了解，NameNode会提供关于需要存储块的目标DataNode的信息。
- en: The HDFS client writes data to the target DataNode and informs the NameNode
    once the write process for the block has completed.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: HDFS客户端将数据写入目标DataNode，并在块的写入过程完成后通知NameNode。
- en: The target DataNode, subsequently, begins copying its copy of the block of data
    to a second DataNode, which will serve as a replica for the current block.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随后，目标DataNode开始将其数据块的副本复制到第二个DataNode，后者将作为当前块的副本。
- en: Once the second DataNode completes the write process, it sends the block of
    data to the third DataNode.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个DataNode完成写入过程后，它将数据块发送给第三个DataNode。
- en: This process repeats until all the blocks corresponding to the data (or equivalently,
    the file) are copied across different nodes.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个过程重复进行，直到所有与数据（或等效地，文件）对应的块都被复制到不同的节点上。
- en: Note that the number of chunks will depend on the file size. The following image
    illustrated the distribution of the data across 5 datanodes.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，块的数量将取决于文件大小。以下图示了数据在5个数据节点之间的分布。
- en: '![](img/0750456b-a13d-47df-ba1d-d734014189af.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0750456b-a13d-47df-ba1d-d734014189af.png)'
- en: Master Node and Data Nodes
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 主节点和数据节点
- en: 'The HDFS architecture in the first release of Hadoop, also known as Hadoop
    1, had the following characteristics:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop的第一个版本中的HDFS架构，也称为Hadoop 1，具有以下特点：
- en: 'Single NameNode: Only one NameNode was available, and as a result it also acted
    as a single point of failure since it stored all the cluster metadata.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个NameNode：只有一个NameNode可用，因此它也是单点故障，因为它存储了整个集群的元数据。
- en: Multiple DataNodes that stored blocks of data, processed client requests, and
    performed I/O operations (create, read, delete, and so on) on the blocks.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储数据块的多个DataNodes，处理客户端请求，并在数据块上执行I/O操作（创建、读取、删除等）。
- en: The HDFS architecture in the second release of Hadoop, also known as Hadoop
    2, provided all the benefits of the original HDFS design and also added some new
    features, most notably, the ability to have multiple NameNodes that can act as
    primary and secondary NameNodes. Other features included the facility to have
    multiple namespaces as well as HDFS Federation.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'HDFS Federation deserves special mention. The following excerpt from [http://hadoop.apache.org](http://hadoop.apache.org)
    explains the subject in a very precise manner:'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The NameNodes are federated; the NameNodes are independent and do not require
    coordination with each other. The DataNodes are used as common storage for blocks
    by all the NameNodes. Each DataNode registers with all the NameNodes in the cluster.
    DataNodes send periodic heartbeats and block reports.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: The secondary NameNode is not a backup node in the sense that it cannot perform
    the same tasks as the NameNode in the event that the NameNode is not available.
    However, it makes the NameNode restart process much more efficient by performing
    housekeeping operations.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: These operations (such as merging HDFS snapshot data with information on data
    changes) are generally performed by the NameNode when it is restarted and can
    take a long time depending on the amount of changes since the last restart. The
    secondary NameNode can, however, perform these housekeeping operations whilst
    the primary NameNode is still in operation, such that in the event of a restart
    the primary NameNode can recover much faster. Since the secondary NameNode essentially
    performs a checkpoint on the HDFS data at periodic intervals, it is also known
    as the checkpoint node.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Hadoop MapReduce
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MapReduce was one of the seminal features of Hadoop that was arguably the most
    instrumental in bringing it to prominence. MapReduce works on the principle of
    dividing larger tasks into smaller subtasks. Instead of delegating a single machine
    to compute a large task, a network of smaller machines can instead be used to
    complete the smaller subtasks. By distributing the work in this manner, the task
    can be completed much more efficiently relative to using a single-machine architecture.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: This is not dissimilar to how we go about completing work in our day-to-day
    lives. An example will help to make this clearer.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: An intuitive introduction to MapReduce
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's take the example of a hypothetical organization consisting of a CEO, directors,
    and managers. The CEO wants to know how many new hires have joined the company.
    The CEO sends a request to his or her directors to report back the number of hires
    in their departments. The directors in turn send a request to managers in their
    individual departments to provide the number of new hires. The managers provide
    the number to the directors, who in turn send the final value back to the CEO.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be considered to be a real-world example of MapReduce. In this analogy,
    the task was finding the number of new hires. Instead of collecting all the data
    on his or her own, the CEO delegated it to the directors and managers who provided
    their own individual departmental numbers as illustrated in the following image:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1d094fb0-9403-42f9-b7cc-04ad8f8e0747.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
- en: The Concept of MapReduce
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: In this rather simplistic scenario, the process of splitting a large task (find
    new hires in the entire company), into smaller tasks (new hires in each team),
    and then a final re-aggregation of the individual numbers, is analogous to how
    MapReduce works.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: A technical understanding of MapReduce
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MapReduce, as the name implies, has a map phase and a reduce phase. A map phase
    is generally a function that is applied on each element of its input, thus modifying
    its original value.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: MapReduce generates key-value pairs as output.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '**Key-value:** A key-value pair establishes a relationship. For example, if
    John is 20 years old, a simple key-value pair could be (John, 20). In MapReduce,
    the map operation produces such key-value pairs that have an entity and the value
    assigned to the entity.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**键值对：** 键值对建立了一种关系。例如，如果约翰今年20岁，一个简单的键值对可以是（约翰，20）。在MapReduce中，映射操作产生这样的键值对，其中有一个实体和分配给该实体的值。'
- en: In practice, map functions can be complex and involve advanced functionalities.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，映射函数可能会复杂，并涉及高级功能。
- en: 'The reduce phase takes the key-value input from the map function and performs
    a summarization operation. For example, consider the output of a map operation
    that contains the ages of students in different grades in a school:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 减少阶段接收来自映射函数的键值输入，并执行汇总操作。例如，考虑包含学校不同年级学生年龄的映射操作的输出：
- en: '| **Student name** | **Class** | **Age** |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| **学生姓名** | **班级** | **年龄** |'
- en: '| John | Grade 1 | 7 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| John | 年级1 | 7 |'
- en: '| Mary | Grade 2 | 8 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| Mary | 年级2 | 8 |'
- en: '| Jill | Grade 1 | 6 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| Jill | 年级1 | 6 |'
- en: '| Tom | Grade 3 | 10 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| Tom | 年级3 | 10 |'
- en: '| Mark | Grade 3 | 9 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| Mark | 年级3 | 9 |'
- en: We can create a simple key-value pair, taking for example the value of Class
    and Age (it can be anything, but I'm just taking these to provide the example).
    In this case, our key-value pairs would be (Grade 1, 7), (Grade 2, 8), (Grade
    1, 6), (Grade 3, 10), and (Grade 3, 9).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建一个简单的键值对，例如取班级和年龄的值（可以是任何值，但我只是拿这些来提供例子）。在这种情况下，我们的键值对将是（年级1，7），（年级2，8），（年级1，6），（年级3，10）和（年级3，9）。
- en: An operation that calculates the average of the ages of students in each grade
    could then be defined as a reduce operation.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 然后可以将计算每个年级学生年龄平均值的操作定义为减少操作。
- en: More concretely, we can sort the output and then send the tuples corresponding
    to each grade to a different server.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，我们可以对输出进行排序，然后将与每个年级对应的元组发送到不同的服务器。
- en: For example, Server A would receive the tuples (Grade 1, 7) and (Grade 1, 6),
    Server B would receive the tuple (Grade 2, 8), Server C would receive the tuples
    (Grade 3, 10) and (Grade 3, 9). Each of the servers, A, B, and C, would then find
    the average of the tuples and report back (Grade 1, 6.5), (Grade 2, 8), and (Grade
    3, 9.5).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，服务器A将接收元组（年级1，7）和（年级1，6），服务器B将接收元组（年级2，8），服务器C将接收元组（年级3，10）和（年级3，9）。然后，服务器A、B和C将找到元组的平均值并报告（年级1，6.5），（年级2，8）和（年级3，9.5）。
- en: Observe that there was an intermediary step in this process that involved sending
    the output to a particular server and sorting the output to determine which server
    it should be sent to. And indeed, MapReduce requires a shuffle and sort phase,
    whereby the key-value pairs are sorted so that each reducer receives a fixed set
    of unique keys.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这个过程中有一个中间步骤，涉及将输出发送到特定服务器并对输出进行排序，以确定应将其发送到哪个服务器。事实上，MapReduce需要一个洗牌和排序阶段，其中键值对被排序，以便每个减少器接收一组固定的唯一键。
- en: In this example, if say, instead of three servers there were only two, Server
    A could be assigned to computing averages for keys corresponding to Grades 1 and
    2, and Server B could be assigned to computing an average for Grade 3.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，如果说，而不是三个服务器，只有两个，服务器A可以被分配为计算与年级1和2对应的键的平均值，服务器B可以被分配为计算年级3的平均值。
- en: 'In Hadoop, the following process takes place during MapReduce:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在Hadoop中，MapReduce期间发生以下过程：
- en: The client sends a request for a task.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 客户端发送任务请求。
- en: NameNode allocates DataNodes (individual servers) that will perform the map
    operation and ones that will perform the reduce operation. Note that the selection
    of the DataNode server is dependent upon whether the data that is required for
    the operation is *local to the server*. The servers where the data resides can
    only perform the map operation.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NameNode分配将执行映射操作和执行减少操作的DataNodes（单独的服务器）。请注意，DataNode服务器的选择取决于所需操作的数据是否*位于服务器本地*。数据所在的服务器只能执行映射操作。
- en: DataNodes perform the map phase and produce key-value (k,v) pairs.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DataNodes执行映射阶段并产生键值（k，v）对。
- en: As the mapper produces the (k,v) pairs, they are sent to these reduce nodes
    based on the *keys* the node is assigned to compute. The allocation of keys to
    servers is dependent upon a partitioner function, which could be as simple as
    a hash value of the key (this is default in Hadoop).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 当映射器生成（k，v）对时，它们根据节点分配的*键*发送到这些减少节点。键分配给服务器取决于分区函数，这可以是键的哈希值（这是Hadoop中的默认值）。
- en: Once the reduce node receives its set of data corresponding to the keys it is
    responsible to compute on, it applies the reduce function and generates the final
    output.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦减少节点接收到与其负责计算的键对应的数据集，它就应用减少函数并生成最终输出。
- en: Hadoop maximizes the benefits of data locality. Map operations are performed
    by servers that hold the data locally, that is, on disk. More precisely, the map
    phase will be executed only by those servers that hold the blocks corresponding
    to the file. By delegating multiple individual nodes to perform computations independently,
    the Hadoop architecture can perform very large-scale data processing effectively.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop最大程度地利用了数据局部性。映射操作由本地保存数据的服务器执行，即在磁盘上。更准确地说，映射阶段将仅由持有文件对应块的服务器执行。通过委托多个独立节点独立执行计算，Hadoop架构可以有效地执行非常大规模的数据处理。
- en: Block size and number of mappers and reducers
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 块大小和映射器和减少器的数量
- en: An important consideration in the MapReduce process is an understanding of HDFS
    block size, that is, the size of the chunks into which the files have been split.
    A MapReduce task that needs to access a certain file will need to perform the
    map operation on each block representing the file. For example, given a 512 MB
    file and a 128 MB block size, four blocks would be needed to store the entire
    file. Hence, a MapReduce operation will at a minimum require four map tasks whereby
    each map operation would be applied to each subset of the data (that is, each
    of the four blocks).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在MapReduce过程中的一个重要考虑因素是理解HDFS块大小，即文件被分割成的块的大小。需要访问某个文件的MapReduce任务将需要对表示文件的每个块执行映射操作。例如，给定一个512MB的文件和128MB的块大小，需要四个块来存储整个文件。因此，MapReduce操作将至少需要四个映射任务，其中每个映射操作将应用于数据的每个子集（即四个块中的每一个）。
- en: If the file was very large, however, and required say, 10,000 blocks to store,
    this means we would have required 10,000 map operations. But, if we had only 10
    servers, then we'd have to send 1,000 map operations to each server. This might
    be sub-optimal as it can lead to a high penalty due to disk I/O operations and
    resource allocation settings on a per-map basis.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果文件非常大，比如需要10,000个块来存储，这意味着我们需要10,000个映射操作。但是，如果我们只有10台服务器，那么我们将不得不向每台服务器发送1,000个映射操作。这可能是次优的，因为它可能导致由于磁盘I/O操作和每个映射的资源分配设置而产生高惩罚。
- en: The number of reducers required is summarized very elegantly on Hadoop Wiki
    ([https://wiki.apache.org/hadoop/HowManyMapsAndReduces](https://wiki.apache.org/hadoop/HowManyMapsAndReduces)).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 所需的减少器数量在Hadoop Wiki上非常优雅地总结了（[https://wiki.apache.org/hadoop/HowManyMapsAndReduces](https://wiki.apache.org/hadoop/HowManyMapsAndReduces)）。
- en: 'The ideal reducers should be the optimal value that gets them closest to:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 理想的减少器应该是最接近以下值的最佳值：
- en: '* A multiple of the block size * A task time between 5 and 15 minutes * Creates
    the fewest files possible'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '* 块大小的倍数 * 5到15分钟之间的任务时间 * 创建尽可能少的文件'
- en: 'Anything other than that means there is a good chance your reducers are less
    than great. There is a tremendous tendency for users to use a REALLY high value
    ("More parallelism means faster!") or a REALLY low value ("I don''t want to blow
    my namespace quota!"). Both are equally dangerous, resulting in one or more of:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，很有可能你的减少器不太好。用户有极大的倾向使用一个非常高的值（“更多的并行性意味着更快！”）或一个非常低的值（“我不想超出我的命名空间配额！”）。这两种情况都同样危险，可能导致以下一种或多种情况：
- en: '* Terrible performance on the next phase of the workflow * Terrible performance
    due to the shuffle * Terrible overall performance because you''ve overloaded the
    namenode with objects that are ultimately useless * Destroying disk IO for no
    really sane reason * Lots of network transfers due to dealing with crazy amounts
    of CFIF/MFIF work'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '* 下一个工作流程阶段的性能差 * 由于洗牌而导致性能差 * 由于过载了最终无用的对象而导致整体性能差 * 没有真正合理的原因而破坏磁盘I/O * 由于处理疯狂数量的CFIF/MFIF工作而产生大量的网络传输'
- en: Hadoop YARN
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hadoop YARN
- en: YARN was a module introduced in Hadoop 2\. In Hadoop 1, the process of managing
    jobs and monitoring them was performed by processes known as JobTracker and TaskTracker(s).
    NameNodes that ran the JobTracker daemon (process) would submit jobs to the DataNodes
    which ran TaskTracker daemons (processes).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: YARN是Hadoop 2中引入的一个模块。在Hadoop 1中，管理作业和监视它们的过程是由称为JobTracker和TaskTracker的进程执行的。运行JobTracker守护进程（进程）的NameNodes会将作业提交给运行TaskTracker守护进程（进程）的DataNodes。
- en: 'The JobTracker was responsible for the co-ordination of all MapReduce jobs
    and served as a central administrator for managing processes, handling server
    failure, re-allocating to new DataNodes, and so on. The TaskTracker monitored
    the execution of jobs local to its own instance in the DataNode and provided feedback
    on the status to the JobTracker as shown in the following:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: JobTracker负责协调所有MapReduce作业，并作为管理进程、处理服务器故障、重新分配到新DataNodes等的中央管理员。TaskTracker监视DataNode中本地作业的执行，并向JobTracker提供状态反馈，如下所示：
- en: '![](img/77c0cfdf-fc44-4b4d-91fe-2d0709ee0109.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/77c0cfdf-fc44-4b4d-91fe-2d0709ee0109.png)'
- en: JobTracker and TaskTrackers
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: JobTracker和TaskTrackers
- en: This design worked well for a long time, but as Hadoop evolved, the demands
    for more sophisticated and dynamic functionalities rose proportionally. In Hadoop
    1, the NameNode, and consequently the JobTracker process, managed both job scheduling
    and resource monitoring. In the event the NameNode failed, all activities in the
    cluster would cease immediately. Lastly, all jobs had to be represented in MapReduce
    terms - that is, all code would have to be written in the MapReduce framework
    in order to be executed.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这种设计长时间以来运行良好，但随着Hadoop的发展，对更复杂和动态功能的需求也相应增加。在Hadoop 1中，NameNode，因此是JobTracker进程，管理作业调度和资源监控。如果NameNode发生故障，集群中的所有活动将立即停止。最后，所有作业都必须以MapReduce术语表示
    - 也就是说，所有代码都必须在MapReduce框架中编写才能执行。
- en: 'Hadoop 2 alleviated all these concerns:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop 2解决了所有这些问题：
- en: The process of job management, scheduling, and resource monitoring was decoupled
    and delegated to a new framework/module called YARN
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作业管理、调度和资源监控的过程被解耦并委托给一个名为YARN的新框架/模块
- en: A secondary NameNode could be defined which would act as a helper for the primary
    NameNode
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以定义一个辅助主NameNode，它将作为主NameNode的辅助
- en: Further, Hadoop 2.0 would accommodate frameworks beyond MapReduce
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，Hadoop 2.0将容纳MapReduce以外的框架
- en: Instead of fixed map and reduce slots, Hadoop 2 would leverage containers
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hadoop 2不再使用固定的映射和减少插槽，而是利用容器
- en: In MapReduce, all data had to be read from disk, and this was fine for operations
    on large datasets but it was not optimal for operations on smaller datasets. In
    fact, any tasks that required very fast processing (low latency), were interactive
    in nature, or had multiple iterations (thus requiring multiple reads from the
    disk for the same data), would be extremely slow.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: By removing these dependencies, Hadoop 2 allowed developers to implement new
    programming frameworks that would support jobs with diverse performance requirements,
    such as low latency and interactive real-time querying, iterative processing required
    for machine learning, different topologies such as the processing of streaming
    data, optimizations such as in-memory data caching/processing, and so on.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'A few new terms became prominent:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '**ApplicationMaster**: Responsible for managing the resources needed by applications.
    For example, if a certain job required more memory, the ApplicationMaster would
    be responsible for securing the required resource. An application in this context
    refers to application execution frameworks such as MapReduce, Spark, and so on.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Containers**: The unit of resource allocation (for example, 1 GB of memory
    and four CPUs). An application may require several such containers to execute.
    The ResourceManager allocates containers for executing tasks. Once the allocation
    is complete, the ApplicationMaster requests DataNodes to start the allocated containers
    and takes over the management of the containers.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ResourceManager**: A component of YARN that had the primary role of allocating
    resources to applications and functioned as a replacement for the JobTracker.
    The ResourceManager process ran on the NameNode just as the JobTracker did.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NodeManagers**: A replacement for TaskTracker, NodeManagers were responsible
    for reporting the status of jobs to the ResourceManager (RM) and monitoring the
    resource utilization of containers.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following image shows a high level view of the ResourceManager and NodeManagers
    in Hadoop 2.0:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9debf45a-4304-4551-9c7b-ac04b702b13f.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
- en: Hadoop 2.0
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 'The prominent concepts inherent in Hadoop 2 have been illustrated in the next
    image:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86aed323-c6e4-4dbe-9272-3fc5e50d9441.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
- en: Hadoop 2.0 Concepts
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Job scheduling in YARN
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is not uncommon for large Hadoop clusters to have multiple jobs running concurrently.
    The allocation of resources when there are multiple jobs submitted from multiple
    departments becomes an important and indeed interesting topic. Which request should
    receive priority if say, two departments, A and B, submit a job at the same time
    but each request is for the maximum available resources? In general, Hadoop uses
    a **First-In-First-Out** (**FIFO**) policy. That is, whoever submits the job first
    gets to use the resources first. But what if A submitted the job first but completing
    A's job will take five hours whereas B's job will complete in five minutes?
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: 'To deal with these nuances and variables in job scheduling, numerous scheduling
    methods have been implemented. Three of the more commonly used ones are:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '**FIFO**: As described above, FIFO scheduling uses a queue to priorities jobs.
    Jobs are executed in the order in which they are submitted.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CapacityScheduler**: CapacityScheduler assigns a value on the number of jobs
    that can be submitted on a per-department basis, where a department can indicate
    a logical group of users. This is to ensure that each department or group can
    have access to the Hadoop cluster and be able to utilize a minimum number of resources.
    The scheduler also allows departments to scale up beyond their assigned capacity
    up to a maximum value set on a per-department basis if there are unused resources
    on the server. The model of CapacityScheduler thus provides a guarantee that each
    department can access the cluster on a deterministic basis.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fair Schedulers**: These schedulers attempt to evenly balance the utilization
    of resources across different apps. While an even balance might not be feasible
    at a certain given point in time, balancing allocation over time such that the
    averages are more or less similar can be achieved using Fair Schedulers.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**公平调度程序**：这些调度程序试图在不同应用程序之间均匀平衡资源的利用。虽然在某个特定时间点上可能无法实现平衡，但通过随时间平衡分配，可以使用公平调度程序实现平均值更或多或少相似的目标。'
- en: These, and other schedulers, provide finely grained access controls (such as
    on a per-user or per-group basis) and primarily utilize queues in order to prioritize
    and allocate resources.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这些以及其他调度程序提供了精细的访问控制（例如基于每个用户或每个组的基础）并主要利用队列来优先和分配资源。
- en: Other topics in Hadoop
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hadoop中的其他主题
- en: A few other aspects of Hadoop deserve special mention. As we have discussed
    the most important topics at length, this section provides an overview of some
    of the other subjects of interest.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop还有一些其他方面值得特别提及。由于我们已经详细讨论了最重要的主题，本节概述了一些其他感兴趣的主题。
- en: Encryption
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加密
- en: Data encryption is mandated by official regulations for various types of data.
    In the US, data that identifies patient information is required to be compliant
    with the rules set forth by HIPAA that dictate how such records should be stored.
    Data in HDFS can be encrypted whilst at rest (on disk) and/or while in transit.
    The keys that are used to decrypt the data are generally managed by **Key Management
    Systems** (**KMSs**).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 数据加密是根据官方规定对各种类型的数据进行的。在美国，要求符合HIPAA规定的规则，对识别患者信息的数据进行加密存储。HDFS中的数据可以在静态状态（在磁盘上）和/或传输过程中进行加密。用于解密数据的密钥通常由密钥管理系统（KMS）管理。
- en: User authentication
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用户认证
- en: Hadoop can use the native user-authentication methods of the server. For example,
    in Linux-based machines, users can be authenticated based on the IDs defined in
    the system's `/etc/passwd` files. In other words, Hadoop inherits the user authentication
    set up on the server side.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop可以使用服务器的本机用户认证方法。例如，在基于Linux的机器上，用户可以根据系统“/etc/passwd”文件中定义的ID进行身份验证。换句话说，Hadoop继承了服务器端设置的用户认证。
- en: User authentication via Kerberos, a cross-platform authentication protocol,
    is also commonly used in Hadoop clusters. Kerberos works based on a concept of
    tickets that grant privileges to users on a temporary as-needed basis. Tickets
    can be invalidated using Kerberos commands, thus restricting the users' rights
    to access resources on the cluster as needed.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 通过Kerberos进行用户认证，这是一种跨平台的认证协议，在Hadoop集群中也很常见。Kerberos基于授予用户临时权限的票据概念。可以使用Kerberos命令使票据无效，从而限制用户根据需要访问集群上的资源的权限。
- en: Note that even if the user is permitted to access data (user authentication),
    he or she can still be limited in what data can be accessed due to another feature
    known as authorization. The term implies that even if the user can authenticate
    and log in to the system, the user may be restricted to only the data the user
    is authorized to access. This level of authorization is generally performed using
    native HDFS commands to change directory and file ownerships to the named users.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，即使用户被允许访问数据（用户认证），由于另一个名为授权的功能，他或她仍然可能受到访问数据的限制。该术语意味着即使用户可以进行身份验证并登录到系统，用户可能仅限于可以访问的数据。通常使用本机HDFS命令执行此级别的授权，以更改目录和文件所有权为指定的用户。
- en: Hadoop data storage formats
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hadoop数据存储格式
- en: Since Hadoop involves storing very large-scale data, it is essential to select
    a storage type that is appropriate for your use cases. There are a few formats
    in which data can be stored in Hadoop, and the selection of the optimal storage
    format depends on your requirements in terms of read/write I/O speeds, how well
    the files can be compressed and decompressed on demand, and how easily the file
    can be split since the data will be eventually stored as blocks.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Hadoop涉及存储大规模数据，因此选择适合您用例的存储类型至关重要。Hadoop中可以以几种格式存储数据，选择最佳存储格式取决于您对读/写I/O速度的要求，文件可以按需压缩和解压缩的程度，以及文件可以被分割的容易程度，因为数据最终将被存储为块。
- en: 'Some of the popular and commonly used storage formats are as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 一些流行和常用的存储格式如下：
- en: '**Text/CSV**: These are plain text CSV files, similar to Excel files, but saved
    in plain text format. Since CSV files contain records on a per-line basis, it
    is naturally trivial to split the files up into blocks of data.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本/CSV**：这些是纯文本CSV文件，类似于Excel文件，但以纯文本格式保存。由于CSV文件包含每行的记录，因此将文件拆分为数据块是自然而然的。'
- en: '**Avro**: Avro was developed to improve the efficient sharing of data across
    heterogeneous systems. It stores both the schema as well as the actual data in
    a single compact binary using data serialization. Avro uses JSON to store the
    schema and binary format for the data and serializes them into a single Avro Object
    Container File. Multiple languages such as Python, Scala, C/C++, and others have
    native APIs that can read Avro files and consequently, it is very portable and
    well suited for cross-platform data exchange.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Avro**：Avro旨在改善在异构系统之间高效共享数据。它使用数据序列化，将模式和实际数据存储在单个紧凑的二进制文件中。Avro使用JSON存储模式和二进制格式存储数据，并将它们序列化为单个Avro对象容器文件。多种语言，如Python、Scala、C/C++等，都有本机API可以读取Avro文件，因此非常适合跨平台数据交换。'
- en: '**Parquet**: Parquet is a columnar data storage format. This helps to improve
    performance, sometimes significantly by permitting data storage and access on
    a per-column basis. Intuitively, if you were working on a 1 GB file with 100 columns
    and 1 million rows, and wanted to query data from only one of the 100 columns,
    being able to access just the individual column would be more efficient than having
    to access the entire file.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ORCFiles**: ORC stands for Optimized Row-Columnar. In a sense, it is a further
    layer of optimization over pure columnar formats such as Parquet. ORCFiles store
    data not only by columns, but also by rows, also known as stripes. A file with
    data in tabular format can thus be split into multiple smaller stripes where each
    stripe comprises of a subset of rows from the original file. By splitting data
    in this manner, if a user task requires access to only a small subsection of the
    data, the process can interrogate the specific stripe that holds the data.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SequenceFiles**: In SequenceFiles, data is represented as key-value pairs
    and stored in a binary serialized format. Due to serialization, data can be represented
    in a compact binary format that not only reduces the data size but consequently
    also improves I/O. Hadoop, and more concretely HDFS, is not efficient when there
    are multiple files of a small size, such as audio files. SequenceFiles solve this
    problem by allowing multiple small files to be stored as a single unit or SequenceFile.
    They are also very well suited for parallel operations that are splittable and
    are overall efficient for MapReduce jobs.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HDFS Snapshots:** HDFS Snapshots allow users to preserve data at a given
    point in time in a read-only mode. Users can create snapshots—in essence a replica
    of the data as it is at that point time—in in HDFS, such that they can be retrieved
    at a later stage as and when needed. This ensures that data can be recovered in
    the event that there is a file corruption or any other failure that affects the
    availability of data. In that regard, it can be also considered to be a backup.
    The snapshots are available in a .snapshot directory where they have been created.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Handling of node failures:** Large Hadoop clusters can contain tens of thousands
    of nodes. Hence it is likely that there would be server failures on any given
    day. So that the NameNode is aware of the status of all nodes in the cluster,
    the DataNodes send a periodic heartbeat to the NameNode. If the NameNode detects
    that a server has failed, that is, it has stopped receiving heartbeats, it marks
    the server as failed and replicates all the data that was local to the server
    onto a new instance.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: New features expected in Hadoop 3
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the time of writing this book, Hadoop 3 is in Alpha stage. Details on the
    new changes that will be available in Hadoop 3 can be found on the internet. For
    example, [http://hadoop.apache.org/docs/current/](http://hadoop.apache.org/docs/current/)
    provides the most up-to-date information on new changes to the architecture.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: The Hadoop ecosystem
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter should be titled as the Apache ecosystem. Hadoop, like all the
    other projects that will be discussed in this section, is an Apache project. Apache
    is used loosely as a short form for the open source projects that are supported
    by the Apache Software Foundation. It originally has its roots in the development
    of the Apache HTTP server in the early 90s, and today is a collaborative global
    initiative that comprises entirely of volunteers who participate in releasing
    open source software to the global technical community.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: Hadoop started out as, and still is, one of the projects in the Apache ecosystem.
    Due to its popularity, many other projects that are also part of Apache have been
    linked directly or indirectly to Hadoop as they support key functionalities in
    the Hadoop environment. That said, it is important to bear in mind that these
    projects can in most cases exist as independent products that can function without
    a Hadoop environment. Whether it would provide optimal functionality would be
    a separate topic.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we''ll go over some of the Apache projects that have had a
    great deal of influence as well as an impact on the growth and usability of Hadoop
    as a standard IT enterprise solution, as detailed in the following figure:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '| **Product** | **Functionality** |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
- en: '| Apache Pig | Apache Pig, also known as Pig Latin, is a language specifically
    designed to represent MapReduce programs through concise statements that define
    workflows. Coding MapReduce programs in the traditional methods, such as with
    Java, can be quite complex, and Pig provides an easy abstraction to express a
    MapReduce workflow and complex **Extract-Transform-Load** (**ETL**) through the
    use of simple semantics. Pig programs are executed via the Grunt shell. |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
- en: '| Apache HBase | Apache HBase is a distributed column-oriented database that
    sits on top of HDFS. It was modelled on Google''s BigTable whereby data is represented
    in a columnar format. HBase supports low-latency read-write across tables with
    billions of records and is well suited to tasks that require direct random access
    to data. More concretely, HBase indexes data in three dimensions - row, column,
    and timestamp. It also provides a means to represent data with an arbitrary number
    of columns as column values can be expressed as key-value pairs within the cells
    of an HBase table. |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
- en: '| Apache Hive | Apache Hive provides a SQL-like dialect to query data stored
    in HDFS. Hive stores data as serialized binary files in a folder-like structure
    in HDFS. Similar to tables in traditional database management systems, Hive stores
    data in tabular format in HDFS partitioned based on user-selected attributes.
    Partitions are thus subfolders of the higher-level directories or tables. There
    is a third level of abstraction provided by the concept of buckets, which reference
    files in the partitions of the Hive tables. |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
- en: '| Apache Sqoop | Sqoop is used to extract data from traditional databases to
    HDFS. Large enterprises that have data stored in relational database management
    systems can thus use Sqoop to transfer data from their data warehouse to a Hadoop
    implementation. |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
- en: '| Apache Flume | Flume is used for the management, aggregation, and analysis
    of large-scale log data. |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
- en: '| Apache Kafka | Kafka is a publish/subscribe-based middleware system that
    can be used to analyze and subsequently persist (in HDFS) streaming data in real
    time. |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
- en: '| Apache Oozie | Oozie is a workflow management system designed to schedule
    Hadoop jobs. It implements a key concept known as a **directed acyclic graph**
    (**DAG**), which will be discussed in our section on Spark. |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
- en: '| Apache Spark | Spark is one of the most significant projects in Apache and
    was designed to address some of the shortcomings of the HDFS-MapReduce model.
    It started as a relatively small project at UC Berkeley and evolved rapidly to
    become one of the most prominent alternatives to using Hadoop for analytical tasks.
    Spark has seen a widespread adoption across the industry and comprises of various
    other subprojects that provide additional capabilities such as machine learning,
    streaming analytics, and others. |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
- en: Hands-on with CDH
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will utilize the CDH QuickStart VM to work through some
    of the topics that have been discussed in the current chapter. The exercises do
    not have to be necessarily performed in a chronological order and are not dependent
    upon the completion of any of the other exercises.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: 'We will complete the following exercises in this section:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: WordCount using Hadoop MapReduce
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with the HDFS
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Downloading and querying data with Apache Hive
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: WordCount using Hadoop MapReduce
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this exercise, we will be attempting to count the number of occurrences of
    each word in one of the longest novels ever written. For the exercise, we have
    selected the book *Artamène ou le Grand Cyrus* written by Georges and/or Madeleine
    de Scudéry between 1649-1653\. The book is considered to be the second longest
    novel ever written, per the related list on Wikipedia ([https://en.wikipedia.org/wiki/List_of_longest_novels](https://en.wikipedia.org/wiki/List_of_longest_novels)).
    The novel consists of 13,905 pages across 10 volumes and has close to two million
    words.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin, we need to launch the Cloudera Distribution of Hadoop Quickstart
    VM in VirtualBox and double-click on the Cloudera Quickstart VM instance:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bcae8e19-32d6-4d52-9798-b80487582a38.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
- en: 'It will take some time to start up as it initializes all the CDH-related processes
    such as the DataNode, NameNode, and so on:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6f3d9fb5-6d5a-48ed-9227-371380b5fac8.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
- en: 'Once the process starts up, it will launch a default landing page that contains
    references to numerous tutorials related to Hadoop. We''ll be writing our MapReduce
    code in the Unix terminal for this section. Launch the terminal from the top-left
    menu, as shown in the following screenshot:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/26b31ed5-02d4-41c1-a81a-e2184b90b038.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
- en: 'Now, we must follow these steps:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: Create a directory named `cyrus`. This is where we will store all the files
    which contain the text of the book.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run `getCyrusFiles.sh` as shown in step 4\. This will download the book into
    the `cyrus` directory.
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run `processCyrusFiles.sh` as shown. The book contains various Unicode and non-printable
    characters. Additionally, we would like to change all the words to lowercase in
    order to ignore double-counting words that are the same but have capitalizations.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This will produce a file called `cyrusprint.txt`. This document contains the
    entire text of the book. We will be running our MapReduce code on this text file.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Prepare `mapper.py` and `reducer.py`. As the name implies, `mapper.py` runs
    the map part of the MapReduce process. Similarly, `reducer.py` runs the reduce
    part of the MapReduce process. The file `mapper.py` will split the document into
    words and assign a value of one to each word in the document. The file, `reducer.py`,
    will read in the sorted output of `mapper.py` and sum the occurrences of the same
    word (by first initializing the count of the word to one and incrementing it for
    each new occurrence of the word). The final output is a file containing the count
    of each word in the document.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The steps are as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: 'Create `getCyrusFiles.sh` - this script will be used to retrieve the data from
    the web:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Create `processCyrusFiles.sh` - this script will be used to concatenate and
    cleanse the files that were downloaded in the previous step:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Change the permissions to 755 to make the `.sh` files executable at the command
    prompt:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Execute `getCyrusFiles.sh`:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Execute `processCyrusFiles.sh`:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Execute the following steps to copy the final file, named `cyrusprint.txt`,
    to HDFS, create the `mapper.py` and `reducer.py` scripts.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The files, `mapper.py` and `reducer.py`, are referenced on Glenn Klockwood's
    website ([http://www.glennklockwood.com/data-intensive/hadoop/streaming.html](http://www.glennklockwood.com/data-intensive/hadoop/streaming.html)),
    which provides a wealth of information on MapReduce and related topics.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows the contents of `mapper.py`:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Execute the mapper and reducer scripts that will perform the MapReduce operations
    in order to produce the word count. You may see error messages as shown here,
    but for the purpose of this exercise (and for generating the results), you may
    disregard them:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The results are stored in HDFS under the `/user/cloudera/output` directory
    in files prefixed with `part-` :'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To view the contents of the file use `hdfs dfs -cat` and provide the name of
    the file. In this case we are viewing the first 10 lines of the output:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Analyzing oil import prices with Hive
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will use Hive to analyze the import prices of oil in countries
    across the world from 1980-2016\. The data is available from the site of the **OECD**
    (**Organisation for Economic Co-operation and Development**) at the URL shown
    in the following screenshot:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/23401bea-8fb7-4edb-af54-e882c4086d69.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
- en: The actual CSV file is available at [https://stats.oecd.org/sdmx-json/data/DP_LIVE/.OILIMPPRICE.../OECD?contentType=csv&amp;detail=code&amp;separator=comma&amp;csv-lang=en](https://stats.oecd.org/sdmx-json/data/DP_LIVE/.OILIMPPRICE.../OECD?contentType=csv&detail=code&separator=comma&csv-lang=en).
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we''ll be loading the data in Hive, it makes sense to download the file
    into our home directory via the terminal in our Cloudera Quickstart CDH environment.
    The steps we''d execute are as follows:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the CSV file into the CDH environment:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/91b3f48c-3292-4ae8-bef9-e9b434b94fd9.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
- en: '[PRE9]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Clean the CSV file. Data cleansing is an area of core importance in data science.
    In practice, it is very common to receive files that will require some level of
    cleansing. This is due to the fact that there could be invalid characters or values
    in columns, missing data, missing or additional delimiters, and so on. We noted
    that various values were enclosed in double-quotes ("). In Hive, we can ignore
    the quotes by specifying the `quoteChar` property whilst creating the table. Since
    Linux also offers simple and easy ways to remove such characters, we used `sed`
    to remove the quotation marks:'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Moreover, in our downloaded file, `oil.csv`, we observed that there were non-printable
    characters that could cause issues. We removed them by issuing the following command:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '(Source: [http://alvinalexander.com/blog/post/linux-unix/how-remove-non-printable-ascii-characters-file-unix](http://alvinalexander.com/blog/post/linux-unix/how-remove-non-printable-ascii-characters-file-unix))'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we copied the new file (`oil_clean.csv`) to `oil.csv`. Since the `oil.csv`
    file already existed in the same folder, we were prompted with an overwrite message
    and we entered `yes`:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Log in to Cloudera Hue:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on Hue on the Bookmarks bar in the browser. This will bring up the Cloudera
    login screen. Log in using ID `cloudera` and password `cloudera`:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e279c451-220f-434d-947b-c166b798f4cf.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
- en: 'Click on Hue from the drop-down menu on Quick Start at the top of the Hue login
    window:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ada22afe-0776-4378-9f95-a056ff1077f5.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
- en: 'Create the table schema, load the CSV file, `oil.csv`, and view the records:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](img/7663083b-9243-4b24-ad98-cc522f0faae4.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
- en: Load the oil file.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that the table has been loaded into Hive, you can run miscellaneous Hive
    commands using HiveQL. A full set of these commands is available at [https://cwiki.apache.org/confluence/display/Hive/LanguageManual](https://cwiki.apache.org/confluence/display/Hive/LanguageManual).
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For instance, to find the maximum, minimum, and average value of oil prices
    in each country from 1980-2015 (the date range of the dataset), we can use familiar
    SQL operators. The query would be as follows:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Here is the screenshot of the same:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e414b22d-47af-4f7d-a052-474c1f7cf74d.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
- en: In similar ways, we can use an array of other SQL commands. The Hive Manual
    provides an in-depth look into these commands and the various ways data can be
    saved, queried, and retrieved.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: Hue includes a set of useful features such as data visualization, data download,
    and others that allow users to perform ad hoc analysis on the data.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: 'To access the visualization feature, click on the visualization icon underneath
    the grid icon in the results section, as shown in the following screenshot:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/499fcfb2-f240-4123-97d1-2f1bb8dcdd62.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
- en: 'Select Scatter. In Hue, this type of chart, also known more generally as a
    scatterplot, allows users to create multivariate charts very easily. Different
    values for the x and y axes, as well as scatter size and grouping, can be selected,
    as shown in the following screenshot:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/259f4b41-4364-4376-b13e-befe47bd30a6.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
- en: 'The following is a simple pie chart that can be constructed by selecting Pie
    in the drop-down menu:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6106cd02-6123-4778-9133-00a18ac7e5d1.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
- en: Joining tables in Hive
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hive supports advanced join functionalities. The following illustrates the process
    of using Left Join. As seen, the original table has data for each country represented
    by their three-letter country code. Since Hue supports map charts, we can add
    the values for latitude and longitude to overlay the oil pricing data on a world
    map.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: 'To do so, we''ll need to download a dataset containing the values for latitude
    and longitude:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Once the file has been downloaded and cleansed, define the schema and load
    the data in Hive:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![](img/c66e5c65-998c-425f-b7d3-0bbcb229eebb.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
- en: 'Join the oil data with the lat/long data:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](img/6ff9ec7c-634e-43a5-bc35-4187a92c525b.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
- en: We can now proceed with creating geospatial visualizations. It would be useful
    to bear in mind that these are preliminary visualizations in Hue that provide
    a very convenient means to view data. More in-depth visualizations can be developed
    on geographical data using shapefiles, polygons, and other advanced charting methods.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: 'Select Gradient Map from the drop-down menu and enter the appropriate values
    to create the chart, as shown in the following figure:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2b47321a-b355-411b-b262-9a5ea24c77cd.png)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
- en: 'The next chart was developed using the Marker Map option in the drop-down menu.
    It uses the three-character country code in order to place markers and associated
    values on the respective regions, as shown in the following figure:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/08fb5f5c-9fd6-4352-9d0b-39d28dd86133.png)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
- en: Summary
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter provided a technical overview of Hadoop. We discussed the core
    components and core concepts that are fundamental to Hadoop, such as MapReduce
    and HDFS. We also looked at the technical challenges and considerations of using
    Hadoop. While it may appear simple in concept, the inner workings and a formal
    administration of a Hadoop architecture can be fairly complex. In this chapter
    we highlighted a few of them.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: We concluded with a hands-on exercise on Hadoop using the Cloudera Distribution.
    For this tutorial, we used the CDH Virtual Machine downloaded earlier from Cloudera's
    website.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at NoSQL, an alternative or a complementary
    solution to Hadoop depending upon your individual and/or organization al needs.
    While Hadoop offers a far richer set of capabilities, if your intended use case(s)
    can be done with simply NoSQL solutions, the latter may be an easier choice in
    terms of the effort required.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
