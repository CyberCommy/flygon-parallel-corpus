- en: Chapter 11. Summarizing Logs with Awk
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the tasks that awk is really good at is filtering data from log files.
    These log files may be many lines in length, perhaps 250,000 or more. I have worked
    with data with over a millions lines. Awk can process these lines quickly and
    effectively. As an example, we will work with a web server access log with 30,000
    lines to show how effective and well written awk code can be. As we work our way
    through the chapter, we will also see different log files and review some of the
    techniques that we can employ with the `awk` command and the awk programming language
    to help with the reporting and administration of our services. In this chapter
    we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: HTTPD log file format
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Displaying data from web server logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summarizing HTTP access codes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Displaying the highest ranking client IP addresses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Listing browser data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with e-mail logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The HTTPD log file format
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When working with any a file, the first task is to become familiar with the
    file schema. In simple terms, we need to know what is represented by each field
    and what is used to delimit the fields. We will be working with the access log
    file from an Apache HTTPD web server. The location of the log file can be controlled
    from the `httpd.conf` file. The default log file location on a Debian based system
    is `/var/log/apache2/access.log`; other systems may use the `httpd` directory
    in place of `apache2`.
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate the layout of the file, I have installed a brand new instance
    of Apache2 on an Ubuntu 15.10 system. Once the web server was installed, we made
    a single access from the Firefox browser to the server from the local host.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `tail` command we can display the content of the log file. Although,
    to be fair, the use of `cat` will do just as well with this file, as it will have
    just a few lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the command and the contents of the file are shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The HTTPD log file format](img/00107.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The output does wrap a little onto the new lines but we do get a feel of the
    layout of the log. We can also see that even though we feel that we access just
    one web page, we are in fact accessing two items: the `index.html` and the `ubuntu-logo.png`.
    We also failed to access the `favicon.ico` file. We can see that the file is space
    separated. The meaning of each of the fields is laid out in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Field | Purpose |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Client IP address. |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Client identity as defined by RFC 1413 and the `identd` client. This
    is not read unless `IdentityCheck` is enabled. If it is not read the value will
    be with a hyphen. |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | The user ID of the user authentication if enabled. If authentication
    is not enabled the value will be a hyphen. |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | The date and time of the request in the format of `day/month/year:hour:minute:second
    offset`. |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | The actual request and method. |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | The return status code, such as 200 or 404. |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | File size in bytes. |'
  prefs: []
  type: TYPE_TB
- en: 'Even though these fields are defined by Apache, we have to be careful. The
    time, date, and time-zone is a single field and is defined within square braces;
    however, there are additional spaces inside the field between that data and the
    time-zone. To ensure that we print the complete time field if required, we need
    to print both `$4` and `$5`. This is shown in the following command example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We can view the command and the output it produces in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The HTTPD log file format](img/00108.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Displaying data from web logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have already had a preview of how we can use awk to view the logs files from
    the Apache web server; however, we will now move onto our demonstration file that
    has a greater and more varied content.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting entries by date
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Having seen how we can display the date, we should perhaps look at how we print
    entries from just one day. To do this, we can use the match operator in `awk`.
    This is denoted by the tilde or squiggly line, if you prefer. As we only need
    the date element, there is no need for us to use both the date and time-zone field.
    The following command shows how to print entries from 10th September 2014:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'For completeness, this command and partial output is shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Selecting entries by date](img/00109.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The round brackets or parentheses embrace the range of lines that we are looking
    for and we have omitted the main block, which ensures that we print the complete
    matching lines from the range. There is nothing stopping us from further filtering
    on the fields to print from the matching lines. For example, if we want to print
    out just the client IP address that is being used to access the web server we
    can print field `1`. This is shown in the following command example.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'If we want to be able to print the total number of accesses on a given date,
    we could pipe the entries through to the `wc` command. This is demonstrated in
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'However, if we want to use `awk` to do this for us, this will be more efficient
    than starting a new process and we can count the entries. If we use the built-in
    variable `NR,` we can print entire lines in the files not just those within the
    range. It is best to increment our own variable in the main block than matching
    the range for each line. The `END` block can be implemented to print the `count`
    variable we use. The following command line acts as an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![Selecting entries by date](img/00110.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The output of the count from both `wc` and the internal counter will give us
    `16205` as a result from the demonstration file. We should use the variable increment
    within the main block if we want to count and nothing else.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see this in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Selecting entries by date](img/00111.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Summarizing 404 errors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The status code of the request page is shown in field `9` of the log. The `404`
    status will represent the page not found error on the server, I am sure we have
    all seen that in our browsers at some stage. This may be indicative of a misconfigured
    link on your site or just produced by a browser searching for the icon image to
    display in tabbed browsers for the page. You can also identify potential threats
    to your site by requests looking for standard pages that may give an access to
    additional information on PHP driven sites, such as WordPress.
  prefs: []
  type: TYPE_NORMAL
- en: 'Firstly, we can solely print the status of the request:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now extend the code a little as well as ourselves and just print the
    `404` errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This is shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Summarizing 404 errors](img/00112.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We can extend this a little further by printing both the status code and the
    page that was being accessed. This will need us to print field `9` and field `7`.
    Simply put, this will be as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Many of these failed accessed pages will be duplicated. To summarize these
    records, we can use the command pipeline to achieve this with `sort` and `uniq`
    commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: To use the `uniq` command, the data must be pre-sorted; hence, we use the `sort`
    command to prepare the data.
  prefs: []
  type: TYPE_NORMAL
- en: Summarizing HTTP access codes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It is time for us to leave the pure command line and start working with the
    awk control files. As always, when the complexity of the required result set increases,
    we see an increase in the complexity of the `awk` code. We will create a `status.awk`
    file in our current directory. The file should look similar to the following file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we will strip down the main code block and this is very simple and sparse.
    This is a simple way to count each unique occurrence of a status code. Instead
    of using a simple variable, we feed this into an array. The array in this case
    is called a record. An array is a multi-values variable and the slots in the array
    are known as keys. So we will have a collection of variables stored in the array.
    For example, we expect to see entries for `record[200]` and `record[404]`. We
    populate each key with their occurrence count. Each time we find a `404` code,
    we increment the count that is stored in the associated key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `END` block, we create the summary information using a `for` loop to
    print out each key and value from the array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'To run this, the associated command line will be similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'To view the command and output, we have included the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Summarizing HTTP access codes](img/00113.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We can take this further and focus on the `404` errors. You could, of course,
    choose any of the status codes. We can see from the results that we have `4382`
    `404` status codes. To summarize these `404` codes, we will copy the `status.awk`
    to a new file named `404.awk`. We can edit the `404.awk` adding an `if` statement
    to work only on the `404` codes. The file should be similar to the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'If we execute the code with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be similar to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Summarizing HTTP access codes](img/00114.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Displaying the highest ranking IP address
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You should now realize some powers of `awk` and how immense the language structure
    is in itself. The data we have been able to produce from the 30K line file is
    truly powerful and easily extracted. We just need to replace the field we have
    used before with `$1`. This field represents the client IP address. If we make
    use of the following code, we will be able to print each IP Address and also the
    number of times it has been used to access the web server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We want to be able to extend this to show only the highest ranking of IP address,
    the address that has been used the most to access the site. The work, again, will
    mainly be in the `END` block and will make use of a comparison against the current
    highest ranking address. The following file can be created and saved as `ip.awk`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see the output of the command in the following screenshot. Part of the
    client IP address has been obscured as it is from my public web server:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Displaying the highest ranking IP address](img/00115.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The functionality of the code comes from within the `END` block. On entering
    the `END` block, we run into a `for` loop. We iterate through each entry in the
    `ip` array. We use the conditional `if` statement to see if the current value
    that we are iterating through is higher than the current maximum. If it is, this
    becomes the new highest entry. When the `loop` has finished, we print the IP address
    that has the highest entry.
  prefs: []
  type: TYPE_NORMAL
- en: Displaying the browser data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The browser that is used to access the web site is contained within the log
    file in field `12`. It may be interesting to display the list of browsers used
    to access your site. The following code will assist you in displaying the list
    of accesses by the reported browser:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see how we can create little plugins to `awk` with these files and
    adjust the field and array names to suit your own liking. The output is shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Displaying the browser data](img/00116.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Interestingly, we see that the Mozilla 4 and 5 make up the majority of the requesting
    client. We see that Mozilla 4 is listed here **1713** times. The Mozilla/5.0 entry
    here is malformed with an extra double-quote. It appears later with 27K accesses.
  prefs: []
  type: TYPE_NORMAL
- en: Working with e-mail logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have worked with logs from the Apache HTTP web server. The reality is that
    we can apply the same ideals and methodology to any log file. We will take a look
    at Postfix mail logs. The mail log holds all activity from the SMTP server and
    we can then see who has been sending e-mails to whom. The log file is usually
    located at `/var/log/mail.log`. I will access this on my Ubuntu 15.10 server that
    has a local e-mail delivery. All this means is that the STMP server is listening
    only to the localhost interface of `127.0.0.1`.
  prefs: []
  type: TYPE_NORMAL
- en: The log format will change a little depending on the type of message. For example,
    `$7` will contain `from` logs on outbound message, whereas inbound messages will
    contain `to`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to list all the inbound messages to the SMTP server, we can use
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'As the string `to` is very short, we can add identification to it by ensuring
    that the field begins with to using the `^`. The command and output is shown in
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Working with e-mail logs](img/00117.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: It will be easy to extend the `to` or `from` searches to also include users
    names. We can see the format of the delivered or received mail. Working with the
    same template we used with the Apache logs, we can easily display the highest
    recipient or sender.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We now have some heavy ammunition behind our text processing and we can begin
    to understand just how powerful `awk` can be. Working with real data is particularly
    useful in gauging the performance and accuracy of our searches. Having begun working
    with simple Apache entries on the newly installed Ubuntu 15.10 Apache web server,
    we soon migrated to the larger sample data from a live web server. With 30,000
    lines, this file gives us some real meat to work with and in no time we were able
    to produce credible reports. We closed up the return to the Ubuntu 15.10 server
    to analyze the Postfix SMTP logs. We can see that we can very much drag and drop
    the technology that we have previously used into the new log files.
  prefs: []
  type: TYPE_NORMAL
- en: Next up, we stick with `awk` and look at how we can report on the lastlog data
    and on flat XML files.
  prefs: []
  type: TYPE_NORMAL
