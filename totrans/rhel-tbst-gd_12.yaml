- en: Chapter 12. Root Cause Analysis of an Unexpected Reboot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this last chapter, we will put the troubleshooting methods and skills that
    you learned in previous chapters to the test. We will perform a root cause analysis
    of one of the most difficult real-world scenarios: an unexpected reboot.'
  prefs: []
  type: TYPE_NORMAL
- en: As we discussed in [Chapter 1](part0014_split_000.html#DB7S1-8ae10833f0c4428b9e1482c7fee089b4
    "Chapter 1. Troubleshooting Best Practices"), *Troubleshooting Best Practices*,
    a root cause analysis is a bit more involved than simply troubleshooting and resolving
    an issue. In Enterprise environments, you will find that every issue that causes
    a significant impact will require a root cause analysis (RCA). The reason for
    this is because Enterprise environments often have well-established processes
    of how incidents are supposed to be handled.
  prefs: []
  type: TYPE_NORMAL
- en: In general, when a significant incident occurs, the organization impacted by
    it wants to avoid it from happening again. You can see this in many industries
    even outside of technical environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we discussed in [Chapter 1](part0014_split_000.html#DB7S1-8ae10833f0c4428b9e1482c7fee089b4
    "Chapter 1. Troubleshooting Best Practices"), *Troubleshooting Best Practices*,
    a useful RCA has the following characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: The problem as it was reported
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The actual root cause of the problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A timeline of events and actions taken
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any key data points
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A plan of action to prevent the incident from re-occurring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For today's issue, we will use an incident to build a sample root cause analysis
    document. To do this, we will use the information gathering and troubleshooting
    steps you learned in previous chapters. While doing all of this, you will also
    learn to handle unexpected reboots, one of the worst incidents to identify the
    root cause for.
  prefs: []
  type: TYPE_NORMAL
- en: The reason unexpected reboots are difficult is that when the system reboots
    you often lose the information you need to identify the root cause of the issue.
    As we have seen in previous chapters, the more data we can collect during an issue,
    the more likely we are to identify the cause of the issue.
  prefs: []
  type: TYPE_NORMAL
- en: The information lost during reboots can often be the difference between identifying
    the root cause and not identifying the root cause.
  prefs: []
  type: TYPE_NORMAL
- en: A late night alert
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have been progressing through the chapters and solving many issues for
    our recent employer, we have also been gaining their confidence in our abilities.
    Recently, we were even placed on the **on call** rotation, which means that if
    issues occur after hours an alert will be sent to our phone by SMS.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, the first night of being on call we get an alert; the alert is not
    a good one.
  prefs: []
  type: TYPE_NORMAL
- en: '*ALERT: blog.example.com is no longer responding to ICMP Pings*'
  prefs: []
  type: TYPE_NORMAL
- en: When we were added to the on call rotation, our team lead informed us that any
    major incident that occurs after hours must also have an RCA performed. The reason
    for this is so that others in our group can learn and understand what we did to
    resolve the issue and how to prevent it from happening again.
  prefs: []
  type: TYPE_NORMAL
- en: As we discussed earlier one of the key components to a useful RCA is listing
    when things happen. A major event in our timeline is when we received the alert;
    based on our SMS message we can see that we received the alert on July 05th, 2015
    at 01:52 or rather; 1:52 A.M. on the fifth of July (welcome to on call!).
  prefs: []
  type: TYPE_NORMAL
- en: Identifying the issue
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'From the alert, we can see that our monitoring system was unable to perform
    `ICMP` pings to our company blog server. The first thing we should do is determine
    whether or not we can `ping` the server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'It seems that we are able to ping the server in question, so maybe this is
    a false alert? Just in case, let''s attempt to log in to the system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Looks like we were able to log in and the system is up and running; let's start
    taking a look around to check whether we can identify any issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'As covered in a previous chapter, the first command we always run is `w`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In this instance, this little habit has actually paid off quite well. With the
    output of the `w` command, we can see that this server has only been up for `9`
    minutes. It seems our monitoring system could not ping our server because it was
    rebooting.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We should take note that we were able to identify that the server was rebooted
    after logging in; this will be a critical event in our timeline.
  prefs: []
  type: TYPE_NORMAL
- en: Did someone reboot this server?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While we have just identified the root cause of the alert, this is not the
    root cause of the issue. We need to identify why the server rebooted. It''s not
    often (at least shouldn''t be) that servers reboot themselves; sometimes it can
    simply be someone performing maintenance on this server without letting others
    know. We can see if anyone has been logged into this server recently using the
    `last` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `last` command''s output starts with the latest logins at the top. This
    data is pulled from `/var/log/wtmp`, which is used to store login details. At
    the end of the last command''s output, we see the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This tells us how far back the `wtmp` log file goes; a pretty useful piece of
    information. If we want to see a specific number of logins, we could simply add
    the `–n` flag followed by the number of logins we wish to see.
  prefs: []
  type: TYPE_NORMAL
- en: This can be pretty useful in general; however, since we don't know how many
    logins there have been lately on this machine we will just use the default.
  prefs: []
  type: TYPE_NORMAL
- en: From the output we received, we can see that there haven't been any logins on
    this server recently. Outside of someone physically pressing the power button
    or unplugging this system, we can assume that a person did not reboot the server.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is another fact/event that we should use in our timeline.
  prefs: []
  type: TYPE_NORMAL
- en: What do the logs tell us?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since a person didn''t reboot this server, our next hypothesis is that this
    server was rebooted by either a software or hardware problem. The next logical
    step for us is to look through the system log files to determine what happened:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Since there is quite a bit of information here, let's break down what we see
    a little bit.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first task is finding a log message that is clearly written on boot. By
    identifying a log message that is written on boot, we will be able to identify
    which logs were written prior to and after the reboot. We will also be able to
    identify a boot time for our root cause documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The first log entry that looks promising is the message from `NetworkManager`
    at `01:50:32`. This message is stating that the `NetworkManager` service has started
    `dhclient`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `dhclient` process is used to make DHCP requests and configure network
    settings based on the reply. This process is generally only called when the network
    is being reconfigured or at boot time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: If we look at the preceding line, we can see that at 01:50:12, the `rsyslogd`
    process is `exiting on signal 15`. This means, the `rsyslogd` process was sent
    a signal to terminate, a pretty standard process during shutdown.
  prefs: []
  type: TYPE_NORMAL
- en: We can determine that at 01:50:12 the server was in the shutdown process and
    at 01:50:32 the server was in the boot process. This means, we should be looking
    at everything before 01:50:12 to determine why the system rebooted.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The shutdown time and boot time will also be needed for our root cause timelines.
  prefs: []
  type: TYPE_NORMAL
- en: From the preceding captured logs, we can see two processes wrote to `/var/log/messages`
    before 01:50; the `auditd` and watchdog processes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s first take a look at the `auditd` process. We can see a "low on disk
    space" message in the first line. Could our system have run into an issue due
    to low disk space? It''s possible, and it is something we can check right now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'It does seem like the filesystem is at 100 percent but something like that
    in itself would not typically cause a reboot. Considering the second `auditd`
    message displays **the daemon is suspending logging**; this would also not seem
    like a reboot procedure. Let''s keep looking and see what else we can identify:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The next two messages from the `watchdog` process are interesting. The first
    one states that the `loadavg` for the server is higher than a specified threshold.
    The second message is very interesting as it specifically states, "shutting down
    the system".
  prefs: []
  type: TYPE_NORMAL
- en: Could the `watchdog` process have rebooted this server? Maybe, but the first
    question is, what is the `watchdog` process?
  prefs: []
  type: TYPE_NORMAL
- en: Learning about new processes and services
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It''s not uncommon when digging through the `messages` log to find a process
    you have never used or seen before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Even on our basic example system, there are 115 unique commands in the process
    list. This is especially true when you add in a newer release such as Red Hat
    Enterprise Linux 7 (newer at the time of writing this). Each new release brings
    in new functionality, which might even mean new processes running by default.
    It's very hard to keep up with it all.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the sake of our example, `watchdog` is one of those cases. At this point,
    outside of inferring from the name that it watches things, we have no idea what
    this process does. So how do we learn more about it? Well, we either Google it,
    or `man` it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Based on the `man` page, we have identified that the `watchdog` service is
    actually used to determine whether the server is healthy. If the `watchdog` is
    unable to do this, it might reboot the server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: It seems from this log message that the watchdog software is the one that caused
    the reboot. Could it be that watchdog rebooted the system because the filesystems
    are full?
  prefs: []
  type: TYPE_NORMAL
- en: 'If we go further down the `man` page, we will see another piece of useful information,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'On the last "`test`" in this list, it states that the `watchdog` daemon can
    check whether the average work load is too high:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Given the `man` page and the preceding log message, it seems that `watchdog`
    didn't reboot the server because of the filesystem, but rather due to the load
    average of the server.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before going further, let's note that at 01:50:02 the `watchdog` process kicked
    off the reboot.
  prefs: []
  type: TYPE_NORMAL
- en: What caused the high load average?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While we have identified what rebooted the server, we still have not gotten
    to the root cause of the issue. We still need to figure out what caused the high
    load average. Unfortunately, this would classify as information that is lost during
    a reboot.
  prefs: []
  type: TYPE_NORMAL
- en: If the system was still experiencing a high load average, we would simply be
    able to use `top` or `ps` to figure out which processes are using the most CPU
    time. Once the system was rebooted however, any process that was causing a high
    load average would have been restarted.
  prefs: []
  type: TYPE_NORMAL
- en: Unless these processes started causing a high load average again, we have no
    way of identifying the source.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: However, we are able to identify when the load average started to increase and
    how high it went. This information might be useful as we investigate further,
    as we can use it to identify what time things started to go wrong.
  prefs: []
  type: TYPE_NORMAL
- en: 'To look at a historical view of the load average, we can use the `sar` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Lucky for us, it seems the `sar` commands collection interval is set to every
    `2` minutes. The default is 10 minutes, which means we would normally see a line
    for every 10 minutes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Looking at the output, we can see that at `01:46`, this system has hardly any
    CPU usage. However, starting at `01:48`, there was a `33` percent utilization
    of the CPU in the user space.
  prefs: []
  type: TYPE_NORMAL
- en: It also seems that at `01:50`, `sar` was able to capture the CPU utilization
    that was being used at `99.99` percent, with `87.8` percent being used by the
    user, and `12.19` percent being used by the system.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The above are all good facts to use during our root cause summary.
  prefs: []
  type: TYPE_NORMAL
- en: With this, we now know that our issue started sometime between `01:44` and `01:46`,
    we can see this from the CPU usage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the load average with the `–q` flag to see if the load
    averages match the CPU utilization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: With the **load average** measurements, we can see that all was quiet at `01:46`
    even though the CPU was high. However, in the next run at `01:48`, we could see
    the **run queue** at 14 and the 1 minute load average at 4.
  prefs: []
  type: TYPE_NORMAL
- en: What are the run queue and load average?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since we are looking at the run queue and load average, let's take a second
    to get an understanding of what these values mean.
  prefs: []
  type: TYPE_NORMAL
- en: In a very basic concept, the run queue value shows the number of processes in
    an active state waiting to be executed.
  prefs: []
  type: TYPE_NORMAL
- en: For more details, let's think about a CPU and how it works. A single CPU is
    able to perform only one task at a time. Most servers these days have multiple
    cores and sometimes multiple processors per server. On Linux, each core and thread
    (for hyper threaded CPUs) are seen as a single CPU.
  prefs: []
  type: TYPE_NORMAL
- en: Each one of these CPUs is able to execute one task at a time. If we had two
    CPU servers, our server could execute two tasks at a time.
  prefs: []
  type: TYPE_NORMAL
- en: Let's assume for a second that our 2 CPU system needs to execute four tasks
    at the same time. The system can execute two of those tasks but the other two
    tasks must wait until the first two are finished. When situations like this happen,
    the processes that are waiting are placed into a "run queue". When the system
    has processes in the run queue, they will be prioritized and executed once CPU's
    become available.
  prefs: []
  type: TYPE_NORMAL
- en: In our `sar` capture, we can see the run queue value was 14 at 01:48; this means
    that at that moment, there were 14 tasks waiting in the run queue for CPU.
  prefs: []
  type: TYPE_NORMAL
- en: Load average
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The load average is a bit different from the run queue, but not very. The load
    average is the average run queue value over a given amount of time. In our preceding
    example, we can see `ldavg-1` (this column is the average run queue length for
    the last minute).
  prefs: []
  type: TYPE_NORMAL
- en: The run queue value and the 1-minute load average can be different because the
    run queue value, as reported by `sar` is at the time of execution where the 1-minute
    load average is the run queue averaged over 60 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: A single capture of a high run queue might not necessarily mean there is an
    issue, especially if the 1-minute load average is not high. However, in our example,
    we can see that at `01:48`, our run queue had 14 tasks in queue, and at `01:50`,
    our run queue had 37 tasks in queue.
  prefs: []
  type: TYPE_NORMAL
- en: On top of that, we can see that at `01:50`, our 1-minute load average was 25.
  prefs: []
  type: TYPE_NORMAL
- en: Given the overlap with the CPU utilization, it seems that roughly around 01:46
    - 01:48, something happened to cause a high CPU utilization. Along with this high
    utilization, there were also a lot of tasks that needed to be executed but could
    not be.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We should take a second and note down the times and values we saw in `sar`,
    as these will be necessary details for the root cause summary.
  prefs: []
  type: TYPE_NORMAL
- en: Investigating the filesystem being full
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Earlier, we noticed that the filesystem was 100 percent full. Unfortunately,
    the version of `sysstat` we have installed doesn''t capture disk space usage.
    A useful thing to identify is when the filesystem filled up as compared to when
    our run queue started to increase:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: From the log messages we saw earlier, we could see the `auditd` process identified
    the low disk space at `01:48`. This is extremely close to the time our run queue
    spike was seen.
  prefs: []
  type: TYPE_NORMAL
- en: This is building towards a hypothesis that the problem's root cause was a filesystem
    filling up, which caused a process to either launch many CPU intensive tasks or
    block the CPU for other tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'While this is a sound theory, we have to prove it to be true. One way we can
    get closer to proving this is to identify what is utilizing the majority of disk
    space on this system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The preceding one-liner is a very useful method for identifying which directories
    or files are using the most space.
  prefs: []
  type: TYPE_NORMAL
- en: The du command
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The preceding one-liner uses the `sort` command, which you learned about in
    [Chapter 11](part0074_split_000.html#26I9K2-8ae10833f0c4428b9e1482c7fee089b4 "Chapter 11. Recovering
    from Common Failures"), *Recovering from Common Failures* to sort the output of
    `du`. The `du` command is a very useful command that can estimate the amount of
    space a given directory is using.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if we wanted to know how much space the `/var/tmp` directory was
    using, we could easily identify that with the following `du` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: A useful attribute of `du` is that, by default, it will not only list `/var/tmp`
    but also the directories within it. We can see that there are a few directories
    with nothing in them but the `/var/tmp/` directory contains 160 kb of data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is important to know that the size of `/var/tmp` is the size of the contents
    within `/var/tmp`, which includes the other subdirectories.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate the preceding point, I created a directory named "`somedir`" and
    put a 4 kb file within it. We can see from this subsequent `du` command that the
    `/var/tmp` directory is now showing 164 kb used.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `du` command has quite a number of flags that allow us to change how it
    outputs disk usage. In the preceding examples, the values are being printed in
    a human-readable format, thanks to the `–h` flag. In the one liner, these values
    are being represented in kilobytes due to the `–k` flag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: If we go back to the one-liner, we can see from the output that from the 38
    GB used in `/`, 34 GB is in the `/opt/myapp/queue` directory. This directory is
    pretty familiar to us, as we were troubleshooting issues with this directory in
    previous chapters.
  prefs: []
  type: TYPE_NORMAL
- en: From our previous experience, we know that this directory is used to queue messages
    received via a custom application.
  prefs: []
  type: TYPE_NORMAL
- en: Given the size of this directory, it's possible that before the reboot, the
    custom application was running on this server and filled up the filesystem.
  prefs: []
  type: TYPE_NORMAL
- en: 'We already know that this directory is consuming the majority of the space
    on this system. It would be useful to determine when the last file in this directory
    was created as this will give us a rough timeframe of when this application was
    running last:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: We can actually do this by performing an `ls` in the `/opt/myapp` directory.
    We can see from the preceding output that the `queue/` directory was last modified
    on July 5th at 01:50\. This correlates very nicely with our issues and at minimum,
    proves that the custom application was running prior to the reboot.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The timestamp of when this directory was last updated and the fact that this
    application was running are both items we will notate in our summary.
  prefs: []
  type: TYPE_NORMAL
- en: Based on the preceding information we can, at this point, safely say that at
    the time of the incident, the custom application was running, and had created
    enough files to fill up the filesystem.
  prefs: []
  type: TYPE_NORMAL
- en: We can also say that around the time the filesystem reached 100 percent utilized,
    the load average of the server spiked suddenly.
  prefs: []
  type: TYPE_NORMAL
- en: From these facts, we can create a hypothesis; our current working theory is
    that once the application filled the filesystem, it was no longer able to create
    files. This might have caused the same application to block CPU time or spawn
    many CPU tasks, which caused a high load average.
  prefs: []
  type: TYPE_NORMAL
- en: Why wasn't the queue directory processed?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since we know the custom application was the source of the filesystem issue,
    we also need to answer why.
  prefs: []
  type: TYPE_NORMAL
- en: 'In earlier chapters, you learned that this application''s queue directory is
    processed by a `cronjob` that runs as the "`vagrant`" user. Let''s take a look
    at when that cron job last ran by looking through the `/var/log/cron` log file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: According to the `/var/log/cron` directory, the last time the job ran was `June
    6th`. This timeline coincides roughly when this process was moved to another system,
    after this the server ran out of memory.
  prefs: []
  type: TYPE_NORMAL
- en: Could it be that the processor job was stopped but the application was not?
    Possibly, we know the application was running but let's check on the `processor`
    job.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can check if the processor job has been removed with the `crontab` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The `–l` (list) flag will cause the `crontab` command to print or list the cronjobs
    defined for the user executing it. When the `-u` (user) flag is added, it allows
    us to specify a user to list the cronjobs for, in this case, the `vagrant` user.
  prefs: []
  type: TYPE_NORMAL
- en: It appears from the list that the `processor` job hasn't been removed, but rather,
    it has been disabled. We can see that it has been disabled because the line starts
    with an `#`, which is used to specify comments in the `crontab` file.
  prefs: []
  type: TYPE_NORMAL
- en: This essentially turns the job into a comment, rather than a scheduled job.
    This means that the `crond` process will not execute this job.
  prefs: []
  type: TYPE_NORMAL
- en: A checkpoint on what you learned
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At this point, let's do a checkpoint on what we were able to identify and gather.
  prefs: []
  type: TYPE_NORMAL
- en: 'After logging into the system, we were able to determine that the server had
    rebooted. We were able to see in `/var/log/messages` that the `watchdog` process
    was responsible for rebooting the server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Based on the log messages in `/var/log/messages`, the watchdog process rebooted
    the server because of a high load. From `sar`, we could see that the load average
    went from 0 to 25 in a matter of a few minutes.
  prefs: []
  type: TYPE_NORMAL
- en: While performing our investigation, we were also able to identify that the server's
    `/` (root) filesystem is full. Not only is it full but also interestingly enough
    it was roughly 100 percent utilized just a few minutes before the system rebooted.
  prefs: []
  type: TYPE_NORMAL
- en: The reason the filesystem was in this condition was because the custom application
    in `/opt/myapp` was still running and creating files in `/opt/myapp/queue`. However,
    the job to clear this queue was not running as it has been commented out in the
    vagrant user's `crontab`.
  prefs: []
  type: TYPE_NORMAL
- en: Based on this, we can say that the root cause of our issue is most likely due
    to the filesystem filling up, which is due to the application running but not
    processing messages.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes you cannot prove everything
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At this point, we have identified about everything we can as to what caused
    the high load average. Since we don't have a snapshot of what processes were running
    at the time of the incident, we cannot say for certain that it was the custom
    application. We also cannot say for certain based on the information we could
    gather that it was triggered because of the filesystem filling up.
  prefs: []
  type: TYPE_NORMAL
- en: We could test this theory by duplicating this scenario in another system, but
    that is not necessarily something to take on at 2:00 A.M. on a weekend. Duplicating
    an issue to that degree is usually something to perform as a follow up activity.
  prefs: []
  type: TYPE_NORMAL
- en: At this point given the data we could find, we can be reasonably certain as
    to the root cause. In many cases, this is as close as you will get as you might
    run out of time to gather or simply not have data to base your root cause on.
  prefs: []
  type: TYPE_NORMAL
- en: Preventing reoccurrence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since we feel pretty confident about our hypothesis as to what happened, we
    now can move on to the final step of our root cause analysis; preventing the issue
    from reoccurring.
  prefs: []
  type: TYPE_NORMAL
- en: As we discussed in the beginning of our chapter, all useful root cause analysis
    reports include a plan of action. Sometimes, this plan of action is something
    to be performed immediately at the time of the issue. Sometimes, this plan is
    to be performed later as a long-term resolution.
  prefs: []
  type: TYPE_NORMAL
- en: For our issue, we are going to have both, immediate actions and long-term actions.
  prefs: []
  type: TYPE_NORMAL
- en: Immediate action
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first immediate action we need to take is to ensure that the systems primary
    function is healthy. In this case, the server's primary function is to serve the
    company's blog.
  prefs: []
  type: TYPE_NORMAL
- en: '![Immediate action](img/00009.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'This is easy enough to check by going to the blog address in a browser. We
    can see from the preceding screenshot that the blog is working as expected. Just
    to be sure, we can validate that the Apache service is running as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: From this, it looks like our web server has been online since the reboot, this
    is good as it means the blog has been working since the reboot as well.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sometimes, depending on the criticality of the system, it might be important
    to first validate that the system is up and running before even investigating
    the issue. As with anything, this really depends on the environment as there are
    hard and fast rules about which comes first.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know the blog is working as expected, we need to resolve the disk
    being full.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'As with earlier chapters, it seems the `queue` directory has quite a few messages
    waiting to be processed. In order to clear this properly, we will need to run
    the `processor` command manually, but there are a few extra steps we must take
    as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The first step we must take is to increase the number of files this system can
    have open at a time. We know this from past experience with the processor application
    and large amounts of messages.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The second step is to increase the user limitations imposed on the `vagrant`
    user; specifically, the number of open files limitation. This step needs to be
    performed in the same shell session that we will execute the `processor` command
    in. Once the step is complete, we can manually execute the `processor` command
    to process the queued messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that the messages have been processed, we can recheck the filesystem utilization
    with the `df` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the `/` filesystem is down to `10` percent utilization.
  prefs: []
  type: TYPE_NORMAL
- en: 'To ensure that we do not fill up this filesystem again, we validate that the
    custom application is currently stopped:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Since we cannot see any processes running under the name application, we can
    be assured that the application is not running currently.
  prefs: []
  type: TYPE_NORMAL
- en: Long-term actions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This brings us to our **long-term actions**. The long-term actions are actions
    that we will recommend in our root cause summary, but aren't taken at this moment.
  prefs: []
  type: TYPE_NORMAL
- en: The first long-term action to recommend is that the custom application be permanently
    removed from this system. Since we know that the application has been migrated
    to another system, it should no longer be needed on this server. However, the
    removal of this application is not something we should take on at 2 A.M. or without
    validating that it is truly no longer required.
  prefs: []
  type: TYPE_NORMAL
- en: The second long-term action would be to investigate adding monitoring solutions,
    which can take periodic snapshots of running processes and the CPU/state of those
    processes. If we had that information available to us during this RCA investigation,
    we would be able to prove, without a doubt, which process was causing a high load.
    Since that information is not available, we are left to make an educated guess.
  prefs: []
  type: TYPE_NORMAL
- en: Again, this would not be a task that we would want to take on during a late
    night call but rather something for a standard work day.
  prefs: []
  type: TYPE_NORMAL
- en: A sample Root Cause Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have all of the information we need, let's create a root cause analysis
    report. This report can be in any format, really, but I've found that something
    along the following lines works well.
  prefs: []
  type: TYPE_NORMAL
- en: Problem summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At approximately 1:50 A.M. on July 5, 2015 the server `blog.example.com` unexpectedly
    rebooted. The `watchdog` process initiated the reboot process due to a high load
    average on the server.
  prefs: []
  type: TYPE_NORMAL
- en: After investigation, the high load average appears to be caused by a custom
    e-mail application, which was left in a running state even though it has been
    migrated to another server.
  prefs: []
  type: TYPE_NORMAL
- en: From the data available, it seems the application consumed 100 percent of the
    root filesystem.
  prefs: []
  type: TYPE_NORMAL
- en: While I was unable to obtain process states from before the reboot, it appears
    the high load average might have also been due to the same application being unable
    to write to the disk.
  prefs: []
  type: TYPE_NORMAL
- en: Problem details
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The time at which the incident was reported—07/05/2015 at `01:52`
  prefs: []
  type: TYPE_NORMAL
- en: 'The timeline of the incident would be:'
  prefs: []
  type: TYPE_NORMAL
- en: An SMS alert came through at `01:52` stating `blog.example.com` was unreachable
    via the ICMP ping.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The first troubleshooting step performed was a ping of the server:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ping showed that the server was online
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logged into the server at `01:59` and determined that the server had rebooted.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Searched the `/var/log/messages` file and identified that the watchdog process
    had rebooted the server at `01:50:12`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Watchdog started the reboot process due to the high load average at `01:50:02`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: During investigation, we found that no users were logged in at the time of the
    incident
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The server started the boot process at `01:50:32`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: During the investigation, it was identified that the server had run out of available
    disk space at `01:48:01`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The load average of this system started to increase at approximately the same
    time reaching 25 at `01:50:05`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We identified that the `/opt/myapp/queue` directory was last modified at `01:50`
    and contained roughly 34 GB of data creating 100 percent disk utilization:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This suggests that the custom e-mail application was running until the server
    rebooted
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We found that the `processor` job has not run since June 6th, which means that
    the messages were not processed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Root cause
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The filesystem reached 100 percent utilization due to the custom application
    running without the `processor` job being executed via cron. The data collected
    suggests this caused a high load average, which trigged the `watchdog` process
    to reboot the server.
  prefs: []
  type: TYPE_NORMAL
- en: Action plan
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We should have the following steps in place:'
  prefs: []
  type: TYPE_NORMAL
- en: Validated that Apache is running and `Blog` is accessible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Validated that the custom application is not running after system reboot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Executed the processor job manually at 02:15 resolving disk space issues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further actions to be taken
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Remove the custom application from the server to prevent the application from
    accidently starting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Investigate the addition of process list monitoring to capture which processes
    are utilizing the CPU time during similar issues:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will help in resolution of any similar situations should they occur
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see in the preceding report, we have a high-level timeline showing
    what we were able to identify, how we identified it, and the actions we took to
    resolve the issue. All key components of a good root cause analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we covered how to respond to a very difficult issue: an unexpected
    reboot. We used the tools and methodologies we saw throughout this book to identify
    the root cause and create a root cause report.'
  prefs: []
  type: TYPE_NORMAL
- en: We used log files heavily throughout this book; in this chapter, we were able
    to use these logs to identify the process that rebooted the server. We also identified
    the reason `watchdog` decided to reboot the server, which was due to a high load
    average.
  prefs: []
  type: TYPE_NORMAL
- en: We were able to use tools such as `sar`, `df`, `du`, and `ls` to determine the
    timing and cause of the high load average. All of these tools are commands you
    learned about throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: With this last chapter, we covered quite a few examples that were covered earlier
    in this book. You learned how to troubleshoot web applications, performance issues,
    custom applications, and hardware problems. We did all of these using real-world
    examples with real-world solutions.
  prefs: []
  type: TYPE_NORMAL
- en: While this book covers quite a few topics, the goal of this book was to show
    you the concepts of troubleshooting issues with Red Hat Enterprise Linux systems.
    The examples might be commonplace or somewhat rare but the commands used in these
    examples are commands that are used daily during troubleshooting. The topics covered
    all provide a core competency with Linux and will provide you with the knowledge
    necessary to troubleshoot issues not directly covered in this book.
  prefs: []
  type: TYPE_NORMAL
