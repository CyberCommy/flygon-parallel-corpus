- en: DevOps with Container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are already familiar with a lot of DevOps tools that help us automate tasks
    and manage configuration at different stages of application delivery, but challenges
    still exist as applications become more micro and diverse. In this chapter, we
    will add another swiss army knife to our tool belt, namely Container. In doing
    so, we will seek to acquire the following skills:'
  prefs: []
  type: TYPE_NORMAL
- en: Container concepts and fundamentals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running Docker applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building Docker applications with `Dockerfile`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orchestrating multiple containers with Docker Compose
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The key feature of container is isolation. In this section, we will elaborate
    how container achieves it and why it matters in the software development life
    cycle to help establish a proper understanding of this powerful tool.
  prefs: []
  type: TYPE_NORMAL
- en: Resource isolation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When an application launches, it consumes CPU time, occupies memory space, links
    to its dependent libraries, and may write to disk, transmit packets, and access
    other devices. Everything it uses up is a resource, and is shared by all the programs
    on the same host. The idea of container is to isolate resources and programs to
    separate boxes.
  prefs: []
  type: TYPE_NORMAL
- en: You may have heard such terms as para-virtualization, **Virtual Machines** (**VMs**),
    BSD jails, and Solaris containers, which can also isolate the resources of a host.
    However, since their designs differ, they are fundamentally distinct but provide
    a similar isolation concept. For example, the implementation of a VM is for virtualizing
    the hardware layer with a hypervisor. If you want to run an application on a Virtual
    Machine, you have to install a full operating system first. In other words, the
    resources are isolated between guest operating systems on the same hypervisor.
    In contrast, container is built on top of Linux primitives, which means it can
    only run in an operating system with those capabilities. BSD jails and Solaris
    containers also work in a similar fashion on other operating systems. The isolation
    relationship of container and VMs is illustrated in the following diagram. Container
    isolates an application at the OS-layer, while VM-based separation is achieved
    by the operating system.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00026.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Linux container concept
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Container comprises several building blocks, the two most important being **namespaces**
    and **cgroups** (**control groups**). Both of them are Linux kernel features.
    Namespaces provide logical partitions of certain kinds of system resources, such
    as mounting point (`mnt`), process ID (`PID`), network (net), and so on. To explain
    the concept of isolation, let's look at some simple examples on the `pid` namespace.
    The following examples are all from Ubuntu 16.04.2 and util-linux 2.27.1.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we type `ps axf`, we will see a long list of running processes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '`ps` is a utility to report current processes on the system. `ps axf` is to
    list all processes in forest.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s enter a new `pid` namespace with `unshare`, which is able to disassociate
    a process resource part-by-part to a new namespace, and check the processes again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'You will find the `pid` of the shell process at the new namespace becoming
    `1`, with all other processes disappearing. That is to say, you have created a
    `pid` container. Let''s switch to another session outside the namespace, and list
    the processes again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You can still see the other processes and your shell process within the new
    namespace.
  prefs: []
  type: TYPE_NORMAL
- en: With the `pid` namespace isolation, processes in different namespaces cannot
    see each other. Nonetheless, if one process eats up a considerable amount of system
    resources, such as memory, it could cause the system to run out of memory and
    become unstable. In other words, an isolated process could still disrupt other
    processes or even crash a whole system if we don't impose resource usage restrictions
    on it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the `PID` namespaces and how an **out-of-memory**
    (**OOM**) event can affect other processes outside a child namespace. The bubbles
    are the process in the system, and the numbers are their PID. Processes in the
    child namespace have their own PID. Initially, there is still free memory available
    in the system. Later, the processes in the child namespace exhaust the whole memory
    in the system. The kernel then starts the OOM killer to release memory, and the
    victims may be processes outside the child namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00027.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'In light of this, `cgroups` is utilized here to limit resource usage. Like
    namespaces, it can set constraint on different kinds of system resources. Let''s
    continue from our `pid` namespace, stress the CPU with `yes > /dev/null`, and
    monitor it with `top`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Our CPU load reaches 100% as expected. Now let''s limit it with the CPU cgroup.
    Cgroups are organized as directories under `/sys/fs/cgroup/` (switch to the host
    session first):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Each of the directories represents the resources they control. It''s pretty
    easy to create a cgroup and control processes with it: just create a directory
    under the resource type with any name, and append the process IDs you''d like
    to control to `tasks`. Here we want to throttle the CPU usage of our `yes` process,
    so create a new directory under `cpu` and find out the PID of the `yes` process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ve just added `yes` into the newly created CPU group `box`, but the policy
    remains unset, and processes still run without restriction. Set a limit by writing
    the desired number into the corresponding file and check the CPU usage again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The CPU usage is dramatically reduced, meaning that our CPU throttle works.
  prefs: []
  type: TYPE_NORMAL
- en: These two examples elucidate how Linux container isolates system resources.
    By putting more confinements in an application, we can definitely build a fully
    isolated box, including filesystem and networks, without encapsulating an operating
    system within it.
  prefs: []
  type: TYPE_NORMAL
- en: Containerized delivery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To deploy applications, the configuration management tool is often used. It's
    true that it works well with its modular and code-based configuration design until
    the application stacks grow complex and diverse. Maintaining a large configuration
    manifest base is complicated. When we want to change one package, we'll have to
    deal with entangled and fragile dependencies between the system and application
    packages. It's not uncommon that some applications break inadvertently after upgrading
    an unrelated package. Moreover, upgrading the configuration management tool itself
    is also a challenging task.
  prefs: []
  type: TYPE_NORMAL
- en: In order to overcome such a conundrum, immutable deployments with pre-baked
    VM images are introduced. That is, whenever we have any update on the system or
    application packages, we'll build a full VM image against the change and deploy
    it accordingly. It solves a certain degree of package problems because we are
    now able to customize runtimes for applications that cannot share the same environments.
    Nevertheless, doing immutable deployment with VM images is costly. From another
    point of view, provisioning a VM for the sake of isolating applications rather
    than insufficient resources results in inefficient resource utilization, not to
    mention the overhead of booting, distributing, and running a bloating VM image.
    If we want to eliminate such inefficiency by sharing VM to multiple applications,
    we'll soon realize that we will run into further trouble, namely, resource management.
  prefs: []
  type: TYPE_NORMAL
- en: Container, here, is a jigsaw piece that snugly fits the deployment needs. A
    manifest of a container can be managed within VCS, and built into a blob image;
    no doubt the image can be deployed immutably as well. This enables developers
    to abstract from actual resources, and infrastructure engineers can escape from
    their dependency hell. Besides, since we only need to pack up the application
    itself and its dependent libraries, its image size would be significantly smaller
    than a VM's. Consequently, distributing a container image is more economical than
    a VM's. Additionally, we have already known that running a process inside a container
    is basically identical to running it on its Linux host and as such almost no overhead
    will be produced. To summarize, container is lightweight, self-contained, and
    immutable. This also gives a clear border to distinguish responsibilities between
    applications and infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many mature container engines such as Docker ([https://www.docker.com](https://www.docker.com))
    and rkt ([https://coreos.com/rkt](https://coreos.com/rkt)) that have already implemented
    features for production usages, so you don't need to start building one from scratch.
    Besides, the **Open Container Initiative** ([https://www.opencontainers.org](https://www.opencontainers.org)),
    an organization formed by container industry leaders, has framed some container
    specifications. Any implementation of those standards, regardless of the underlying
    platform, should have similar properties as OCI aims to provide, with seamless
    experience of containers across a variety of operating systems. In this book,
    we will use the Docker (community edition) container engine to fabricate our containerized
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Docker for Ubuntu
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Docker requires a 64-bit version of Yakkety 16.10, Xenial 16.04LTS, and Trusty
    14.04LTS. You can install Docker with `apt-get install docker.io`, but it usually
    updates more slowly than the Docker official repository. Here are the installation
    steps from Docker ([https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/#install-docker-ce](https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/#install-docker-ce)):'
  prefs: []
  type: TYPE_NORMAL
- en: 'Make sure you have the packages to allow `apt` repositories; get them if not:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Add Docker''s `gpg` key and verify if its fingerprint matches `9DC8 5822 9FC7
    DD38 854A E2D8 8D81 803C 0EBF CD88`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Set up the repository of `amd64` arch:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Update the package index and install Docker CE:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Installing Docker for CentOS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'CentOS 7 64-bit is required to run Docker. Similarly, you can get the Docker
    package from CentOS''s repository via `sudo yum install docker`. Again, the installation
    steps from Docker official guide ([https://docs.docker.com/engine/installation/linux/docker-ce/centos/#install-using-the-repository](https://docs.docker.com/engine/installation/linux/docker-ce/centos/#install-using-the-repository))
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install the utility to enable `yum` to use the extra repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Set up Docker''s repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Update the repository and verify if the fingerprint matches:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Install Docker CE and start it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Installing Docker for macOS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker wraps a micro Linux moby with the hypervisor framework to build a native
    application on macOS, which means we don't need third-party virtualization tools
    to develop Docker in Mac. To benefit from the Hypervisor framework, you must upgrade
    your macOS to 10.10.3 or above.
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the Docker package and install it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://download.docker.com/mac/stable/Docker.dmg](https://download.docker.com/mac/stable/Docker.dmg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Likewise, Docker for Windows requires no third-party tools. Check here for
    the installation guide: [https://docs.docker.com/docker-for-windows/install](https://docs.docker.com/docker-for-windows/install)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now you are in Docker. Try creating and running your first Docker container;
    run it with `sudo` if you are on Linux:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see that you''re under a `root` directory instead of your current
    one. Let''s check the processes list again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: It is isolated, as expected. You are all ready to work with container.
  prefs: []
  type: TYPE_NORMAL
- en: Alpine is a Linux distribution. Since it's really small in size, many people
    use it as their base image to build their application container.
  prefs: []
  type: TYPE_NORMAL
- en: Container life cycle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using containers is not as intuitive as the tools that we are used to work with.
    In this section, we will go through Docker usages from the most fundamental ideas
    to the extent that we are able to benefit from containers.
  prefs: []
  type: TYPE_NORMAL
- en: Docker basics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When `docker run alpine ls` is executed, what Docker did behind the scenes
    is:'
  prefs: []
  type: TYPE_NORMAL
- en: Find the image `alpine` locally. If not found, Docker will try to find and pull
    it from the public Docker registry to the local image storage.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extract the image and create a container accordingly.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Execute the entry point defined in the image with commands, which are the arguments
    after the image name. In this example, it is `ls`. The entry point by default
    is `/bin/sh -c` on the Linux-based Docker.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When the entry point process is exited, the container then exits.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An image is an immutable bundle of codes, libraries, configurations, and everything
    needed to run an application. A container is an instance of an image, which would
    actually be executed during runtime. You can use the `docker inspect IMAGE` and
    `docker inspect CONTAINER` commands to see the difference.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes when we need to enter a container for checking the image or updating
    something inside, we''ll use the option `-i` and `-t` (`--interactive` and `--tty`).
    Besides, option `-d` (`--detach`) enables you to run a container in detached mode.
    If you would like to interact with a detached container, `exec` and `attach` commands
    can do us a favor. The `exec` command allows us run a process in a running container,
    and `attach` works, as per its literal meaning. The following example demonstrates
    how to use them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Your Terminal should be flooded with `meow~` now. Switch to another Terminal
    and run `docker ps`, a command to get the status of containers, to find out the
    name and ID of the meowing container. Both the name and ID here are generated
    by Docker, and you can access a container with either of them. As a matter of
    convenience, the name can be assigned upon `create` or `run` with the `--name`
    flag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we get in the container and inspect its processes, we will see two shells:
    one is meowing and another one is where we are. Kill it with `kill -s 2 1` inside
    the container and we''ll see the whole container stopped as the entry point is
    exited. Finally, let''s list the stopped containers with `docker ps -a`, and clean
    them up with `docker rm CONTAINER_NAME` or `docker rm CONTAINER_ID`. Since Docker
    1.13, the `docker system prune` command has been introduced, which helps us clean
    up stopped containers and occupied resources with ease.'
  prefs: []
  type: TYPE_NORMAL
- en: Layer, image, container, and volume
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We know that an image is immutable; a container is ephemeral, and we know how
    to run an image as a container. Nevertheless, there's still a missing step on
    packing an image.
  prefs: []
  type: TYPE_NORMAL
- en: An image is a read-only stack that consists of one or more layers, and a layer
    is a collection of files and directories in the filesystem. To improve the disk
    size usage, layers are not locked to only one image but shared among images; which
    means that Docker simply stores only one copy of a base image locally regardless
    of how many images are derived from it. You can utilize the `docker history [image]`
    command to understand how an image is built. For example, there's only one layer
    in an Alpine Linux image if you type `docker history alpine`.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever a container is created, it adds a writable layer on top of the base
    image. Docker adopts the **copy-on-write** (**COW**) strategy on the layer. That
    is to say, a container reads against the layers of the base image where the target
    files are stored, and copies the file to its own writable layer if the file is
    modified. Such an approach prevents containers created from the same image intervening
    with each other. The `docker diff [CONTAINER]` command shows the difference between
    the container and its base image in terms of filesystem states. For example, if
    `/etc/hosts` in the base image is modified, Docker copies the file to the writable
    layer, and it will also be the only one file in the output of `docker diff`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the hierarchical structure of Docker''s images:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00028.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: It's important to note that data in the writable layer is deleted along with
    its container. To persist data, you commit the container layer with the `docker
    commit [CONTAINER]` command as a new image, or mount data volumes into a container.
  prefs: []
  type: TYPE_NORMAL
- en: 'A data volume allows a container''s reading and writing to bypass Docker''s
    filesystem, and it can be on a host''s directory or other storages, such as Ceph
    or GlusterFS. Therefore, any disk I/O against the volume can operate at native
    speeds depending on the underlying storage. Since the data is persistent outside
    a container, it can be reused and shared by multiple containers. Mounting a volume
    is done by specifying the `-v`(`--volume`) flag at `docker run` or `docker create`.
    The following example mounts a volume under `/chest` in the container, and leaves
    a file there. Afterwards, we use `docker inspect` to locate the data volume:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The default `tty` path of moby Linux provided by Docker CE on macOS is under:'
  prefs: []
  type: TYPE_NORMAL
- en: '`~/Library/Containers/com.docker.docker/Data/com.docker.driver.amd64-linux/tty`.'
  prefs: []
  type: TYPE_NORMAL
- en: You can attach to it with `screen`.
  prefs: []
  type: TYPE_NORMAL
- en: 'One use case of data volumes is sharing data between containers. To do so,
    we first create a container and mount volumes on it, and then mount one or more
    containers and reference the volume with `--volumes-from` flag. The following
    examples create a container with a data volume, `/share-vol`. Container A can
    put a file into it, and container B can read it as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition, data volumes can be mounted under a given host path, and of course
    the data inside is persistent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Distributing images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Registry is a service that stores, manages, and distributes images. Public services,
    such as Docker Hub ([https://hub.docker.com](https://hub.docker.com)) and Quay
    ([https://quay.io](https://quay.io)), converge all kinds of pre-built images of
    popular tools, such as Ubuntu and Nginx, and custom images from other developers.
    The Alpine Linux we have used many times is actually pulled from Docker Hub ([https://hub.docker.com/_/alpine](https://hub.docker.com/_/alpine)).
    Absolutely, you can upload your tool onto such services and share with everyone
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: If you need a private registry, but for some reason you don't want to subscribe
    to paid plans of registry service providers, you can always set up one on your
    own with registry ([https://hub.docker.com/_/registry](https://hub.docker.com/_/registry)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Before provisioning a container, Docker will try to locate the specified image
    in a rule indicated in the image name. An image name consists of three sections
    `[registry/]name[:tag]`, and it''s resolved with the following rules:'
  prefs: []
  type: TYPE_NORMAL
- en: If the `registry` field is left out, search for the name on Docker Hub
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the `registry` field is a registry server, search the name for it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can have more than one slash in a name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The tag defaults to `latest` if it's omitted
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example, an image name such as `gcr.io/google-containers/guestbook:v3`
    instructs Docker to download `v3` of `google-containers/guestbook` from `gcr.io`.
    Likewise, if you want to push an image to a registry, tag your image in the same
    manner and push it. To list the images you currently own in the local disk, use
    `docker images`, and remove an image with `docker rmi [IMAGE]`. The following
    example shows how to work between different registries: Download an `nginx` image
    from Docker Hub, tag it to a private registry path, and push it accordingly. Notice
    that though the default tag is `latest`, you have to tag and push it explicitly.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Most registry services ask for authentications if you are going to push images.
    The `docker login` is designed for this purpose. Sometimes you may receive an
    `image not found error` when attempting to pull an image, even though the image
    path is valid. It''s very likely that you are unauthorized with the registry that
    keeps the image. To resolve this problem, log in first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to distributed images via the registry service, there are options
    to dump images as a TAR archive, and import them back into the local repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '`docker commit [CONTAINER]`: Commits the changes of the container layer into
    a new image'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker save --output [filename] IMAGE1 IMAGE2 ...`: Saves one or more images
    to a TAR archive'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker load -i [filename]`: Loads a `tarball` image into the local repository'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker export --output [filename] [CONTAINER]`: Exports a container''s filesystem
    as a TAR archive'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker import --output [filename] IMAGE1 IMAGE2`: Imports a filesystem `tarball`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `commit` command with `save` and `export` looks pretty much the same. The
    main difference is that a saved image preserves files in-between layers even if
    they are to be deleted eventually; on the other hand, an exported image squashes
    all intermediate layers into one final layer. Another difference is that a saved
    image keeps metadata such as layer histories, but those are not available at the
    exported one. As a result, the exported image is usually smaller in size.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram depicts the relationship of states between container
    and images. The captions on the arrows are the corresponding sub-commands of Docker:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00029.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Connect containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker provides three kinds of networks to manage communications within containers
    and between the hosts, namely `bridge`, `host`, and `none`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'By default, every container is connected to the bridge network upon creation.
    In this mode, every container is allocated a virtual interface as well as a private
    IP address, and the traffic going through the interface is bridged to the host''s
    `docker0` interface. Also, other containers within the same bridge network can
    connect to each other via their IP address. Let''s run one container that is feeding
    a short message over port `5000`, and observe its configuration. The `--expose`
    flag opens the given ports to the world outside a container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Here the container `greeter` is allocated with IP `172.17.0.2`. Now run another
    container connecting to it with this IP address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The `docker network inspect bridge` command gives configuration details, such
    as subnet segments and the gateway information.
  prefs: []
  type: TYPE_NORMAL
- en: 'On top of that, you can group some containers into one user-defined bridge
    network. It''s also the recommended way to connect multiple containers on a single
    host. The user-defined bridge network slightly differs from the default one, the
    major difference being that you can access a container from other containers with
    its name rather than IP address. Creating a network is done by `docker network
    create [NW-NAME]`, and attaching containers to it is done by the flag `--network
    [NW-NAME]` at the time of creation. The network name of a container defaults to
    its name, but it can be given another alias name with the `--network-alias` flag
    as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The host network works literally according to its name; every connected container
    shares the host''s network, but it loses the isolation property at the same time.
    The none network is a completely separated box. Regardless of ingress or egress,
    traffic is isolated inside as there is no network interface attached to the container.
    Here we attach a container that listens on port `5000` to the host network, and
    communicates with it locally:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: If you are using Docker CE for macOS, the host means the moby Linux on top of
    the hypervisor framework.
  prefs: []
  type: TYPE_NORMAL
- en: The interaction between the host and three network modes are shown in the following
    diagram. Containers in the host and bridge networks are attached with proper network
    interfaces and communicate with containers within the same network as well as
    the outside world, but the none network is kept away from the host interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00030.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Other than sharing the host network, the flag `-p(--publish) [host]:[container]`,
    on creating a container, also allows you to map a host port to a container. This
    flag implies `-expose`, as you'll need to open a container's port in any case.
    The following command launches a simple HTTP server at port `80`. You can view
    it with a browser as well.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Working with Dockerfile
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When assembling an image, whether by a Docker commit or export, optimizing the
    outcome in a managed way is a challenge, let alone integrating with a CI/CD pipeline.
    On the other hand, `Dockerfile` represents the building task in the form of as-a-code,
    which significantly reduces the complexities of building a task for us. In this
    section, we will describe how to map Docker commands into a `Dockerfile` and go
    a step further to optimizing it.
  prefs: []
  type: TYPE_NORMAL
- en: Writing your first Dockerfile
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A `Dockerfile` consists of a series of text instructions to guide the Docker
    daemon to form a Docker image. Generally, a `Dockerfile` is and must be starting
    with the directive `FROM`, and follows zero or more instructions. For example,
    we may have an image built from the following one liner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'It roughly equates to the following `Dockerfile`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Obviously, building with a `Dockerfile` is more concise and clear.
  prefs: []
  type: TYPE_NORMAL
- en: The `docker build [OPTIONS] [CONTEXT]` command is the only one command associated
    with building tasks. A context can be a local path, URL, or `stdin`; which denotes
    the location of the `Dockerfile`. Once a build is triggered, the `Dockerfile`,
    alongside everything under the context, will be sent to the Docker daemon beforehand,
    and then the daemon will start to execute instructions in the `Dockerfile` sequentially.
    Every execution of instructions results in a new cache layer, and the ensuing
    instruction is executed at the new cache layer in the cascade. Since the context
    will be sent to somewhere that is not guaranteed to be a local path, it's a good
    practice to put the `Dockerfile`, codes, the necessary files, and a `.dockerignore`
    file in an empty folder to make sure the resultant image encloses only the desired
    files.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `.dockerignore` file is a list indicating which files under the same directory
    can be ignored during the building time, and it typically looks like the following
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Generally, `docker build` will try to find a file named `Dockerfile` under
    the `context` to start a build; but sometimes we may like to give it another name
    for some reason. The `-f`(`--file`) flag is for this purpose. Also, another useful
    flag, `-t`(`--tag`), is able to give an image of one or more repository tags after
    an image is built. Say we want to build a `Dockerfile` named `builder.dck` under
    `./deploy` and label it with the current date and the latest tag, the command
    will be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Dockerfile syntax
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The building blocks of a `Dockerfile` are a dozen or more directives; most
    of them are a counterpart of the functions of `docker run/create` flags. Here
    we list the most essential ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '`FROM <IMAGE>[:TAG|[@DIGEST]`: This is to tell the Docker daemon which image
    the current `Dockerfile` is based on. It''s also the one and only instruction
    that must be in a `Dockerfile`, which means that you can have a `Dockerfile` that
    contains only one line. Like all the other image-relevant commands, the tag defaults
    to the latest if unspecified.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RUN`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The `RUN` instruction runs one line of a command at the current cache layer,
    and commits out the outcome. The main discrepancy between the two forms is in
    how the command is executed. The first one is called **shell form**, which actually
    executes commands in the form of `/bin/sh -c <commands>`; the other form is called
    **exec form**, and it treats the command with `exec` directly.
  prefs: []
  type: TYPE_NORMAL
- en: Using the shell form is similar to writing shell scripts, thus concatenating
    multiple commands by shell operators and line continuation, condition tests, or
    variable substitutions are totally valid. But bear in mind that commands are not
    processed by `bash` but `sh`.
  prefs: []
  type: TYPE_NORMAL
- en: The exec form is parsed as a JSON array, which means that you have to wrap texts
    with double quotes and escape reserved characters. Besides, as the command is
    not processed by any shell, the shell variables in the array will not be evaluated.
    On the other hand, if the shell doesn't exist in the base image, you can still
    use the exec form to invoke executables.
  prefs: []
  type: TYPE_NORMAL
- en: '`CMD`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The `CMD` sets default commands for the built image; it doesn't run the command
    during build time. If arguments are supplied at Docker run, the `CMD` configurations
    here are overridden. The syntax rule of `CMD` is almost identical to `RUN`; the
    first form is the exec form, and the third one is the shell form, which is the
    prepend a `/bin/sh -c` as well. There is another directive in which `ENTRYPOINT`
    interacts with `CMD`; three forms of `CMD` actually would be a prepend with `ENTRYPOINT`
    when a container starts. There can be many `CMD` directives in a `Dockerfile`,
    but only the last one will take effect.
  prefs: []
  type: TYPE_NORMAL
- en: '`ENTRYPOINT`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'These two forms are, respectively, the exec form and the shell form, and the
    syntax rules are the same as `RUN`. The entry point is the default executable
    for an image. That is to say, when a container spins up, it runs the executable
    configured by the `ENTRYPOINT`. When the `ENTRYPOINT` is combined with `CMD` and
    `docker run` arguments, writing in a different form would lead to very diverse
    behavior. Here are the organized rules of their combinations:'
  prefs: []
  type: TYPE_NORMAL
- en: 'If the `ENTRYPOINT` is in shell form, then the `CMD` and Docker `run` arguments
    would be ignored. The command will become:'
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'If the `ENTRYPOINT` is in exec form and the Docker `run` arguments are specified,
    then the `CMD` commands are overridden. The runtime command would be:'
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'If the `ENTRYPOINT` is in exec form and only `CMD` is configured, the runtime
    command would become the following for the three forms:'
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '`ENV`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The `ENV` instruction sets environment variables for the consequent instructions
    and the built image. The first form sets the key to the string after the first
    space, including special characters. The second form allows us to set multiple
    variables in a line, separated with spaces. If there are spaces in a value, either
    enclose it with double quotes or escape the space character. Moreover, the key
    defined with `ENV` also takes effect on variables in the same documents. See the
    following examples to observe the behavior of `ENV`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'And the output during the Docker build would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '`LABEL key1=value1 key2=value2 ...`: The usage of `LABEL` resembles `ENV`,
    but a label is stored only in the metadata section of the images and is used by
    other host programs instead of programs in a container. It deprecates the `maintainer`
    instruction in the following form:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: And we can filter objects with labels if a command has the `-f(--filter)` flag.
    For example, `docker images --filter label=maintainer=johndoe@example.com` queries
    out the images labeled with the preceding maintainer.
  prefs: []
  type: TYPE_NORMAL
- en: '`EXPOSE <port> [<port> ...]`: This instruction is identical to the `--expose`
    flag at `docker run/create`, exposing ports at the container created by the resulting
    image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`USER <name|uid>[:<group|gid>]`: The `USER` instruction switches the user to
    run the subsequent instructions. However, it cannot work properly if the user
    doesn''t exist in the image. Otherwise, you have to run `adduser` before using
    the `USER` directive.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`WORKDIR <path>`: This instruction sets the working directory to a certain
    path. The path would be created automatically if the path doesn''t exist. It works
    like `cd` in a `Dockerfile`, as it takes both relative and absolute paths and
    can be used multiple times. If an absolute path is followed by a relative path,
    the result would be relative to the previous path:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Also, environment variables set with `ENV` take effect on the path.
  prefs: []
  type: TYPE_NORMAL
- en: '`COPY:`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: This directive copies the source to a file or a directory in the building container.
    The source could be files or directories, as could be the destination. The source
    must be within the context path, as only files under the context path will be
    sent to the Docker daemon. Additionally, `COPY` makes use of `.dockerignore` to
    filter files that would be copied into the building container. The second form
    is for a use case where the path contains spaces.
  prefs: []
  type: TYPE_NORMAL
- en: '`ADD`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '`ADD` is quite analogous to `COPY` in terms of functionality: moving files
    into an image. More than copying files, `<src>` can also be URL or a compressed
    file. If `<src>` is a URL, `ADD` will download it and copy it into the image.
    If `<src>` is inferred as a compressed file, it will be extracted into `<dest>`
    path.'
  prefs: []
  type: TYPE_NORMAL
- en: '`VOLUME`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The `VOLUME` instruction creates data volumes at the given mount points. Once
    it has been declared during build time, any change in the data volume at consequent
    directives would not persist. Besides, mounting host directories in a `Dockerfile`
    or `docker build` isn''t doable because of portability issues: there''s no guarantee
    that the specified path would exist in the host. The effect of both syntax forms
    is identical; they only differ in syntax parsing; The second form is a JSON array,
    so characters such as `"\"` should be escaped.'
  prefs: []
  type: TYPE_NORMAL
- en: '`ONBUILD [Other directives]`: `ONBUILD` allows you to postpone some instructions
    to later builds in the derived image. For example, we may have the following two
    Dockerfiles:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The instruction then would be evaluated in the following order on `docker build`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Organizing a Dockerfile
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even though writing a `Dockerfile` is the same as composing a building script,
    there are some more factors we should consider to build efficient, secure, and
    stable images. Moreover, a `Dockerfile` itself is also a document, and keeping
    its readability eases management efforts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Say we have an application stack that consists of application codes, a database,
    and cache, we''ll probably start from a `Dockerfile`, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The first suggestion is making a container dedicated to one thing and one thing
    only. So, we''ll remove the installation and configuration at both `mysql` and
    `redis` in this `Dockerfile` at the beginning. Next, the code is moved into the
    container with `ADD`, which means we will very likely move the whole code repository
    into the container. Usually there are lots of files that are not directly relevant
    to the application, including VCS files, CI server configurations, or even build
    caches, and we probably wouldn''t like to pack them into an image. Thus, using
    a `.dockerignore` to filter out those files is suggested as well. Incidentally,
    due to the `ADD` instruction, we could do more than just add files into a build
    container. Using `COPY` is preferred in general, unless there is a real need not
    to do so. Now our `Dockerfile` is simpler, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'While building an image, the Docker engine will try to reuse the cache layer
    as much as possible, which notably reduces the build time. In our `Dockerfile`,
    we have to go through whole updating and dependency installation processes as
    long as there''s any update in our repository. To benefit from building caches,
    we''ll re-order the directives based on a rule of thumb: run less frequent instructions
    first.'
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, as we've described before, any change to the container filesystem
    results in a new image layer. Even though we deleted certain files in the consequent
    layer, those files are still occupied image sizes as they are still being kept
    at intermediate layers. Therefore, our next step is to minimize the image layers
    by simply compacting multiple `RUN` instructions. Moreover, to keep the readability
    of the `Dockerfile`, we tend to format the compacted `RUN` with the line continuation
    character, "`\`".
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to working with the building mechanisms of Docker, we''d also like
    to write a maintainable `Dockerfile` to make it more clear, predictable, and stable.
    Here are some suggestions:'
  prefs: []
  type: TYPE_NORMAL
- en: Use `WORKDIR` instead of inline `cd`, and use absolute path for `WORKDIR`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explicitly expose the required ports
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specify a tag for the base image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the exec form to launch an application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The first three suggestions are pretty straightforward, aimed at eliminating
    ambiguity. The last one is about how an application is terminated. When a stop
    request from the Docker daemon is sent to a running container, the main process
    (PID 1) will receive a stop signal (`SIGTERM`). If the process is not stopped
    after a certain period of time, the Docker daemon will send another signal (`SIGKILL`)
    to kill the container. The exec form and shell form differ here. In the shell
    form, the PID 1 process is "`/bin/sh -c`", not the application. Further, different
    shells don''t handle signals in the same way. Some forward the stop signal to
    child processes while some do not. The shell at Alpine Linux doesn''t forward
    them. As a result, to stop and clean up our application properly, using the `exec`
    form is encouraged. Combining those principles, we have the following `Dockerfile`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: There are still other practices to make a `Dockerfile` better, including starting
    from a dedicated and smaller base image such as Alpine-based ones rather than
    generic purpose distributions, using users other than `root` for security, and
    removing unnecessary files in the `RUN` in which they are joined.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-containers orchestration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we pack more and more applications into isolated boxes, we'll soon realize
    that we need a tool that is able to help us tackle many containers simultaneously.
    In this section, we'll move a step up from spinning up simply one single container
    to orchestrating containers in a band.
  prefs: []
  type: TYPE_NORMAL
- en: Piling up containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Modern systems are usually built as a stack made up of multiple components that
    are distributed over networks, such as application servers, caches, databases,
    message queues, and so on. Meanwhile, a component itself is also a self-contained
    system with many sub-components. What's more, the trend of microservices introduces
    additional degrees of complexity into such entangled relationships between systems.
    From this fact, even though container technology gives us a certain degree of
    relief regarding deployment tasks, launching a system is still difficult.
  prefs: []
  type: TYPE_NORMAL
- en: Say we have a simple application called kiosk, which connects to a Redis to
    manage how many tickets we currently have. Once a ticket is sold, it publishes
    an event through a Redis channel. The recorder subscribes the Redis channel and
    writes a timestamp log into a MySQL database upon receiving any event.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the **kiosk** and the **recorder**, you can find the code as well as the
    Dockerfiles here: [https://github.com/DevOps-with-Kubernetes/examples/tree/master/chapter2](https://github.com/DevOps-with-Kubernetes/examples/tree/master/chapter2).
    The architecture is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00031.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We know how to start those containers separately, and connect them to each
    other. Based on what we have discussed before, we would first create a bridge
    network, and run the containers inside:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Everything works well so far. However, if next time we want to launch the same
    stack again, our applications are very likely to start up prior to the databases,
    and they might fail if any incoming connection requests any change against the
    databases. In other words, we have to consider the startup order in our startup
    scripts. Additionally, scripts are also inept with problems such as how to deal
    with a random components crash, how to manage variables, how to scale out certain
    components, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Compose overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Docker Compose is the very tool that enables us to run multiple containers
    with ease, and it''s a built-in tool in the Docker CE distribution. All it does
    is read `docker-compose.yml` (or `.yaml`) to run defined containers. A `docker-compose`
    file is a YAML-based template, and it typically looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Launching it is pretty simple: save the template to `docker-compose.yml` and
    use the `docker-compose up` command to start it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: Let's see what `docker-compose` did behind the `up` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'Docker Compose is basically a medley of Docker functions for multiple containers.
    For example, the counterpart of `docker build` is `docker-compose build`; the
    previous one builds a Docker image, and so the later one builds Docker images
    listed in the `docker-compose.yml`. But there''s one thing that needs to be pointed
    out: the `docker-compose run` command is not the correspondent of `docker run`;
    it''s running a specific container from the configuration in the `docker-compose.yml`.
    In fact, the closest command to `docker run` is `docker-compose up`.'
  prefs: []
  type: TYPE_NORMAL
- en: The `docker-compose.yml` file consists of configurations of volumes, networks,
    and services. Besides, there should be a version definition to indicate which
    version of the `docker-compose` format is used. With such an understanding of
    the template structure, what the previous `hello-world` example does is quite
    clear; it creates a service called `hello-world` and it is created by the image
    `hello-world:latest`.
  prefs: []
  type: TYPE_NORMAL
- en: Since there is no network defined, `docker-compose` would create a new network
    with a default driver and connect services to the same network as shown in lines
    1 to 3 of the example's output.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the network name of a container would be the service's name. You
    may notice that the name displayed in the console slightly differs from its original
    one in the `docker-compose.yml`. It's because Docker Compose tries to avoid name
    conflicts between containers. As a result, Docker Compose runs the container with
    the name it generated, and makes a network-alias with the service name. In this
    example, both "`hello-world`" and "`cwd_hello-world_1`" are resolvable to other
    containers within the same network.
  prefs: []
  type: TYPE_NORMAL
- en: Composing containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As Docker Compose is the same as Docker in many aspects, it''s more efficient
    to understand how to write a `docker-compose.yml` with examples than start from
    `docker-compose` syntaxes. Here let''s go back to the `kiosk-example` earlier
    and start with a `version` definition and four `services`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'The `docker run` arguments for the `kiosk-example` are pretty simple, including
    a publishing port and an environment variable. On the Docker Compose side, we
    fill the source image, publishing port, and environment variables accordingly.
    Because Docker Compose is able to handle `docker build`, it would build images
    if those images cannot be found locally. We are very likely to want to leverage
    it to further decrease the effort of image management:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Converting the Docker run of the `recorder-example` and `redis` in the same
    manner, we have a template like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'For the MySQL part, it requires a data volume to keep its data as well as configurations.
    Therefore, in addition to the `lmysql` section, we add `volumes` at the level
    of `services` and an empty map `mysql-vol` to claim a data volume:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Combining all of preceding configurations, we have the final template, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'This file is put in the root folder of a project. The corresponding file tree
    is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Lastly, run `docker-compose up` to check if everything is fine. And we can check
    if our kiosk is up by sending a `GET /tickets` request.
  prefs: []
  type: TYPE_NORMAL
- en: Writing a template for Docker Compose is nothing more than this. We are now
    able to run an application in the stack with ease.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Starting from the very primitive elements of Linux container to Docker tool
    stacks, we went through every aspect of containerizing an application, including
    packing and running a Docker container, writing a `Dockerfile` for code-based
    immutable deployment, and manipulating multi-containers with Docker Compose. However,
    our abilities gained in this chapter only allow us to run and connect containers
    within the same host, which limits the possibility to build larger applications.
    As such, in the next chapter, we'll meet Kubernetes, unleashing the power of Container
    beyond the limits of scale.
  prefs: []
  type: TYPE_NORMAL
