- en: Building Applications Using Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, you were introduced to the sample application, and
    you were able to download and run the application locally. At present, your development
    environment is set up for local development; however, before you can get your
    application to production, you need to be able to package up your application
    and all of its dependencies, ensure the target production environment has the
    correct supporting operating system libraries and configuration, select an appropriate
    web server to host your application, and have a mechanism to be able to package
    this all together, ideally in a self-contained artifact that requires minimal
    external configuration. Traditionally, all of this has been very difficult to
    achieve reliably and consistently – but this is where Docker has changed the landscape
    dramatically. With Docker and supporting tools, you now have the ability to achieve
    all of this and more in a much faster, more reliable, more consistent, and more
    portable fashion than ever before.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will learn how to create a comprehensive workflow that
    allows you to test, build, and publish your applications in a portable, repeatable,
    and consistent manner using Docker. The approach you will learn about has numerous
    benefits—for example, you will be able to perform all tasks by running a handful
    of simple, easy-to-remember commands, and you will be able to do so without needing
    to install any application-specific or operating-system-specific dependencies
    into your local development or build environment. This makes it very easy to move
    to another machine or configure a continuous-delivery service to perform the same
    workflow—as long as you have the core Docker-based environment you set up in the
    previous chapter, you will be able to run the workflow on any machine, regardless
    of the specifics of your application or programming language.
  prefs: []
  type: TYPE_NORMAL
- en: You will learn how to define test and runtime environments for your application
    using a Dockerfile, configuring support for multi-stage builds that allow you
    to build application artifacts in an image that has all development tools and
    libraries available, and then copy those artifacts to other stages of your Dockerfile.
    You will leverage Docker Compose as a tool to orchestrate complex Docker environments
    with multiple containers, which allows you to test integration scenarios, such
    as your application interacting with a database, and also mimic how you would
    run your application in production environments.  An important concept that will
    be introduced is the concept of building a release image, which is a production-ready
    image that can be shipped to production, assuming any new application features
    and functionality work as expected. You will build and run this release image
    in your local Docker environment, connect your application to a database, and
    then create acceptance tests that verify the application works as expected, from
    the perspective of an external client connecting to your application.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you will bring all you have learned together using GNU Make to automate
    your workflow. Once finished, you will be able to run unit tests and build application
    artifacts by simply running `make test`, and then build your release image, start
    up a production-like environment, and run acceptance tests by running `make release`. 
    This will make it very simple to test and publish new application changes with
    confidence as they are developed, using a portable and consistent workflow that
    can be easily run in a local development environment and in any continuous-delivery
    environment that supports Docker and Docker Compose.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered:'
  prefs: []
  type: TYPE_NORMAL
- en: Testing and building applications using Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating multi-stage builds
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a test stage to build and test application artifacts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a release stage to build and test a release image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Docker Compose to test and build applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating acceptance tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automating the workflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following lists the technical requirements to complete this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Prerequisite software installed as per instructions in Chapter 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GitHub account created as per instructions in Chapter 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The following GitHub URL contains the code samples used in this chapter: [https://github.com/docker-in-aws/docker-in-aws/tree/master/ch2](https://github.com/docker-in-aws/docker-in-aws/tree/master/ch2)[.](https://github.com/docker-in-aws/docker-in-aws/tree/master/ch3)
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://bit.ly/2PJG2Zm](http://bit.ly/2PJG2Zm)'
  prefs: []
  type: TYPE_NORMAL
- en: Testing and building the application using Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, you gained a good understanding of what the sample
    application is, and how to test and run the application in your local development
    environment. You are now ready to start creating a Docker workflow that will test,
    build, and package your application into a Docker image.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to understand that whenever you are packaging an application
    into a Docker image, the best-practice approach is to reduce or eliminate all
    development and test dependencies from your final packaged application. By my
    own convention, I refer to this packaged application—free of test and development
    dependencies—as a *release image, *which supports the paradigm of continuous delivery,
    where every successful build should be a release candidate that is able to be
    published to production if required.
  prefs: []
  type: TYPE_NORMAL
- en: 'To achieve this goal of creating a release image, an approach that works well
    is to split the Docker build process into two stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Test stage**: This stage has all the test and development dependencies available
    to compile and build your application source into an application artifact, and
    run unit and integration tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Release stage**: This stage copies the tested and built application artifact(s)
    from the test stage into a minimalistic runtime environment configured appropriately
    for running the application in production.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker natively supports such an approach using a feature called multi-stage
    builds, and this is the approach we will adopt in this book. For now, we will
    focus on the test stage, and move on to the release stage in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a test stage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will get started by creating a `Dockerfile` at the root of the `todobackend` repository,
    meaning your repository structure should look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now define a couple of directives in the newly created Dockerfile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `FROM` directive is the first directive you define in a Dockerfile, and
    note that we are using the Alpine Linux distribution as the base image. Alpine
    Linux is a minimalistic distribution that has a much smaller footprint than the
    more traditional Linux distributions, such as Ubuntu and CentOS, and has become
    very popular in the container world since Docker adopted Alpine as the distribution
    of choice for official Docker images.
  prefs: []
  type: TYPE_NORMAL
- en: One keyword you may not have come across is the `AS` keyword, which is appended
    to the `FROM` directive, which configures the Dockerfile as a [multi-stage build](https://docs.docker.com/develop/develop-images/multistage-build/)
    and names the current stage as `test`. When you have a multi-stage build, you
    can include multiple `FROM` directives, with each stage defined as including the
    current `FROM` directive and subsequent directives, up until the next `FROM` directive.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we use the `LABEL` directive to attach a label called `application` with
    a value of `todobackend`, which is useful for being able to identify Docker images
    that support the todobackend application.
  prefs: []
  type: TYPE_NORMAL
- en: Installing system and build dependencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We now need to install the various system and build operating system dependencies
    that will support testing and building the application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, we install the following dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Basic utilities**: In Alpine Linux, the package manager is called `apk`,
    and a common pattern used in Docker images is `apk add --no-cache`, which installs
    the referenced packages and ensures the downloaded packages are not cached. We
    install `bash`, which is useful for troubleshooting, and `git`, which is required
    as we will use Git metadata later on to generate application-version tags for
    the Docker release image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Build dependencies**: Here we install the various development libraries required
    to build the application.  This includes `gcc`, `python3-dev`, `libffi-dev`, `musl-dev`,
    and `linux-headers` for compiling any Python C extensions and their supporting
    standard libraries, as well as the `mariadb-dev` package, which is required to
    build the MySQL client in the todobackend application. You also install a Python
    package called `wheel` that allows you to build Python *wheels*, which are a precompiled
    and pre-built packaging format that we will use later on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing application dependencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next step is to install application dependencies, which, as you learned
    in the previous chapter, means installing packages defined in the `src/requirements.txt` and `src/requirements_test.txt` files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: You first use the `COPY` directive to copy the `src/requirements.txt` and `src/requirements_test.txt` files
    to a folder in the `/build` container, which you then specify as the working directory
    via the `WORKDIR` directive.   Note that `/src/requirements.txt` is not a physical
    path on your Docker client - it is a path within the Docker *build context,* which
    is a configurable location on your Docker client file system that you specify
    whenever you execute a build.  To ensure all relevant application source code
    files are available for the Docker build process, a common practice is to set
    the root of your application repository as the build context, so in the example
    above `/src/requirements.txt` refers to `<path-to-repository>/src/requirements.txt` on
    your Docker client.
  prefs: []
  type: TYPE_NORMAL
- en: Next, you use the `pip3` wheel command to build Python wheels into the `/build` working
    directory for all of the base application and test dependencies, using the `--no-cache-dir` flag
    to avoid bloating our image and the `--no-input` flag to disable prompting for
    user confirmations. Finally, you install the previously built wheels into the
    container using the `pip3 install` command, using the `--no-index` flag to instruct
    pip not to attempt to download any packages from the internet, and instead install
    all packages from the `/build` folder as specified by the `-f` flag.
  prefs: []
  type: TYPE_NORMAL
- en: This approach may seem a little strange, however, it is based upon the principle
    that you should only build your application dependencies once as installable packages,
    and then install the built dependencies as required.  Later on, we will install
    the same dependencies into the release image, ensuring that your release image
    accurately reflects the exact set of dependences your application was tested and
    built against.
  prefs: []
  type: TYPE_NORMAL
- en: Copying application source and running tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The final steps in the test stage are to copy the application source into the
    container and add support for running tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, you first copy the entire `/src` folder to a folder
    called `/app`, and then change the working directory to `/app`. You might be wondering
    why we didn't just copy all of the application source earlier when we copied the
    requirements files. The answer here is that we are implementing a caching optimization,
    as your requirements files require the building of application dependencies, and
    by building them in a separate, earlier layer, if the requirements files remain
    the same (which they tend to do), Docker can leverage cached versions of the most
    recent layers that were built, rather than having to build and install application
    dependencies each time your image is built.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we add the `CMD` directive, which defines the default command that
    will be executed should a container based from this image be created and executed.
    Note that we specify the same `python3 manage.py test` command we used in the
    previous chapter to run our application tests locally.
  prefs: []
  type: TYPE_NORMAL
- en: You might wonder why we didn't just run our tests in the image using the `RUN` directive.
    The answer here is that you may want to collect artifacts as part of the build
    process, such as test reports, which are much easier to copy from a container
    that you spawn from a Docker image, than during the actual image-build process.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we have defined the first stage of our Docker build process,
    which will create a ready-to-test self-contained environment complete with the
    required operating-system dependencies, application dependencies and application
    source code. To build the image, you can run the `docker build` command, tagging
    the image with a name of `todobackend-test`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, the `--target` flag allows you to target a specific
    stage in a multi-stage Dockerfile.  Although we only have a single stage at the
    moment, this flag allows us to build only the test stage in the event we have
    multiple stages in the Dockerfile. By convention, the `docker build` command looks
    for a `Dockerfile` file in the directory where you run the command, and the period
    at the end of the command specifies the current directory (i.e. the application
    repository root in this example) as the build context that should be copied to
    the Docker Engine when building the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the image built and tagged with an image name of `todobackend` in your
    local Docker Engine, you can now start a container from the image, which by default
    will run the `python3 manage.py test` command as specified by the `CMD` directive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The `-it` flag specifies to run the container with an interactive terminal,
    and the `--rm` flag will automatically delete the container once it exits. Note
    that the tests all pass successfully, so we know the application built in the
    image is in a good state, at least in terms of the current tests that have been
    defined for the application.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the release stage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the test stage in place, we now have an image that includes all application
    dependencies packaged in a format that can be installed without compilation or
    development dependencies, along with our application source code in a state that
    we can easily verify passes all tests.
  prefs: []
  type: TYPE_NORMAL
- en: The next stage that we need to configure is the release stage, which copies
    the application source code and various application dependencies built during
    the test stage to a new production-ready release image. Because the application
    dependencies are now available in a precompiled format, the release image does
    not require development dependencies or source code compilation tools, allowing
    us to create a smaller, leaner release image with a reduced attack surface.
  prefs: []
  type: TYPE_NORMAL
- en: Installing system dependencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To get started creating the release stage, we can add a new `FROM` directive
    at the bottom of the Dockerfile, which Docker will treat as the start of a new
    stage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, you can see the release image is based, once again,
    on the Alpine Linux image, which is an excellent choice for a release image given
    its very small footprint. You can see that we install fewer operating-system dependencies,
    which includes the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`python3`: The Python 3 interpreter and runtime is required given the sample
    application is a Python application'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mariadb-client`: Includes system libraries required to communicate with the
    MySQL application database'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bash`: Useful for troubleshooting and executing entry point scripts, which
    we will discuss in later chapters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that instead of installing the `python3-dev` and  `mariadb-dev` packages,
    we only need to install the non development versions of these packages, given
    we compiled and built all application dependences as precompiled wheels in the
    test stage.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an application user
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next step is to create an application user that our application will run
    as. By default, Docker containers run as root, which is fine for test and development
    purposes, however, in production, even with the isolation mechanisms that containers
    provide, it is still considered best practice to run your containers as a non-root
    user:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we first create a group named `app` with a group ID
    of `1000`, and then create a user called `app` with a user ID of `1000`, which
    belongs to the `app` group.
  prefs: []
  type: TYPE_NORMAL
- en: Copying and installing application source code and dependencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The final step is to copy the application source code and dependencies that
    were previously built in the test stage, install the dependencies into the release
    image, and then remove any temporary files used during this process.  We also
    need to set the working directory to `/app`, and configure the container to run
    as the `app` user we created in the previous section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: You first use the `COPY` directive with the `--from` flag, which tells Docker
    to look in the stage specified in the `--from` flag for the files to copy. Here
    we copy the `/build` and `/app` folders from the test stage image to folders with
    the same names in the release stage, and also configure the `--chown` flag to
    change the ownership of these copied folders to the application user. We then
    use the `pip3` command to install only the core requirements specified in the `requirements.txt` file
    (you don't need the dependencies specified in `requirements_test.txt` for running
    the application), using the `--no-index` flag to disable the PIP connecting to
    the internet to download packages, and instead use the `/build` folder, as referenced
    by the `-f` flag, to find the dependencies previously built during the test stage
    and copied to this folder. We also specify the `--no-cache-dir` flag to avoid
    unnecessarily caching packages in the local filesystem, and remove the `/build` folder
    once everything is installed.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you set the working directory as `/app`, and configure the container
    to run as the `app` user by specifying the `USER` directive.
  prefs: []
  type: TYPE_NORMAL
- en: Building and running the release image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have completed the configuration of the release stage of the Dockerfile,
    it's time to build our new released image and verify we can actually run our application
    successfully.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build the image, we can use the `docker build` command, and because the
    release stage is the last stage of the Dockerfile, you don''t need to target a
    specific stage, as we did previously for the test stage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: At this point, we can run the Django application that is located in the release
    image, but you might be wondering exactly how that works. When we ran the `python3
    manage.py runserver` command earlier, it spun up a local development web server
    which is not recommended for production-user cases, so we require an alternative
    web server to run our application in production.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may have noticed earlier in the `requirements.txt` file a package called `uwsgi`—this
    is a very popular web server that can be used in production, and, conveniently
    for our use case, can be installed via PIP.  This means that `uwsgi` is already
    available as a web server in our release container and can be used to serve the
    sample application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We use the `-p` flag to map port `8000` on the container to port `8000` on your
    host, and execute the `uwsgi` command passing in various configuration flags that
    run the application on port `8000` and specify the `todobackend.wsgi` module as
    the application served by `uwsgi`.
  prefs: []
  type: TYPE_NORMAL
- en: The Web Server Gateway Interface (WSGI) is a standard interface used by Python
    applications to interact with web servers. Every Django application includes a
    WSGI module for communicating with a web server, which can be accessed via `<application-name>.wsgi`.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, you can browse to `http://localhost:8000` and although the application
    does return a response, you will find that the web server and application are
    missing a bunch of static content:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/1666a16d-f8ad-4509-974d-aca192694abf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The problem here is that Django automatically generates static content when
    you run the Django development web server, however, when you run the application
    in production along with an external web server, you are responsible for generating
    static content yourself. We will learn how to do this later on in this chapter,
    however for now, you can verify the API works by using `curl`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'One thing to note here is that the todobackend data has the same data that
    we loaded back in Chapter 1, despite us having built a Docker image from scratch.
    The problem here is that the SQLite database that was created back in Chapter
    1 resides in the `src` folder, in a file called `db.sqlite3`. Clearly, we don''t
    want to copy this file into our Docker image during the build process, and one
    way to achieve this is to create a `.dockerignore` file at the root of the repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The `.dockerignore` file works similarly to `.gitignore` in a Git repository,
    and is used to exclude files from the Docker build context. Because the `db.sqlite3` file
    is located in a subfolder, we use a wildcard globing pattern of `**` (note this
    is different from `.gitignore` behavior, which globs by default), which means
    we recursively exclude any file matching the wildcard pattern. We also exclude
    any test output files that have a `.xml` extension, code coverage files, the `__pycache__` folder,
    and any compiled Python files with `.pyc` extensions, which are intended to be
    generated on the fly at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you now rebuild the Docker image and start-up the the `uwsgi` web server
    locally on port `8000`, when you browse to the application (`http://localhost:8000`),
    you will get a different error:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/c7ab5b6d-1d1b-47d8-8242-5e7c51cc22c4.png)'
  prefs: []
  type: TYPE_IMG
- en: The problem now is that no database exists for the todobackend application,
    so the application is failing as it cannot locate the table that stores Todo items.
    To resolve this problem, we are now at the point where we need to integrate with
    an external database engine, meaning we need a solution to work with multiple
    containers locally.
  prefs: []
  type: TYPE_NORMAL
- en: Testing and building the application using Docker Compose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous section, you used Docker commands to perform the following
    tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Build a test image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build a release image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run the application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each time we ran a Docker command, we had to supply quite a bit of configuration,
    and trying to remember the various commands that you need to run is already starting
    to become difficult. In addition to this, we also discovered that to start the
    release image for the application, we need to have an operational external database. 
    For local testing use cases, running an external database in another container
    is an excellent approach, but having to orchestrate this by running a series of
    Docker commands with lots of different input parameters very quickly becomes difficult
    to manage.
  prefs: []
  type: TYPE_NORMAL
- en: '**Docker Compose** is a tool that allows you to orchestrate multi-container
    environments using a declarative approach, making it much easier to orchestrate
    complex workflows that may require multiple containers. By convention, Docker
    Compose looks for a file called `docker-compose.yml` in the current directory,
    so let''s create this file at the root of the `todobackend` repository, alongside
    our `Dockerfile`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Docker Compose files are defined in a YAML format, which requires proper indentation
    to infer the correct relationships between parent, siblings and child objects
    or properties.  If you have not worked with YAML before, you can check out the [Ansible
    YAML Syntax guide](https://docs.ansible.com/ansible/latest/reference_appendices/YAMLSyntax.html),
    which provides a brief introduction to YAML formatting.  You can also use an online
    YAML linting tool  such as http://www.yamllint.com/ to check your YAML, or install
    YAML support in your favourite text editor.
  prefs: []
  type: TYPE_NORMAL
- en: We first specify the `version` property, which is mandatory and references the
    version of the Compose file format syntax that we are using. If you are using
    Docker for local development and build tasks, I recommending using version 2.x
    of the Compose file format, as it includes some useful features, such as health
    checks on dependent services, that we will learn how to use shortly.  If you are
    using Docker Swarm to run your containers, then you should use version 3.x of
    the Compose file format, as this version supports a number of features that relate
    to managing and orchestrating Docker Swarm.
  prefs: []
  type: TYPE_NORMAL
- en: If you choose to use version 3.x, your applications will need to be more robust
    in terms of dealing with scenarios such as your database not being available at
    application startup (see [https://docs.docker.com/compose/startup-order/](https://docs.docker.com/compose/startup-order/)),
    which is a problem we will encounter later on in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We next specify the `services` property, which defines one or more services
    that run in our Docker Compose environment. In the preceding example, we create
    two services that correspond to the test and release stages of our workflow, and
    then add a single `build` property to each service, which defines how we want
    to build the Docker image for each service. Note that the `build` properties are
    based upon the various flags that we passed to the `docker build` command—for
    example, when we build the test stage image, we set the build context to the local
    folder, used the local Dockerfile as the build specification for the image, and
    targeted only the test stage for building the image. Rather than imperatively
    specifying these settings each time we run a Docker command, we are declaratively
    defining the desired configuration for the build process, which is an important
    distinction.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course we need to run a command to actually build these services, which
    you can do by running the `docker-compose build` command at the root of the `todobackend`
    repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: You can see that running the `docker-compose build test` command achieves the
    equivalent of the earlier `docker build` command we ran, however, we don't need
    to pass any build options or configuration to the `docker-compose` command, given
    all of our specific settings are captured in the `docker-compose.yml` file.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you now want to run tests from the newly built image, you can execute the `docker-compose
    run` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also extend the Docker Compose file to add port mapping and command
    configurations to services, as demonstrated in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we specify that when the release service is run, it should create a static
    port mapping from port `8000` on the host to port `8000` on the container, and
    pass the `uwsgi` command we used earlier to the release container.  If you now
    run the release stage using the `docker-compose up` command, note that Docker
    Compose will automatically build the image for a service if it does not yet exist,
    and then start the service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: You typically use the `docker-compose up` command for long-running services,
    and the `docker-compose run` command to run short-lived tasks. You also cannot
    override the command arguments passed to `docker-compose up`, whereas you can
    pass command overrides to the `docker-compose run` command.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a database service using Docker Compose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To resolve the application error we currently have when running the release
    image, we need to run a database that the application can connect to, and ensure
    the application is configured to use the database.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can achieve this using Docker Compose by adding a new service called `db`,
    which is based on the official MySQL server container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Note that you can specify an external image using the `image` property, and
    the environment settings configure the MySQL container with a database called
    todobackend, a username, password, and a root password.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, you might be wondering how we configure our application to use MySQL and
    the new `db` service.  The todobackend application includes a settings file called `src/todobackend/settings_release.py`,
    which configures support for MySQL as the database backend:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The `DATABASES` setting includes a configuration that specifies an engine of `mysql.connector.django`,
    which provides support for MySQL overriding the default SQLite driver, and you
    can see that the database name, username, and password can be obtained from the
    environment via the `os.environ.get` call. Also note that the `STATIC_ROOT` setting
    – this is where Django looks for static content, such as HTML, CSS, JavaScript,
    and images—and by default, Django will look in `/public/static` if this environment
    variable is not defined.  As we saw earlier, currently our web application is
    missing this content, so keep this setting in mind for later when we fix the missing
    content issue.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you understand how the todobackend application can be configured to
    support a MySQL database, let''s modify the Docker Compose file to use the `db` service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: We first configure the `environment` property on the `release` service, which
    configures environment variables that will be passed to the container. Note that
    for Django applications, you can configure the `DJANGO_SETTINGS_MODULE` environment
    variable to specify which settings should be used, and this allows you to use
    the `settings_release` configuration that adds MySQL support. This configuration
    also allows you to use environment variables to specify the MySQL database settings,
    which must match the configuration of the `db` service.
  prefs: []
  type: TYPE_NORMAL
- en: We next configure the `depends_on` property for the `release` service, which
    describes any dependencies the service may have. Because the application must
    have a working connection to the database before it can start, we specify a condition
    of `service_healthy`, which means the `db` service must have passed a Docker health
    check before Docker Compose will attempt to start the `release` service. To configure
    the Docker health check on the `db` service, we configure the `healthcheck` property,
    which will configure Docker to run the command specified by the `test` parameter
    inside the `db` service container to verify service health, and to retry this
    command every 3 seconds up to 10 times until the `db` service is healthy. For
    this scenario, we use the `mysqlshow` command, which will only return a successful
    zero exit code once the MySQL process is accepting connections. Because Docker
    Compose will interpret single dollar signs as environment variables it should
    evaluate and replace in the Docker Compose file, we escape the environment variables
    referenced in the `test` command with double dollar signs to ensure that the command
    will literally execute `mysqlshow -u $MYSQL_USER -p$MYSQL_PASSWORD`.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we can test the changes by tearing down the current environment
    by pressing *Ctrl* + *C* in the terminal running the `release` service and typing
    the `docker-compose down -v` command (the `-v` flag will also delete any volumes
    created by Docker Compose), and then executing the `docker-compose up release` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, note that Docker Compose automatically pulls the MySQL
    5.7 image as configured via the `image` property, and then starts the `db` service.
    This will take between 15-30 seconds, and during this period, Docker Compose is
    waiting for Docker to report back that the `db` service is healthy. Every 3 seconds
    Docker runs the `mysqlshow` command as configured in the health check, repeating
    this continuously until the command returns a successful exit code (that is, an
    exit code of `0`), at which point Docker will mark the container as healthy. Only
    at this point will Docker Compose start up the `release` service, which should
    start successfully given the `db` service is fully operational.
  prefs: []
  type: TYPE_NORMAL
- en: If you browse once again to `http://localhost:8000/todos`, you will find that
    even though we added a `db` service and configure the release service to use this
    database, you are still receiving the `no such table` error you saw previously
    in the previous screenshot.
  prefs: []
  type: TYPE_NORMAL
- en: Running database migrations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are still receiving errors about missing tables, and the reason is because
    we have not run database migrations to establish the required database schema
    the application expects to be in place. Recall that we used the `python3 manage.py
    migrate` command locally to run these migrations, so we need to do the same in
    our Docker environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you tear down the environment again by pressing *Ctrl* + *C* and running `docker-compose
    down -v`, one approach would be to use the `docker-compose run` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, note that when you use the `docker-compose run` command,
    Docker Compose does NOT support the health check behavior we previously observed
    when we ran `docker-compose up`.  This means you can take one of two approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: Ensure you run `docker-compose up release` first, and then run `docker-compose
    run python3 manage.py migrate` - this will leave your application in a state where
    it will raise errors until the migrations complete.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define the migrations as a separate service, called `migrate`, with a dependency
    on the `db` service, bring up the `migrate` service, which will execute the migrations
    and exit, and then bring up the application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although as you will soon see, option 1 is simpler, option 2 is more robust
    as it ensures the database is in the correct state before starting the application.
    Option 2 also aligns with the approach we will take later on in this book when
    we have to orchestrate running database migrations in AWS, so we will implement
    option 2 now.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example demonstrates the changes we need to make to run the migrations
    as a separate service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, note that in addition to the `migrate` service, we
    have added a new service, called `app`, as well. The reason is that we want to
    extend migrate from the `release` service (as defined by the `extends` parameter)
    so it will inherit the release image and release service settings, however, one
    limitation of extending another service is that you cannot extend a service that
    has a `depends_on` statement. This requires us to use the `release` service as
    more of a base configuration that other services inherit from, and shift the `depends_on`, `ports`, and `command` parameters
    from the release service to the new `app` service.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this configuration in place, we can tear down the environment and stand
    up our new environment, as demonstrated in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, note that Docker Compose builds new images for each
    service, however these builds complete very quickly as they are identical to the
    release image, given each service extends the `release` service. You will observe
    a 15-30 second delay when you bring up the `migrate` service waiting for the `db` service
    health check to pass, after which the migrations are run, creating the appropriate
    schema and tables the todobackend application expects. After starting the `app` service,
    you should be able to interact with the todobackend API without receiving any
    errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Generating static web content
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you browse to `http://localhost:8000/todos`, although the application is
    no longer returning an error, the formatting of the web page still is broken.
    The problem here is that Django requires you to run a separate `manage.py` management
    task called `collectstatic`, which generates static content and places it at the
    location defined by the `STATIC_ROOT` setting. The release settings for our application
    define the file location for this as `/public/static`, so we somehow need to run
    the `collectstatic` task before our application starts up. Note that Django serves
    all static content from the `/static` URL path, for example `http://localhost:8000/static`.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a couple of approaches that you can use to solve this:'
  prefs: []
  type: TYPE_NORMAL
- en: Create an entrypoint script that runs on startup and executes the `collectstatic` task
    before starting the application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create an external volume and run a container that executes the `collectstatic` task,
    generating static files in the volume. Then start the application with the external
    volume mounted, ensuring it has access to static content.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both of these approaches are valid, however, to introduce the concept of Docker
    volumes and how you can use them in Docker Compose, we will adopt the second approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'To define a volume in Docker Compose, you use the top-level `volumes` parameter,
    which allows you to define one or more named volumes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, you add a volume called `public` and specify the driver
    as local, meaning it is a standard Docker volume. You then use the `volumes` parameter
    in the app service to mount the public volume to the `/public` path in the container,
    and finally you configure `uwsgi` to serve requests for static content from the `/public` path,
    which avoids expensive application calls to the Python interpreter to serve static
    content.
  prefs: []
  type: TYPE_NORMAL
- en: 'After tearing down your current Docker Compose environment, all that is required
    to generate static content is the `docker-compose run` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, the `collectstatic` task fails because, by default,
    volumes are created as root and the container runs as the app user. To resolve
    this, we need to pre-create the `/public` folder in `Dockerfile` and make the
    app user the owner of this folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Note that the approach shown above only works for volumes that are created using
    Docker volume mounts, which is what Docker Compose uses if you don't specify a
    host path on your Docker Engine.   If you specify a host path, the volume is bind
    mounted, which causes the volume to have root ownership by default, unless you
    pre-create the path on the host with the correct permissions.  We will encounter
    this issue later on when we use the Elastic Container Service, so keep this in
    mind.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because you modified the Dockerfile, you need to tell Docker Compose to rebuild
    all images, which you can do by using the `docker-compose build` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: If you now browse to `http://localhost:8000`, the correct static content should
    be displayed.
  prefs: []
  type: TYPE_NORMAL
- en: When you define a local volume in Docker Compose, the volume will be automatically
    be destroyed when you run the `docker-compose down -v` command. If you wish to
    persist storage independently of Docker Compose, you can define an external volume,
    which you are then responsible for creating and destroying.  See [https://docs.docker.com/compose/compose-file/compose-file-v2/#external](https://docs.docker.com/compose/compose-file/compose-file-v2/#external)
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: Creating acceptance tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that the application is configured correctly, the final task to configure
    for the release stage is to define acceptance tests that verify the application
    is working as expected. Acceptance tests are all about ensuring the release image
    you have built works in an environment that is as close to production as possible,
    within the constraints of a local Docker environment. At a minimum, if your application
    is a web application or API service, such as the todobackend application, you
    might just verify the application returns a valid HTTP response, or you might
    run through key features, such as creating an item, updating an item, and deleting
    an item.
  prefs: []
  type: TYPE_NORMAL
- en: For the todobackend application, we will create a few basic tests to demonstrate
    the approach, using a tool called BATS (Bash automated test system). BATS is great
    for system administrators who are more comfortable using bash, and leverages out-of-the-box
    tools to execute tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started with BATS, we need to create a test script, called `acceptance.bats`,
    in the `src` folder of the **todobackend** repository using the BATS syntax, which
    you can read more about at [https://github.com/sstephenson/bats](https://github.com/sstephenson/bats):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The BATS file includes a `setup()` function and a number of test cases, which
    are each prefixed with the `@test` marker. The `setup()` function is a special
    function that will be run before each test case, and is useful for defining common
    variables and ensuring the application state is consistent before each test. You
    can see that we set a few variables that are used in the various test cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '`url`: Defines the URL of the application under test. This is defined by the `APP_URL` environment
    variable, defaulting to `localhost:8000` if `APP_URL` is not defined.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`item`: Defines a test Todo item in JSON format that is created via the Todos
    API during the tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`location`: Defines a regular expression intended to locate and capture the
    value of the Location header that is returned in the HTTP response whenever you
    create a Todo item.  The `([^[:space:]]*)` portion of the regular expression captures
    zero or more characters until whitespace (as designated by the `[:space:]` indicator)
    is encountered. For example, if the location header was `Location: http://localhost:8000/todos/53`,
    the regular expression will capture `http://localhost:8000/todos/53`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `curl` command: The final setup task is to delete all todo items in the
    database, which you can do by sending a DELETE request to the `/todos` URL. This
    ensures the todobackend database is clean on each test run, reducing the likelihood
    of different tests introducing side effects that break other tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The BATS file next defines several test cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '`todobackend root`: This includes the `run` function, which runs the specified
    command and captures the exit code of the command in a variable called status,
    and the output of the command in a variable called `output`.  For this scenario,
    the test runs a special configuration of the `curl` command that captures only
    the HTTP status code that is returned, and then verifies the `curl` command completed
    successfully by calling `[ $status = 0 ]`, and that the returned HTTP status code
    was a 200 code by calling `[ $output = 200 ]`. These tests are regular shell *test
    expressions*, and are the equivalent of the canonical `assert` statement found
    in many programming languages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`todo items returns empty list`: This test case uses the `jq` command to pass
    the output calling the `/todos` path. Note that because you can''t use pipes in
    conjunction with the special `run` function, I have used the bash process substitution
    syntax, `<(...)`, to make the output of the `curl` command appear as a file that
    is being read by the `jq` command.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`create todo item`: This first creates a todo item, checks whether the returned
    exit code is zero, and then uses a *bash conditional expression* (as indicated
    by the `[[...]]` syntax) to verify that the output of the `curl` command includes `201
    Created` in the HTTP response, which is a standard response when creating an item.
    When using the bash conditional expressions, it is important to note that BATS
    will not detect an error if the conditional expression fails, hence we use the `||
    false` special syntax, which is only evaluated in the event the conditional expression
    fails and returns a non-zero response of `false`, causing the test case to fail
    if the test expression fails. The conditional expressions use the `=~` regular
    expression operator (this operator is not available in conditional expressions,
    hence our use of bash test expressions), with the second conditional expression
    evaluating the `location` regular expression defined in the setup function. The
    final command uses the special `BASH_REMATCH` variable that includes the results
    of the most recent conditional expression evaluation, which in this case is the
    URL matched in the Location header. This allows us to capture the returned location
    when we create a Todo item, and verify that the created item matches the item
    that we posted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`delete todo item`: This creates a Todo item, captures the location returned
    for the item, deletes the item, and then verifies that the item was in fact deleted
    by verifying the number of Todo items in the database is zero after the deletion.
    Recall that the setup function runs before each test case, which clears all Todo
    items, hence at the beginning of this test case the Todo item count will always
    be zero, and the action of creating and then deleting an item should always return
    the count to zero.  The various commands used in this test case are based upon
    the concepts introduced in the `create todo item` test case, hence I won''t describe
    each command in detail.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have define a suite of acceptance tests, it's time to modify the
    Docker environment to support the execution of these tests once the application
    is started successfully.
  prefs: []
  type: TYPE_NORMAL
- en: 'We first need to add the `curl`, `bats`, and `jq` packages to the `Dockerfile` at
    the root of the todobackend repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Next we need to add a new service called `acceptance` to the `docker-compose.yml`
    file, which will wait until the `app` service is healthy and then run acceptance
    tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: We first add a `healthcheck` property to the `app` service, which uses the `curl`
    utility to check connectivity to the local web server endpoint.  We then define
    the acceptance service, which we extend from the `release` image and configure with
    the `APP_URL` environment variable, which configures the correct URL the acceptance
    tests should be executed against, whilst  the `command` and `depends_on` properties
    are used to run the acceptance tests once the `app` service is healthy.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this configuration in place, you now need to tear down the current environment,
    rebuild all images, and perform the various steps to get the application up and
    running, except when you get to the point where you are about to run the `docker-compose
    up app` command, you should now run the `docker-compose up acceptance` command,
    as this will automatically start the `app` service in the background:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, all tests pass successfully, as indicated by the `ok` status
    for each test.
  prefs: []
  type: TYPE_NORMAL
- en: Automating the workflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point, you have managed to successfully configure Docker Compose to
    build, test, and create a working local environment for the sample application,
    complete with MySQL database integration and acceptance tests.  You can now stand
    up this environment with a handful of commands, but even though using Docker Compose
    has significantly simplified the commands you need to run, it is still difficult
    to remember which commands to use and in which order. Ideally we want a single
    command to run the complete workflow, and this is where a tool such as GNU Make
    is very useful.
  prefs: []
  type: TYPE_NORMAL
- en: Make has been around a long time, and is still considered the build tool of
    choice for many C and C++ applications. Task automation is a key feature of Make,
    and the ability to define tasks or targets in a simple format that can be invoked
    with a single command has made Make a popular automation tool, particularly when
    dealing with Docker containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'By convention make looks for a file, called Makefile, in the current working
    directory, and you can create a very simple Makefile, as demonstrated here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, you create a *target* called `hello` with two shell
    commands, which you can execute by running `make <target>`, or `make hello` in
    this example.  Each target can include one or more commands, which are executed
    in the sequence provided.
  prefs: []
  type: TYPE_NORMAL
- en: 'One important point to note is that make expects tabs (not spaces) to be used
    when you define the various commands for a given target, so if you receive a missing
    separator error, such as `Makefile:2: *** missing separator. Stop.`, check that
    you have used tabs to indent each command.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, you can see that the output of the each command is
    displayed on screen. Note that the special `@` character on the first command
    suppresses echoing each command as it is run.
  prefs: []
  type: TYPE_NORMAL
- en: Any decent modern text editor, such as Sublime Text or Visual Studio Code, should
    automatically take care of tabs for you in Makefiles.
  prefs: []
  type: TYPE_NORMAL
- en: 'One important piece of housekeeping you should perform in your Makefiles when
    using them for task automation is to configure the somewhat amusingly-named special target called `.PHONY`, with
    the names of each target that you will be executing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Because `make` is really a build tool for compiling source code files, the `.PHONY` target
    tells make that if it sees a file named `hello`, it should still run the target.
    If you didn't specify `.PHONY` and there was a file called `hello` in the local
    directory, make would exit stating that the `hello` file has already been built. 
    This clearly doesn't make much sense when you are using make to automate tasks,
    so you should always use the `.PHONY` target to avoid any strange surprises.
  prefs: []
  type: TYPE_NORMAL
- en: Automating the test stage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that you have been introduced to make, let''s modify our Makefile to do
    something that is actually useful, and execute the various actions performed during
    the test stage. Recall that the test stage involves building the first stage of
    the Dockerfile as a service, called `test`, and then running the `test` service,
    which by default will run the  `python3 manage.py test` command, executing application
    unit tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Note that rather than building the `test` service in the Docker Compose file,
    we actually build the release service and specify the `--pull` flag, which ensures
    that Docker will always check whether there are any newer releases of the Docker
    image referenced in the `FROM` directive. We build the `release` service this way
    because we only want to build the entire `Dockerfile` once, rather than rebuild
    the `Dockerfile` on each stage execution.
  prefs: []
  type: TYPE_NORMAL
- en: This guards against the unlikely, yet still possible, scenario where you could
    pull a newer base image if rebuilding during the release stage, which may result
    in a different runtime environment to what you tested in the test stage.  We also
    run the docker-compose build command immediately afterwards, which ensures all
    services are built before we run tests.  Because we built the entire `Dockerfile`
    in the previous command, this will ensure any cached images for other services
    are updated to the newest image build.
  prefs: []
  type: TYPE_NORMAL
- en: Automating the release stage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After completing the test stage, we next run the release stage, which requires
    us to perform the following actions:'
  prefs: []
  type: TYPE_NORMAL
- en: Run database migrations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collect static files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Start the application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run acceptance tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following demonstrates creating a target, called `release`, in the Makefile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we execute each of the required commands with one minor variation,
    which is to add the `--abort-on-container-exit` command to each of the `docker-compose
    up` commands.  By default, the `docker-compose up` command will not return a non-zero
    exit code should any of the container(s) started by the command fail. This flag
    allows you to override this and specify should any service fail that was started
    by the `docker-compose up` command, then Docker Compose should exit with an error.
    Setting this flag is important if you want your make commands to fail whenever
    there is an error.
  prefs: []
  type: TYPE_NORMAL
- en: Refining the workflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There's a few more minor enhancements we can make to the workflow that will
    ensure we have a robust, consistent, and portable mechanism for testing and building
    our application.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning up the Docker environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this chapter, we have been cleaning up our environment by running
    the `docker-compose down` command, which stops and destroys any containers associated
    with the todobackend Docker Compose environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'One other aspect of housekeeping that you need to be aware of when building
    Docker images is the concept of orphaned or dangling images, which are images
    that have been superseded by a newer build. You can get a sense of this by running
    the `docker images` command, and I have indicated which images are dangling in
    bold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Note that each highlighted image has no repository and no tag, hence why they
    are referred to as orphaned or dangling. These dangling images are of no use and
    take up resources and storage, so it is ideal that you clean up these images regularly,
    to ensure the performance of your Docker environment. Back in our Dockerfile,
    we added the `LABEL` directive to each stage, which allows for easy identification
    of images that relate to our todobackend application.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can leverage these labels to target dangling images built for the todobackend
    application, so let''s add a new target, called `clean`, to our Makefile, which
    brings down the Docker Compose environment and removes dangling images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: We use the `-q` flag to only print out image IDs, and then use the `-f` flag
    to add filters that specify to only show dangling images that have a label of `application=todobackend`.
    We then pipe the output of this command to the `xargs` command, which captures
    the list of filtered images in the `ARGS` parameter and passes `ARGS` to the `docker
    rmi -f --no-prune` command, removing the images forcibly as specified by the `-f` flag
    with the `--no-prune` flag ensuring any untagged images that include layers from
    current tagged images are not removed. We use `xargs` here because it deals with
    the list of images intelligently – for example, if there are no images to delete,
    then `xargs` exits silently without an error.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following demonstrates the output of running the `make clean` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: One thing you may notice when running the `make clean` command is that stopping
    the todobackend app service takes some time, in fact, it takes around 10 seconds
    to stop. This is because Docker first sends a SIGTERM signal to the container
    when stopping a container, which signals to the container that it is about to
    be terminated.  By default, if the container does not exit within 10 seconds,
    Docker sends a SIGKILL signal, which forcibly terminates the container.
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem here is that the `uwsgi` process running in our app container ignores
    SIGTERM signals by default, so we need to add the `--die-on-term` flag in the
    Docker Compose file that configures `uwsgi` to shut down if it receives a SIGTERM
    signal, ensuring it will be able to shut down gracefully and in a timely fashion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, I have also added the `--processes` and `--threads` flags,
    which enable concurrent processing.  You can read about these and more configuration
    options at [https://uwsgi-docs.readthedocs.io/en/latest/WSGIquickstart.html#adding-concurrency-and-monitoring](https://uwsgi-docs.readthedocs.io/en/latest/WSGIquickstart.html#adding-concurrency-and-monitoring).
  prefs: []
  type: TYPE_NORMAL
- en: Using dynamic port mapping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Currently, the release stage workflow runs the application using a static port-mapping,
    where port 8000 on the app service container is mapped to port `8000` on your
    Docker Engine. Although this will typically work fine when running locally (unless
    you have some other application that is using port 8000), this may cause problems
    when it comes to running the release-stage workflow on a remote continuous-delivery
    build service, which may be running multiple builds for many different applications.
  prefs: []
  type: TYPE_NORMAL
- en: A better approach is to use dynamic port-mapping, which maps the `app` service
    container port to a dynamic port on your Docker Engine that is currently not in
    use. The port is picked from what is referred to as the *ephemeral port range*,
    which is a port range reserved for dynamic use by applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'To configure dynamic port-mapping, you need to change the port-mapping in the `docker-compose.yml` file
    for the `app` service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, we simply change the port-mapping from a static mapping
    of `8000:8000` to `8000`, which enables dynamic port-mapping. With this configuration
    in place, one problem is that you don''t know in advance what port is going to
    be assigned, however, you can use the `docker-compose port <service> <container-port>` command
    to determine the current dynamic port-mapping for a given service on a given container
    port:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Of course, rather than manually type this command each time, we can incorporate
    it into our automation workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we use a command substitution to obtain the current
    port-mapping and pipe the output to a `sed` expression that replaces `0.0.0.0` with `localhost`.
    Note that because GNU Make interprets the dollar sign symbol as a Make variable
    reference, you are required to double-escape dollar signs (`$$`) if you want a
    single dollar sign evaluated by the shell command that will be executed.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this in place, the output of the `make release` command will now complete
    with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Adding a version target
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Versioning your applications is critical, particularly when building Docker
    images and you want to distinguish between various images. Later on, when we publish
    our Docker images, we will need to include a version tag on each published image,
    and a simple convention for versioning is to use the Git commit hash of the current
    commit in your application repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following demonstrates how you can capture this in a Make variable and
    display the current version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: We first declare a variable called `APP_VERSION` and prefix this with the `export`
    keyword, which means the variable will be available in the environment for each
    target. We then use a Make function called `shell` to execute the `git rev-parse
    --short HEAD` command, which returns the seven-character short hash of the current
    commit. Finally, we add a new target, called `version`, that simply prints the
    version in a JSON format to the terminal, which will be useful later in this book
    when we automate the continuous delivery of our application.  Note that `make`
    uses the dollar sign to reference variables and also to execute Make functions,
    which you can read more about at [https://www.gnu.org/software/make/manual/html_node/Functions.html](https://www.gnu.org/software/make/manual/html_node/Functions.html).
  prefs: []
  type: TYPE_NORMAL
- en: If you just run the `make` command without specifying a target, make will execute
    the first target in the Makefile. This means, for our scenario, just running `make` will
    output the current version.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following demonstrates running the `make version` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Testing the end-to-end workflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point, all of the pieces of our local Docker workflow are in place,
    and now is a good time to review the workflow and verify everything is working.
  prefs: []
  type: TYPE_NORMAL
- en: 'The core workflow now consists of the following tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Run the test stage – `make test`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run the release stage – `make release`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clean up – `make clean`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I will leave this up to you to test, but I encourage you to get comfortable
    with the workflow and ensure everything completes without error.  After running `make
    release`, verify you can navigate to the application, the application displays
    HTML content correctly, and that you can perform create, read, update, and delete
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: Once you are satisfied everything is working as expected, ensure you have committed
    and pushed your changes to the GitHub repository you forked in the previous chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you implemented a Docker workflow that tests, builds, and packages
    your application into a Docker image that is ready to publish and deploy to production.
    You learned how you can build your application in two stages using Docker multi-stage
    builds—the test stage uses a development environment complete with development
    libraries and source compilation tools that allows you to build and test your
    application and its dependencies in precompiled packages, while the release stage
    takes those built packages and installs them into a production-ready operating
    environment, free of development libraries and other tools, significantly reducing
    the attack surface of your application.
  prefs: []
  type: TYPE_NORMAL
- en: You learned how you to use Docker Compose to help simplify the various commands
    and actions you need to perform during the test and release stages, creating a
    `docker-compose.yml` file with a number of services, each defined in a declarative,
    easy-to-understand format. You learned how to replicate a number of deployment
    tasks required to get your application up and running, such as running database
    migrations, collecting static files, and ensuring the application database was
    healthy before you attempted to run your application. Being able to perform each
    of these tasks in a local environment provides you with the confidence and understanding
    of how these tasks will work in your actual production environments, and gives
    you early warning should any of your application or configuration changes break
    these processes locally. After starting your application in the correct state
    and connected to the application database, you learned how you can run acceptance
    tests from the point of view of an external client, which gives you great confidence
    that your image is working as expected, and early warning when these acceptance
    tests fail as part of the ongoing development of your application.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you learned how to bring all of this together in a fully automated
    workflow using GNU Make, which provides you with simple high-level commands that
    you can use to execute the workflow. You now have the ability to execute the test
    stage by simply running `make test`, run the release stage by running `make release`,
    and clean up your environment using `make clean`. This makes it very easy to run
    the workflow, and later in this book, will simplify the configuration of continuous-delivery
    build systems that we will be using to automatically test, build, and publish
    your Docker applications.
  prefs: []
  type: TYPE_NORMAL
- en: In coming chapters, you will learn how to actually publish the Docker release
    image you created in this chapter, but before you can do this, you need to establish
    an AWS account, configure access to your account, and install tools that support
    interacting with AWS, which will be the focus of the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'True/false: You use the `FROM` and `TO` directives to define a multi-stage
    Dockerfile.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True/false: The `docker` command `--rm` flag automatically deletes a container
    after it has exited.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True/false: When you run your workflow, you should only build application artifacts
    once.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True/false: When running the `docker-compose run` command with no additional
    flags, if the targeted services started fails with an error, docker-compose will
    exit with a non-zero code.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True/false: When running the `docker-compose up` command with no additional
    flags, if one of the services started fails with an error, docker-compose will
    exit with a non-zero code.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True/false: You should configure a Docker Compose version of 3.x if you want
    to use Docker Swarm.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You configure the service_healthy condition on a dependency of a service in
    your Docker file.  Then you run the service using the `docker-compose run` command;
    the dependency is started, however, Docker Compose does not wait until the dependency
    is healthy and starts the service immediately, causing a failure. How could you
    resolve this?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You create a service in Docker Compose with a port-mapping of `8000:8000`. When
    you attempt to start this service, an error is raised indicating the port is in
    use. How could you resolve this and ensure it never happens again?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After creating a Makefile, you receive an error about a missing separator when
    attempting to run a target. What is the most likely cause of this error?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which GNU Make function allows you to capture the output of a shell command?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You define a target called test in a Makefile, however when you run `make test`,
    you get a response saying there is nothing to do. How could you resolve this?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which properties must be configured in a Docker Compose service definition to
    use the `docker-compose push` command?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can check the following links for more information about the topics covered
    in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Docker Command-Line Reference: [https://docs.docker.com/engine/reference/commandline/cli/](https://docs.docker.com/engine/reference/commandline/cli/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker multi-stage builds: [https://docs.docker.com/develop/develop-images/multistage-build/](https://docs.docker.com/develop/develop-images/multistage-build/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Compose Version 2 Specification: [https://docs.docker.com/compose/compose-file/compose-file-v2/](https://docs.docker.com/compose/compose-file/compose-file-v2/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Compose Command-Line Reference: [https://docs.docker.com/compose/reference/](https://docs.docker.com/compose/reference/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Compose start order: [https://docs.docker.com/compose/startup-order/](https://docs.docker.com/compose/startup-order/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: uWSGI Quickstart for Python Applications: [http://uwsgi-docs.readthedocs.io/en/latest/WSGIquickstart.html](http://uwsgi-docs.readthedocs.io/en/latest/WSGIquickstart.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bash-Automated Test System: [https://github.com/sstephenson/bats](https://github.com/sstephenson/bats)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GNU Make Phony Targets: [https://www.gnu.org/software/make/manual/html_node/Phony-Targets.html](https://www.gnu.org/software/make/manual/html_node/Phony-Targets.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GNU Make Functions: [https://www.gnu.org/software/make/manual/html_node/Functions.html#Functions](https://www.gnu.org/software/make/manual/html_node/Functions.html#Functions)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
