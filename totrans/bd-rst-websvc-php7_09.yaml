- en: Microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although we discussed different aspects, what we have made is a RESTful web
    service for a simple blog in this book. We took that example to keep things simple
    in terms of business logic so that we can focus on our actual subject in detail.
    This was helpful, but in the real world, things are not that simple and small.
    There are big systems with different parts, which are difficult to maintain. These
    parts are also difficult to debug and scale. Scaling is different from just maintaining
    something and optimizing it for better performance. In scaling, optimization of
    both code and deployment environment matter. Scalability, maintainability, and
    performance have always been challenges that we have faced.
  prefs: []
  type: TYPE_NORMAL
- en: To handle this, we have an architectural style, known as microservices. So,
    in this chapter, we will discuss this. Microservices are not an essential thing
    to use. However, they solve some challenges that we often face while making RESTful
    web services for bigger systems. So, we will see how microservices solve those
    problems and what are the challenges that come with microservices architecture.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the topics that we will discuss in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Motivation towards microservices-based architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How it is different from SOA (Service Oriented Architecture)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Team structure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservices challenges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservices implementation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing Microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s first define microservices architecture and then go into the details
    of microservices. Microservices architecture became a hot term, but there wasn''t
    any formal definition. In fact, to date, there is no official consensus regarding
    its properties or definition. However, different people have tried to define it.
    I found a definition on Martin Fowler''s blog very convincing. He and James Lewis
    defined it this way:'
  prefs: []
  type: TYPE_NORMAL
- en: <q>The microservice architectural style is an approach to developing a single
    application as a **suite of small services**, each **running in its own process**
    and communicating with lightweight mechanisms, often an HTTP resource API. These
    services are **built around business capabilities** and **independently deployable**
    by fully automated deployment machinery. There is a **bare minimum of centralized
    management** of these services, which may be written in different programming
    languages and use different data storage technologies. -- James Lewis and Martin
    Fowler</q>
  prefs: []
  type: TYPE_NORMAL
- en: It seems very formal, so let's dig into this definition and try to understand
    microservice architecture.
  prefs: []
  type: TYPE_NORMAL
- en: First of all, you should know that in the example, the RESTful web service we
    created for the blog was a monolithic web service. This means everything was in
    the same web service. Everything was together, so it needs to be deployed together
    as one code base. We can use the same monolithic approach for a bigger application
    as well, but that application will start becoming more and more complex and will
    be less scalable.
  prefs: []
  type: TYPE_NORMAL
- en: As opposed to that, microservices are composed of a lot of small services. Every
    small service is known as a microservice, or we can simply call it a service.
    These services fulfill the purpose of one application, but they are independent
    and very loosely coupled. So, every microservice has a separate code base and
    has a separate database or storage. As each microservice is independent, it can
    be deployed independently, even if we want to deploy on the same server or a different
    one. This means all services may or may not be in the same language or framework.
    It is possible that if one service is in PHP, another can be in Node.js and another
    can be in Python.
  prefs: []
  type: TYPE_NORMAL
- en: How to divide an application into microservices?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So, the question is, "If we have a big application, then how do we decide how
    to divide it in different micro services?" We will look into different factors
    while understanding how to divide one big system into microservices. These factors
    are based on what Martin Fowler called "Characteristics of Microservices." You
    can see Martin Fowler's complete post on Characteristics of Microservices at [https://martinfowler.com/articles/microservices.html](https://martinfowler.com/articles/microservices.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'So, these are the factors to consider while dividing a big system into small
    microservices:'
  prefs: []
  type: TYPE_NORMAL
- en: Each microservice should be independent of other microservices. If not completely
    independent (as these services are part of one application so they may interact
    with each other) then dependency should be minimal.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will divide the application into different components. By components, we
    mean a unit of software that is independently replaceable and upgradeable. This
    means replacing or upgrading a component should not have any (or should have minimum)
    effect on the application. One microservice will be based on such a single component.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A service should have a single responsibility.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To divide an application or system into several micro-systems, you can start
    by looking at the business requirements. It is a good idea to make components
    based on business capabilities. In fact, our teams should be divided based on
    business capability, not based on technology.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the same time, it is important to ensure that services are not too fine-grained.
    Fine-grained services can result in more effort at the development end and still
    result in bad performance because there are too many things interacting with each
    other because they actually depend on each other.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In an ideal case, those services are always independent of each other. However,
    it is not always possible. Sometimes, there is something that one service needs
    from the other one, and sometimes, two or more services have some common logic.
    So, dependent services interact with each other mostly through HTTP calls, and
    common logic can be in a shared code base across different services. However,
    that is only possible when the same technology is being used in those services.
    Actually, this means that two or more services are depending on common code base.
    So, in theory based on the preceding definition, this is against the microservices
    architecture, but as there is no formal theory or official specification so we
    are considering anything that is happening in real world what is happening in
    the real world.
  prefs: []
  type: TYPE_NORMAL
- en: Motivation towards microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are several motivations towards microservices. However, the one that I
    want to start with is when we are dividing it into components having single responsibilities,
    we are abiding by the **SRP** (**Single Responsibility Principle**). Single responsibility
    is actually one of the first five Object Oriented Principles, also known as SOLID
    ([https://en.wikipedia.org/wiki/SOLID_(object-oriented_design)](https://en.wikipedia.org/wiki/SOLID_(object-oriented_design))
    ). This single responsibility principle, even if it is at architectural level
    or low level, it makes things simple and easy. Here, in the case of microservices,
    separates different components from each other. So, the reason for modifying a
    component will be related to one single functionality. Other components and functionalities
    of the system will work as they were working before. This is how being separated
    and being independent as microservices makes them easier to modify without affecting
    others.
  prefs: []
  type: TYPE_NORMAL
- en: Here are some of the other reasons why it is necessary to separate microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Maintenance and debugging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is nothing new to tell that modular code is always more easily maintainable.
    You can debug it easily and what can be more modular than components that are
    not only modular but also deployed as separate modules possibly on separate servers
    or separate server instances. So, we get a lot of advantages out of microservices
    that we can get from modular code.
  prefs: []
  type: TYPE_NORMAL
- en: However, there is something to understand. If we are working with the microservices
    architecture from start, application will be modular because we are making services
    separately. However, if we didn't start with microservices and later on, we want
    to convert it to microservices, then first, we need to have modular code and then
    we can use the microservices architecture because if we don't have modules and
    loosely coupled code, we cannot split them in to independent components.
  prefs: []
  type: TYPE_NORMAL
- en: So, in short, motivation here for microservices is simply that we can debug
    modular code and components easily. In the case of maintenance, there will not
    be such a ripple effect if the code is in separate components and other services
    are getting what they need, without worrying about the internal logic of modified
    components.
  prefs: []
  type: TYPE_NORMAL
- en: Actually this is not it; a very important factor in the maintenance stage is
    productivity. In bigger code bases, productivity can be reduced over time, because
    developers need to worry about the whole application. However, in microservices,
    developers in one team doing one particular change don't have to worry about the
    whole application but the code inside that particular service at the time, because
    for that particular change and for the developer working on it, this one microservice
    is the whole application which has a lot less responsibility than the overall
    application. So, that way, productivity during maintenance can be much better
    in microservices than monolithic applications.
  prefs: []
  type: TYPE_NORMAL
- en: Scalability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When your system scales and you want to serve more clients and want good performance
    as well, after sometime, when you have done optimizations as well, you need better,
    more powerful servers. You can make servers more powerful by adding more resources
    into them. This is called vertical scaling. Vertical scaling has its limits. After
    all, this is one server. What if we want more scalability? Actually, there is
    another way of scaling, that is, horizontal scaling. In horizontal scaling, you
    add more small servers or server instances instead of adding all the resources
    in to one server. In that case, how will one monolithic application be deployed
    on multiple servers? We will probably need to deploy the complete application
    on multiple servers and then load balancers, managing traffic through multiple
    servers.
  prefs: []
  type: TYPE_NORMAL
- en: However, having the whole application on multiple servers is not cost effective.
    What if we can have one part of the application served from one server and another
    part from another server? How can this be possible? We have one application. So,
    this is where the microservices architecture comes in. Its advantages are not
    limited to just scalability. One of its key benefits is the loosely coupled components
    of a system.
  prefs: []
  type: TYPE_NORMAL
- en: Technology diversity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have seen, in microservices, every codebase is separate from the other.
    So, different teams working on different services can use different technologies
    and different storage if they want to. In fact, those teams are completely free
    from the need to use the same technology across different services until you are
    providing other services that are interacting with each other. However, if we
    want to use the option of shared code to avoid repeatedly writing the same logic
    in different technologies, then to have a shared code base, we may need to use
    the same technology.
  prefs: []
  type: TYPE_NORMAL
- en: Resilience
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In microservices, resilience is also one of the key benefits. As every service
    is a separate component, if one component of the system is failing for some reason,
    then the problem can be isolated from the rest of the system.
  prefs: []
  type: TYPE_NORMAL
- en: However, we need to make sure that with failures, the system degrades properly.
    If there is failure in a service, we can try to minimize it, but there can be
    a failure again. However, to minimize its effect, we should handle it carefully
    so that we minimize its impact on other services and our application's user.
  prefs: []
  type: TYPE_NORMAL
- en: Replaceability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you want to replace a part of the system, then it is not that simple in monolithic
    architecture because everything is in the same code base. However, in microservices,
    it is easier to replace one component of the system because all you need to do
    is have another service and replace it with the existing one. Obviously, you still
    need to have an alternative service, but it is not like replacing the whole component
    in the same code base with some other code.
  prefs: []
  type: TYPE_NORMAL
- en: Parallelization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Normally, clients want their software to be developed early and come onto the
    market early so that they can test their idea or capture more market. For that
    reason, they want more developers working in parallel on their application. Unfortunately,
    in monolithic applications, we can do limited parallel work. Actually, we can
    do that in monolithic applications as well if we have very modular code. However,
    still, it can't be as independent and modular as it is in a microservices-based
    application.
  prefs: []
  type: TYPE_NORMAL
- en: Every service is being developed and deployed separately. Although these services
    communicate with each other, still, development can be done independently, and
    in most cases, we can keep several services being developed separately. So, many
    developers, in fact, the development team, can work in parallel, which means software
    can be developed early. If there is a problem or another feature is required in
    multiple modules, then it can be done in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: How it is different from SOA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'SOA stands for Service Oriented Architecture. By name it seems that this architecture
    depends on services just like micro-services. Service Orientation is a design
    paradigm in computer software in the form of services. Its principles stress the
    separation of concerns (the same as SRP). Until now, it seems similar to microservices.
    Before understanding difference, we need to know that what is SOA. Although there
    is no one clear official definition of SOA. So let''s take this basic definition
    from wikipedia:'
  prefs: []
  type: TYPE_NORMAL
- en: A service-oriented architecture (SOA) is a style of software design where services
    are provided to the other components by application components, through a communication
    protocol over a network. The basic principles of service-oriented architecture
    are independent of vendors, products and technologies.
  prefs: []
  type: TYPE_NORMAL
- en: If you look at this definition then you will find that SOA is very similar to
    micro-services but its definition is not that concise and clear. One reason can
    be that SOA itself is a generalized architecture. Or we can better say that SOA
    is generalized form of micro-services.
  prefs: []
  type: TYPE_NORMAL
- en: 'As stated in Oracle''s post:'
  prefs: []
  type: TYPE_NORMAL
- en: <q>Microservices are the kind of SOA we have been talking about for the last
    decade. -- *Torsten Winterberg, Oracle ACE Director.*</q>
  prefs: []
  type: TYPE_NORMAL
- en: So micro-services follow same principles but it is bit more specialized and
    focus on having multiple independent services where a service is a completely
    different component and it exists independent of other services.
  prefs: []
  type: TYPE_NORMAL
- en: Team structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As per Conway''s law:'
  prefs: []
  type: TYPE_NORMAL
- en: <q>"Organizations which design systems ... are constrained to produce designs
    which are copies of the communication structures of these organizations."</q>
  prefs: []
  type: TYPE_NORMAL
- en: So, in order to produce designs based on microservices architecture and to gain
    its benefits, we also need structured teams working on this accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Normally, in a monolithic application, we have teams such as the following
    ones:'
  prefs: []
  type: TYPE_NORMAL
- en: Dev-ops team
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backend-developer team
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DB administrator team
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mobile application developer team
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, in the case of distributed architecture such as microservices (if
    we are developing an e-commerce application), we will have teams such as the following
    ones:'
  prefs: []
  type: TYPE_NORMAL
- en: Products catalog
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inventory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Coupons
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wishlist
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All these teams will have members, including Dev-ops, Backend-developer, DB
    administrator, and mobile app developer. So, in the case of microservices, we
    will have a team per service.
  prefs: []
  type: TYPE_NORMAL
- en: '**Size of team:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'There is no hard and fast rule, but it is recommended that team size should
    be as per Jeff Bezos'' 2 pizza rule: <q>if a team couldn''t be fed with two pizzas,
    it was too big.</q> The reason is that if the team becomes bigger, then communication
    can be terrible.'
  prefs: []
  type: TYPE_NORMAL
- en: Challenges of micro-services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Nothing comes free. Everything has its downside or at least some challenges
    that you need to deal with. If we go for microservices, it has its own challenges.
    So, let's look at them and discuss how they can be minimized if there is trade-off.
  prefs: []
  type: TYPE_NORMAL
- en: Infrastructure maintenance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although you don't have to update your infrastructure every day, it still needs
    to be maintained and it needs more effort. Technology freedom comes with microservices,
    but not without any cost. You have to maintain different server instances using
    different technologies. This will need better infrastructure and people with experience
    of more technologies.
  prefs: []
  type: TYPE_NORMAL
- en: Actually, you don't always need better infrastructure and people with knowledge
    of all those different technologies. Normally, every team working on different
    services will have its own infrastructure or Dev-ops-related people. However,
    in that case, you need more people because now, you are not sharing Dev-ops or
    infrastructure-related people across different teams. In fact, this is how teams
    are made for microservices. Teams don't have shared resources at-least they shouldn't
    have. Otherwise, you don't get the advantage of parallel working because of independent
    services.
  prefs: []
  type: TYPE_NORMAL
- en: However, infrastructure doesn't only mean server setup, but also deployments,
    monitoring, and logging. So, for that purpose, you can't just use one technology
    and solve the problem on the trade-off of limiting your technology choices. However,
    limiting your technology choices can make it a bit easier for Dev-ops as well.
  prefs: []
  type: TYPE_NORMAL
- en: Another thing is that you need to have automated deployments on a continuous
    integration server. It runs your test cases, and then, if everything works well,
    it deploys on your actual server. For this purpose, you need to have Dev-ops person/people
    who write scripts to automate your deployments. There are several ways to do so.
  prefs: []
  type: TYPE_NORMAL
- en: Performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Actually, there can be reasons for microservices to run faster if one completely
    independent microservice is being used by the client. A clear reason is that a
    request has to go through less stuff in one small micro-service than passing through
    a big monolithic application.
  prefs: []
  type: TYPE_NORMAL
- en: However, this is an ideal case and not all microservices are completely independent
    of each other. They interact with each other and depend on each other. So, if
    one service has to get something from another one, it will most probably need
    a network call, and network calls are expensive. This results in performance problems.
    However, this can be minimized if services are created in a way where dependency
    is minimal. If dependency is not minimal, that means services are not independent
    and in that case we can combine such services and make one independent service.
  prefs: []
  type: TYPE_NORMAL
- en: Another option can be shared code; the code that will be used across different
    services. If two or more services are using the same functionality, then instead
    of having that as another service that different services depend on, we can simply
    make it a shared code that will be part of different services' code base. We will
    not repeat ourselves and will try to make it a module or package that different
    services can use. However, some people think it is bad practice as we will have
    some code shared between different services, which means it is not going to be
    loosely coupled.
  prefs: []
  type: TYPE_NORMAL
- en: Debugging and fault-finding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you can see, we said debugging and maintenance will be easier in a microservice.
    However, it also becomes a challenge when there is communication between these
    services and one's output is effecting another.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we have different services, we need a way for services to communicate
    with each other. Services communicate with each other in two ways: through HTTP
    calls or through messages. Here, by messages we mean using some sort of messaging
    queues such as RabbitMQ and so on. In the case of message passing, it can be very
    difficult if there is some bug or something unexpected is happening. Since it
    is not one service and every service is working based on the previous service''s
    output, it is difficult to know where the problem is.'
  prefs: []
  type: TYPE_NORMAL
- en: So, a way to tackle this is to write tests thoroughly. Because if it is making
    sure that every service's test cases are written and testing whether they are
    working fine, then it can fail before deployment.
  prefs: []
  type: TYPE_NORMAL
- en: However, this is not always the case. It is because there is not one service.
    Many services are interacting and sometimes, there is a problem in the live environment
    and you want to debug and fix it. For this purpose, logs are very important. However,
    again, this is a distributed environment. So, what can we do? Here are few things
    that you need to ensure you do with logs.
  prefs: []
  type: TYPE_NORMAL
- en: Logs should be centralized
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You need to collect logs in some central place. If you have logs in one centralized
    place, then it is much easier to look into them instead of checking every server
    instance for its logs.
  prefs: []
  type: TYPE_NORMAL
- en: It is also important because you should have logs in an external place other
    than your instances as logs' backup. The reason is that if you replace an instance,
    then you probably want to keep a copy of your logs to utilize while debugging.
    This can be any place either Amazon S3, your DB, or a disk, but you want it to
    be durable and available. If you are on AWS, then you can also use their monitoring
    service named CloudWatch at [https://aws.amazon.com/cloudwatch/](https://aws.amazon.com/cloudwatch/).
  prefs: []
  type: TYPE_NORMAL
- en: Logs should be searchable
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having logs is good. But just like a lot of information on Internet, it is not
    really useful if you don't know which link has the right information for you.
    It has become easier because of search engines telling us which pages have more
    relevant content. Similarly, logs of live applications, especially when there
    is a log of many services together, will not be that helpful. There will be a
    lot of logs. So, in order to make them usable, you should store your logs in way
    in which they can be searched for and be easily understood when you see them.
  prefs: []
  type: TYPE_NORMAL
- en: Track chain of requests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just like users go from one page to another on a website, the users' clients
    send request after request to perform different tasks. So, it is a good idea to
    know which requests the user sent before this one because in some cases, previous
    requests can have an impact othes. So, to track this, you can simply pass an identifier
    for the first time and should expect the same among all other requests.
  prefs: []
  type: TYPE_NORMAL
- en: Another advantage is that it will not only show you flow, but it will also be
    easier for you if you are asked to explain why some specific problem occurred.
    If that identifier is at the client side, the concerned person can give you that
    identifier for reference with their error report so that you can can understand
    which request flow to trace.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic log levels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Normally, for logging, you use some sort of logging framework, and typical log
    levels are warning, info, debug, and verbose. Normally, in production, log level
    info or other information is used, but if you want to have some problem and you
    want to debug it, you should be able to dynamically change that log level.
  prefs: []
  type: TYPE_NORMAL
- en: So, if you need, you should be able to set the log level dynamically on the
    fly. This is important because if you have problems in production, then you don't
    want it to persist for a long time.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As this chapter is just an introduction to microservices, we will not go into
    the details of implementation. However, we will just have an overview of how we
    will implement different things in microservices. We have already discussed RESTful
    web service implementation in this book. However, here are some other pieces that
    come with microservices. So, we will just get idea of what is involved in implementing
    these parts.
  prefs: []
  type: TYPE_NORMAL
- en: Deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will have deployments automated. We will use continuous delivery tools. Continuous
    delivery is a process in which there are frequent deliveries with short cycles,
    and it ensures that software can be reliably released at any time. It aims to
    release software faster and minimize risk with a build, and test and release software
    frequently approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuous delivery takes automation from source control all the way through
    production. There are various tools or processes that help in accomplishing a
    continuous delivery process. However, two important things in this are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CI (Continuous Integration)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First of all, before committing to code, a developer should run their tests
    (most importantly, unit tests) while on commit CI server, run integration tests,
    and integrate on the CI server if tests are passed. Travis CI and Jenkins CI are
    popular CI tools. Other than that, Circle CI is popular as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'After continuous integration, build is made automatically and deployed automatically.
    As a picture is worth a thousand words, to elaborate further, I have added this
    image from Wikipedia here (this image is from Wikimedia):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/649c4881-012a-43e8-adbf-adb9dc13a4b3.png)'
  prefs: []
  type: TYPE_IMG
- en: Through this diagram, we will get some idea of CI. For detailed information
    on continuous delivery, you can read the Wikipedia article at [https://en.wikipedia.org/wiki/Continuous_delivery](https://en.wikipedia.org/wiki/Continuous_delivery).
  prefs: []
  type: TYPE_NORMAL
- en: Inter-services communication
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We saw that communication between servers is important. Services depend on each
    other, and sometimes, input of one service is the output of another, while sometimes,
    one service is using another. One important thing is communication between these
    services.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, we can divide inter-service communication into two types:'
  prefs: []
  type: TYPE_NORMAL
- en: Synchronous communication
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Asynchronous communication
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Synchronous communication
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In synchronous communication, one service communicates with another and waits
    to get a result. This is normally done through simple HTTP calls using the same
    approach as end clients. So, these are simple HTTP calls that get a response (mostly
    JSON). One service sends an HTTP request to another service, waits for its response,
    and proceeds after getting the response. Synchronous communication has network
    overheads and have to wait for response, but it is simple to implement and sometimes
    that delay is not a problem. So in such cases, for the sake of simplicity we can
    use synchronous communication.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous communication
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In asynchronous communication, one service doesn't wait for another's response.
    It is based on a pub-sub model. It uses a message broker to send messages to other
    consumer/subscriber's services. It is done using Lightweight Messaging tools,
    through which one service sends messages to another. Such messaging tools include,
    but are not limited to, RabbitMQ, Apache Kafka, and Akka.
  prefs: []
  type: TYPE_NORMAL
- en: If you are interested in knowing more about microservices inter communications,
    then the article at [http://howtocookmicroservices.com/communication/](http://howtocookmicroservices.com/communication/)
    might seem interesting.
  prefs: []
  type: TYPE_NORMAL
- en: Shared library or common code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we discussed, there can be some code that is common among different services.
    It can be third-party code as well as code written by teams for the same application.
    In either case, we obviously want to use that common code. In order to do that,
    we don't just replicate that code in our applications because it breaks the DRY
    (Don't Repeat Yourself) principle. However, note that we can't use common code
    if we are using different programming languages/technologies.
  prefs: []
  type: TYPE_NORMAL
- en: So what we do is, we package that common code or shared library and upload it
    somewhere, from where we can fetch that package while deploying it. In the case
    of PHP, we will create composer packages and upload at packagist. Then, in service,
    when we need that common code, we will simply install the composer's package and
    use that common code from the vendor directory.
  prefs: []
  type: TYPE_NORMAL
- en: Such packages and package managers like composer are not just in PHP. In Node.js,
    there is NPM (Node Package Manager) using which you can create a Node package
    to serve the purpose. So, in different technologies, there are different ways
    to create and use such packages.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, as the last chapter of this book, I tried to introduce microservices,
    an architecture style getting a lot of attention nowadays. We looked into it because
    we needed an architecture in which we can use RESTful web services to achieve
    better performance and scalability in complex and bigger systems.
  prefs: []
  type: TYPE_NORMAL
- en: The focus of the book was RESTful web services in PHP7, and we looked at other
    topics that were connected with building RESTful web services or PHP7 in someway.
    We looked at some of these topics in detail, whereas we just touched upon some
    others. Many of these topics are too broad to be contained in one chapter. Some
    of these topics can have a complete book dedicated to them. That's why, I provided
    different URLs towards learning material or suggested reading, which you can refer
    to if you are interested.
  prefs: []
  type: TYPE_NORMAL
- en: What's next
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two important things:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Practice:**'
  prefs: []
  type: TYPE_NORMAL
- en: Actual learning starts when you start practicing something. When you practice,
    you sometimes face problems and learn more, which you couldn't learn without solving
    those problems.
  prefs: []
  type: TYPE_NORMAL
- en: '**Looking into suggested material:**'
  prefs: []
  type: TYPE_NORMAL
- en: Wherever I have provided suggested reading, pause there and at least have a
    look at the suggested material. If you find it helpful, feel free to dig deeper
    into it. Who knows, that suggested material might teach you something even more
    valuable to you than this entire book. After all, that material provides much
    more detail than we have discussed in this book.
  prefs: []
  type: TYPE_NORMAL
