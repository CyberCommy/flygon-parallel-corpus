- en: Awesome Things You Could Develop Using Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will discuss some advanced topics in Python. We will also
    discuss certain unique topics (such as image processing) that let you get started
    with application development in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Image processing using a Raspberry Pi Zero
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Raspberry Pi Zero is an inexpensive piece of hardware that is powered by
    a 1 GHz processor. While it is not powerful to run certain advanced image processing
    operations, it can help you learn the basics on a $25 budget (the cost of Raspberry
    Pi Zero and a camera).
  prefs: []
  type: TYPE_NORMAL
- en: We recommend using a 16 GB card (or higher) with your Raspberry Pi Zero in order
    to install the image processing tool set discussed in this section.
  prefs: []
  type: TYPE_NORMAL
- en: For example, you could use a Raspberry Pi Zero to track a bird in your backyard.
    In this chapter, we are going to discuss different ways to get started with image
    processing on the Raspberry Pi Zero.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to test some examples using the camera in this section, a Raspberry
    Pi Zero v1.3 or later is required. Check the back of your Raspberry Pi Zero to
    verify the board version:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/336f6014-9c00-42b2-8bd6-df6bcf8234f9.png)Identifying your Raspberry
    Pi Zero''s version'
  prefs: []
  type: TYPE_NORMAL
- en: OpenCV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**OpenCV** is an open source toolbox that consists of different software tools
    developed for image processing. OpenCV is a cross-platform toolbox that has been developed
    with support for different operating systems. Because OpenCV is available under
    an open source license, researchers across the world have contributed to its growth
    by developing tools and techniques. This has made developing applications with
    relative ease. Some applications of OpenCV include face recognition and license
    plate recognition.'
  prefs: []
  type: TYPE_NORMAL
- en: Due to its limited processing power, it can take several hours to complete the
    installation of the framework. It took us approximately 10 hours at our end.
  prefs: []
  type: TYPE_NORMAL
- en: We followed the instructions to install OpenCV on the Raspberry Pi Zero from
    [http://www.pyimagesearch.com/2015/10/26/how-to-install-opencv-3-on-raspbian-jessie/](http://www.pyimagesearch.com/2015/10/26/how-to-install-opencv-3-on-raspbian-jessie/).We
    specifically followed the instructions to install OpenCV with Python 3.x bindings
    and verified the installation process. It took us approximately 10 hours to finish
    installing OpenCV on the Raspberry Pi Zero. We are not repeating the instructions
    in the interest of not reinventing the wheel.
  prefs: []
  type: TYPE_NORMAL
- en: The verification of the installation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s make sure that the OpenCV installation and its Python bindings work.
    Launch the command-line terminal and make sure that you have launched the `cv`
    virtual environment by executing the `workon cv` command (you can verify that
    you are in the `cv` virtual environment):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/f6bb84ac-5cb6-47c7-957c-38a368522c8f.png)Verify that you are in
    the cv virtual environment'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s make sure that our installation works correctly. Launch the Python
    interpreter from the command line and try to import the `cv2` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This proves that OpenCV is installed on the Raspberry Pi Zero. Let''s write
    a *hello world* example involving OpenCV. In this example, we are going to open
    an image (this can be any color image on your Raspberry Pi Zero''s desktop) and
    display it after converting it to grayscale. We will be using the following documentation
    to write our first example: [http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html](http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 'According to the documentation, we need to make use of the `imread()` function
    to read the contents of the image file. We also need to specify the format in
    which we would like to read the image. In this case, we are going to read the
    image in grayscale format. This is specified by `cv2.IMREAD_GRAYSCALE` that is
    passed as the second argument to the function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that the image is loaded in grayscale format and saved to the `img` variable,
    we need to display it in a new window. This is enabled by the `imshow()` function.
    According to the documentation, we can display an image by specifying the window
    name as the first argument and the image as the second argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, we are going to open a window named `image` and display the contents
    of `img` that we loaded in the previous step. We will display the image until
    a keystroke is received. This is achieved using the `cv2.waitKey()` function.
    According to the documentation, the `waitkey()` function listens for keyboard
    events:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `0` argument indicates that we are going to wait indefinitely for a keystroke.
    According to the documentation, when the duration, in milliseconds, is passed
    as an argument, the `waitkey()` function listens to keystrokes for the specified
    duration. When any key is pressed, the window is closed by the `destroyAllWindows()`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Putting it all together, we have this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code sample is available for download along with this chapter
    as `opencv_test.py`. Once you are done installing OpenCV libraries, try loading
    an image as shown in this example. It should load an image in grayscale, as shown
    in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/07c57257-d721-43d2-8a6b-ca99272b7111.jpg)The Raspberry Pi desktop
    loaded in grayscale'
  prefs: []
  type: TYPE_NORMAL
- en: This window would close at the press of any key.
  prefs: []
  type: TYPE_NORMAL
- en: A challenge to the reader
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the preceding example, the window closes at the press of any key. Take a
    look at the documentation and determine if it is possible to close all windows
    at the press of a mouse button.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the camera to the Raspberry Zero
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A camera connector and a camera is required for testing our next example. One
    source to buy the camera and the adapter is provided here:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Name** | **Source** |'
  prefs: []
  type: TYPE_TB
- en: '| Raspberry Pi Zero camera adapter | [https://thepihut.com/products/raspberry-pi-zero-camera-adapter](https://thepihut.com/products/raspberry-pi-zero-camera-adapter)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Raspberry Pi camera | [https://thepihut.com/products/raspberry-pi-camera-module](https://thepihut.com/products/raspberry-pi-camera-module)
    |'
  prefs: []
  type: TYPE_TB
- en: 'Perform the following steps to install a camera to the Raspberry Pi Zero:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is interfacing the camera to the Raspberry Pi Zero. The camera
    adapter can be installed as shown in the following figure. Lift the connector
    tab and slide the camera adapter and press the connector gently:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/ce975b8d-7043-48b9-888c-5cc2f83c2bbc.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We need to enable the camera interface on the Raspberry Pi Zero. On your desktop,
    go to Preferences and launch Raspberry Pi Configuration. Under the Interfaces
    tab of the Raspberry Pi configuration, enable the camera, and save the configuration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/f4cb1bc3-eb01-4a84-93d0-ab51a26c6525.png)Enable the camera interface'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s test the camera by taking a picture by running the following command
    from the command-line terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'It should take a picture and save it to your Raspberry Pi''s desktop. Verify
    that the camera is functioning correctly. If you are not able to get the camera
    working, we recommend the troubleshooting guide published by the Raspberry Pi
    Foundation: [https://www.raspberrypi.org/documentation/raspbian/applications/camera.md](https://www.raspberrypi.org/documentation/raspbian/applications/camera.md).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The camera cable is a bit unwieldy, and it can make things difficult while
    trying to take a picture. We recommend using a camera mount. We found this one
    to be useful (shown in the following image) at [http://a.co/hQolR7O](http://a.co/hQolR7O):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/9e2dd057-9117-42fe-b345-e1913a450643.png)Use a mount for your Raspberry
    Pi''s camera'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take the camera for a spin and use it alongside OpenCV libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to take a picture using the camera and display it using the OpenCV
    framework. In order to access the camera in Python, we need the `picamera` package.
    This can be installed as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Let's make sure that the package works as intended with a simple program. The
    documentation for the `picamera` package is available at [https://picamera.readthedocs.io/en/release-1.12/api_camera.html](https://picamera.readthedocs.io/en/release-1.12/api_camera.html).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The first step is initializing the `PiCamera` class. This is followed by flipping
    the image across the vertical axis. This is only required because the camera is
    mounted upside down on the mount. This may not be necessary with other mounts:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Before taking a picture, we can preview the picture that is going to be captured
    using the `start_preview()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s preview for `10` seconds before we take a picture. We can take a picture
    using the `capture()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The `capture()` method requires the file location as an argument (as shown in
    the preceding snippet). Once we are done, we can close the camera preview using
    `stop_preview()`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Putting it altogether, we have this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code sample is available for download along with this chapter
    as `picamera_test.py`. A snapshot taken using the camera is shown in the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/355f9dc6-2b49-4a4a-82df-4dc5cb381f71.png)Image captured using the
    Raspberry Pi camera module'
  prefs: []
  type: TYPE_NORMAL
- en: Let's combine this example with the previous one—convert this image to grayscale
    and display it until a key is pressed. Ensure that you are still within the `cv`
    virtual environment workspace.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s convert the captured image to grayscale as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the image converted upon capture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/48620f3f-ce1a-4271-8e97-d07f43502fbf.png)Image converted to grayscale
    upon capture'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can display the grayscale image as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The modified example is available for download as `picamera_opencvtest.py`.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have demonstrated developing image processing applications in Python.
    We also recommend checking out examples available with the OpenCV Python binding
    documentation (link provided in the introduction part of this section).
  prefs: []
  type: TYPE_NORMAL
- en: Speech recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will discuss developing a speech recognition example in
    Python involving speech recognition. We will make use of the `requests` module
    (discussed in the previous chapter) to transcribe audio using `wit.ai` ([https://wit.ai/](https://wit.ai/)).
  prefs: []
  type: TYPE_NORMAL
- en: There are several speech recognition tools, including Google's Speech API, IBM
    Watson, Microsoft Bing's speech recognition API. We are demonstrating `wit.ai`
    as an example.
  prefs: []
  type: TYPE_NORMAL
- en: Speech recognition can be useful in applications where we would like to enable
    the Raspberry Pi Zero responses to voice commands.
  prefs: []
  type: TYPE_NORMAL
- en: Let's review building the speech recognition application in Python using `wit.ai`
    (its documentation is available here at [https://github.com/wit-ai/pywit](https://github.com/wit-ai/pywit)).
    In order to perform speech recognition and recognize voice commands, we will need
    a microphone. However, we will demonstrate using a readily available audio sample.
    We will make use of audio samples made available by a research publication (available
    at [http://ecs.utdallas.edu/loizou/speech/noizeus/clean.zip](http://ecs.utdallas.edu/loizou/speech/noizeus/clean.zip)).
  prefs: []
  type: TYPE_NORMAL
- en: The `wit.ai` API license states that the tool is free to use, but the audio
    uploaded to their servers are used to tune their speech transcription tool.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now attempt transcribing the `sp02.wav` audio sample performing the
    following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is signing up for an account with `wit.ai`. Make a note of the
    API as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/f4e59c40-82a5-4fcf-8ccc-d7512b47c0fe.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The first step is installing the requests library. It could be installed as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'According to the `wit.ai` documentation, we need to add custom headers to our
    request that includes the API key (replace `$TOKEN` with the token from your account).
    We also need to specify the file format in the header. In this case, it is a `.wav`
    file, and the sampling frequency is 8000 Hz:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to transcribe the audio sample, we need to attach the audio sample
    in the request body:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Putting it all together, gives us this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code sample is available for download along with this chapter
    as `wit_ai.py`. Try executing the preceding code sample, and it should transcribe
    the audio sample: `sp02.wav`. We have the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The audio sample contains the following recording: *He knew the skill of the
    great young actress*. According to the `wit.ai` API, the transcription is *He
    knew the the great young actress*. The word error rate is 22% ([https://en.wikipedia.org/wiki/Word_error_rate](https://en.wikipedia.org/wiki/Word_error_rate)).'
  prefs: []
  type: TYPE_NORMAL
- en: Automating routing tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to discuss automating routing tasks in Python.
    We took two examples such that they demonstrate the ability of a Raspberry Pi
    Zero acting as a personal assistant. The first example involves improving your
    commute, whereas the second example serves as an aid to improve your vocabulary.
    Let's get started.
  prefs: []
  type: TYPE_NORMAL
- en: Improving daily commute
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many cities and public transit systems have started sharing data with the public
    in the interest of being transparent and improving their operational efficiency.
    Transit systems have started sharing advisories and transit information to the
    public through an API. This enables anyone to develop mobile applications that
    provide information to commuters. At times, it helps with easing congestion within
    the public transit system.
  prefs: []
  type: TYPE_NORMAL
- en: This example was inspired by a friend who tracks bicycle availability in San
    Francisco's bike share stations. In the San Francisco Bay Area, there is a bicycle
    sharing program that enables commuters to rent a bike from a transit center to
    their work. In a crowded city like San Francisco, bike availability at a given
    station fluctuates depending on the time of day.
  prefs: []
  type: TYPE_NORMAL
- en: This friend wanted to plan his day based on bike availability at the nearest
    bike share station. If there are very few bikes left at the station, this friend
    preferred leaving early to rent a bike. He was looking for a simple hack that
    would push a notification to his phone when the number of bikes is below a certain
    threshold. San Francisco's bike share program makes this data available at [http://feeds.bayareabikeshare.com/stations/stations.json](http://feeds.bayareabikeshare.com/stations/stations.json).
  prefs: []
  type: TYPE_NORMAL
- en: Let's review building a simple example that would enable sending a push notification
    to a mobile device. In order to send a mobile push notification, we will be making
    use of **If This Then That** (**IFTTT**)—a service that enables connecting your
    project to third-party services.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we will parse the data available in JSON format, check the
    number of available bikes at a specific station, and if it is lower than the specified
    threshold, it triggers a notification on your mobile device.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: The first step is retrieving the bike availability from the bike share service.
    This data is available in JSON format at [http://feeds.bayareabikeshare.com/stations/stations.json](http://feeds.bayareabikeshare.com/stations/stations.json).
    The data includes bike availability throughout the network.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The bike availability at each station is provided with parameters, such as station
    ID, station name, address, number of bikes available, and so on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In this example, we will retrieve the bike availability for the `Townsend at
    7th` station in San Francisco. The station ID is `65` (open the earlier-mentioned
    link in a browser to find `id`). Let''s write some Python code to retrieve the
    bike availability data and parse this information:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The first step is fetching the data using a `GET` request (via the `requests`
    module). The `requests` module provides an inbuilt JSON decoder. The JSON data
    can be parsed by calling the `json()` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can iterate through the dictionary of stations and find the bike availability
    at `Townsend at 7th`, by performing the following steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the retrieved data, each station''s data is furnished with an ID. The station
    ID in question is `65` (open the data feed URL provided earlier in a browser to
    understand the data format; a snippet of the data is shown in the following screenshot):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/5dc6a42b-f6ff-49b5-b0e5-01f33cebc4ce.png)A snippet of the bike share
    data feed fetched using a browser'
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to iterate through the values and determine if the station `id` matches
    that of `Townsend at 7th`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: If there are less than `2` bikes available at the station, we push a mobile
    notification to our mobile device.
  prefs: []
  type: TYPE_NORMAL
- en: In order to receive mobile notifications, you need to install *IF by IFTTT*
    app (available for Apple and Android devices).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We also need to set up a recipe on IFTTT to trigger mobile notifications. Sign
    up for an account at [https://ifttt.com/](https://ifttt.com/).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: IFTTT is a service that enables creating recipes that connecting devices to
    different applications and automating tasks. For example, it is possible to log
    events tracked by the Raspberry Pi Zero to a spreadsheet on your Google Drive.
  prefs: []
  type: TYPE_NORMAL
- en: All recipes on IFTTT follow a common template—*if this then that*, that is,
    if a particular event has occurred, then a specific action is triggered. For this
    example, we need to create an applet that triggers a mobile notification on receiving
    a web request.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can start creating an applet using the drop-down menu under your account,
    as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/b3366418-76f2-48ad-809c-1b1f1a7430b3.png)Start creating a recipe
    on IFTTT'
  prefs: []
  type: TYPE_NORMAL
- en: 'It should take you to a recipe setup page (shown as follows). Click on this
    and set up an incoming web request:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/23037a0e-b3a4-47e9-8049-ddc92161b253.png)Click on this'
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the Maker Webhooks channel as the incoming trigger:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/67372bef-0815-42f2-8df2-81aa088e6aab.png)Select the Maker Webhooks
    channel'
  prefs: []
  type: TYPE_NORMAL
- en: 'Select Receive a web request. A web request from the Raspberry Pi would act
    as a trigger to send a mobile notification:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/73429b8a-fcb0-4be5-9e76-bd54cde37d86.png)Select Receive a web request'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a trigger named `mobile_notify`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/adc6d023-51ad-4120-8e02-3fcaa1fc4645.png)Create a new trigger named
    mobile_notify'
  prefs: []
  type: TYPE_NORMAL
- en: It is time to create an action for the incoming trigger. Click on that.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/07d3564b-95ee-496e-927f-3c66400bc4e5.png)Click on that'
  prefs: []
  type: TYPE_NORMAL
- en: 'Select Notifications:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/31cf0258-7cb2-4ab3-ab1d-6207f545b4dd.png)Select Notifications'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s format the notification that we would like to receive on our devices:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/624dbdf8-0882-422f-9795-2207e23aa71f.png)Setup notification for
    your device'
  prefs: []
  type: TYPE_NORMAL
- en: In the mobile notification, we need to receive the number of bikes available
    at the bike share station. Click on the + Ingredient button and select `Value1`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/67d4c4f5-3a6b-4c6b-95ea-c1671f8bb5a0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Format the message to suit your needs. For example, when a notification is
    triggered by the Raspberry Pi, it would be great to receive a message in the following
    format: `Time to go home! Only 2 bikes are available at Townsend & 7th!`'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/21ebe4f5-60ce-42ca-b57a-a7ac6ce9b362.png)'
  prefs: []
  type: TYPE_IMG
- en: Once you are satisfied with the message format, select Create action and your
    recipe should be ready!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/77fb0b9e-af9f-4ed6-ac95-fd5881e6545e.png)Create a recipe'
  prefs: []
  type: TYPE_NORMAL
- en: In order to trigger a notification on our mobile device, we need a URL to make
    the `POST` request and a trigger key. This is available under Services | Maker
    Webhooks | Settings in your IFTTT account.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The trigger can be located here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/b4bd2cc0-41f1-45c2-a1b5-2bccbd8fb0d1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Open the URL listed in the preceding screenshot in a new browser window. It
    provides the URL for the `POST` request as well as an explanation on (shown in
    the following screenshot) how to make a web request:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/eb376740-2b7f-4b22-8f8e-76a6d19b7657.png)Making a POST request using
    the earlier-mentioned URL (key concealed for privacy)'
  prefs: []
  type: TYPE_IMG
- en: While making a request (as explained in the IFTTT documentation), if we include
    the number of bikes in the JSON body of request (using `Value1`), it can be shown
    on the mobile notification.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s revisit the Python example to make a web request when the number of
    bikes is below a certain threshold. Save the `IFTTT` URL and your IFTTT access
    key (retrieved from your IFTTT account) to your code as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'When the number of bikes is below a certain threshold, we need to make a `POST`
    request with the bike information encoded in the JSON body:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code snippet, if there are less than three bikes, a `POST`
    request is made using the `requests` module. The number of available bikes is
    encoded with the key `value1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Putting it all together, we have this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code sample is available for download along with this chapter
    as `bike_share.py`. Try executing it after setting up a recipe on IFTTT. If necessary,
    adjust the threshold for the number of available bikes. You should receive a mobile
    notification on your device:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/0e3e05fa-062c-4929-887e-afabf3fd16d8.png)Notification on your mobile
    device'
  prefs: []
  type: TYPE_NORMAL
- en: A challenge to the reader
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this example, the bike information is fetched and parsed and if necessary,
    a notification is triggered. How would you go about modifying this code example
    to make sure that it is executed between a given time of the day? (hint: make
    use of `datetime` module).'
  prefs: []
  type: TYPE_NORMAL
- en: How would you go about building a desktop display that serves as a visual aid?
  prefs: []
  type: TYPE_NORMAL
- en: Project challenge
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Try to find out if the transit systems in your area provide such data to its
    users. How would you make use of the data to help commuters save time? For example,
    how would you provide transit system advisories to your friends/colleagues using
    such data?
  prefs: []
  type: TYPE_NORMAL
- en: On completion of the book, we will post a similar example using the data from
    San Francisco **Bay Area Rapid Transit** (**BART**).
  prefs: []
  type: TYPE_NORMAL
- en: Improving your vocabulary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is possible to improve your vocabulary using Python! Imagine setting up
    a large display that is installed somewhere prominently and updated on a daily
    basis. We will be making use of the `wordnik` API (sign up for an API key at [https://www.wordnik.com/signup](https://www.wordnik.com/signup)):'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to install the `wordnik` API client for `python3`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: There are restrictions on the wordnik API usage. Refer to the API documentation
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s review writing our first example using the `wordnik` Python client.
    In order to fetch the word of the day, we need to initialize the `WordsApi` class.
    According to the API documentation, this could be done as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that the `WordsApi` class is initialized, let''s go ahead and fetch the
    word of the day:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This returns a `WordOfTheDay` object. According to the `wordnik` Python client
    documentation, this object consists of different parameters including the word,
    its synonym, source, usage, and so on. The word of the day and its synonym could
    be printed as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Putting it all together, we have this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code snippet is available for download along with this chapter
    as `wordOfTheDay.py`. Sign up for an API key, and you should be able to retrieve
    the word of the day:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: A challenge to the reader
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'How would you daemonize this application such that the word of the day is updated
    every day? (hint: cronjob or `datetime`).'
  prefs: []
  type: TYPE_NORMAL
- en: Project challenge
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is possible to build a word game using the `wordnik` API. Think of a word
    game that is entertaining as well as helps improve your vocabulary. How would
    you go about building something that prompts questions to the player and accepting
    answer inputs?
  prefs: []
  type: TYPE_NORMAL
- en: Try displaying the word of the day on a display. How would you implement this?
  prefs: []
  type: TYPE_NORMAL
- en: Logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Logging ([https://docs.python.org/3/library/logging.html](https://docs.python.org/3/library/logging.html))
    helps with troubleshooting a problem. It helps with determining the root cause
    of a problem by tracing back through the sequence of events logged by the application.
    Let''s review logging using a simple application. In order to review logging,
    let''s review it by making a `POST` request:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step in logging is setting the log file location and the log level:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'While initializing the `logging` class, we need to specify the format for logging
    information, errors, and so on to the file. In this case, the format is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The log messages are in the following format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The log messages are saved to a file named `log_file.log`.
  prefs: []
  type: TYPE_NORMAL
- en: The logging level determines the level of logging needed for our application.
    The different log levels include `DEBUG`, `INFO`, `WARN`, and `ERROR`.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we have set the logging level to `INFO`. So, any log message
    belonging to `INFO`, `WARNING`, or `ERROR` levels are saved to the file.
  prefs: []
  type: TYPE_NORMAL
- en: If the logging level is set to `ERROR`, only those log messages are saved to
    the file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s log a message based on the outcome of the `POST` request:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Putting it all together, we have this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code sample (`logging_example.py`) is available for download along
    with this chapter. This is a very soft introduction to the concept of logging
    in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Threading in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to discuss the concept of threading in Python.
    Threads enable running multiple processes at the same time. For example, we can
    run motors while listening to incoming events from sensors. Let's demonstrate
    this with an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to emulate a situation where we would like to process events from
    sensors of the same type. In this example, we are just going to print something
    to the screen. We need to define a function that listens to events from each sensor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'We can make use of the preceding function to listen for sensor events from
    three different sensors at the same time using the `threading` module in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Putting it all together, we have this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code sample (available for download as `threading_example.py`)
    starts three threads that listens to events from three sensors at the same time.
    The output looks something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: PEP8 style guide for Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**PEP8** is a style guide for Python that helps programmers write readable
    code. It is important to follow certain conventions to make our code readable.
    Some examples of coding conventions include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Inline comments should start with a `# ` and be followed by a single space.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Variables should have the following convention: `first_var`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoiding trailing whitespaces on each line. For example, `if name == "test":`
    should not be followed by whitespaces.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can read the entire PEP8 standards at [https://www.python.org/dev/peps/pep-0008/#block-comments](https://www.python.org/dev/peps/pep-0008/#block-comments).
  prefs: []
  type: TYPE_NORMAL
- en: Verifying PEP8 guidelines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are tools to verify PEP8 standards of your code. After writing a code
    sample, ensure that your code adheres to PEP8 standards. This can be done using
    the `pep8` package. It can be installed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s check whether one of our code samples has been written according to
    the PEP8 convention. This can be done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The check indicated the following errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'As the output indicates, the following lines are missing a whitespace after
    a comma on lines `5` and `6`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/1b943d8f-20da-4864-b184-b775bba8fd7b.png)Missing trailing whitespace
    after the comma'
  prefs: []
  type: TYPE_NORMAL
- en: Let's fix the problem, and our code should adhere to PEP8 conventions. Recheck
    the file and the errors would have disappeared. In order to make your code readable,
    always run a PEP8 check before checking in your code to a public repository.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed advanced topics in Python. We discussed topics
    including speech recognition, building a commuter information tool, and a Python
    client to improve your vocabulary. There are advanced tools in Python that are
    widely used in the fields of data science, AI, and so on. We hope that the topics
    discussed in this chapter are the first step in learning such tools.
  prefs: []
  type: TYPE_NORMAL
