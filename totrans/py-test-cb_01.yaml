- en: Using Unittest to Develop Basic Tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Asserting the basics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up and tearing down a test harness
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running test cases from the command line
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running a subset of test case methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chaining together a suite of tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining test suites inside the test module
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retooling old test code to run inside unittest
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Breaking down obscure tests into simple ones
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing the edges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing corner cases by iteration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing has always been a part of software development. However, the world was
    introduced to a new concept called **automated testing** when Kent Beck and Erich
    Gamma introduced JUnit for Java development ([http://junit.org](http://junit.org)).
    It was based on Kent's earlier work with Smalltalk and automated testing[.](http://www.xprogramming.com/testfram.htm))
    Currently, automated testing has become a well-accepted concept in the software
    industry.
  prefs: []
  type: TYPE_NORMAL
- en: A Python version, originally dubbed **PyUnit**, was created in 1999 and added
    to Python's standard set of libraries later in 2001 in Python 2.1\. Currently,
    the PyUnit library is available for both versions of Python, that is, 2.7 ([https://docs.python.org/2.7/library/unittest.html](https://docs.python.org/2.7/library/unittest.html))
    and 3.x ([https://docs.python.org/3.6/library/unittest.html](https://docs.python.org/3.6/library/unittest.html)).
    Since then, the Python community has referred to it as **unittest**, the name
    of the library imported into the test code.
  prefs: []
  type: TYPE_NORMAL
- en: Unittest is the foundation of automated testing in the Python world. In this
    chapter, we will explore the basics of testing and asserting code functionality,
    building suites of tests, test situations to avoid, and finally testing edges
    and corner cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'For all the recipes in this chapter, we will use `virtualenv` ([https://pypi.python.org/pypi/virtualenv](https://pypi.python.org/pypi/virtualenv))
    to create a controlled Python runtime environment. Unittest is part of the standard
    library, which requires no extra installation steps. But in later chapters, using
    `virtualenv` will allow us to conveniently install other test tools, without cluttering
    up our default Python installation. The steps to install `virtualenv` are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To install `virtualenv`, either download it from the site mentioned previously
    or if you have Easy Install, just type: `easy_install virtualenv`. You can also
    use `pip install virtualenv` as well.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For some systems, you may need to install it either as `root` or by using `sudo`.
  prefs: []
  type: TYPE_NORMAL
- en: After installing `virtualenv`, use it to create a clean environment named `ptc` (an
    abbreviation used for *Python Testing Cookbook*) by using `--no-site-packages`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Activate the virtual Python environment. This can vary, depending on which shell
    you are using. Take a look at this screenshot:![](../images/00005.jpeg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For the Windows platform, you can either select the folder where you want to
    create the `ptc` folder or you can directly get it created in your desired drive.
    Look at this screenshot:![](../images/00006.jpeg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, verify that the environment is active by checking the path of `pip`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For more information on the usage and benefits of `virtualenv`, please read [http://iamzed.com/2009/05/07/a-primer-on-virtualenv](http://iamzed.com/2009/05/07/a-primer-on-virtualenv).
  prefs: []
  type: TYPE_NORMAL
- en: Asserting the basics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The basic concept of an automated unittest test case is to instantiate part
    of our code, subject it to operations, and verify certain results using assertions:'
  prefs: []
  type: TYPE_NORMAL
- en: If the results are as expected, unittest counts it as a test success
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the results don't match, an exception is thrown, and unittest counts it as
    a test failure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unittest was added to Python's standard batteries included library suite and
    doesn't require any extra installation.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With these steps, we will code a simple program and then write some automated
    tests using unittest:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new file called `recipe1.py` for this recipe''s code. Pick a class
    to test. This is known as the **class under test**. For this recipe, we''ll pick
    a class that uses a simplistic Roman numeral converter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This Roman numeral converter applies the simple rules of addition, but it doesn't
    have the special subtraction patterns such as `XL` mapping to `40`. The purpose
    is not to have the best Roman numeral converter, but to observe the various test
    assertions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Write a new class and give it the same name with `Test` appended to the end,
    subclassing `unittest.TestCase`. Appending a test class with `Test` is a common
    convention, but not a requirement. Extending `unittest.TestCase` is a requirement
    needed to hook into unittest''s standard test runner:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Create several methods with names starting with `test`, so they are automatically
    picked up by the test number of unittest:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Make the entire script runnable and then use unittest''s test runner:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the file from the command line, as shown in this screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../images/00007.jpeg)`self.assertEquals()` has been deprecated in Python
    3.'
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the first step, we picked a class to test. Next, we created a separate class
    to test. By naming the test class as `[class under test]Test`, it is easy to tell
    which class is under test. Each test method name must start with `test`, so that
    unittest will automatically pick it up and run it. To add more tests, just define
    more `test` methods. Each of these tests utilizes various assertions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`assertEqual(first, second[, msg])`: Compares first and second expressions
    and fails if they don''t have the same value. We can optionally print a special
    message if there is a failure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`assertTrue(expression[, msg])`: Tests the expression and fails if it is false.
    We can optionally print a special message if there is a failure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`assertFalse(expression[, msg])`: Tests the expression and fails if it is true.
    We can optionally print a special message if there is a failure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`assertRaises(exception, callable, ...)`: Runs the callable with any arguments,
    for the callable listed afterwards, and fails if it doesn''t raise the exception.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unittest provides many options for asserting, failing, and other convenient
    options. The following sections show some recommendations on how to pick and choose
    from these options.
  prefs: []
  type: TYPE_NORMAL
- en: assertEquals is preferred over assertTrue and assertFalse
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When an `assertEquals` assertion fails, the first and second values are printed
    in the error report, giving a better feedback of what went wrong, whereas `assertTrue`
    and `assertFalse` simply report failure. Not all testable results fit this, but,
    if possible, use `assertEquals`.
  prefs: []
  type: TYPE_NORMAL
- en: It's important to understand the concept of equality. When comparing integers,
    strings, and other scalars, it's very simple. It doesn't work as well with collections
    such as dictionaries, lists, and sets. Complex, custom-defined objects may carry
    custom definitions of equality. These complex objects may require more fine-grained
    assertions. That is why it's probably a good idea to also include some test methods
    that directly target equality and inequality when working with custom objects.
  prefs: []
  type: TYPE_NORMAL
- en: self.fail([msg]) can usually be rewritten with assertions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unittest has a `self.fail([msg])` operation that unconditionally causes the
    test to fail, along with an optional message. This was not shown earlier because
    it is not recommended for use.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `fail` method is often used to detect certain situations such as exceptions.
    A common idiom is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This tests the same behavior as the earlier `test_no_roman_numeral`. The problem
    with this approach is that when the code is working properly the fail method is
    never executed. Code not executed regularly is at risk of becoming out of date
    and invalid. This will also interfere with coverage reports. Instead, it is better
    to use `assertRaises` as we used in the earlier examples. For other situations
    look at rewriting the test using the other assertions.
  prefs: []
  type: TYPE_NORMAL
- en: Our version of Python can impact our options
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python's official documentation on unittest shows many other assertions; however,
    they depend on the version of Python we are using. Some have been deprecated;
    others are only available in later versions, such as Python 3.6.
  prefs: []
  type: TYPE_NORMAL
- en: If our code must support multiple versions of Python then we must use the lowest
    common denominator. This recipe shows core assertions available in all versions
    since Python 3.6.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up and tearing down a test harness
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unittest provides an easy mechanism to configure the state of the system when
    a piece of code is put through a test. It also allows us to clean things up afterward,
    if needed. This is commonly needed when a particular test case has repetitive
    steps used in every test method.
  prefs: []
  type: TYPE_NORMAL
- en: Barring any references to external variables or resources that carry state from
    one test method to the next, each test method starts from the same state.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the following steps, we will set up and teardown a test harness for each
    test method:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new file called `recipe2.py` for the code in this recipe.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Pick a class to test. In this case, we will use a slightly altered version
    of our Roman numeral converter, where the function, not the constructor, provides
    the input value to convert:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a class to test using the same name as the class under test with `Test`
    appended to the end:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `setUp` method that creates an instance of the class under test:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `tearDown` method that destroys the instance of the class under test:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Create all the test methods using `self.converter`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Make the entire script runnable and then use the test runner of unittest:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the file from the command line, as shown in this screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../images/00008.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the first step, we picked a class to test. Next, we created a separate test
    class. By naming the test class `[class under test]Test`, it is easy to tell which
    class is under test.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we defined a `setUp` method that unittest runs before every `Test` method.
    Next, we created a `tearDown` method that unittest runs after every `Test` method.
    In this case, we added a print statement in each of them to demonstrate unittest
    rerunning these two methods for every test method. In reality, it would probably
    add too much noise to our testing.
  prefs: []
  type: TYPE_NORMAL
- en: One deficiency of unittest is the lack of `setUpClass`/`tearDownClass` and `setUpModule`/`tearDownModule`,
    providing the opportunity to run code in greater scopes than at the test method
    level. This has been added to `unittest2`.
  prefs: []
  type: TYPE_NORMAL
- en: '**Each test case can have one setUp and one tearDown method: **Our `RomanNumeralConverter`
    is pretty simple and fits easily into a single test class. But the test class
    allows only one `setUp` method and one `tearDown` method. If different combinations
    of `setUp`/`tearDown` methods are needed for various test scenarios, then this
    is a cue to code more test classes. Just because we write a `setUp` method, doesn''t
    mean we need a `tearDown` method. In our case, we could have skipped destroying
    the `RomanNumeralConverter`, because a new instance would be replacing it for
    every test method. It was really for demonstration purposes only. What are the
    other uses of those cases that need a `tearDown` method? Using a library that
    requires some sort of close operation is a ripe candidate for writing a `tearDown`
    method.'
  prefs: []
  type: TYPE_NORMAL
- en: Running test cases from the command line
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is easy to adjust the test runner to print out every test method as it is
    run.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we will run test cases with more detailed output, giving
    us better insight into how things run:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new file called `recipe3.py` for this recipe's code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Pick a class to test. In this case, we will use our Roman numeral converter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a test class using the same name as the class under test with `Test`
    appended to the end:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Create several test methods. For this recipe, the second test have been deliberately
    coded to fail:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a test suite that automatically loads all the test methods, and then
    runs them with the higher level of verbosity:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the file from the command line. Notice how, in this screenshot the test
    method that fails, prints out its Python docstring:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../images/00009.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A key part of automated testing is organizing the tests. The base units are
    called **test cases**. These can be combined together into **test suites**. Python's
    unittest module provides `TestLoader().loadTestsFromTestCase` to fetch all the
    `test*` methods automatically into a test suite. This test suite is then run through
    unittest's `TextTestRunner` with an increased level of verbosity.
  prefs: []
  type: TYPE_NORMAL
- en: '`TextTestRunner` is unittest''s only test runner. Later in this book, we will
    look at other test tools that have different runners, including the one that plugs
    in a different unittest test runner.'
  prefs: []
  type: TYPE_NORMAL
- en: The previous screenshot shows each method along with its module and class name,
    as well as success/failure.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe not only demonstrates how to turn up the verbosity of running tests,
    but also shows what happens when a test case fails. It renames the `test` method
    with the document string embedded in the `test` method, and prints the details
    later after all the test methods have been reported.
  prefs: []
  type: TYPE_NORMAL
- en: Running a subset of test case methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes, it's convenient to run only a subset of test methods in a given test
    case. This recipe will show how to run either the whole test case, or pick a subset
    from the command line.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following steps show how to code a command-line script to run subsets of
    tests:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new file named `recipe4.py` to put all the code for this recipe.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Pick a class to test. In this case, we will use our Roman numeral converter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a test class using the same name as the class under test with `Test`
    appended to the end:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Create several `test` methods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Write a main runner that either runs the entire test case or accepts a variable
    number of test methods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the recipe with no extra command-line arguments and see it run all the
    tests, as shown in this screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../images/00010.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this test case, we coded a couple of test methods. But instead of simply
    running all the tests, or defining a fixed list, we used Python's `sys` library
    to parse the command-line arguments. If there are no extra arguments, it runs
    the entire test case. If there are extra arguments, then they are assumed to be
    test method names. It uses unittest's inbuilt ability to specify test method names
    when instantiating `RomanNumeralConverterTest`.
  prefs: []
  type: TYPE_NORMAL
- en: Chaining together a suite of tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unittest makes it easy to chain together test cases into a `TestSuite`. A `TestSuite`
    can be run just like a `TestCase`, but it also provides additional functionality
    to add a single/multiple tests, and count them.
  prefs: []
  type: TYPE_NORMAL
- en: Why do we need this? Chaining together tests into a suite gives us the ability
    to pull together more than one module of test cases for a test run, as well as
    picking and choosing a subset of test cases. Up until now, we have generally run
    all the test methods from a single class. `TestSuite` gives us an alternative
    means to define a block of testing.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we will code multiple test case classes, and then load
    their test methods into suites so we can run them:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new file named `recipe5.py` to put our sample application and test
    cases.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Pick a class to test. In this case, we will use our Roman numeral converter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Create two test classes with various test methods spread between them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a test runner in a separate file named `recipe5_runner.py` that pulls
    in both test cases:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Execute the test runner, and observe from this screenshot how tests are pulled
    in from both test cases.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../images/00011.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The unittest module provides a convenient way to find all the test methods in
    a `TestClass` and bundle them together as a suite using its `loadTestsFromTestCase`.
    To further the usage of test suites, we are able to combine these two suites together
    as a single suite using `unittest.TestSuite([list...])`. The `TestSuite` class
    is designed to act as a `TestCase` class does, even though it doesn't subclass
    `TestClass`, allowing us to run it using `TextTestRunner`. This recipe shows the
    verbosity turned up, allowing us to see exactly what test methods were run, and
    from what test case they came from.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we ran the tests from a different file than where the test cases
    are defined. This is different than the previous recipes where the runnable code
    and the test case were contained in the same file. Since the runner is defining
    the tests we run, we can easily create more runners that combine different suites
    of tests.
  prefs: []
  type: TYPE_NORMAL
- en: The name of the test case should be significant
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous recipes, it has been advised to name the test case as `[class
    under test]Test`. This is to make it apparent to the reader that the class under
    test and the related test share an important relationship. Now that we are introducing
    another test case, we need to pick a different name. The name should explain clearly
    why these particular test methods are split out into a separate class. For this
    recipe, the methods are split out to show more complex combinations of Roman numerals.
  prefs: []
  type: TYPE_NORMAL
- en: Defining test suites inside the test module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Each test module can provide one or more methods that define a different test
    suite. One method can exercise all the tests in a given module, another method
    can define a particular subset.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the following steps, we will create some methods that define test suites
    using different means:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new file called `recipe6.py` to put our code for this recipe.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Pick a class to test. In this case, we will use our Roman numeral converter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a test class using the same name as the class under test with `Test`
    appended to the end:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Write a series of test methods, including a `setUp` method that creates a new
    instance of the `RomanNumeralConverter` for each test method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Create some methods in the recipe''s module (but not in the test case) that
    define different test suites:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a runner that will iterate over each of these test suites and run them
    through unittest''s `TextTestRunner`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the combination of test suites, and see the results. Take a look at this
    screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../images/00012.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We pick a class to test and define a number of test methods that check things
    out. Then we define a few module-level methods such as, `high_and_low`, `combos`,
    and `all`, to define test suites. Two of them contain fixed subsets of methods
    while `all` dynamically loads the `test*` methods from the class. Finally, the
    main part of our module iterates over a listing of all these functions that generate
    suites to smoothly create and run them.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All of our test suites were run from the recipe's main runner. But this probably
    wouldn't be the case for a real project. Instead, the idea is to define different
    suites, and code a mechanism to pick which suite to run. Each suite is geared
    towards a different purpose, and it is necessary to allow the developer to pick
    which suite to run. This can be done by coding a command-line script using Python's
    optparse module to define command-line flags to pick one of these suites.
  prefs: []
  type: TYPE_NORMAL
- en: Test suite methods must be outside of the test class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If we make these suite-defining methods members of the test class, we would
    have to instantiate the test class. Classes that extend `unittest.TestCase` have
    a specialized `init` method that doesn't work well with an instance that is created
    just to call a non-test method. That is why the methods are outside the test class.
    While these methods can be in other modules, it is very convenient to define them
    inside the module containing the test code, to keep things in proximity.
  prefs: []
  type: TYPE_NORMAL
- en: Why have different suites?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'What if we started our project off by running all tests? Sounds like a good
    idea, right? But what if the time to run the entire test suite grew to over an
    hour? There is a certain threshold after which developers tend to stop running
    tests, and *nothing is worse than an un-run test**suite*. By defining subsets
    of tests, it is easy to run alternate suites during the day, and then perhaps
    run the comprehensive test suite once a day. Bear in mind the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`all` is the comprehensive suite'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`high_and_low` is an example of testing the edges'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`combos` is a random sampling of values used to show that things are generally
    working'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining our test suites is a judgment call. It's also worth re-evaluating each
    test suite every so often. If one test suite is getting too costly to run, consider
    moving some of its more expensive tests to another suite.
  prefs: []
  type: TYPE_NORMAL
- en: optparse is being phased out and replaced by argparse
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While `optparse` is a convenient way to add command-line flags to Python scripts,
    it won't be available forever. Python 2.7 has deprecated this module and is continuing
    this development in `argparse`.
  prefs: []
  type: TYPE_NORMAL
- en: Retooling old test code to run inside unittest
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes, we may have developed demo code to exercise our system. We don't
    have to rewrite it to run it inside unittest. Instead, it is easy to hook it up
    to the test framework and run it with some small changes.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With these steps, we will dive into capturing the test code that was written
    without using unittest, and repurposing it with minimal effort to run inside unittest:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a file named `recipe7.py` to put our application code that we will be
    testing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Pick a class to test. In this case, we will use our Roman numeral converter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Create a new file named `recipe7_legacy.py` to contain test code that doesn't
    use the unittest module.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a set of legacy tests that are coded, based on Python''s `assert` function,
    not with unittest, along with a runner:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: This set of legacy tests is meant to represent legacy test code that our team
    has developed to exercise things before unittest was an option.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the legacy tests. What is wrong with this situation? Did all the test methods
    run? Have we caught all the bugs? Take a look at this screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../images/00013.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Create a new file called `recipe7_pyunit.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a unittest set of tests, wrapping each legacy test method inside unittest''s
    `FunctionTestCase`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the unittest test. Did all the tests run this time? Which test failed?
    Where is the bug? Look at this screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../images/00014.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python provides a convenient assert statement that tests a condition. When true,
    the code continues. When false, it raises an `AssertionError`. In the first test
    runner, we have several tests that check results using a mixture of `assert` statements
    or raising an `AssertionError`.
  prefs: []
  type: TYPE_NORMAL
- en: unittest provides a convenient class, `unittest.FunctionTestCase`, that wraps
    a bound function as a unittest test case. If an `AssertionError` is thrown, `FunctionTestCase`
    catches it, flags it as a test *failure*, and proceeds to the next test case.
    If any other type of exception is thrown, it will be flagged as a test error.
    In the second test runner, we wrap each of these legacy test methods with `FunctionTestCase`,
    and chain them together in a suite for unittest to run.
  prefs: []
  type: TYPE_NORMAL
- en: As seen by running the second test run, there is a bug lurking in the third
    test method. We were not aware of it because the test suite was prematurely interrupted.
  prefs: []
  type: TYPE_NORMAL
- en: Another deficiency of Python's assert statement is shown by the first failure,
    as seen in the previous screenshot. When an assert fails, there is little to no
    information about the values that were compared. All we have is the line of code
    where it failed. The second assert in that screenshot was more useful, because
    we coded a custom checker that threw a custom `AssertionError`.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unittest does more than just run tests. It has a built-in mechanism to trap
    errors and failures, and then it continues running as much of our test suite as
    possible. This helps, because we can shake out more errors and fix more things
    within a given test run. This is especially important when a test suite grows
    to the point of taking minutes or hours to run.
  prefs: []
  type: TYPE_NORMAL
- en: Where are the bugs?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'They exist in the test methods, and fundamentally were made by making slight
    alterations to the Roman numeral being converted, as shown in the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The `combo_test1` test method prints out that it is converting `MMX`, but actually
    tries to convert `MMXX`. The `combo_test2` test method prints out that it is converting
    `MMMMDCLXVIII`, but actually tries to convert `MMMMDCLXVII`.
  prefs: []
  type: TYPE_NORMAL
- en: This is a contrived example, but have you ever run into bugs just as small that
    drove you mad trying to track them down? The point is, showing how easy or hard
    it can be to track them down is based on how the values are checked. Python's
    `assert` statement isn't very effective at telling us what values are compared
    where. The customized `check` method is much better at pinpointing the problem
    with `combo_test2`.
  prefs: []
  type: TYPE_NORMAL
- en: This highlights the problem with having comments or print statements trying
    to reflect what the asserts do. They can easily get out of sync and the developer
    may face some problems trying to track down bugs. Avoiding this situation is known
    as the **DRY** principle (**Don't Repeat Yourself**).
  prefs: []
  type: TYPE_NORMAL
- en: FunctionTestCase is a temporary measure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`FunctionTestCase` is a test case that provides an easy way to quickly migrate
    tests based on Python''s `assert` statement, so they can be run with unittest.
    But things shouldn''t stop there. If we take the time to convert `RomanNumeralTester`
    into a unittest `TestCase`, then we gain access to other useful features such
    as the various `assert*` methods that come with `TestCase`. It''s a good investment.
    The `FunctionTestCase` just lowers the bar to migrate to unittest.'
  prefs: []
  type: TYPE_NORMAL
- en: Breaking down obscure tests into simple ones
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unittest provides the means to test the code through a series of assertions.
    I have often felt the temptation to exercise many aspects of a particular piece
    of code within a single test method. If any part fails, it becomes obscured as
    to which part failed. It is preferable to split things up into several smaller
    test methods, so that when some part of the code under test fails, it is obvious.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With these steps, we will investigate what happens when we put too much into
    a single test method:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new file named `recipe8.py` to put out application code in for this
    recipe.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Pick a class to test. In this case, we will use an alternative version of the
    Roman numeral converter, which converts both ways:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Create a new file called `recipe8_obscure.py` to put some longer test methods.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create some test methods that combine several test assertions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Run the obscure tests. Why did it fail? Where is the bug? It reports that `II`
    is not equal to `I`, so something appears to be off. Is this the only bug? Create
    another file called `recipe8_clear.py` to create a more fine-grained set of test
    methods. Take a look at this screenshot:![](../images/00015.jpeg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Split up the assertions into separate test methods to give a higher fidelity
    of output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the clearer test suite. Is it a bit clearer where the bug is? What did
    we trade in to get this higher degree of test failure? Was it worth the effort?
    Refer to this screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../images/00016.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this case, we created a modified Roman numeral converter that converts both
    ways. We then started creating test methods to exercise things. Since each of
    these tests were a simple, one line assertion, it was convenient to put them all
    in the same test method.
  prefs: []
  type: TYPE_NORMAL
- en: In the second test case, we put each assertion into a separate test method.
    Running it exposes the fact that there are multiple bugs in this Roman numeral
    converter.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we started off writing tests, it was very convenient to bundle all these
    assertions into a single test method. After all, if everything is working, there
    is no harm, right? But what if everything does *not* work; what do we have to
    deal with? An obscure error report!
  prefs: []
  type: TYPE_NORMAL
- en: Where is the bug?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The obscured test runner may not be clear. All we have to go on is `II != I` which
    isn't much. The clue is that it is only off by one. The clear test runner gives
    more clues. We see that `V != IIII, XII != XI`, and some more. Each of these failures
    shows things being off by one.
  prefs: []
  type: TYPE_NORMAL
- en: 'The bug involves the various Boolean conditions in the while checks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Instead of testing greater than, it should test for *greater than* or *equal
    to*. This causes it to skip out of each Roman numeral before counting the last
    one.
  prefs: []
  type: TYPE_NORMAL
- en: What is the right size for a test method?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we broke things down to a single assertion per test. But I wouldn't
    advise thinking along these lines.
  prefs: []
  type: TYPE_NORMAL
- en: If we look a little closer, each test method also involves a single usage of
    the Roman numeral API. For the converter, there is only one result to examine
    when exercising the code. For other systems, the output may be more complex. It
    is completely warranted to use several assertions in the same test method to check
    the outcome by making that single call.
  prefs: []
  type: TYPE_NORMAL
- en: When we proceed to make more calls to the Roman numeral API, it should signal
    us to consider splitting it off into a new test method.
  prefs: []
  type: TYPE_NORMAL
- en: 'This raises the question: *What is a unit of code?* There has been much debate
    over what defines a unit of code, and what makes a good unit test. There are many
    opinions. Hopefully, reading this chapter and weighing it against the other test
    tactics covered throughout this book will help you enhance your own opinion and
    ultimately improve your own testing talent.'
  prefs: []
  type: TYPE_NORMAL
- en: Unittests versus integration tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unittest can easily help us write both unittests as well as integration tests.
    Unittests exercise smaller blocks of code. When writing unittests, it is best
    to keep the testing as small and fine-grained as possible. Breaking testing up
    into lots of smaller tests is often a better approach to detecting and pinpointing
    bugs.
  prefs: []
  type: TYPE_NORMAL
- en: When we move up to a higher level (such as integration testing), it makes sense
    to test multiple steps in a single test method. But this is only recommended if
    there are adequate low-level unit tests. This will shed some light on whether
    it is broken at the unit level, or there exists a sequence of steps that causes
    the error.
  prefs: []
  type: TYPE_NORMAL
- en: Integration tests often extend to things such as external systems. For example,
    many argue that unit testing should never connect to a database, talk to an LDAP
    server, or interact with other systems.
  prefs: []
  type: TYPE_NORMAL
- en: Just because we are using unittest doesn't mean the tests we are writing are
    unit tests. Later in this book, we will visit the concept that unittest can be
    used to write many types of tests including integration tests, smoke tests, and
    other types as well.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the edges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we write automated tests, we pick the inputs and assert the expected outputs.
    It is important to test the limits of the inputs to make sure our code can handle
    good and bad inputs. This is also known as **testing corner cases**.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we dig into this recipe, we will look for good boundaries to test against:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new file named `recipe9.py` for the code in this recipe.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Pick a class to test. In this recipe, we''ll use another variation of our Roman
    numeral converter. This one doesn''t process values greater than `4000`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a test case that sets up an instance of the Roman numeral converter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Add several test methods that exercise the edges of converting to Roman numeral
    notation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Add several test methods that exercise the edges of converting to decimal notation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Add some tests that exercise the tiers of converting decimals to Roman numerals:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Add some tests that input unexpected values to the Roman numeral converter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Add a unit test runner:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the test case. Take a look at this screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../images/00017.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have a specialized Roman numeral converter that only converts values up
    to `MMMM` or `4000`. We have written several test methods to exercise it. The
    immediate edges we write tests for are `1` and `4000`. We also write some tests
    for one step past that: `0` and `4001`. To make things complete, we also test
    against `-1`.'
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A key part of the algorithm involves handling the various tiers of Roman numerals
    (5, 10, 50, 100, 500, and 1000). These could be considered *mini-edges*, so we
    wrote tests to check that the code handled those as well. Do you think we should
    test one past the mini-edges?
  prefs: []
  type: TYPE_NORMAL
- en: It's recommended we should. Many bugs erupt due to coding *greater than*, when
    it should be *greater than or equal* (or vice versa), and so on. Testing one past
    the boundary, in both directions, is the perfect way to make sure that things
    are working exactly as expected. We also need to check bad inputs, so we tried
    converting `None` and a `float`.
  prefs: []
  type: TYPE_NORMAL
- en: 'That previous statement raises an important question: *How many invalid types
    should* *we test against*? Because Python is dynamic, we can expect a lot of input
    types. So, what is reasonable? If our code hinges on a dictionary lookup, such
    as certain parts of our Roman numeral API does, then confirming that we correctly
    handle a `KeyError` would probably be adequate. We don''t need to input lots of
    different types if they all result in a `KeyError`.'
  prefs: []
  type: TYPE_NORMAL
- en: Identifying the edges is important
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It's important to identify the edges of our system, because we need to know
    our software can handle these boundaries. We also need to know it can handle both
    sides of these boundaries that are good values and bad values. That is why we
    need to check `4000` and `4001` as well as `0` and `1`. This is a common place
    where software breaks.
  prefs: []
  type: TYPE_NORMAL
- en: Testing for unexpected conditions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Does this sound a little awkward? Expect the unexpected? Our code involves converting
    integers and strings back and forth. By unexpected, we mean types of inputs passed
    in when someone uses our library that doesn't understand the edges, or wires it
    to receive inputs that are wider ranging types than we expected to receive.
  prefs: []
  type: TYPE_NORMAL
- en: A common occurrence of misuse is when a user of our API is working against a
    collection, such as a list, and accidentally passes the entire list instead of
    a single value by iteration. Another, often seen situation is when a user of our
    API passes in `None` due to some other bug in their code. It's good to know that
    our API is resilient enough to handle this.
  prefs: []
  type: TYPE_NORMAL
- en: Testing corner cases by iteration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While developing code, new corner-case inputs are often discovered. Being able
    to capture these inputs in an iterable array makes it easy to add related test
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we will look at a different way to test corner cases:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new file called `recipe10.py` for our code in this recipe.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Pick a class to test. In this recipe, we''ll use another variation of our Roman
    numeral converter. This one doesn''t process values greater than `4000`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a test class to exercise the Roman numeral converter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Write a test method that exercises the edges of the Roman numeral converter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a test method that exercises the tiers converting from decimal to Roman
    numerals:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a test method that exercises a set of invalid inputs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Code a utility method that iterates over the edge cases and runs different
    assertions based on each edge:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Make the script runnable by loading the test case into `TextTestRunner`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the test case, as shown in this screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../images/00018.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have a specialized Roman numeral converter that only converts values up
    to `MMMM` or `4000`. The immediate edges we write tests for are `1` and `4000`.
    We also write some tests for one step past that: `0` and `4001`. To make things
    complete, we also test against `-1`.'
  prefs: []
  type: TYPE_NORMAL
- en: But we've written the tests a little differently. Instead of writing each test
    input/output combination as a separate test method, we capture the input and output
    values in a tuple that is embedded in a list. We then feed it to our test iterator,
    `checkout_edge`. Because we need both `assertEqual` and `assertRaise` calls, the
    tuple also includes either equals or raises to flag which assertion to use.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, to make it flexibly handle the conversion of both Roman numerals and
    decimals, the handles on the `convert_to_roman` and `convert_to_decimal` functions
    of our Roman numeral API are embedded in each tuple as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in the following highlighted parts, we grab a handle on `convert_to_roman` and
    store it in `r`. Then we embed it in the third element of the highlighted tuple,
    allowing the `checkout_edge` function to call it when needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A key part of the algorithm involves handling the various tiers of Roman numerals
    (5, 10, 50, 100, 500, and 1000). These could be considered *mini-edges*, so we
    wrote a separate test method that has a list of input/output values to check those
    out as well. In the *Testing the edges* recipe, we didn't include testing before
    and after these mini-edges, for example, `4` and `6` for `5`. Now that it only
    takes one line of data to capture this test, we have it in this recipe. The same
    was done for all the others (except 1000).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we need to check bad inputs, so we created one more test method where
    we try to convert `None` and a `float` to and from a Roman numeral.
  prefs: []
  type: TYPE_NORMAL
- en: Does this defy the recipe – breaking down obscure tests into simple ones?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a way, it does. If something goes wrong in one of the test data entries,
    then that entire test method will have failed. That is one reason why this recipe
    split things up into three test methods instead of one big test method to cover
    them all. This is a judgment call about when it makes sense to view inputs and
    outputs as more data than test method. If you find the same sequence of test steps
    occurring repeatedly, consider if it makes sense to capture the values in some
    sort of table structure, such as a list used in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How does this compare with the recipe – testing the edges?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In case it wasn't obvious, these are the exact same tests used in the *Testing
    the edges* recipe. The question is, which version do you find more readable? Both
    are perfectly acceptable. Breaking things up into separate methods makes it more
    fine-grained and easier to spot if something goes wrong. Collecting things together
    into a data structure, the way we did in this recipe, makes it more succinct and
    could spur us on to write more test combinations as we did for the conversion
    tiers.
  prefs: []
  type: TYPE_NORMAL
- en: In my own opinion, when testing algorithmic functions that have simple inputs
    and outputs, it's more suitable to use this recipe's mechanism to code an entire
    battery of test inputs in this concise format. For example, a mathematical function,
    a sorting algorithm, or perhaps a transform function.
  prefs: []
  type: TYPE_NORMAL
- en: When testing functions that are more logical and imperative, the other recipe
    may be more useful. For example, functions that interact with a database, cause
    changes in the state of the system, or other types of side effects that aren't
    encapsulated in the return value would be hard to capture using this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Breaking down obscure tests into simple ones*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Testing the edges*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
