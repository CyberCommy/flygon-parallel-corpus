- en: Configuring Applications to Use Kubernetes Features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The last chapter demonstrated how to work with a containerized Windows application
    in Kubernetes—now, we are going to extend our voting application to use more advanced
    features which make the orchestration even more robust and automated. Over the
    years, Kubernetes has been extended with a growing number of features, ranging
    from fine-grained **Role-Based Access Control** (**RBAC**) or Secrets management
    to autoscaling using **Horizontal Pod Autoscaler** (**HPA**), the holy grail of
    container orchestration. Of course, we are not able to cover all of them in the
    scope of this book, but we are going to include the most useful features that
    help running containerized Windows applications. Also, please bear in mind that
    some of the features are not available when you are running an on-premises Kubernetes
    cluster, for example, cloud-specific StorageClass provisioners—all of the examples
    we are going to present are assuming that you are running an AKS Engine Kubernetes
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Using namespaces to isolate applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Health monitoring using liveness and readiness probes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specifying resource limits and configuring autoscaling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing application configuration using ConfigMaps and Secrets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing persistent data storage on Windows nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring rolling updates for Deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RBAC
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you will need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Windows 10 Pro, Enterprise, or Education (version 1903 or later, 64-bit) installed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microsoft Visual Studio 2019 Community (or any other edition) if you want to
    edit the source code for the application and debug it—Visual Studio Code has limited
    support for the classic .NET Framework
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An Azure account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Windows/Linux Kubernetes cluster deployed using AKS Engine, ready to deploy
    the voting application from the previous chapter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To follow along, you will need your own Azure account to create Azure resources
    for the Kubernetes cluster. If you haven't already created the account for the
    previous chapters, you can read more about how to obtain a limited free account
    for personal use at [https://azure.microsoft.com/en-us/free/](https://azure.microsoft.com/en-us/free/).
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a Kubernetes cluster using AKS Engine has been covered in [Chapter
    8](ab695a0d-05dc-48f8-8c41-bbd167cfbfa6.xhtml), *Deploying a Hybrid Azure Kubernetes
    Service Engine Cluster*. Voting application Deployment to Kubernetes has been
    covered in [Chapter 10](4e5931bc-4267-4631-a5fe-bc140827257d.xhtml), *Deploying
    Microsoft SQL Server 2019 and ASP.NET MVC Application*.
  prefs: []
  type: TYPE_NORMAL
- en: You can download the latest code samples for this chapter from the official
    GitHub repository, at [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11).
  prefs: []
  type: TYPE_NORMAL
- en: Using namespaces to isolate applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous chapter, we already used a namespace (named `dev`) to logically
    group components of our application into a virtual cluster within an existing
    physical Kubernetes cluster. The general principle of namespaces is providing
    resource quotas and a scope for object names—names inside a given namespace must
    be unique, but they do not have to be unique across different namespaces. By default,
    Kubernetes provides the following namespaces out of the box:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kube-system`: A namespace for objects created by the Kubernetes system, such
    as `kube-apiserver` or `kube-proxy` Pods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kube-public`: A namespace that can be read by all users, also not authenticated—it
    will be created in clusters that are bootstrapped by kubeadm and it is generally
    intended for system use.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`default`: A namespace for objects with no other namespace.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Depending on your needs and the size of your team, you may be more comfortable
    with using just object labels (small teams) or separating the objects at namespace
    level (large team):'
  prefs: []
  type: TYPE_NORMAL
- en: For small teams, where a single developer is capable of understanding the whole
    system (around 10 microservices) and where the whole development environment can
    be hosted using local clusters, such as minikube or kubeadm deployment running
    on VMs, it is possible to stick just to the default namespace for your production
    services. Alternatively, you may use a dedicated namespace for production workloads
    and a separate one for the development/staging environment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For rapidly growing medium-sized teams, where a single developer is not working
    in the scope of the whole system, it may be easier to provide dedicated namespaces
    for each sub-team, especially if it is not possible to create the whole development
    environment on a local Kubernetes cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For large teams, where sub-teams operate almost independently, it may be a good
    idea to have separate production and development namespaces for each team. You
    may also think about using resource quotas per each namespace and using RBAC.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For enterprise organizations, where individual teams may not even be aware of
    other teams, it may be easier to create separate clusters instead of dividing
    a single cluster using namespaces. This makes resource and billing management
    easier and provides better boundaries between deployments in case of issues.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When creating a Service object, namespaces influence what is the **Fully-Qualified
    Domain Name** (**FQDN**) for the DNS entry of the Service. The FQDNs have a form
    of `<service-name>.<namespace-name>.svc.cluster.local`—this means that if you
    use `<service-name>` when calling a Service from a Pod, the call will be scoped
    to the namespace where this Pod is running. Note that cross-namespace calls to
    Services are possible but then you need to specify the FQDN.
  prefs: []
  type: TYPE_NORMAL
- en: Let's demonstrate how you can create a namespace for your objects.
  prefs: []
  type: TYPE_NORMAL
- en: Creating namespaces
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create a namespace named `prod`, you can use the following imperative command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'As in the case of other objects, it is generally recommended to use declarative
    object configuration management and apply manifest files to the Kubernetes cluster.
    The following `namespace-prod.yaml` manifest file will create the `prod` namespace,
    additionally specifying the `ResourceQuota` object, which determines the total
    CPU and memory quota for this namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To apply the manifest file, execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, you can use the `kubectl describe` command to check how many resources
    are used in our namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Resource quotas in Kubernetes are highly customizable and can be applied to
    different resources and scoped using sophisticated selectors. You can read more
    about this in the official documentation at [https://kubernetes.io/docs/concepts/policy/resource-quotas/](https://kubernetes.io/docs/concepts/policy/resource-quotas/).
  prefs: []
  type: TYPE_NORMAL
- en: Now, when you know how to manage namespaces, let's see how you can use them
    efficiently with `kubectl` commands.
  prefs: []
  type: TYPE_NORMAL
- en: kubectl commands and namespaces
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`kubectl` commands, which operate on namespace-scoped objects by convention,
    use the `--namespace` or `-n` flag to specify the namespace that should be used
    for the command. If you need to query for objects in all namespaces, you can use
    the `--all-namespaces` flag instead. For example, to list all Pods in the `prod`
    namespace, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In the previous chapters, you have used this construct a lot. However, it is
    good to know that if no namespace is provided for the command, it will use the
    namespace set as default in the current kubeconfig context. In other words, it
    does not have to be the default namespace—it all depends on your context settings.
    We have covered contexts in depth in [Chapter 6](791e78c0-f625-4232-9907-36e25ec2767d.xhtml), *Interacting
    with Kubernetes Clusters*—for completeness, we will show how to change the namespace
    used in the current context. To set the `prod` namespace permanently in your current
    context, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Now, any command that supports specifying namespace will use the `prod` namespace
    by default.
  prefs: []
  type: TYPE_NORMAL
- en: Deleting namespaces
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Similar to other objects, deleting namespaces is recommended to be done imperatively.
    To delete the `prod` namespace, execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Please note that this command deletes all objects within this namespace, which
    means it is a highly destructive command and should be used with caution!
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will see how you can use probes to configure containers
    monitoring for liveness and readiness.
  prefs: []
  type: TYPE_NORMAL
- en: Health monitoring using liveness and readiness probes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In Kubernetes, probes are used by kubelet to determine the state of a Pod—you
    can use them to customize how you check whether a Pod is ready to serve your traffic
    or a container needs to be restarted. There are three types of probes that you
    can configure for each container running in a Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Readiness probe**: This is used to determine whether a given container is
    ready to accept traffic. A Pod is considered ready only if all of its containers
    are ready. Pods that are not ready will be removed from Service Endpoints until
    they become ready again.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Liveness** **probe**: This is used to detect whether a container needs to
    be restarted. This can help in situations when a container has been stuck in a
    deadlock or other issues when the container process is alive but unable to operate properly.
    Restarting the container may increase the availability of Pods in that case.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Startup** **probe**: This is an additional probe used for determining whether
    a container has been fully started—readiness and liveness probes are disabled
    until this probe returns successfully. This is especially useful for containers
    that have a long startup time due to some initialization. In this way, you can
    avoid premature kills by the liveness probe.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By default, there are no probes configured on Pod containers. However, Kubernetes
    will serve traffic only if the Pod containers have been started (in the Docker
    sense) and restart the containers if they crash (depending on your restart policy
    of course).
  prefs: []
  type: TYPE_NORMAL
- en: 'All types of probes can be configured using three types of handler actions:'
  prefs: []
  type: TYPE_NORMAL
- en: Running a command (`exec`)—if a given command running in the container returns
    non-zero exit code, the probe is in a failed state.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Executing an HTTP GET request (`httpGet`)—the probe is in a successful state
    only if the container responds to the HTTP GET request with an HTTP code greater
    than or equal to 200 and less than 400.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Opening a TCP socket to the container on a specified port (`tcpSocket`)—the
    probe is in a successful state if the connection can be established.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You should additionally consider using the termination grace period for your
    Pods to properly manage a containerized application life cycle and make your application
    gracefully exit when a SIGTERM signal is received ([https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-terminating-with-grace](https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-terminating-with-grace)).
    Please note that, for Windows Pods, the termination grace period is not supported
    as of Kubernetes 1.17.
  prefs: []
  type: TYPE_NORMAL
- en: There are a couple of caveats and best practices when working with probes that
    are true for any large distributed system with many dependent components. We will
    go through the details when explaining each type of probes—the voting application
    source code reflecting the examples can be found in the official GitHub repository,
    at [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/02_voting-application-probes-src](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/02_voting-application-probes-src).
    First, let's take a look at the most popular probe, the readiness probe.
  prefs: []
  type: TYPE_NORMAL
- en: Readiness probes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Readiness probes are used in Kubernetes to determine whether a Pod container
    is ready to accept traffic incoming from a Kubernetes Service—Pods that are not
    ready (a Pod is ready only if all of its containers are considered ready) will
    be removed from the Service Endpoints list until they become ready again. In other
    words, it is a signal for notifying that a given Pod can be used for requests
    incoming to the Service.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a couple of established best practices for readiness probes that
    you should consider:'
  prefs: []
  type: TYPE_NORMAL
- en: Use this probe whenever your containers may not be ready to properly serve traffic
    as soon as the container is started.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure that you check the cache warm-up or database migration status during
    readiness probe evaluation. You may also consider starting the actual process
    of a warm-up if it hasn't been started yet, but use this approach with caution—a readiness
    probe will be executed constantly throughout the life cycle of a Pod, which means
    you shouldn't do any costly operations for every request. Alternatively, you may
    want to use a startup probe for this purpose, newly-introduced in Kubernetes 1.16.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For microservice applications that expose HTTP endpoints, consider always configuring
    the `httpGet` readiness probe. This will ensure that all cases are covered when
    a container is successfully running but the HTTP server is not fully initialized.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is a good idea to use a separate, dedicated HTTP endpoint for readiness checks
    in your application, for example, a common convention is using `/health`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are checking the state of dependencies (external database and logging
    services) in this type of probe, be careful with shared dependencies, such as
    SQL Server in the voting application. In this case, you should consider using
    a probe timeout, which is greater than the maximum allowed timeout for the external
    dependency— otherwise, you may get cascading failures and lower availability instead
    of occasionally increased latency.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For web applications hosted using **IIS** (short for **Internet Information
    Services**), a readiness probe makes a lot of sense—the IIS App Pool needs to
    be fully started and database migrations may not be applied yet. As an example,
    we will configure a simple readiness probe for our voting application, which will
    look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The ASP.NET MVC application will implement a dedicated controller serving `/health`
    requests.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pending database migrations will be checked. Note that this will indirectly
    verify the database connection status, which might be not desirable in some cases.
    Therefore, we will use a probe timeout larger than 30 seconds (the default SQL
    command timeout).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Controller actions will return a simple JSON. The HTTP status will be 503 in
    case of a failed check and 200 in case of success.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To add a readiness probe for the voting application, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation of a health check controller action can be found in the `HealthController`
    class ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/02_voting-application-probes-src/Controllers/HealthController.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/02_voting-application-probes-src/Controllers/HealthController.cs))
    and looks as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Additionally, you need to remember to modify routing configuration for your
    application in the `RouteConfig` class ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/02_voting-application-probes-src/App_Start/RouteConfig.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/02_voting-application-probes-src/App_Start/RouteConfig.cs)),
    before the default route map:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: As in the previous chapter, build a Docker image of the application, tag it
    as 1.1.0 version, and push it to Docker Hub. In our demonstration case, we will
    be using the `packtpubkubernetesonwindows/voting-application:1.1.0` image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Modify the Deployment manifest file, `voting-application.yaml`, to include
    the following readiness probe configuration for the `frontend` container:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The probe is configured to call the `/health` endpoint, which will execute
    the controller action that we have previously implemented. The important parts
    in the probe configuration are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`initialDelaySeconds` is set to `30` seconds to allow IIS for full initialization.
    It turns out that too early calls to applications running on IIS under `ServiceMonitor.exe` supervision
    may result in premature exits of the container (maybe a bug in the `ServiceMonitor.exe` implementation).'
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timeoutSeconds` is set to `40` seconds to exceed the SQL Server database timeout,
    which is set by default to `30` seconds.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, apply the manifest file using the `kubectl apply -f .\voting-application-readiness-probe.yaml`
    command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Inspect the rollout process using the `kubectl get pods -n dev` and `kubectl
    describe` commands as usual. In the Pod events, you can verify whether the Pod
    had any readiness failures.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the web browser, when you navigate to the application, you should not experience
    any IIS App Pool startup delays —the web server will be warmed up by readiness
    checks.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, let's take a look at another probe that determines the liveness status
    of a Pod container.
  prefs: []
  type: TYPE_NORMAL
- en: Liveness probes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The second type of probe is the liveness probe, which can be configured similarly
    to the readiness probe in the manifest. Liveness probes are used to determine
    whether a Pod container needs to be restarted. This type of probe may be useful
    in recovering deadlocks or other types of issues in the container when the process
    has not exited but is not able to handle any operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to readiness probes, there are a couple of guidelines on how and when
    you should use liveness probes:'
  prefs: []
  type: TYPE_NORMAL
- en: Liveness probes should be used with caution. The wrong configuration of this
    probe can result in cascading failures in your services and container restart
    loops. As a quick experiment, you can redeploy the voting application manifest
    where you replace the readiness probe with a liveness probe, with similar configuration
    but very short timeouts and delays—you will experience multiple random crashes
    and poor availability of the application!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do not use liveness probes unless you have a good reason for this. A good reason
    may, for example, be a known issue with a deadlock in your application that has
    an as yet unknown root cause.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Execute simple and fast checks that determine the status of the process, not
    its dependencies. In other words, you do not want to check external dependencies'
    statuses in the liveness probe—this can lead to cascading failures due to an avalanche
    of container restarts and overloading a small subset of Service Pods.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your process running in the container is able to crash or exit whenever it
    encounters an unrecoverable error, you probably do not need a liveness probe at
    all.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use conservative settings for `initialDelaySeconds` to avoid any premature container
    restarts and falling into a restart loop.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Web applications hosted by IIS can be a good candidate for using a liveness
    probe if you do not know exactly what is going under the hood of the `ServiceMonitor.exe`
    and `LogMonitor.exe` entry point processes. In theory, they should crash the container
    whenever there is a problem with IIS or IIS App Pool, but let''s assume we need
    to implement these checks ourselves. We will implement a liveness probe that will
    check whether IIS App Pool is running using the `exec` handler. To do that, follow
    these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Modify the `voting-application.yaml` manifest file with `Deployment` for our
    application. Add the following liveness probe configuration for the `frontend`
    container:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The probe is configured so that it executes a PowerShell command, `if ((Get-WebAppPoolState
    DefaultAppPool).Value -ne "Started") { throw "Default IIS App Pool is NOT started"
    }`, which checks whether the default IIS App Pool is in a `Started` state. If
    it is not, an exception will be thrown and the PowerShell process will exit with
    non-zero exit code causing the probe to go into a failed state.
  prefs: []
  type: TYPE_NORMAL
- en: Now, apply the manifest file using the `kubectl apply -f .\voting-application-readiness-probe.yaml` command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Again, inspect the rollout process using the `kubectl get pods -n dev` and `kubectl
    describe` commands. In the Pod events, you may verify whether the Pods had any
    liveness failures.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When using the `exec` handler, you should carefully analyze how the chosen command
    behaves. The `exec` handler has been reported to cause zombie process bloat in
    some cases.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, let's take a quick look at the last type of probe, the startup probe.
  prefs: []
  type: TYPE_NORMAL
- en: Startup probes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Startup probes have been recently introduced in Kubernetes 1.16 to support cases
    when a container may require more time for initialization than `initialDelaySeconds
    + failureThreshold * periodSeconds` set in the readiness probe. In general, you
    should use the same handler configuration for startup probes that you would for
    readiness probes but use larger delays. If a container is not ready within `initialDelaySeconds
    + failureThreshold * periodSeconds` for a readiness probe, then the container
    will be killed and subject to the Pod's restart policy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our voting application does not need a dedicated startup probe, but an example
    definition in the Deployment manifest file could look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we will focus on assigning resource limits for Pods and
    how to configure autoscaling for our voting application.
  prefs: []
  type: TYPE_NORMAL
- en: Specifying resource limits and configuring autoscaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As a container orchestrator, Kubernetes comes out of the box with two important
    features that help to manage your cluster resources:'
  prefs: []
  type: TYPE_NORMAL
- en: Resource requests and limits for Pod containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HPA, which allows automatic scaling of your Deployments or StatefulSets based
    on CPU resource usage (stable support), memory resource usage (beta support),
    or custom metrics (also beta support)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's first take a look at specifying resource requests and limits.
  prefs: []
  type: TYPE_NORMAL
- en: Resource requests and limits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you create a Pod, it is possible to specify how much compute resources
    its containers require—we already performed a short exercise on assigning resources
    for the voting application in the last chapter. In general, compute resources
    are CPU and RAM memory—Kubernetes is also able to manage other resources, such
    as HugePages on Linux or ephemeral storage on the local node.
  prefs: []
  type: TYPE_NORMAL
- en: The Kubernetes resource model provides an additional distinction between two
    classes of resources: compressible and incompressible. In short, a compressible
    resource can be easily throttled, without severe consequences. A perfect example
    of such a resource is the CPU—if you need to throttle CPU usage for a given container,
    the container will operate normally, just slower. On the other end, we have incompressible
    resources that cannot be throttled without bad consequences—memory allocation
    is an example of such a resource.
  prefs: []
  type: TYPE_NORMAL
- en: There are two great design proposal documents that describe the Kubernetes resource
    model ([https://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/resources.md](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/resources.md))
    and resource quality of service ([https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/resource-qos.md](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/resource-qos.md)).
    We highly recommend reading them to fully understand the vision of Kubernetes
    resource management and which features are already implemented.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can specify two values for a Pod container regarding resource allocation:'
  prefs: []
  type: TYPE_NORMAL
- en: '`requests`: This specifies the guaranteed amount of a given resource provided
    by the system. You can also think of this the other way round—this is the amount
    of a given resource that the Pod container requires from the system to function
    properly. Pod scheduling is dependent on the `requests` value (not `limits`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`limits`: This specifies the maximum amount of a given resource provided by
    the system. If specified together with `requests`, this value must be greater
    than or equal to `requests`. Depending on whether the resource is compressible
    or incompressible, exceeding the limit has different consequences—compressible
    resources (CPU) will be throttled whereas incompressible resources (memory) can
    result in container kill.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using different values of `requests` and `limits` allows for resource overcommit,
    which is useful for efficiently handling short bursts of resource usage while
    allowing better resource utilization on average. If you do not specify limits
    at all, the container can consume as much of the resource on a node as it wants.
    This can be controlled by namespace resource quotas (introduced earlier in this
    chapter) and limit ranges—you can read more about these objects in the documentation
    at [https://kubernetes.io/docs/concepts/policy/limit-range/](https://kubernetes.io/docs/concepts/policy/limit-range/).
  prefs: []
  type: TYPE_NORMAL
- en: We covered the details of resource management support on Windows nodes in Kubernetes
    in [Chapter 4](118e3c89-786e-4718-ba67-6c38928e2a42.xhtml), *Kubernetes Concepts
    and Windows Support*. The important bit is that Windows currently lacks support
    for an out-of-memory killer (some support for memory limiting may be available
    with incoming Hyper-V containers features in Kubernetes). This means that exceeding
    the `limits` value set for memory for Windows containers will not result in any
    throttling or container restart. Here, the rule of thumb is to carefully manage
    scheduling using `requests` for memory and monitoring for any sudden memory paging.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we dive into the configuration details, we need to look at what are
    the units for measuring CPU resources and memory in Kubernetes. For CPU resources,
    the base unit is **Kubernetes CPU** (**KCU**) where `1`is equivalent to, for example,
    1 vCPU on Azure, 1 Core on GCP, or 1 hyperthreaded core on a bare-metal machine.
    Fractional values are allowed: `0.1` can be also specified as `100m` (milliCPUs).
    For memory, the base unit is a byte; you can, of course, specify standard unit
    prefixes such as `M`, `Mi`, `G`, or `Gi`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate how to use resource `limits` and `requests`, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Modify the `voting-application.yaml` Deployment manifest so that it does not
    specify any update `strategy` and has resource allocation set for CPU and memory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: For memory, we follow the current recommendations for Windows nodes—we only
    specify how much memory we would like to request. For the CPU to simulate resource
    exhaustion, we specify a large requested value that will consume all of the cluster
    CPU for Windows nodes. The reason for this is that two nodes with Azure VM type Standard_D2_v3
    have two vCPUs each and with five replicas running, we would need five vCPUs in
    total. The update `strategy` needs to be removed to avoid any deadlocks during
    the rollout.
  prefs: []
  type: TYPE_NORMAL
- en: Apply the manifest file using the `kubectl apply -f .\voting-application.yaml`
    command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, carefully observe the creation of new Pods in your Deployment. You will
    notice there are Pods that show the `Pending` status:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This is expected, as the `voting-application-frontend-54bbbbd655-phdhr` Pod
    cannot be scheduled to any node because there are no available CPU resources.
    To check what is the actual reason, describe the Pod and check `Events`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: As expected, the Pod cannot be scheduled due to insufficient CPU resources on
    all nodes that match the node selector. Let's fix the issue by lowering the `requests`
    and `limits` CPU values for the Pod container—modify the `voting-application.yaml`
    manifest file so that `requests` is set to `250m` and `limits` is set to `500m`
    for the CPU.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply the manifest file using the `kubectl apply -f .\voting-application.yaml` command
    and observe the successful Deployment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that you know how to allocate and manage resources for your containers,
    we can demonstrate how to use autoscaling for your application using the HPA.
  prefs: []
  type: TYPE_NORMAL
- en: HPA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The true power of Kubernetes comes with autoscaling implemented by the HPA,
    which is a dedicated controller backed by the `HorizontalPodAutoscaler` API object.
    At a high level, the goal of the HPA is to automatically scale the number of replicas
    in a Deployment or StatefulSet depending on the current CPU utilization or other custom
    metrics (including multiple metrics at once). The details of the algorithm that
    determines the target number of replicas based on metric values can be found at [https://kubernetes.io/docs/tasks/run-application/horizontal-Pod-autoscale/#algorithm-details](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#algorithm-details).
    HPAs are highly configurable and in this book, we will cover a standard scenario
    for when we would like to autoscale based on target CPU usage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our voting application exposes features that do not require much CPU, which
    means that it may be hard to trigger autoscaling on demand. To solve this, we
    will add a dedicated controller action that can simulate a constant CPU load with
    a given target percentage value. The source code for the `packtpubkubernetesonwindows/voting-application:1.2.0`
    Docker image for stress simulation can be found at [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/08_voting-application-hpa-src](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/08_voting-application-hpa-src).
    If you want to customize the application yourself, open your solution in Visual
    Studio 2019 and follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the `StressCpuWorker` class ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/Services/CpuStressWorker.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/Services/CpuStressWorker.cs)),
    which contains the main worker code for simulating CPU stress:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This code will start several threads, the number of which will be equal to the
    currently available processor count in the environment, and each logical processor
    will be then stressed for `this.targetCpuLoad` milliseconds by doing almost empty
    `while` loops. For the rest of the 100-millisecond "segment", the thread will
    be sleeping—this means that, on average, we should have all available CPUs loaded
    to `this.targetCpuLoad` percent. Of course, it depends on how many processors
    are allotted to the container—this number may vary depending on your `requests`
    and `limits` values; you can always check the Pod logs to see what number of logical
    processors were available for this Pod. Also, please note that even if there are
    two logical processors available to the container, it doesn't mean that the container
    will be able to fully utilize them; the load may be throttled depending on the `limits`
    value.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `HomeController` class ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/Controllers/HomeController.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/Controllers/HomeController.cs)),
    add a new controller action that will be available via the `/Home/StressCpu?value={targetPercent}`
    route. Please note that we allow this action to be performed via a GET request
    (instead of PUT) to make the interaction easy when using a web browser. Additionally,
    inject `IStressCpuWorker` into the constructor—the final action implementation
    will be as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This implementation will enable CPU stressing if you provide a positive value
    and for a negative value, stressing will be disabled.
  prefs: []
  type: TYPE_NORMAL
- en: 'Configure dependency injection in the `NinjectWebCommon` class ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/App_Start/NinjectWebCommon.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/App_Start/NinjectWebCommon.cs)).
    Ensure that the `StressCpuWorker` class is resolved as a singleton:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Build the Docker image with the tag `1.2.0` and push it to your repository,
    exactly as we did before.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'With the image ready, we can proceed with deploying a new version of the voting
    application and configure autoscaling. To do that, execute the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Modify the `voting-application.yaml` manifest file and ensure that you use
    the `1.2.0` tag of the image and that `resources` is specified as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: In a PowerShell window, apply the manifest file using the `kubectl apply -f
    .\voting-application.yaml` command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Wait for the Deployment to finish and observe the CPU usage by Pods using this
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: When the IIS App Pool is fully initialized, the CPU usage for each Pod should
    stabilize around `150m`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the `hpa.yaml` manifest file for the HPA:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This HPA will automatically scale the `voting-application-frontend` Deployment
    to between `1` and `8` replicas, trying to target `60` percent CPU usage. Please
    note that this target usage is high and in production environments, you should
    consider using lower, more appropriate values. This manifest file is roughly the
    same as for the HPA created imperatively using the `kubectl autoscale deployment/voting-application-frontend
    -n dev --cpu-percent=60 --min=1 --max=8` command.
  prefs: []
  type: TYPE_NORMAL
- en: Apply the manifest file using the `kubectl apply -f .\hpa.yaml` command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'HPAs are subject to delay for cooldown to avoid thrashing (that is, the replica
    count fluctuating frequently). The default delay is five minutes. This means that
    you should expect some delay until the HPA scales the Deployment after you apply
    it. Monitor the status of the HPA using the `kubectl describe` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Over time, you will notice that the HPA will tend to scale down to a single
    replica as there is not enough CPU load.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s increase the CPU load using our dedicated endpoint. In the web browser,
    go to the following URL: `http://<serviceExternalIp>/Home/StressCpu?value=90`.
    This will start stressing the CPU at a target level of 90%—bear in mind that,
    depending on how the logical processors are allocated for your Pods, the actual
    usage may be different.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can perform multiple requests to ensure that more Pods in the Deployment
    start stressing the CPU.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After a while, observe what happens in the HPA events:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The Deployment was automatically scaled up as the CPU resource utilization was
    above the 60% target! After more Pods are added, the average utilization will
    decrease because not all Pods are performing CPU stressing.
  prefs: []
  type: TYPE_NORMAL
- en: For AKS and an AKS Engine cluster, it is possible to leverage the cluster autoscaler
    to automatically adjust the number of nodes in your cluster depending on the resource
    demands. You can read more in the official Azure documentation ([https://docs.microsoft.com/en-us/azure/aks/cluster-autoscaler](https://docs.microsoft.com/en-us/azure/aks/cluster-autoscaler))
    and in the guide for configuring the cluster autoscaler on Azure ([https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/azure/README.md](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/azure/README.md)).
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations, you have successfully configured the HPA for the voting application.
    The next Kubernetes feature that we are going to demonstrate is using ConfigMaps
    and Secrets for injecting configuration data.
  prefs: []
  type: TYPE_NORMAL
- en: Managing application configuration using ConfigMaps and Secrets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To provide configuration for an application running on Kubernetes, there are
    a couple of possible approaches, documented in [https://kubernetes.io/docs/tasks/inject-data-application/](https://kubernetes.io/docs/tasks/inject-data-application/):'
  prefs: []
  type: TYPE_NORMAL
- en: Passing arguments to the container commands
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining system environment variables for the container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mounting ConfigMaps or Secrets as container volumes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optionally wrapping everything up using PodPresets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This section will focus on using ConfigMaps and Secrets, which are, in many
    aspects, similar but have very different purposes.
  prefs: []
  type: TYPE_NORMAL
- en: First, let's take a look at Secrets. In almost every application, you will have
    to manage sensitive information for accessing dependencies, such as passwords,
    OAuth tokens, or certificates. Putting such information in a Docker image as hardcoded
    values is out of the question due to obvious security concerns and very limited
    flexibility. Similarly, defining a password directly in the Pod manifest file
    is not recommended—manifest files are intended to be kept in source control and
    this definitely is not a place for storing such sensitive information. To manage
    this type of information, Kubernetes offers Secret objects, which can hold technically
    any type of data consisting of key-value pairs. Optionally, it is possible to
    encrypt Secrets at rest in `etcd`, which is recommended in production scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now demonstrate how to create a generic (opaque) Secret using `kubectl`.
    You can also use manifest files for this purpose but how you generate these manifest
    files depends on your CI/CD pipelines (you do not want to check in these manifest
    files to your source control!). To create a Secret for a SQL Server password,
    execute the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a PowerShell window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Assuming that you would like to create a Secret named `mssql` in the `dev`
    namespace, which holds `S3cur3P@ssw0rd` under the `SA_PASSWORD` key, execute the
    following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the Secret can be consumed as a volume mounted in the container (as a
    file or a directory) or used to define environment variables for a container.
    In the case of the voting application, it is easier to use the Secret with a SQL
    Server password as an environment variable. This is achieved in the following
    way in the Deployment manifest:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The key concept here is using `secretKeyRef` to reference a value for the `SA_PASSWORD`
    key from the `mssql` Secret that we have just created. The value is injected into
    the `MSSQL_SA_PASSWORD` environment variable (but you can check that it is not
    possible to see the value when using `kubectl describe`!), which can be accessed
    by the application running in the container. In our case, we use this variable
    to define another environment variable named `CONNECTIONSTRING_VotingApplication`.
    This is a common pattern when you need to create, for example, a connection string
    that has to include a password but please bear in mind that it may be a less secure
    solution than using volumes.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is one significant difference between consuming Secrets as environment
    variables and as mounted volumes: the Secret data provided via a volume will be updated
    if the Secret changes. Depending on your needs and implementation details, you
    may want to choose to mount Secrets as volumes. This, of course, requires your
    application to be aware of possible changes to the Secrets file, which means it
    needs to actively monitor the filesystem and refresh any credential providers,
    connection strings, or certificates, which are often kept in memory. Approaching
    Secrets as immutable configuration values is the best option (both when mounted
    as a volume and as environment variables) and makes your application more predictable
    and less complex. But if your architecture has limitations that prefer as few
    Pod restarts as possible, then injecting Secrets as a volume and implementing
    automatic refresh in your application is be the suggested solution.'
  prefs: []
  type: TYPE_NORMAL
- en: 'From a security perspective, injecting Secrets as environment variables is less
    secure on Linux as, when having root privileges, you can enumerate all environment
    variables for a process from `/proc/<pid>/environ`. On Windows nodes, the issue
    is even more complex: you can still access environment variables for processes
    but volumes cannot currently use the in-memory filesystem. This means that Secrets
    are then stored directly on the node''s disk storage.'
  prefs: []
  type: TYPE_NORMAL
- en: To store non-sensitive configuration data for your application, Kubernetes offers
    ConfigMap objects. This is another concept that you can use to fully decouple
    Docker images (your build artifacts) from the runtime configuration data. From
    an API perspective, the concept is similar to Secrets—you can store key-value
    pairs and inject them either as environment variables for the container or mount
    them using a volume as a file or a directory. To demonstrate this, we will create
    a ConfigMap for storing a configuration file, `customErrors.config`, referenced
    in the `Web.config` file for the ASP.NET MVC application and mount it using a
    volume.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned in [Chapter 4](118e3c89-786e-4718-ba67-6c38928e2a42.xhtml), *Kubernetes
    Concepts and Windows Support*, as of Kubernetes 1.17, there is no support for
    mounting a volume `subPath` as a file on Windows. This means that it is not possible
    to easily override the whole `Web.config` file for the ASP.NET MVC using ConfigMap.
  prefs: []
  type: TYPE_NORMAL
- en: 'Please follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to perform a small change to the voting application source code
    ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/10_voting-application-configmap-src](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/10_voting-application-configmap-src)).
    We will extract the `<customErrors>` node from the `<system.web>` node to a separate
    file in a subdirectory. In the `Web.config` file, change the `<system.web>` node
    to this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the `customErrors.config` file in the `config` directory with the following
    contents. We will override it using a ConfigMap in the next steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Build a Docker image with the `1.3.0` tag and publish it to Docker Hub, as in
    the previous examples.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create the `voting-application-customerrors-config.yaml` manifest file for
    a ConfigMap definition that has the following form and contains the file ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/10_voting-application-configmap-src/config/customErrors.config](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/10_voting-application-configmap-src/config/customErrors.config))
    as `data`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: It is possible to create ConfigMaps imperatively using `kubectl`, but we would
    like to demonstrate the structure of the ConfigMap manifest file. The important
    part is to keep proper indentation when using a YAML multiline string for bigger
    config files (`|`).
  prefs: []
  type: TYPE_NORMAL
- en: Apply the manifest file using the `kubectl apply -f .\voting-application-customerrors-config.yaml`
    command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Modify the `voting-application.yaml` manifest file for Deployment to mount
    our ConfigMap as a directory in the container (remember to use the new Docker
    image tag):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The important part here is to reference the `voting-application-customerrors-config`
    ConfigMap as a volume (`customerrors-config-volume`) and mount it to `C:\inetpub\wwwroot\config\`
    in the container. If `subPath` mounts were currently supported on Windows, we
    could override just a single file instead of the whole directory.
  prefs: []
  type: TYPE_NORMAL
- en: Apply the manifest file using the `kubectl apply -f .\voting-application.yaml`
    command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, navigate to the `http://<serviceExternalIp>/Home/StressCpu` address in
    your browser. This will trigger an exception—we did not provide the required request
    parameter in the URL. You should see a custom error page that just informs that `An
    error occurred while processing your request`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Turn off the custom errors page and modify the `voting-application-customerrors-config.yaml`
    manifest file for ConfigMap so that it contains the node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Apply the manifest file using the `kubectl apply -f .\voting-application-customerrors-config.yaml` command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Depending on whether IIS is able to watch for changes in the `C:\inetpub\wwwroot\config\`
    directory, the IIS App Pool may not be reloaded in the Pod. In such a case, `exec`
    into the container and execute the `Restart-WebAppPool DefaultAppPool` command.
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to `http://<serviceExternalIp>/Home/StressCpu` again. If your IIS App
    Pool has been reloaded, you will see full exception details instead of the custom
    error page.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this way, we have demonstrated how to use Secrets and ConfigMaps in Windows
    Pods. Now, it is time to familiarize ourselves with managing persistent data storage
    on Windows nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Managing persistent data storage on Windows nodes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [Chapter 4](118e3c89-786e-4718-ba67-6c38928e2a42.xhtml), *Kubernetes Concepts
    and Windows Support*, we have already covered some storage-related concepts in
    Kubernetes, such as **PersistentVolumes** (**PV**), **PersistentVolumeClaims**
    (**PVC**), and **StorageClasses** (**SC**), and how they are supported in Windows
    workloads. Managing state and storage in containerized applications and using
    StatefulSets is a broad and complex topic that is not in the scope of this book—the
    official documentation offers a good introduction, which can be found at [https://kubernetes.io/docs/concepts/storage/](https://kubernetes.io/docs/concepts/storage/).
    The key takeaway for PersistentVolume support for Windows Pods is that you can
    use some of the existing volume plugins but not all. On Windows, there is support
    for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In-tree volume plugins: azureDisk, azureFile, gcePersistentDisk, awsElasticBlockStore
    (since 1.16), and vsphereVolume (since 1.16)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'FlexVolume plugins: SMB and iSCSI'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CSI volume plugins (out-of-tree plugins)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This means that, for Windows nodes, in the case of AKS or AKS Engine clusters,
    you are limited to using the azureDisk and azureFile in-tree volume plugins and
    technically, you can combine the FlexVolume SMB plugin with Azure Files SMB Share.
    For on-premises scenarios, you have to rely on the FlexVolume SMB or iSCSI plugins
    configured to use your own storage or connect to SMB shares exposed as external
    cloud services. If you are running on vSphere, you can, of course, leverage the
    vsphereVolume plugin. In general, handling PersistentVolumes for hybrid Windows/Linux
    clusters running on-premises is still hard.
  prefs: []
  type: TYPE_NORMAL
- en: For on-premises clusters, using Rook ([https://rook.io/](https://rook.io/))
    to orchestrate storage and integrate with Kubernetes is a good solution. Unfortunately,
    there is no support for Windows yet, even for consuming the volumes.
  prefs: []
  type: TYPE_NORMAL
- en: Our voting application is already using PersistentVolumes for SQL Server running
    in a Linux Pod—in this case, we have been using StorageClass with the `kubernetes.io/azure-disk`
    provisioner, which internally uses the azureDisk volume plugin. This scenario
    concerned Linux Pods—now, we will use PersistentVolumes for Windows Pods. The
    voting application does not have any particular need for persisting data in frontend
    containers but as a pure example, we will show how to store a voting log for each
    Pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'The source code for this change is available at [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/12_voting-application-persistentvolume-src](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/12_voting-application-persistentvolume-src).
    We will not go into implementation details but the change is simple:'
  prefs: []
  type: TYPE_NORMAL
- en: Add a new `VoteLogManager` class ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/12_voting-application-persistentvolume-src/Services/VoteLogManager.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/12_voting-application-persistentvolume-src/Services/VoteLogManager.cs)),
    which manages the `C:\data\voting.log` file—you can add new votes to the log and
    read the log contents. This log file will be persisted using Kubernetes PersistentVolume.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For each vote that is added in the `SurveyController` class ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/12_voting-application-persistentvolume-src/Controllers/SurveysController.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/12_voting-application-persistentvolume-src/Controllers/SurveysController.cs)),
    inform `VoteLogManager`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the `HomeController` class ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/12_voting-application-persistentvolume-src/Controllers/HomeController.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/12_voting-application-persistentvolume-src/Controllers/HomeController.cs)),
    add a new controller action, `VotingLog`, which returns the contents of the voting
    log. Then, you can access the voting log for the currently serving replica using
    `http://<serviceExternalIp>/Home/VotingLog`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To deploy the application, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Build a Docker image with the tag `1.4.0` for the voting application and push
    it to Docker Hub as in previous examples.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We need to convert our Deployment into a StatefulSet. Therefore, you first
    need to delete the Deployment from the cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the `StorageClass` manifest, `sc.yaml`, with the following contents.
    We will use the `kubernetes.io/azure-disk` provisioner to use the azureDisk Volume
    plugin:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Apply the manifest file using the `kubectl apply -f sc.yaml` command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Convert the Deployment into a StatefulSet and use the `1.4.0` version of the
    Docker image. The full manifest file can be found at [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/13_persistentvolume/voting-application.yaml](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/13_persistentvolume/voting-application.yaml).
    We highlight the changes that are needed compared to the previous `voting-application.yaml`
    manifest file as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: StatefulSet requires providing a Service name that is responsible for this StatefulSet
    (`1`). On top of that, we define `volumeClaimTemplates` (`4`), which will be used
    for creating a dedicated PersistentVolumeClaim for each Pod replica in this StatefulSet.
    We reference this PVC for mounting the volume as the `C:/data` directory in the
    container (`3`), where `voting.log` will be persisted. Additionally, we also need
    to give proper read/write permissions to the `C:/data` directory to the IIS App
    Pool user—otherwise, the web application will not be able to access our PersistentVolume.
    This is achieved using `icasls.exe` executed in an `init` container (`2`). Note
    that you need to first start IIS (`iisreset.exe /START`) to have the IIS App Pool
    user properly created before assigning the permission!
  prefs: []
  type: TYPE_NORMAL
- en: Apply the manifest file using the `kubectl apply -f .\voting-application.yaml`
    command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When the StatefulSet is ready, navigate to the application in the web browser
    and vote a few times.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open `http://<serviceExternalIp>/Home/VotingLog` in a web browser and, depending
    on which Pod replica you have reached, you will see different results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/a40d5661-8380-427f-88ca-7e156f2419d7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Good, so now we know that writing to the directory in a container works as
    expected. But let''s prove that this directory is indeed backed by a PersistentVolume
    mount. To do that, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Scale down `statefulset` to `0` replicas. This will remove all of the Pods
    for the StatefulSet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Wait until all Pods are terminated, and observe using the `kubectl get pods
    -n dev` command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Scale up `statefulset`, for example, to `5` replicas:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Wait for the Pods to create and become ready. It may take a few minutes due
    to our readiness probes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to `http://<serviceExternalIp>/Home/VotingLog` in your web browser.
    You should see exactly the same voting log for each Pod replica as before. This
    shows that all Pods have the same PersistentVolumes mounted as previously.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Congratulations! You have successfully mounted azureDisk PersistentVolumes in
    a Windows Pod for the voting application. Next, we will take a look at how you
    can configure rolling updates for your application.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring rolling updates for Deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In production scenarios, you will definitely need a deployment strategy that
    provides zero downtime updates for your application. As a container orchestrator,
    Kubernetes comes with different building blocks that can be used for implementing
    blue-green Deployments, canary Deployments, or rolling Deployments. A Kubernetes
    Deployment object has full support for performing a rolling update Deployment—in
    this type of Deployment, the new version of the application is rolled out by gradually
    swapping old replicas with new replicas, all of which are behind the same Service.
    This means that, during the rollout, the end user will reach either the old or
    new version of the application.
  prefs: []
  type: TYPE_NORMAL
- en: To ensure real zero downtime updates of your Deployments in Kubernetes, you
    need to configure proper probes, especially readiness. In this way, the user will
    be redirected to a replica only if this replica can properly respond to the request.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how you can implement rolling deployment for the voting application.
    In fact, we have already been using this approach in the previous examples and
    now we will explain the configuration in more detail. Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Delete the StatefulSet, which we created in the previous section, using the `kubectl
    delete statefulset -n dev voting-application-frontend` command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let's revert back to the `voting-application.yaml` Deployment manifest file
    that we used for the HPA demonstration. You can find the file in the GitHub repository
    at [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/14_rollingupdate/voting-application.yaml](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/14_rollingupdate/voting-application.yaml).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The rolling update deployment is configured in the following way:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The key part for defining rolling update deployment for your Deployment object
    is `strategy`. To configure the rolling update, you need to use `type` with the
    `RollingUpdate` value (which is also the default value). The alternative is using
    recreate, which will simply kill all Pods before creating new Pods—generally,
    you do not want to use this strategy type in production unless it is combined
    with more complex patterns such as blue-green deployments. For the `RollingUpdate`
    type, you can define `maxUnavailable`, which says how many Pods can be in a non-ready
    state during the update. Similarly, `maxSurge` defines the maximum number of Pods
    that can be created over the desired number of Pods during the deployment. You
    can specify these values as a number or percentage—by default, they are both set
    to 25%. To better understand what these numbers mean in practice, let''s analyze
    our example. With the desired number of replicas being `5`, when you trigger the
    Deployment rollout, the following sequence of events may happen:'
  prefs: []
  type: TYPE_NORMAL
- en: A new Pod is created. Now, we have six Pods in total, so we have reached the
    limit set by `maxSurge`.
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: '`maxUnavailable` is set to `1`, and we have five Pods ready, so one old Pod
    can be terminated. We have five Pods in total, with four ready.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A new Pod is created. We again have six Pods in total but four ready. The rollout
    has to wait until more Pods become ready.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One of the new Pods becomes ready. We have six Pods in total, five ready, which
    means that one old Pod can be terminated and then a new Pod is created.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This process gradually continues until all five new Pods become ready.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's see how it works in practice. First, apply the manifest file using the `kubectl
    apply -f .\voting-application.yaml` command—this will create the initial version
    of the application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Rollouts for existing Deployments can be done imperatively by live-editing
    the object or using the `kubectl rollout` command. In general, it is better to
    use the declarative approach: change the manifest file and apply it again. Change
    the container image tag to `packtpubkubernetesonwindows/voting-application:1.4.0`
    in the manifest file and apply using the `kubectl apply -f .\voting-application.yaml` command.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Quickly after that, start observing `rollout status` using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: During the rollout, you can use commands such as `kubectl rollout undo -n dev
    deployment/voting-application-frontend` or `kubectl rollout pause -n dev deployment/voting-application-frontend`
    to control the Deployment rollout. However, you can still achieve the same just
    by modifying the manifest file and applying it again—this even includes pausing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can try accessing the application during the rollout. We have properly configured
    the readiness probes so you will not experience any unexpected responses from
    the application!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: StatefulSets also have a customizable strategy for rollouts. Due to state persistence,
    the strategy is a bit different from Deployments. You can read more in the official
    documentation, at [https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s focus on another important topic in Kubernetes: **Role-Based Access
    Control** (**RBAC**).'
  prefs: []
  type: TYPE_NORMAL
- en: Role-Based Access Control
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes comes with a built-in RBAC mechanism that allows you to configure
    fine-grained sets of permissions and assign them to users, groups, and service
    accounts (subjects). In this way, as a cluster administrator, you can control
    how cluster users (internal and external) interact with the API Server, which
    API resources they can access, and which actions (verbs) they can perform.
  prefs: []
  type: TYPE_NORMAL
- en: Authentication in Kubernetes is highly configurable and extensible; you can
    read more in the official documentation, at [https://kubernetes.io/docs/reference/access-authn-authz/authentication/](https://kubernetes.io/docs/reference/access-authn-authz/authentication/).
    In AKS Engine clusters, it is possible to easily integrate with **Azure Active
    Directory** (**AAD**); you can find more details at [https://github.com/Azure/aks-engine/blob/master/docs/topics/aad.md](https://github.com/Azure/aks-engine/blob/master/docs/topics/aad.md)[.](https://github.com/Azure/aks-engine/blob/master/docs/topics/aad.md)
  prefs: []
  type: TYPE_NORMAL
- en: 'Using RBAC involves two groups of API resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Role` and `ClusterRole`: They define a set of permissions. Each rule in `Role`
    says which verb(s) are allowed for which API resource(s). The only difference
    between `Role` and `ClusterRole` is that `Role` is namespace-scoped whereas `ClusterRole`
    is not.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RoleBinding` and `ClusterRoleBinding`: They associate users or a set of users
    with a given role. Similarly, `RoleBinding` is namespace-scoped, `ClusterRoleBinding`
    is cluster-wide. `ClusterRoleBinding` works with `ClusterRole`, and `RoleBinding` works
    with either `ClusterRole` or `Role`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kubernetes uses a permissive RBAC model—there are no deny rules; everything
    is denied by default, and you have to define allow rules. Using RBAC is well documented
    and all of the features have been presented in the official documentation, available
    at [https://kubernetes.io/docs/reference/access-authn-authz/rbac/](https://kubernetes.io/docs/reference/access-authn-authz/rbac/).
    There are two key points you should consider for your RBAC strategy:'
  prefs: []
  type: TYPE_NORMAL
- en: Use the principle of least privilege. Your applications should have access to
    their own resources only (it is recommended that you run each application using
    a dedicated service account that has access to Secrets or ConfigMaps for the very
    application). Users should have restricted access depending on their role in the
    project (for example, a QA engineer may be fine with just read-only access to
    the cluster).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assign `RoleBinding` to groups instead of individual users. This will make your
    permission management much easier. Note that this requires integrating with external
    authentication providers to function best.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s demonstrate how to use `Role` and `RoleBinding` for the voting application
    to restrict access to the Deployment to a minimum set of ConfigMaps and Secrets
    that are needed. We will do that for the ASP.NET MVC application, and using a
    similar approach for SQL Server can be an additional exercise. For this, we will
    use the voting application Docker image, `packtpubkubernetesonwindows/voting-application:1.3.0`,
    which we used for demonstrating ConfigMaps. This Deployment requires both ConfigMaps
    and Secrets at runtime. Please follow these steps to configure RBAC:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the `serviceaccount.yaml` manifest file for the dedicated ServiceAccount,
    named `voting-application`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Apply the manifest file using the `kubectl apply -f .\serviceaccount.yaml` command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create the `role.yaml` manifest file for `Role` for reading Secrets and ConfigMaps
    for the application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Use the `kubectl auth reconcile -f .\role.yaml` command to apply `Role`. Using
    `kubectl auth reconcile` is recommended over `kubectl apply`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create the `rolebinding.yaml` manifest file for `RoleBinding`, which associates
    our ServiceAccount with the preceding role:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Use the `kubectl auth reconcile -f .\rolebinding.yaml` command to apply `RoleBinding`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check whether RBAC allows access to the ConfigMap for the ServiceAccount. You
    can use the `kubectl auth can-i get configmap/voting-application-customerrors-config
    -n dev --as system:serviceaccount:dev:voting-application` command or visualize
    all accessible API resources using the `kubectl auth can-i --list -n dev --as
    system:serviceaccount:dev:voting-application` command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Modify the `voting-application.yaml` manifest file so that the Deployment uses
    the `voting-application` ServiceAccount:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Apply the Deployment manifest file using the `kubectl apply -f .\voting-application.yaml`
    command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can perform a similar operation for users in your cluster, for example,
    by defining Roles that allow read-only access to all API resources.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You have successfully set up RBAC for the voting application.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we demonstrated several commonly used, advanced features of
    Kubernetes. First, you learned what the purpose of namespaces in Kubernetes is
    and how to manage them. Then, we introduced readiness, liveness, and startup probes,
    which are used for monitoring the life cycle of Pod containers—and we provided
    you with a set of recommended practices when working with probes and how to avoid
    common pitfalls. The next step was learning how to specify Pod resource requests
    and limits and how to combine this with autoscaling using the HPA. To inject configuration
    data (including sensitive passwords) into our application, we used ConfigMaps
    and Secrets. On top of that, we have demonstrated how to use PersistentVolumes
    (backed by the azureDisk Volume plugin) in StatefulSets running on Windows nodes.
    And lastly, you learned how to approach rolling updates for Deployment objects
    and what the purpose of RBAC in Kubernetes is.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will focus on development workflows with Kubernetes and how
    you can cooperate with other developers when creating Kubernetes applications.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When should you consider using Kubernetes namespaces?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between readiness and liveness probes?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the risks of using a liveness probe with inappropriate configuration?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between resource `requests` and `limits` values for Pod
    containers?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the purpose of delay for cooldown in the HPA?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between ConfigMaps and Secrets?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is `volumeClaimTemplates` in StatefulSet spec?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why should you ensure the proper configuration of readiness probes when using
    rolling updates for Deployments?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the most important rules of thumb when using RBAC in Kubernetes?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can find answers to these questions in the *Assessment* of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information about Kubernetes features and how to manage applications,
    please refer to the following Packt books:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*The Complete Kubernetes Guide* by Jonathan Baier, Gigi Sayfan, Et al ([https://www.packtpub.com/virtualization-and-cloud/complete-kubernetes-guide](https://www.packtpub.com/virtualization-and-cloud/complete-kubernetes-guide)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Getting Started with Kubernetes - Third Edition* by Jonathan Baier, Jesse
    White ([https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition](https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Kubernetes for Developers* by Joseph Heck ([https://www.packtpub.com/virtualization-and-cloud/kubernetes-developers](https://www.packtpub.com/virtualization-and-cloud/kubernetes-developers)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
