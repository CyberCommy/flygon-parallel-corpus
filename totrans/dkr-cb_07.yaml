- en: Chapter 7. Docker Performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Benchmarking CPU performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Benchmarking disk performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Benchmarking network performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting container resource usage using the stats feature
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up performance monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 3](part0038.xhtml#aid-147LC1 "Chapter 3. Working with Docker Images"),
    *Working with Docker Images*, we saw, how Dockerfiles can be used to create images
    consisting of different services/software and later in [Chapter 4](part0055.xhtml#aid-1KEEU2
    "Chapter 4. Network and Data Management for Containers"), *Network and Data Management
    for Containers*, we saw, how one Docker container can talk to the outside world
    with respect to data and network. In [Chapter 5](part0062.xhtml#aid-1R42S1 "Chapter 5. Docker
    Use Cases"), *Docker Use Cases*, we looked into the different use cases of Docker,
    and in [Chapter 6](part0069.xhtml#aid-21PMQ1 "Chapter 6. Docker APIs and Language
    Bindings"), *Docker APIs and Language Bindings*, we looked at how to use remote
    APIs to connect to a remote Docker host.
  prefs: []
  type: TYPE_NORMAL
- en: 'Ease of use is all good, but before going into production, performance is one
    of the key aspects that is considered. In this chapter, we''ll see the performance
    impacting features of Docker and what approach we can follow to benchmark different
    subsystems. While doing performance evaluation, we need to compare Docker performance
    against the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Bare metal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Virtual machine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker running inside a virtual machine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the chapter, we will look at the approach you can follow to do performance
    evaluation rather than performance numbers collected from runs to do comparison.
    However, I'll point out performance comparisons done by different companies, which
    you can refer to.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s first look at some of the Docker performance impacting features:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Volumes**: While putting down any enterprise class workload, you would like
    to tune the underlying storage accordingly. You should not use the primary/root
    filesystem used by containers to store data. Docker provides the facility to attach/mount
    external storage through volumes. As we have seen in [Chapter 4](part0055.xhtml#aid-1KEEU2
    "Chapter 4. Network and Data Management for Containers"), *Network and Data Management
    for Containers*, there are two types of volumes, which are as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Volumes that are mounted through host machines using the `--volume` option
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Volumes that are mounted through another container using the `--volumes-from`
    option
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Storage drivers**: We looked at different storage drivers in [Chapter 1](part0015.xhtml#aid-E9OE2
    "Chapter 1. Introduction and Installation"), *Installation and Introduction*,
    which are vfs, aufs, btrfs, devicemapper, and overlayFS. Support for ZFS has been
    merged recently as well. You can check the currently supported storage drivers
    and their priority of selection if nothing is chosen as the Docker start time
    at [https://github.com/docker/docker/blob/master/daemon/graphdriver/driver.go](https://github.com/docker/docker/blob/master/daemon/graphdriver/driver.go).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are running Fedora, CentOS, or RHEL, then the device mapper will be the
    default storage driver. You can find some device mapper specific tuning at [https://github.com/docker/docker/tree/master/daemon/graphdriver/devmapper](https://github.com/docker/docker/tree/master/daemon/graphdriver/devmapper).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can change the default storage driver with the `-s` option to the Docker
    daemon. You can update the distribution-specific configuration/systems file to
    make changes across service restart. For Fedora/RHEL/CentOS, you will have the
    update `OPTIONS` field in `/etc/sysconfig/docker`. Something like the following
    to use the `btrfs` backend:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The following graph shows you how much time it takes to start and stop 1,000
    containers with different configurations of storage driver:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Introduction](../Images/image00375.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '[http://developerblog.redhat.com/2014/09/30/overview-storage-scalability-docker/](http://developerblog.redhat.com/2014/09/30/overview-storage-scalability-docker/)'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, overlayFS performs better than other storage drivers.
  prefs: []
  type: TYPE_NORMAL
- en: '**--net=host**: As we know, by default, Docker creates a bridge and associates
    IPs from it to the containers. Using `--net=host` exposes host networking stack
    to the container by skipping the creation of a network namespace for the container.
    From this, it is clear that this option always gives better performance compared
    to the bridged one.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This has some limitations, such as not being able to have two containers or
    host apps listening on the same port.
  prefs: []
  type: TYPE_NORMAL
- en: '**Cgroups**: Docker''s default execution driver, `libcontainer`, exposes different
    Cgroups knobs, which can be used to fine tune container performance. Some of them
    are as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CPU shares**: With this, we can give proportional weight to the containers
    and accordingly the resource will be shared. Consider the following example:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**CPUsets**: This allows you to create CPU masks, using which execution of
    threads inside a container on host CPUs is controlled. For example, the following
    code will run threads inside a container on the 0th and 3rd core:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Memory limits**: We can set memory limits to a container. For example, the
    following command will limit the memory usage to 512 MB for the container:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '**Sysctl and ulimit settings**: In a few cases, you might have to change some
    of the `sysclt` values depending on the use case to get optimal performance, such
    as changing the number of open files. With Docker 1.6 ([https://docs.docker.com/v1.6/release-notes/](https://docs.docker.com/v1.6/release-notes/))
    and above we can change the `ulimit` settings with the following command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command will change the settings for just that given container,
    it is a per container tuning variable. We can also set some of these settings
    through the systemd configuration file of Docker daemon, which will be applicable
    to all containers by default. For example, looking at the systemd configuration
    file for Docker on Fedora, you will see something like the following in the service
    section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: You can update this as per your need.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can learn about Docker performance by studying the work done by others.
    Over the last year, some Docker performance-related studies have been published
    by a few companies:'
  prefs: []
  type: TYPE_NORMAL
- en: 'From Red Hat:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Performance Analysis of Docker on Red Hat Enterprise Linux:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[http://developerblog.redhat.com/2014/08/19/performance-analysis-docker-red-hat-enterprise-linux-7/](http://developerblog.redhat.com/2014/08/19/performance-analysis-docker-red-hat-enterprise-linux-7/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/jeremyeder/docker-performance](https://github.com/jeremyeder/docker-performance)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Comprehensive Overview of Storage Scalability in Docker:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[http://developerblog.redhat.com/2014/09/30/overview-storage-scalability-docker/](http://developerblog.redhat.com/2014/09/30/overview-storage-scalability-docker/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Beyond Microbenchmarks—breakthrough container performance with Tesla efficiency:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[http://developerblog.redhat.com/2014/10/21/beyond-microbenchmarks-breakthrough-container-performance-with-tesla-efficiency/](http://developerblog.redhat.com/2014/10/21/beyond-microbenchmarks-breakthrough-container-performance-with-tesla-efficiency/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Containerizing Databases with Red Hat Enterprise Linux:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[http://rhelblog.redhat.com/2014/10/29/containerizing-databases-with-red-hat-enterprise-linux/](http://rhelblog.redhat.com/2014/10/29/containerizing-databases-with-red-hat-enterprise-linux/)'
  prefs: []
  type: TYPE_NORMAL
- en: From IBM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An Updated Performance Comparison of Virtual Machines and Linux Containers:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[http://domino.research.ibm.com/library/cyberdig.nsf/papers/0929052195DD819C85257D2300681E7B/$File/rc25482.pdf](http://domino.research.ibm.com/library/cyberdig.nsf/papers/0929052195DD819C85257D2300681E7B/%24File/rc25482.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/thewmf/kvm-docker-comparison](https://github.com/thewmf/kvm-docker-comparison)'
  prefs: []
  type: TYPE_NORMAL
- en: From VMware
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Containers Performance in VMware vSphere
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[http://blogs.vmware.com/performance/2014/10/docker-containers-performance-vmware-vsphere.html](http://blogs.vmware.com/performance/2014/10/docker-containers-performance-vmware-vsphere.html)'
  prefs: []
  type: TYPE_NORMAL
- en: To do the benchmarking, we need to run similar workload on different environments
    (bare metal/VM/Docker) and then collect the results with the help of different
    performance stats. To simplify things, we can write common benchmark scripts which
    can be used to run on different environments. We can also create Dockerfiles to
    spin off containers with workload generation scripts. For example, in the *Performance
    Analysis of Docker on Red Hat Enterprise Linux* article, which is listed earlier
    ([https://github.com/jeremyeder/docker-performance/blob/master/Dockerfiles/Dockerfile](https://github.com/jeremyeder/docker-performance/blob/master/Dockerfiles/Dockerfile)),
    the author has used a Dockerfile to create a CentOS image and used the `container`
    environment variable to select Docker and non-Docker environment for benchmark
    script `run-sysbench.sh`.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, Dockerfiles and related scripts are published by IBM for their study
    available at [https://github.com/thewmf/kvm-docker-comparison](https://github.com/thewmf/kvm-docker-comparison).
  prefs: []
  type: TYPE_NORMAL
- en: We will be using some of the Docker files and scripts mentioned earlier in the
    recipes of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Benchmarking CPU performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can use benchmarks such as Linpack ([http://www.netlib.org/linpack/](http://www.netlib.org/linpack/))
    and sysbench ([https://github.com/nuodb/sysbench](https://github.com/nuodb/sysbench))
    to benchmark CPU performance. For this recipe, we'll use sysbench. We'll see how
    to run the benchmark on bare metal and inside the container. Similar steps can
    be performed in other environments, as mentioned earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will use the CentOS 7 container to run the benchmark inside the container.
    Ideally, we should have a system with CentOS 7 installed to get benchmark results
    on bare metal. For the container test, let''s build the image from the GitHub
    repository that we referred to earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Inside the same GitHub repository, we have a script to run sysbench, `docker-performance/bench/sysbench/run-sysbench.sh`.
    It has some configurations, which you can modify according to your needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the root user, create the `/results` directory on the host:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, run the benchmark after setting the container environment variable to
    something other than Docker, which we used while building the `c7perf` image on
    the host machine, run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: By default, the results are collected in `/results`. Make sure you have write
    access to it or change the `OUTDIR` parameter in the benchmark script.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run the benchmark inside the container, we need to first start the container
    and then run the benchmark script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: As we mounted the host directory, `/results_container`,inside the `/results`
    container`,` the result will be collected on the host.
  prefs: []
  type: TYPE_NORMAL
- en: 'While running the preceding test on Fedora/RHEL/CentOS, where SELinux is enabled,
    you will get a `Permission denied` error. To fix it, relabel the host directory
    while mounting it inside the container as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, for the time being, put SELinux in permissive mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, after the test, put it back in permissive mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Refer to [Chapter 9](part0092.xhtml#aid-2NNJO2 "Chapter 9. Docker Security"),
    *Docker Security*, for more details about SELinux.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The benchmark script internally calls sysbench's CPU benchmark for the given
    input. CPU is benchmarked by using the 64-bit integer manipulation using Euklid
    algorithms for prime number computation. The result for each run gets collected
    in the corresponding results directory, which can be used for comparison.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Almost no difference is reported in bare metal and Docker CPU performance.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Look at the CPU benchmark results published in IBM and VMware using Linpack
    in the links referenced earlier in this chapter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Benchmarking disk performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are tools such as Iozone ([http://www.iozone.org/](http://www.iozone.org/)),
    smallfile ([https://github.com/bengland2/smallfile](https://github.com/bengland2/smallfile)),
    and Flexible IO ([https://github.com/axboe/fio](https://github.com/axboe/fio))
    available to benchmark disk performance. For this recipe, we will use FIO. For
    that, we need to write a job file, which mimics the workload you want to run.
    Using this job file, we can simulate the workload on the target. For this recipe,
    let's take the FIO example from the benchmark results, which IBM has published
    ([https://github.com/thewmf/kvm-docker-comparison/tree/master/fio](https://github.com/thewmf/kvm-docker-comparison/tree/master/fio)).
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the bare metal / VM / Docker container, install FIO and mount the disk containing
    a filesystem for each test under `/ferrari` or anything which is mentioned in
    the FIO job file. On bare metal, you can mount natively and on VM it can be mounted
    using the virtual disk driver or we can do device pass through. On Docker, we
    can attach the filesystem from the host machine using Docker volumes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Prepare the workload file. We can pick [https://github.com/thewmf/kvm-docker-comparison/blob/master/fio/mixed.fio](https://github.com/thewmf/kvm-docker-comparison/blob/master/fio/mixed.fio):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Using the preceding job file, we can do random direct I/O on `/ferrari/fio-test-file`
    with 4K block size using the `libaio` driver on a 16 GB file. The I/O depth is
    32 and the number of parallel jobs is 8\. It is a mix workload, which does 70
    percent read and 30 percent write.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For the bare metal and VM tests, you can just run the FIO job file and collect
    the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'For the Docker test, you can prepare a Docker file as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, create an image using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Start the container as follows to run the benchmark and collect the results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'While running the preceding test on Fedora/RHEL/CentOS, where SELinux is enabled,
    you will get the `Permission denied` error. To fix it, re-label the host directory
    while mounting it inside the container as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: FIO will run the workload given in the job file and spit out the results.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once the results are collected, you can do the result comparison. You can even
    try out different kinds of I/O patterns using the job file and get the desired
    result.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Look at the disk benchmark results published in IBM and VMware using FIO in
    the links referenced earlier in this chapter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Benchmarking network performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Network is one of the key aspects to consider while deploying the applications
    in the container environment. To do performance comparison with bare metal, VM
    and containers, we have to consider different scenarios as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Bare metal to bare metal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VM to VM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker container to container with the default networking mode (bridge)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker container to container with host net (`--net=host`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker container running inside VM with the external world
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In any of the preceding cases, we can pick up two endpoints to do the benchmarking.
    We can use tools such as `nuttcp` ([http://www.nuttcp.net/](http://www.nuttcp.net/))
    and `netperf` ([http://netperf.org/netperf/](http://netperf.org/netperf/)) to
    measure the network bandwidth and request/response, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Make sure both the endpoints can reach each other and have the necessary packages/software
    installed. On Fedora 21, you can install `nuttcp` with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: And, get `netperf` from its website.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To measure the network bandwidth using `nuttcp`, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start the `nuttcp` server on one endpoint:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Measure the transmit throughput (client to server) from the client with the
    following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Measure the receiver throughput on the client (server to client) with the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'To run the request/response benchmark using `netperf`, perform the following
    steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Start `netserver` on one endpoint:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Connect to the server from the other endpoint and run the request/response
    test:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For TCP:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'For UDP:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In both the cases mentioned earlier, one endpoint becomes the client and sends
    the requests to the server on the other endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can collect the benchmark results for different scenarios and compare them.
    `netperf` can also be used for throughput tests.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Look at the network benchmark results published by IBM and VMware in the links
    referenced earlier in this chapter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting container resource usage using the stats feature
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the release of version 1.5, Docker added a feature to get container resource
    usage from in-built commands.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A Docker host with version 1.5 or later installed, which can be accessed via
    the Docker client. Also, start a few containers to get stats.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Run the following command to get stats from one or more containers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'For example, if we have two containers with the names `some-mysql` and `backstabbing_turing`,
    then run the following command to get the stats:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '![How to do it…](../Images/image00376.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Docker daemon fetches the resource information from the Cgroups and serves
    it through the APIs.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Refer to the release notes of Docker 1.5 at [https://docs.docker.com/v1.5/release-notes/](https://docs.docker.com/v1.5/release-notes/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up performance monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have tools such as SNMP, Nagios, and so on to monitor bare metal and VM performance.
    Similarly, there are a few tools/plugins available to monitor container performance
    such as cAdvisor ([https://github.com/google/cadvisor](https://github.com/google/cadvisor))
    and sFlow ([http://blog.sflow.com/2014/06/docker-performance-monitoring.html](http://blog.sflow.com/2014/06/docker-performance-monitoring.html)).
    In this recipe, let's see how we can configure cAdvisor.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Setting up cAdvisor.
  prefs: []
  type: TYPE_NORMAL
- en: 'The easiest way to run cAdvisor is to run its Docker container, which can be
    done with the following command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: If you want to run cAdvisor outside Docker, then follow the instructions given
    on the cAdvisor home page at [https://github.com/google/cadvisor/blob/master/docs/running.md#standalone](https://github.com/google/cadvisor/blob/master/docs/running.md#standalone)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After the container starts, point your browser to `http://localhost:8080`. You
    will first get the graphs for CPU, memory usage and other information for the
    host machine. Then, by clicking on the Docker Containers link, you will get the
    URLs for the containers running on the machine under the **Subcontainers** section.
    If you click on any one of them, you will see the resource usage information for
    the corresponding container.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the screenshot of one such container:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](../Images/image00377.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the `docker run` command, we have mounted few volumes from host machines
    in read-only mode. cAdvisor will read the relevant information from those like
    the Cgroup details for containers and show them graphically.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: cAdvisor supports exporting the performance matrices to influxdb ([http://influxdb.com/](http://influxdb.com/)).
    Heapster ([https://github.com/GoogleCloudPlatform/heapster](https://github.com/GoogleCloudPlatform/heapster))
    is another project from Google, which allows cluster-wide (Kubernetes) monitoring
    using cAdvisor.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can look at the matrices used by cAdvisor from Cgroups in the documentation
    on the Docker website [https://docs.docker.com/articles/runmetrics/](https://docs.docker.com/articles/runmetrics/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
