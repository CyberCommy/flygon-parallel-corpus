- en: 2\. An Overview of Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Overview
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will have our first hands-on introduction to Kubernetes.
    This chapter will give you a brief overview of the different components of Kubernetes
    and how they work together. We will also try our hand at working with some fundamental
    Kubernetes components.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have a single-node Minikube environment
    set up where you can run many of the exercises and activities in this book. You
    will be able to understand the high-level architecture of Kubernetes and identify
    the roles of the different components. You will also learn the basics required
    to migrate containerized applications to a Kubernetes environment.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We ended the previous chapter by providing a brief and abstract introduction
    to Kubernetes, as well as some of its advantages. In this chapter, we will provide
    you with a much more concrete high-level understanding of how Kubernetes works.
    First, we will walk you through how to install Minikube, which is a handy tool
    that creates a single-node cluster and provides a convenient learning environment
    for Kubernetes. Then, we will take a 10,000-foot overview of all the components,
    including their responsibilities and how they interact with each other. After
    that, we will migrate the Docker application that we built in the previous chapter
    to Kubernetes and illustrate how it can enjoy the benefits afforded by Kubernetes,
    such as creating multiple replicas, and version updates. Finally, we will explain
    how the application responds to external and internal traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Having an overview of Kubernetes is important before we dive deeper into the
    different aspects of it so that when we learn more specifics about the different
    aspects, you will have an idea of where they fit in the big picture. Also, when
    we go even further and explore how to use Kubernetes to deploy applications in
    a production environment, you will have an idea of how everything is taken care
    of in the background. This will also help you with optimization and troubleshooting.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Had you asked the question, "*How do you easily install Kubernetes?*" three
    years ago, it would have been hard to give a compelling answer. Embarrassing,
    but true. Kubernetes is a sophisticated system, and getting it installed and managing
    it well isn't an easy task.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, as the Kubernetes community has expanded and matured, more and more
    user-friendly tools have emerged. As of today, based on your requirements, there
    are a lot of options to choose from:'
  prefs: []
  type: TYPE_NORMAL
- en: If you are using physical (bare-metal) servers or **virtual machines** (**VMs**),
    Kubeadm is a good fit.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you're running on cloud environments, Kops and Kubespray can ease Kubernetes
    installation, as well as integration with the cloud providers. In fact, we will
    teach you how to deploy Kubernetes on AWS using Kops in *Chapter 11*, *Build Your
    Own HA Cluster*, and we will take another look at the various options we can use
    to set up Kubernetes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you want to drop the burden of managing the Kubernetes control plane (which
    we will learn about later in this chapter), almost all cloud providers have their
    Kubernetes managed services, such as **Google Kubernetes Engine** (**GKE**), **Amazon
    Elastic Kubernetes Service** (**EKS**), **Azure Kubernetes Service** (**AKS**),
    and **IBM Kubernetes Service** (**IKS**).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you just want a playground to study Kubernetes in, Minikube and Kind can
    help you spin up a Kubernetes cluster in minutes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will use Minikube extensively throughout this book as a convenient learning
    environment. But before we proceed to the installation process, let's take a closer
    look at Minikube itself.
  prefs: []
  type: TYPE_NORMAL
- en: An Overview of Minikube
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Minikube is a tool that can be used to set up a single-node cluster, and it
    provides handy commands and parameters to configure the cluster. It primarily
    aims to provide a local testing environment. It packs a VM containing all the
    core components of Kubernetes that get installed onto your host machine, all at
    once. This allows it to support any operating system, as long as there is a virtualization
    tool (also known as a Hypervisor) pre-installed. The following are the most common
    Hypervisors supported by Minikube:'
  prefs: []
  type: TYPE_NORMAL
- en: VirtualBox (works for all operating systems)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: KVM (Linux-specific)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyperkit (macOS-specific)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyper-V (Windows-specific)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regarding the required hardware resources, the minimum requirement is 2 GB RAM
    and any dual-core CPU that supports virtualization (Intel VT or AMD-V), but you
    will, of course, need a more powerful machine if you are trying out heavier workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Just like any other modern software, Kubernetes provides a handy command-line
    client called kubectl that allows users to interact with the cluster conveniently.
    In the next exercise, we will set up Minikube and use some basic kubectl commands.
    We will go into more detail about kubectl in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 2.01: Getting Started with Minikube and Kubernetes Clusters'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will use Ubuntu 20.04 as the base operating system to
    install Minikube, using which we can start a single-node Kubernetes cluster easily.
    Once the Kubernetes cluster has been set up, you should be able to check its status
    and use `kubectl` to interact with it:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'Since this exercise deals with software installations, you will need to be
    logged in as root/superuser. A simple way to switch to being a root user is to
    run the following command: `sudo su -`.'
  prefs: []
  type: TYPE_NORMAL
- en: In *step 9* of this exercise, we will create a regular user and then switch
    back to it.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, ensure that VirtualBox is installed. You can confirm this by using the
    following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: If VirtualBox has been successfully installed, the `which` command should show
    the path of the executable, as shown in the preceding screenshot. If not, then
    please ensure that you have installed VirtualBox as per the instructions provided
    in the *Preface*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the Minikube standalone binary by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In this command, `<version>` should be replaced with a specific version, such
    as `v1.5.2` (which is the version we will use in this chapter) or the `latest`.
    Depending on your host operating system, `<ostype-arch>` should be replaced with
    `linux-amd64` (for Ubuntu) or `darwin-amd64` (for macOS).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To ensure compatibility with the commands provided in this book, we recommend
    that you install Minikube version `v1.5.2`.
  prefs: []
  type: TYPE_NORMAL
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1: Downloading the Minikube binary'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.1: Downloading the Minikube binary'
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding command contains two parts: the first command, `curl`, downloads
    the Minikube binary, while the second command, `chmod`, changes the permission
    to make it executable.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Move the binary into the system path (in the example, it''s `/usr/local/bin`)
    so that we can directly run Minikube, regardless of which directory the command
    is run in:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: When executed successfully, the move (`mv`) command does not give a response
    in the terminal.
  prefs: []
  type: TYPE_NORMAL
- en: 'After running the move command, we need to confirm that the Minikube executable
    is now in the correct location:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: If the `which minikube` command doesn't give you the expected result, you may
    need to explicitly add `/usr/local/bin` to your system path by running `export
    PATH=$PATH:/usr/local/bin`.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can check the version of Minikube using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s download kubectl version `v1.16.2` (so that it''s compatible with
    the version of Kubernetes that our setup of Minikube will create later) and make
    it executable by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: As mentioned earlier, `<ostype>` should be replaced with `linux` (for Ubuntu)
    or `darwin` (for macOS).
  prefs: []
  type: TYPE_NORMAL
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2: Downloading the kubectl binary'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.2: Downloading the kubectl binary'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, move it to the system path, just like we did for the executable of Minikube
    earlier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s check whether the executable for kubectl is at the correct path:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we are currently logged in as the `root` user, let''s create a regular
    user called `k8suser` by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Enter your desired password when you are prompted for it. You will also be
    prompted to enter other details, such as your full name. You may choose to skip
    those details by simply pressing *Enter*. You should see an output similar to
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3: Creating a new Linux user'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.3: Creating a new Linux user'
  prefs: []
  type: TYPE_NORMAL
- en: Enter `Y` and hit *Enter* to confirm the final prompt for creating a user, as
    shown at the end of the previous screenshot.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, switch user from `root` to `k8suser`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can create a Kubernetes cluster using `minikube start`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: If you want to manage multiple clusters, Minikube provides a `--profile <profile
    name>` parameter to each cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'It will take a few minutes to download the VM images and get everything set
    up. After Minikube has started up successfully, you should see a response that
    looks similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4: Minikube first startup'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.4: Minikube first startup'
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned earlier, Minikube starts up a VM instance with all the components
    of Kubernetes inside it. By default, it uses VirtualBox, and you can use the `--vm-driver`
    flag to specify a particular hypervisor driver (such as `hyperkit` for macOS).
    Minikube also provides the `--kubernetes-version` flag so you can specify the
    Kubernetes version you want to use. If not specified, it will use the latest version
    that was available when the Minikube release was finalized. In this chapter, to
    ensure compatibility of the Kubernetes version with the kubectl version, we have
    specified Kubernetes version `v1.16.2` explicitly.
  prefs: []
  type: TYPE_NORMAL
- en: The following commands should help establish that the Kubernetes cluster that
    was started by Minikube is running properly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the following command to get the basic status of the various components
    of the cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s look at the version of the kubectl client and Kubernetes server:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s learn how many machines comprise the cluster and get some basic information
    about them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see a response similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: After finishing this exercise, you should have Minikube set up with a single-node
    Kubernetes cluster. In the next section, we will enter the Minikube VM to take
    a look at how the cluster is composed and the various components of Kubernetes
    that make it work.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes Components Overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By completing the previous exercise, you have a single-node Kubernetes cluster
    up and running. Before playing your first concert, let's hold on a second and
    pull the curtains aside to take a look backstage to see how Kubernetes is architected
    behind the scenes, and then check how Minikube glues its various components together
    inside its VM.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes has several core components that make the wheels of the machine
    turn. They are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: API server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: etcd
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Controller manager
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scheduler
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubelet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These components are critical for the functioning of a Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Besides these core components, you would deploy your applications in containers,
    which are bundled together as pods. We will learn more about pods in *Chapter
    5*, *Pods*. These pods, and several other resources, are defined by something
    called API objects.
  prefs: []
  type: TYPE_NORMAL
- en: An **API object** describes how a certain resource should be honored in Kubernetes.
    We usually define API objects using a human-readable manifest file, and then use
    a tool (such as kubectl) to parse it and hand it over to a Kubernetes API server.
    Kubernetes then tries to create the resource specified in the object and match
    its state to the desired state in the object definition, as mentioned in the manifest
    file. Next, we will walk you through how these components are organized and behave
    in a single-node cluster created by Minikube.
  prefs: []
  type: TYPE_NORMAL
- en: 'Minikube provides a command called `minikube ssh` that''s used to gain SSH
    access from the host machine (in our machine, it''s the physical machine running
    Ubuntu 20.04) to the `minikube` virtual machine, which serves as the sole node
    in our Kubernetes cluster. Let''s see how that works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5: Accessing the Minikube VM via SSH'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.5: Accessing the Minikube VM via SSH'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: All the commands that will be shown later in this section are presumed to have
    been run inside the Minikube VM, after running `minikube ssh`.
  prefs: []
  type: TYPE_NORMAL
- en: Container technology brings the convenience of encapsulating your application.
    Minikube is no exception – it leverages containers to glue the Kubernetes components
    together. In the Minikube VM, Docker is pre-installed so that it can manage the
    core Kubernetes components. You can take a look at this by running `docker ps`;
    however, the result may be overwhelming as it includes all the running containers
    – both the core Kubernetes components and add-ons, as well as all the columns
    – which will output a very large table.
  prefs: []
  type: TYPE_NORMAL
- en: 'To simplify the output and make it easier to read, we will pipe the output
    from `docker ps` into two other Bash commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '`grep -v pause`: This will filter the results by not displaying the "sandbox"
    containers.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Without `grep -v pause`, you would find that each container is "paired" with
    a "sandbox" container (in Kubernetes, it's implemented as a `pause` image). This
    is because, as mentioned in the previous chapter, Linux containers can be associated
    (or isolated) by joining the same (or different) Linux namespace. In Kubernetes,
    a "sandbox" container is used to bootstrap a Linux namespace, and then the containers
    that run the real application are able to join that namespace. Finer details about
    how all this works under the hood have been left out of scope for the sake of
    brevity.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: If not specified explicitly, the term "namespace" is used interchangeably with
    "Kubernetes namespace" across this book. In terms of "Linux namespace", "Linux"
    would not be omitted to avoid confusion.
  prefs: []
  type: TYPE_NORMAL
- en: '`awk ''{print $NF}''`: This will only print the last column with a container
    name.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Thus, the final command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6: Getting the list of containers by running the Minikube VM'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.6: Getting the list of containers by running the Minikube VM'
  prefs: []
  type: TYPE_NORMAL
- en: The highlighted containers shown in the preceding screenshot are basically the
    core components of Kubernetes. We'll discuss each of these in detail in the following
    sections.
  prefs: []
  type: TYPE_NORMAL
- en: etcd
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A distributed system may face various kinds of failures (network, storage, and
    so on) at any moment. To ensure it still works properly when failures arise, critical
    cluster metadata and state must be stored in a reliable way.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes abstracts the cluster metadata and state as a series of API objects.
    For example, the node API object represents a Kubernetes worker node's specification,
    as well as its latest status.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes uses **etcd** as the backend key-value database to persist the API
    objects during the life cycle of a Kubernetes cluster. It is important to note
    that nothing (internal cluster resources or external clients) is allowed to talk
    to etcd without going through the API server. Any updates to or requests from
    etcd are made only via calls to the API server.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, etcd is usually deployed with multiple instances to ensure the
    data is persisted in a secure and fault-tolerant manner.
  prefs: []
  type: TYPE_NORMAL
- en: API Server
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The API server allows standard APIs to access Kubernetes API objects. It is
    the only component that talks to backend storage (etcd).
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, by leveraging the fact that it is the single point of contact
    for communicating to etcd, it provides a convenient interface for clients to "watch"
    any API objects that they may be interested in. Once the API object has been created,
    updated, or deleted, the client that is "watching" will get instant notifications
    so they can act upon those changes. The "watching" client is also known as the
    "controller", which has become a very popular entity that's used in both built-in
    Kubernetes objects and Kubernetes extensions.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: You will learn more about the API server in *Chapter 4*, *How to Communicate
    with Kubernetes* *(API Server)*, and about controllers in *Chapter 7*, *Kubernetes
    Controllers*.
  prefs: []
  type: TYPE_NORMAL
- en: Scheduler
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The scheduler is responsible for distributing the incoming workloads to the
    most suitable node. The decision regarding distribution is made by the scheduler's
    understanding of the whole cluster, as well as a series of scheduling algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: You will learn more about the scheduler in *Chapter 17*, *Advanced Scheduling
    in Kubernetes*.
  prefs: []
  type: TYPE_NORMAL
- en: Controller Manager
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we mentioned earlier in the *API Server* subsection, the API server exposes
    ways to "watch" almost any API object and notify the watchers about the changes
    in the API objects being watched.
  prefs: []
  type: TYPE_NORMAL
- en: It works pretty much like a Publisher-Subscriber pattern. The controller manager
    acts as a typical subscriber and watches the only API objects that it is interested
    in, and then attempts to make appropriate changes to move the current state toward
    the desired state described in the object.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if it gets an update from the API server saying that an application
    claims two replicas, but right now there is only one living in the cluster, it
    will create the second one to make the application adhere to its desired replica
    number. The reconciliation process keeps running across the controller manager's
    life cycle to ensure that all applications stay in their expected state.
  prefs: []
  type: TYPE_NORMAL
- en: The controller manager aggregates various kinds of controllers to honor the
    semantics of API objects, such as Deployments and Services, which we will introduce
    later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Where Is the kubelet?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Note that etcd, the API server, the scheduler, and the controller manager comprise
    the control plane of Kubernetes. A machine that runs these components is called
    a master node. The kubelet, on the other hand, is deployed on each worker machine.
  prefs: []
  type: TYPE_NORMAL
- en: In our single-node Minikube cluster, the kubelet is deployed on the same node
    that carries the control plane components. However, in most production environments,
    it is not deployed on any of the master nodes. We will learn more about production
    environments when we deploy a multi-node cluster in *Chapter 11*, *Build Your
    Own HA Cluster*.
  prefs: []
  type: TYPE_NORMAL
- en: The kubelet primarily aims at talking to the underlying container runtime (for
    example, Docker, containerd, or cri-o) to bring up the containers and ensure that
    the containers are running as expected. Also, it's responsible for sending the
    status update back to the API server.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, as shown in the preceding screenshot, the `docker ps` command doesn''t
    show anything named `kubelet`. To start, stop, or restart any software and make
    it auto-restart upon failure, usually, we need a tool to manage its life cycle.
    In Linux, systemd has that responsibility. In Minikube, the kubelet is managed
    by systemd and runs as a native binary instead of a Docker container. We can run
    the following command to check its status:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see an output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7: Status of kubelet'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.7: Status of kubelet'
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, the kubelet has the configuration for `staticPodPath` in its config
    file (which is stored at `/var/lib/kubelet/config.yaml`). kubelet is instructed
    to continuously watch the changes in files under that path, and each file under
    that path represents a Kubernetes component. Let''s understand what this means
    by first finding `staticPodPath` in the kubelet''s `config` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s see the contents of this path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: As shown in the list of files, the core components of Kubernetes are defined
    by objects that have a definition specified in YAML files. In the Minikube environment,
    in addition to managing the user-created pods, the kubelet also serves as a systemd
    equivalent in order to manage the life cycle of Kubernetes system-level components,
    such as the API server, the scheduler, the controller manager, and other add-ons.
    Once any of these YAML files is changed, the kubelet auto-detects that and updates
    the state of the cluster so that it matches the desired state defined in the updated
    YAML configuration.
  prefs: []
  type: TYPE_NORMAL
- en: We will stop here without diving deeper into the design of Minikube. In addition
    to "static components", the kubelet is also the manager of "regular applications"
    to ensure that they're running as expected on the node and evicts pods according
    to the API specification or upon resource shortage.
  prefs: []
  type: TYPE_NORMAL
- en: kube-proxy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: kube-proxy appears in the output of the `docker ps` command, but it was not
    present at `/etc/kubernetes/manifests` when we explored that directory in the
    previous subsection. This implies its role – it's positioned more as an add-on
    component instead of a core one.
  prefs: []
  type: TYPE_NORMAL
- en: kube-proxy is designed as a distributed network router that runs on every node.
    Its ultimate goal is to ensure that inbound traffic to a **Service** (this is
    an API object that we will introduce later) endpoint can be routed properly. Moreover,
    if multiple containers are serving one application, it is able to balance the
    traffic in a round-robin manner by leveraging the underlying Linux iptables/IPVS
    technology.
  prefs: []
  type: TYPE_NORMAL
- en: There are also some other add-ons such as CoreDNS, though we will skip those
    so that we can focus on the core components and get a high-level picture.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, kube-proxy and CoreDNS are also considered core components of a Kubernetes
    installation. To some extent, that's technically true as they're mandatory in
    most cases; otherwise, the Service API object won't work. However, in this book,
    we're leaning more toward categorizing them as "add-ons" as they focus on the
    implementation of one particular Kubernetes API resource instead of general workflow.
    Also, kube-proxy and CoreDNS are defined in `addon-manager.yaml.tmpl` instead
    of being portrayed on the same level as the other core Kubernetes components.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes Architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous section, we gained a first impression of the core Kubernetes
    components: etcd, the API server, the scheduler, the controller manager, and the
    kubelet. These components, plus other add-ons, comprise the Kubernetes architecture,
    which can be seen in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8: Kubernetes architecture'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.8: Kubernetes architecture'
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we won't look at each component in too much detail. However,
    at a high-level view, it's critical to understand how the components communicate
    with each other and why they're designed in that way.
  prefs: []
  type: TYPE_NORMAL
- en: The first thing to understand is which components the API server can interact
    with. From the preceding diagram, we can easily tell that the API server can talk
    to almost every other component (except the container runtime, which is handled
    by the kubelet) and that it also serves to interact with end-users directly. This
    design makes the API server act as the "heart" of Kubernetes. Additionally, the
    API server also scrutinizes incoming requests and writes API objects into the
    backend storage (etcd). This, in other words, makes the API server the throttle
    of security control measures such as authentication, authorization, and auditing.
  prefs: []
  type: TYPE_NORMAL
- en: The second thing to understand is how the different Kubernetes components (except
    for the API server) interact with each other. It turns out that there is no explicit
    connection among them – the controller manager doesn't talk to the scheduler,
    nor does the kubelet talk to kube-proxy.
  prefs: []
  type: TYPE_NORMAL
- en: You read that right – they do need to work in coordination with each other to
    accomplish many functionalities, but they never directly talk to each other. Instead,
    they communicate implicitly via the API server. More precisely, they communicate
    by watching, creating, updating, or deleting corresponding API objects. This is
    also known as the controller/operator pattern.
  prefs: []
  type: TYPE_NORMAL
- en: Container Network Interface
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are several networking aspects to take into consideration, such as how
    a pod communicates with its host machine's network interface, how a node communicates
    with other nodes, and, eventually, how a pod communicates with any pod across
    different nodes. As the network infrastructure differs vastly in the cloud or
    on-premises environments, Kubernetes chooses to solve those problems by defining
    a specification called the **Container Network Interface** (**CNI**). Different
    CNI providers can follow the same interface and implement their logic that adheres
    to the Kubernetes standards to ensure that the whole Kubernetes network works.
    We will revisit the idea of the CNI in *Chapter 11*, *Build Your Own HA Cluster*.
    For now, let's return to our discussion of how the different Kubernetes components
    work.
  prefs: []
  type: TYPE_NORMAL
- en: Later in this chapter, *Exercise 2.05*, *How Kubernetes Manages a Pod's Life
    Cycle*, will help you consolidate your understanding of this and clarify a few
    things, such as how the different Kubernetes components operate synchronously
    or asynchronously to ensure a typical Kubernetes workflow, and what would happen
    if one or more of these components malfunctions. The exercise will help you better
    understand the overall Kubernetes architecture. But before that, let's introduce
    our containerized application from the previous chapter to the Kubernetes world
    and explore a few benefits of Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Migrating Containerized Application to Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we built a simple HTTP server called `k8s-for-beginners`,
    and it runs as a Docker container. It works perfectly for a sample application.
    However, what if you have to manage thousands of containers, and coordinate and
    schedule them properly? How can you upgrade a service without downtime? How do
    you keep a service healthy upon unexpected failure? These problems exceed the
    abilities of a system that simply uses containers alone. What we need is a platform
    that can orchestrate, as well as manage, our containers.
  prefs: []
  type: TYPE_NORMAL
- en: We have told you that Kubernetes is the solution that we need. Next, we will
    walk you through a series of exercises regarding how to orchestrate and run containers
    in Kubernetes using a Kubernetes native approach.
  prefs: []
  type: TYPE_NORMAL
- en: Pod Specification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A straightforward thought is that we wish to see what the equivalent API call
    or command to run a container in Kubernetes is. As explained in *Chapter 1*, *Introduction
    to Kubernetes and Containers*, a container can join another container's namespace
    so that they can access each other's resources (for example, network, storage,
    and so on) without additional overhead. In the real world, some applications may
    need several containers working closely, either in parallel or in a particular
    order (the output of one will be processed by another). Also, some generic containers
    (for example, logging agent, network throttling agent, and so on) may need to
    work closely with their target containers.
  prefs: []
  type: TYPE_NORMAL
- en: Since an application may often need several containers, a container is not the
    minimum operational unit in Kubernetes; instead, it introduces a concept called
    **pods** to bundle one or multiple containers. Kubernetes provides a series of
    specifications to describe how this pod is supposed to be, including several specifics
    such as images, resource requests, startup commands, and more. To send this pod
    spec to Kubernetes, particularly to the Kubernetes API server, we're going to
    use kubectl.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'We will learn more about pods in *Chapter 5*, *Pods*, but we will use them
    in this chapter for the purpose of simple demonstrations. You can refer to the
    complete list of available pod specifications at this link: [https://godoc.org/k8s.io/api/core/v1#PodSpec](https://godoc.org/k8s.io/api/core/v1#PodSpec).'
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's learn how to run a single container in Kubernetes by composing the
    pod spec file (also called the specification, manifest, config, or configuration
    file). In Kubernetes, you can use YAML or JSON to write this specification file,
    though YAML is commonly used since it is more human-readable and editable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following YAML spec for a very simple pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s go through the different fields briefly:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kind` tells Kubernetes which type of object you want to create. Here, we are
    creating a `Pod`. In later chapters, you will see many other kinds, such as Deployment,
    StatefulSet, ConfigMap, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`apiVersion` specifies a particular version of an API object. Different versions
    may behave a bit differently.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`metadata` includes some attributes that can be used to uniquely identify the
    pod, such as name and namespace. If we don''t specify a namespace, it goes in
    the `default` namespace.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`spec` contains a series of fields describing the pod. In this example, there
    is one container that has its image URL and name specified.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pods are one of the simplest Kubernetes objects to deploy, so we will use them
    to learn how to deploy objects using YAML manifests in the following exercise.
  prefs: []
  type: TYPE_NORMAL
- en: Applying a YAML Manifest
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once we have a YAML manifest ready, we can use `kubectl apply -f <yaml file>`
    or `kubectl create -f <yaml file>` to instruct the API server to persist the API
    resources defined in this manifest. When you create a pod from scratch for the
    first time, it doesn't make much difference which of the two commands you use.
    However, we may often need to modify the YAML (let's say, for example, if we want
    to upgrade the image version) and reapply it. If we use the `kubectl create` command,
    we have to delete and recreate it. However, with the `kubectl apply` command,
    we can rerun the same command and the delta change will be calculated and applied
    automatically by Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: This is very convenient from an operational point of view. For example, if we
    use some form of automation, it is much simpler to repeat the same command. So,
    we will use `kubectl apply` across the following exercise, regardless of whether
    it's the first time it's being applied or not.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: A detailed on kubectl can be obtained in *Chapter 4*, *How to Communicate with
    Kubernetes (API Server)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 2.02: Running a Pod in Kubernetes'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous exercise, we started up Minikube and looked at the various
    Kubernetes components running as pods. Now, in this exercise, we shall deploy
    our pod. Follow these steps to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: If you have been trying out the commands from the *Kubernetes Components Overview*
    section, don't forget to leave the SSH session by using the `exit` command before
    beginning this exercise. Unless otherwise specified, all commands using `kubectl`
    should run on the host machine and not inside the Minikube VM.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Kubernetes, we use a spec file to describe an API object such as a pod.
    As mentioned earlier, we will stick to YAML as it is more human-readable and editable
    friendly. Create a file named `k8s-for-beginners-pod.yaml` (using any text editor
    of your choice) with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Please replace the image path in the last line of the preceding YAML file with
    the path to your image that you created in the previous chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the host machine, run the following command to create this pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can use the following command to check the pod''s status:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: By default, `kubectl get pod` will list all the pods using a table format. In
    the preceding output, we can see the `k8s-for-beginners` pod is running properly
    and that it has one container that is ready (`1/1`). Moreover, kubectl provides
    an additional flag called `-o` so we can adjust the output format. For example,
    `-o yaml` or `-o json` will return the full output of the pod API object in YAML
    or JSON format, respectively, as it's stored version in Kubernetes' backend storage
    (etcd).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use the following command to get more information about the pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.9: Getting more information about pods'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.9: Getting more information about pods'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the output is still in the table format and we get additional
    information such as `IP` (the internal pod IP) and `NODE` (which node the pod
    is running on).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can get the list of nodes in our cluster by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The IP listed in *Figure 2.9* refers to the internal IP Kubernetes assigned
    for this pod, and it''s used for pod-to-pod communication, not for routing external
    traffic to pods. Hence, if you try to access this IP from outside the cluster,
    you will get nothing. You can try that using the following command from the host
    machine, which will fail:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Remember to change `172.17.0.4` to the value you get for your environment in
    *step 4*, as seen in *Figure 2.9*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `curl` command will just hang and return nothing, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: You will need to press *Ctrl* + *C* to abort it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In most cases, end-users don''t need to interact with the internal pod IP.
    However, just for observation purposes, let''s SSH into the Minikube VM:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the following response in the terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.10: Accessing the Minikube VM via SSH'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.10: Accessing the Minikube VM via SSH'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, try calling the IP from inside the Minikube VM to verify that it works:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get a successful response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: With this, we have successfully deployed our application in a pod on the Kubernetes
    cluster. We can confirm that it is working since we get a response when we call
    the application from inside the cluster. Now, you may end the Minikube SSH session
    using the `exit` command.
  prefs: []
  type: TYPE_NORMAL
- en: Service Specification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The last part of the previous section proves that network communication works
    great among different components inside the cluster. But in the real world, you
    would not expect users of your application to gain SSH access into your cluster
    to use your applications. So, you would want your application to be accessed externally.
  prefs: []
  type: TYPE_NORMAL
- en: To facilitate just that, Kubernetes provides a concept called a **Service**
    to abstract the network access to your application's pods. A Service acts as a
    network proxy to accept network traffic from external users and then distributes
    it to internal pods. However, there should be a way to describe the association
    rule between the Service and the corresponding pods. Kubernetes uses labels, which
    are defined in the pod definitions, and label selectors, which are defined in
    the Service definition, to describe this relationship.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: You will learn more about labels and label selectors in *Chapter 6*, *Labels
    and Annotations*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider the following sample spec for a Service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to a pod spec, here, we define `kind` and `apiVersion`, while `name`
    is defined under the `metadata` field. Under the `spec` field, there are several
    critical fields to take note of:'
  prefs: []
  type: TYPE_NORMAL
- en: '`selector` defines the labels to be selected to match a relationship with the
    corresponding pods, which, as you will see in the following exercise, are supposed
    to be labeled properly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`type` defines the type of Service. If not specified, the default type is `ClusterIP`,
    which means it''s only used within the cluster, that is, internally. Here, we
    specify it as `NodePort`. This means the Service will expose a port in each node
    of the cluster and associate the port with the corresponding pods. Another well-known
    type is called `LoadBalancer`, which is typically not implemented in a vanilla
    Kubernetes offering. Instead, Kubernetes delegates the implementation to each
    cloud provider, such as GKE, EKS, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ports` include a series of `port` fields, each with a `targetPort` field.
    The `targetPort` field is the actual port that''s exposed by the destination pod.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thus, the Service can be accessed internally via `<service ip>:<port>`. Now,
    for example, if you have an NGINX pod running internally and listening on port
    8080, then you should define `targetPort` as `8080`. You can specify any arbitrary
    number for the `port` field, such as `80` in this case. Kubernetes will set up
    and maintain the mapping between `<service IP>:<port>` and `<pod IP>:<targetPort>`.
    In the following exercise, we will learn how to access the Service from outside
    the cluster and bring external traffic inside the cluster via the Service.
  prefs: []
  type: TYPE_NORMAL
- en: In the following exercise, we will define Service manifests and create them
    using `kubectl apply` commands. You will learn that the common pattern for resolving
    problems in Kubernetes is to find out the proper API objects, then compose the
    detailed specs using YAML manifests, and finally create the objects to bring them
    into effect.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 2.03: Accessing a Pod via a Service'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous exercise, we observed that an internal pod IP doesn''t work
    for anyone outside the cluster. In this exercise, we will create Services that
    will act as connectors to map the external requests to the destination pods so
    that we can access the pods externally without entering the cluster. Follow these
    steps to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Firstly, let''s tweak the pod spec from *Exercise 2.02*, *Running a Pod in
    Kubernetes*, to apply some labels. Modify the contents of the `k8s-for-beginners-pod1.yaml`
    file, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we added a label pair, `tier: frontend`, under the `labels` field.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Because the pod name remains the same, let''s rerun the `apply` command so
    that Kubernetes knows that we''re trying to update the pod''s spec, instead of
    creating a new pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Behind the scenes, for the `kubectl apply` command, kubectl generates the difference
    of the specified YAML and the stored version in the Kubernetes server-side storage
    (that is, etcd). If the request is valid (that is, we have not made any errors
    in the specification format or the command), kubectl will send an HTTP patch to
    the Kubernetes API server. Hence, only the delta changes will be applied. If you
    look at the message that's returned, you'll see it says `pod/k8s-for-beginners
    configured` instead of `created`, so we can be sure it's applying the delta changes
    and not creating a new pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use the following command to explicitly display the labels that have
    been applied to existing pods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that the pod has the `tier: frontend` attribute, we''re ready to create
    a Service and link it to the pods.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a file named `k8s-for-beginners-svc.yaml` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s create the Service using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `get` command to return the list of created Services and confirm whether
    our Service is online:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.11: Getting the list of Services'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.11: Getting the list of Services'
  prefs: []
  type: TYPE_NORMAL
- en: So, you may have noticed that the `PORT(S)` column outputs `80:32571/TCP`. Port
    `32571` is an auto-generated port that's exposed on every node, which is done
    intentionally so that external users can access it. Now, before moving on to the
    next step, exit the SSH session.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we have the "external port" as `32571`, but we still need to find the
    external IP. Minikube provides a utility we can use to easily access the `k8s-for-beginners`
    Service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see a response that looks similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.12: Getting the URL and port to access the NodePort Service'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.12: Getting the URL and port to access the NodePort Service'
  prefs: []
  type: TYPE_NORMAL
- en: Depending on your environment, this may also automatically open a browser web
    page so you can access the Service. From the URL, you will be able to see that
    the Service port is `32571`. The external IP is actually the IP of the Minikube
    VM.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also access our application from outside the cluster via the command
    line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'As a summary, in this exercise, we created a `NodePort` Service to enable external
    users to access the internal pods without entering the cluster. Under the hood,
    there are several layers of traffic transitions that make this happen:'
  prefs: []
  type: TYPE_NORMAL
- en: The first layer is from the external user to the machine IP at the auto-generated
    random port (3XXXX).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second layer is from the random port (3XXXX) to the Service IP (10.X.X.X)
    at port `80`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The third layer is from the Service IP (10.X.X.X) ultimately to the pod IP at
    port `8080`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is a diagram illustrating these interactions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.13: Routing traffic from a user outside the cluster'
  prefs: []
  type: TYPE_NORMAL
- en: to the pod running our application
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.13: Routing traffic from a user outside the cluster to the pod running
    our application'
  prefs: []
  type: TYPE_NORMAL
- en: Services and Pods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In *step 3* of the previous exercise, you may have noticed that the Service
    tries to match pods by labels (the `selector` field under the `spec` section)
    instead of using a fixed pod name or something similar. From a pod's perspective,
    it doesn't need to know which Service is bringing traffic to it. (In some rare
    cases, it can even be mapped to multiple Services; that is, multiple Services
    may be sending traffic to a pod.)
  prefs: []
  type: TYPE_NORMAL
- en: 'This label-based matching mechanism is widely used in Kubernetes. It enables
    the API objects to be loosely coupled at runtime. For example, you can specify
    `tier: frontend` as the label selector, which will, in turn, be associated with
    the pods that are labeled as `tier: frontend`.'
  prefs: []
  type: TYPE_NORMAL
- en: Due to this, by the time the Service is created, it doesn't matter if the backing
    pods exist or not. It's totally acceptable for backing pods to be created later,
    and after they are created, the Service object will become associated with the
    correct pods. Internally, the whole mapping logic is implemented by the service
    controller, which is part of the controller manager component. It's also possible
    that a Service may have two matching pods at a time, and later a third pod is
    created with matching labels, or one of the existing pods gets deleted. In either
    case, the service controller can detect such changes and ensure that users can
    always access their application via the Service endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: It's a very commonly used pattern in Kubernetes to orchestrate your application
    using different kinds of API objects and then glue them together by using labels
    or other loosely coupled conventions. It's also the key part of container orchestration.
  prefs: []
  type: TYPE_NORMAL
- en: Delivering Kubernetes-Native Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous sections, we migrated a Docker-based application to Kubernetes
    and successfully accessed it from inside the Minikube VM, as well as externally.
    Now, let's see what other benefits Kubernetes can provide if we design our application
    from the ground up so that it can be deployed using Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Along with the increasing usage of your application, it may be common to run
    several replicas of certain pods to serve a business functionality. In this case,
    grouping different containers in a pod alone is not sufficient. We need to go
    ahead and create groups of pods that are working together. Kubernetes provides
    several abstractions for groups of pods, such as Deployments, DaemonSets, Jobs,
    CronJobs, and so on. Just like the Service object, these objects can also be created
    by using a spec that's been defined in a YAML file.
  prefs: []
  type: TYPE_NORMAL
- en: To start understanding the benefits of Kubernetes, let's use a Deployment to
    demonstrate how to replicate (scale up/down) an application in multiple pods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Abstracting groups of pods using Kubernetes gives us the following advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Creating replicas of pods for redundancy**: This is the main advantage of
    abstractions of groups of pods such as Deployments. A Deployment can create several
    pods with the given spec. A Deployment will automatically ensure that the pods
    that it creates are online, and it will automatically replace any pods that fail.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Easy upgrades and rollbacks**: Kubernetes provides different strategies that
    you can use to upgrade your applications, as well as rolling versions back. This
    is important because in modern software development, the software is often developed
    iteratively, and updates are released frequently. An upgrade can change anything
    in the Deployment specification. It can be an update of labels or any other field(s),
    an image version upgrade, an update on its embedded containers, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s take a look at some notable aspects of the spec of a sample Deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: k8s-for-beginners-deploy.yaml
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: In addition to wrapping the pod spec as a "template", a Deployment must also
    specify its kind (`Deployment`), as well as the API version (`apps/v1`).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For some historical reason, the spec name `apiVersion` is still being used.
    But technically speaking, it literally means `apiGroupVersion`. In the preceding
    Deployment example, it belongs to the `apps` group and is version `v1`.
  prefs: []
  type: TYPE_NORMAL
- en: In the Deployment spec, the `replicas` field instructs Kubernetes to start three
    pods using the pod spec defined in the `template` field. The `selector` field
    plays the same role as we saw in the case of the Service – it aims to associate
    the Deployment object with specific pods in a loosely coupled manner. This is
    particularly useful if you want to bring any preexisting pods under the management
    of your new Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: The replica number defined in a Deployment or other similar API object represents
    the desired state of how many pods are supposed to be running continuously. If
    some of these pods fail for some unexpected reason, Kubernetes will automatically
    detect that and create a corresponding number of pods to take their place. We
    will explore that in the following exercise.
  prefs: []
  type: TYPE_NORMAL
- en: We'll see a Deployment in action in the following exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 2.04: Scaling a Kubernetes Application'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In Kubernetes, it''s easy to increase the number of replicas running the application
    by updating the `replicas` field of a Deployment spec. In this exercise, we''ll
    experiment with how to scale a Kubernetes application up and down. Follow these
    steps to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a file named `k8s-for-beginners-deploy.yaml` using the content shown
    here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: If you take a closer look, you'll see that this Deployment spec is largely based
    on the pod spec from earlier exercises (`k8s-for-beginners-pod1.yaml`), which
    you can see under the `template` field.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can use kubectl to create the Deployment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Given that the Deployment has been created successfully, we can use the following
    command to show all the Deployment''s statuses, such as their names, running pods,
    and so on:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in the previous command, we are using `deploy` instead of `deployment`.
    Both of these will work and `deploy` is an allowed short name for `deployment`.
    You can find a quick list of some commonly used short names at this link: [https://kubernetes.io/docs/reference/kubectl/overview/#resource-types](https://kubernetes.io/docs/reference/kubectl/overview/#resource-types).'
  prefs: []
  type: TYPE_NORMAL
- en: You can also view the short names by running `kubectl api-resources`, without
    specifying the resource type.
  prefs: []
  type: TYPE_NORMAL
- en: 'A pod called `k8s-for-beginners` exists that we created in the previous exercise.
    To ensure that we see only the pods being managed by the Deployment, let''s delete
    the older pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, get a list of all the pods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.14: Getting the list of pods'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_14.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.14: Getting the list of pods'
  prefs: []
  type: TYPE_NORMAL
- en: The Deployment has created three pods, and their labels (specified in the `labels`
    field in *step 1*) happen to match the Service we created in the previous section.
    So, what will happen if we try to access the Service? Will the network traffic
    going to the Service be smartly routed to the new three pods? Let's test this
    out.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see how the traffic is distributed to the three pods, we can simulate a
    number of consecutive requests to the Service endpoint by running the `curl` command
    inside a Bash `for` loop, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: In this command, use the same IP and port that you used in the previous exercise
    if you are running the same instance of Minikube. If you have restarted Minikube
    or have made any other changes, please get the proper IP of your Minikube cluster
    by following *step 9* of the previous exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you''ve run the command with the proper IP and port, you should see the
    following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.15: Repeatedly accessing our application'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.15: Repeatedly accessing our application'
  prefs: []
  type: TYPE_NORMAL
- en: From the output, we can tell that all 30 requests get the expected response.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can run `kubectl logs <pod name>` to check the log of each pod. Let''s
    go one step further and figure out the exact number of requests each pod has responded
    to, which might help us find out whether the traffic was evenly distributed. To
    do that, we can pipe the logs of each pod into the `wc` command to get the number
    of lines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the preceding command three times, copying the pod name you obtained, as
    shown in *Figure 2.16*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.16: Getting the logs of each of the three pod replicas running our
    application'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_16.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.16: Getting the logs of each of the three pod replicas running our
    application'
  prefs: []
  type: TYPE_NORMAL
- en: The result shows that the three pods handled `9`, `10`, and `11` requests, respectively.
    Due to the small sample size, the distribution is not absolutely even (that is,
    `10` for each), but it is sufficient to indicate the default round-robin distribution
    strategy used by a Service.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'You can read more about how kube-proxy leverages iptables to perform the internal
    load balancing by looking at the official documentation: [https://kubernetes.io/docs/concepts/services-networking/service/#proxy-mode-iptables](https://kubernetes.io/docs/concepts/services-networking/service/#proxy-mode-iptables).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s learn how to scale up a Deployment. There are two ways of accomplishing
    this: one way is to modify the Deployment''s YAML config, where we can set the
    value of `replicas` to another number (such as `5`), while the other way is to
    use the `kubectl scale` command, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s verify whether there are five pods running:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see a response similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.17: Getting the list of pods'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_17.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.17: Getting the list of pods'
  prefs: []
  type: TYPE_NORMAL
- en: The output shows that the existing three pods are kept and that two new pods
    are created.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, you can specify replicas that are smaller than the current number.
    In our example, let''s say that we want to shrink the replica''s number to `2`.
    The command for this would look as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s verify the number of pods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see a response similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.18: Getting the list of pods'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_18.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.18: Getting the list of pods'
  prefs: []
  type: TYPE_NORMAL
- en: As shown in the preceding screenshot, there are two pods, and they are both
    running as expected. Thus, in Kubernetes' terms, we can say, "the Deployment is
    in its desired state".
  prefs: []
  type: TYPE_NORMAL
- en: 'We can run the following command to verify this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s see what happens if we delete one of the two pods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the status of the pods to see what has happened:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.19: Getting the list of pods'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_19.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.19: Getting the list of pods'
  prefs: []
  type: TYPE_NORMAL
- en: We can see that there are still two pods. From the output, it's worth noting
    that the first pod name is the same as the second pod in *Figure 2.18* (this is
    the one that was not deleted), but that the highlighted pod name is different
    from any of the pods in *Figure 2.18*. This indicates that the highlighted one
    is the pod that was newly created to replace the deleted one. The Deployment created
    a new pod so that the number of running pods satisfies the desired state of the
    Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, we have learned how to scale a deployment up and down. You
    can scale other similar Kubernetes objects, such as DaemonSets and StatefulSets,
    in the same way. Also, for such objects, Kubernetes will try to auto-recover the
    failed pods.
  prefs: []
  type: TYPE_NORMAL
- en: Pod Life Cycle and Kubernetes Components
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous sections in this chapter briefly described the Kubernetes components
    and how they work internally with each other. On the other hand, we also demonstrated
    how to use some Kubernetes API objects (Pods, Services, and Deployments) to compose
    your applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'But how is a Kubernetes API object managed by different Kubernetes components?
    Let''s consider a pod as an example. Its life cycle can be illustrated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.20: The process behind the creation of a pod'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_20.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.20: The process behind the creation of a pod'
  prefs: []
  type: TYPE_NORMAL
- en: 'This entire process can be broken down as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A user starts to deploy an application by sending a Deployment YAML manifest
    to the Kubernetes API server. The API server verifies the request and checks whether
    it's valid. If it is, it persists the Deployment API object to its backend datastore
    (etcd).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For any step that evolves by modifying API objects, interactions have to happen
    between etcd and the API server, so we don't list the interactions as extra steps
    explicitly.
  prefs: []
  type: TYPE_NORMAL
- en: By now, the pod hasn't been created yet. The controller manager gets a notification
    from the API server that a Deployment has been created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, the controller manager checks whether the desired number of replica pods
    are running already.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If there are not enough pods running, it creates the appropriate number of pods.
    The creation of pods is accomplished by sending a request with the pod spec to
    the API server. It's quite similar to how a user would apply the Deployment YAML,
    but with the major difference being that this happens inside the controller manager
    in a programmatic manner.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Although pods have been created, they're nothing but some API objects stored
    in etcd. Now, the scheduler gets a notification from the API server saying that
    new pods have been created and no node has been assigned for them to run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The scheduler checks the resource usage, as well as existing pods allocation,
    and then calculates the node that fits best for each new pod. At the end of this
    step, the scheduler sends an update request to the API server by setting the pod's
    `nodeName` spec to the chosen node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By now, the pods have been assigned a proper node to run on. However, no physical
    containers are running. In other words, the application doesn't work yet. Each
    kubelet (running on different worker nodes) gets notifications, indicating that
    some pods are expected to be run. Each kubelet will then check whether the pods
    to be run have been assigned the node that a kubelet is running on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the kubelet determines that a pod is supposed to be on its node, it calls
    the underlying container runtime (Docker, containerd, or cri-o, for instance)
    to spin up the containers on the host. Once the containers are up, the kubelet
    is responsible for reporting its status back to the API server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'With this basic flow in mind, you should now have a vague understanding of
    the answers to the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Who is in charge of pod creation? What's the state of the pod upon creation?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Who is responsible for placing a pod? What's the state of the pod after placement?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Who brings up the concrete containers?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Who is in charge of the overall message delivery process to ensure that all
    components work together?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following exercise, we will use a series of concrete experiments to help
    you solidify this understanding. This will allow you to see how things work in
    practice.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 2.05: How Kubernetes Manages a Pod''s Life Cycle'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As a Kubernetes cluster comprises multiple components, and each component works
    simultaneously, it''s usually difficult to know what''s exactly happening in each
    phase of a pod''s life cycle. To solve this problem, we will use a film editing
    technique to "play the whole life cycle in slow motion", so as to observe each
    phase. We will turn off the master plane components and then attempt to create
    a pod. Then, we will respond to the errors that we see, and slowly bring each
    component online, one by one. This will allow us to slow down and examine each
    stage of the process of pod creation step-by-step. Follow these steps to complete
    this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s delete the Deployment and Service we created earlier by using
    the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'Prepare two terminal sessions: one (host terminal) to run commands on your
    host machine and another (Minikube terminal) to pass commands inside the Minikube
    VM via SSH. Thus, your Minikube session will be initiated like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.21: Accessing the Minikube VM via SSH'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_21.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.21: Accessing the Minikube VM via SSH'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: All `kubectl` commands are expected to be run in the host terminal session,
    while all `docker` commands are to be run in the Minikube terminal session.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the Minikube session, clean up all stopped Docker containers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.22: Cleaning up all stopped Docker containers'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_22.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.22: Cleaning up all stopped Docker containers'
  prefs: []
  type: TYPE_NORMAL
- en: You may see some error messages such as "You cannot remove a running container
    ...". This is because the preceding `docker rm` command runs against all containers
    (`docker ps -a -q`), but it won't stop any running containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the Minikube session, stop the kubelet by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: This command does not show any response upon successful execution.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Later in this exercise, we will manually stop and start other Kubernetes components,
    such as the API server, that are managed by the kubelet in a Minikube environment.
    Hence, it's required that you stop the kubelet first in this exercise; otherwise,
    the kubelet will automatically restart its managed components.
  prefs: []
  type: TYPE_NORMAL
- en: Note that in typical production environments, unlike Minikube, it's not necessary
    to run the kubelet on the master node to manage the master plane components; the
    kubelet is only a mandatory component on worker nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'After 30 seconds, check the cluster''s status by running the following command
    in your host terminal session:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: It's expected that the status of the `minikube` node is changed to `NotReady`
    because the kubelet has been stopped.
  prefs: []
  type: TYPE_NORMAL
- en: 'In your Minikube session, stop `kube-scheduler`, `kube-controller-manager`,
    and `kube-apiserver`. As we saw earlier, all of these are running as Docker containers.
    Hence, you can use the following commands, one after the other:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following responses:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.23: Stopping the containers running Kubernetes components'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_23.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.23: Stopping the containers running Kubernetes components'
  prefs: []
  type: TYPE_NORMAL
- en: As we explained in the *Kubernetes Components Overview* section, the `grep -v
    pause | awk '{print $1}'` command can fetch the exact container ID (`$1` = the
    first column) of the required Docker containers. Then, the `docker pause` command
    can pause that running Docker container.
  prefs: []
  type: TYPE_NORMAL
- en: Now, the three major Kubernetes components have been stopped.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, you need to create a Deployment spec on your host machine. Create a file
    named `k8s-for-beginners-deploy2.yaml` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'Try to create the Deployment by running the following command on your host
    session:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see a response similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.24: Trying to create a new Deployment'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_24.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.24: Trying to create a new Deployment'
  prefs: []
  type: TYPE_NORMAL
- en: 'Unsurprisingly, we got a network timeout error since we intentionally stopped
    the Kubernetes API server. If the API server is down, you cannot run any `kubectl`
    commands or use any equivalent tools (such as Kubernetes Dashboard) that rely
    on API requests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see what happens if we restart the API server and try to create the
    Deployment once more. Restart the API server container by running the following
    command in your Minikube session:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'This command tries to find the container ID of the stopped container carrying
    the API server, and then it starts it. You should get a response like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'Wait for 10 seconds. Then, check whether the API server is online. You can
    run any simple kubectl command for this. Let''s try getting the list of nodes
    by running the following command in the host session:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we are able to get a response without errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try to create the Deployment again:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s check whether the Deployment has been created successfully by running
    the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: From the preceding screenshot, there seems to be something wrong as in the `READY`
    column, we can see `0/1`, which indicates that there are 0 pods associated with
    this Deployment, while the desired number is 1 (which we specified in the `replicas`
    field in the Deployment spec).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s check that all the pods that are online:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get a response similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: We can see that our pod has not been created. This is because the Kubernetes
    API server only creates the API objects; the implementation of any API object
    is carried out by other components. For example, in the case of Deployment, it's
    `kube-controller-manager` that creates the corresponding pod(s).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s restart the `kube-controller-manager`. Run the following command
    in your Minikube session:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see a response similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'After waiting for a few seconds, check the status of the Deployment by running
    the following command in the host session:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the pod that we are looking for is still not online.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, check the status of the pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.25: Getting the list of pods'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_25.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.25: Getting the list of pods'
  prefs: []
  type: TYPE_NORMAL
- en: The output is different from the one in *step 15*, as in this case, one pod
    was created by `kube-controller-manager`. However, we can see `Pending` under
    the `STATUS` column. This is because assigning a pod to a suitable node is not
    the responsibility of `kube-controller-manager`; it's the responsibility of `kube-scheduler`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before starting `kube-scheduler`, let''s take a look at some additional information
    about the pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.26: Getting more information about the pod'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_26.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.26: Getting more information about the pod'
  prefs: []
  type: TYPE_NORMAL
- en: The highlighted `NODE` column indicates that no node has been assigned to this
    pod. This proves that the scheduler is not working properly, which we know because
    we took it offline. If the scheduler were to be online, this response would indicate
    that there is no place to land this pod.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: You will learn a lot more about pod scheduling in *Chapter 17*, *Advanced Scheduling
    in Kubernetes*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s restart `kube-scheduler` by running the following command in the Minikube
    session:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see a response similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: 'We can verify that `kube-scheduler` is working by running the following command
    in the host session:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'Please get the pod name from the response you get at *step 17*, as seen in
    *Figure 2.26*. You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: 'We are truncating the output screenshots for a better presentation. Please
    take a look at the following excerpt, highlighting the `Events` section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.27: Examining the events reported by the pod'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_27.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.27: Examining the events reported by the pod'
  prefs: []
  type: TYPE_NORMAL
- en: In the `Events` section, we can see that the `kube-scheduler` has tried scheduling,
    but it reports that there is no node available. Why is that?
  prefs: []
  type: TYPE_NORMAL
- en: This is because, earlier, we stopped the kubelet, and the Minikube environment
    is a single-node cluster, so there is no available node(s) with a functioning
    kubelet for the pod to be placed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s restart the kubelet by running the following command in the Minikube
    session:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: This should not give any response in the terminal upon successful execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the host terminal, verify the status of the Deployment by running the following
    command in the host session:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: Now, everything looks healthy as the Deployment shows `1/1` under the `READY`
    column, which means that the pod is online.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, verify the status of the pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get an output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.28: Getting more information about the pod'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_28.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.28: Getting more information about the pod'
  prefs: []
  type: TYPE_NORMAL
- en: We can see `Running` under `STATUS` and that it's been assigned to the `minikube`
    node.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this exercise, we traced each phase of a pod''s life cycle by breaking the
    Kubernetes components and then recovering them one by one. Now, based on the observations
    we made about this exercise; we have better clarity regarding the answers to the
    questions that were raised before this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Steps 12 – 16**: We saw that in the case of a Deployment, a controller manager
    is responsible for requesting the creation of pods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Steps 17 – 19**: The scheduler is responsible for choosing a node to place
    in the pod. It assigns the node by setting a pod''s `nodeName` spec to the desired
    node. Associating a pod to a node, at this moment, merely happened at the level
    of the API object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Steps 20 – 22**: The kubelet actually brings up the containers to get our
    pod running.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Throughout a pod's life cycle, Kubernetes components cooperate by updating a
    pod's spec properly. The API server serves as the key component that accepts pod
    update requests, as well as to report pod changes to interested parties.
  prefs: []
  type: TYPE_NORMAL
- en: In the following activity, we will bring together the skills we learned in the
    chapter to find out how we can migrate from a container-based environment to a
    Kubernetes environment in order to run our application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 2.01: Running the Pageview App in Kubernetes'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In *Activity 1.01*, *Creating a Simple Page Count Application*, in the previous
    chapter, we built a web application called Pageview and connected it to a Redis
    backend datastore. So, here is a question: without making any changes to the source
    code, can we migrate the Docker-based application to Kubernetes and enjoy Kubernetes''
    benefits immediately? Try it out in this activity with the guidelines given.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This activity is divided into two parts: in the first part, we will create
    a simple pod with our application that is exposed to traffic outside the cluster
    by a Service and connected to a Redis datastore running as another pod. In the
    second part, we will scale the application to three replicas.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Connecting the Pageview App to a Redis Datastore Using a Service**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to the `--link` option in Docker, Kubernetes provides a Service that
    serves as an abstraction layer to expose one application (let''s say, a series
    of pods tagged with the same set of labels) that can be accessed internally or
    externally. For example, as we discussed in this chapter, a frontend app can be
    exposed via a `NodePort` Service so that it can be accessed by external users.
    In addition to that, in this activity, we need to define an internal Service in
    order to expose the backend application to the frontend application. Follow these
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: In *Activity 1.01*, *Creating a Simple Page Count Application*, we built two
    Docker images – one for the frontend Pageview web app and another for the backend
    Redis datastore. You can use the skills we learned in this chapter to migrate
    them into Kubernetes YAMLs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Two pods (each managed by a Deployment) for the application is not enough. We
    also have to create the Service YAML to link them together.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure that the `targetPort` field in the manifest is consistent with the exposed
    port that was defined in the Redis image, which was `6379` in this case. In terms
    of the `port` field, theoretically, it can be any port, as long as it's consistent
    with the one specified in the Pageview application.
  prefs: []
  type: TYPE_NORMAL
- en: The other thing worth mentioning here is the `name` field of the pod for Redis
    datastore. It's the symbol that's used in the source code of the Pageview app
    to reference the Redis datastore.
  prefs: []
  type: TYPE_NORMAL
- en: Now, you should have three YAMLs – two pods and a Service. Apply them using
    `kubectl -f <yaml file name>`, and then use `kubectl get deploy,service` to ensure
    that they're created successfully.
  prefs: []
  type: TYPE_NORMAL
- en: At this stage, the Pageview app should function well since it's connected to
    the Redis app via the Service. However, the Service only works as the internal
    connector to ensure they can talk to each other inside the cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To access the Pageview app externally, we need to define a `NodePort` Service.
    Unlike the internal Service, we need to explicitly specify the `type` as `NodePort`.
  prefs: []
  type: TYPE_NORMAL
- en: Apply the external Service YAML using `kubectl -f <yaml file name>`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run `minikube service <external service name>` to fetch the Service URL.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Access the URL multiple times to ensure that the Pageview number gets increased
    by one each time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With that, we have successfully run the Pageview application in Kubernetes.
    But what if the Pageview app is down? Although Kubernetes can create a replacement
    pod automatically, there is still downtime between when the failure is detected
    and when the new pod is ready.
  prefs: []
  type: TYPE_NORMAL
- en: A common solution is to increase the replica number of the application so that
    the whole application is available as long as there is at least one replica running.
  prefs: []
  type: TYPE_NORMAL
- en: '**Running the Pageview App in Multiple Replicas**'
  prefs: []
  type: TYPE_NORMAL
- en: The Pageview app can certainly work with a single replica. However, in a production
    environment, high availability is essential and is achieved by maintaining multiple
    replicas across nodes to avoid single points of failure. (This will be covered
    in detail in upcoming chapters.)
  prefs: []
  type: TYPE_NORMAL
- en: 'In Kubernetes, to ensure the high availability of an application, we can simply
    increase the replica number. Follow these steps to do so:'
  prefs: []
  type: TYPE_NORMAL
- en: Modify the Pageview YAML to change `replicas` to `3`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply these changes by running `kubectl apply -f <pageview app yaml>`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By running `kubectl get pod`, you should be able to see three Pageview pods
    running.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Access the URL shown in the output of the `minikube service` command multiple
    times.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check the logs of each pod to see whether the requests are handled evenly among
    the three pods.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's verify the high availability of the Pageview app. Terminate any arbitrary
    pods continuously while keeping one healthy pod. You can achieve this manually
    or automatically by writing a script. Alternatively, you can open another terminal
    and check whether the Pageview app is always accessible.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you opt for writing scripts to terminate the pods, you will see results
    similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.29: Killing pods via a script'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_29.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.29: Killing pods via a script'
  prefs: []
  type: TYPE_NORMAL
- en: 'Assuming that you take a similar approach and write a script to check whether
    the application is online, you should see an output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.30: Repeatedly accessing the application via the script'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_02_30.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.30: Repeatedly accessing the application via the script'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution to this activity can be found at the following address: [https://packt.live/304PEoD](https://packt.live/304PEoD).'
  prefs: []
  type: TYPE_NORMAL
- en: A Glimpse into the Advantages of Kubernetes for Multi-Node Clusters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can only truly appreciate the advantages of Kubernetes after seeing it in
    the context of a multi-node cluster. This chapter, like many of the other chapters
    in this book, uses a single-node cluster (Minikube environment) to demonstrate
    the features that Kubernetes provides. However, in a real-world production environment,
    Kubernetes is deployed with multiple workers and master nodes. Only then can you
    ensure that a fault in a single node won't impact the general availability of
    the application. And reliability is just one of the many benefits that a multi-node
    Kubernetes cluster can bring to us.
  prefs: []
  type: TYPE_NORMAL
- en: But wait – isn't it true that we can implement applications and deploy them
    in a highly available manner *without using Kubernetes*? That's true, but that
    usually comes with a lot of management hassle, both in terms of managing the application
    as well as the infrastructure. For example, during the initial Deployment, you
    may have to intervene manually to ensure that all redundant containers are not
    running on the same machine. In the case of a node failure, you will have to not
    only ensure that a new replica is respawned properly but to guarantee high availability,
    you also need to ensure that the new one doesn't land on the nodes that are already
    running existing replicas. This can be achieved either by using a DevOps tool
    or injecting logic on the application side. However, either way is very complex.
    Kubernetes provides a unified platform that we can use to wire apps to proper
    nodes by describing the high availability features we want using Kubernetes primitives
    (API objects). This pattern frees the minds of application developers, as they
    only need to consider how to build their applications. Features that are required
    for high availability, such as failure detection and recovery, are taken care
    of by Kubernetes under the hood.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we used Minikube to provision a single-node Kubernetes cluster
    and gave a high-level overview of Kubernetes' core components, as well as its
    key design rationale. After that, we migrated an existing Docker container to
    Kubernetes and explored some basic Kubernetes API objects, such as pods, Services,
    and Deployments. Lastly, we intentionally broke a Kubernetes cluster and restored
    it one component at a time, which allowed us to understand how the different Kubernetes
    components work together to get a pod up and running on a node.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this chapter, we have used kubectl to manage our cluster. We provided
    a quick introduction to this tool, but in the following chapter, we will take
    a closer look at this powerful tool and explore the various ways in which we can
    use it.
  prefs: []
  type: TYPE_NORMAL
