- en: Chapter 5. Monitoring System Resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As the needs of your organization expand, your network will grow and change
    in order to match the growth. Keeping track of the resources on each node is extremely
    important for stability. While Linux handles resources exceptionally well, it
    can only do so much. CPUs can be overutilized, disks become full, and excessive
    input/output can halt even the strongest of servers. Keeping an eye on these things
    is very important, especially when systems are used in production and depended
    upon by others.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll look at ways to inspect what's running on your Linux
    systems and manage their resources to help ensure your nodes are good citizens
    on your network.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Inspecting and managing processes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding load average
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Checking available memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using shell-based resource monitors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Checking disk space
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scanning used storage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to logging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maintaining log size with logrotate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the systemd init system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the systemd journal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inspecting and managing processes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In a typical troubleshooting scenario, you might have a process that is misbehaving
    or needs an action performed against it. If you''re using a graphical desktop
    environment for a workstation, you might use a tool such as the GNOME System Monitor
    to investigate processes running on your system, and then kill the problem child.
    In most cases though, you probably won''t have a desktop environment (at least
    not on servers), so you would use a command such as `kill` in order to get rid
    of whatever process is misbehaving. But before you can kill a process, you''ll
    need to know its **process identifier** (**PID**). One method that works on all
    Linux systems to find the PID of a process is to open a terminal and us the `ps`
    command. Here''s an example of its usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Along with `ps`, it's common to use `grep` if you happen to already know the
    name of the process. In that case, you can pipe the output of `ps aux` into `grep`
    and then search for a process.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `ps` command will give you a list of running processes. If you used `grep`,
    the output would be narrowed down to a list of processes matching the search term.
    You'll see the `PID` located for each process that comes up in the results within
    the second column. In the third column, you'll see how much CPU the process is
    consuming, followed by a column for memory usage immediately after that.
  prefs: []
  type: TYPE_NORMAL
- en: '![Inspecting and managing processes](img/B03919_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Output of ps aux on a Debian system
  prefs: []
  type: TYPE_NORMAL
- en: '`USER`, `STAT`, `START`, `TIME`, and `COMMAND` are additional columns we can
    see from this output. While `USER` is self-explanatory, here''s a short description
    of the other column headers:'
  prefs: []
  type: TYPE_NORMAL
- en: '`STAT`: This field identifies the state of the program, with a one or two-character
    code representing the state the program is currently in. For example, `S` means
    that the process is waiting for some event to complete, while `D` is an uninterruptible
    sleep state, typically related to IO. To view a complete list, check out the manual
    page on `ps`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`START`: This field refers to the time at which the process began running.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TIME`: This indicates the total time the process has been utilizing the CPU.
    Every time a process hits the CPU and needs work done, time is logged against
    the CPU.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`COMMAND`: This displays the command that the current process is running.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now that you know how to find the PID of a process, we can take a look at the
    `kill` command, which is a command that''s useful in case you need to close a
    program that otherwise won''t close by normal means. For example, if you are running
    a script with a process ID 25787, you could kill it by executing the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The `kill` command works by sending a specific signal to a PID. Signal 15,
    for example, is known as **SIGTERM**. If you execute the `kill` against a process
    without any parameters (as we did in our last example), you''re sending signal
    15 by default, which basically asks politely for the process to close down. There
    are 18 different signals you can send to a process, which you can read about in
    the manual pages. For the sake of our discussion here, `SIGINT`, `SIGTERM`, and
    `SIGKILL` are the ones you''ll likely use the most. You can view a list of these
    signals, as well as their meanings, by executing the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'To send a specific signal, type a hyphen after the `kill` command followed
    by the signal you wish to send. Since `kill` by itself sends signal 15, you can
    do the same thing by executing the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'To send a different signal, such as 2 (**SIGINT**), type the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'If you''re *very* desperate, you could send signal 9 (**SIGKILL**) to the process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: However, `SIGKILL` should be used only if you've already exhausted all your
    other options, and you cannot get the process to close despite your best efforts.
    `SIGKILL` closes the process immediately, but unfortunately it does not give it
    a chance to clean up after itself. This may cause unclean temporary files and
    open socket connections to remain on your system. Worse, it can actually damage
    databases and configuration. Therefore, I cannot stress this enough, `kill -9`
    should definitely be the very last thing you try if you can't get a process to
    close out gracefully. Try every method you know to first close a process gracefully,
    and then make several more attempts before considering using it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another command that can be used to kill processes is the `killall` command.
    The `killall` command allows you to kill all the processes on your system which
    match a specific name. For example, let''s say you have multiple Firefox windows
    open and the program stops responding. To kill all instances of Firefox running
    on your system instantly, simply execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: And just like that, every Firefox window on your system will instantly vanish.
    The `killall` command can be used to close down multiple processes that all share
    the same name, and it can be very useful on servers which run multiple instances
    of a single unresponsive program or script.
  prefs: []
  type: TYPE_NORMAL
- en: That's pretty much all there is to using the `kill` and `killall` commands.
    Sure, there are more options and the man pages will give you more information.
    But in a nutshell, those are the variations you'll actually use. In a perfect
    world, you should never need to use `kill` and all processes running on your servers
    will obey you without question. Unfortunately, we don't live in a perfect world
    and you'll probably use these commands more often than you'd like.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding load average
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For a Linux administrator, **load average** is one of the most important concepts
    you''ll ever learn. While you may know already that this number represents how
    much load your system is experiencing, it also represents trending performance
    as well. Using this number, you''ll be able to determine whether your system is
    being overwhelmed or it''s recovering and calming down. Essentially, the load
    average consists of three numbers, each representing the average load of the system
    over a specific time frame. The first number represents one minute, the second
    represents five minutes, and the third represents 15 minutes. There are many ways
    in which you can view your load average, and it will also be displayed in most
    system monitors available for Linux. One way to view your load average in a snap
    is to execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![Understanding load average](img/B03919_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Viewing the load average
  prefs: []
  type: TYPE_NORMAL
- en: A simpler technique is to use the `uptime` command. Though the main purpose
    of the `uptime` command is to view how long your system has been up, it displays
    the system's load average as well.
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding load average](img/B03919_05_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The output of the uptime command
  prefs: []
  type: TYPE_NORMAL
- en: 'So, how does one properly interpret this information? With the screenshot of
    the uptime command shown in this section, we see the following numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: As mentioned, the first three numbers represent the system's load during a period
    of 1, 5, and 15 minutes respectively. The load that's being referred to represents
    the number of processes that are waiting on, or currently utilizing, the CPU during
    each timeframe. On the system used in this example, we can see that the load on
    it is relatively low. We can also see trends with load average as well. On the
    example system, the load is trending upward but just by a bit.
  prefs: []
  type: TYPE_NORMAL
- en: Generally speaking, the lower the load averages, the better. But that's not
    always the case; lower numbers can be disturbing too. For example, if you have
    a server that's supposed to be doing a lot of work and its load average drops
    down to being less than one, that may be a cause for alarm. If the load is that
    low, the server clearly isn't busy. This might represent that a process which
    is supposed to be running has failed. For example, if you have a MySQL server
    that normally sees hundreds of queries at a time, it would definitely be odd to
    see that the server was suddenly bored. On the flipside, a server with load average
    in the hundreds would be so busy it would be unlikely that it could even process
    a login request for you to even access the system!
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at another load average. Here''s one from a busier system
    on a network that I help manage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see that the load on this system is much higher than the previous
    example. This might be something I'll want to look into. But one confusing thing
    about a system's load average is that the number itself isn't enough to justify
    cause for alarm. If that system had ten cores, I wouldn't be so worried. Despite
    the load average being over nine, there would be plenty of CPU's to handle the
    workload in that case. However, the system I took that output from has only four
    cores, so it's a cause for alarm. It means that during each of the three time
    windows, there were more processes waiting for CPU time than the system actually
    has in cores. That's not good. But thankfully, I can see that the system is recovering
    since the load is trending downward. In this case, I won't panic but I'll certainly
    want to keep my eye on it to ensure that it continues to recover. I may also investigate
    the system to find out what exactly caused the load to spike up so high. Perhaps
    the server just finished a really big job, but it's worth looking into.
  prefs: []
  type: TYPE_NORMAL
- en: As a general rule of thumb, it's a good idea to record a baseline of your systems
    when they are under their normal, expected load. Each system on your network will
    have a designated purpose and each will have a certain load you can reasonably
    expect your system to face at any one time. If the systems load average dips too
    far below or climbs higher than the baseline, then you would want to take a look
    and find out what's going on. If the load reaches a level where there are more
    processes than you have cores to handle, that's cause for alarm.
  prefs: []
  type: TYPE_NORMAL
- en: Checking available memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Linux systems handle memory exceptionally well, though it's always possible
    for things to get out of hand if a process misbehaves or not enough memory was
    allocated. In such a situation where a system starts to perform sluggish, checking
    your available memory will probably be one of the first things you look into.
    To do this, we use the `free` command. To make the output even more readable,
    you can add the `-m` option, which shows your memory usage in terms of megabytes,
    which can make it much easier to read. Reading this output may be confusing at
    first, though I'm sure you'll find it straightforward after we go through the
    output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Checking available memory](img/B03919_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The output of the free command
  prefs: []
  type: TYPE_NORMAL
- en: When running the `free` command, we're presented with three rows and six columns
    of information. The first row shows us our actual RAM usage, while the second
    row declares buffers and the third our swap usage. Under `total`, we see that
    this system has 7923 MB of RAM installed. Technically, this system has 8 GB of
    RAM, though some is reserved for the kernel or some kind of hardware and may not
    show here. In the next column (`used`) we see how much of our system's RAM has
    been consumed, followed by `free` where it shows us how much of the system's RAM
    is unused. In our preceding example, it would appear as though we only have 927
    MB free of our 8 GB, but that's not exactly correct. So, how exactly does one
    interpret how much memory is actually free?
  prefs: []
  type: TYPE_NORMAL
- en: First, `used` on the first line corresponds to how much memory is actually being
    used, including what has been cached. Essentially, memory management in Linux
    declares what is known as a **disk cache**, which is a chunk of memory set aside
    for data that has yet to be written to disk. You can see this in our output of
    the `free -m` command; it's the number on the far right underneath `cached`. This
    memory is not necessarily being used by a process; it's declared in order to make
    your system run faster. If a process is started and it requires more RAM than
    what shows in the first line under `free`, the Linux kernel will happily give
    up memory from the disk cache to other processes as needed.
  prefs: []
  type: TYPE_NORMAL
- en: The disk cache helps increase performance. When you read something from the
    disk, it is stored in the disk cache, and then read from there instead of from
    the disk each time. For example, say you take a look at a text file saved in your
    `/home` directory several times each day. The first time you read it, you're reading
    it from the disk. From that point on, it's stored in disk cache, and accessed
    from there each time you wish to read the file from that point forward. Since
    RAM is faster than your disk, this file will open each additional time because
    it only has to read it from disk one time, then going forward its read from the
    disk cache.
  prefs: []
  type: TYPE_NORMAL
- en: The information stored within the disk cache ages out over time. As disk cache
    fills up, the oldest information stored there drops off to make room for other
    things. In addition, when memory is needed for processes, memory from the cache
    can be taken back at any time. This is why that even though it may appear that
    an excessive amount of RAM is being used up by the cache at times, it's not a
    big issue—applications are never prevented access to this memory when they need
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Going back to our example, the number we want to look at when determining how
    much memory we have free is the amount shown in the secondcolumn, on the second
    row. In the case of this example, 3736 MB is considered free. This is plenty of
    free memory in regards to this particular system. You should worry when this number
    decreases and swap starts to increase to compensate. As long as your system has
    enough RAM for its designated purpose, swap should barely be used. A small amount
    will almost always be used, but it is a problem when a large amount is being used.
    When your system actually does start to run out of memory, it will start to use
    your swap partition. Since your hard drive is many times slower than your RAM,
    you do not want this. If you see your swap space being abused, you should run
    some sort of resource monitor (a few of which we discuss in this chapter) to identify
    what is using it up.
  prefs: []
  type: TYPE_NORMAL
- en: To make sure we have a well-rounded understanding of the `free` command output,
    let's go over all of the sections it contains, starting with the very first row.
    We already covered `total`, which is the amount of memory your system has physically
    installed (minus whatever your kernel or hardware has reserved). Next in the first
    row, we have `used`, which refers to the amount of memory which is being used
    by anything at all, including the cache. The `free` column is the exact opposite
    and refers to memory that is not being used by anything whatsoever.
  prefs: []
  type: TYPE_NORMAL
- en: The last two items on the first row are `buffers` and `cache`. While these two
    sections aren't being used by any process, the kernel uses them to cache data
    for performance optimization. But if a process needs more memory, it's welcome
    to take from these two numbers. We already covered the disk cache, which is the
    last number. The `buffers` refer to data that hasn't yet been written to disk.
    Linux will, at various intervals, run a `sync` to write this information to the
    disk. You can even run the `sync` command yourself if you want, though this is
    rarely necessary. The concept of a buffer is also a key indicator on why you don't
    want to abruptly remove external media from your computer without unmounting first.
    If your system hasn't yet synced the data to the disk, you may lose it if you
    eject the media prematurely.
  prefs: []
  type: TYPE_NORMAL
- en: On the second row, we have `-/+ buffers cache` (which in our example above is
    4186 MB and 3736 MB, respectively). The first number on this row (4186 MB) is
    a number calculated by subtracting the total of buffers and cache (2808 MB) from
    the used column of the first row (6995 MB). This gives us a total of 4187 MB,
    which is a bit off due to rounding (we're viewing the output in MB since we used
    the `-m` flag, so we're off by a small amount), but close enough. If we followed
    the same math but without the `-m` flag in our `free` command, the result would've
    been exact. The next number on the second row is 3736 MB. As mentioned earlier,
    this is the amount of memory that is actually free for the system to use. To get
    this number, we subtract the used memory (4186 MB) from our total memory (7923
    MB).
  prefs: []
  type: TYPE_NORMAL
- en: Again, the amount of memory under `free` on the second row is the number you
    care about when wondering how much memory you have left. However, it's also important
    to understand how we arrived at this number and how Linux manages memory for us.
  prefs: []
  type: TYPE_NORMAL
- en: Using shell-based resource monitors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you install any Linux distribution with a desktop environment, chances
    are there will be a graphical system monitor bundled along with it. Popular among
    these are **KSysGuard** and the **GNOME System Monitor**, but there are many others.
    For the most part, these are fine and do the job well. The GNOME System Monitor
    is capable of showing you your load average, currently running processes (as well
    as their PID, CPU percent, memory, and more), and how much of your disks are being
    used. Many graphical system monitors also show this information and more. While
    these tools are great, nodes within a typical Linux-based network don't always
    have a graphical user interface available. Thankfully, there are many different
    resource monitoring tools available via the shell and they don't require that
    you're running a desktop environment at all. Some of these are so great that you'll,
    at some point, forego the graphical tools for the shell tools. Popular tools in
    this category include `top`, `htop`, `iotop`, and `ncdu`.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we would need to make sure the aforementioned tools are installed on
    our system. In most cases, `top` is already installed for us but the others will
    need to be installed manually. You can verify that `top` is installed by running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'You can use your distribution''s package manager to install the others. For
    Debian, you can install them all in one shot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Unfortunately, on CentOS, not all of these packages are available in the default
    repositories. To install these tools on CentOS, you''ll first need to add the
    `epel` repository, and then you can install all of the packages. The following
    outlines the commands to use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Feel free to give these tools a try. The `top` and `htop` commands will both
    run without root access. However, you'll need to run `iotop` with at least `sudo`
    for it to function. The `ncdu` command will function as a normal user, but would
    then be limited to viewing only the resources that user has access to. Let's take
    a closer look at these tools.
  prefs: []
  type: TYPE_NORMAL
- en: What do these tools do for us, anyway? First, `top` is tried and true; something
    that you've probably used before if you're not new to Linux. When it comes to
    seeing what's running on your system, `top` is quite common. With `top`, you'll
    see all kinds of information, such as uptime, load average, used memory, used
    swap, cache, and more. In the bottom section of the screen, you'll see a list
    of processes. When you're finished, simply press *Q* to exit.
  prefs: []
  type: TYPE_NORMAL
- en: '![Using shell-based resource monitors](img/B03919_05_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The top command running on a CentOS system
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several ways in which you can run `top`. By running `top` with no
    parameters, you''ll see a screen similar to what was shown earlier in this section.
    You will see a summary of system performance in the upper section and various
    processes in the bottom. However, if you already know which process you want to
    monitor, you can use the `-p` flag coupled with a PID to watch only that process.
    For example, we could use the following to monitor a process with a PID of `12844`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'By default, the output within the `top` command updates every three seconds.
    To change this, you can use the `-d` flag to choose a different frequency (in
    seconds):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'If you prefer, frequency can be less than a second:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: If `top` is already running and you would like to change how frequently it updates,
    you don't have to close it and start it up again. You can type `s` while it is
    running and you'll be prompted to designate a new frequency.
  prefs: []
  type: TYPE_NORMAL
- en: Within `top`, you can change how the process list is sorted by pressing a key
    on your keyboard. If you type `P`, you'll sort by CPU usage; using `M`, you can
    sort by memory usage (capitalization matters here). You can even kill a process
    from here if you wish, by pressing `k`, which will then prompt you for a PID to
    kill. Be careful though; this defaults to whatever happens to be at the top of
    your process list at the time you press it, so make sure that you don't press
    `Enter` until you've actually typed the PID or you may kill a process you didn't
    mean to.
  prefs: []
  type: TYPE_NORMAL
- en: So, why use `top` anyway? The main purpose that administrators use `top` for
    is to help determine what is causing a system to become CPU or memory bound. Most
    often, `top` is never the solution, but rather the beginning of a root cause analysis.
    You can immediately see which process is consuming your CPU or RAM, but depending
    on the context you may not have an idea yet on how to correct the problem. With
    `top`, you're only able to discover the culprit. Unfortunately, `top` may not
    always show you the root cause process, but it's definitely a very easy first
    place to look when you have a system that's running sluggish.
  prefs: []
  type: TYPE_NORMAL
- en: To begin your troubleshooting, the information at the top would give you a starting
    point to see which resource is being used up. On the `%Cpu(s)` line, we can tell
    immediately if the system is suffering from excessive **I/O wait** (the `%wa`
    field), which would basically mean there is more being thrown at the CPU than
    it's capable of handling. In this situation, tasks would back up and the load
    average would increase. Idle time (or `%id`) is a number that's better the higher
    it gets, which means your system would have CPU time to spare.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, you may find excessive CPU usage but not a lot in the process
    list to show for it. In such a case, you may bring up `iotop` in order to determine
    if your system is I/O bound. Using `iotop` (requires root) you can see just how
    much data is being written to or read from your disks. Using the left and right
    arrows, you can change focus from one column to another, which sorts the process
    list by that column.
  prefs: []
  type: TYPE_NORMAL
- en: '![Using shell-based resource monitors](img/B03919_05_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Running iotop on a Debian system
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, the list of processes within `iotop` is quite crowded. You can
    slim it down by executing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: By appending -`only`, you'll only see processes that have actual read and write
    operations occurring. In the `iotop` screenshot in this section, you can see that
    there are quite a few processes with no activity happening at all. But with `-only`,
    it may be easier to read since it cleans up the output. You can actually activate
    `-only` while `iotop` is running, by simply pressing *O* on your keyboard. In
    addition, another useful keyboard shortcut is the ability to change the sort order
    of any column with `r`.
  prefs: []
  type: TYPE_NORMAL
- en: Next in this section, we have `htop`. While `top` is the the tried and true
    standard for viewing system resources on a Linux system, `htop` is increasing
    in popularity very quickly.
  prefs: []
  type: TYPE_NORMAL
- en: '![Using shell-based resource monitors](img/B03919_05_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The htop command in action
  prefs: []
  type: TYPE_NORMAL
- en: The basic idea of `htop` is the same as `top`—the `top` area shows current CPU
    and memory usage and the bottom section provides a list of processes. But where
    `htop` differs is how it presents this information, which is easier to read and
    offers an area for graphs of your CPU's usage. In addition to that, it allows
    you to easily send a specific signal to a process. Earlier, we covered various
    signals you can use to end a process. Here, we can see that same concept illustrated
    graphically. To send a signal to a process, use the up and down arrows on your
    keyboard to highlight a process, and then press *F9* to choose a specific signal.
    `SIGTERM` is selected by default, but you can send any of the other signals to
    a process as well.
  prefs: []
  type: TYPE_NORMAL
- en: '![Using shell-based resource monitors](img/B03919_05_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Preparing to send a signal to a process in htop
  prefs: []
  type: TYPE_NORMAL
- en: The process list in `htop` can be sorted similar to `iotop`. One thing that
    may not be apparent at first is that `htop` supports mouse input. While you can
    select columns with arrow keys, you can also click on them.
  prefs: []
  type: TYPE_NORMAL
- en: Another benefit to `htop` is how customizable it is. Although the default layout
    is decent for most use cases, you can add additional meters. To do so, press *F2*
    or click on **Setup** and you'll be brought to a menu where you can add or remove
    meters from the current view. Under `Available Meters`, highlight one that you
    want to add and press *F5* to add it to the left column or *F6* to add it to the
    right column. One meter you may find useful is the `CPU average`. Once you've
    added a new meter, you can reposition it by highlighting it and pressing *F7*
    to move it up or *F8* to move it down. When finished, press *Esc* to return to
    the main screen. These changes are saved automatically, so the next time you open
    `htop`, your custom layout will be intact.
  prefs: []
  type: TYPE_NORMAL
- en: Scanning used storage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Almost everyone experiences a situation where disk space seems to vanish, with
    no clear indication as to what is taking up all the space. There are multiple
    ways in which you can troubleshoot what in particular is eating your hard drive
    space for breakfast. In order to see an overview of your mounted filesystems as
    well as their used and free space, execute the `df` command. Using `-h` with `df`
    is easier to read for most people, as it will show used space in MB and GB:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Armed with that information, you'll know exactly what device is being used up
    and what volumes to focus your attention on. But the `df` command doesn't actually
    tell you what is using up all the space; it only gives you an overview of the
    current situation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next up is `du`. The `du` command, which can also be paired with `-h` for the
    same reason, shows you how much space is being used in a directory. All you would
    need to do is to `cd` into the directory you wish to check, and then run `du -h`.
    For even easier to read output, run the following in a directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Breaking down that command, we have `-h` parameter that we already know makes
    the output easier to read. The `-s` parameter shows only a total and `-c` will
    present you with a grand total at the end. Since we used an asterisk with the
    command, it will run `du -hsc` against each subdirectory contained within the
    current one. With this command, you can determine which directories in your current
    working directory are using up the most space.
  prefs: []
  type: TYPE_NORMAL
- en: However, it gets even better than that. As useful as `du -hsc *` is, you still
    have to run it manually for each subdirectory. There are ways to use it to scan
    deeper, but `du` is only useful for an overview summary. An even better way is
    to install `ncdu`. The `ncdu` command is not a graphical utility in that it doesn't
    require a graphical desktop environment. But it's so easy to use; you may think
    that it actually was a graphical utility. Once kicked off against a particular
    directory, it does a deep dive and allows you to actually traverse the filesystem
    tree from that point and follow what is using up all your space straight down
    to the culprit.
  prefs: []
  type: TYPE_NORMAL
- en: 'You don''t need to be the root user or have `sudo` permission to utilize `ncdu`,
    but keep in mind `ncdu` can only scan directories that its calling user has permission
    to access. In some cases, you may need to run it as root to get around that. The
    basic usage of `ncdu` is simple; call `ncdu` along with a path for it to scan.
    For example, you can scan your entire filesystem or a section of it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '![Scanning used storage](img/B03919_05_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Scanning the root filesystem of a CentOS system with ncdu
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s important to note that by default `ncdu` will scan everything within
    the directory you give it, including anything that may be mounted. An example
    of this can be mounted NFS shares or external disks, but you may not want external
    mounts to factor into the results. Thankfully, this is as easy as presenting the
    `-x` option to `ncdu`, which tells it to ignore anything you have mounted when
    you run your scan:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Once the scan is finished, you can traverse the results by pressing up and down
    keys on your keyboard, and press *Enter* to change into a directory. From within
    `ncdu` itself, you can even delete files without having to run any extra commands
    by simply pressing *D*. This way, you can do your auditing and cleanup from the
    same tool.
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to run `ncdu` on your own systems and interrogate where your free
    space is going. Unless you actually start deleting things, it's harmless and can
    show you some potential items you may want to clean up. On actual servers, `ncdu`
    is quite useful in troubleshooting where your disk space is going.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By default, Linux logs almost everything. This is important for developing a
    root cause analysis when things go wrong. When you're faced with a problem on
    a production server, all you should need to do is determine the time in which
    the problem started and then read the log files for the types of things that happened
    on the system during that time. Linux logging is very informative.
  prefs: []
  type: TYPE_NORMAL
- en: But nowadays, the way that Linux handles logging is changing. With the rise
    of systemd, which is now the default init system on most Linux distributions,
    it's taken over almost everything, including logging. In the past, you would venture
    into `/var/log` whenever you wanted to read your logs, which is a directory containing
    various log files in plain text format. On both Debian and CentOS, you can still
    find logs in `/var/log`, so you'll still be able to utilize them for troubleshooting
    the same as we always have. But it's not yet certain how much longer this will
    be kept around.
  prefs: []
  type: TYPE_NORMAL
- en: Many might think that systemd taking over logging is a bad thing. After all,
    having the init system take care of so much of the system's upkeep gives it more
    work to perform, which may stretch it too thin. But one issue with syslog (the
    previous approach) is that there was no consistency from one distribution to another
    in how the logs were created or named. For example, Debian systems include an
    `auth.log`, which CentOS doesn't. Both have `dmesg` and only CentOS has a `boot.log`
    file. This makes troubleshooting a mixed environment, a beast.
  prefs: []
  type: TYPE_NORMAL
- en: The systemd approach (which we'll discuss later) offers a more consistent approach
    between distributions. So while it may be true that systemd is being spread thin
    with the multitude of responsibilities it has on the system, consistency is definitely
    welcome.
  prefs: []
  type: TYPE_NORMAL
- en: Both Debian and CentOS have a log file that is used whenever a user logs into
    the system, even if she or he does so via SSH. On CentOS, this log is located
    in `/var/log/secure`. Debian uses `/var/log/auth.log` for this purpose. If you
    need to know who is logging into your system and when, you would want to look
    at these logs in order to find out. On both, you can find `/var/log/messages`,
    which includes a smorgasbord of useful information, such as output from processes,
    network activation, services starting up, and more. When it comes to troubleshooting
    hardware, `/var/log/dmesg` is a great place to look. In fact, `/var/log/dmesg`
    has its own command. Typing `dmesg` from anywhere on the system (even if your
    current working directory isn't `/var/log`) will present you with the same log.
  prefs: []
  type: TYPE_NORMAL
- en: 'The log files in `/var/log` are very easy to follow in near real time by using
    `tail -f`. The `-f` flag of `tail` isn''t specifically limited to log files. It
    allows you to display the output of a log file, as it''s being written to. When
    you''re troubleshooting a system, `tail -f` is indispensable. For example, if
    you have a user that cannot log in to the system, you could run the following
    on a Debian system to watch the `auth.log` file as they make their attempt. That
    way, you can see what error message the system is registering for their failed
    attempts at logging in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: From there, as the `auth.log` gets updated, the results will show in your terminal
    immediately. To end, simply press *Ctrl* + *C* to stop following the output. You
    can do this with any log, or any text file on your system. This is very useful
    for a multitude of troubleshooting tactics, as most processes you may want to
    investigate will log its activities to at least one log.
  prefs: []
  type: TYPE_NORMAL
- en: Maintaining log size with logrotate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you know, logs are crucial when it comes to troubleshooting. Linux generally
    does a very good job of logging almost everything you would want to know, but
    over time these logs can really add up. On a production server, a log file growing
    out of control and taking up literally all of your server's free space is a very
    real issue if left unchecked. In addition to disk space being consumed, a gigantic
    log file is very hard to open in a text editor in order to view the contents,
    which makes troubleshooting even harder. A log file of over 500 GB would not only
    take up a ridiculous amount of space; it would likely cause the system to hang
    if you try to open it, and transferring a log file to another server for analysis
    once it reaches a very large size isn't practical either.
  prefs: []
  type: TYPE_NORMAL
- en: For the most part, excessive log files are not as much of an issue on newer
    Linux distributions than those of the past. With syslog, there was no automatic
    maintenance. If you didn't either clean the logs yourself or set up something
    to rotate them for you, you would definitely need to keep an eye on them. Nowadays,
    **journald** handles this for us. But with Debian and CentOS, this can be somewhat
    of a mixed bag. This is because although the systemd journald takes care of logging
    for us on newer releases of most popular Linux distributions, syslog is still
    used for compatibility. Therefore, we still have to deal with log rotation even
    though all the pieces are in place for journald. The journald is the future, though
    syslog is still used on Enterprise Linux distributions today for compatibility.
  prefs: []
  type: TYPE_NORMAL
- en: Log rotation is the process of taking an existing log file, renaming it, and
    having the process write to a brand-new empty log file. The previous log files
    can all be kept, or you can keep only a few of them if you wish. It's not uncommon
    for Enterprise systems to have a specific retention policy. It's a common practice
    to compress previous logs, which saves a great amount of disk space. This is where
    logrotate comes in. It's a process that we can run on our server to automatically
    swap out our log files and (as an option) compress the backup copies.
  prefs: []
  type: TYPE_NORMAL
- en: While designing a Linux network, it's important to understand which processes
    each server needs to run and to take into account the logging requirements of
    those processes from the start. Having logrotate installed and configured before
    a server enters production is a good practice. Having a server run out of free
    space in the middle of production is never a good experience, and knowing first
    what log files a running process creates, and being prepared to handle them is
    a good idea. While configuring your logging, it's important to take into consideration
    the retention requirements of your company, if there are any.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the CentOS system used in my lab, `logrotate` was installed by default.
    Debian had it installed out of the box as well. To verify this on your system,
    simply run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: On CentOS, the `logrotate` binary is located in `/usr/sbin`, while Debian stores
    theirs in `/usr/sbin`. If the `which` command shows no output, you may need to
    use your distribution's package manager to install the `logrotate` package.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the default installations of both Debian and CentOS, `logrotate` is already
    configured to run each day. When it does, it checks the `/etc/logrotate.d` directory
    for instructions and then executes them. The configuration for setting up `logrotate`
    rules is fairly straightforward. If you need example syntax, refer to your own
    system. By default, several `logrotate` scripts are created for you. An example
    of this is Debian''s package manager `apt`. Whenever you install packages on a
    Debian system, it''s logged in the following place:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'If you view this file, you should see results of recent package installations
    that you or another user has performed. By default, the following file exists
    on Debian systems to handle the rotation of this log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'On Debian 8, this file contains the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, this configuration file for `logrotate` handles not only the
    `history.log` we mentioned earlier, but also `term.log` as well. Each section
    of this configuration begins with a path for `logrotate` to check, followed by
    individual options within brackets.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `term.log` file shows the actual terminal output that would've been seen
    while running an apt instance.
  prefs: []
  type: TYPE_NORMAL
- en: Among the options, we can see `rotate 12`, which means that up to 12 backup
    log files will be kept. Next, we see `monthly`, which details how often the log
    will actually be rotated. Despite the fact that `logrotate` is configured by default
    to run daily, it will follow the instructions contained within the individual
    configurations and only rotate if it meets that criteria. The `compress` option
    tells `logrotate` to compress the backed up file, which is probably what you want
    in most cases. Compressed log files use up very little space compared to the uncompressed
    live log, so it's definitely something to consider. `missingok` tells `logrotate`
    to keep running even if it encounters a missing log file. Otherwise, it would've
    displayed an error. Finally, we have `notifempty`, which simply tells `logrotate`
    to not bother with a log file if it is empty.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can see a complete list of `logrotate` configuration options by perusing
    its man page:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: While `logrotate` has some fairly decent default configuration for some of the
    services that ship with CentOS and Debian, you'll want to consider creating configuration
    for any new services that you set up. To do so, it's easiest to follow the format
    shown in example files that you'll already have stored in `/etc/logrotate.d`.
    It's as simple as beginning your configuration block with the path to a file you
    want `logrotate` to handle for you, followed by options within curly brackets.
    There's no service to restart or special command to make your new configuration
    active. The next time that `logrotate` runs, it will check the `/etc/logrotate.d`
    directory for new configurations and run them if there are no errors.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the systemd init system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: On quite a few Linux distributions these days, the init system has been switched
    to systemd. This is true of Debian and CentOS starting with Version 8 and 7, respectively,
    but other distributions such as Fedora, Ubuntu, Arch Linux, and others have switched
    as well. Although some administrators prefer sysvinit, which was the previous
    dominant init system, systemd offers quite a few advancements over older systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'With systemd, commands you would use to start processes are now different,
    though the majority of the older commands still work (for now). With sysvinit
    on a Debian 7 system, you would use the following command to restart Samba:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'However, with systemd, we now use `systemctl` to `start`, `stop`, or `restart`
    a process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The sysvinit style of managing processes was the same in CentOS and Debian,
    and it is still the same now. At the time of this writing, both have switched
    to systemd. But the older `/etc/init.d/<process-name> restart|stop|start` commands
    still work in both Debian and CentOS with current releases, but instead of using
    sysvinit (which is gone) the commands are just translated to systemd commands
    instead. If you were to run the older sysvinit style commands, you'll likely see
    some text in the output informing you that the system is using `systemctl` instead.
    While this is great for the sake of compatibility (scripts relying on sysvinit
    style commands will likely still work), this won't be around forever. Learning
    systemd is important as once the sysvinit compatibility layer is removed, you'll
    no longer be able to rely on the older method. Thankfully, the basics of systemd
    are quick to learn.
  prefs: []
  type: TYPE_NORMAL
- en: To start a process with systemd, execute `systemctl` followed by the action
    you want to perform, followed by the process you would like to perform the action
    on. As we've done earlier with Samba, we executed `systemctl restart samba`. But
    we can also stop samba using `systemctl stop samba`, or we can start it by executing
    `systemctl start samba` as root.
  prefs: []
  type: TYPE_NORMAL
- en: 'The systemd init system also allows you to enable or disable a process. A process
    which is enabled will be started as the system is booted. A disabled process will
    only start if you do so manually. Depending on the distribution, processes (or
    units, as systemd calls them) may not be enabled by default. On CentOS, for example,
    you can install Samba, but it won''t start automatically unless you tell it to
    do so. On Debian systems, it''s largely assumed that since you installed something,
    you probably want it to run, so it will enable the newly installed process by
    default. Either way, it''s not a good idea to assume that a process will automatically
    start with systemd. To find out, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '![Understanding the systemd init system](img/B03919_05_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Checking the status of a unit with systemctl
  prefs: []
  type: TYPE_NORMAL
- en: Checking the status with `systemctl` gives you a great deal of useful information,
    typically more than checking the status of processes with sysvinit. First, you
    can see whether or not a unit is running. In the previous screenshot, we can see
    that `nfs-kernel-server` is running. In addition, status gives us a few lines
    of log output as well, so if there are any problems starting a unit we may find
    the error right there.
  prefs: []
  type: TYPE_NORMAL
- en: 'You might be wondering how to find out whether or not a unit is configured
    to come up automatically when the system is booted. Systemd makes that easy as
    well. We can use `is-enabled` with `systemctl` in order to find out if the unit
    is enabled. For example, to ensure the `ssh` daemon is configured to automatically
    start, we would issue the following command on a Debian system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'To show all the units on your system and how they''re configured, run the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: To enable a unit, pass `enable` as a parameter to `systemctl`. Similarly, you
    can do the same with `disable` to ensure a unit does not start at boot. Therefore,
    on a Debian system, `systemctl enable ssh` would configure the `ssh` daemon to
    start at boot, while `systemctl disable ssh` would ensure that it doesn't. CentOS
    would be the same, but substitute `sshd` for `ssh`. While the differing unit names
    can be annoying between Linux systems, always remember that you can use `systemctl
    list-unit-files` as mentioned earlier to see a list of the units registered to
    your system and what they're named.
  prefs: []
  type: TYPE_NORMAL
- en: In a nutshell, that's pretty much all the knowledge required to use `systemctl`
    to manage processes (units) on your Linux system. For the most part, starting,
    stopping, enabling, and disabling units covers most use cases. For more advanced
    usage, see the man page for `systemctl`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Systemd handles power management as well. You can use options such as `reboot`,
    `poweroff`, and `suspend` with `systemctl` to power on, shut down, or suspend
    the entire system.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the systemd journal
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another component of systemd is journald, which handles logging. The systemd
    method of journald enables binary logs, which is quite a different approach to
    simple text files as used before. Due to the fact that many distributions which
    have adopted systemd are still in a transitional phase, you're likely to still
    see text file logs in `/var/log` in much the same way as you still may see init
    scripts in `/etc/init.d`. It's always recommended to use the systemd approach
    whenever possible, as that is the current solution that distributions are moving
    toward.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can view journald logs with the `journalctl` command. In addition, various
    options can be used with the `journalctl` command in order to narrow down the
    output or perform certain actions. For example, you can use `journalctl -f` to
    follow new log output on your system, similar to how you could do the same with
    `tail -f` against log files stored in `/var/log`. Additionally, you can use `journalctl`
    to show output from a particular PID. To do so, simply use `journalctl` with `PID=`
    along with a PID. For example, to view output from PID `11753`, you would execute
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition, you can use the name of the unit to show its output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: While `journalctl` is relatively simple to use, for those of you that are accustomed
    to the pervious syslog style of logging will be happy to know that you can (at
    least for now) still navigate to `/var/log` and peruse the logs there. For example,
    the `dmesg` command and log is still alive and well. But while `journalctl` and
    the concept of binary logs may take a while to get used to, I'm sure you'll find
    with practice that it is actually very handy.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered various ways in which you can manage your system's
    resources and look at logs. We started with an overview of managing processes
    and discussed load averages. Then, we covered monitoring a system's memory. In
    addition, we looked at shell-based system monitors such as `top` and `htop`. We
    also covered investigating disk usage and `ncdu`, which is a neat tool that allows
    you to scan a filesystem and view its usage in an easy to use way. We also covered
    `logrotate` and `systemd`.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll take a look at managing our Linux-based network.
    This will include things such as configuring DHCP, DNS, NTP, as well as using
    `exim` to send e-mail and advertising shared services over the network.
  prefs: []
  type: TYPE_NORMAL
