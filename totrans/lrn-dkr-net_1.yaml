- en: Chapter 1. Docker Networking Primer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Docker** is a lightweight container technology that has gathered enormous
    interest in recent years. It neatly bundles various Linux kernel features and
    services, such as namespaces, cgroups, SELinux, and AppArmor profiles, over union
    filesystems such as AUFS and BTRFS in order to make modular images. These images
    provide a highly configurable virtualized environment for applications and follow
    a **write once, run anywhere** workflow. An application can be composed of a single
    process running in a Dcker container or it could be made up of multiple processes
    running in their own containers and being replicated as the load increases. Therefore,
    there is a need for powerful networking elements that can support various complex
    use cases.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will learn about the essential components of Docker networking
    and how to build and run simple container examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Networking and Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `docker0` bridge networking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker OVS networking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unix domain networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linking Docker containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What's new in Docker networking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Docker is getting a lot of traction in the industry because of its performance-savvy
    and universal replicability architecture, while providing the following four cornerstones
    of modern application development:'
  prefs: []
  type: TYPE_NORMAL
- en: Autonomy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decentralization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parallelism
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Isolation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Furthermore, wide-scale adoption of Thoughtworks's microservices architecture,
    or **LOSA** (**Lots of Small Applications**), is further bringing potential to
    Docker technology. As a result, big companies such as Google, VMware, and Microsoft
    have already ported Docker to their infrastructure, and the momentum is continued
    by the launch of myriad Docker start-ups, namely Tutum, Flocker, Giantswarm, and
    so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since Docker containers replicate their behavior anywhere, be it your development
    machine, a bare metal server, virtual machine, or data center, application designers
    can focus their attention on development, while operational semantics are left
    with DevOps. This makes team workflow modular, efficient, and productive. Docker
    is not to be confused with a **virtual machine** (**VM**), even though they are
    both virtualization technologies. While Docker shares an OS with providing a sufficient
    level of isolation and security to applications running in containers, it later
    completely abstracts away the OS and gives strong isolation and security guarantees.
    However, Docker''s resource footprint is minuscule in comparison to a VM and hence
    preferred for economy and performance. However, it still cannot completely replace
    VMs and is therefore complementary to VM technology. The following diagram shows
    the architecture of VMs and Docker:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Docker Networking Primer](../images/00002.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Networking and Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Each Docker container has its own network stack, and this is due to the Linux
    kernel NET namespace, where a new NET namespace for each container is instantiated
    and cannot be seen from outside the container or from other containers.
  prefs: []
  type: TYPE_NORMAL
- en: Docker networking is powered by the following network components and services.
  prefs: []
  type: TYPE_NORMAL
- en: Linux bridges
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: These are L2/MAC learning switches built into the kernel and are to be used
    for forwarding.
  prefs: []
  type: TYPE_NORMAL
- en: Open vSwitch
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is an advanced bridge that is programmable and supports tunneling.
  prefs: []
  type: TYPE_NORMAL
- en: NAT
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Network address translators are immediate entities that translate IP addresses
    and ports (SNAT, DNAT, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: IPtables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is a policy engine in the kernel used for managing packet forwarding, firewall,
    and NAT features.
  prefs: []
  type: TYPE_NORMAL
- en: AppArmor/SELinux
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Firewall policies for each application can be defined with these.
  prefs: []
  type: TYPE_NORMAL
- en: 'Various networking components can be used to work with Docker, providing new
    ways to access and use Docker-based services. As a result, we see a lot of libraries
    that follow a different approach to networking. Some of the prominent ones are
    Docker Compose, Weave, Kubernetes, Pipework, libnetwork, and so on. The following
    figure depicts the root ideas of Docker networking:'
  prefs: []
  type: TYPE_NORMAL
- en: '![AppArmor/SELinux](../images/00003.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The docker0 bridge
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `docker0` bridge is the heart of default networking. When the Docker service
    is started, a Linux bridge is created on the host machine. The interfaces on the
    containers talk to the bridge, and the bridge proxies to the external world. Multiple
    containers on the same host can talk to each other through the Linux bridge.
  prefs: []
  type: TYPE_NORMAL
- en: '`docker0` can be configured via the `--net` flag and has, in general, four
    modes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--net default`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--net=none`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--net=container:$container2`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--net=host`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The --net default mode
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this mode, the default bridge is used as the bridge for containers to connect
    to each other.
  prefs: []
  type: TYPE_NORMAL
- en: The --net=none mode
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With this mode, the container created is truly isolated and cannot connect to
    the network.
  prefs: []
  type: TYPE_NORMAL
- en: The --net=container:$container2 mode
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With this flag, the container created shares its network namespace with the
    container called `$container2`.
  prefs: []
  type: TYPE_NORMAL
- en: The --net=host mode
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With this mode, the container created shares its network namespace with the
    host.
  prefs: []
  type: TYPE_NORMAL
- en: Port mapping in Docker container
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we look at how container ports are mapped to host ports. This
    mapping can either be done implicitly by Docker Engine or can be specified.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we create two containers called **Container1** and **Container2**, both
    of them are assigned an IP address from a private IP address space and also connected
    to the **docker0** bridge, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Port mapping in Docker container](../images/00004.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Both the preceding containers will be able to ping each other as well as reach
    the external world.
  prefs: []
  type: TYPE_NORMAL
- en: For external access, their port will be mapped to a host port.
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned in the previous section, containers use network namespaces. When
    the first container is created, a new network namespace is created for the container.
    A vEthernet link is created between the container and the Linux bridge. Traffic
    sent from `eth0` of the container reaches the bridge through the vEthernet interface
    and gets switched thereafter. The following code can be used to show a list of
    Linux bridges:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be similar to the one shown as follows, with a bridge name
    and the `veth` interfaces on the containers it is mapped to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'How does the container connect to the external world? The `iptables nat` table
    on the host is used to masquerade all external connections, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: How to reach containers from the outside world? The port mapping is again done
    using the `iptables nat` option on the host machine.
  prefs: []
  type: TYPE_NORMAL
- en: '![Port mapping in Docker container](../images/00005.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Docker OVS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Open vSwitch is a powerful network abstraction. The following figure shows
    how OVS interacts with the **VM**s, **Hypervisor**, and the **Physical Switch**.
    Every **VM** has a **vNIC** associated with it. Every **vNIC** is connected through
    a **VIF** (also called a **virtual interface**) with the **Virtual Switch**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Docker OVS](../images/00006.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'OVS uses tunnelling mechanisms such as GRE, VXLAN, or STT to create virtual
    overlays instead of using physical networking topologies and Ethernet components.
    The following figure shows how OVS can be configured for the containers to communicate
    between multiple hosts using GRE tunnels:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Docker OVS](../images/00007.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Unix domain socket
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Within a single host, UNIX IPC mechanisms, especially UNIX domain sockets or
    pipes, can also be used to communicate between containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Apps on `c1` and `c2` can communicate over the following Unix socket address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '| C1: Server.c | C2: Client.c |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Linking Docker containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we introduce the concept of linking two containers. Docker
    creates a tunnel between the containers, which doesn't need to expose any ports
    externally on the container. It uses environment variables as one of the mechanisms
    for passing information from the parent container to the child container.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the environment variable `env`, Docker also adds a host entry
    for the source container to the `/etc/hosts` file. The following is an example
    of the host file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'There are two entries:'
  prefs: []
  type: TYPE_NORMAL
- en: The first is an entry for the container `c2` that uses the Docker container
    ID as a host name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second entry, `172.17.0.2 c1alaias 6e5cdeb2d300 c1`, uses the `link` alias
    to reference the IP address of the `c1` container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following figure shows two containers **Container 1** and **Container 2**
    connected using veth pairs to the `docker0` bridge with `--icc=true`. This means
    these two containers can access each other through the bridge:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Linking Docker containers](../images/00008.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Links
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Links provide service discovery for Docker. They allow containers to discover
    and securely communicate with each other by using the flag `-link name:alias`.
    Inter-container communication can be disabled with the daemon flag `-icc=false`.
    With this flag set to `false`, **Container 1** cannot access **Container 2** unless
    explicitly allowed via a link. This is a huge advantage for securing your containers.
    When two containers are linked together, Docker creates a parent-child relationship
    between them, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Links](../images/00009.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'From the outside, it looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'On the inside, it looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: What's new in Docker networking?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker networking is at a very nascent stage, and there are many interesting
    contributions from the developer community, such as Pipework, Weave, Clocker,
    and Kubernetes. Each of them reflects a different aspect of Docker networking.
    We will learn about them in later chapters. Docker, Inc. has also established
    a new project where networking will be standardized. It is called **libnetwork**.
  prefs: []
  type: TYPE_NORMAL
- en: libnetwork implements the **container network model** (**CNM**), which formalizes
    the steps required to provide networking for containers while providing an abstraction
    that can be used to support multiple network drivers. The CNM is built on three
    main components—sandbox, endpoint, and network.
  prefs: []
  type: TYPE_NORMAL
- en: Sandbox
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A sandbox contains the configuration of a container's network stack. This includes
    management of the container's interfaces, routing table, and DNS settings. An
    implementation of a sandbox could be a Linux network namespace, a FreeBSD jail,
    or other similar concept. A sandbox may contain many endpoints from multiple networks.
  prefs: []
  type: TYPE_NORMAL
- en: Endpoint
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An endpoint connects a sandbox to a network. An implementation of an endpoint
    could be a veth pair, an Open vSwitch internal port, or something similar. An
    endpoint can belong to only one network but may only belong to one sandbox.
  prefs: []
  type: TYPE_NORMAL
- en: Network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A network is a group of endpoints that are able to communicate with each other
    directly. An implementation of a network could be a Linux bridge, a VLAN, and
    so on. Networks consist of many endpoints, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Network](../images/00010.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The Docker CNM model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The CNM provides the following contract between networks and containers:'
  prefs: []
  type: TYPE_NORMAL
- en: All containers on the same network can communicate freely with each other
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple networks are the way to segment traffic between containers and should
    be supported by all drivers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple endpoints per container are the way to join a container to multiple
    networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An endpoint is added to a network sandbox to provide it with network connectivity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will discuss the details of how CNM is implemented in [Chapter 6](part0043_split_000.html#190861-2d417e3c905d4b6c9e03acfd1355cc86
    "Chapter 6. Next Generation Networking Stack for Docker: libnetwork"), *Next Generation
    Networking Stack for Docker: libnetwork*.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about the essential components of Docker networking,
    which have evolved from coupling simple Docker abstractions and powerful network
    components such as Linux bridges and Open vSwitch.
  prefs: []
  type: TYPE_NORMAL
- en: We learned how Docker containers can be created with various modes. In the default
    mode, port mapping helps through the use of iptables NAT rules, allowing traffic
    arriving at the host to reach containers. Later in the chapter, we covered the
    basic linking of containers. We also talked about the next generation of Docker
    networking, which is called libnetwork.
  prefs: []
  type: TYPE_NORMAL
