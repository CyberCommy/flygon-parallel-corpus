- en: '*Chapter 13*: Backing Up Workloads'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Accidents and disasters happen, and just like you may have insurance for these
    events in real life, you should have insurance for your cluster and the workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Most Kubernetes distributions do not include any components to back up workloads,
    but there are a number of products available from both the open source community
    and vendor-supported solutions from companies such as Kasten.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will be introduced to Velero, which can be used to back
    up workloads in the cluster. We will explain how to use Velero to back up namespaces
    and schedule backup jobs, as well as how to restore workloads.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Kubernetes backups
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing an etcd backup
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing and setting up Heptio's Velero
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Velero to back up workloads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing Velero using the CLI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Restoring from a backup
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To perform the hands-on experiments in this chapter, you will need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A KinD Kubernetes cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A new Ubuntu 18.04 server with a minimum of 4 GB of RAM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can access the code for this chapter at the following GitHub repository:
    [https://github.com/PacktPublishing/Kubernetes-and-Docker-The-Complete-Guide](https://github.com/PacktPublishing/Kubernetes-and-Docker-The-Complete-Guide).'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Kubernetes backups
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Backing up a Kubernetes cluster requires backing up not only the workloads running
    on the cluster but also the cluster itself. Remember that the cluster state is
    maintained in an etcd database, making it a very important component that you
    need to back up to recover from any disasters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating a backup of the cluster and the running workloads allows you to do
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Migrate clusters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a development cluster from a production cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recover a cluster from a disaster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recover data from persistent volumes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Namespace and deployment recovery.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will provide the details and tools to back up your etcd
    database and every namespace and object in the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: Recovering a cluster from a complete disaster in an enterprise usually involves
    backing up custom SSL certificates for various components, such as Ingress controllers,
    load-balancers, and the API server.
  prefs: []
  type: TYPE_NORMAL
- en: Since the process to back up all custom components is different for all environments,
    we will focus on the procedures that are common among most Kubernetes distributions.
  prefs: []
  type: TYPE_NORMAL
- en: As you know, the cluster state is maintained in etcd, and if you lose all of
    your etcd instances, you will lose your cluster. In a multi-node control plane,
    you would have a minimum of three etcd instances, providing redundancy for the
    cluster. If you lose a single instance, the cluster would remain running and you
    could build a new instance of etcd and add it to the cluster. Once the new instance
    has been added, it will receive a copy of the etcd database and your cluster will
    be back to full redundancy.
  prefs: []
  type: TYPE_NORMAL
- en: In the event that you lost all of your etcd servers without any backup of the
    database, you would lose the cluster, including the cluster state itself and all
    of the workloads. Since etcd is so important, the **etcdctl** utility includes
    a built-in backup function.
  prefs: []
  type: TYPE_NORMAL
- en: Performing an etcd backup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since we are using KinD for our Kubernetes cluster, we can create a backup of
    the etcd database, but we will not be able to restore it.
  prefs: []
  type: TYPE_NORMAL
- en: Our etcd server is running in a pod on the cluster called **etcd-cluster01-control-plane**,
    located in the **kube-system** namespace. The running container includes the **etcdctl**
    utility, and we can execute a backup using **kubectl** commands.
  prefs: []
  type: TYPE_NORMAL
- en: Backing up the required certificates
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Most Kubernetes installations store certificates in **/etc/kuberetes/pki**.
    In this respect, KinD is no different, so we can back up our certificates using
    the **docker cp** command. Let''s see how to do this in two simple steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will create a directory to store the certificates and the etcd database.
    Change your directory to the **chapter13** folder where you cloned the book repository.
    Under the **chapter13** folder, create a directory named **backup** and make it
    your current path:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**mkdir backup cd ./backup**'
  prefs: []
  type: TYPE_NORMAL
- en: 'To back up the certificates located on the API server, use the following **docker
    cp** command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**docker cp cluster01-control-plane:/etc/kubernetes/pki ./**'
  prefs: []
  type: TYPE_NORMAL
- en: This will copy the contents of the **pki** folder on the control plane node
    to your **localhost** in a new folder in the **chapter13/backup/pki** folder.
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to create a backup of the etcd database.
  prefs: []
  type: TYPE_NORMAL
- en: Backing up the etcd database
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To back up the etcd database on your KinD cluster, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: Older versions of **etcdctl** required you to set the API version to 3 using
    **ETCDCTL_API=3**, since they defaulted to the version 2 API. Etcd 3.4 changed
    the default API to 3, so we do not need to set that variable before using **etcdctl**
    commands.
  prefs: []
  type: TYPE_NORMAL
- en: 'Back up the database in the etcd pod and store it in the container''s root
    folder. Using **kubectl exec**, run a shell on the etcd pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**kubectl exec -it etcd-cluster01-control-plane /bin/sh -n kube-system**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the etcd pod, back up the etcd database using **etcdctl**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**etcdctl snapshot save etcd-snapshot.db --endpoints=https://127.0.0.1:2379
    --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/healthcheck-client.crt
    --key=/etc/kubernetes/pki/etcd/healthcheck-client.key**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You will receive the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '**{"level":"info","ts":1591637958.297016,"caller":"snapshot /v3_snapshot.go:110","msg":"created
    temporary db file","path":"etcd-snapshot.db.part"}**'
  prefs: []
  type: TYPE_NORMAL
- en: '**{"level":"warn","ts":"2020-06-08T17:39:18.323Z","caller":"clientv3/retry_interceptor.go:116","msg":"retry
    stream intercept"}**'
  prefs: []
  type: TYPE_NORMAL
- en: '**{"level":"info","ts":1591637958.3238735,"caller":"snapshot/v3_snapshot.go:121","msg":"fetching
    snapshot","endpoint":"https://127.0.0.1:2379"}**'
  prefs: []
  type: TYPE_NORMAL
- en: '**{"level":"info","ts":1591637958.7283804,"caller":"snapshot/v3_snapshot.go:134","msg":"fetched
    snapshot","endpoint":"https://127.0.0.1:2379","took":0.431136053}**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Snapshot saved at etcd-snapshot.db**'
  prefs: []
  type: TYPE_NORMAL
- en: '**{"level":"info","ts":1591637958.732125,"caller":"snapshot /v3_snapshot.go:143","msg":"saved","path":"etcd-snapshot.db"}**'
  prefs: []
  type: TYPE_NORMAL
- en: Exit the etcd pod.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Copy the backup to your local machine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**kubectl cp kube-system/etcd-cluster01-control-plane:etcd-snapshot.db ./etcd-snap-kind.db**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Verify that the copy was successful by viewing the contents of the current
    folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ls -la
  prefs: []
  type: TYPE_NORMAL
- en: You should see the **pki** directory and the etcd backup, **etcd-snap-kind.db**.
    If you do not see your backup, repeat the steps again and watch for any errors
    in the output.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, this process only backs up the etcd database once. In the real world,
    you should create a scheduled process that executes a snapshot of etcd at regular
    intervals and stores the backup file in a safe, secure location.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Due to how KinD runs the control plane, we cannot use the restore procedures
    in this section. We are providing the steps in this section so that you know how
    to restore a corrupt etcd database or node in an enterprise environment.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing and setting up Heptio's Velero
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Velero is an open source backup solution for Kubernetes from Heptio. It offers
    many features that are only available in commercial products, including scheduling,
    backup hooks, and granular backup controls – all for no charge.
  prefs: []
  type: TYPE_NORMAL
- en: While Velero is free, it has a learning curve since it does not include an easy-to-use
    GUI like most commercial products. All operations in Velero are carried out using
    their command-line utility, an executable called **velero**. This single executable
    allows you to install the Velero server, create backups, check the status of backups,
    restore backups, and more. Since every operation for management can be done with
    one file, restoring a cluster's workloads becomes a very easy process. In this
    chapter, we will create a second KinD cluster and populate it with a backup from
    an existing cluster.
  prefs: []
  type: TYPE_NORMAL
- en: But before that, we need to take care of a few requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Velero requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Velero consists of a few components to create a backup system:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Velero CLI**: This provides the installation of Velero components. It
    is used for all backup and restore functions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The Velero server**: Responsible for executing backing up and restore procedures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Storage provider plug-ins**: Used for backup and restoring specific storage
    systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Outside of the base Velero components, you will also need to provide an object
    storage location that will be used to store your backups. If you do not have an
    object storage solution, you can deploy MinIO, which is an open source project
    that provides an S3-compatible object store. We will deploy MinIO in our KinD
    cluster to demonstrate the backup and restore features provided by Velero.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the Velero CLI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first step to deploy Velero is to download the latest Velero CLI binary.
    To install the CLI, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the release from Velero''s GitHub repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**wget  https://github.com/vmware-tanzu/velero/releases/download/v1.4.0/velero-v1.4.0-linux-amd64.tar.gz**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Extract the contents of the archive:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**tar xvf velero-v1.4.0-linux-amd64.tar.gz**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Move the Velero binary to **/usr/bin**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**sudo mv velero-v1.4.0-linux-amd64/velero /usr/bin**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Verify that you can run the Velero CLI by checking the version:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**velero version**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You should see from the output from Velero that you are running version 1.4.0:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.1 – Velero client version output'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Fig_13.1_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 13.1 – Velero client version output
  prefs: []
  type: TYPE_NORMAL
- en: You can safely ignore the last line, which shows an error in finding the Velero
    server. Right now, all we have installed is the Velero executable, so we will
    install the server in the next step.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Velero
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Velero has minimal system requirements, most of which are easily met:'
  prefs: []
  type: TYPE_NORMAL
- en: A Kubernetes cluster running version 1.10 or higher
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Velero executable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Images for the system components
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A compatible storage location
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A volume snapshot plugin (optional)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Depending on your infrastructure, you may not have a compatible location for
    the backups or snapshotting volumes. Fortunately, if you do not have a compatible
    storage system, there are open source options that you can add to your cluster
    to meet the requirements.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will explain the natively supported storage options
    and since our example will use a KinD cluster, we will install open source options
    to add compatible storage to use as a backup location.
  prefs: []
  type: TYPE_NORMAL
- en: Backup storage location
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Velero requires an S3-compatible bucket to store backups. There are a number
    of officially supported systems, including all object-store offerings from AWS,
    Azure, and Google.
  prefs: []
  type: TYPE_NORMAL
- en: 'Along with the officially supported providers, there are a number of community-
    and vendor-supported providers from companies such as DigitalOcean, Hewlett Packard,
    and Portworx. The following chart lists all of the current providers:'
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: In the following table, the **Backup Support** column means that the plugin
    provides a compatible location to store Velero backups. Volume Snapshot Support
    means that the plugin supports backing up persistent volumes.
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 13.1 – Velero storage options'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Table_13.1.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Table 13.1 – Velero storage options
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Velero's AWS S3 driver is compatible with many third-party storage systems,
    including EMC ECS, IBM Cloud, Oracle Cloud, and MinIO.
  prefs: []
  type: TYPE_NORMAL
- en: If you do not have an existing object storage solution, you can deploy the open
    source S3 provider, MinIO.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the Velero executable installed, and our KinD cluster has persistent
    storage, thanks to the auto-provisioner from Rancher, we can move on to the first
    requirement – adding an S3-compatible backup location for Velero.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying MinIO
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: MinIO is an open source object storage solution that is compatible with Amazon's
    S3 cloud services API. You can read more about MinIO on its GitHub repository
    at [https://github.com/minio/minio](https://github.com/minio/minio).
  prefs: []
  type: TYPE_NORMAL
- en: 'If you install MinIO using a manifest from the internet, be sure to verify
    what volumes are declared in the deployment before trying to use it as a backup
    location. Many of the examples on the internet use **emptyDir: {}**, which is
    not persistent.'
  prefs: []
  type: TYPE_NORMAL
- en: We have included a modified MinIO deployment from the Velero GitHub repository
    in the **chapter13** folder. Since we have persistent storage on our cluster,
    we edited the volumes in the deployment to use **PersistentVolumeClaims** (**PVCs**),
    which will use the auto-provisioner for Velero's data and configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'To deploy the MinIO server, change directories to **chapter13** and execute
    **kubectl create**. The deployment will create a Velero namespace, PVCs, and MinIO
    on your KinD cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: kubectl create -f minio-deployment.yaml
  prefs: []
  type: TYPE_NORMAL
- en: 'This will deploy the MinIO server and expose it as **minio** on port **9000/TCP**,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.2 – Minio service creation'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Fig_13.2_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 13.2 – Minio service creation
  prefs: []
  type: TYPE_NORMAL
- en: The MinIO server can be targeted by any pod in the cluster, with correct access
    keys, using **minio.velero.svc** on port **9000**.
  prefs: []
  type: TYPE_NORMAL
- en: Exposing the MinIO dashboard
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'MinIO includes a dashboard that allows you to browse the contents of the S3
    buckets on the server. To allow access to the dashboard, you can deploy an Ingress
    rule that exposes the MinIO service. We have included an example Ingress manifest
    in the **chapter13** folder. You can create it using the included file, or from
    the following manifest:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember to change the host to include the host''s IP address in the **nip.io**
    URL:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'apiVersion: networking.k8s.io/v1beta1'
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: Ingress'
  prefs: []
  type: TYPE_NORMAL
- en: 'metadata:'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: minio-ingress'
  prefs: []
  type: TYPE_NORMAL
- en: 'namespace: velero'
  prefs: []
  type: TYPE_NORMAL
- en: 'spec:'
  prefs: []
  type: TYPE_NORMAL
- en: 'rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '- host: minio.[hostip].nip.io'
  prefs: []
  type: TYPE_NORMAL
- en: 'http:'
  prefs: []
  type: TYPE_NORMAL
- en: 'paths:'
  prefs: []
  type: TYPE_NORMAL
- en: '- path: /'
  prefs: []
  type: TYPE_NORMAL
- en: 'backend:'
  prefs: []
  type: TYPE_NORMAL
- en: 'serviceName: minio'
  prefs: []
  type: TYPE_NORMAL
- en: 'servicePort: 9000'
  prefs: []
  type: TYPE_NORMAL
- en: Once deployed, you can use a browser on any machine and open the URL you used
    for the Ingress rule. On our cluster, the host IP is **10.2.1.121**, so our URL
    is **minio.10.2.1.121.nip.io**:![Figure 13.3 – MinIO dashboard
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](image/Fig_13.3_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 13.3 – MinIO dashboard
  prefs: []
  type: TYPE_NORMAL
- en: To access the dashboard, supply the access key and secret key from the MinIO
    deployment. If you used the MinIO installer from the GitHub repository, the access
    key and secret key are **packt**/**packt**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once logged in, you will see a list of buckets and any items that are stored
    in them. Right now, it will be fairly empty since we haven''t created a backup
    yet. We will revisit the dashboard after we execute a backup of our KinD cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.4 – MinIO Browser'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Fig_13.4_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 13.4 – MinIO Browser
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: If you are new to object storage, it is important to note that while this deploys
    a storage solution in your cluster, it **will not** create a StorageClass or integrate
    with Kubernetes in any way. All pod access to the S3 bucket is done using the
    URL that we will provide in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have an S3-compatible object store running, you need to create
    a configuration file that Velero will use to target your MinIO server.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the S3 target configuration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'First, we need to create a file with credentials to the S3 bucket. When we
    deployed the MinIO manifest from the **chapter13** folder, it created an initial
    key ID and access key, **packt**/**packt**:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new credential file in the **chapter13** folder called **credentials-velero**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**vi credentials-velero**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following lines to the credentials file and save the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[default]'
  prefs: []
  type: TYPE_NORMAL
- en: aws_access_key_id = packt
  prefs: []
  type: TYPE_NORMAL
- en: aws_secret_access_key = packt
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can deploy Velero using the Velero executable and the **install** option.
  prefs: []
  type: TYPE_NORMAL
- en: 'Execute the Velero installation using the following command from inside the
    **chapter13** folder to deploy Velero:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**velero install \**'
  prefs: []
  type: TYPE_NORMAL
- en: '**     --provider aws \**'
  prefs: []
  type: TYPE_NORMAL
- en: '**     --plugins velero/velero-plugin-for-aws:v1.1.0 \**'
  prefs: []
  type: TYPE_NORMAL
- en: '**     --bucket velero \**'
  prefs: []
  type: TYPE_NORMAL
- en: '**     --secret-file ./credentials-velero \**'
  prefs: []
  type: TYPE_NORMAL
- en: '**     --use-volume-snapshots=false \**'
  prefs: []
  type: TYPE_NORMAL
- en: '**     --backup-location-config region=minio,s3ForcePathStyle="true",s3Url=http://minio.velero.svc:9000**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s explain the installation options and what the values mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 13.2 – Velero Install Options'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Table_13.2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Table 13.2 – Velero Install Options
  prefs: []
  type: TYPE_NORMAL
- en: 'When you execute the install, you will see a number of objects being created,
    including a number of **CustomResourceDefinitions** (**CRDs**) and secrets that
    Velero uses to handle backup and restore operations. If you run into issues with
    your Velero server starting up correctly, there are a few CRDs and secrets that
    you can look at that may have incorrect information. In the following table, we
    explain some of the common objects that you may need to interact with when using
    Velero:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 13.3 – Velero''s CRDs and Secrets'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Table_13.3.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Table 13.3 – Velero's CRDs and Secrets
  prefs: []
  type: TYPE_NORMAL
- en: While most of your interaction with these objects will be through the Velero
    executable, it is always a good practice to understand how utilities interact
    with the API server. Understanding the objects and what their functions are is
    helpful if you do not have access to the Velero executable but you need to view,
    or potentially change, an object value to address an issue quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have Velero installed, and a high-level understanding of Velero
    objects, we can move on to creating different backup jobs for a cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Using Velero to back up workloads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Velero supports running a "one-time" backup with a single command or on a recurring
    schedule. Whether you chose to run a single backup or a recurring backup, you
    can back up all objects or only certain objects using **include** and **exclude**
    flags.
  prefs: []
  type: TYPE_NORMAL
- en: Running a one-time cluster backup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To create an initial backup, you can run a single Velero command that will back
    up all of the namespaces in the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Executing a backup without any flags to include or exclude any cluster objects
    will back up every namespace and all of the objects in the namespace.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a one-time backup, execute the **velero** command with the **backup
    create <backup name>** option. In our example, we have named the backup **initial-backup**:'
  prefs: []
  type: TYPE_NORMAL
- en: velero backup create initial-backup
  prefs: []
  type: TYPE_NORMAL
- en: 'The only confirmation you will receive from this is that the backup request
    was submitted:'
  prefs: []
  type: TYPE_NORMAL
- en: Backup request "initial-backup" submitted successfully.
  prefs: []
  type: TYPE_NORMAL
- en: Run `velero backup describe initial-backup` or `velero backup logs initial-backup`
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, Velero also tells you the command to check the backup status and
    logs. The last line of the output tells us that we can use the **velero** command
    with the **backup** option and either **describe** or **logs** to check the status
    of the backup operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **describe** option will show all of the details of the job:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.5 – The Velero describe output'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Fig_13.5_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 13.5 – The Velero describe output
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To reinforce the previous section, where we mentioned some of the CRDs that
    Velero uses, we also want to explain where the Velero utility retrieves this information
    from.
  prefs: []
  type: TYPE_NORMAL
- en: Each backup that is created will create a backup object in the Velero namespace.
    For our initial backup, a new backup object named **initial-backup** was created.
    Using **kubectl**, we can describe the object to see similar information that
    the Velero executable will provide.
  prefs: []
  type: TYPE_NORMAL
- en: As shown in *Figure 13.5*, the **describe** option shows you all of the settings
    for the backup job. Since we didn't pass any options to the backup request, the
    job contains all the namespaces and objects. Some of the most important details
    to verify are the phase, total items to be backed up, and the items backed up.
  prefs: []
  type: TYPE_NORMAL
- en: If the status of the phase is anything other than **success**, you may not have
    all the items that you want in your backup. It's also a good idea to check the
    backed-up items; if the number of items backed up is less than the items to be
    backed up, our backup did not back up all of the items.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may need to check the status of a backup, but you may not have the Velero
    executable installed. Since this information is in a CR, we can describe the CR
    to retrieve the backup details. Running **kubectl describe** on the backup object
    will show the status of the backup:'
  prefs: []
  type: TYPE_NORMAL
- en: kubectl describe backups initial-backup -n velero
  prefs: []
  type: TYPE_NORMAL
- en: 'If we jump to the bottom of the output from the **describe** command, you will
    see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.6 – The kubectl describe output on the backup resource'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Fig_13.6_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 13.6 – The kubectl describe output on the backup resource
  prefs: []
  type: TYPE_NORMAL
- en: In the output, you can see that the phase is completed, the start and completion
    times, and the number of objects that were backed up and included in the backup.
  prefs: []
  type: TYPE_NORMAL
- en: It's good practice to use a cluster add-on that can generate alerts based on
    information in log files or the status of an object, such as AlertManager. You
    always want a successful backup, and if a backup fails, you should look into the
    failure immediately.
  prefs: []
  type: TYPE_NORMAL
- en: Scheduling a cluster backup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Creating a one-time backup is useful if you have a cluster operation scheduled
    or if there is a major software upgrade in a namespace. Since these events will
    be rare, you will want to schedule a backup that will back up the cluster at regular
    intervals, rather than random one-time backups.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a scheduled backup, you use the **schedule** option and create a
    tag with the Velero executable. Along with the schedule and create, you need to
    provide a name for the job and the **schedule** flag, which accepts *cron*-based
    expressions. The following schedule tells Velero to back up at 1 AM every day:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.7 – Cron scheduling expression'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Fig_13.7_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 13.7 – Cron scheduling expression
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the information in *Figure 13.7*, we can create a backup that will create
    a backup at 1 a.m., using the following **velero schedule create** command:'
  prefs: []
  type: TYPE_NORMAL
- en: velero schedule create cluster-daily --schedule="0 1 * * *"
  prefs: []
  type: TYPE_NORMAL
- en: 'Velero will reply that a schedule has been successfully created:'
  prefs: []
  type: TYPE_NORMAL
- en: Schedule "cluster-daily" created successfully.
  prefs: []
  type: TYPE_NORMAL
- en: If you are not familiar with cron and the options that are available, you should
    read the cron package documentation at [https://godoc.org/github.com/robfig/cron](https://godoc.org/github.com/robfig/cron).
  prefs: []
  type: TYPE_NORMAL
- en: 'cron will also accept some shorthand expressions, which may be easier than
    using the standard cron expressions. The following table contains the shorthand
    for predefined schedules:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 13.4 – cron shorthand scheduling'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Table_13.4.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Table 13.4 – cron shorthand scheduling
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the values from the shorthand table to schedule a backup job that executes
    daily at midnight, we use the following Velero command:'
  prefs: []
  type: TYPE_NORMAL
- en: velero schedule create cluster-daily --schedule="@daily"
  prefs: []
  type: TYPE_NORMAL
- en: Scheduled jobs will create a backup object when the job is executed. The backup
    name will contain the name of the schedule, with a dash and the date and time
    of the backup. Using the name from the preceding example, our initial backup was
    created with the name **cluster-daily-20200627174947**. Here, **20200627** is
    the date the backup ran, and **174947** is the time the backup ran in UTC time.
    This is the equivalent of **2020-06-27 17:49:47 +0000 UTC**.
  prefs: []
  type: TYPE_NORMAL
- en: All of our examples so far have been configured to back up all of the namespaces
    and objects in the cluster. You may need to create different schedules or exclude/include
    certain objects based on your specific clusters.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will explain how to create a custom backup that will
    allow you to use specific tags to include and exclude namespaces and objects.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a custom backup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When you create any backup job, you can provide flags to customize what objects
    will be included in or excluded from the backup job. Some of the most common flags
    are detailed here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image/Table_13.5a.jpg)![Table 13.5 – Velero backup flags'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Table_13.5b.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Table 13.5 – Velero backup flags
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a scheduled backup that will run daily and include only Kubernetes
    system namespaces, we would create a scheduled job using the **--include-namespaces**
    flag:'
  prefs: []
  type: TYPE_NORMAL
- en: velero schedule create cluster-ns-daily --schedule="@daily" --include-namespaces
    ingress-nginx,kube-node-lease,kube-public,kube-system,local-path-storage,velero
  prefs: []
  type: TYPE_NORMAL
- en: Since Velero commands use a CLI for all operations, we should start by explaining
    the common commands you will use to manage backup and restore operations.
  prefs: []
  type: TYPE_NORMAL
- en: Managing Velero using the CLI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Right now, all Velero operations must be done using the Velero executable. Managing
    a backup system without a GUI can be a challenge at first, but once you get comfortable
    with the Velero management commands, it becomes easy to perform operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Velero executable accepts two options:'
  prefs: []
  type: TYPE_NORMAL
- en: Commands
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flags
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A command is an operation such as **backup**, **restore**, **install**, and
    **get**. Most initial commands require a second command to make a complete operation.
    For example, a **backup** command requires another command, such as **create**
    or **delete**, to form a complete operation.
  prefs: []
  type: TYPE_NORMAL
- en: There are two types of flags – command flags and global flags. Global flags
    are flags that can be set for any command, while command flags are specific to
    the command being executed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Like many CLI tools, Velero includes built-in help for every command. If you
    forget some syntax or want to know what flags can be used with a command, you
    can use the **-h** flag to get help:'
  prefs: []
  type: TYPE_NORMAL
- en: velero backup create -h
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the abbreviated help output for the **backup create** command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.8 – Velero help output'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Fig_13.8_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 13.8 – Velero help output
  prefs: []
  type: TYPE_NORMAL
- en: We find Velero's help system to be very helpful; once you get comfortable with
    the Velero basics, you will find that the built-in help provides enough information
    for most commands.
  prefs: []
  type: TYPE_NORMAL
- en: Using common Velero commands
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since many of you may be new to Velero, we wanted to provide a quick overview
    of the most commonly used commands to get you comfortable with operating Velero.
  prefs: []
  type: TYPE_NORMAL
- en: Listing Velero objects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we have mentioned, Velero management is driven by using the CLI. You can
    imagine that as you create additional backup jobs, it may become difficult to
    remember what has been created. This is where the **get** command comes in handy.
  prefs: []
  type: TYPE_NORMAL
- en: 'The CLI can retrieve, or get, a list of the following Velero objects:'
  prefs: []
  type: TYPE_NORMAL
- en: Backup-locations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backups
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plugins
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Restores
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schedules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Snapshot locations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As you may expect, executing **velero get <object>** will return a list of
    the objects managed by Velero:'
  prefs: []
  type: TYPE_NORMAL
- en: velero get backups
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.9 – The velero get output'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Fig_13.9_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 13.9 – The velero get output
  prefs: []
  type: TYPE_NORMAL
- en: All the **get** commands will produce a similar output, which contains the names
    of each object and any unique values for the objects.
  prefs: []
  type: TYPE_NORMAL
- en: The **get** command is useful for a quick look at what objects exists, but it's
    usually used as the first step toward executing the next command, **describe**.
  prefs: []
  type: TYPE_NORMAL
- en: Retrieving details for a Velero object
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'After you get the name of the object that you want the details for, you can
    use the **describe** command to get the details of the object. Using the output
    from the **get** command in the previous section, we want to view the details
    for the **cluster-daily-20200627175009** backup job:'
  prefs: []
  type: TYPE_NORMAL
- en: velero describe backup cluster-daily-20200627175009
  prefs: []
  type: TYPE_NORMAL
- en: The output of the command provides all the details for the requested object.
    You will find yourself using the **describe** command to troubleshoot issues such
    as backup failures.
  prefs: []
  type: TYPE_NORMAL
- en: Creating and deleting objects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since we have already used the **create** command a few times, we will focus
    on the **delete** command in this section.
  prefs: []
  type: TYPE_NORMAL
- en: To recap, the **create** command allows you to create objects that will be managed
    by Velero, including backups, schedules, restores, and locations for backups and
    snapshots. We have created a backup and a schedule, and in the next section, we
    will create a restore.
  prefs: []
  type: TYPE_NORMAL
- en: Once an object is created, you may discover that you need to delete it. To delete
    objects in Velero, you use the **delete** command, along with the object and name
    you want to delete.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our **get backups** output example, we had a backup called **day2**. To
    delete that backup, we would execute the following **delete** command:'
  prefs: []
  type: TYPE_NORMAL
- en: velero delete backup day2
  prefs: []
  type: TYPE_NORMAL
- en: 'Since a delete is a one-way operation, you will need to confirm that you want
    to delete the object. Once confirmed, it may take a few minutes for the object
    to be removed from Velero since it waits until all associated data is removed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.10 – Velero delete output'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Fig_13.10_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 13.10 – Velero delete output
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in the output, when we delete a backup, Velero will delete all
    of the objects for the backup, including the snapshot's backup files and restores.
  prefs: []
  type: TYPE_NORMAL
- en: There are additional commands that you can use, but the commands covered in
    this section are the main commands you need to get comfortable with Velero.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you can create and schedule backups, and know how to use the help system
    in Velero, we can move on to using a backup to restore objects.
  prefs: []
  type: TYPE_NORMAL
- en: Restoring from a backup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With any luck, you will rarely need to execute a restore of any Kubernetes object.
    Even if you haven't been in the IT field long, you have likely experienced a personal
    situation where you had a drive failure, or accidentally deleted an important
    file. If you don't have a backup of the data that was lost, it is a very frustrating
    situation. In the enterprise world, missing data or not having a backup can lead
    to huge revenue losses, or in some scenarios, large fines in regulated industries.
  prefs: []
  type: TYPE_NORMAL
- en: To run a restore from a backup, you use the **create restore** command with
    the **--from-backup <backup name>** tag.
  prefs: []
  type: TYPE_NORMAL
- en: 'Earlier in the chapter, we created a single, one-time backup, called **initial-backup**,
    which includes every namespace and object in the cluster. If we decided that we
    needed to restore that backup, we would execute a restore using the Velero CLI:'
  prefs: []
  type: TYPE_NORMAL
- en: velero restore create --from-backup initial-backup
  prefs: []
  type: TYPE_NORMAL
- en: 'The output from the **restore** command may seem odd:'
  prefs: []
  type: TYPE_NORMAL
- en: Restore request "initial-backup-20200627194118" submitted successfully.
  prefs: []
  type: TYPE_NORMAL
- en: At a quick glance, it may seem like a backup request was made since Velero replies
    with **"initial-backup-20200627194118" submitted successfully**. Velero uses the
    backup name to create a restore request, and since we named our backup **initial-backup**,
    the restore job name will use that name and append the date and time of the restore
    request.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can view the status of the restore using the **describe** command:'
  prefs: []
  type: TYPE_NORMAL
- en: velero restore describe initial-backup-20200627194118
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the size of the restore, it may take some time to restore the entire
    backup. During the restore phase, the status of the backup will be **InProgress**.
    Once completed, the status will change to **Completed**.
  prefs: []
  type: TYPE_NORMAL
- en: Restoring in action
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With all of the theory behind us, let's use two examples to see Velero in action.
    For the examples, we will start with a simple deployment that will delete and
    restore on the same cluster. The next example will be more complex; we will use
    the backup for our main KinD cluster and restore the cluster objects to a new
    KinD cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Restoring a deployment from a backup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For the first example, we will create a simple deployment using an NGINX web
    server. We will deploy the application, verify that it works as expected, and
    then delete the deployment. Using the backup, we will restore the deployment and
    test that the restore worked by browsing to the web server's home page.
  prefs: []
  type: TYPE_NORMAL
- en: We have included a deployment in the **chapter13** folder of your cloned repository.
    This deployment will create a new namespace, the NGINX deployment, a service,
    and an Ingress rule for our exercise. The deployment manifest has also been included.
  prefs: []
  type: TYPE_NORMAL
- en: 'As with any Ingress rule we have created throughout the book, you will need
    to edit its URL to reflect your host''s IP address for **nip.io** to work correctly.
    Our lab server has an IP address of **10.2.1.121** – change this IP to your host''s
    IP:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Edit the manifest from the GitHub repository under the **chapter13** folder
    called **nginx-deployment.yaml** to include your **niop.io** URL. The section
    you need to change is shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'spec:'
  prefs: []
  type: TYPE_NORMAL
- en: 'rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '**  - host: nginx-lab.10.2.1.121.nip.io**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Deploy the manifest using **kubectl**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**kubectl apply -f nginx-deployment.yaml**'
  prefs: []
  type: TYPE_NORMAL
- en: 'This will create the objects we need for the deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '**namespace/nginx-lab created**'
  prefs: []
  type: TYPE_NORMAL
- en: '**pod/nginx-deployment created**'
  prefs: []
  type: TYPE_NORMAL
- en: '**ingress.networking.k8s.io/nginx-ingress created**'
  prefs: []
  type: TYPE_NORMAL
- en: '**service/nginx-lab created**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, test the deployment using any browser and open the URL from the Ingress
    rule:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.11 – Verify that NGINX is running'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Fig_13.11_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 13.11 – Verify that NGINX is running
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have verified that the deployment works, we need to create a backup
    using Velero.
  prefs: []
  type: TYPE_NORMAL
- en: Backing up the namespace
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Create a one-time backup of the new namespace using the Velero **create backup**
    command. Assign the backup job the name **nginx-lab**:'
  prefs: []
  type: TYPE_NORMAL
- en: velero create backup nginx-lab --include-namespaces=nginx-lab
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the namespace only contains a small deployment, the backup should complete
    quickly. Verify that the backup has completed successfully by using the **describe**
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: velero backup describe nginx-lab
  prefs: []
  type: TYPE_NORMAL
- en: Verify that the phase status is complete. If you have an error in the phase
    status, you may have entered the namespace name incorrectly in the **create backup**
    command.
  prefs: []
  type: TYPE_NORMAL
- en: After you verify that the backup has been successful, you can move on to the
    next step.
  prefs: []
  type: TYPE_NORMAL
- en: Simulating a failure
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To simulate an event that would require a backup of our namespace, we will
    delete the entire namespace using **kubectl**:'
  prefs: []
  type: TYPE_NORMAL
- en: kubectl delete ns nginx-lab
  prefs: []
  type: TYPE_NORMAL
- en: It may take a minute to delete the objects in the namespace. Once you have returned
    to a prompt, the deletion should have completed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Verify that the NGINX server does not reply by opening the URL in a browser;
    if you are using the same browser from the initial test, refresh the page. You
    should receive an error when refreshing or opening the URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.12 – Verify whether NGINX is running'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Fig_13.12_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 13.12 – Verify whether NGINX is running
  prefs: []
  type: TYPE_NORMAL
- en: With the confirmation that the NGINX deployment has been deleted, we will restore
    the entire namespace and objects from the backup.
  prefs: []
  type: TYPE_NORMAL
- en: Restoring a namespace
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine this is a "real-world" scenario. You receive a phone call that a developer
    has accidentally deleted every object in their namespace and they do not have
    the source files.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, you are prepared for this type of event. You have several backup
    jobs running in your cluster and you tell the developer that you can restore it
    to the state it was in last night from a backup:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We know that the backup''s name is **nginx-lab**, so using Velero, we can execute
    a **restore create** command with the **--from-backup** option:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**velero create restore --from-backup nginx-lab**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Velero will return that a restore job has been submitted:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Restore request "nginx-lab-20200627203049" submitted successfully.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Run `velero restore describe nginx-lab-20200627203049` or `velero restore
    logs nginx-lab-20200627203049` for more details.**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can check the status using the **velero restore describe** command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**velero restore describe nginx-lab-20200627203049**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Verify that the phase status shows **completed**, and verify that the deployment
    has been restored by browsing to the URL or refreshing the page if you already
    have it open:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.13 – Verify that NGINX has been restored'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Fig_13.13_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 13.13 – Verify that NGINX has been restored
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations, you just saved the developer a lot of work because you had
    a backup of the namespace!
  prefs: []
  type: TYPE_NORMAL
- en: Velero is a powerful product that you should consider using in every cluster
    to protect the workloads from disasters.
  prefs: []
  type: TYPE_NORMAL
- en: Using a backup to create workloads in a new cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Restoring objects in a cluster is just one use case for Velero. While it is
    the main use case for most users, you can also use your backup files to restore
    a workload or all workloads on another cluster. This is a useful option if you
    need to create a new development or disaster recovery cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: Remember that Velero backup jobs are only the namespaces and objects in the
    namespaces. To restore a backup to a new cluster, you must have a running cluster
    running Velero before you can restore any workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Backing up the cluster
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By this point in the chapter, we assume that you have seen this process a few
    times and that you know how to use the Velero CLI. If you need a refresher, you
    can go back a few pages in the chapter for reference, or use the CLI help function.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we should create a few namespaces and add some deployments to each one
    to make it more interesting:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a few demo namespaces:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**kubectl create ns demo1**'
  prefs: []
  type: TYPE_NORMAL
- en: '**kubectl create ns demo2**'
  prefs: []
  type: TYPE_NORMAL
- en: '**kubectl create ns demo3**'
  prefs: []
  type: TYPE_NORMAL
- en: '**kubectl create ns demo4**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can add a quick deployment to a namespace using the **kubectl run** command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**kubectl run nginx --image=bitnami/nginx -n demo1**'
  prefs: []
  type: TYPE_NORMAL
- en: '**kubectl run nginx --image=bitnami/nginx -n demo2**'
  prefs: []
  type: TYPE_NORMAL
- en: '**kubectl run nginx --image=bitnami/nginx -n demo3**'
  prefs: []
  type: TYPE_NORMAL
- en: '**kubectl run nginx --image=bitnami/nginx -n demo4**'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have some additional workloads, we need to create a backup of the
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Back up the new namespaces using a backup name of **namespace-demo**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**velero backup create namespace-demo --include-namespaces=demo1,demo2,demo3,demo4**'
  prefs: []
  type: TYPE_NORMAL
- en: Before moving on, verify that the backup has been completed successfully.
  prefs: []
  type: TYPE_NORMAL
- en: Building a new cluster
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Since we are only demonstrating how Velero can be used to create workloads
    on a new cluster from a backup, we will create a simple single-node KinD cluster
    as our restore point:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: This section gets a little complex since you will have two clusters in your
    **kubeconfig** file. Follow the steps carefully if you're new to switching config
    contexts.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have completed this exercise, we will delete the second cluster since
    we will not need to have two clusters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new KinD cluster with the name **velero-restore**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**kind create cluster --name velero-restore**'
  prefs: []
  type: TYPE_NORMAL
- en: This will create a new single-node cluster that contains both the control plane
    and worker node, and it will set your cluster context to the new cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the cluster has deployed, verify that your context has been switched to
    the **velero-restore** cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**kubectl config get-contexts**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.14 – Verifying your current context'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Fig_13.14_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 13.14 – Verifying your current context
  prefs: []
  type: TYPE_NORMAL
- en: Verify that the current context is set to the **kind-velero-restore** cluster.
    You will see an ***** in the current field of the cluster that is being used.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Finally, verify the namespaces in the cluster using **kubectl**. You should
    only see the default namespaces that are included with a new cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.15 – New cluster namespaces'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Fig_13.15_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 13.15 – New cluster namespaces
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a new cluster created, we can start the process to restore
    the workloads. The first step is to install Velero on the new cluster, pointing
    to the existing S3 bucket as the backup location.
  prefs: []
  type: TYPE_NORMAL
- en: Restoring a backup to the new cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With our new KinD cluster up and running, we need to install Velero to restore
    our backup. We can use most of the same manifests and settings that we used in
    the original cluster, but since we are in a different cluster, we need to change
    the S3 target to the external URL we used to expose the MinIO dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Velero in the new cluster
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We already have the **credentials-velero** file in the **chapter13** folder,
    so we can jump right in to installing Velero using the **velero install** command:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Be sure to change the IP address in **s3Url target** to your host''s IP address:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**velero install \**'
  prefs: []
  type: TYPE_NORMAL
- en: '**     --provider aws \**'
  prefs: []
  type: TYPE_NORMAL
- en: '**     --plugins velero/velero-plugin-for-aws:v1.1.0 \**'
  prefs: []
  type: TYPE_NORMAL
- en: '**     --bucket velero \**'
  prefs: []
  type: TYPE_NORMAL
- en: '**     --secret-file ./credentials-velero \**'
  prefs: []
  type: TYPE_NORMAL
- en: '**     --use-volume-snapshots=false \**'
  prefs: []
  type: TYPE_NORMAL
- en: '**     --backup-location-config region=minio,s3ForcePathStyle="true",s3Url=http://minio.10.2.1.121.nip.io**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The install will take a few minutes, but once the pod is up and running, view
    the log files to verify that the Velero server is up and running and connected
    to the S3 target:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**kubectl logs deployment/velero -n velero**'
  prefs: []
  type: TYPE_NORMAL
- en: 'If all of your settings were correct, the Velero log will have an entry saying
    that it has found backups in the backup location that need to be synced with the
    new Velero server (The number of backups may be different for your KinD cluster):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**time="2020-06-27T22:14:02Z" level=info msg="Found 9 backups in the backup
    location that do not exist in the cluster and need to be synced" backupLocation=default
    controller=backup-sync logSource="pkg/controller/backup_sync_controller.go:196"**'
  prefs: []
  type: TYPE_NORMAL
- en: 'After confirming the installation, verify that Velero can see the existing
    backup files using **velero get backups**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.16 – Viewing backups on the new cluster'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Fig_13.16_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 13.16 – Viewing backups on the new cluster
  prefs: []
  type: TYPE_NORMAL
- en: Your backup list will differ from ours, but you should see the same list that
    you had in the original cluster.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we can use any of the backup files to create a restore job in
    the new cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Restoring a backup in a new cluster
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will use the backup that was created in the previous section
    and restore the workloads to a brand new KinD cluster to simulate a workload migration.
  prefs: []
  type: TYPE_NORMAL
- en: 'The backup that was created of the original cluster, after we added the namespaces
    and deployment, was called **namespace-demo**:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using that backup name, we can restore the namespaces and objects by running
    the **velero restore create** command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**velero create restore --from-backup=namespace-demo**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Wait for the restore to complete before moving on to the next step. To verify
    that the restore was successful, use the **velero describe restore** command with
    the name of the restore job that was created when you executed the **create restore**
    command. In our cluster, the restore job was assigned the name **namespace-demo-20200627223622**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**velero restore describe namespace-demo-20200627223622**'
  prefs: []
  type: TYPE_NORMAL
- en: Once the phase has changed from **InProgress** to **Completed**, verify that
    your new cluster has the additional demo namespaces using **kubectl get ns**:![Figure
    13.17 – Viewing backups on the new cluster
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](image/Fig_13.17_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 13.17 – Viewing backups on the new cluster
  prefs: []
  type: TYPE_NORMAL
- en: 'You will see that the new namespaces were created, and if you look at the pods
    in each namespace, you will see that each has a pod called **nginx.**You can verify
    that the pods were created using kubectl get pods. For example, to verify the
    pods in the demo1 namespace: **kubectl get pods -n demo1**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.18 – Verifying pods in restored namespaces'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Fig_13.18_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 13.18 – Verifying pods in restored namespaces
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You have successfully restored objects from one cluster into
    a new cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Deleting the new cluster
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Since we do not need two clusters, let''s delete the new KinD cluster that
    we restored the backup to:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To delete the cluster, execute the **kind delete cluster** command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**kind delete cluster --name velero-restore**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Set your current context to the original KinD cluster, **kind-cluster01**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**kubectl config use-context kind-cluster01**'
  prefs: []
  type: TYPE_NORMAL
- en: You are now ready to continue to the final chapter of the book, [*Chapter 14*](B15514_14_Final_ASB_ePub.xhtml#_idTextAnchor337),
    *Provisioning a Platform*.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Backing up clusters and workloads is a requirement for any enterprise cluster.
    In this chapter, we reviewed how to back up the etcd cluster database using **etcdctl**
    and the snapshot feature. We also went into detail on how to install Heptio's
    Velero in a cluster to back up and restore workloads. We closed out the chapter
    by copying workloads from an existing backup by restoring an existing backup on
    a new cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Having a backup solution allows you to recover from a disaster or human error.
    A typical backup solution allows you to restore any Kubernetes object, including
    namespaces, persistent volumes, RBAC, services, and service accounts. You can
    also take all of the workloads from one cluster and restore them on a completely
    different cluster for testing or troubleshooting.
  prefs: []
  type: TYPE_NORMAL
- en: Coming up next, in our final chapter, we will pull together many of the previous
    lessons in this book to build a platform for both your developers and your admins.
    We will add source control and pipelines to build a platform, allowing a developer
    to build a "project," checking in source code to create a running application.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: True or false – Velero can only use an S3 target to store backup jobs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. True
  prefs: []
  type: TYPE_NORMAL
- en: B. False
  prefs: []
  type: TYPE_NORMAL
- en: If you do not have an object storage solution, how can you provide an S3 target
    using a backend storage solution such as NFS?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. You can't – there is no way to add anything in front of NFS to present S3.
  prefs: []
  type: TYPE_NORMAL
- en: B. Kubernetes can do this using native CSI features.
  prefs: []
  type: TYPE_NORMAL
- en: C. Install MinIO and use the NFS volumes as persistent disks in the deployment.
  prefs: []
  type: TYPE_NORMAL
- en: D. You don't need to use an object store; you can use NFS directly with Velero.
  prefs: []
  type: TYPE_NORMAL
- en: True or false – Velero backups can only be restored on the same cluster where
    the backup was originally created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. True
  prefs: []
  type: TYPE_NORMAL
- en: B. False
  prefs: []
  type: TYPE_NORMAL
- en: What utility can you use to create an etcd backup?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. Velero.
  prefs: []
  type: TYPE_NORMAL
- en: B. MinIO.
  prefs: []
  type: TYPE_NORMAL
- en: C. There is no reason to back up the etcd database.
  prefs: []
  type: TYPE_NORMAL
- en: D. **etcdctl**.
  prefs: []
  type: TYPE_NORMAL
- en: Which command will create a scheduled backup that runs every day at 3 a.m.?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. **velero create backup daily-backup**
  prefs: []
  type: TYPE_NORMAL
- en: B. **velero create @daily backup daily-backup**
  prefs: []
  type: TYPE_NORMAL
- en: C. **velero create backup daily-backup –schedule="@daily3am"**
  prefs: []
  type: TYPE_NORMAL
- en: D. **velero create schedule daily-backup --schedule="0 3 * * *"**
  prefs: []
  type: TYPE_NORMAL
