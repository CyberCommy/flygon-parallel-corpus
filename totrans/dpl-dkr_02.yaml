- en: Rolling Up the Sleeves
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous chapter, we looked at what containers are, what role they can
    fill in your infrastructure, and why Docker is the one leading the pack in service
    deployments. Now that we know what Docker is and isn''t, we can get started with
    the basics. In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Installing Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extending a container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Debugging containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The installation of Docker varies greatly between operating systems, but for
    most systems, there are detailed instructions at [https://docs.docker.com/engine/installation/](https://docs.docker.com/engine/installation/).
    Two levels of Docker are generally available: the **Community Edition** (**CE**)
    and the **Enterprise Edition** (**EE**). While slightly different, for almost
    everything that we will work on in this book, the Community Edition is perfectly
    functional and will suffice in every way. Once you reach levels of scale where
    you need much more advanced features, such as security scans, LDAP, and technical
    support, the Enterprise Edition might make sense. As would be expected, the Enterprise
    Edition is not free, and you can take a look at [https://www.docker.com/pricing](https://www.docker.com/pricing)
    to see how these editions differ.'
  prefs: []
  type: TYPE_NORMAL
- en: For our examples and any OS-specific commands in this book, from here on, we
    will be using Ubuntu's **Long Term Support** (**LTS**) version, with Ubuntu being
    currently the most popular Linux distribution. The latest version of the LTS product
    available is 16.04, which will be the base for our CLI interactions and examples
    but by the time you read this book, 18.04 might be available too. Keep in mind
    that outside of the installation part, most code and examples are very portable
    and should generally run on other platforms, so even if there are changes needed,
    they should be minimal. That said, developing Docker services on non-Linux platforms
    may not be as refined or stable due to the fact that Docker is generally used
    to deploy Linux-based services on Linux machines even though other niche cases
    are supported to some extent. Microsoft has been making significant advancements
    in this space with Docker for Windows since they have been trying to push their
    own container strategy, so keep an eye on their progress as it may become a pretty
    competent development platform.
  prefs: []
  type: TYPE_NORMAL
- en: Some manual networking examples in later chapters may not work fully in macOS
    due to the different implementation of this subsystem for that platform. For those,
    using a virtual machine with Ubuntu LTS is advised if you want to follow along.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, with our clean Ubuntu 16.04 LTS machine, VM, or a compatible OS, let''s
    get Docker installed. While the Docker package is already available on `apt` repositories
    within the distribution, I would highly discourage installation this way, as these
    versions are usually much older. While this is not a problem for most software,
    for fast-moving projects such as Docker, it will put you at a significant disadvantage
    when it comes to support for the latest features. For this reason, we will install
    Docker from its own apt repository:'
  prefs: []
  type: TYPE_NORMAL
- en: Warning! There are couple of other ways to install Docker using many of the
    following tools, but unless absolutely necessary, installation with the `sudo
    curl -sSL https://somesite.com/ | sh` pattern or anything similar to it is a very
    dangerous thing to do as you are rooting your own box for a website without checking
    what the script does. This execution pattern also leaves minimal evidence of what
    was done behind. Additionally mid-stream exception can corrupt the download but
    still execute, partially causing damage, and you are only relying on **Transport
    Layer Security** (**TLS**), for which hundreds of organizations across the world
    can create fake certificates. In other words, if you care about your machine,
    you should never, ever try to install software in this way unless, of course,
    the software vendor is clueless about security and they force you to do this,
    in which case, you are at their mercy.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'By default, Docker will require `sudo` (or `root`) prefixed to all of your
    commands to run including ones in this book that don''t have it explicitly mentioned.
    Generally, for development machines, this is a big pain to deal with so I might
    mention, but *strongly* discourage, that you can also add your current user to
    the `docker` group so that you do not need to prefix every Docker command with
    `sudo`:'
  prefs: []
  type: TYPE_NORMAL
- en: Add user to group with `usermod`  (for example `$ sudo usermod -aG docker $USER`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fully log out and log back in (groups are evaluated only on session start).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Keep in mind that this is a *huge* security hole that can allow a local user
    to escalate to root privileges trivially so never, under any circumstance, do
    this on any server that will sit on the Internet.
  prefs: []
  type: TYPE_NORMAL
- en: 'If all of the preceding commands work as expected, you will be able to see
    whether Docker is installed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Having Docker installed without anything to run is pretty useless, so let us
    see whether we can get an image that we can run locally. Our choices here would
    be to either make our own image from scratch or use something that's already built.
    Given that a big reason why Docker has reached such high adoption rates is its
    ease of sharing of images through Docker Hub ([https://hub.docker.com/](https://hub.docker.com/))
    and we're just starting out, we will delay creating our own image for a little
    bit to explore this site, a centralized place for publishing and downloading Docker
    images.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/23f9cd78-8642-458f-a455-be3f7500a5c8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Behind this non-descriptive and bland page is the storage of thousands of Docker
    images, and since we are not interested in publishing images right now, we can
    just click on the Explore button in the top-right corner of the page to see what
    images are available:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aa15341a-9d6e-4376-a016-ff0167b56dd5.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, this lists the most popular images at the time of writing, but
    you can look for specific ones through the Search box in the upper-left corner
    as well. For now, as mentioned a while ago, we will not be spending too much time
    here, but it will be valuable for you to know how to run images from Docker Hub,
    so we will try to pull and run one of them to show you how it is done.
  prefs: []
  type: TYPE_NORMAL
- en: 'The top container available here right now seems to be NGINX, so we will try
    to run that in our Docker environment. If you have not worked with NGINX before,
    it is a high-performance web server that is used by a large number of websites
    on the internet. At this stage, we just want to get the feel for running these
    containers, so let us see how that is done:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The `pull` command pulls any and all layers that compose this image. In this
    case, the NGINX image is based on three stacked layers and has a hash of `788fa277..27a311c3`,
    and since we didn't specify a specific version that we wanted, we got the default
    tag, which is `latest`. With this single command, we have retrieved the NGINX
    image from Docker Hub so that we can run it locally. If we wanted to use a different
    tag or pull from a different server, the command gets the more expressive form
    similar to `docker pull <hostname_or_ip>:<port>/<tag_name>` , but we will cover
    these advanced usages in later chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the image now sitting in our local Docker storage (usually in `/var/lib/docker`),
    we can try to run it. NGINX has an absolute sea of possible options that you can
    examine in further detail at [https://hub.docker.com/_/nginx/](https://hub.docker.com/_/nginx/),
    but we are interested in just starting the image for now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'You probably noticed that nothing is happening, but do not worry as this is
    expected. Sadly, this command by itself is not enough as NGINX will run in foreground
    and not be accessible over a socket at all, so we need to cover a few flags and
    switches to really make it useful. So let''s shut the container down by pressing
    *Ctrl* + *C* and try again, this time adding some of the necessary flags:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The `-d` flag runs the container in the background (the detached mode) so that
    our Terminal isn't held on by NGINX and the `-p 8080:80` flag maps our local port
    `8080` to the container's port `80`. Containers often have specific ports that
    they expose, amd in this case, it is `80` but without the mapping we would have
    no way of accessing it. The output that the command returns is a unique identifier
    (container ID) that can be used to track and control this specific container after
    starting it. Hopefully, you can now see how the port whitelisting approach of
    Docker adds an extra level of security as only the things you explicitly allow
    to listen are permitted.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can now open your browser to `http://localhost:8080`, and you should see
    a page similar to this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/287da44a-bb94-449b-8065-7dd405fd8a17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'But how exactly did we know that port `80` needs to be listened to? Indeed,
    we will cover that in just a second, but first, because we started this container
    in the detached mode, it will still be running in the background and we should
    probably make sure that we stop it too. To see which containers we have running,
    let''s check our Docker container statuses with `docker ps`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: What we see here is that our NGINX container is still running, that it has mapped
    localhost interface ports `8080` (including externally accessible ones) with the
    container's port `80`, and that we have been running it for `13` minutes. If we
    had more containers, they would all be listed here so this command is extremely
    useful for working with Docker containers and is generally used for debugging
    and container management.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we wanted to shut this container down, we will actually do that now.
    To shut a container down, we need to know the container ID that is both the value
    that was returned by `docker run` and the value that the first column of `docker
    ps` shows (`dd1fd1b62d9c`). Feel free to use either the short or long version
    of the ID, but for brevity, we will use the former:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This will gracefully try to stop the container and return the resources used
    back to the OS and after a specific timeout, kill it forcefully. If the container
    was really stuck and we knew it, we could replace `stop` with `kill` to hard kill
    the process, but that''s rarely needed since `stop` generally does the same thing
    if the process is not responding. We will now make sure that our container is
    gone:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Yes, things look as we expect them to, but beware that while stopped containers
    are not visible, they are not completely removed from the filesystem by default:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The `-a` flag is used to show all container statuses, not just the running ones,
    and you can see that the system still knows about our old container. We can even
    resume it with `docker start`!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'To really remove our container permanently, we need to explicitly get rid of
    it using `docker rm`, as shown here, or run the `docker run` command with the
    `--rm` switch (we''ll cover this one in the next few pages):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Success!
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let us get back to the earlier question of how we knew that the container
    needed to have port 80 mapped to it? We have a couple of options there for finding
    this information out, and the simplest one is starting the container and checking
    in `docker ps` to see which ports are unbound:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The new flag here that we used with `docker run` is `--rm`, which we just mentioned,
    and it tells the Docker daemon to remove the container completely after it is
    stopped so we don't have to do it manually ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: If you already have a container that you want to check the mapped ports on,
    you can use `docker port <container_id>` command but we are omitting it here since
    it cannot be used on images, but just containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'While this is the quickest way to see what ports will be needed, the general
    way to inspect an image outside of reading its Dockerfile and documentation is
    through `docker inspect`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Additionally, `docker inspect` can show all kinds of other interesting information,
    such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The ID of the image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The tag name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The image creation date
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hardcoded environment variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The command that the container runs on start
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The size of the container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image layers IDs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Volumes specified
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feel free to run the inspect command on any container or image and see what
    gems you might find there. Majority of the time, this output is mainly used for
    debugging, but in cases where the image documentation is lacking, it can be an
    invaluable tool to get you running in a minimal amount of time.
  prefs: []
  type: TYPE_NORMAL
- en: Debugging containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Often in general work with containers, you will likely have to figure out what
    is going on with a container that is running, but `docker ps` is not good enough
    to provide you with all the information you need to figure things out. For these
    cases, the first command to use is `docker logs`. This command displays any output
    that the container has emitted, including both `stdout` and `stderr` streams.
    For the following logs, I started the same NGINX container from before and accessed
    its hosted page on `localhost`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: You can see here that NGINX records all access and the associated response codes
    that are invaluable to debugging a web server. In general, the output can vary
    from very useful to garbage depending on what is running the service, but it is
    usually a good place to start your search. You can also add the `-f` flag if you
    want to follow the logs as they are being written, which is very helpful when
    logs are large and you are trying to filter noise from specific things you are
    looking for.
  prefs: []
  type: TYPE_NORMAL
- en: Seeing what the container sees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When logs aren''t really enough to figure things out, the command to use is
    `docker exec` in order to execute a command on the running container that can
    include access to a full-blown shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: In this case, we used `docker exec` to run the `ls` command in the container,
    but as-is that is not really a powerful debugging tool. What if we try to get
    that full shell within the container and examine it that way?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, we used `-it`, which is shorthand for `-i` and `-t` flags that combine
    to set up the interactive Terminal needed for a full shell access and then we
    use `/bin/bash` to run Bash within the container. The shell within the container
    is a much more useful tool here, but we are at the mercy of the container itself
    in terms of installed tooling since many images trim out any unnecessary packages
    from the image--in this case, the NGINX container doesn''t have `ps`, which is
    an extremely valuable utility for finding causes of problems. Since containers
    are isolated throwaway components generally, sometimes it might be fine to add
    your debugging tools to the container in order to find out what is causing problems
    (though we will cover a much better way of doing this with `pid` namespaces joining
    in later chapters):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, adding any debug tooling to the container from its upstream
    distribution is easy, but be aware that once you find your issue, you should start
    a new container and remove the old one to clean up the leftover junk since it
    is wasting space and a new container will start from the image that did not have
    your newly-installed debugging tools added (in our case `procps`).
  prefs: []
  type: TYPE_NORMAL
- en: Another thing to keep in mind is that sometimes, the images prevent the installation
    of additional packages, so for those cases we will need to wait until later chapters
    to see how we can use namespaces to work in such constrained settings.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, the container is locked into a limited user shell, and because of
    it, you will be unable to access or modify other parts of the system of the container.
    In such configurations, you can add the `-u 0` flag to run the `docker exec` command
    as `root` (`user 0`). You can also specify any other username or user ID instead,
    but generally if you need a secondary user to work with on a container, `root`
    is what you want.
  prefs: []
  type: TYPE_NORMAL
- en: Our first Dockerfile
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we know a little bit about how to get around containers, this is a
    good place to try out creating our own container. To start building a container,
    the first thing that we need to know is that the default filename that Docker
    looks for when building images is `Dockerfile`. While you can use different names
    for this main configuration file, it is highly discouraged though in some rare
    cases, you might not be able to avoid it - if, for example, you need a test suite
    image and the main image build files in the same folder. For now, we will assume
    you just have a single build configuration, and with that in mind, how about we
    see what one of these basic `Dockerfile` looks like. Create a test folder somewhere
    on your filesystem and put this into a file named `Dockerfile`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Let's examine this file line by line. First, we have the `FROM ubuntu:latest`
    line in there. This line indicates that we want to use the latest Ubuntu Docker
    image as our base on which we will layer our own service. This image will be automatically
    pulled from Docker Hub, but this image can also be from a custom repository, your
    own local image, and could be based on any other image as long as it provides
    a good base for your service (that is, NGINX, Apline Linux, Jenkins, and so on)
    if we wanted to.
  prefs: []
  type: TYPE_NORMAL
- en: The next line is very important as the base Ubuntu image does not come with
    almost anything out of the box, so we need to install the package that provides
    the ping utility (`iputils-ping`) through its package manager `apt` , just like
    we would on the command line by using the `RUN` directive to Docker. Before we
    install it, though, we also need to make sure that our update indexes are up-to-date,
    and we use `apt-get update` for that. In a bit, we will cover in detail why we
    used `&&` to chain the `update` and `install` commands, but for now, we will magically
    ignore it so that we don't derail our example too much.
  prefs: []
  type: TYPE_NORMAL
- en: The `CMD` directive instructs Docker that by default, Docker will run `"ping"
    "google.com"` every time the container is started without further arguments. This
    directive is used to start the service within the container, and it ties the life
    cycle of the container to that process, so if our `ping` fails, our container
    terminates, and vice versa. You can only have one `CMD` line in your Dockerfile,
    so be especially careful what you use it for.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have the whole container configured, let''s build it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'As the comment on it implies, what we did here with `docker build -t test_container
    .` is that we built the container (using the default Dockerfile configuration
    name) in our current directory and tagged it with the name `test_container`. Since
    we didn''t specify the version at the end of `test_container`, Docker assigned
    us one called `latest`, as we can see from the end of the output. If we carefully
    examine the output, we can also see that each change to the base image creates
    a new layer and that layer''s ID is then used as the input into the next directive,
    each layer creating its own filesystem diff onto the image. If, for example, we
    run the build again, Docker is smart enough to know that nothing has changed and
    it will use the cached version of those layers again. Compare the final container
    ID (`a719d8db1c35`) with the one from the previous run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: If any change is detected in the directives of the Dockerfile, Docker will rebuild
    that layer and any subsequent ones to ensure consistency. This functionality and
    selective "cache busting" will also be covered later and it has a very important
    role in managing your repository and image sizes.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the container built, let''s see whether it actually works (to exit its
    loop, press *Ctrl* + *C*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Another success! You wrote your first running Docker container!
  prefs: []
  type: TYPE_NORMAL
- en: Breaking the cache
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the container we just wrote, we somewhat glanced over the line `RUN apt-get
    update -q && apt-get install -qy iputils-ping` since it requires a bit of a deeper
    discussion here. In most Linux distributions, packages rotate in versions all
    the time, but the listing of these indexes that tell us where to find these is
    baked into the original Docker image when it gets created (`ubuntu:latest` in
    this case). Before we can install a package, in most cases, our index files have
    been stale for too long (if they haven''t been completely removed), so we need
    to update them. Splitting this `&&` joined line into two separate ones would work
    for that first build:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: But what happens when you add another package to that second line later, as
    shown in the following line?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: In this case, Docker is not very smart and will consider the `update` line to
    be unchanged and will not run the update command again, so it will use the state
    from the cache for the update layer and then continue on to the next one that
    tries to install `curl` (since that one did change since the last build), which
    is likely to fail if enough versions have been rotated in the repositories as
    the indexes will be stale again. To prevent this from occurring, we join the `update`
    and the `install` commands with `&&` so they are treated as one directive and
    create one layer, in which case, changing any part of either of the two joined
    commands will break the cache and run the `update` correctly. Sadly, as you get
    more involved with scalable Docker components, using odd tricks such as these
    to manage the cache and do selective cache busting will become a large part of
    your work.
  prefs: []
  type: TYPE_NORMAL
- en: A container more practical
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is probably where we start diverging from other Docker materials out there
    that practically assume that with just this basic knowledge, the rest of the work
    is a cakewalk when it is really nothing like that. It is not rocket science, but
    these simple examples really do not do enough to get us where we need to be, so
    we will use a practical example based a bit on our previous work with NGINX and
    create a container that uses this web server image to provide and serve up content
    that we will bake into the image.
  prefs: []
  type: TYPE_NORMAL
- en: This example and all the other ones in this book are also available on GitHub
    at [https://github.com/sgnn7/deploying_with_docker](https://github.com/sgnn7/deploying_with_docker).
    You can use either `git` or their web interface to follow along with the examples,
    but all examples of code that we will use will be directly included in the book
    too.
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin creating our web server, we need to create a directory to put all
    of our files in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The first file we need to create is our dummy text file that we will try to
    serve up in the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The next file we will need is the required NGINX configuration. Put the following
    text into a file called `nginx_main_site.conf`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: If you've never worked with NGINX, let's check out what this file does. In the
    first block, we are creating a `server` that listens on port `80` rooted in `/srv/www/html`
    on the image. The second block, while not strictly needed and would require changing
    for bigger websites, should be muscle memory for anyone working on NGINX since
    it prevents the downloading of hidden files like `.htaccess`, `.htpasswd`, and
    many others that should not be available publicly. The last block just makes sure
    that any path starting with `/` will be read from `root` and if the index file
    is not provided, it will use `index.html`. If no such file is available and we
    are in a directory, `autoindex` ensures that it can show you a human-readable
    listing of a directory.
  prefs: []
  type: TYPE_NORMAL
- en: While this NGINX configuration is functional, there are many things that it
    is not including (SSL configuration, logging, error files, file lookup matching,
    and so on), but that is mostly because this is a book is trying to focus on Docker
    itself and not NGINX. If you would like to learn more about how to fully and properly
    configure NGINX, you can visit [https://nginx.org/en/docs/](https://nginx.org/en/docs/)
    for more information.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the configuration written, we can now create our Dockerfile, which will
    take our test file, our configuration file, and the NGINX image and turn it all
    into a Docker image that runs a web server and serves up our test file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: This Dockerfile probably looks a lot different from the first one, so we will
    spend some time diving into what we are doing here.
  prefs: []
  type: TYPE_NORMAL
- en: Extending another container with FROM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Similar to our last container, our `FROM nginx:latest` line ensures that we
    are using the latest version of a base image, but instead of Ubuntu, here, we
    will use NGINX as our base. The `latest` ensures that we get the image with the
    latest features and often patches too at a slight risk of breakages and API incompatibility
    in the future.
  prefs: []
  type: TYPE_NORMAL
- en: When writing your Docker containers, you will often have to make these trade-off
    decisions based on your situation and stability requirements, but the NGINX API
    has been very stable for years now, so in this specific case, we do not need the
    stability that the named tags provide. If we wanted one of those tagged versions
    here, `latest` would just change to the version we wanted that is offered on Docker
    Hub, which we can find at [https://hub.docker.com/_/nginx/](https://hub.docker.com/_/nginx/) ,
    so something like `FROM nginx:1.13` would have been perfectly fine too.
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring the latest patches are included
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our next steps, `apt-get upgrade` and `apt-get dist-upgrade`, are a bit controversial
    in the current Docker world, but I think they are a good addition, and I'll explain
    why. On a regular `deb` package-based Linux distribution (that is, Debian, Ubuntu,
    and so on), these two commands ensure that your system is fully up to date with
    the currently released packages for your version of the system. This means that
    any package that isn't the newest version will be upgraded and any obsolete packages
    will be replaced with newer ones. Since the general maxim of Docker is that the
    containers are more or less disposable, updating your container this way seems
    to be somewhat frowned upon, but it's not without its faults.
  prefs: []
  type: TYPE_NORMAL
- en: Since most Docker images on Docker Hub are only built when the base source files
    or Dockerfile itself changes, many of these images have older and/or unpatched
    system libraries, so when the service uses them as a dynamic library, it may be
    vulnerable to any bugs that have since been fixed. To ensure that we are not behind
    on this security hardening, we make sure that we update the system before we do
    anything else. While there is a small risk of the service breaking due to the
    system API possibly changing and there is an increase in image size due to the
    additional changes applied, the trade-off is, in my opinion, not good enough to
    leave the service unprotected, but feel free to use your best judgment here.
  prefs: []
  type: TYPE_NORMAL
- en: Applying our custom NGINX configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our directive after the system update (`RUN rm /etc/nginx/conf.d/default.conf`)
    is one that removes the default web server configuration from the container. You
    can find out more about the NGINX configuration with the link from our last tip,
    but for now, it will suffice to say that by default, all the individual site configuration
    files are stored in `/etc/nginx/conf.d` and NGINX Docker image comes out of the
    box with a simple example file called `default.conf` , which we absolutely do
    not want to use.
  prefs: []
  type: TYPE_NORMAL
- en: While we could overwrite the mentioned file, we would be stuck with the name
    `default`, which isn't very descriptive, so for our configuration, we will delete
    this one and add ours with a better filename.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we need to make sure that the folder we will be serving files from is
    available and readable by the web server process. The first command using `mkdir
    -p` creates all the relevant directories, but since NGINX doesn''t run as the
    root, we need to know what user the process will be reading the files we want
    to serve up or otherwise our server will not be able to display anything. We can
    find what the original configuration has there as the default user by showing
    the first few lines of the system-wide NGINX configuration included in the image
    at `/etc/nginx/nginx.conf`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Perfect! Well, now that the user that needs to be able to read this directory
    is `nginx` , we will change the owner of our target folder with `chown nginx:nginx
    /srv/www/html` , but what is going on with that new style of `run` Docker command
    we just used when trying to find this out? If you include a command after specifying
    the image name instead of the `CMD` directive in the image, Docker will substitute
    it with this new command. In the preceding command, we are running the `/bin/head`
    executable, passing in arguments to tell it that we only want the top two lines
    from the `/etc/nginx/nginx.conf` file. Since this command exits as soon as it
    is done, the container stops and is fully removed because we used the `--rm` flag.
  prefs: []
  type: TYPE_NORMAL
- en: With the default configuration gone and our directories created, we can now
    copy our main configuration for NGINX in place with `COPY nginx_main_site.conf
    /etc/nginx/conf.d/`. The `COPY` argument does pretty much the obvious thing of
    copying a file from the current build directory into the image at a specified
    location.
  prefs: []
  type: TYPE_NORMAL
- en: Be very careful with how you end the `COPY` directive argument, as leaving the
    slash off will put the source into a file at the destination even if the destination
    is a directory. To ensure that this doesn't happen, always end your target directory
    paths with a slash.
  prefs: []
  type: TYPE_NORMAL
- en: Adding our main `test.txt` file that we want hosted is the last part, and it
    follows along the same lines as the other `COPY` directive, but we will make sure
    that we put this one in the folder that our NGINX configuration is referencing.
    Since we turned on the `autoindex` flag for this endpoint, there are no additional
    steps to be taken as the folder itself will be browsable.
  prefs: []
  type: TYPE_NORMAL
- en: Building and running
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we went over the whole build configuration, we can create our image
    and see what we just made:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Seems like the container build is just fine; let''s run it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: So far, so good, as it seems to be running fine. Now we will access the container
    with our browser at `http://localhost:8080`.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/db512100-8d98-4a43-b3a1-e44bf11f56a2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As we were hoping, our server is working and showing us the content of `/srv/www/html`,
    but let''s click on `test.txt` to make sure it is working too:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/9fe2c484-ccde-41db-b19e-ff2c81ffa618.png)'
  prefs: []
  type: TYPE_IMG
- en: Great, it looks like our plan worked and we have created a high-performance
    static website hosting server container! Sure, there are many other things we
    can add to this, but our main goal of extending a sample image to do something
    useful is a success!
  prefs: []
  type: TYPE_NORMAL
- en: Service from scratch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our last example was decently comprehensive but it left out some important Docker
    commands that we should also know, so we will use another example, albeit reworking
    the web server solution in a slightly less optimal way, to both show them used
    and to explain what they do. In the process, we will go a bit deeper and see whether
    we can make as many parts of the service on our own.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start this example with creating a clean directory and creating the
    same test file we used earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we will create our bit-more-complex Python-based web server container by
    putting the following content in the `Dockerfile`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Using Python's built-in web server is highly discouraged in almost all cases,
    as it is neither scalable nor configurable in any significant way, but it serves
    as a good example of a service that could be hosted through Docker and is available
    on almost all systems with Python. Do not use this in real production services
    unless you really know what you are doing.
  prefs: []
  type: TYPE_NORMAL
- en: Barring the note about using python's web server module in production, this
    is still a good example of all of the other major Dockerfile directives that we
    didn't cover and that you will now learn how to use.
  prefs: []
  type: TYPE_NORMAL
- en: Labels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our first new directive here is `LABEL`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '`LABEL <key>=<value>` or `LABEL <key> <value>` is used to add metadata about
    the image that is being built, which can later be examined and filtered by `docker
    ps` and `docker images` using something like `docker images --filter "<key>=<value>"`.
    Keys are generally all lowercase in the `reverse-dns` notation, but you can use
    anything you want here and `version` should be present on every image, so we use
    the top-level version key name. However, the version here is not only there so
    that we can filter images but also to break Docker''s cache if we change it. Without
    cache-busting of this sort or through the manually set flag during builds ( `docker
    build --no-cache` ), Docker will keep reusing the cache all the way up to the
    most recently changed directive or files so there is a high probability that your
    container will stay stuck in a frozen package configuration. This condition may
    or may not be what you want, but just in case you have automated build tooling,
    adding a `version` layer that can break the cache whenever you change it makes
    the container very easy to update.'
  prefs: []
  type: TYPE_NORMAL
- en: Setting environment variables with ENV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`ENV`, unlike some of these other commands, should be mostly self-explanatory:
    it sets the environmental variables both in the `Dockerfile` and the container.
    Since we would need to keep re-typing `/srv/www/html` in our `Dockerfile`, in
    order to prevent typos and to ensure easy changes to our final server directory
    target, we set the `SRV_PATH` variable that we keep reusing with `$SRV_PATH` later.
    Generally for Docker containers, almost all the configurations to containers are
    done through environmental variables such as these, so expect to see this directive
    more in the later chapters.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Even though we don''t use it in this example, you need to watch out when using
    environment variables in the `CMD` directive directly as it does not get expanded
    but runs directly. You can ensure that your variable gets expanded in `CMD` by
    using it as part of a shell command structure similar to this: `CMD [ "sh", "-c",
    "echo", "$SRV_PATH" ]`.'
  prefs: []
  type: TYPE_NORMAL
- en: Exposing ports
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our next new directive here is `EXPOSE 8000`. Remember how we used `docker info`
    to find out what port the NGINX container was using? This directive filled in
    that information in the metadata and is used by the Docker orchestration tooling
    to map incoming ports into the right ingress port on the container. Since Python's
    HTTP server starts its service on port `8000` by default, we use `EXPOSE` to inform
    Docker that whoever uses this container should make sure that they map this port
    on the host. You can also list multiple ports here with this directive but since
    our service is using only one, we will not need to use that right now.
  prefs: []
  type: TYPE_NORMAL
- en: Container security layering with limited users
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following novel block of code in our `Dockerfile` is probably a little
    bit of a convoluted puzzle, but we will go through it together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: This is something we need to expand on multiple levels, but the first thing
    you need to know is that by default, Dockerfile directives are executed as `root`,
    and if at any point later you do not specify a different `USER`, your service
    will run with `root` credentials, which is a massive hole from a security perspective
    that we are trying to patch up by running our service as a limited user only.
    However, without the user and group defined, we cannot switch our context away
    from the `root`, so we create both a `pythonsrv` group first and then we follow
    it up by creating the `pythonsrv` user attached to the said group. The `-r` flags
    mark the user and group a system-level entity and is a good practice for groups
    and users that will not be directly logged into.
  prefs: []
  type: TYPE_NORMAL
- en: Speaking of users and groups, if you mount a volume from the host to the Docker container
    that is running as a limited user, if neither the host nor the container perfectly
    agree on the user and group IDs (`uid` and `gid`, respectively), you cannot read
    or write files from volumes. To avoid this situation, we use a stable UID and
    GID of `350` that is easy to remember and is not normally in the regular UID/GID
    tables on most host systems. This number is mostly arbitrary, but as long as it
    is in the service range for your host OS and doesn't clash with the users or groups
    on the host either, it should be fine.
  prefs: []
  type: TYPE_NORMAL
- en: The last flag that wasn't covered so far is `-m`, and what it does is create
    the home directory skeleton files for the user. Most of the time, you will not
    need this, but if any subsequent operations try to use `$HOME` (such as `npm`
    or a large swathe of other services), there will be no such directory unless you
    specify this flag and your build will fail so we make sure we do not hit this
    condition by creating `$HOME` for the `pythonsrv` user.
  prefs: []
  type: TYPE_NORMAL
- en: To round this off, we chained all of these `RUN` commands together to ensure
    that we use as few layers as we can. Each layer creates additional metadata and
    increases the size of your image, so just like the Docker best practices document
    states, we try to reduce them by stacking these commands together. While it is
    not the best thing to do in all cases as debugging this style of configuration
    is pretty difficult, it does usually trim the container size significantly.
  prefs: []
  type: TYPE_NORMAL
- en: VOLUMEs and data that lives outside of the container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: But what if we want to add files that live outside of the container that might
    need to persist even when the container dies? That is where the `VOLUME` directive
    comes into play. With `VOLUME`s, any time you start the container, this path is
    actually assumed to be mounted from outside of the container, and if none is provided,
    one will be created and attached for you automatically.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we are assigning our `/srv/www/html/external` path to this unnamed volume,
    but we will reserve majority of our detailed discussion about volumes for later
    chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Setting the working directory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since the Python HTTP server can only serve files from the current directory
    that it runs in, without explicitly configuring this correctly our container would
    show files out of the `/` directory. To work around this, we include `WORKDIR
    $SRV_ROOT` into the `Dockerfile` which changes our working directory to the one
    that will contain the files we want to serve up. A thing to note about this command
    is that you can reuse it as many times as you want and it applies to any subsequent
    commands in the Dockerfile (such as `RUN` or `CMD`).
  prefs: []
  type: TYPE_NORMAL
- en: Adding files from the internet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'What about trying to add files to your container that are not hosted locally
    and/or due to licensing you cannot include them in your repository where the `Dockerfile`
    lives? For this specific purpose, there is the `ADD` directive. This command downloads
    the file from the URI provided and puts it in the container. If the file is local
    compressed archive, such as a `.tgz` or a `.zip` file and the target path ends
    with a slash, it will get expanded into that directory, making this a very useful
    option as opposed to `COPY`. In the example that we''re writing here, we will
    take a semi-random file from GitHub and put it in the directory to be included
    with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Changing the current user
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have explained why we need to run our service as a limited user and how we
    created the user for it, but now is the time to permanently switch the context
    to `pythonsrv`. Using `USER pythonsrv`, any further commands will be executed
    as `pythonsrv` user, including the container's `CMD` executable command, which
    is exactly what we want. Just like `WORKDIR`, this directive can be used multiple
    times in a `Dockerfile`, but for our purposes, there is no need to do the rest
    of the configuration as non-`root`. Generally, it is a good practice to keep this
    layer statement as high as possible in the `Dockerfile` since it is very unlikely
    that it will change and would be unlikely to break cache. However, for this example,
    we can't move it higher as our previous command uses `chown`, which requires `root`
    privileges.
  prefs: []
  type: TYPE_NORMAL
- en: Putting it all together
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''re nearly done! The last thing we need to do is start Python''s built-in
    HTTP server module when our container starts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'With everything in place, we can build and start our new container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'We can cross our fingers and check what we have built by accessing `http://localhost:8000`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/8cac3147-3307-43d6-9026-d10ee62ac0c2.png)'
  prefs: []
  type: TYPE_IMG
- en: It works! Clicking on the `test.txt` shows the correct `Just a test` string
    and `README.md` that we fetched from GitHub downloads just fine when clicked.
    With all of the functionality there, what is in the `external/` directory?
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/70ef7834-4904-45e7-b723-429b14c7fb7a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If the volume is empty, it is really no surprise that our directory here is
    empty too. How about we see whether we can mount some files from our host into
    this directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Here, we are mounting our current directory (`$(pwd)`) to our `/srv/www/html/external`
    target with our `-v` flag. So what does `http://localhost:8000/external` look
    like now? Do we have our files visible?
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/81036609-264a-4e9e-8299-de7b1323fe22.png)'
  prefs: []
  type: TYPE_IMG
- en: Indeed we do - our service works exactly as we expect it to! A real service
    written from scratch!
  prefs: []
  type: TYPE_NORMAL
- en: With a working service under our belt, we should now be able to continue our
    journey into Docker in the next chapter by scaling our containers.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered everything from the basic Docker container to extending
    an existing container, all the way to creating our own service from scratch. Along
    the way, we covered the most important Docker and Dockerfile commands and how
    to use them and, even more importantly, *where* and *why* to use them. While this
    was not the most in-depth coverage of the topic, it is just the right amount of
    depth we need in order to start working on scaling containers in our next chapter.
  prefs: []
  type: TYPE_NORMAL
