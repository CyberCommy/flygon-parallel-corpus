- en: Multithreading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a thread of execution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Syncing access to a common resource
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fast access to a common resource using atomics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a work_queue class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple-readers-single-writer lock
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating variables that are unique per thread
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interrupting a thread
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manipulating a group of threads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Initializing a shared variable safely
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Locking multiple mutexes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we'll take care of threads and all the stuff connected with
    them. Basic knowledge of multithreading is encouraged.
  prefs: []
  type: TYPE_NORMAL
- en: '**Multithreading** means multiple threads of execution exist within a single
    process. Threads may share process resources and have their own resources. Those
    threads of execution may run independently on different CPUs, leading to faster
    and more responsible programs. The `Boost.Thread` library provides unification
    across operating system interfaces to work with threads. It is not a header-only
    library, so all the examples from this chapter need to link against the `libboost_thread`
    and `libboost_system` libraries.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a thread of execution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'On modern multi-core compilers, to achieve maximal performance (or just to
    provide a good user experience), programs usually use multiple threads of execution.
    Here is a motivating example in which we need to create and fill a big file in
    a thread that draws the user interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe requires knowledge of `boost::bind` or `std::bind`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Starting a thread of execution was never so easy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `boost::thread` variable accepts a functional object that can be called
    without parameters (we provided one using `boost::bind`) and creates a separate
    thread of execution. That functional object is copied into a constructed thread
    of execution and run there. The return value of the functional object is ignored.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00006.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: We are using version 4 of the `Boost.Thread` in all recipes (defined `BOOST_THREAD_VERSION`
    to `4`). Important differences between `Boost.Thread` versions are highlighted.
  prefs: []
  type: TYPE_NORMAL
- en: 'After that, we call the `detach()` function, which does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The thread of execution is detached from the `boost::thread` variable but continues
    its execution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `boost::thread` variable starts to hold a `Not-A-Thread` state
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Without a call to `detach()`, the destructor of `boost::thread` will notice
    that it still holds an OS thread and will call `std::terminate`. It terminates
    our program without calling destructors, freeing up resources and without other
    cleanup.
  prefs: []
  type: TYPE_NORMAL
- en: Default constructed threads also have a `Not-A-Thread` state, and they do not
    create a separate thread of execution.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'What if we want to make sure that a file was created and written before doing
    some other job? In that case, we need to join thread in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: After the thread is joined, the `boost::thread` variable holds a `Not-A-Thread`
    state and its destructor does not call `std::terminate`.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that the thread must be joined or detached before its destructor is
    called. Otherwise, your program will terminate!
  prefs: []
  type: TYPE_NORMAL
- en: With `BOOST_THREAD_VERSION=2` defined, the destructor of `boost::thread` calls
    `detach()`, which does not lead to `std::terminate`. But doing so breaks compatibility
    with `std::thread` and, some day, when your project is moving to the C++ standard
    library threads, or when `BOOST_THREAD_VERSION=2` isn't supported, this will give
    you a lot of surprises. Version 4 of `Boost.Thread` is more explicit and strong,
    which is usually preferable in C++ language.
  prefs: []
  type: TYPE_NORMAL
- en: Beware that `std::terminate()` is called when any exception that is not of type
    `boost::thread_interrupted` leaves a boundary of the functional object that was
    passed to the `boost::thread` constructor.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a very helpful wrapper that works as a RAII wrapper around the thread
    and allows you to emulate the `BOOST_THREAD_VERSION=2` behavior; it is called
    `boost::scoped_thread<T>`, where `T` can be one of the following classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`boost::interrupt_and_join_if_joinable`: To interrupt and join a thread at
    destruction'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`boost::join_if_joinable`: To join a thread at destruction'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`boost::detach`: To detach a thread at destruction'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is a short example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The `boost::thread` class was accepted as a part of the C++11 standard and you
    can find it in the `<thread>` header in the `std::` namespace. There is no big
    difference between the Boost's Version 4 and C++11 standard library versions of
    the `thread` class. However, `boost::thread` is available on the C++03 compilers,
    so its usage is more versatile.
  prefs: []
  type: TYPE_NORMAL
- en: There is a very good reason for calling `std::terminate` instead of joining
    by default! C and C++ languages are often used in life critical software. Such
    software is controlled by other software, called **watchdog**. Those watchdogs
    can easily detect that an application has terminated but can not always detect
    deadlocks or detect them with longer delays. For example, for defibrillator software,
    it's safer to terminate, than hang on `join()` for a few seconds waiting for a
    watchdog reaction. Keep that in mind when designing such applications.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the recipes in this chapter use `Boost.Thread`. You may continue reading
    to get more information about the library.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The official documentation has a full list of the `boost::thread` methods and
    remarks about their availability in the C++11 standard library. Follow the link
    [http://boost.org/libs/thread](http://boost.org/libs/thread) for its official
    documentation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Interrupting a thread* recipe will give you an idea of what the `boost::interrupt_and_join_if_joinable`
    class does.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Syncing access to a common resource
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we know how to start threads of execution, we want to have access
    to some common resources from different threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This `Oops!` is not written there accidentally. For some people, it may be
    a surprise, but there is a big chance that `shared_i` won''t be equal to `0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Modern compilers and processors have a huge number of different tricky optimizations
    that can break the preceding code. We won't discuss them here, but there is a
    useful link in the *See also* section of the document that briefly describes them.
  prefs: []
  type: TYPE_NORMAL
- en: Things get even worse in cases when a common resource is a non-trivial class;
    segmentation faults and memory leaks may (and will) occur.
  prefs: []
  type: TYPE_NORMAL
- en: We need to change the code so that only one thread modifies the `shared_i` variable
    at a single moment of time and so that all the processor and compiler optimizations
    that inflict multithreaded code are bypassed.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Basic knowledge of threads is recommended for this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can fix the previous example and make `shared_i` equal at
    the end of the run:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, we''ll need to create a **mutex**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Put all the operations that modify or get data from the `shared_i` variable
    between the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'And the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s how it should look:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `boost::mutex` class takes care of all the synchronization stuff. When
    a thread tries to lock it via the `boost::lock_guard<boost::mutex>` variable and
    there is no other thread holding a lock, it successfully acquires unique access
    to the section of code until the lock is unlocked or destroyed. If some other
    thread already holds a lock, the thread that tried to acquire the lock waits until
    another thread unlocks the lock. All the locking/unlocking operations imply specific
    instructions so that the changes made in a critical section are visible to all
    threads. Also, you no longer need to:'
  prefs: []
  type: TYPE_NORMAL
- en: Make sure that modified values of resources are visible to all cores
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make sure that values are not just modified in the processor's register
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Force the processor to not reorder the instructions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Force the compiler to not reorder the instructions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Force the compiler to not remove writes to storage that is not read
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A bunch of other nasty compiler/architecture specific stuff
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you have a variable that is used from different threads and at least one
    thread modifies that variable, usually, all the code that uses it must be treated
    as a critical section and secured by a mutex.
  prefs: []
  type: TYPE_NORMAL
- en: The `boost::lock_guard` class is a very simple RAII class that stores a reference
    to the mutex, locks it in the single-parameter constructor, and unlocks it in
    the destructor.
  prefs: []
  type: TYPE_NORMAL
- en: In the curly bracket usage in the preceding example the `lock` variable is constructed
    inside them so that, on reaching the `// Critical section end.` closing bracket,
    the destructor for the `lock` variable is called and the mutex is unlocked. Even
    if some exception occurs in the critical section, the mutex is correctly unlocked.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00007.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: If you initialize a common variable and then construct threads that only read
    it, then no mutex or other synchronization is required.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Locking a mutex is potentially a very slow operation, which may stop your code
    for a long time, until some other thread releases a lock. Try to make critical
    sections as small as possible; try to have less of them in your code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at how some operating systems handle locking on a multicore
    CPU. When `thread #1`, running on CPU 1, tries to lock a mutex that is already
    locked by another thread, `thread #1` is stopped by the OS till the lock is released.
    The stopped thread does not eat processor resources, so the OS executes other
    threads on CPU 1\. Now, we have some threads running on CPU 1; some other thread
    releases the lock, and now the OS has to resume execution of a `thread #1`. So,
    it resumes its execution on a currently free CPU, for example, CPU2.'
  prefs: []
  type: TYPE_NORMAL
- en: This results in CPU cache misses, so the code runs slightly slower after mutex
    is released. Usually, things are not so bad because a good OS tries hard to resume
    the thread on the same CPU that it was using before. Unfortunately, such OS-specific
    optimizations are not always possible. Reduce the count of critical sections and
    their sizes to reduce the chance of thread suspending and cache misses.
  prefs: []
  type: TYPE_NORMAL
- en: Do not attempt to lock a `boost::mutex` variable twice in the same thread; it
    will lead to a **deadlock**. If locking a mutex multiple times from a single thread
    is required, use `boost::recursive_mutex` instead from the `<boost/thread/recursive_mutex.hpp>`
    header. Locking it multiple times does not lead to a deadlock. The `boost::recursive_mutex`
    releases the lock only after `unlock()` is called once for each `lock()` call.
    Avoid using `boost::recursive_mutex` when it is not required, because it is slower
    than `boost::mutex` and usually indicates bad code flow design.
  prefs: []
  type: TYPE_NORMAL
- en: The `boost::mutex`, `boost::recursive_mutex`, and `boost::lock_guard` classes
    were accepted to the C++11 standard library, and you may find them in the `<mutex>`
    header in the `std::` namespace. No big difference between Boost and standard
    library versions exists. The Boost version may have some extensions (which are
    marked in the official documentation as *EXTENSION*) and provide better portability
    because they can be used even on pre-C++11 compilers.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The next recipe will give you ideas on how to make this example much faster
    (and shorter).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Read the first recipe from this chapter to get more information about the `boost::thread`
    class. The official documentation at [http://boost.org/libs/thread](http://boost.org/libs/thread)
    may help you too.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To get more information about why the first example fails and how multiprocessors
    work with common resources, see *Memory Barriers: a Hardware View for Software
    Hackers* at [http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.07.23a.pdf](http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.07.23a.pdf).
    Note that this is a hard topic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fast access to common resource using atomics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous recipe, we saw how to safely access a common resource from
    different threads. But in that recipe, we were doing two system calls (in locking
    and unlocking `mutex`) to just get the value from an integer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This looks lame and slow! Can we make the code from the previous recipe better?
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reading the first recipe is all you need to start with this one. Some basic
    knowledge of multithreading will be welcome.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how to improve our previous example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we need different headers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Changing the type of `shared_i` is required:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Remove all the `boost::lock_guard` variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'That''s it! Now, it works:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Processors provide specific **atomic operations** that cannot be interfered
    with by other processors or processor cores. These operations appear to occur
    instantaneously for a system. `Boost.Atomic` provides classes that wrap around
    system-specific atomic operations, cooperate with the compiler to disable optimizations
    that may break multithreaded work with a variable, and provide a unified portable
    interface to work with atomic operations. If two atomic operations on the same
    memory location start simultaneously from different threads, one of the operations
    waits till the other one finishes and then reuses the result of the previous operation.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00008.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'In other words, it is safe to use the `boost::atomic<>` variables from different
    threads simultaneously. Each operation on the atomic variable is seen by the system
    as a single transaction. Series of operations on the atomic variables are treated
    by the system as a series of independent transactions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Never ever avoid synchronization for a variable that is modified from multiple
    threads. Even if the variable is a `bool` and all you do is read or write `true`/`false`
    to it! The compiler has all the rights to optimize away all the stores and reads,
    breaking your code in a million ways that nobody can even imagine. Guess whom
    a good employer would punish for such breakage? (The compiler is not the right
    answer to that question!)
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `Boost.Atomic` library can work only with POD types; otherwise, behavior
    is undefined. Some platforms/processors do not provide atomic operations for some
    types, so `Boost.Atomic` emulates atomic behavior using `boost::mutex`. The atomic
    type does not use `boost::mutex` if the type specific macro is set to `2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The `boost::atomic<T>::is_lock_free` member function depends on runtime, so
    it is not good for compile-time checks but may provide a more readable syntax
    when the runtime check is enough:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Atomics work much faster than mutexes but are still much slower than non-atomic
    operations. If we compare the execution time of a recipe that uses mutexes (0:00.08
    seconds) and the execution time of the preceding example in this recipe (0:00.02
    seconds), we'll see the difference (tested on 30,0000 iterations).
  prefs: []
  type: TYPE_NORMAL
- en: All the known to the book author standard library implementations had issues
    with atomic operations. All of them! Do not write your own atomics. If you think
    that your own implementation of atomics would be better and you wish to waste
    some time--write it, check it using special tools, and think again. Repeat until
    you understand that you're wrong.
  prefs: []
  type: TYPE_NORMAL
- en: The C++11 compatible compilers should have all the atomic classes, `typedefs`,
    and macro in the `<atomic>` header in the `std::` namespace. Compiler-specific
    implementations of `std::atomic` may work faster than the Boost's version, if
    the compiler correctly supports the C++11 memory model and is specially trained
    to optimize `std::atomic` variables.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The official documentation at [http://boost.org/libs/atomic](http://boost.org/libs/atomic)
    may give you many more examples and some theoretical information on the topic.
  prefs: []
  type: TYPE_NORMAL
- en: Creating work_queue class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's call the functional object that takes no arguments (a task, for short).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, imagine a situation where we have threads that post tasks and threads
    that execute posted tasks. We need to design a class that can be safely used by
    both types of those threads. This class must have functions for:'
  prefs: []
  type: TYPE_NORMAL
- en: Getting a task or waiting for a task till it is posted by another thread
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Checking and getting a task if we have one (returning an empty task if no tasks
    remain)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Posting tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Make sure that you feel comfortable with `boost::thread` or `std::thread` ,
    know basics of mutexes, and are aware of `boost::function` or `std::function`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The class that we are going to implement is close by functionality to `std::queue<task_t>`
    but also has thread synchronization. Let''s start:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We need the following headers and members:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'A function for putting a task in a queue must look like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'A non-blocking function for getting a pushed task or an empty task (if no tasks
    remain):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Blocking function for getting a pushed task or for blocking while the task
    is pushed by another thread:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s how a `work_queue` class may be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this example, we see a new RAII class `boost::unique_lock`. It is just a
    `boost::lock_guard` class with additional functionality for explicit unlocking
    and locking mutexes.
  prefs: []
  type: TYPE_NORMAL
- en: Back to our `work_queue` class. Let's start with the `pop_task()` function.
    In the beginning, we are acquiring a lock and checking for available tasks. If
    there is a task, we return it; otherwise, `cond_.wait(lock)` is called. This method
    atomically unlocks the lock and pauses the thread of execution till some other
    thread notifies the current thread.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's take a look at the `push_task` method. In it, we also acquire a lock,
    push a task in `tasks_.queue`, unlock the lock, and call `cond_.notify_one()`,
    which wakes up the thread (if any) waiting in `cond_.wait(lock)`. So, after that,
    if some thread is waiting on a conditional variable in a `pop_task()` method,
    the thread will continue its execution, call `lock.lock()` deep inside `cond_.wait(lock)`,
    and check `tasks_empty()` in `while`. Because we just added a task in `tasks_`,
    we'll get out from the `while` loop, unlock the `<mutex>` (the `lock` variable
    gets out of scope), and return a task.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00009.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: You must check conditions in a loop, not just in an `if` statement! The `if`
    statement leads to errors, as the operating system sometimes may wake up the threads
    without any notify calls from the user.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Note that we explicitly unlocked mutex before calling `notify_one()`. However,
    without unlocking, our example still works.
  prefs: []
  type: TYPE_NORMAL
- en: But, in that case, the thread that has woken up may be blocked once again during
    an attempt to call `lock.lock()` deep inside `cond_wait(lock)`, which leads to
    more context switches and worse performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'With `tests_tasks_count` set to `3000000` and without explicit unlocking, this
    example runs for 7 seconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'With explicit unlocking, this example runs for 5 seconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: You may also notify all the threads waiting on a specific conditional variable
    using `cond_.notify_all()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some extremely exotic operating systems had an extremely rare issue with calling
    `notify_one()` outside the critical section (without holding a lock) on Boost
    before version 1.64 [https://github.com/boostorg/thread/pull/105](https://github.com/boostorg/thread/pull/105).
    It''s doubtful that you will ever work with those. But, anyway, to avoid issues
    on those platforms, you may add a `flush()` function to the `work_queue` class
    that holds a lock and calls `notify_all()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`void flush() {` `boost::lock_guard<boost::mutex> lock(tasks_mutex_);` `cond_.notify_all();`
    `}`'
  prefs: []
  type: TYPE_NORMAL
- en: Call `flush()` when you are done with pushing tasks in a queue to force the
    wakeup of all the threads.
  prefs: []
  type: TYPE_NORMAL
- en: The C++11 standard has `std::condition_variable` declared in the `<condition_variable>`
    header and `std::unique_lock` declared in the `<mutex>` header. Use the Boost
    version if you use C++03 compiler or just use some of the Boost's extensions.
  prefs: []
  type: TYPE_NORMAL
- en: The `work_queue` class could be significantly improved by adding support for
    **rvalue references** and calling `std::move(tasks_.front())`. This will make
    the code in the critical section much faster, resulting in less threads, suspends,
    and wakeups, less cache misses and a much better performance.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first three recipes in this chapter provide a lot of useful information
    about `Boost.Thread`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The official documentation may give you many more examples and some theoretical
    information on the topic; it can be found at [http://boost.org/libs/thread](http://boost.org/libs/thread)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple-readers-single-writer lock
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Imagine that we are developing some online services. We have an unordered map
    of registered users with some properties for each user. This set is accessed by
    many threads, but it is very rarely modified. All operations with the following
    set are done in a thread-safe manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Unfortunately, our online service is somehow slow and the profilers show that
    the problem is in the `users_online` class. Any operation acquires a unique lock
    on the `mutex_` variable, so even getting resources results in waiting on a locked
    mutex. As some of the resources are hard to copy, the critical sections consume
    a lot of time, slowing down any operation on the `users_online` class.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, the project requirements do not allow us to redesign the class.
    Can we speed it up without interface changes?
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Make sure that you feel comfortable with `boost::thread` or `std::thread` and
    know the basics of mutexes.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This will probably help:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Replace `boost::mutex` with `boost::shared_mutex`. Replace `boost::unique_locks`
    with `boost::shared_lock` for methods that do not modify data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can allow getting the data from multiple threads simultaneously if those
    threads do not modify data. We need to uniquely own the mutex only if we are going
    to modify the data protected by it. In all other situations, simultaneous access
    to data is allowed. And that is what `boost::shared_mutex` was designed for. It
    allows shared locking (read locking), which allows multiple simultaneous access
    to resources.
  prefs: []
  type: TYPE_NORMAL
- en: When we do try to unique lock a resource that is shared locked, operations will
    be blocked till there are no read locks remaining, and only after that resource
    is unique locked, forcing new shared locks to wait until the unique lock is released.
    `boost::shared_lock` locking for reading and writing is much slower than the usual
    `boost::mutex` locking. Do not use `boost::shared_lock` unless you are sure that
    there's no good way to redesign your code and you are sure that `boost::shared_lock`
    will speed things up.
  prefs: []
  type: TYPE_NORMAL
- en: Some readers may see the `mutable` keyword for the first time. This keyword
    can be applied to non-static and non-constant class members. The `mutable` data
    member can be modified in the constant member functions and is usually used for
    mutexes and other helper variables that are not directly related to the class
    logic.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you do need only unique locks, do not use `boost::shared_mutex` because
    it is slower than a usual `boost::mutex` class.
  prefs: []
  type: TYPE_NORMAL
- en: Shared mutexes were not available in C++ until C++14\. `shared_timed_mutex`
    and `shared_lock` are defined in the `<shared_mutex>` header in `std::` namespace.
    They have performance characteristics close to the Boost versions, so apply all
    the preceding performance notes.
  prefs: []
  type: TYPE_NORMAL
- en: C++17 has a `shared_mutex` that may be slightly faster than `shared_timed_mutex`,
    because it dose not provide the means for timed locking. This may save you a few
    precious nanoseconds.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is also a `boost::upgrade_mutex` class, which may be useful for cases
    when shared lock needs promotion to unique lock. See the `Boost.Thread` documentation
    at [http://boost.org/libs/thread](http://boost.org/libs/thread) for more information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to [http://herbsutter.com/2013/01/01/video-you-dont-know-const-and-mutable/](http://herbsutter.com/2013/01/01/video-you-dont-know-const-and-mutable/)
    for more information about the mutable keyword.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating variables that are unique per thread
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s take a glance at the recipe *Creating* *work_queue class*. Each task
    there can be executed in one of the many threads and we do not know in which one.
    Imagine that we want to send the results of an executed task using some connection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We have the following solutions:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new connection when we need to send the data (which is very slow)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have a single connection for all the threads and wrap them in mutex (which is
    also slow)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have a pool of connections, get a connection from it in a thread-safe manner,
    and use it (a lot of coding is required, but this solution is fast)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have a single connection per thread (fast and simple to implement)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, how can we implement the last solution?
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Basic knowledge of threads is required.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is time to make a thread local variable. Declare a function in a header
    file after the `connection` class definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Make your source file look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Done. Using a thread-specific resource was never so easy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `boost::thread_specific_ptr` variable holds a separate pointer for each
    thread. Initially, this pointer is equal to `nullptr`; that is why we check for
    `!p` and open a connection if it is `nullptr`.
  prefs: []
  type: TYPE_NORMAL
- en: So, when we enter `get_connection()` from the thread that already initiated
    the pointer, `!p` return the value `false` and we return the already opened connection.
  prefs: []
  type: TYPE_NORMAL
- en: '`delete` for the pointer stored inside the `connection_ptr` variable is called
    when the thread is exiting, so we do not need to worry about memory leaks.'
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You may provide your own cleanup function that will be called instead of `delete`
    at thread exit. A cleanup function must have the `void (*cleanup_function)(T*)`
    signature and must be passed during the `boost::thread_specific_ptr` construction.
  prefs: []
  type: TYPE_NORMAL
- en: C++11 has a special keyword, `thread_local`, to declare variables with thread
    local storage duration. C++11 has no `thread_specific_ptr` class, but you may
    use `thread_local T` or `thread_local std::unique_ptr<T>` to achieve the same
    behavior on compilers that support `thread_local`. `boost::thread_specific_ptr`
    works on pre-C++11 compilers, unlike `thread_local`.
  prefs: []
  type: TYPE_NORMAL
- en: C++17 has `inline` variables, and you may use `thread_local` with `inline` to
    declare thread local variables in header files.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `Boost.Thread` documentation gives a lot of good examples on different cases;
    it can be found at [http://boost.org/libs/thread](http://boost.org/libs/thread)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reading this topic at [http://stackoverflow.com/questions/13106049/c11-gcc-4-8-thread-local-performance-penalty.html](http://stackoverflow.com/questions/13106049/c11-gcc-4-8-thread-local-performance-penalty.html)
    and about the GCCs `__thread` keyword at [http://gcc.gnu.org/onlinedocs/gcc-3.3.1/gcc/Thread-Local.html](http://gcc.gnu.org/onlinedocs/gcc-3.3.1/gcc/Thread-Local.html)
    may give you some ideas about how `thread_local` is implemented in compilers and
    how fast it is
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interrupting a thread
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Sometimes, we need to kill a thread that has eaten too many resources or that
    is just executing for too long. For example, some parser works in a thread (and
    actively uses `Boost.Thread`), but we have already got the required amount of
    data from it, so parsing can be stopped. Here''s the stub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: How can we do it?
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Almost nothing is required for this recipe. You only need to have at least a
    basic knowledge of threads.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can stop a thread by interrupting it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`Boost.Thread` provides some predefined **interruption points** in which the
    thread is checked for being interrupted via the `interrupt()` call. If the thread
    is interrupted, the exception `boost::thread_interrupted` is thrown. While the
    exception is propagated through the `do_parse()` internals, it calls destructors
    for all the resources, just like a typical exception does. `boost::thread_interrupted`
    exceptions are treated specially by the `Boost.Thread` library, and for that exception,
    it is allowed to leave the thread function (`do_parse()` in our example). When
    the exception leaves the thread function, it is caught by the `boost::thread`
    internals and treated as a request to cancel the thread.'
  prefs: []
  type: TYPE_NORMAL
- en: '`boost::thread_interrupted` is not derived from `std::exception`! Interruptions
    work well if you catch exceptions by their type or by references to `std::exception`.
    But if you catch an exception by `catch (...)` and do not rethrow it, the interruptions
    won''t work.'
  prefs: []
  type: TYPE_NORMAL
- en: As we know from the first recipe in this chapter, if a function passed into
    a thread does not catch an exception and the exception leaves function bounds,
    the application terminates. `boost::thread_interrupted` is the only exception
    to that rule; it may leave function bounds and does not `std::terminate()` the
    application.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Interruption points of the `Boost.Thread` library are listed in official documentation.
    As a rule of a thumb everything that blocks checks for interruptions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We may also manually add interruption points at any place. All we need is to
    call `boost::this_thread::interruption_point()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: If interruptions are not required for a project, defining `BOOST_THREAD_DONT_PROVIDE_INTERRUPTIONS`
    gives a small performance boost and totally disables thread interruptions.
  prefs: []
  type: TYPE_NORMAL
- en: 'C++11 has no thread interruptions, but you can partially emulate them using
    atomic operations:'
  prefs: []
  type: TYPE_NORMAL
- en: Create an atomic `bool` variable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check the atomic variable in the thread and throw an exception if it has changed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do not forget to catch that exception in the function passed to the thread (otherwise
    your application will terminate)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, this won't help you if the code is waiting somewhere in a conditional
    variable or in a sleep method.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The official documentation for `Boost.Thread` provides a list of predefined
    interruption points at [http://www.boost.org/doc/libs/1_64_0/doc/html/thread/thread_management.html#thread.thread_management.tutorial.interruption.predefined_interruption_points](http://www.boost.org/doc/libs/1_64_0/doc/html/thread/thread_management.html#thread.thread_management.tutorial.interruption.predefined_interruption_points)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As an exercise, see the other recipes from this chapter and think of where additional
    interruption points would improve the code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reading other parts of the `Boost.Thread` documentation may be useful; go to
    [http://boost.org/libs/thread](http://boost.org/libs/thread)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manipulating a group of threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Those readers who were trying to repeat all the examples by themselves, or
    those who were experimenting with threads must already be bored with writing the
    following code to launch and join threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Maybe there is a better way to do this?
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Basic knowledge of threads will be more than enough for this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We may manipulate a group of threads using the `boost::thread_group` class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Construct a `boost::thread_group` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Create threads into the preceding variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, you may call functions for all the threads inside `boost::thread_group`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `boost::thread_group` variable just holds all the threads constructed or
    moved to it and may send some calls to all the threads.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: C++11 has no `thread_group` class; it's Boost specific.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The official documentation of `Boost.Thread` may surprise you with a lot of
    other useful classes that are not described in this chapter; go to [http://boost.org/libs/thread](http://boost.org/libs/thread).
  prefs: []
  type: TYPE_NORMAL
- en: Initializing a shared variable safely
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Imagine that we are designing a safety-critical class that is used from multiple
    threads, receives answers from a server, postprocesses them, and outputs the response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Note the `return read_defaults();` line. There may be situations when server
    does not respond because of networking issues or some other problems. In those
    cases, we attempt to read defaults from file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'From the preceding code, we hit the problem: the server may be unreachable
    for some noticeable time, and for all that time we''ll be rereading the file on
    each `act` call. This significantly affects performance.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can attempt to fix it by storing `default_` inside the class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'That''s also not a perfect solution: we do not know how many instances of `postprocessor`
    class are constructed by the user and we are wasting memory on defaults that may
    not be required during the run.'
  prefs: []
  type: TYPE_NORMAL
- en: So, we have to concurrent-safely read and store the data in the current instance
    on the first remote server failure and do not read it again on the next failures.
    There are many ways to do that, but let's look at the most right one.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Basic knowledge of threads is more than enough for this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have to add variables for storing information that defaults were initialized
    and a variable for storing the defaults:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Variables are `mutable` because we are going to modify them inside `const` member
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s initialize our variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let''s change the `act` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In short, `boost::call_once` and `boost::once_flag` make sure that the function
    passed as a second parameter is executed only once.
  prefs: []
  type: TYPE_NORMAL
- en: The `boost::call_once` function synchronizes calls to the function *F* passed
    as a second argument. `boost::call_once` and `boost::once_flag` make sure that
    only one call to the function *F* progresses if there are two or more concurrent
    calls on the same `once_flag` and make sure that only once successful call to
    *F* is performed.
  prefs: []
  type: TYPE_NORMAL
- en: If the call to function *F* has not thrown exceptions that left the body of
    *F*, then `boost::call_once` assumes that the call was successful and stores that
    information inside the `boost::once_flag`. Any subsequent calls to `boost::call_once`
    with the same `boost::once_flag` do nothing.
  prefs: []
  type: TYPE_NORMAL
- en: Do not forget to initialize the `boost::once_flag` with the `BOOST_ONCE_INIT`
    macro.
  prefs: []
  type: TYPE_NORMAL
- en: There's more..
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `boost::call_once` may pass parameters to the function to call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, if we call `once_printer` function in a loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Only a single line will be in the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: C++11 has a `std::call_once` and `std::once_flag` in the `<mutex>` header. Unlike
    the Boost version, the standard library version of the `once_flag` does not require
    initialization via a macro, it has a constexpr constructor. As usual, Boost version
    is usable on pre-C++11 compilers, so use it if you have to support old compilers.
  prefs: []
  type: TYPE_NORMAL
- en: Visual Studio before 2015 was shipping a suboptimal `std::call_once` implementation
    more than ten times slower than the Boost's version. Stick to the `boost::call_once`
    if you're not using modern compilers.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `Boost.Thread` documentation gives a lot of good examples on different cases.
    It can be found at [http://boost.org/libs/thread.](http://boost.org/libs/thread)
  prefs: []
  type: TYPE_NORMAL
- en: Locking multiple mutexes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the next few paragraphs, you'll be one of the people who write games. Congratulations,
    you can play at work!
  prefs: []
  type: TYPE_NORMAL
- en: 'You''re developing a server and you have to write code for exchanging loot
    between two users:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Each user action could be concurrently processed by different threads on a
    server, so you have to guard the resources by mutexes. The junior developer tried
    to deal with the problem, but his solution does not work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: The issue in the preceding code is a well-known **ABBA deadlock** problem. Imagine
    that *thread 1* locks *mutex A* and *thread 2* locks *mutex B*. And now *thread
    1* attempts to lock the already locked *mutex B* and *thread 2* attempts to lock
    the already locked *mutex A*. This results in two threads locked for infinity
    by each other, as they need a resource locked by other thread to proceed while
    the other thread waits for a resource owned by the current thread.
  prefs: []
  type: TYPE_NORMAL
- en: Now, if user1 and user2 call `exchange_loot` for each other concurrently, then
    we may end up with a situation that `user1.exchange_loot(user2)` calls locked
    `user1.loot_mutex_` and `user2.exchange_loot(user1)` calls locked `user2.loot_mutex_`.
    `user1.exchange_loot(user2)` waits for infinity in attempt to lock `user2.loot_mutex_`
    and `user2.exchange_loot(user1)` waits for infinity in an attempt to lock `user1.loot_mutex_`.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Basic knowledge of threads and mutexes is enough for this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two major out-of-the-box solutions to that problem:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The short one that requires variadic template support from the compiler:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The same code using using `auto`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'The portable solution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The core idea is to order mutexes somehow and lock them always following that
    particular order. In that case, there's no ABBA problem possible, as all the threads
    would always lock mutex *A* before *B*. Usually, other deadlock avoidance algorithms
    are used but for the simplicity of the example here, we assume that the ordering
    of mutexes is used.
  prefs: []
  type: TYPE_NORMAL
- en: In the first example, we used `boost::make_unique_locks` that always locks threads
    in some particular order and returns a tuple that holds the locks.
  prefs: []
  type: TYPE_NORMAL
- en: In the second example, we created the locks manually but have not locked them
    thanks to a passed `boost::defer_lock` parameter. The actual locking happened
    in the `boost::lock(l0, l1)` call, which locked the mutexes in some predefined
    order.
  prefs: []
  type: TYPE_NORMAL
- en: Now, if `user1` and `user2` call `exchange_loot` for each other concurrently,
    then both `user1.exchange_loot(user2)` and `user2.exchange_loot(user1)` calls
    will try to lock `user1.loot_mutex_` first or both will try to lock `user2.loot_mutex_`
    first. That depends on a runtime.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`boost::make_unique_locks` and `boost::lock` functions may accept more than
    2 locks or mutexes, so you could use them in more advanced cases, where more than
    two mutexes must be locked simultaneously.'
  prefs: []
  type: TYPE_NORMAL
- en: C++11 has a `std::lock` function defined in the header `<mutex>` that behaves
    exactly like the `boost::lock` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'C++17 has a much more beautiful solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, `std::scoped_lock` is a class that accepts a variadic
    amount of locks. It has variadic template parameters that are automatically deduced
    from the C++17 deduction guide. The actual type of the `std::scoped_lock` from
    the preceding example is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: The `std::scoped_lock` holds a lock to all the mutexes passed during construction
    and avoids deadlocks. In other words, it works like the first example, but looks
    slightly better.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The official documentation of `Boost.Thread` may surprise you with a lot of
    other useful classes that were not described in this chapter; go to [http://boost.org/libs/thread.](http://boost.org/libs/thread)
  prefs: []
  type: TYPE_NORMAL
