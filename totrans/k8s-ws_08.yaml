- en: 8\. Service Discovery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Overview
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will take a look at how to route traffic between the various
    kinds of objects that we have created in previous chapters and make them discoverable
    from both within and outside our cluster. This chapter also introduces the concept
    of Kubernetes Services and explains how to use them to expose the application
    deployed using controllers such as Deployments. By the end of this chapter, you
    will be able to make your application accessible to the external world. You will
    also know about the different types of Services and be able to use them to make
    different sets of pods interact with each other.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the past few chapters, we learned about Pods and Deployments, which help
    us run containerized applications. Now that we are equipped to deploy our applications,
    in this chapter, we will take a look at some API objects that help us with the
    networking setup to ensure that our users can reach our application and that the
    different components of our application, as well as different applications, can
    work together.
  prefs: []
  type: TYPE_NORMAL
- en: As we have seen in the previous chapters, each Kubernetes Pod gets its IP address.
    However, setting up networking and connecting everything is not as simple as coding
    in Pod IP addresses. We can't rely on a single Pod to run our applications reliably.
    Due to this, we use a Deployment to ensure that, at any given moment, we will
    have a fixed number of specific kinds of Pods running in the cluster. However,
    this means that during the runtime of our application, we can tolerate the failure
    of a certain number of Pods as new pods are automatically created to replace them.
    Hence, the IP addresses of these Pods don't stay the same. For example, if we
    have a set of Pods running the frontend application that need to talk to another
    set of Pods running the backend application inside our cluster, we need to find
    a way to make the Pods discoverable.
  prefs: []
  type: TYPE_NORMAL
- en: To solve this problem, we use Kubernetes Services. Services allow us to make
    a logical set of Pods (for example, all pods managed by a Deployment) discoverable
    and accessible for other Pods running inside the same cluster or to the external
    world.
  prefs: []
  type: TYPE_NORMAL
- en: Service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Service defines policies by which a logical set of Pods can be accessed. Kubernetes
    Services enable communication between various components of our application, as
    well as between different applications. Services help us connect the application
    with other applications or users. For example, let's say we have a set of Pods
    running the frontend of an application, a set of Pods running the backend, and
    another set of Pods connecting the data source. The frontend is the one that users
    need to interact with directly. The frontend then needs to connect to the backend,
    which, in turn, needs to talk to the external data source.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider you are making a survey app that also allows users to make visualizations
    based on their survey results. Using a bit of simplification, we can imagine three
    Deployments â€“ one that runs the forms'' frontend to collect the data, another
    that validates and stores the data, and a third one that runs the data visualization
    application. The following diagram should help you visualize how Services would
    come into the picture for routing traffic and exposing different components:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1: Using Services to route traffic into and within the cluster'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_08_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.1: Using Services to route traffic into and within the cluster'
  prefs: []
  type: TYPE_NORMAL
- en: Hence, the abstraction of Services helps in keeping the different parts of the
    application decoupled and enables communication between them. In legacy (non-Kubernetes)
    environments, you may expect different components to be linked together by the
    IP addresses of different VMs or bare-metal machines running different resources.
    When working with Kubernetes, the predominant way of linking different resources
    together is using labels and label selectors, which allows a Deployment to easily
    replace failed Pods or scale the number of Deployments as needed. Thus, you can
    think of a Service as a translation layer between the IP addresses and label selector-based
    mechanism of linking different resources. Hence, you just need to point toward
    a Service, and it will take care of routing the traffic to the appropriate application,
    regardless of how many replica Pods are associated with the application or which
    nodes these Pods are running on.
  prefs: []
  type: TYPE_NORMAL
- en: Service Configuration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Similar to the configuration of Pods, ReplicaSets, and Deployments, the configuration
    for a Service also contains four high-level fields; that is, `apiVersion`, `kind`,
    `metadata`, and `spec`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example manifest for a Service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: For a Service, `apiVersion` is `v1` and `kind` will always be `Service`. In
    the `metadata` field, we will specify the name of the Service. In addition to
    the name, we can also add `labels` and `annotations` in the `metadata` field.
  prefs: []
  type: TYPE_NORMAL
- en: The content of the `spec` field depends on the type of Service we want to create.
    In the next section, we will go through the different types of Services and understand
    various parts of the `spec` field regarding the configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Types of Services
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are four different types of Services:'
  prefs: []
  type: TYPE_NORMAL
- en: '**NodePort**: This type of Service makes internal Pod(s) accessible on a port
    on the node on which the Pod(s) are running.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ClusterIP**: This type of Service exposes the Service on a certain IP inside
    the cluster. This is the default type of Service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**LoadBalancer**: This type of Service exposes the application externally using
    the load balancer provided by the cloud provider.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ExternalName**: This type of Service points to a DNS rather than a set of
    Pods. The other types of Services use label selectors to select the Pods to be
    exposed. This is a special type of Service that doesn''t use any selectors by
    default.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will take a closer look at all these Services in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: NodePort Service
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A NodePort Service exposes the application on the same port on all the nodes
    in the cluster. The Pods may be running across all or some of the nodes in the
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a simplified case where there''s only one node in the cluster, the Service
    exposes all the selected Pods on the port configured in the Service. However,
    in a more practical case, where the Pods may be running on multiple nodes, the
    Service spans across all the nodes and exposes the Pods on the specific port on
    all the nodes. This way, the application can be accessed from outside the Kubernetes
    cluster using the following IP/port combination: `<NodeIP>:<NodePort>`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A `config` file for a sample Service would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, there are three ports involved in the definition of a `NodePort`
    Service. Let''s take a look at these:'
  prefs: []
  type: TYPE_NORMAL
- en: '`targetPort`: This field represents the port where the application running
    on the Pods is exposed. This is the port that the Service forwards the request
    to. By default, `targetPort` is set to the same value as the `port` field.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`port`: This field represents the port of the Service itself.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`nodePort`: This field represents the port on the node that we can use to access
    the Service itself.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Besides the ports, there''s also another field called `selector` in the Service
    `spec` section. This section is used to specify the labels that a Pod needs to
    have in order to be selected by a Service. Once this Service is created, it will
    identify all the Pods that have the `app: nginx` and `environment: production`
    labels and add endpoints for all such Pods. We will look at endpoints in more
    detail in the following exercise.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 8.01: Creating a Simple NodePort Service with Nginx Containers'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, we will create a simple NodePort Service with Nginx containers.
    Nginx containers, by default, expose port `80` on the Pod with an HTML page saying
    `Welcome to nginx!`. We will make sure that we can access that page from a browser
    on our local machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'To successfully complete this exercise, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a file called `nginx-deployment.yaml` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following command to create the Deployment using the `kubectl apply`
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, `nginx-deployment` has been created.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to verify that the Deployment has created three replicas:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see a response similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2: Getting all Pods'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_08_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.2: Getting all Pods'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a file called `nginx-service-nodeport.yaml` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following command to create the Service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, we can use the `kubectl expose` command to expose a Deployment
    or a Pod using a Kubernetes Service. The following command will also create a
    NodePort Service named `nginx-service-nodeport`, with `port` and `targetPort`
    set to `80`. The only difference is that this command doesn''t allow us to customize
    the `nodePort` field. `nodePort` is automatically allocated when we create the
    Service using the `kubectl expose` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: If we use this command to create the Service, we will be able to figure out
    what `nodePort` was automatically assigned to the Service in the following step.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to verify that the Service was created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This should give a response similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3: Getting the NodePort Service'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_08_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.3: Getting the NodePort Service'
  prefs: []
  type: TYPE_NORMAL
- en: You can ignore the additional Service named `kubernetes`, which already existed
    before we created our Service. This Service is used to expose the Kubernetes API
    of the cluster internally.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to verify that the Service was created with the correct
    configuration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This should give us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.4: Describing the NodePort Service'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_08_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.4: Describing the NodePort Service'
  prefs: []
  type: TYPE_NORMAL
- en: In the highlighted sections of the output, we can confirm that the Service was
    created with the correct `Port`, `TargetPort`, and `NodePort` fields.
  prefs: []
  type: TYPE_NORMAL
- en: There's also another field called `Endpoints`. We can see that the value of
    this field is a list of IP addresses; that is, `172.17.0.3:80`, `172.17.0.4:80`,
    and `172.17.0.5:80`. Each of these IP addresses points to the IP addresses allocated
    to the three Pods created by `nginx-deployment`, along with the target ports exposed
    by all of those Pods. We can use the `custom-columns` output format alongside
    the `kubectl get pods` command to get the IP addresses for all three pods. We
    can create a custom column output using the `status.podIP` field, which contains
    the IP address of a running Pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to see the IP addresses of all three Pods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Hence, we can see that the `Endpoints` field of the Service actually points
    to the IP addresses of our three Pods.
  prefs: []
  type: TYPE_NORMAL
- en: As we know in the case of a NodePort Service, we can access the Pod's application
    using the IP address of the node and the port exposed by the Service on the node.
    To do this, we need to find out the IP address of the node in the Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to get the IP address of the Kubernetes cluster running
    locally:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following command to send a request to the IP address we obtained from
    the previous step at port `32023` using `curl`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get a response from Nginx like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5: Sending a curl request to check the NodePort Service'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_08_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.5: Sending a curl request to check the NodePort Service'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, open your browser and enter `192.168.99.100:32023` to make sure we
    can get to the following page:![Figure 8.6: Accessing the application in a browser'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](image/B14870_08_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.6: Accessing the application in a browser'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, you would want to create the objects for each exercise and activity
    in different namespaces to keep them separate from the rest of your objects. So,
    feel free to create a namespace and create the Deployment in that namespace. Alternatively,
    you can ensure that you clean up any objects shown in the following commands so
    that there is no interference.
  prefs: []
  type: TYPE_NORMAL
- en: 'Delete both the Deployment and the Service to ensure you''re working on the
    clean ground for the rest of the exercises in this chapter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, delete the Service using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see this response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In this exercise, we have created a Deployment with three replicas of the Nginx
    container (this can be replaced with any real application running in the container)
    and exposed the application using the NodePort Service.
  prefs: []
  type: TYPE_NORMAL
- en: ClusterIP Service
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we mentioned earlier, a ClusterIP Service exposes the application running
    on the Pods on an IP address that's accessible from inside the cluster only. This
    makes the ClusterIP Service a good type of Service to use for communication between
    different types of Pods inside the same cluster.
  prefs: []
  type: TYPE_NORMAL
- en: For example, let's consider our earlier example of a simple survey application.
    Let's say we have a survey application that serves the frontend to show the forms
    to the users where they can fill in the surveys. It's running on a set of Pods
    managed by the `survey-frontend` Deployment. We also have another application
    that is responsible for validating and storing the data filled by the users. It's
    running on a set of Pods managed by the `survey-backend` Deployment. This backend
    application needs to be accessed internally by the survey frontend application.
    We can use a ClusterIP Service to expose the backend application so that the frontend
    Pods can easily access the backend application using a single IP address for that
    ClusterIP Service.
  prefs: []
  type: TYPE_NORMAL
- en: Service Configuration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Here''s an example of what the configuration for a ClusterIP Service looks
    like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The `type` of Service is set to `ClusterIP`. Only two ports are needed for
    this type of the Service: `targetPort` and `port`. These represent the port where
    the application is exposed on the Pod and the port where the Service is created
    on a given cluster IP, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to the NodePort Service, the ClusterIP Service''s configuration also
    needs a `selector` section, which is used to decide which Pods to select by the
    Service. In this example, this Service will select all the Pods that have both
    `app: nginx` and `environment: production` labels. We will create a simple ClusterIP
    Service in the following exercise based on a similar example.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 8.02: Creating a Simple ClusterIP Service with Nginx Containers'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will create a simple ClusterIP Service with Nginx containers.
    Nginx containers, by default, expose port `80` on the Pod with an HTML page saying
    `Welcome to nginx!`. We will make sure that we can access that page from inside
    the Kubernetes cluster using the `curl` command. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a file called `nginx-deployment.yaml` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following command to create the Deployment using the `kubectl apply`
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following command to verify that the Deployment has created three replicas:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.7: Getting all the Pods'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_08_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.7: Getting all the Pods'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a file called `nginx-service-clusterip.yaml` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following command to create the Service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following command to verify that the Service was created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.8: Getting the ClusterIP Service'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_08_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.8: Getting the ClusterIP Service'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to verify that the Service has been created with
    the correct configuration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.9: Describing the ClusterIP Service'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_08_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.9: Describing the ClusterIP Service'
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the Service has been created with the correct `Port` and `TargetPort`
    fields. In the `Endpoints` field, we can see the IP addresses of the Pods, along
    with the target ports on those Pods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to see the IP addresses of all three Pods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Hence, we can see that the `Endpoints` field of the Service actually points
    to the IP addresses of our three Pods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to get the cluster IP of the Service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.10: Getting the cluster IP from the Service'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_08_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.10: Getting the cluster IP from the Service'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the Service has a cluster IP of `10.99.11.74`.
  prefs: []
  type: TYPE_NORMAL
- en: We know that, in the case of a ClusterIP Service, we can access the application
    running on its endpoints from inside the cluster. So, we need to go inside the
    cluster to be able to check whether this really works.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to access the `minikube` node via SSH:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.11: SSHing into the minikube node'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_08_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.11: SSHing into the minikube node'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we are inside the cluster, we can try to access the cluster IP address
    of the Service and see whether we can access the Pods running Nginx:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response from Nginx:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.12: Sending a curl request to the Service from inside the cluster'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_08_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.12: Sending a curl request to the Service from inside the cluster'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that `curl` returns the HTML code for the default Nginx landing
    page. Thus, we can successfully access our Nginx Pods. Next, we will delete the
    Pods and Services.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to exit the SSH session inside minikube:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Delete the Deployment and the Service to ensure you''re working on the clean
    ground for the following exercises in this chapter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Delete the Service using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: In this exercise, we were able to expose the application running on multiple
    Pods on a single IP address. This can be accessed by all the other Pods running
    inside the same cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a Custom IP Address for the Service
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the previous exercise, we saw that the Service was created with a random
    available IP address inside the Kubernetes cluster. We can also specify an IP
    address if we want. This may be particularly useful if we already have a DNS entry
    for a particular address and we want to reuse that for our Service.
  prefs: []
  type: TYPE_NORMAL
- en: We can do this by setting the `spec.clusterIP` field with a value of the IP
    address we want the Service to use. The IP address specified in this field should
    be a valid IPv4 or IPv6 address. If an invalid IP address is used to create the
    Service, the API server will return an error.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 8.03: Creating a ClusterIP Service with a Custom IP'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will create a ClusterIP Service with a custom IP address.
    We will try a random IP address. As in the previous exercise, we will make sure
    that we can access the default Nginx page from inside the Kubernetes cluster by
    using the `curl` command to the set IP address. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a file called `nginx-deployment.yaml` with the same content that we used
    in the previous exercises in this chapter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Run the following command to create the Deployment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a file named `nginx-service-custom-clusterip.yaml` with the following
    content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: This uses a random ClusterIP value at the moment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to create a Service with the preceding configuration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.13: Service creation failure due to incorrect IP address'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_08_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.13: Service creation failure due to incorrect IP address'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the command gives us an error because the IP address we used
    (`10.90.10.70`) isn't in the valid IP range. As highlighted in the preceding output,
    the valid IP range is `10.96.0.0/12`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can actually find this valid range of IP addresses before creating the Service
    using the `kubectl cluster-info dump` command. It provides a lot of information
    that can be used for cluster debugging and diagnosis. We can filter for the `service-cluster-ip-range`
    string in the output of the command to find out the valid ranges of IP addresses
    we can use in a cluster. The following command will output the valid IP range:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: We can then use the appropriate IP address for `clusterIP` for our Service.
  prefs: []
  type: TYPE_NORMAL
- en: 'Modify the `nginx-service-custom-clusterip.yaml` file by changing the value
    of `clusterIP` to `10.96.0.5` since that''s one of the valid values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following command to create the Service again:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the Service has been created successfully.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to ensure that the Service was created with the custom
    ClusterIP we specified in the configuration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.14: Getting the ClusterIP from the Service'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_08_14.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.14: Getting the ClusterIP from the Service'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can confirm that the Service was indeed created with the IP address
    mentioned in the configuration; that is, `10.96.0.5`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s confirm that we can access the Service using the custom IP address
    from inside the cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.15: SSHing into the minikube node'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_08_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.15: SSHing into the minikube node'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, run the following command to send a request to `10.96.0.5:80` using `curl`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'We intentionally skipped the port number (`80`) in the `curl` request because,
    by default, curl assumes the port number to be `80`. If the Service were using
    a different port number, we would have to specify that in the curl request explicitly.
    You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.16: Sending a curl request to a Service from the minikube node'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_08_16.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.16: Sending a curl request to a Service from the minikube node'
  prefs: []
  type: TYPE_NORMAL
- en: Thus, we can see that we are able to access our Service from inside the cluster
    and that that service can be accessed at the IP address that we defined for `clusterIP`.
  prefs: []
  type: TYPE_NORMAL
- en: LoadBalancer Service
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A LoadBalancer Service exposes the application externally using the load balancer
    provided by the cloud provider. This type of Service has no default local implementation
    and can only be deployed using a cloud provider. The cloud providers provision
    a load balancer when a Service of the `LoadBalancer` type is created.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, a LoadBalancer Service is basically a superset of the NodePort Service.
    The LoadBalancer Service uses the implementation offered by the cloud provider
    and assigns an external IP address to the Service.
  prefs: []
  type: TYPE_NORMAL
- en: 'The configuration of a `LoadBalancer` Service depends on the cloud provider.
    Each cloud provider requires you to add a particular set of metadata in the form
    of annotations. Here''s a simplified example of the configuration for a `LoadBalancer`
    Service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: ExternalName Service
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The ExternalName Service maps a Service to a DNS name. In the case of the ExternalName
    Service, there's no proxying or forwarding. Redirecting the request happens at
    the DNS level instead. When a request comes for the Service, a CNAME record is
    returned with the value of the DNS name that was set in the Service configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'The configuration of the ExternalName Service doesn''t contain any selectors.
    It looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: The preceding Service template maps `externalname-service` to a DNS name; for
    example, `my.example.domain.com`.
  prefs: []
  type: TYPE_NORMAL
- en: Let's say you're migrating your production applications to a new Kubernetes
    cluster. A good approach is to start with stateless parts and move them to a Kubernetes
    cluster first. During the migration process, you will need to make sure those
    stateless parts in the Kubernetes cluster can still access the other production
    Services, such as database storage or other backend Services/APIs. In such a case,
    we can simply create an ExternalName Service so that our Pods from the new cluster
    can still access resources from the old cluster, which are outside the bounds
    of the new cluster. Hence, ExternalName provides communication between Kubernetes
    applications and external Services running outside the Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Ingress
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Ingress is an object that defines rules that are used to manage external access
    to the Services in a Kubernetes cluster. Typically, Ingress acts like a middleman
    between the internet and the Services running inside a cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.17: Ingress'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_08_17.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.17: Ingress'
  prefs: []
  type: TYPE_NORMAL
- en: You will learn much more about Ingress and the major motivations for using it
    in *Chapter 12*, *Your Application and HA*. Due to this, we will not cover the
    implementation of Ingress here.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have learned about the different types of Services in Kubernetes,
    we will implement all of them to get an idea of how they would work together in
    a real-life scenario.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 8.01: Creating a Service to Expose the Application Running on a Pod'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Consider a scenario where the product team you're working with has created a
    survey application that has two independent and decoupled components â€“ a frontend
    and a backend. The frontend component of the survey application renders the survey
    forms and needs to be exposed to external users. It also needs to communicate
    with the backend component, which is responsible for validating and storing the
    survey's responses.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the scope of this activity, consider the following tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: To avoid overcomplicating this activity, you can deploy the Apache server ([https://hub.docker.com/_/httpd](https://hub.docker.com/_/httpd))
    as the frontend, and we can treat its default placeholder home page as the component
    that should be visible to the survey applicants. Expose the frontend application
    so that it's accessible on the host node at port `31000`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For the backend application, deploy an Nginx server. We will treat the default
    home page of Nginx as the page that you should be able to see from the backend.
    Expose the backend application so that it's accessible for the frontend application
    Pods in the same cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Both Apache and Nginx are exposed at port `80` on the Pods by default.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: We are using Apache and Nginx here to keep the activity simple. In a real-world
    scenario, these two would be replaced with the frontend survey site and the backend
    data analysis component of your survey application, along with a database component
    for storing all the survey data.
  prefs: []
  type: TYPE_NORMAL
- en: To make sure frontend applications are aware of the backend application Service,
    add an environment variable to the frontend application Pods that contain the
    IP and the port address of the backend Service. This will ensure that the frontend
    applications know where to send a request to backend applications.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To add environment variables to a Pod, we can add a field named `env` to the
    `spec` section of a Pod configuration that contains a list of name and value pairs
    for all the environment variables we want to add. Here''s an example of how to
    add an environment variable called `APPLICATION_TYPE` with a value of `Frontend`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: We used something called a `ConfigMap` to add an environment variable here.
    We will learn more about them in *Chapter 10*, *ConfigMaps and Secrets*.
  prefs: []
  type: TYPE_NORMAL
- en: Let's assume that, based on load testing the application, you have estimated
    that you'll initially need five replicas of the frontend application and four
    replicas of the backend application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following are the high-level steps you will need to perform in order to
    complete this activity:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a namespace for this activity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write an appropriate Deployment configuration for the backend application and
    create the Deployment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write an appropriate Service configuration for the backend application with
    the appropriate Service type and create the Service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure that the backend application is accessible, as expected.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write an appropriate Deployment configuration for the frontend application.
    Make sure it has the environment variables set for the IP address and the port
    address for the backend application Service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a deployment for the frontend application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write an appropriate Service configuration for the frontend application with
    the appropriate service type and create the Service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure that the frontend application is accessible as expected on port `31000`
    on the host node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Expected Output:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'At the end of the exercise, you should be able to access the frontend application
    in the browser using the host IP address at port `31000`. You should see the following
    output in your browser:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.18: Expected output of Activity 8.01'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B14870_08_18.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.18: Expected output of Activity 8.01'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution to this activity can be found at the following address: [https://packt.live/304PEoD](https://packt.live/304PEoD).'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered the different ways in which we can expose our application
    running on Pods. We have seen how we can use a ClusterIP Service to expose an
    application inside the cluster. We have also seen how we can use a NodePort Service
    to expose an application outside the cluster. We have also covered the LoadBalancer
    and ExternalName Services in brief.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have created a Deployment and learned how to make it accessible
    from the external world, in the next chapter, we will focus on storage aspects.
    There, we will cover reading and storing data on disk, in and across Pods.
  prefs: []
  type: TYPE_NORMAL
