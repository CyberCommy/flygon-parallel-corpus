- en: Chapter 8. Understanding Advanced Networking Concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we've made our way through our journey into Linux network administration
    so far, we've covered everything from planning, setting up file servers, network
    services, and more. Now as we approach the end of this book, the last few chapters
    will round off this knowledge with information on advanced networking, security,
    and even troubleshooting. In this chapter, we'll take a look at several concepts
    that are a bit more advanced, such as subnetting, routing, and more!
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Dividing your network into subnets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the CIDR notation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing **Quality of Service** (**QoS**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding **Network Address Translation** (**NAT**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Routing TCP/IP traffic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating redundant DHCP and DNS servers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring a network gateway
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dividing your network into subnets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unless you're running a very small home or office network, subnetting is generally
    a good idea. Subnetting allows you to split your network into smaller pieces,
    each with their own IP addresses and resources. An example may include placing
    wireless traffic, servers, workstations, and company-issued mobile devices on
    their own subnets. In addition, if there is any specific service on your network
    that receives the most traffic, you can also place that service on its own subnet
    as well. There are endless possibilities, and every administrator will have his
    or her own ideas of the best way of splitting up the network.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 6](ch06.html "Chapter 6. Configuring Network Services"), *Configuring
    Network Services*, we set up a DHCP server. In it, I included an example of using
    a specific subnet for dynamically leased IP addresses. In that scheme, the network
    we used was `10.10.96.0/22`. This means that we have several networks available
    to us, which include `10.10.96.0`, `10.10.97.0`, `10.10.98.0`, and `10.10.99.0`.
    With this network, we can basically divide several services each into their own
    network. In our configuration, `10.10.99.0` was used for DHCP. But of course,
    there's nothing stopping you from using IP addresses `10.10.96.1` through `10.10.99.254`
    should you decide to do so. It really is up to you how you configure your network.
    In that chapter, we set some of the ground work that will be used in this chapter.
    But we didn't go over how we arrived at these numbers, or how to manually split
    up the network ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: The magic in subnetting is all about the subnet mask, though this number is
    only glanced over by most. For quite a few networks, the subnet mask is left at
    its default (`255.255.255.0`) and no one really questions it. If you purchase
    a router from a store and put it into production without configuring it (bad idea),
    you're left with a 24-bit network and a `255.255.255.0` subnet mask. But what
    does this actually mean?
  prefs: []
  type: TYPE_NORMAL
- en: There are two different styles of subnets, **classful** and **classless**. In
    production networks, it's rare that anyone mentions actual classes anymore, as
    classless is how subnetting is done nowadays (more on that later). But before
    we get into classless networking, it's important to understand what came before.
    With our discussion on subnetting, we used the example subnet mask of `255.255.255.0`
    several times, which belongs to what is considered a Class C network. In total,
    there are five classes, Class A through Class E. Classes D and E aren't used for
    much, so we'll stick with Classes A through C for the sake of our discussion of
    classful IP addressing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The subnet masks for classes A to C are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Class | Subnet mask |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| A | `255.0.0.0` |'
  prefs: []
  type: TYPE_TB
- en: '| B | `255.255.0.0` |'
  prefs: []
  type: TYPE_TB
- en: '| C | `255.255.255.0` |'
  prefs: []
  type: TYPE_TB
- en: 'Each of these subnet masks corresponds to which portion of the IP address is
    designated for the network, and which part is designated for each individual node.
    For example, say we have a network configured with a network address `192.168.50.0`
    as a Class C network. This means that our network has a subnet mask of `255.255.255.0`.
    As with all IPv4 IP addresses, our network address has four octets: `192`, `168`,
    `50`, and `0`. To illustrate how a subnet mask affects an IP address, I''ll line
    up each octet in a table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| 192 | 168 | 50 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 255 | 255 | 255 | 0 |'
  prefs: []
  type: TYPE_TB
- en: The purpose of a subnet mask is to *mask out* which octets of an IPv4 address
    correspond to the entire network and which correspond to individual nodes. The
    highest possible number in each octet is `255`. If an octet within a subnet mask
    is set to `255`, which takes up that entire octet and thus cancels it out. In
    this case, the IP address of every node will begin with `192.168.50`, since the
    first three octets were canceled out. Notice that the last octet is a zero in
    both the network address and subnet mask. In IPv4 networking, a `0` means anything.
    Therefore, the last octet of the subnet mask being `0` tells us that it doesn't
    care about that octet, and the network address being `0` means that it doesn't
    either. Thus, any number in the last place is fair game.
  prefs: []
  type: TYPE_NORMAL
- en: In our case, IP addresses starting from `192.168.50.0` through `192.168.50.255`
    belong to this network (subnet). Well, almost. We could never begin our DHCP IP
    range with distributing the `192.168.50.0` IP address if our subnet mask was `255.255.255.0`.
    This is because the first IP address of a subnet cannot be assigned to a node.
    The first IP address is designated as the **network identifier** and is reserved.
    It's certainly possible to have an IP address ending in `0`, as long as it's not
    the first IP address in the block. But in a Class C network, an IP address of
    `192.168.50.0` is not valid since it is indeed the first address within that subnet.
  prefs: []
  type: TYPE_NORMAL
- en: Another IP address that cannot be assigned to any node is the last IP of a subnet.
    In our Class C example, that would be `192.168.255.255`. This IP address is known
    as the **broadcast address** and is also reserved. If a broadcast message needs
    to be sent to the entire network, the broadcast address is used for that purpose.
    With that in mind, the maximum our DHCP range can be in a Class C network such
    as the one used in our example is `192.168.50.1` to `192.168.50.254`.
  prefs: []
  type: TYPE_NORMAL
- en: You may be wondering about the purpose of a broadcast address. As mentioned,
    it allows for packets to be sent to an entire network. In practice, network services,
    such as DHCP, utilize broadcast. When you first plug in a computer to an Ethernet
    cable (a computer that is not programmed with a static IP), it will send a broadcast
    message requesting an IP address. Until it connects, it has no idea what the IP
    address is of your DHCP server. It could be `192.168.1.1`, or even `192.168.1.100`.
    It has no idea whatsoever. By sending broadcast messages, whichever server is
    responsible for DHCP should be able to hear the request and respond to it.
  prefs: []
  type: TYPE_NORMAL
- en: So, why was the IP address `192.168.50.0` chosen for the previous example? That
    number was just chosen at random in order to illustrate how the subnet mask impacts
    the IP addresses that are available. We could have used `172.16.254.0` as our
    network address and with the Class C subnet mask of `255.255.255.0`, which would
    still give us the same number of usable IP addresses (254). In this second example,
    we're still declaring a Class C network, but just with a different IP scheme.
    Since you're managing an internal network, you can choose whatever numbering system
    you want. As long as your IP addresses aren't publicly routable, it's all fair
    game as long as you don't use numbers above 255 in any octet, or the first or
    last IP address within a network. There are a few other IP addresses we can't
    use, but we'll get to those later.
  prefs: []
  type: TYPE_NORMAL
- en: To better understand how this works, we'll need to revisit subnet masks. As
    mentioned, a subnet mask helps determine which portion of an IP address scheme
    belongs to individual nodes and which portion belongs to the network itself. Think
    about it like this. A value of 255 is the maximum number that can be in any octet
    of a subnet mask or IP address. Each 255 within a subnet mask represents a number
    that cannot change. So, if you have an IP address `10.19.100.24` and a subnet
    mask `255.255.255.0`, you can tell right away that the first three octets of this
    network will never change. This means that every host that is a member of this
    subnet will have an IP address beginning with `10.19.100`. If the subnet mask
    was `255.255.0.0`, there would be more IP addresses available, since the last
    two octets are up for grabs. This would actually give us 65,534 IP addresses.
    The former would only allow us 254 IP addresses, since the last octet is the only
    one that could change and its maximum number is 255 (subtracting one for the broadcast
    address).
  prefs: []
  type: TYPE_NORMAL
- en: But you may have noticed that I used an example of a Class A IP address (`10.19.100.24`),
    but I used a Class C subnet mask (`255.255.255.0`). Is this valid? Sure! Regardless
    of the generally agreed upon class structure, the sole purpose of a subnet mask
    is to help you understand which portion is host and which portion of node. Thus,
    subnet masks of `255.255.0.0` and `255.255.255.0` are both valid for this network.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, some IP addresses aren''t considered valid for individual classes.
    While an internal IP network of `253.221.96.0` with a subnet mask of `255.255.255.0`
    fits all these rules, it''s not considered valid for a Class C network. If you''re
    only managing your IP addresses within your network, it may or may not work. So
    for each class in the classful style, there is a recommended scheme to stay within.
    I''ll illustrate that in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Class | Beginning IP | Ending IP |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| A | `0.0.0.0` | `127.255.255.255` |'
  prefs: []
  type: TYPE_TB
- en: '| B | `128.0.0.0` | `191.255.255.255` |'
  prefs: []
  type: TYPE_TB
- en: '| C | `192.0.0.0` | `223.255.255.255` |'
  prefs: []
  type: TYPE_TB
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As with all things networking, there's an exception to keep in mind here as
    well and you cannot assign `127.0.0.0` or `127.0.0.1` to anything, since that
    refers to your local loop-back adapter.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, it's very common with internal networks to start an IP address range
    with `10`, within the Class A scheme. That's what we've done earlier in the book
    when we set up our DHCP server. In that example, we used the `10.10.96.0` network.
    But if you recall, we did not use a Class C subnet mask of `255.255.255.0`; we
    used `255.255.252.0`. This distinction will lead us right into our next topic,
    CIDR.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the CIDR notation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As I mentioned earlier, the concept of classful subnetting isn't used that often
    anymore. The main use of classful subnetting is in the default configuration of
    network appliances (such as routers) and also the default settings of most DHCP
    servers. In the case of home routers, the DHCP server is typically built in, and
    the default scheme is most often a Class C network (typically `192.168.1.0`, with
    a couple of variations in between). But with most devices, home or enterprise,
    you'll probably get a Class C IP scheme if you don't change it to something else.
    There's nothing necessarily wrong with these default settings in a small network,
    but almost no one configuring a network nowadays uses the classful style. The
    reason for this is that classful networks are too limiting; in complex network
    roll-outs, it can be a pain to try to force your network plan to fit within one
    of these predetermined schemes.
  prefs: []
  type: TYPE_NORMAL
- en: The answer to the lack of flexibility in classful schemes comes in the form
    of **Classless Inter-Domain Routing** (**CIDR**). With CIDR, we basically throw
    the limitations of Class A, B, and C subnet masks out the window. Instead, we
    use a binary system to determine how to divide our networks. So, rather than stick
    with just three different subnet masks, we can *borrow* bits and change the subnet
    mask to divide networks in more flexible ways.
  prefs: []
  type: TYPE_NORMAL
- en: To understand this concept, it's important to first understand the idea of bits.
    Each octet within a subnet mask contains eight bits. Each bit is either a `1`
    or a `0` (binary). Also, each of the eight bits has a value of worth. To illustrate
    this, take the number `255`. This is the highest value any octet can be. Written
    in binary, `255` is `11111111`. Therefore, a Class C subnet mask of `255.255.255.0`
    written in binary would be `11111111.11111111.11111111.00000000`.
  prefs: []
  type: TYPE_NORMAL
- en: To make this even easier to understand, see the following table where I outline
    one of the four outlets (`255`) and show it in binary. In this table, the top
    row gives you the point value of each bit. You can see that the rightmost bit
    is worth only `1`, while the leftmost is worth `128`. Any bit that is a `1` on
    the bottom gets totaled up. In this case, every bit is a `1` (since `255` is the
    maximum), so we add up every number on the top row and come out with `255`.
  prefs: []
  type: TYPE_NORMAL
- en: '| 128 | 64 | 32 | 16 | 8 | 4 | 2 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: 'For another example, see the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| 128 | 64 | 32 | 16 | 8 | 4 | 2 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | 1 | 1 | 0 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: To convert this number into a decimal, start at the right and work your way
    to the left. The first bit is a 0\. Does it qualify for the point value of 1?
    Nope. Skip it. Next, it doesn't qualify for 2, 4, or 8 either. So skip those.
    But it does qualify for the last four, 16, 32, 64, and 128\. Add those together.
    The answer? 224\. You just converted the binary number of `1111000` into decimal.
  prefs: []
  type: TYPE_NORMAL
- en: 'Could we have used `1101000` for a value within a subnet mask? No way. The
    reason is because the bits that are a 1 in a subnet mask must be sequential. The
    following are all valid binary numbers in a subnet mask:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In fact, that's it. Since any 1's must be sequential (starting from the left
    to the right), those are the only numbers that are valid for any octet within
    a subnet mask. Therefore, the only valid decimal values for any octet of a subnet
    mask are 0, 128, 192, 224, 240, 248, 252, 254, and 255.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If converting an IP address into binary, you'd follow the same point values
    in the tables previously, though the rule of sequential 1's wouldn't apply. Any
    number from 0 to 255 is valid in any octet in an IP address, as are any combination
    of 1's and 0's in each octet.
  prefs: []
  type: TYPE_NORMAL
- en: To *subnet* a network, we simply alter the number of sequential 1's. For example,
    the binary representation of `255.255.255.0` is `11111111.11111111.11111111.00000000`.
    We could add an additional 1 to this mask, giving us `11111111.11111111.11111111.10000000`,
    which gives us a subnet mask of `255.255.255.128`. Using this subnet mask, we
    are able to divide our network into two parts. Let's break this down.
  prefs: []
  type: TYPE_NORMAL
- en: As I've mentioned several times, the purpose of a subnet mask is to *mask out*
    which portion of the IP address is for the network and which portion is for the
    individual nodes. As we already know, a subnet mask of `255.255.255.0` means that
    the first three octets cannot be used, but we can use it as the last one is a
    0\. If we apply this subnet mask to the `10.10.10.0` network, we can tell that
    every host will have an IP address of `10.10.10.x`. The last octet is 0 and it
    tells us that IP addresses `10.10.10.1` to `10.10.10.254` are up for grabs. Again,
    we can't use the first IP of a subnet (`10.10.10.0` in this case) or the last
    (`10.10.10.255`), as those correspond to the network identifier and broadcast
    address, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'But what do we do with a subnet mask that does *not* end in 0? With a subnet
    mask of `255.255.255.128`, the last octet is used but not exhausted, since it''s
    not the maximum value of 255\. We have some left over. This is because when an
    octet is *not* 255 in a subnet mask, it doesn''t completely mask out that octet.
    Instead, it creates a dividing line. If we apply that subnet mask to our `10.10.10.0`
    network, the IP address of `10.10.10.128` cannot be used. What we''ve done is
    split that last octet in half. Remember, values 0 to 255 are valid in an octet;
    thus, 256 available numbers halved is 128\. With that in mind, we created a scheme
    where we have two networks. One network contains IP addresses `10.10.10.1` to
    `10.10.10.126`. The other allows us IP addresses `10.10.10.129` to `10.10.10.254`.
    The reason for this is because `10.10.10.128` is the dividing line of our subnet
    and cannot be used. I also mentioned that the first and last IP addresses within
    a block can''t be used either, because `10.10.10.0` and `10.10.10.128` are the
    identifiers for each network. The last IP addresses in each block are `10.10.10.127`
    and `10.10.10.255`, respectively, and are off-limits because those are now the
    broadcast addresses for these two networks. If we write out these networks in
    the CIDR format, we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Remember, we count the number of sequential ones in the subnet mask to reach
    the *slash* number at the end. We could have written it as the following, but
    I''m sure you''ll agree that CIDR is easier to type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In binary, that subnet mask is `11111111.11111111.11111111.1 0000000`. Since
    there are 25 1's, the CIDR notation for this subnet mask is 25\. Hopefully, the
    concept is making sense now.
  prefs: []
  type: TYPE_NORMAL
- en: As for our classless style, there's nothing stopping you from using a subnet
    mask such as `255.255.255.0`. Not everyone needs a large number of hosts. But
    instead of calling that a Class C subnet mask, in the CIDR style we would instead
    refer to it as a `/24` network. In the table, I list the subnet masks used in
    discussion of classful networks, as well as their CIDR equivalent.
  prefs: []
  type: TYPE_NORMAL
- en: '| Class | Subnet mask | CIDR notation |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| A | 255.0.0.0 | /8 |'
  prefs: []
  type: TYPE_TB
- en: '| B | 255.255.0.0 | /16 |'
  prefs: []
  type: TYPE_TB
- en: '| C | 255.255.255.0 | /24 |'
  prefs: []
  type: TYPE_TB
- en: 'Now that we understand how subnetting works, how do we put this in action in
    our network? Fortunately, that part is easy. The magic for rolling out a subnet
    is all in your DHCP server. If you recall, in [Chapter 6](ch06.html "Chapter 6. Configuring
    Network Services"), *Configuring Network Services*, we used the following configuration
    in our DHCP server''s `/etc/dhcp/dhcpd.conf` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In the first bold line, I'm providing a subnet mask of `255.255.252.0` to each
    node that receives an IP address from this server. In the block of code toward
    the end, I've decided to issue IP addresses from `10.10.99.100` through `10.10.99.254`.
    Therefore, each node will receive a `10.10.99.x` IP address and a `255.255.252.0`
    subnet mask.
  prefs: []
  type: TYPE_NORMAL
- en: The only thing left when rolling out a subnet scheme is to ensure that every
    server or appliance that has a static IP address is also changed. Unless you've
    used a static lease (also known as a *reservation*), you'll have to find those
    hosts and change them manually. For this reason, I always prefer static leases
    over static IPs. With static leases, all you would have to do is edit your DHCP
    configuration and change the IPs distributed to your hosts. Refer to [Chapter
    6](ch06.html "Chapter 6. Configuring Network Services"), *Configuring Network
    Services*, for how we set up our reservations.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Quality of Service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Not all network traffic is created equal nor are all services equally important.
    There are times when a network requires certain services to be treated with more
    urgency than others. Perhaps in a server environment, your web servers receive
    a high level of traffic from visitors and must prioritize MySQL, or perhaps your
    office uses **VoIP** (short for **Voice over IP**) and needs priority placed on
    the phone system. There are many reasons why your network may require a service
    to be treated with more urgency than others. **Quality of Service** (**QoS**)
    helps us achieve this.
  prefs: []
  type: TYPE_NORMAL
- en: 'While there are multiple ways of tweaking network adapters for QoS, the most
    typical is something known as **queuing discipline** (or more simply, **qdisc**).
    A queuing discipline is something an administrator can apply to a network adapter
    to use one of a multiple of schedulers, each with varying effects on how traffic
    is handled. To see which scheduler your network adapter is currently using, run
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Look for your default network card, which will likely either be `eth0` (in Debian)
    or `eno1` (in CentOS) or similar.
  prefs: []
  type: TYPE_NORMAL
- en: '![Implementing Quality of Service](img/B03919_08_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Viewing the output of IP link list in Debian
  prefs: []
  type: TYPE_NORMAL
- en: Most likely, you'll see `qdisc pfifo_fast` in the output, which tells us that
    the queuing discipline currently in use is `pfifo_fast`. This is basically a first-come
    first-serve scheduler (first in, first out). But rather than contain a single
    band, `pfifo_fast` it contains three—each separating traffic into three priorities.
    The first band (band 0) contains the highest priority traffic. Each band is handled
    only after the previous one has been serviced. Unless your distribution has changed
    the default scheduler, `pfifo_fast`, is most likely what is currently in use on
    your system out of the box.
  prefs: []
  type: TYPE_NORMAL
- en: The `pfifo_fast` scheduler is known as a classless scheduler. In other words,
    what you see is what you get—there is no configuration to be done when it comes
    to how classless schedulers filter traffic. Other classless disciplines include
    **Stochastic Fair** **Queuing** (**SFQ**), **Extended Stochastic Fair Queuing**
    (**ESFQ**), and **Token Bucket Filter** (**TBF**).
  prefs: []
  type: TYPE_NORMAL
- en: 'The SFQ qdisc uses the concept of FIFO as we''ve mentioned before, but separates
    network traffic into more than one FIFO, handled in a round-robin fashion. This
    qdisc tries to be as fair as possible, using flows to schedule packet transmission.
    This gives each flow a turn to transmit, preventing any one of them from becoming
    saturated. ESFQ is very similar, but it gives the administrator more options in
    which to configure. Unlike SFQ, TBF does not actually manipulate packets nor does
    it do any scheduling. The main purpose of TBF is to set a rate at which transmission
    will occur, allowing you to set parameters, such as the rate, burst, peakrate,
    and more. For more in-depth information, on these qdiscs, see the main pages for
    `sfq` and `tbf`. Setting the preferred qdisc on a network adapter is done via
    the `tc` command. See the following example for setting `sfq` on Ethernet adapter
    `eno1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Here, we're calling the `tc` command with `qdisc` and clarifying that we would
    like to `add` (we can also `del`) a qdisc. We're going to execute this against
    interface `eno1`, and we're requesting this change to egress (`root`) while targeting
    the `sfq` qdisc for our interface. Finally, we're setting our qdisc specific parameters
    (in this case, `pertub`). The perturb parameter allows us to set the seconds in
    which the hashing algorithm for this qdisc will be reset. There are other sfq-specific
    values we can alter, such as the number of flows used, quantum, redflowlimit,
    and more. See `man sfq` for complete descriptions of the parameters that can be
    used with sfq or tbf.
  prefs: []
  type: TYPE_NORMAL
- en: Where the concept of classless qdiscs falls short is the fact that they don't
    allow you to classify traffic as granularly as one might like. While it is certainly
    useful to change how packets are scheduled, that concept doesn't allow you to
    pick and choose which type of traffic receives priority at any given time. Classful
    qdiscs solves this issue, and gives the administrator much more flexibility. With
    these, you're able to set parents and children, each with different rules. In
    fact, that is the primary difference between classful and classless qdiscs. It's
    not the case that classless qdiscs aren't configurable at all; they just don't
    have the options to support the flexibility of advanced use cases. Next, we'll
    explore the classful qdiscs and how they allow us this added flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: By utilizing the power of classful qdiscs, you gain almost total control over
    how packets are handled on your network. I said *almost* because it's important
    to remember that the idea of queuing discipline affects only outbound traffic
    (egress) while little can be done to manage incoming traffic. However, on a production
    network, guaranteeing particular services a certain amount of bandwidth can be
    very beneficial. As we've discussed in the previous section, classless qdiscs
    allow us to manage the general way in which packets are handled, but classful
    qdiscs allow us more control by setting classes as well as filters.
  prefs: []
  type: TYPE_NORMAL
- en: A possible scenario you may run into is VoIP traffic becoming unstable, causing
    calls to sound fuzzy or drop altogether. In this case, you may want to guarantee
    more bandwidth to your VoIP server, even if that means sacrificing traffic from
    another source. In addition, SSH is also important on a Linux network. If your
    server is too inundated with packets to even respond to a request to connect to
    it via SSH, that could be a very bad problem since you wouldn't be able to log
    in and correct any issues that may come up. These are very real scenarios many
    face without prioritizing traffic. If there is a service your network or company
    depends on, it's a good measure to prioritize it.
  prefs: []
  type: TYPE_NORMAL
- en: The most popular qdisc to achieve this is **Hierarchical Token Bucket** (**HTB**),
    which is a classful qdisc. HTB allows you to control the egress bandwidth used
    on a device, and it is based on the TBF style we discussed earlier. HBT features
    a number of classes that can be used to control traffic, such as setting the `parent`,
    `priority`, `rate`, `ceil`, and the number of burst bytes. See `man htb` to view
    a complete list.
  prefs: []
  type: TYPE_NORMAL
- en: Just as we did with configuring a classless qdisc, the setting of a classful
    qdisc like HTB is also done via the `tc` command. On most systems, this command
    is stored in `/sbin` and is likely not to be in a regular user's path. Type `which
    tc` to locate where this binary is on your distribution. In most cases, your system
    should recognize this command if run while logged in root. What follows is an
    example of the process of setting up HTB as the qdisc for a network device named
    `eth0`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In the first command, we're changing the qdisc from the default `pfifo_fast`
    to `htb`. In this command, `root` pertains to the fact we're setting this against
    egress traffic. The handle of `1:` is a name for this particular instance of `htb`.
    Setting a default of `10` means that any traffic that is not specifically classed
    elsewhere will be given a class ID of `1:10`. With the second command, we're creating
    class ID `1:1` and adjusting it to use a rate of `2mbit`. In the third, we're
    doing the same, except we're creating an ID of `1:10` with a ceiling, which will
    limit this class to `1.5mbit`. Because we set the default as `10`, this is the
    class that will be used if we don't specifically target traffic to use something
    else. Finally, I also threw in a third class, `1:20`, which has a much lower limit
    of `100kbps`. With both the `rate` and `ceil` values set to the same value, we
    can reasonably expect traffic under this class to consume `100kbps` but also be
    limited to `100kbps`. You can continue to add additional classes to the `1:` parent
    using this method, as many as you need to split up your bandwidth accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have our classes identified, we should put them to use. With our
    previous example, you''ll likely notice your bandwidth is now less than it was
    (assuming your bandwidth is above the `1.5mbit` default that we set). But our
    other two classes are unused, so we can boost our limit our bandwidth for other
    services as we see fit. So, let''s add a filter for SSH. Since SSH doesn''t require
    a great deal of bandwidth, we can assign our `1:20` class to it. To do so, we''ll
    again use the `tc` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It's possible to change the port that your server listens on for SSH connections,
    as we'll discuss in [Chapter 9](ch09.html "Chapter 9. Securing Your Network"),
    *Securing Your Network*. If you changed your SSH port, adjust the `tc` command
    accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'That leaves us with two classes, `1:1` and `1:10`. We can assign filters to
    those as well, depending on which port we would like to classify for the traffic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Here, I used ports `80` and `5060` for HTTP and VoIP traffic, respectively.
    Your ports may differ, so feel free to adjust the command accordingly to fit the
    needs of your network. But in this hypothetical example, traffic on port `80`
    will be classified as `1:1` and granted a maximum rate of `2mbit` (great for a
    web server), and traffic on port `5060` will be granted `1.5mbit`.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, classless qdiscs allow you to control the general consensus of how
    packets are managed on your system. Depending on your environment, you may find
    that changing to a classless qdisc increases performance. But the real benefit
    comes in the form of classful qdiscs, which allows you more granular control over
    how packets are handled, as well as the rates your server's resources are provided.
    Tuning network performance is a time-consuming task and requires trial and error
    to determine which values, classes, and filters will improve performance on your
    network.
  prefs: []
  type: TYPE_NORMAL
- en: Routing TCP/IP traffic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The entire purpose of networking is to get traffic from point A to point B.
    When a computer requests information from another, packets are routed to the destination
    and then back. Sometimes, computers need a little guidance on how to get packets
    to the destination. This is known as **routing**. To assist with this, nodes utilize
    the concept of a **routing table** to help decide where packets should be sent
    given specific destinations. It would be very easy if every network in existence
    used the same IP scheme, but in truth, every network is completely different.
    To talk to a different network, your computer must know how to get to that network.
    Think of a routing table as a map of external destinations and the gateways to
    get to those destinations.
  prefs: []
  type: TYPE_NORMAL
- en: To better understand this, let's also talk about the concept of the **default
    gateway**. Typically, the default gateway is a router that understands how to
    talk to other networks. When you send a request for information over a network,
    packets traverse to the local default gateway and then onto other networks from
    there. In the case of a small office or home network, the default gateway is likely
    the router that sits in between your network and the rest of the world. In addition,
    it's also in between your local device and all other devices within your network.
    Without a default gateway, it's unlikely you'd be able to communicate over your
    network at all.
  prefs: []
  type: TYPE_NORMAL
- en: To view your default gateway, issue the `ip route` command and look for the
    line that reads `default via`.
  prefs: []
  type: TYPE_NORMAL
- en: '![Routing TCP/IP traffic](img/B03919_08_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Output of the ip route command
  prefs: []
  type: TYPE_NORMAL
- en: 'Without a default gateway (or with a default gateway that hasn''t been properly
    configured), you''re likely to find that you aren''t able to communicate with
    other nodes on your network. In most cases, the default gateway is added to your
    routing table once you receive an address via DHCP. If you''re using a static
    IP configuration, you can manually set the default gateway in Debian via `/etc/network/interfaces`,
    or the init script for your network card in CentOS (such as `/etc/sysconfig/network-scripts/ifcfg-eno1`).
    Here''s a sample of these configuration files with the relevant line highlighted:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `/etc/network/interfaces` file (Debian):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The `/etc/sysconfig/network-scripts/ifcfg-eno1` file (CentOS):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'If you''d like to set your default gateway even more manually than that, you
    can also do so in your terminal via a shell command, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If the route command isn't recognized by your system, you'll need to install
    the `net-tools` package.
  prefs: []
  type: TYPE_NORMAL
- en: Simple enough. We use the route command to add a new route; in this case, we're
    adding our default gateway (`default gw`). In this case, we're setting that gateway
    to `10.10.10.1` and binding it to interface `eth0`. It probably goes without saying,
    but once you reboot this machine or restart networking, this setting will likely
    be lost unless you make it permanent by updating the `init` script for your interface
    card, as we discussed earlier.
  prefs: []
  type: TYPE_NORMAL
- en: To view your routing table, simply execute the `route -n` command without any
    arguments. If the command isn't found, you may need to call out the path (such
    as `/sbin/route`) or run it as root. When you execute this command, you'll see
    the routing table. This will also show you your default gateway.
  prefs: []
  type: TYPE_NORMAL
- en: '![Routing TCP/IP traffic](img/B03919_08_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Output of the route -n command
  prefs: []
  type: TYPE_NORMAL
- en: 'First up for discussion in regards to this table is the IP address of `0.0.0.0`.
    In terms of networking, this refers to everything. As you can see in the table
    shown in the previous example, the gateway for destination `0.0.0.0` on this network
    is `192.168.1.1`. Therefore, any communication is sent to this IP (after all,
    it is the default gateway). There are also other networks shown in this table
    as well. In my case, they refer to instances of Docker running on this test machine
    as well as KVM virtualization, and each have their own independent virtual networking.
    Since they are all running on this same machine, their gateway is local: `0.0.0.0`.'
  prefs: []
  type: TYPE_NORMAL
- en: A Linux machine can easily act as a router itself, without the need for expensive
    networking equipment from companies such as Cisco. This flexibility makes Linux
    a very prominent choice for networking, and Linux-based hardware routers are becoming
    quite common. This is due, at least in part, to how easy it is to configure a
    Linux system to be a router. In a nutshell, all it takes to turn a Linux node
    into a router is multiple network interface cards. Each interface card can have
    its own default gateway, so you can actually configure routing the same way as
    how we've added a default gateway for `eth0` earlier in this section. You would
    just do the same for `eth1`, `eth2`, or for whatever other interfaces you may
    have on the system.
  prefs: []
  type: TYPE_NORMAL
- en: However, there is one caveat. With most Linux distributions, routing between
    network interfaces is typically disabled by default. This has caused your author
    much grief and frustration until this became known early on in my career, so I'll
    save you the trouble and show you how to enable routing between interfaces on
    your Linux system.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, see if this has already been done for you. While I''ve found that many
    distributions don''t have forwarding enabled by default, some do. Checking this
    is easy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'What is the output of that command? Is it `1`? If so, you''re all set. If not,
    we''ll need to change this. To do so, simply replace the value with 1 (as root):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'That''s it, you''re done. You just enabled routing between interfaces (forwarding).
    That wasn''t so hard. But, I suppose you''d prefer this to be a permanent change.
    Once you reboot your system, it''s likely that this setting will just revert back
    to its default. To make this change permanent, edit `/etc/sysctl.conf` with your
    favorite text editor (as root) and add the following line to the end of the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Now, whenever you reboot your system, you will keep this setting. Of all the
    networking tweaks I've had you do thus far, this was definitely the easiest.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, let's spend a little bit of time on **Network Address Translation**
    (**NAT**). The concept of NAT is to alter packets that are destined for one host
    and alter them so that their destination becomes something else. This alteration
    is actually done by altering the packets themselves, and it can be quite useful
    for managing network routing. The most common use for NAT is to conserve IP addresses,
    which is especially important given the shortage of IPv4 addresses these days.
    If you have a router in your home, you're likely familiar with this concept already.
    Your **Internet Service Provider** (**ISP**) gives you an IP, and that IP is what
    the rest of the world sees you as. But within your local network, you probably
    have a dozen or so devices connected and using the same Internet connection. Each
    of your internal devices have an IP address given to them by your local DHCP server,
    but that address is just local and is not routable to the outside world. In this
    case your router keeps track of the packets coming to and from each of your devices,
    and it alters the packets so that they don't get mixed up and end up at the right
    place.
  prefs: []
  type: TYPE_NORMAL
- en: For example, say you have a laptop and a desktop (on the same network), and
    you visit [https://www.packtpub.com/](https://www.packtpub.com/) on your laptop.
    Your router sends the request out to the Internet, and delivers the result. Basically,
    your router makes that request on behalf of your laptop. When the return packets
    arrive from [https://www.packtpub.com/](https://www.packtpub.com/), the destination
    address of the packets is changed from your public IP address, back to the IP
    address of the machine that requested the information. This way, you can be reasonably
    sure your laptop will get the reply, since it was the one that asked for it in
    the first place.
  prefs: []
  type: TYPE_NORMAL
- en: 'The concept of NAT is clever, and this isn''t even the only use-case. You could
    even manually alter the destination address yourself as well, which could assist
    you with sending packets to other networks that your internal computers would
    otherwise have no idea how to route to. To alter NAT manually, we use the `ip
    rule` command. Utilizing this command is just a matter of altering the destination
    based on where the traffic is originating from. Consider the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This couldn't be simpler. Here, we're telling our system to look for any packets
    that are from `192.168.1.134`, and rewrite them to flow to `10.10.10.1` instead.
    Repeat this for any other *NATing* you need to perform.
  prefs: []
  type: TYPE_NORMAL
- en: Creating redundant DHCP and DNS servers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 6](ch06.html "Chapter 6. Configuring Network Services"), *Configuring
    Network Services*, we set up DHCP and DNS servers. This is great, but unfortunately
    there's one major problem. Either one is a single point of failure. If the DHCP
    server were to go down, new devices wouldn't be able to receive an IP address,
    and clients that are currently connected will drop off the network as their current
    IP lease expires. If the DNS server were to go down, clients wouldn't be able
    to reach destinations by the hostname. Depending on the scope of your network,
    this downtime might be hard to deal with, so having redundancy for these services
    may be a good idea.
  prefs: []
  type: TYPE_NORMAL
- en: With a DHCP server configured for redundancy with another server, it will synchronize
    its list of IP addresses that were issued, and each will detect if the other stops
    responding. In this case, the secondary would take over the task of issuing new
    IP addresses. With DNS, it's just a matter of adding another DNS server on your
    network, but I'll talk more about that in just a bit.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start with adding redundancy to our DHCP server. The initial one that
    was created earlier can be considered the primary server for the sake of simplicity.
    The next thing you would do is create another server to serve as the secondary.
    This can be another physical server or even a VM, the choice is yours. Install
    `isc-dhcp-server` as we discussed in [Chapter 6](ch06.html "Chapter 6. Configuring
    Network Services"), *Configuring Network Services*. Once you have the second server
    stood up, we can begin.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It's absolutely *imperative* to ensure the clocks are synchronized on both of
    your DHCP servers before they are placed into production. Before continuing, it
    may be a good idea to double check that NTP is configured and working on both.
    In [Chapter 6](ch06.html "Chapter 6. Configuring Network Services"), *Configuring
    Network Services*, information pertaining to setting up NTP was included.
  prefs: []
  type: TYPE_NORMAL
- en: 'Starting on our primary node, we should add some additional code to our /`etc/dhcp/dhcpd.conf`
    file. I''ve bolded the lines of configuration that are new and for the purpose
    of adding redundancy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Note that the following line was removed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: It was replaced by the pool `{}` block in the same section.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the most part, the same configuration we''ve done on our primary server
    can be copied over to the secondary. Feel free to use the /`etc/dhcp/dhcpd.conf`
    file we have here as a base for starting the configuration on the second server.
    Again, I''ll highlight what''s different between the two. The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following lines were removed from the configuration of the secondary server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: You should notice that the address of the primary and secondary are reversed
    in each. In the first configuration file, the primary is `10.10.96.1` and the
    secondary was set to `10.10.96.2`. In the second, this was changed to `10.10.96.2`
    and `10.10.96.1`, respectively. Also, pay careful attention to the IP addresses,
    subnet mask, and any other value that would likely be different from one network
    to the next. If you start the DHCP service on both your servers (on Debian, it's
    `isc-dhcp-server`, and on CentOS it's `dhcpd`) you should see them communicate
    via the logs. The specific logs to check would be `/var/log/syslog` in Debian-based
    systems and `/var/log/messages` in CentOS systems. You can easily test if this
    is working, by disabling the DHCP service on one of the servers and you should
    see the other issuing IP addresses in its place.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have redundancy configured for DHCP, let's do the same for DNS.
    In fact, this is a great deal easier. All you have to do is designate another
    server to act as your secondary DNS server (you can create a new machine, or just
    add it to your secondary DHCP server) and then copy over your configuration files
    and zone files to the new server. Again, [Chapter 6](ch06.html "Chapter 6. Configuring
    Network Services"), *Configuring Network Services*, has all the relevant details
    for these files. If you want to save a bit of time, you could even just clone
    your original DNS server into a new machine, which is easy to do if you're using
    virtualization or understand how to use the `dd` command. After whatever method
    you prefer for creating the secondary server and copying your zone files over,
    test that DNS is working on the new server. Once it is, we turn back to our DHCP
    configuration to deploy this secondary server to all of our nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our /`etc/dhcp/dhcpd.conf` file, look for the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Change it to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: You're done. Now, every time your clients' lease expires or they request a new
    IP address, they'll automatically be provided the secondary DNS address.
  prefs: []
  type: TYPE_NORMAL
- en: The only thing left to do at this point is to configure any nodes you may have
    set up with static IP addresses to use the secondary DNS server. As I've mentioned
    somewhere in the neighborhood of a thousand times by now, I highly prefer static
    leases (reserving IP addresses for various nodes on the DHCP server) to manual
    static IP assignments for this reason and more. You only need to configure them
    in the DHCP server. But if you do have any nodes you've configured networking
    by hand (to each their own), just update their `init` scripts. Again, you'll find
    this configuration in `/etc/network/interfaces` (Debian) or `/etc/sysconfig/network-scripts/<if-name>.cfg`
    (CentOS).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point in our journey, your network should be in much better shape. In
    this chapter, we accomplished quite a bit. We've discussed advanced topics such
    as routing, NAT, subnetting, Quality of Service, and we even set up redundancy
    for our DHCP and DNS servers. It would sure be a shame if something were to happen
    to our awesome network. That's why in the next chapter, I'll cover how to strengthen
    the security of our network. See you there!
  prefs: []
  type: TYPE_NORMAL
