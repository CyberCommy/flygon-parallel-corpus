- en: ECS Auto Scaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Elasticity** is one of the fundamental tenets of cloud computing, and describes
    the ability to auto scale your applications on demand to ensure the best possible
    experience and responsiveness for your customers, while optimizing cost by only
    providing additional capacity for your application when it is actually required.'
  prefs: []
  type: TYPE_NORMAL
- en: 'AWS supports scaling your Docker applications that are deployed using ECS via
    two key features:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Application Auto Scaling**: This uses the AWS application auto scaling service
    and supports Auto Scaling at an ECS service level, where the number of ECS tasks
    or containers running your ECS services can be scaled up or down.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**EC2 Auto Scaling**: This uses the EC2 Auto Scaling service and supports Auto
    Scaling at an EC2 Auto Scaling group level, where the number of EC2 instances
    in your Auto Scaling group can be scaled up or down. In the context of ECS, your
    EC2 Auto Scaling groups typically correspond to ECS clusters, and the individual
    EC2 instances correspond to ECS container instances, so EC2 Auto Scaling is managing
    the overall capacity of your ECS cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because there are two paradigms at play here, the goal of Auto Scaling for your
    Docker applications can be a challenging technical concept to understand, let
    alone implement successfully in a predictable and reliable manner. This is further
    exacerbated by the fact that, as of the time of writing this book, application
    auto scaling and EC2 Auto Scaling are completely independent features that offer
    no integration with each other, hence, you are responsible for ensuring both features
    work together with one another.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to analyzing each of these features, the good news is that application
    auto scaling is very straightforward to understand and implement. With application auto
    scaling, you simply need to define the key performance metrics for your applications,
    and scale up (increase) or scale down (decrease) the number of ECS tasks that
    run your application. The bad news is that EC2 auto scaling, when applied in the
    context of auto scaling ECS container instances in an ECS cluster, is definitely
    a much harder proposition to deal with. Here, you need to ensure your ECS clusters
    are providing enough compute, memory, and network resources across all ECS tasks
    running in your cluster, and you need to ensure that your cluster is able to add
    or remove capacity whenever application auto scaling scales individual ECS services
    up or down.
  prefs: []
  type: TYPE_NORMAL
- en: Another challenge of scaling ECS clusters is ensuring you do not disrupt service
    and drain running tasks on an ECS container instance that is about to be removed
    from the cluster during a scale down/in event. The ECS life cycle hooks solution
    implemented in Chapter 11 - *Managing the ECS Infrastructure Life Cycle* takes
    care of this for you, ensuring the ECS container instances are drained of all
    running tasks before permitting the EC2 auto scaling service to take an instance
    out of service.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with the problem of scaling your ECS cluster resources is the primary
    focus of this chapter, as once solved, you will be able to arbitrarily scale each
    of your ECS services and be assured that your ECS cluster will dynamically add
    or remove ECS container instances to ensure there is always sufficient and optimal
    resources for your applications. In this chapter, we will first focus on solving
    the problem of ECS cluster-capacity management, and then discuss how to configure
    the AWS application auto scaling service to auto scale your ECS services and applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the ECS cluster resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculating the ECS cluster capacity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing an ECS cluster-capacity management solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring CloudWatch events to trigger capacity-management calculations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Publishing custom CloudWatch metrics related to the ECS cluster capacity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring CloudWatch alarms and EC2 auto scaling policies to scale your ECS
    clusters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring ECS application auto scaling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following lists the technical requirements to complete this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Administrator access to an AWS account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Local AWS profile configured as per the instructions in Chapter 3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS CLI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter continues on from Chapter 11, so it requires that you have successfully
    completed all the configuration tasks defined there.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The following GitHub URL contains the code samples used in this chapter: [https://github.com/docker-in-aws/docker-in-aws/tree/master/ch12](https://github.com/docker-in-aws/docker-in-aws/tree/master/ch12).
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://bit.ly/2PdgtPr](http://bit.ly/2PdgtPr)'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding ECS cluster resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before you can start to manage the capacity of your ECS clusters, you need to
    have a clear and solid understanding of the various resources that affect the
    capacity of your ECS clusters.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, there are three key resources that you need to consider:'
  prefs: []
  type: TYPE_NORMAL
- en: CPU
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CPU resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**CPU** is a core resource that Docker supports and manages as a first-class
    citizen. ECS leverages the CPU resource management capabilities of Docker, and
    exposes the ability to manage these via your ECS task definitions. ECS defines
    CPU resources in terms of *CPU units*, where a single CPU core contains 1,024
    CPU units. When you configure your ECS task definitions, you specify a CPU reservation,
    which defines how much CPU time will be allocated to the application whenever
    there is contention for CPU time.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that a CPU reservation is not a limit as to how much CPU the ECS task can
    use–each ECS task is free to burst and use all available CPU resources–the reservation
    is only applied when there is contention for CPU, and Docker attempts to allocate
    CPU time fairly based upon the configured reservation for each running ECS task.
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s important to understand that each CPU reservation deducts from the available
    CPU capacity of a given ECS container instance. For example, if your ECS container
    instance has 2 CPU cores, that equates to a total of 2,048 CPU units. If you run
    3 ECS tasks that are configured with 500, 600, and 700 CPU units, this means that
    your ECS container instance has 2,048 - (500 + 600 + 700), or 248, CPU units available.
    Note that whenever the ECS scheduler needs to run a new ECS task, it will always
    ensure that a target ECS container instance has enough CPU capacity to run the
    task. Following on from the previous example, if a new ECS task needed to be started
    that reserves 400 CPU units, then the ECS container instance with 248 CPU units
    remaining would not be considered, given it does not have sufficient CPU resources
    currently available:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/a5a2aea8-a27b-4ae9-baa9-7e542ad03403.png)'
  prefs: []
  type: TYPE_IMG
- en: Allocating CPU resources
  prefs: []
  type: TYPE_NORMAL
- en: In terms of configuring CPU reservations, you have already learned how to do
    this via CloudFormation–see the *Defining an ECS task definition using CloudFormation* example
    in Chapter 8 - *Deploying applications using ECS*, where you assigned a value
    of 245 to the todobackend container definition, via a property called `Cpu`.
  prefs: []
  type: TYPE_NORMAL
- en: Memory resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Memory** is another fundamental resource that is managed via Docker, and
    works in a similar fashion to CPU, although you can both reserve and limit memory
    capacity for a given ECS task, whereas you can only reserve (not limit) CPU resources
    when it comes to managing CPU capacity. This additional ability to limit memory
    results in three scenarios when it comes to configuring memory for your ECS tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Memory reservation only**: This scenario behaves identically to how CPU reservations
    work. Docker will deduct the configured reservation from the available memory
    of the ECS container instance, and attempt to allocate this amount of memory whenever
    there is contention for memory. ECS will allow the ECS task to use up to the maximum
    amount of memory supported by the ECS container instance. Memory reservations
    are configured using the `MemoryReservation` property within an ECS task container
    definition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Memory reservation + limit**: In this scenario, the memory reservation works
    as the previous scenario, however, the maximum amount of memory that the ECS task
    can ever use is constrained by the configure memory limit. In general, configuring
    both a memory reservation and memory limit is considered the best option. Memory
    limits are configured using the `Memory` property within an ECS task container
    definition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Memory limit only**: Here, ECS treats the memory reservation and memory limit
    values as one and the same, meaning ECS will deduct the configured memory limit
    from the available ECS container instance memory, and also limit memory usage
    to the same limit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring memory reservations and limits is straightforward–if you refer back
    to the *Defining an ECS task definition using CloudFormation* section of Chapter
    8 - *Deploying Applications Using ECS*, you can see that you configure the `MemoryReservation`
    property to configure a reservation of 395 MB. If you wanted to configure a memory
    limit, you would also need to configure the `Memory` property with an appropriate
    maximum limit value.
  prefs: []
  type: TYPE_NORMAL
- en: Network resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'CPU and memory are typical and obvious resources that you would expect your
    ECS clusters to control and manage. One less obvious set of resources is *network
    resources*, which can be split into two categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Host network ports**: Whenever you configure static port mappings for your
    ECS services, host network ports is a resource that you will need to consider.
    The reason is that static port mappings use a common port exposed by the ECS container
    instance–for example, if you created an ECS task with a static port mapping that
    exposes port 80 for a given application, you won''t be able to deploy another
    instance of the ECS task on the same ECS container instance host, given port 80
    is still in use.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Host network interfaces**: If you are using ECS task networking, it is important
    to understand that this feature currently requires you to implement a single elastic
    network interface (ENI) per ECS task. Because EC2 instances have finite limits
    as to the number of ENIs each instance type can support, the number of ECS tasks
    configured with ECS task networking that can be supported will be restricted to
    the maximum number of ENIs the ECS container instance can support.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculating the ECS cluster capacity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before you can calculate the ECS cluster capacity, you need to have a clear
    understanding of which resources affect capacity and how you can calculate the
    current capacity for each resource. Once you have defined this for each individual
    resource, you then need to apply an aggregate calculation across all resources,
    which will result in a final calculation of the current capacity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculating capacity can appear to be quite a daunting task, especially when
    you consider the different types of resources and how they behave:'
  prefs: []
  type: TYPE_NORMAL
- en: '**CPU**: This is the simplest resource you can work with, as each CPU reservation
    simply deducts from the available CPU capacity of the cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Memory:** Calculating the current capacity of the cluster based upon memory
    is identical to CPU in that a memory reservation deducts from the available memory
    capacity of the cluster. As per our earlier discussion in this chapter, how the
    memory reservation is configured is complicated by the various permutations of
    memory limits and memory reservations, however fundamentally once you have determined
    the memory reservation, the calculation is the same as for CPU resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Static network ports**: If your ECS cluster needs to support *any* containers
    that are using static port mappings, then you need to consider your ECS container
    instance network ports as a resource. For example, if a container application
    always uses port 80 on the ECS container instance, then you can only ever deploy
    one container per instance, regardless of how much CPU, memory, or other resources
    that instance might possess.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network interfaces**: If you are have any ECS services or tasks that are
    configured for ECS task networking, it is important to understand you can currently
    only run one ECS task per network interface. For example, if you are running a
    t2.micro instance, this means you can only run one ECS task with task networking
    enabled per instance, given a t2.micro can only support a single elastic network
    interface for ECS task networking.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given the sample application is not using ECS task networking and is being deployed
    using dynamic port mapping, we will only consider CPU and memory resources for
    the remainder of this chapter. If you are interested in an example solution that
    incorporates static network ports, check out the Auto Scaling ECS Applications
    module of my [Docker in Production Using Amazon Web Services](https://www.pluralsight.com/courses/docker-production-using-amazon-web-services)
    course.
  prefs: []
  type: TYPE_NORMAL
- en: The challenge here is how to consider all of your ECS services and tasks in
    terms of all of the preceding considerations, and then make a decision as to when
    you should scale up or scale down the number of instances in your cluster. A common
    and somewhat naive approach I have seen is to treat each resource independently
    and scale your instances accordingly. For example, you would add a new container
    instance as soon as your cluster runs out of memory capacity, and similarly if
    your cluster is about to run out of CPU capacity. This approach works fine if
    you consider purely the ability to scale out, however it does not work when you
    want to scale in your cluster. If you scale in your cluster solely based upon
    current memory capacity, you risk scaling in too soon in terms of CPU capacity,
    as your cluster may not have sufficient CPU capacity if you remove an instance
    from the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: This will risk your cluster getting stuck in an auto scaling loop–that is, your
    cluster keeps on scaling out and then in, and this is because individual resource
    capacities are independently driving scale-in and scale-out decisions, without
    consideration of the impact to other resources.
  prefs: []
  type: TYPE_NORMAL
- en: The key to solving this challenge is that you need to make a *single* decision
    to scale out or in, and consider *all* applicable resources for your cluster.
    This might make the overall problem seem a whole lot harder to solve, however
    it is actually quite simple. The crux of the solution is that you always consider
    the *worst-case scenario*, and make a decision based upon that. For example, if
    you have plenty of CPU and memory capacity in your cluster, however all static
    port mappings for a given port are in use on all of your cluster instances, the
    worst-case scenario says if you scale in your cluster and remove an instance,
    you will no longer be able to support the current ECS tasks that are using the
    affected static port mapping. Therefore, the decision here is simple and is purely
    based upon the worst-case scenario–all other scenarios are ignored.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the container capacity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One key consideration when calculating the capacity of your cluster is that
    you need to normalize your resource capacity calculations, such that the capacity
    of each resource can be expressed in a common and equivalent format, independent
    of the specific units of measurement for each individual resource. This is critical
    in making a collective decision that considers all resources, and a natural way
    to do this is to express resource capacity in terms of the number of additional
    ECS tasks that can be supported using the currently available unallocated resources.
    In addition, keeping with the theme of worst-case scenarios, you don't need to
    consider all of the different ECS tasks that you need to support–you only need
    to consider the ECS task that is the worst case (the one requiring the most resources)
    for the resource you are currently calculating the capacity for.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if you have two ECS tasks that require 200 CPU units and 400 CPU
    units, respectively, you only need to calculate the CPU capacity in terms of the
    ECS task with 400 CPU units:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/dd9bfcd2-98df-4a3e-9140-462f6575f3a0.png)'
  prefs: []
  type: TYPE_IMG
- en: The expression with the somewhat strange upside down A in the formula means
    "for each taskCpu value in a given set of taskDefinitions".
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have determined the worst-case ECS task that needs to be supported,
    you can proceed to calculate the number of additional ECS tasks that the cluster
    can currently support. Given the worst-case ECS task requires 400 CPU units, if
    we now assume that you have two instances in your cluster that each have 600 CPU
    units of free capacity, this means you can currently support an additional 2 ECS
    tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/43729108-b796-419e-9e92-32de63550246.png)'
  prefs: []
  type: TYPE_IMG
- en: Calculating container capacity
  prefs: []
  type: TYPE_NORMAL
- en: It's important to note here that you need to make this calculation on a per-instance
    basis, rather than just making the calculation across the entire cluster. Using
    the previous example, if you consider the free CPU capacity across the entire
    cluster, you have 1,200 CPU units available and therefore you would calculate
    a free capacity of three ECS tasks, however the reality is that you can't *split* the
    ECS task across 2 instances, so if you consider the free capacity on a per-instance
    basis, it's obvious you can only support one additional ECS task on each instance
    for a correct total of 2 additional ECS tasks across the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be formalized as a mathematical equation, as follows, where the![](assets/1a7ada8d-43a9-4c10-a5bc-be9a6ea6f917.png) annotation
    on the right-hand side of the formula means to take *floor* or the lowest nearest
    integer value of the calculation, andrepresents an instance in the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/f68b3eb6-74a7-4799-94d9-feaa134f7d59.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If you repeat the previous approach for your memory resource, you will calculate
    a separate calculation that defines the current spare capacity of the cluster
    in terms of memory. If we assume the worst-case ECS task for memory requires 500
    MB of memory and both instances have 400 MB available, it''s obvious that in terms
    of memory, the cluster currently has no spare capacity:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bbf249ea-73f3-449a-b9bd-5539dcbf50d3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If you now consider the two previous calculations for CPU (currently two free
    ECS tasks) and memory (currently zero ECS tasks), it''s obvious that the worst
    case scenario is the memory capacity calculation of zero free ECS tasks, which
    can be formalized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/adf03873-dfc3-4bee-b660-ed1316ce93a2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Note that although we are not incorporating calculations for static network
    ports and network interfaces to help simplify our solution, the general approach
    is the same–calculate the current capacity for each instance and sum to obtain
    an overall cluster capacity value for the resource, and then incorporate the value
    into the overall cluster capacity calculation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/72628df2-87bc-4414-a63f-3588709b546c.png)'
  prefs: []
  type: TYPE_IMG
- en: Deciding when to scale out
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point, we have established that you need to assess each of the current
    resource capacities in your cluster, express this in terms of the number of free
    or spare ECS tasks your cluster currently can support, and then use the worst-case
    calculation (minimum value) to determine your overall current cluster capacity.
    Once you have this calculation, you need to decide whether or not you should scale
    out the cluster, or leave the current cluster capacity unchanged. Of course, you
    also need to decide when to scale in the cluster, however we will discuss that
    topic separately soon.
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, we will focus on whether or not we should scale *out* the cluster
    (that is, add capacity), as this is the simpler scenario to evaluate. The rule
    here is that at a minimum, you should scale out your cluster whenever your current
    cluster capacity is less than one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/58383abe-4357-4cb0-924c-090eac36d6f7.png)'
  prefs: []
  type: TYPE_IMG
- en: In other words, if you do not currently have sufficient capacity in your cluster
    to support one more *worst-case* *scenario* ECS task, you should add a new instance
    to the ECS cluster. This makes sense, in that you are attempting to ensure that
    your cluster always has sufficient capacity for new ECS tasks as they are started.
    Of course, you can increase this threshold higher if you want more free capacity,
    which might be applicable for more dynamic environments where containers are often
    spinning up and down.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the idle host capacity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If we now consider the scale-in scenario, this becomes a little bit harder
    to determine. The spare ECS task capacity calculation we have discussed is related
    and required, however you need to think in these terms: if you removed an ECS
    container instance from the cluster, would there be enough capacity for all of
    the current running ECS tasks plus spare capacity for at least one additional
    ECS task? Another way to express this is to calculate the *idle host capacity*
    of the cluster–if greater than 1.0 hosts are idle in the cluster, then you can
    safely scale in the cluster, as subtracting a host would result in a remaining
    positive non-zero capacity. Note that we are referring to idle host capacity across
    the cluster–so think of this as more of a virtual host calculation, as you probably
    won''t have a completely idle host. This virtual host calculation is safe, because
    if we did remove a host from the cluster, the life cycle hooks and ECS container
    instance-draining features we introduced previously in Chapter 11 - *Managing
    the ECS Infrastructure Life Cycle* will ensure any containers that are running
    on the instance to be removed will be migrated to other instances in the cluster.'
  prefs: []
  type: TYPE_NORMAL
- en: It's also important to understand that the idle host capacity must be greater
    than 1.0 and not equal to 1.0, as you must have enough spare capacity for one
    ECS task, otherwise you will trigger a scale-out action, resulting in an auto
    scaling scale-out/scale-in loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'To determine the current idle host capacity, we need to understand the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The maximum number of ECS tasks that each ECS container instance can run for
    each of the different types of ECS resources (expressed as ![](assets/ded39ac8-2846-4051-8be4-ce102e7957d4.png)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The current free capacity for each type of ECS resource across the entire cluster
    (expressed as ![](assets/848fe089-3774-4825-8c43-ef5ea0ac8539.png)), which we
    already calculate when determining whether to scale out.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With these pieces of information, you can calculate the idle host capacity
    for a given resource as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/d6c9883f-b371-4841-9fd4-7e37766be0fc.png)'
  prefs: []
  type: TYPE_IMG
- en: Idle host capacity example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To make this more apparent, let''s work through an example, as illustrated
    in the following diagram, which starts by assuming the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Worst-case ECS task CPU requirement of 400 CPU units
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Worst-case ECS task memory required of 200 MB
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each ECS container instance support has a maximum of 1,000 CPU units and 1,000
    MB memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Two ECS container instances currently in the ECS cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each ECS container instance currently has 600 CPU units' spare capacity. Using
    the free capacity calculations discussed previously, this equates to a current
    free capacity across the cluster of two
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ECS tasks in terms of CPU resources, which we will refer to as ![](assets/fe5db803-ec6f-4713-9618-9e2eac790629.png).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each ECS container instance currently has 800 MB of spare capacity. Using the
    free capacity calculations discussed previously, this equates to a current free
    capacity across the cluster of eight ECS tasks in terms of memory resources, which
    we will refer to as ![](assets/d214eb41-2e71-45da-babb-68b187099957.png):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](assets/6f13b876-6d57-4671-8b33-368c9854c33a.png)Idle host capacity'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can first calculate the ![](assets/ab3ad606-7126-402a-8bc2-17b6ac2916d3.png)value
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/a4a2e4f2-fc90-47ca-8260-a8a8a86f925b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For CPU, it equates to a value of 2, and for memory equates to a value of *5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/3d4d598d-9e35-4bfb-b62d-e92855b344d6.png)![](assets/761d58d4-9b6c-46b0-82c9-7781d9f2987c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'With these values calculated and knowledge of the current free capacity of
    the cluster, we can now calculate the idle host capacity for each resource:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/e923ae69-d5f0-4d01-b2ca-1943fd040d19.png)![](assets/d9551f76-8da1-491b-bbba-816942c7297b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here''s how to calculate a worst-case overall idle host capacity:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/7201e489-d66f-4cae-b766-2b62ae79f69d.png)'
  prefs: []
  type: TYPE_IMG
- en: At this point, given the idle host capacity is 1.0, we should *not* scale in
    the cluster as the capacity is not currently *greater* than 1\. This may seem
    counterintuitive given you have exactly one idle host, but if you did remove an
    instance at this point, it would result in an available CPU capacity of 0 for
    the cluster, and the cluster would scale out given there is no free CPU capacity.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing an ECS Auto Scaling solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that you have a good understanding of how to calculate the ECS cluster
    capacity for the purposes of making scale-out and scale-in decisions, we are ready
    to implement an auto scaling solution, as illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/42bafe58-768e-4b70-9a30-b8e072ea6c64.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following provides a walkthrough of the solution shown in the preceding
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: Before you calculate the ECS cluster capacity, you need a mechanism that will
    trigger calculations of capacity, ideally whenever the capacity of your ECS container
    instances changes. This can be achieved by leveraging the CloudWatch Events service,
    which publishes events for various AWS services including ECS, and allows you
    to create *event rules* that subscribe to specific events and process them using
    a variety of mechanisms, including a Lambda function. CloudWatch events support
    receiving information about ECS container-instance state changes, and this represents
    the ideal mechanism for triggering cluster capacity calculations, as any change
    to the available resources of an ECS container instance will trigger a state-change
    event.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A Lambda function responsible for calculating ECS cluster capacity is triggered
    for each ECS container-instance state-change event.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rather than making a decision to auto scale the cluster, the Lambda function
    simply publishes the current capacity in the form of CloudWatch custom metrics,
    which report both the current free container capacity and the idle host capacity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The CloudWatch service is configured with alarms that trigger EC2 auto scaling
    actions whenever the free container capacity or idle host capacity falls below
    or exceeds the threshold for scaling out or scaling in the cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The EC2 auto scaling service is configured with EC2 auto scaling policies, which
    are invoked in response to alarms raised by CloudWatch.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In addition to the CloudWatch alarms configured to manage the ECS cluster capacity,
    you can configure appropriate CloudWatch alarms for each of your ECS services,
    which can then trigger the AWS application auto scaling service to scale out or
    scale in the number of ECS tasks that are running for your ECS services. For example,
    in the preceding diagram, the ECS service is configured with an application auto
    scaling policy that increases the number of ECS tasks should the CPU utilization
    for the ECS service exceed 50%.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let's now implement the various components of the solution.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring CloudWatch events for ECS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first task we need to perform is to set up a CloudWatch event rule, which
    subscribes to ECS container-instance state-change events and is configured with
    a target of a Lambda function that will calculate the ECS cluster capacity.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example demonstrates adding a CloudWatch event rule to the todobackend-aws
    `stack.yml` CloudFormation template:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The `EcsCapacityEvents` resource defines the event rule and includes two key
    properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '`EventPattern`: Defines the pattern that matches events to this rule. All CloudWatch
    events include `source`, `detail-type`, and `detail` properties, and the event
    pattern ensures only ECS events (as defined by the `source` pattern of `aws.ecs`)
    that relate to ECS container-instance state changes (as defined by the `detail-type`
    pattern) for the `ApplicationCluster` resource (as defined by the `detail` pattern)
    that will be matched to the rule.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Targets`: Defines the target resource that the event should be routed to.
    In the preceding example, you reference the ARN of a Lambda function called `EcsCapacityFunction`,
    which you will define shortly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `EcsCapacityPermission` resource ensures the CloudWatch events service has
    permission to invoke the `EcsCapacityFunction` Lambda function. This is a common
    approach for any service that invokes a Lambda function, where you add a Lambda
    permission that grants a given resource (as defined by the `SourceArn` property)
    for a given AWS service (as defined by the `Principal` property) the ability to
    invoke a Lambda function ( `FunctionName` property).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s add the referenced Lambda function, along with an IAM role and
    CloudWatch logs group:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: By now, you should have a good understanding of how to define Lambda functions
    using CloudFormation, so I won't describe the preceding example in depth. Note,
    however, that for now, I have implemented a basic function that simply prints
    any received events–we will use to this to gain an initial understanding of how
    the ECS container instance state change events are structured.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, you can now deploy your changes using the `aws cloudformation
    deploy` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Once deployment is complete, you can trigger an ECS container-instance state
    change by stopping an existing ECS task that is running on your ECS cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Because this ECS task is linked to an ECS service, ECS will automatically start
    a new ECS task, and if you head over to the CloudWatch console, select Logs, and
    then open the most recent log stream for the log group for the Lambda function
    that processes ECS container instance state change events (`/aws/lambda/todobackend-ecsCapacity`),
    you should see a couple of events have been logged:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/7c264632-6b24-4dd9-b464-645108398b4e.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding screenshot, you can see that two events were logged within
    a couple of seconds, which represent you stopping the ECS task and ECS then automatically
    starting a new ECS task to ensure the linked ECS service meets its configured
    desired count.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see that the `source` and `detail-type` properties match the event
    pattern you configured earlier, and, if you scroll down further in the second
    event, you should find a property called `registeredResources` and `remainingResources`,
    as demonstrated in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The `registeredResources` property defines the total resources allocated to
    the instance, while `remainingResources` indicates the current remaining quantity
    of each resource. Because the event in the preceding example is raised when ECS
    starts a new ECS task for the todobackend service, the total 250 CPU units and
    400 MB of memory allocated to this task are deducted from `registeredResources`,
    which is then reflected in the `remainingResources` property. Notice also at the
    top of the output of Example 12-6 that the event includes other useful information,
    such as the ECS cluster ARN and ECS container instance ARN values (as specified
    by the `clusterArn` and `containerInstanceArn` properties).
  prefs: []
  type: TYPE_NORMAL
- en: Programming the Lambda function that calculates the cluster capacity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that you have set up a CloudWatch event and Lambda function that is invoked
    whenever ECS container-instance state changes are detected, you can now implement
    the required application code in the Lambda function that will perform the appropriate
    ECS cluster-capacity calculations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, you first define the maximum CPU and maximum memory
    of the ECS tasks that your cluster will support, which is required to make the
    various cluster-capacity calculations, and we use the current configured CPU and
    memory settings for the todobackend service, given this is the only application
    we are supporting on our cluster. Within the `handler` function, the first step
    is to collect the current resource capacity data using the received CloudWatch
    event. The event includes details about the maximum capacity of your ECS container
    instance in the `registeredResources` property, and also includes the ECS cluster
    that the instance belongs to. The function first lists all of instances in the
    cluster, and then loads detailed information about each instance using the `describe_container_instances`
    call on the ECS client.
  prefs: []
  type: TYPE_NORMAL
- en: The information collected on each instance is limited to ACTIVE instances only,
    as you don't want to include resources for instances that may be in a DRAINING
    state or some other non-active state.
  prefs: []
  type: TYPE_NORMAL
- en: The code in the preceding example, will only work correctly in a Python 3.x
    environment, so ensure your Lambda function is configured to use Python 3.6.
  prefs: []
  type: TYPE_NORMAL
- en: With the necessary information collected about each ECS container instance,
    you then iterate through each instance and calculate the CPU and memory capacity.
    This calls helper functions that query the `remainingResources` property for each
    instance, which return the current available capacity of each resource. Each calculation
    is expressed in terms of the maximum-sized containers you defined earlier, and
    is summed together to provide the CPU and memory capacity across the cluster,
    which is printed for informational purposes.
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to calculate the overall container capacity, which is easily
    calculated by taking the minimum value of the previously calculated resource capacities,
    and this will be used to determine when your ECS cluster needs to scale out, at
    the very least when container capacity falls below zero. Finally, the idle host
    capacity calculation is made–this value will be used to determine when your ECS
    cluster should scale in, which should only happen if the idle host capacity is
    greater than 1.0, as discussed previously.
  prefs: []
  type: TYPE_NORMAL
- en: Adding IAM permissions for calculating the cluster capacity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One point to note about the code in the preceding example, is that it requires
    the ability to call the ECS service and execute the `ListContainerInstances` and
    `DescribeContainerInstances` API calls. This means you need to add the appropriate
    IAM permissions to the Lambda function IAM role, as demonstrated in the following
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Testing cluster-capacity calculations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You have added the code required to calculate the cluster capacity, and ensured
    that your Lambda function has the appropriate permissions to query ECS to determine
    the current capacity of all ECS container instances in the cluster. You can now
    deploy your changes using the `aws cloudformation deploy` command, and, once deployment
    is complete, you can test your Lambda function again by stopping any ECS task
    that is running inside the todobackend ECS cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you review the CloudWatch logs for your Lambda function, you should see
    events similar to those shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ce9d382e-863a-4cc2-a461-e0cb3898e99e.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice that when you stopped the ECS task (as represented by the stop task event),
    the Lambda function reports a CPU capacity of 4, memory capacity of 2, and an
    overall capacity of 2, which is the minimum value of each of the calculated resource
    capacities.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you sanity-check this, you should find that the calculations are accurate
    and correct. For the initial event, because you stopped the ECS tasks, there are
    no tasks running, so the available CPU and memory resources are 1,024 units and
    993 MB, respectively (the capacity of a t2.micro instance). This equates to the
    following container capacities:'
  prefs: []
  type: TYPE_NORMAL
- en: CPU capacity = 1024 / 250 = 4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory capacity = 993 / 400 = 2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When ECS automatically replaces the stopped ECS task, you can see that the
    cluster capacity drops, given a new ECS task (with 250 CPU units and 400 MB of
    memory) is now consuming resources:'
  prefs: []
  type: TYPE_NORMAL
- en: CPU capacity = 1024 - 250 / 250 = 774 / 250 = 3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory capacity = 993 - 400 / 400 = 593 / 400 = 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, you can see that the overall idle host capacity is correctly calculated
    as 1.0 when you stop the ECS task, which is correct as no ECS tasks are running
    on your cluster at that time. When ECS replaces the stopped task, the overall
    idle host capacity reduces to 0.5, given the ECS container instance is now running
    one out of the maximum two ECS tasks that can be run on a single instance in terms
    of memory resources.
  prefs: []
  type: TYPE_NORMAL
- en: Publishing custom CloudWatch metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At this point, we are calculating the appropriate metrics that determine when
    you need to both scale out or scale in the cluster, and the final task that needs
    to be performed in the function is to publish custom CloudWatch event metrics,
    which we can use to trigger auto scaling policies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, you use the CloudWatch client `put_metric_data` function
    to publish the `ContainerCapacity` and `IdleHostCapacity` custom metrics within
    the AWS/ECS namespace. These metrics are dimensioned based upon the ECS cluster,
    as specified by the ClusterName dimension name, and are limited to the todobackend
    ECS cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'One final configuration task required to ensure the Lambda function operates
    correctly is to grant the function permissions to publish the CloudWatch metrics.
    This is achieved by adding the appropriate IAM permissions to the `EcsCapacityRole`
    you created earlier in the previous example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'If you now deploy your changes using the `aws cloudformation deploy` command
    and then stop a running ECS task, after switching over to the CloudWatch console,
    you should be able to see new metrics being published in relation to your ECS
    cluster. If you select **Metrics** from the left-hand menu and then select **ECS
    > ClusterName** under **All metrics**, you should see your custom metrics (`ContainerCapacity`
    and `IdleHostCapacity`). The following screenshot shows these metrics graphed
    on the basis of the maximum value collected within a one-minute period. At 12:49
    on the graph, you can see both the `ContainerCapacity` and `IdleHostCapacity`
    metrics increased when you stopped the ECS task, and then once ECS started a new
    ECS task, the values for both metrics decreased as the new ECS task was allocated
    resources from your cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/59c87186-8313-4217-ba03-df4041c220e8.png)'
  prefs: []
  type: TYPE_IMG
- en: Creating CloudWatch alarms for cluster-capacity management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You now have the ability to calculate and publish ECS cluster capacity metrics
    whenever an ECS container-instance state change occurs in your ECS cluster. The
    next step in the overall solution is to implement CloudWatch alarms, which will
    trigger auto scaling actions whenever a metric exceeds or drops below a specified
    threshold that relates to cluster capacity.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code demonstrates adding two CloudWatch alarms to the todobackend
    stack:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, you add two CloudWatch alarms–a `ContainerCapacityAlarm` that
    will be used to trigger scale-out actions whenever the container capacity falls
    below 1, and an `IdleHostCapacityAlarm` that will be used to trigger scale-in
    actions whenever the idle host capacity is greater than 1\. The various properties
    for each alarm are described in further detail here:'
  prefs: []
  type: TYPE_NORMAL
- en: '`AlarmActions`: Defines the actions that should be taken should the alarm breach
    its configured criteria. Here we reference the EC2 auto scaling policy resources
    that we will define shortly, which trigger the appropriate auto scaling scale-out
    or scale-in action whenever an alarm is raised.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Namespace`: Defines the namespace of the metric the alarm relates to.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Dimensions`: Defines the context of how the metric relates to resources within
    the given namespace. In the preceding example, the context is configured as the
    ECS cluster within our stack.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MetricName`: Defines the name of the metric. Here, we specify the name of
    each custom metric we published in the previous section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Statistic`: Defines the statistic of the metric that should be evaluated.
    This is actually quite an important parameter and, as an example in the case of
    the container capacity alarm, setting a value of maximum ensures transient metrics
    that fall below the configured threshold of 1 will not unnecessarily trigger the
    alarm, assuming that at least 1 value during each evaluation period exceeds the
    configured threshold. The same is applied for the idle host capacity alarm but
    in the opposite direction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Period`, `EvaluationPeriods`, `Threshold`, and `ComparisonOperator`: These
    define the timeframe over which the metric must fall outside the bounds of the
    configured threshold and comparison operator. If these bounds are exceeded, an
    alarm will be raised.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TreatMissingData`: This setting defines how you should treat missing metric
    data. In our use case, missing metric data is a common occurrence given we only
    publish metrics whenever an ECS container instance state changes, so setting a
    value of `ignore` ensures we do not treat missing data as an indication that something
    is wrong.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating EC2 Auto Scaling policies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You now need to create the EC2 auto scaling policy resources that you referenced
    in each CloudWatch alarm resource.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example demonstrates adding a scale-out and scale-in policy to
    the todobackend stack:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, you define two auto scaling policies of the `SimpleScaling`
    type, which represents the simplest form of auto scaling that you can implement.
    A discussion of the various auto scaling types is outside the scope of this book,
    however if you are interested in learning more about the available options, you
    can refer to [https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scale-based-on-demand.html](https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scale-based-on-demand.html). 
    The `AdjustmentType` and `ScalingAdjustment` properties are configured to either
    increase or decrease the size of the auto scaling group by one instance, while
    the `Cooldown` property provides a mechanism to ensure further auto scaling actions
    are disabled for the specified duration, which can help avoiding auto scaling
    loops where your clusters keep on scaling out and scaling in frequently.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the `ApplicationAutoscaling` `UpdatePolicy` setting has been updated
    to include the `SuspendProcesses` parameter, which configures CloudFormation to
    disable certain operational processes whenever an auto scaling rolling update
    is taking place. This specifically disables auto scaling operations during a rolling
    update, which is important as you don't want auto scaling actions interfering
    with the rolling update that is orchestrated by CloudFormation. Finally, we also
    set the various count settings on the `ApplicationAutoscaling` resource to a fixed
    value of 1, as auto scaling will now manage the size of our ECS cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Testing ECS cluster-capacity management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, that we have all of the components to calculate the ECS cluster capacity,
    publish metrics, and trigger alarms that will invoke auto scaling actions, let's
    deploy our changes and test the solution works as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Testing scale out
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To artificially trigger a scale-out action, we need to set the `ApplicationDesiredCount`
    input parameter to 2 in the `dev.cfg` configuration file, which will increase
    the ECS task count for our ECS service to 2 and will cause the single ECS container
    instance in the ECS cluster to no longer have enough resources to support any
    further additional containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This configuration change should result in the `ContainerCapacity` metric falling
    below the configured alarm threshold of `1`, which we can test by now deploying
    our changes to CloudFormation by running the `aws cloudformation deploy` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the deployment is complete, if you browse to the CloudWatch console and
    select Alarms from the left-hand menu, you should see your container capacity alarm
    go into an ALARM state (this may take a few minutes) as demonstrated earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/3aedb0f1-0201-435f-b6b0-557d67d1ed07.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see in the Actions details that the CloudWatch alarm has triggered the
    application Auto Scaling scale-out policy, and notice in the graph on the left
    that this is because the container capacity has dropped to 0 due to the increase
    in ECS tasks running on the single ECS container instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you now navigate to the EC2 console, select **Auto Scaling Group**s from
    the left-hand menu, and then select the **Activity History** tab for the todobackend
    auto scaling group, you can see that the current instance count in the auto scaling
    group is `2`, and that a new EC2 instance was launched due to the container capacity
    alarm transitioning to an ALARM state:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/f9681a0f-4867-4e7c-adca-a75bc78fc5d7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once the new ECS container instance is added to the ECS cluster, a new capacity
    calculation will take place, and if you switch back to the CloudWatch console,
    you should see the ContainerCapacity alarm eventually transition to an OK state,
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/4ae43aef-c5b7-4dc5-98b3-2fe6a3b832eb.png)'
  prefs: []
  type: TYPE_IMG
- en: In the graph in the lower-right-hand corner, you can see the effect of adding
    a new ECS container instance, which increases the container capacity from `0`
    to `2`, placing the container capacity alarm into an OK state.
  prefs: []
  type: TYPE_NORMAL
- en: Testing scale in
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that you have successfully tested the scale-out behavior of your ECS cluster-capacity
    management solution, let''s now artificially trigger scale-in behavior by reducing
    the `ApplicationDesiredCount` to 1 in the `dev.cfg` file and running the `aws
    cloudformation deploy` command to deploy the modified count:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Once this change has been deployed, in the CloudWatch console you should see
    the idle host capacity alarm change to an ALARM state after a few moments:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/4121b365-3f94-4ed5-ba0e-e95ceb74cc1f.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding screenshot, the idle host capacity has increased from 1.0 to
    1.5, given we now only have one running ECS task and two ECS container instances
    in the cluster. This has triggered the configured application autoscaling scale
    in policy, which will reduce the ECS cluster capacity to a single ECS container
    instance, and eventually the idle host capacity alarm will transition to an OK
    state.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the AWS application Auto Scaling service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We now have an ECS cluster-capacity management solution in place that will automatically
    scale out and scale in your ECS cluster, as new ECS tasks come and go in your
    ECS cluster. To date, we artificially tested this by manually increasing the task
    count of the todobackend ECS service, however in your real world applications,
    you typically would use the AWS application auto scaling service to dynamically
    scale your ECS services up and down based upon whatever metrics make the most
    sense for your application.
  prefs: []
  type: TYPE_NORMAL
- en: Another scenario that impacts ECS cluster capacity is the deployment of new
    applications, in the form of ECS task definition changes to your ECS services.
    The rolling-update mechanism of ECS will often temporarily increase the ECS task
    count, which can result in your ECS cluster scaling out for a short period of
    time, and then scaling back in. You can tune this behavior by adjusting the period
    of time the container capacity can fall below your configured minimum threshold
    before raising an alarm, and also increasing the minimum container capacity threshold
    that must be available at all times. This approach builds more spare capacity
    in your cluster, which allows you to respond less aggressively to capacity changes
    and absorb the transient capacity fluctuations caused by rolling deployments.
  prefs: []
  type: TYPE_NORMAL
- en: 'AWS application auto scaling is more complex to configure than EC2 auto scaling,
    and requires, at a minimum, several components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**CloudWatch alarms**: This define the metrics that you are interested in and
    trigger when you should scale out or scale in.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Auto Scaling target**: This defines the target component that the application
    auto scaling will be applied to. For our scenario, this will be configured as
    the todobackend ECS service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Auto Scaling IAM role**: You must create an IAM role that grants the AWS
    application auto scaling service permissions to manage your CloudWatch alarms,
    read your application auto scaling policies, and modify your ECS services to increase
    or decrease the ECS service task count.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scale out and scale in policies**: These define the behavior associated with
    scaling your ECS services out and back in.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring CloudWatch alarms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s get started by adding a CloudWatch alarm that will trigger application
    auto scaling in the todobackend `stack.yml` template:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, alarms are created for low CPU and high CPU conditions,
    and are dimensioned to the todobackend ECS service running on the todobackend
    ECS cluster. A high CPU alarm will fire when the average CPU utilization for the
    ECS service is greater than 40% for a period of 3 minutes (3 x 60 seconds), and
    a low CPU alarm will fire when the average CPU utilization falls below 20%, again
    for a period of 3 minutes. In each case, an alarm action is configured, which
    references scale-out and scale-in policy resources that we will create shortly.
  prefs: []
  type: TYPE_NORMAL
- en: Defining an Auto Scaling target
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The AWS application auto scaling requires you to define an auto scaling target,
    which is the resource that you need to scale up or scale down. For an ECS use
    case, this is defined as an ECS service, as demonstrated in the preceding example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, you define the following properties for the auto
    scaling target:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ServiceNamespace`: Defines the namespace of the target AWS service. Set this
    to `ecs` when targeting an ECS service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ResourceId`: The identifier of the resource associated with the target. For
    ECS, this is defined in the `service/<ecs-cluster-name>/<ecs-service-name>` format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ScalableDimension`: Specifies the property of the target resource type that
    can be scaled. In the case of an ECS service, this is the `DesiredCount` property,
    which is defined as `ecs:service:DesiredCount`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MinCapacity` and `MaxCapacity`: The minimum and maximum bounds to which the
    desired ECS service count can be scaled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RoleARN`: The ARN of the IAM role that the application auto scaling service
    will use to scale out and scale in the target. In the preceding example, you references
    an IAM resource that you will create in the next section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more details on each of the preceding properties, you can refer to the [Application
    Auto Scaling API reference](https://docs.aws.amazon.com/autoscaling/application/APIReference/API_RegisterScalableTarget.html).
  prefs: []
  type: TYPE_NORMAL
- en: Creating an Auto Scaling IAM role
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the resource definition for the application auto scaling target, you referenced
    an IAM role that the application auto scaling service will assume. The following
    example defines this IAM role and the permissions required by the application
    auto scaling service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: You can see that the application auto scaling service requires a number of read
    permissions associated with the application auto scaling service itself, an ability
    to manage CloudWatch alarms, and must be able to update the ECS services in order
    to manage the ECS service's desired count. Notice that you must specify the principal
    as `application-autoscaling.amazonaws.com` in the `AssumeRolePolicyDocument` section,
    which allows the application auto scaling service to assume the role.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring scale-out and scale-in policies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The final task required when configuring application auto scaling is to add
    scale-out and scale-in policies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Here you define scale-out and scale-in policies, ensuring the resource names
    match those you referenced earlier, when you configured the CloudWatch alarms
    used to trigger the policies. The `PolicyType` parameter specifies you are configuring
    Step-Scaling policies, which work in a similar manner to the EC2 auto scaling
    policies you defined earlier and allow you to scale up or down in incremental
    steps. The remaining properties are fairly self-explanatory, although the `StepAdjustments`
    property does warrant some further description.
  prefs: []
  type: TYPE_NORMAL
- en: The `ScalingAdjustment` indicates how much you will increase or decrease the
    ECS service count by each time you scale, while the `MetricIntervalLowerBound`
    and `MetricIntervalUpperBound` properties allow you to define additional bounds
    when your alarm thresholds are exceeded to which your auto scaling actions should
    apply.
  prefs: []
  type: TYPE_NORMAL
- en: The configuration shown in the preceding example is such that whenever the CPU
    utilization exceeds or falls below the configured CloudWatch alarm thresholds,
    the application auto scaling will always be invoked. This is because the unconfigured
    upper and lower bounds default to a value of infinity or negative infinity, respectively,
    so any metric value between the alarm threshold and infinity/negative infinity
    will trigger the alarm. To help further clarify the context of the metric interval
    bounds, if you instead configured a `MetricIntervalLowerBound` value of 10 and
    `MetricIntervalUpperBound` of 30, when the CloudWatch alarm threshold (currently
    configured as 40% CPU utilization) is exceeded, the auto scaling action would
    only apply between 50% utilization (threshold + `MetricIntervalLowerBound` or
    40 + 10 = 50) and 70% utilization (`threshold` + `MetricIntervalUpperBound` or
    40 + 30 = 70%).
  prefs: []
  type: TYPE_NORMAL
- en: Deploying application Auto Scaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At this point, you are now ready to deploy your ECS application auto scaling
    solution. After running the `aws cloudformation deploy` command, if you browse
    to the ECS console, select the todobackend cluster and todobackend ECS service,
    on the Auto Scaling tab, you should see your new application auto scaling configuration
    in place:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/b959b6fd-e570-4d8f-99d1-2d243f9b4f1d.png)'
  prefs: []
  type: TYPE_IMG
- en: Now whenever your ECS service is experiencing greater than 40% CPU utilization
    (averaged across all ECS tasks), the desired count of your ECS service will be
    increased by one. This will continue for as long as the CPU utilization exceeds
    40%, up to a maximum of 4 tasks, and as per the configuration of the preceding
    example, a cool-down period of 360 seconds will apply between each auto scaling
    action.
  prefs: []
  type: TYPE_NORMAL
- en: At an ECS service level, you don't need to worry about the underlying ECS cluster
    resources, as your ECS cluster capacity management solution ensures there is always
    spare capacity for additional ECS tasks in the cluster. This means you now have
    the freedom to scale each ECS service independently according to its specific
    performance characteristics, and underscores the importance of understanding the
    optimal-per-ECS-task resource allocations for each of your applications.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you created a comprehensive auto scaling solution that allows
    you to auto scale your ECS services and applications in response to application
    load and customer demand, and at the same time ensures your underlying ECS cluster
    has sufficient resources to deploy new ECS tasks as required.
  prefs: []
  type: TYPE_NORMAL
- en: You first learned about key ECS resources including CPU, memory, network ports
    and network interfaces, and how ECS allocates these resources. When managing the
    ECS cluster capacity, these resources determine whether or not an ECS container
    instance can run a given ECS task, so it is critical that you understand how each
    resource is consumed.
  prefs: []
  type: TYPE_NORMAL
- en: You next implemented an ECS cluster-capacity management solution that calculates
    the ECS cluster capacity whenever an ECS container instance state change occurs.
    ECS publishes theses state changes via CloudWatch events, and you created a CloudWatch
    event rule that triggers a Lambda function that calculates the current cluster
    capacity. This function calculates two key metrics–container capacity, expressed
    as the number of additional containers or ECS tasks that the cluster can currently
    support, and idle host capacity, which defines how many "virtual" hosts are currently
    idle across the entire cluster. The container capacity is used to scale out your
    ECS clusters, adding additional ECS container instances whenever the container
    capacity falls below 1, meaning the cluster no longer has enough resources to
    deploy an additional ECS task. The idle host capacity is used to scale in your
    ECS clusters, removing ECS container instances whenever idle host capacity is
    greater than 1.0, meaning you can safely remove an ECS container instance and
    still have capacity to deploy new ECS tasks.
  prefs: []
  type: TYPE_NORMAL
- en: A key concept we discussed was the requirement to always make these calculations
    for the worst-case scenario collectively across all of your resources, which ensures
    you will never scale in when you have plenty of spare capacity of one type of
    resource, but may have low capacity for another type of resource.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you learned how to configure the AWS application auto scaling service
    to scale up and down your ECS services. Here you are scaling individual ECS services
    based on appropriate metrics specific to your applications, and because you are
    scaling in the context of a single ECS service, auto scaling at this level is
    simple to define and understand. Scaling your ECS services is ultimately what
    drives changes to your overall ECS cluster capacity, with the ECS cluster-capacity
    management solution you implemented taking care of this and allowing you to auto
    scale your ECS services without needing to worry about the impact to your underlying
    ECS cluster.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn how to continuously deliver your ECS applications
    to AWS, incorporating all of the features we have discussed in the previous chapters.
    This will allow you to deploy your latest application changes in a fully automated
    fashion, reducing operational overheads and providing fast feedback to your development
    teams.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'True/false: When you use ECS and deploy your own ECS container instances, ECS
    automatically scales your clusters up and down for you.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which AWS service do you use to scale your ECS clusters?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which AWS service do you use to scale your ECS services?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Your application requires a minimum of 300 MB and maximum of 1 GB of memory
    to run. What parameters would you configure on your ECS task definition to support
    this configuration?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You deploy 3 different ECS tasks that each run a different application to a
    single instance ECS cluster, and configure each ECS task to reserve 10 CPU units.
    During busy periods, one of the ECS tasks hogs CPU, slowing down the other ECS
    tasks. Assuming the ECS container instance has 1,000 CPU units' capacity, what
    could you do to avoid one ECS task hogging CPU?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True/false: If you only use dynamic port mapping for your ECS tasks, you do
    not need to worry about network port resources.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You deploy an instance to AWS that supports four network interfaces in total.
    What is the capacity in terms of number of ECS tasks for the instance, assuming
    all ECS tasks use ECS task networking?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When should you disable auto scaling in an EC2 auto scaling group?How would
    you go about this?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Your ECS cluster currently has 2 ECS container instances each with 500 CPU units
    and 500 MB of memory of spare capacity. You are only deploying a single type of
    application to your cluster, and you currently have two ECS tasks running. Assuming
    the ECS task requires 500 CPU units, 500 MB of memory, and has a static port mapping
    to TCP port 80, what is the current overall spare capacity of the cluster in terms
    of number of ECS tasks?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Your ECS cluster needs to support 3 different ECS tasks that require 300, 400,
    and 500MB of memory, respectively. If each of your ECS container instances has
    2 GB of memory, what would you calculate as the maximum number of containers per
    ECS container instance in terms of memory when performing ECS cluster-capacity
    calculations?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can check the following links for more information about the topics we
    covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: ECS Service Auto Scaling: [https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-auto-scaling.html](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-auto-scaling.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: EC2 Auto Scaling User Guide: [https://docs.aws.amazon.com/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-scaling.html](https://docs.aws.amazon.com/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-scaling.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: EC2 Auto Scaling Policy Types: [https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html](https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommended Best Practices for Auto Scaling Group Rolling Updates: [https://aws.amazon.com/premiumsupport/knowledge-center/auto-scaling-group-rolling-updates/](https://aws.amazon.com/premiumsupport/knowledge-center/auto-scaling-group-rolling-updates/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application Auto Scaling User Guide: [https://docs.aws.amazon.com/autoscaling/application/userguide/what-is-application-auto-scaling.html](https://docs.aws.amazon.com/autoscaling/application/userguide/what-is-application-auto-scaling.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Task Definion Parameters Reference (See `cpu`, `memory`, and `memoryReservation`
    parameters):[ https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#container_definitions](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#container_definitions)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CloudFormation CloudWatch Events Rule Resource Reference: [https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-events-rule.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-events-rule.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CloudFormation CloudWatch AlarmResource Reference: [https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cw-alarm.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cw-alarm.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CloudFormation EC2 Auto Scaling Policy Resource Reference: [https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-as-policy.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-as-policy.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CloudFormation Application Auto Scaling Scalable Target Resource Reference: [https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-applicationautoscaling-scalabletarget.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-applicationautoscaling-scalabletarget.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CloudFormation Application Auto Scaling Policy Resource Reference: [https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-applicationautoscaling-scalingpolicy.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-applicationautoscaling-scalingpolicy.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
