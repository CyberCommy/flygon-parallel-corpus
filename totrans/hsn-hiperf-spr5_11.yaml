- en: Inside JVM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous chapter gave us knowledge on how to tune an application's performance
    by understanding the symptoms of the performance issues. We walked through the
    performance tuning life cycle, learning at what stages of the application performance
    can be tuned and how. We also learned how to connect JMX to the Spring application,
    observed the application's bottleneck, and tuned it.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will walk through the insides of **Java Virtual Machine** (**JVM**)
    and tuning JVM to achieve high performance. JVM performs two primary jobs—executing
    code and managing memory. JVM allocates memory from OS, manages to do heap compaction,
    and performs **garbage collection** (**GC**) of unreferenced objects. GC is important
    because proper GC improves the memory management of the application and the performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the topics we will go through in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding JVM internals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding memory leak
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common pitfalls
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GC
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GC methods and policies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tools to analyze GC logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding JVM internals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Being a Java developer, we know that Java bytecode runs in a **Java Runtime
    Environment** (**JRE**) and the most important part of the JRE is JVM, which analyzes
    and executes the Java bytecode. When we create a Java program and compile it,
    the result is a file with the `.class` extension. It contains Java bytecode. JVM
    converts Java bytecode into machine instructions that are executed on the hardware
    platform where we run our application. When a JVM runs a program, it needs memory
    to store bytecodes and other information it extracts from loaded class files,
    instantiated objects, method parameters, return values, local variables, and intermediate
    results of computations. The JVM organizes the memory it needs into several runtime
    data areas.
  prefs: []
  type: TYPE_NORMAL
- en: 'JVM consist of three parts:'
  prefs: []
  type: TYPE_NORMAL
- en: Class loader subsystem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory areas
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Execution engine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the high-level JVM architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cfada67e-a629-4d24-a687-572f75805824.jpg)'
  prefs: []
  type: TYPE_IMG
- en: JVM architecture
  prefs: []
  type: TYPE_NORMAL
- en: Let's briefly understand the three different parts of JVM we saw in the diagram.
  prefs: []
  type: TYPE_NORMAL
- en: Class loader subsystem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The class loader subsystem''s responsibilities are not limited to just locating
    and importing the binary data for classes. It also verifies that the imported
    classes are correct, allocates and initializes memory for class variables, and
    assists in resolving symbolic references. These activities are performed in a
    strict order:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Loading**: The class loader reads the `.class` file and finds and imports
    binary data for a type.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Linking**: It performs verification, preparation, and (optionally) resolution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Verification**: Ensures the correctness of the imported type'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Preparation**: Allocates memory to class variables and initializes the memory
    to default values'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resolution**: Transforms symbolic references from the type into direct references'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Initialization**: Assigns values to all static variables defined in the code
    and executes static block (if any). Execution occurs from top to bottom in a class,
    and from parent to child in a class hierarchy.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In general, there are three class loaders:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bootstrap class loader**: This loads core-trusted Java API classes located
    in the `JAVA_HOME/jre/lib` directory. These Java APIs are implemented in native
    languages, such as C or C++.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Extension class loader**: This inherits the Bootstrap class loader. It loads
    the classes from extension directories located at `JAVA_HOME/jre/lib/ext`, or
    any other directory specified by the `java.ext.dirs` system property. It is implemented
    in Java by the `sun.misc.Launcher$ExtClassLoader` class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**System class loader**: This inherits the extension class loader. It loads
    classes from our application classpath. It uses the `java.class.path` environment
    variable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To load classes, JVM follows the delegation hierarchy principle. The system
    class loader delegates a request to the extension class loader, and the extension
    class loader delegates the request to the Bootstrap class loader. If a class is
    found in the Bootstrap path, the class is loaded, otherwise, the request will
    be transferred to the extension class loader and then to the system class loader.
    At the end, if the system class loader fails to load the class, then a `java.lang.ClassNotFoundException`
    exception is generated.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the delegation hierarchy principle:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a69d9611-b82a-41b5-a33b-4395f6b52766.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Delegation hierarchy principle
  prefs: []
  type: TYPE_NORMAL
- en: Memory areas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Java runtime memory is divided into five different areas, as shown in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0e01a252-cd4f-468e-af57-7d81a78d933a.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Memory areas
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look into a brief description of each component:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Method Area**: This contains all the class-level information, such as class
    name, parent class, methods, instance, and static variables. There is only one
    method area per JVM, and it is a shared resource.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heap Area**: This contains the information of all the objects. There is one
    **Heap Area** per JVM. It is also a shared resource. As **Method Area** and **Heap
    Area** are shared memory between multiple threads, the data stored is not thread-safe.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stack Memory**: JVM creates one runtime stack for every thread in execution
    and stores it in the stack area. Every block of this stack is called an **activation
    record** that stores methods call. All local variables of that method are stored
    in their corresponding frame. The stack area is thread-safe since it is not a
    shared resource. The runtime stack will be destroyed by the JVM up on termination
    of the thread. So, in the case of infinite loops of method calls, we might see
    `StackOverFlowError`, which is due to no memory in the stack for storing method
    calls.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**PC Registers**: These hold the addresses of current instructions under execution.
    Once the instruction is executed, the **PC Registers** will be updated with the
    next instruction. Each thread has a separate **PC Registers**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Native Method Stacks**: For every thread, a separate native stack is created.
    It stores the native method information. Native information is nothing but native
    method calls.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Execution engine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The execution engine executes bytecode in runtime data areas. It executes bytecode
    by each line and uses the information available in runtime data areas. The execution
    engine can be classified into three parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Interpreter**: This reads, interprets, and executes bytecode by each line.
    It interprets and executes bytecode quickly; however, it can be very slow in executing
    interpreted results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Just-In-Time (JIT)**: In order to overcome the interpreter''s slowness in
    executing interpreted results, the JIT compiler converts the bytecode to native
    code once the interpreter interprets the code the first time. Execution happens
    fast with native code; it executes instructions one by one.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Garbage collector**: This destroys anything that is not referenced. This
    is very important, so anything not required will be destroyed to create room for
    new execution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding memory leak
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Java's best benefit is the JVM, which offers memory management out of the box.
    We can create objects and Java's garbage collector takes care of freeing up memory
    for us. Still, memory leaks occur in Java applications. In the following section,
    we will see some common causes of memory leaks and walk through a few solutions
    to detect/avoid them.
  prefs: []
  type: TYPE_NORMAL
- en: Memory leak in Java
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A memory leak occurs when the garbage collector could not collect the objects
    any longer being used/referenced by an application. If the objects are not garbage
    collected, the application uses more memory and, once the entire heap is full,
    the object cannot be allocated, which leads to `OutOfMemoryError`.
  prefs: []
  type: TYPE_NORMAL
- en: Heap memory has two types of objects—referenced objects and unreferenced objects.
    The garbage collector will remove all unreferenced objects. However, the garbage
    collector would not be able to remove referenced objects even though they aren't
    used by the application.
  prefs: []
  type: TYPE_NORMAL
- en: Common reasons for memory leaks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the most common reasons for memory leaks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Open streams**: While working on streams and readers, we often forget to
    close the streams, which eventually results in the memory leak. There are two
    types of leaks that result from unclosed streams—low-level resource leak and memory
    leak. Low-level resource leak includes OS-level resources, such as file descriptor
    and open connection. As JVM consumes memory to track these resources, it leads
    to memory leak. To avoid leaks, use the `finally` block to close the stream or
    use the autoclose feature of Java 8.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Open connections**: We often forget to close opened HTTP, database, or FTP
    connections, which results in the memory leak. Similar to closing streams, close
    the connections.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Static variables referencing instance objects**: Any static variable referencing
    a heavy object could lead to memory leak because even if the variable is not in
    use, it won''t be garbage collected. To prevent this, try not to have heavy static
    variables; use local variables instead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Missing methods for objects in collection**: Adding objects having no implementation
    of the `equals` and `hashcode` methods to `HashSet` will add the number of duplicate
    objects in `HashSet` and we would not be able to remove these objects once added.
    To prevent this, implement the `equals` and `hashcode` methods in the object added
    to `HashSet`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Diagnosing memory leaks is a lengthy process that requires a lot of practical
    experience, debugging skills, and detailed knowledge of the application. The following
    are the ways to diagnose memory leaks:'
  prefs: []
  type: TYPE_NORMAL
- en: Enable GC logs and fine-tune GC parameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Profiling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code review
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following sections, we will see GC's common pitfalls, GC methods, and
    tools to analyze GC logs.
  prefs: []
  type: TYPE_NORMAL
- en: Common pitfalls
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Performance tuning is critical, and things can start getting hairy with one
    small JVM flag. JVM is subject to GC pauses, which vary in frequency and duration.
    During a pause, everything stops and all kinds of unexpected behaviors start. During
    pauses and unstable behavior where JVM gets stuck, performance is impacted. We
    can see the symptoms of slow response times, high CPU, and memory utilization,
    or the system acts normally most of the time but behaves weirdly, such as performing
    extremely slow transactions and disconnections.
  prefs: []
  type: TYPE_NORMAL
- en: The majority of the time, we measure the average transaction time and ignore
    the outliers that cause unstable behavior. Most of the time a system behaves normally,
    however at certain points, system responsiveness degrades. The majority of the
    time, the reason for this low performance is due to low awareness of GC overhead
    and focusing on only average response times.
  prefs: []
  type: TYPE_NORMAL
- en: 'When defining performance requirements, an important question we need to answer
    is: What are the acceptable criteria for our application related to GC pause frequency
    and duration? Requirements vary from application to application, so based on our
    application and user experience, we need to first define these criteria.'
  prefs: []
  type: TYPE_NORMAL
- en: A few common misunderstandings we usually have are as follows.
  prefs: []
  type: TYPE_NORMAL
- en: Number of garbage collectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most of the time, people are not aware that there isn't only one, but four,
    garbage collectors. The four garbage collectors are—**Serial**, **Parallel**,
    **Concurrent**, and **Garbage First** (**G1**). We will see them in the following
    section. There are some third-party garbage collectors, such as **Shenandoah**.
    JVM HotSpot's default garbage collector is Parallel up to Java 8, while from Java
    9, the default collector is **Garbage First Garbage Collector** (**G1 GC**). A
    Parallel garbage collector isn't best most of the time; however, it depends on
    our application requirements. For example, the **Concurrent Mark Sweep** (**CMS**)
    and G1 collectors cause less frequent GC pauses. But when they do cause a pause,
    the pause duration will most likely be longer than a pause caused by the Parallel
    collector. On the other hand, the Parallel collector usually achieves higher throughput
    for the same heap size.
  prefs: []
  type: TYPE_NORMAL
- en: Wrong garbage collector
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A common reason for the GC issue is the wrong choice of garbage collector for
    the type of application. Each collector has their own significance and benefits.
    We need to find our application's behavior and priorities and based on which we
    need to choose right garbage collector. The default garbage collector of HotSpot's is
    Parallel/Throughput and, most of time, it hasn't proven to be a good choice. The
    CMS and G1 collector are concurrent and cause less frequent pauses, but when a
    pause does come, its duration is longer than the Parallel collector. So the choice
    of the collector is a common mistake we often make.
  prefs: []
  type: TYPE_NORMAL
- en: Parallel / Concurrent keywords
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A GC can either cause a **s****top-the-world** (**STW**) situation, or objects
    can be collected concurrently without stopping the application. The GC algorithm
    can be executed in a single thread or in multithread. So, Concurrent GC does not
    mean it executes in parallel, whereas Serial GC doesn't mean it causes more pauses
    due to serial execution. Concurrent and Parallel are different, where Concurrent
    means the GC cycle, and Parallel means the GC algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: G1 is a problem solver
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the introduction of the new garbage collector in Java 7, many people think
    that it is the problem solver to all previous garbage collectors. An important
    problem solved by G1 GC is the fragmentation problem, which is common to the CMS
    collector. However, in many cases other collectors can outperform G1 GC. So it
    all depends on our application's behavior and requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Average transaction time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Mostly, while testing performance, we tend to measure average transaction time
    and, by only doing that, we miss the outliers. At some point, when GC causes pauses
    for a long duration, the application's response time increases drastically, which
    affects users accessing the application. This can go unnoticed, as we are only
    looking at the average transaction time. When the GC pause frequency increases,
    response time becomes a serious problem that we might have ignored by just measuring
    the average response time.
  prefs: []
  type: TYPE_NORMAL
- en: Reducing new object allocation rates improves GC behavior
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Instead of focusing or reducing the new object allocation rate, we should focus
    on the life of objects. There are three different types of objects lives: long-lived
    objects, we cannot do much about them; mid-lived objects, these cause the biggest
    issues; and short-lived objects, which usually get freed and allocated quickly
    so they are collected by the next GC cycle. So instead of concentrating on long-lived
    and short-lived objects, focusing on the mid-lived objects allocation rate could
    bring positive results. It''s not the object allocation rate alone; it''s the
    type of objects in play that causes all the trouble.'
  prefs: []
  type: TYPE_NORMAL
- en: GC logs cause overhead
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is not true that GC logs cause overhead, especially in the default log settings.
    The data is extremely valuable and Java 7 introduced hooks to control the size
    of their log files. If we don''t collect GC logs with timestamps, then we are
    missing out on a critical source of data to analyze and solve pausing issues.
    GC logs are the richest source of data for the state of GC in a system. We can
    get data about all GC events in our application; say, it is completed concurrently
    or caused an STW pause: how long did it take, how much CPU it consumed, and how
    much memory was freed. From this data, we would be able to understand the frequency
    and duration of pauses, their overhead, and move on to take action to reduce them.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Enable GC by adding following arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: GC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of Java's best achievements is GC. The GC process automatically manages
    memory and heap allocation that tracks down dead objects, removes them, and reallocates
    memory to a new object. Theoretically, as garbage collector automatically manages
    memory, it makes developers create new objects without thinking about the allocation
    and deallocation of memory to eliminate memory leaks and other problems related
    to memory.
  prefs: []
  type: TYPE_NORMAL
- en: How GC works
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We usually think that GC collects and removes the unreferenced objects. Instead,
    GC in Java tracks live objects and marks all unreferenced objects as garbage.
  prefs: []
  type: TYPE_NORMAL
- en: 'The heap area of the memory is where objects are allocated dynamically. We
    should allocate heap memory to JVM before running the application. Allocating
    heap to JVM in advance has a couple of consequences:'
  prefs: []
  type: TYPE_NORMAL
- en: Improves object creation rate because JVM doesn't need to communicate with the
    OS to get memory for each new object. Once the JVM allocates memory to an object,
    JVM moves the pointer toward the next available memory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Garbage collectors collect the object when there is no object reference and
    reuse its memory for new object allocation. As the garbage collector doesn't delete
    the object, no memory is returned to the OS.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Until the objects are being referenced, JVM considers them live objects. When
    an object is no longer referenced and is not reachable by the application code,
    the garbage collector removes it and reclaims its memory. We get a question in
    our mind, who is the first reference in the tree of objects, right? Let's see
    the object tree and its roots.
  prefs: []
  type: TYPE_NORMAL
- en: GC roots
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Each tree of an object has one or more objects at the root. If the garbage collector
    can reach the root, the tree is reachable. Any object that is not reached by,
    or referenced by, GC roots is considered dead and the garbage collector removes
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the different kinds of GC roots in Java:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Local variables: **Variables or parameters of a Java method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Active threads:** A running thread is a live object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Static variables:** Classes referencing static variables. When the garbage
    collector collects classes, it removes references to static variables.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**JNI references:** Object reference created during the JNI call. They are
    kept alive because JVM is unaware that the native code has references of it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Please have a look at the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/659a24ab-1fe8-43dd-a409-8b29f771150d.jpg)'
  prefs: []
  type: TYPE_IMG
- en: GC roots
  prefs: []
  type: TYPE_NORMAL
- en: GC methods and policies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we learned in the preceding section, there isn't one but four different garbage
    collectors. Each one has its own advantages and disadvantages. The one thing these
    collectors have in common is that they split the managed heap into different segments
    with the assumption that objects are short-lived and should be removed shortly.
    Let's see four different algorithms of GC.
  prefs: []
  type: TYPE_NORMAL
- en: Serial collector
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Serial collector is the simplest GC implementation, mainly designed for
    single-threaded environments and small heaps. This GC implementation freezes all
    application threads whenever it's working. Hence, it's not a good idea to use
    it in multithreaded applications, such as server environments.
  prefs: []
  type: TYPE_NORMAL
- en: To enable the Serial garbage collector, set `-XX:+UseSerialGC` to VM arguments
  prefs: []
  type: TYPE_NORMAL
- en: Parallel/Throughput collector
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Parallel collector is the JVM's default collector and is also known as the
    Throughput collector. As the name suggests, this collector, unlike the Serial
    collector, uses multithread to manage the heap memory. The Parallel garbage collector
    still freezes all the application threads when performing either minor or full
    GC. If we want to use the Parallel garbage collector, we should specify the tuning
    parameters, such as threads, pause time, throughput, and footprints.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the arguments to specify the tuning parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: Threads: `-XX:ParallelGCThreads=<N>`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pause time: `-XX:MaxGCPauseMillis=<N>`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Throughput: `-XX:GCTimeRatio=<N>`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Footprint (maximum heap size): `-Xmx<N>`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To enable the Parallel garbage collector in our application, set the `-XX:+UseParallelGC`
    option.
  prefs: []
  type: TYPE_NORMAL
- en: CMS garbage collector
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The CMS implementation uses multiple garbage collector threads to scan (mark)
    the unused objects that can be removed (sweep). This garbage collector is preferable
    for applications that require short GC pauses, and who can share processor resources
    with the garbage collector while the application is running.
  prefs: []
  type: TYPE_NORMAL
- en: 'The CMS algorithm enters into STW mode in only two cases: when objects in Old
    Generations are still referenced from the thread entry point or static variables,
    and when the application changed the state of the heap while CMS is running which
    makes the algorithm go back and reiterate the object tree to validate that it
    had marked the correct objects.'
  prefs: []
  type: TYPE_NORMAL
- en: With this collector, promotion failure is the greatest cause for concern. Promotion
    failure occurs when a race condition occurs between a collection of objects from
    the Young and Old Generations. If the collector needs to promote objects from
    the Young Generation to the Old Generation and there is not enough space, it has
    to first STW to create the space. In order to make sure this doesn't happen in
    the case of the CMS collector, increase the size of the Old Generation or allocate
    more background thread to the collector to compete with the allocation rate.
  prefs: []
  type: TYPE_NORMAL
- en: In order to provide high throughput, CMS uses more CPU to scan and collect objects.
    It is good for long-running server applications, which are adverse to application
    freezes. So, if we can allocate more CPU to avoid application pauses, we can choose
    the CMS collector for GC in our application. To enable the CMS collector, set
    the -`XX:+UseConcMarkSweepGC` option.
  prefs: []
  type: TYPE_NORMAL
- en: G1 collector
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is the new collector, introduced in JDK 7 update 4\. The G1 collector is
    designed for an application willing to allocate heap memory of more than 4 GB.
    G1 divides the heap into multiple regions, spanning from 1 MB to 32 MB, depending
    on the heap we configure and uses multiple background threads to scan through
    the heap regions. The benefit of dividing the heap into multiple regions is that
    G1 will scan through regions where there is plenty of garbage first in order to
    meet a given pause time.
  prefs: []
  type: TYPE_NORMAL
- en: G1 reduces the change of low-heap availability before the background threads
    have finished scanning for unused objects. This reduced the chances to STW. G1
    compacts the heap on-the-go, unlike CMS, which does this during STW.
  prefs: []
  type: TYPE_NORMAL
- en: In order to enable the G1 garbage collector in our application, we need to set
    the `-XX:+UseG1GC` option in the JVM parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Java 8 update 20 introduced a new JVM argument, `-XX:+UseStringDeduplication`,
    for the G1 collector. With this argument, G1 identifies duplicate strings and
    creates the pointer to the same integral `char[]` array to avoid multiple copies
    of the same string.
  prefs: []
  type: TYPE_NORMAL
- en: From Java 8 `PermGen`, part of the heap is removed. This was the part that was
    allocated for class metadata, static variables, and interned strings. This parameter-tuning
    caused many `OutOfMemory` exceptions, which would be fine from Java 8 onward,
    where JVM would take care of it.
  prefs: []
  type: TYPE_NORMAL
- en: Heap memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Heap memory is divided into primarily two generations: Young Generation and
    Old Generation. There is a **PERM GENERATION** that is a part of heap memory until
    Java 7, while from Java 8, the **PERM GENERATION** is replaced by **METASPACE**.
    **METASPACE** is not part of the heap memory but is part of the **Native Memory**.
    Set size of **METASPACE** using the `-XX:MaxMetaspaceSize` option. It is critical
    to consider this setting when going to production since if **METASPACE** takes
    up excessive memory, it affects the application''s performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3c93fe61-8690-43ce-9362-ff57c083d627.png)'
  prefs: []
  type: TYPE_IMG
- en: Java 8 memory management
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Young Generation** is where objects are created and allocated; it''s
    for young objects. The **Young Generation** is further divided into **Survivor
    Space**. The following is the **Hotspot Heap Structure**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f239e0c8-d541-4a54-9646-068d5a38f0ec.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The **eden** area is, by default, bigger than **Survivor Space**. All the objects
    are created first in the **eden** area. When **eden** is full, minor GC is triggered,
    which will quickly scan the object''s references, and unreferenced objects are
    marked dead and collected. The **Survivor Space** area in either of them would
    always be empty. Objects that survived in **eden** during minor GC will be moved
    to the empty **Survivor Space**. We might wonder why there are two **Survivor
    Space **areas and not one. The reason is to avoid memory fragmentation. When the
    **Young Generation** runs through and removes dead objects from the **Survivor
    Space**, it leaves holes in the memory and needs compaction. To avoid compaction,
    JVM moves surviving objects from one **Survivor Space** to another. This ping-pong
    of live objects from **eden** and one **Survivor Space** to another happens until
    the following conditions occur:'
  prefs: []
  type: TYPE_NORMAL
- en: Objects reach maximum tenuring threshold. This means objects are no longer young.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Survivor Space** is full and cannot accommodate any new objects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the preceding conditions happen, objects are moved to the **Old Generation**.
  prefs: []
  type: TYPE_NORMAL
- en: JVM flags
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following are the JVM parameters/flags commonly used in applications to
    tune the JVM for better performance. Tuning values depend on our application's
    behavior and the rate at which it is generated. So there is no defined guideline
    to use specific values for JVM flags in order to achieve better performance.
  prefs: []
  type: TYPE_NORMAL
- en: -Xms and -Xmx
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `-Xms` and `-Xmx` are known as the minimum and maximum heap size. Setting `-Xms` equal
    to `-Xmx` prevents GC pauses during heap expansion and improves performance.
  prefs: []
  type: TYPE_NORMAL
- en: -XX:NewSize and -XX:MaxNewSize
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can set the size of the Young Generation using `-XX:MaxNewSize`. The Young
    Generation resides under the total heap memory and the Old Generation size will
    be smaller if we set the size of the Young Generation as large. The Young Generation
    size should never be larger than the Old Generation for stability reasons. Thus, `-Xmx/2`
    is the maximum size we can set for `-XX:MaxNewSize`.
  prefs: []
  type: TYPE_NORMAL
- en: To achieve better performance, set the initial size of the Young Generation
    by setting the `-XX:NewSize` flag. This saves some costs in terms of the Young
    Generation growing to that size over time.
  prefs: []
  type: TYPE_NORMAL
- en: -XX:NewRatio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can set the size of the Young Generation as a ratio of the Old Generation
    using the `-XX:NewRatio` option. The benefit we can get with this option could
    be that the Young Generation can grow and shrink when JVM adjusts the total heap
    size during execution. `-XX:NewRatio` means the ratio of Old Generation is larger
    than the Young Generation. `-XX:NewRatio=2` means the size of the Old Generation
    is twice that of the Young Generation, which further means that the Young Generation
    is 1/3 of the total heap.
  prefs: []
  type: TYPE_NORMAL
- en: If we specify ratio and a fixed size for the Young Generation, then the fixed
    size will take precedence. There is no generation rule regarding which method
    of specifying the size of the Young Generation is preferable. The rule of thumb
    here is that if you know the size of the objects generated by our application,
    then specify the fixed size, otherwise, specify the ratio.
  prefs: []
  type: TYPE_NORMAL
- en: -XX:SurvivorRatio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `-XX:SurvivorRatio` value is the ratio of eden relative to Survivor Spaces.
    There will be two Survivor Spaces and each one would be equal to the other. If `-XX:SurvivorRatio=8`,
    then eden occupies 3/4 and each Survivor Spaces occupies 1/4 of the total Old
    Generation size.
  prefs: []
  type: TYPE_NORMAL
- en: If we set a ratio such that Survivor Spaces are small, then eden will make more
    space for new objects. During minor GC, unreferenced objects will be collected
    and eden will be empty for new objects, however, if the object still has references,
    then the garbage collector moves them to the Survivor Space. If the Survivor Space
    is small and cannot accommodate the new object, then the objects will be moved
    to the Old Generation. Objects in the Old Generation can only be collected during
    full GC, which creates long pauses in the application. And if the Survivor Space
    is large enough, then more objects can live in the Survivor Space but die young.
    If the Survivor Spaces are large, eden would be small, and a small eden would
    cause frequent young GC.
  prefs: []
  type: TYPE_NORMAL
- en: -XX:InitialTenuringThreshold, -XX:MaxTenuringThreshold, and -XX:TargetSurvivorRatio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The tenuring threshold decides when an object can be promoted/moved from the
    Young Generation to the Old Generation. We can set the initial and maximum value
    of the tenuring threshold using the `-XX:InitialTenuringThreshold` and `-XX:MaxTenuringThreshold` JVM
    flags. We can also use `-XX:TargetSurvivorRatio` to specify the target utilization
    (as a percentage) of the Survivor Space at the end of a Young Generation GC.
  prefs: []
  type: TYPE_NORMAL
- en: -XX:CMSInitiatingOccupancyFraction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Use the `-XX:CMSInitiatingOccupancyFraction=85` option when using the CMS collector
    (`-XX:+UseConcMarkSweepGC`). If the flag is set and the Old Generation is 85%
    full, the CMS collector starts collecting unreferenced objects. It is not necessary
    that CMS will start collection only after the Old Generation 85% occupied. If
    we want CMS to start only at 85%, then we need to set `-XX:+UseCMSInitiatingOccupancyOnly`.
    The default value of the `-XX:CMSInitiatingOccupancyFraction` flag is 65%.
  prefs: []
  type: TYPE_NORMAL
- en: -XX:+PrintGCDetails, -XX:+PrintGCDateStamps, and -XX:+PrintTenuringDistribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Flags are set to generate GC logs. In order to fine-tune JVM parameters to achieve
    better performance, it is important to understand GC logs and the behavior of
    the application. `-XX:+PrintTenuringDistribution` reports the statistics of an
    object (how old they are) and the desired threshold of objects when they are promoted.
    This is very important to understand how our application is holding the objects.
  prefs: []
  type: TYPE_NORMAL
- en: Tools to analyze GC logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Java GC logs are one of the places where we can start debugging an application
    in the event of a performance issue. The GC logs provide important information,
    such as:'
  prefs: []
  type: TYPE_NORMAL
- en: The last time the GC ran
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of GC cycles run
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The interval at which the GC ran
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The amount of memory freed up after the GC ran
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The time the GC took to run
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The amount of time for which the JVM paused when the garbage collector ran
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The amount of memory allocated to each generation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is the sample GC logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: These logs are very difficult to interpret quickly. If we have a tool that can
    render these logs in a visual interface, it would be easy and quick to understand
    what is going on with the GC. We will take a look at one such tool to interpret
    the GC logs in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: GCeasy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GCeasy is one of the most popular garbage collection log analysis tools. GCeasy
    is developed to identify problems from the GC logs automatically. It is intelligent
    enough to provide alternative ways to solve problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the important basic features provided by GCeasy:'
  prefs: []
  type: TYPE_NORMAL
- en: Uses machine learning algorithms to analyze the logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quickly detects memory leaks, premature object promotions, long JVM pauses,
    and many other performance issues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Powerful and informative visual analyzer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provides the REST API for proactive log analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Free cloud-based tool for log analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provides suggestions on the JVM heap size
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Equipped to analyze all formats of GC logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GCeasy.io ([http://www.gceasy.io/](http://www.gceasy.io/)) is the online garbage
    collection log analysis tool. It requires the log files to be uploaded on the
    GCeasy public cloud.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the steps to gather detailed log analysis using the online
    tool:'
  prefs: []
  type: TYPE_NORMAL
- en: Enable GC logs in the application by adding `XX:+PrintGCDetails -XX:+PrintGCDateStamps
    -Xloggc:<GC-log-file-path>` in the JVM parameters on the server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the GC log file is generated at a specified location, upload the file to
    the GCeasy cloud by navigating to [http://gceasy.io/](http://gceasy.io/). It is
    also possible to upload a compressed ZIP file in case there are multiple log files
    to be analyzed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the log files are processed, the detailed analysis report will be generated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The report is properly organized and detailed enough to highlight every possible
    problem causing the performance hit. The following section explains the important
    sections in the report generated by GCeasy.
  prefs: []
  type: TYPE_NORMAL
- en: Tips on JVM tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The top section in the report provides suggestions based on the garbage-collection-log
    analysis. The suggestions are generated dynamically by machine learning algorithms
    after a thorough analysis of the log files. The details in the suggestion also
    include the probable cause of the issue. The following is an example suggestion
    provided by GCeasy after GC log analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a9d60f2f-d1d0-4b46-9d97-627b209fc693.jpg)'
  prefs: []
  type: TYPE_IMG
- en: JVM Heap Size
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section in the report provides information on the heap allocation and
    peak memory usage for each memory generation. It is possible that the allocated
    heap size may not match the one defined in the JVM parameters. This is because
    the GCeasy tool obtains the allocated memory information from the logs. It is
    possible that we have allocated 2 GB of heap memory, but at runtime, JVM could
    allocate only 1 GB of heap memory. In such a case, the report will show the allocated
    memory as 1 GB. The report shows the heap allocation in tabular and graphical
    formats. The following is an example heap size section from the report:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/760de75d-71b3-44b7-84b9-9583efa5af91.png)'
  prefs: []
  type: TYPE_IMG
- en: Key Performance Indicators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Key Performance Indicators** (**KPIs**) help make profound decisions for
    improving the application''s performance. Throughput, latency, and footprint are
    a few of the important KPIs. The KPIs in the report include Throughput and Latency.
    The footprint basically describes the amount of time CPU was occupied. It can
    be obtained from a performance-monitoring tool, such as JVisualVM.'
  prefs: []
  type: TYPE_NORMAL
- en: The Throughput option indicates the amount of productive work done by the application
    during a specified time period. The Latency option indicates the average time
    taken by the GC to run.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of KPIs from the report:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6d375ac5-b067-44c4-8efe-98a2a8498c14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: GC Statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The GC statistics section provides information on the behavior of the garbage
    collector over a period of time. The period is the time duration for which the
    logs are analyzed. The GC statistics are provided based on real-time analysis.
    The statistics include the bytes reclaimed after the garbage collector ran, the
    cumulative GC time in seconds, and the average GC time in seconds. This section
    also provides information on total GC statistics, minor and full GC statistics,
    and GC pause statistics in a tabular format.
  prefs: []
  type: TYPE_NORMAL
- en: GC Causes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The GC Causes section provides information on what caused the garbage collector
    to run. The information is provided in tabular as well as graphical format. Along
    with the reasons, it also provides information on the time it took for the garbage
    collector to execute. The following is an example from the report:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1f5ee498-4526-4f89-a07b-3d56e0863889.png)'
  prefs: []
  type: TYPE_IMG
- en: Based on the preceding details, GCeasy is an important tool in helping developers
    to interpret GC logs in a visual manner.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about JVM and its parameters. We learned about memory
    leaks and common misunderstandings related to GC. We learned about different GC
    methods and their importance. We learned about import JVM flags, which are tuned
    to achieve better performance.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about Spring Boot microservices and its performance
    tuning. Microservice is an architecture of an application with loosely coupled
    services that implements business capabilities. Spring Boot enables us to build
    production-ready applications.
  prefs: []
  type: TYPE_NORMAL
