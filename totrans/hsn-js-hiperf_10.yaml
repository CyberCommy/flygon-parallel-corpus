- en: Workers - Learning about Dedicated and Shared Workers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the past few chapters, we have focused on Node.js and how we can write backend
    applications utilizing the same language as the frontend. We have seen various
    ways of creating servers, offloading tasks, and streaming. In this part, we will
    focus on the offloading tasks aspect of the browser.
  prefs: []
  type: TYPE_NORMAL
- en: Eventually, as we have seen in Node.js, we need to offload some computationally
    intensive tasks from the main thread to a separate thread, or process, to make
    sure that our application stays responsive. While the effects of having a server
    not respond can be quite jarring, the effects of our user interface not working
    are downright off-putting to most users. Therefore, we have the Worker API.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will specifically look at two kinds of workers, dedicated
    and shared. Overall, we will do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Learn to offload heavy processing to a worker thread via the Worker API.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn how to talk with workers via the `postMessage` and `BroadcastChannel`
    APIs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Talk about `ArrayBuffer` and the `Transferrable` property so we can quickly
    move data between workers and the main thread.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Look at `SharedWorker` and the Atomics API to see how we can share data between
    multiple tabs of our application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Take a look at a partial implementation of a shared cache utilizing the knowledge
    from the previous sections.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following items are needed to complete this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: A text editor or IDE, preferably VS Code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to Chrome or Firefox
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some knowledge of parallelization in computing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code found at [https://github.com/PacktPublishing/Hands-On-High-Performance-Web-Development-with-JavaScript/tree/master/Chapter10](https://github.com/PacktPublishing/Hands-On-High-Performance-Web-Development-with-JavaScript/tree/master/Chapter10).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Offloading work to a dedicated worker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Workers give us the ability to offload long-running, computationally-intensive
    tasks to the background. Instead of having to make sure our event loop is not
    filled with some type of heavy task, we can offload that task to a background
    thread.
  prefs: []
  type: TYPE_NORMAL
- en: 'In other languages/environments, this might look like the following (this is
    only pseudo-code and is not really tied to any language):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: While this works well in those environments, we have to start thinking about
    topics such as deadlock, zombie threads, read after write, and so on. All of these
    can be quite hard to comprehend and are usually some of the most difficult bugs
    that can be encountered. Instead of JavaScript giving us the capability of utilizing
    something like the preceding, they gave us workers, which give us another context
    to work in where we don't face the same issues.
  prefs: []
  type: TYPE_NORMAL
- en: For those that are interested, a book on operating systems or Unix programming
    can help shed light on the preceding issues. These topics are out of the scope
    of this book, but they are quite interesting and there are even languages that
    are trying to address these issues by building the workarounds into the languages.
    Some examples of these are Go ([https://golang.org/](https://golang.org/)), which
    uses a technique of message passing, and Rust ([https://www.rust-lang.org/](https://www.rust-lang.org/)),
    which utilizes the concept of borrow checking and such to minimize these issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start off with an example of work being done in the background, we are going
    to spawn a `Worker` and have it compute a sum over 1 million numbers. To do this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We add the following `script` section to our HTML file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We create a JavaScript file for our `Worker` and add the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: If we launch Chrome, we should see two messages printed – one that says it was
    run on the main thread and another with the value 499999500000. We should also
    see that one was logged by the HTML file and the other was logged by the worker.
    We have just spawned a worker and got it to do some work for us!
  prefs: []
  type: TYPE_NORMAL
- en: Remember that if we want to run JavaScript files from our filesystem and not
    a server, we will need to close out of all instances of Chrome and then relaunch
    it from the command line using `chrome.exe –-allow-file-access-from-files`. This
    will give us access to launch our external JavaScript files from the filesystem
    and not need a server.
  prefs: []
  type: TYPE_NORMAL
- en: Let's go ahead and do something a little more complex that the user may want
    to do. One interesting math problem is getting the prime factorization for a number.
    This means that, when given a number, we will try to find all of the prime numbers
    (numbers that are only divisible by one and itself) that make up that number.
    An example would be the prime factorization of 12, which is 2, 2, and 3.
  prefs: []
  type: TYPE_NORMAL
- en: This problem leads to the interesting field of cryptography and how public/private
    keys work. The basic understanding is that, given two relatively large prime numbers,
    multiplying them is easy, but finding those two numbers from that product of them
    is infeasible due to time constraints.
  prefs: []
  type: TYPE_NORMAL
- en: 'Back to the task at hand, what we will do is spawn a `worker` after the user
    inputs a number into an input box. We will compute that number and log it to the
    console. So let''s begin:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We add an input to our HTML file and change the code to spawn a `worker` on
    the change event for that input box:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will grab our name in the `worker` and use that as the input. From
    there, we will run the prime factorization algorithm found at [https://www.geeksforgeeks.org/print-all-prime-factors-of-a-given-number/](https://www.geeksforgeeks.org/print-all-prime-factors-of-a-given-number/),
    but transposed to JavaScript. Once we are done, we will turn off the `worker`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: If we now run this application in the browser, we will see that after each input
    we get the console log message in the console. Notice that there is no factor
    for the number 1\. There is a mathematical reason for this, but just note that
    there is no prime factorization for the number 1.
  prefs: []
  type: TYPE_NORMAL
- en: We can run this for a bunch of inputs, but if we put in a relatively large number
    such as `123,456,789`, it will still compute it in the background as we do things
    on the main thread. Now, we are currently passing data to the worker through the
    name of the worker. There has to be a way to pass data between the worker and
    the main thread. This is where the `postMessage` and `BroadcastChannel` APIs come
    into play!
  prefs: []
  type: TYPE_NORMAL
- en: Moving data in our application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have seen in the `worker_thread` module inside of Node.js, there is a
    way to communicate with our workers. This is through the `postMessage` system.
    If we take a look at the method signature, we will see that it requires a message
    that can be any JavaScript object, even those with cyclical references. We also
    see another parameter called transfer. We will go into depth on that in a bit
    but, as the name suggests, it allows us to actually transfer the data instead
    of copying the data to the worker. This is a much faster mechanism for transferring
    data, but there are some caveats when utilizing it that we will discuss later.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take the example that we have been building on and respond to messages
    sent from the frontend:'
  prefs: []
  type: TYPE_NORMAL
- en: We will swap out creating a new `worker` each time a change event occurs and
    just create one right away. Then, on a change event, we will send the data to
    the `worker` via the `postMessage`*:*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'If we now tried this example, we would not receive anything from the main thread.
    We have to respond to the `onmessage` event that comes on the worker''s global
    descriptor called `self`. Let''s go ahead and add our handler to that and also
    remove the `self.close()` method since we want to keep this around:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see from this example, we have moved the calculation of the primes
    to a separate function and when we get a message, we grab the data and pass it
    to the `calculatePrimes` method. Now, we are working with the messaging system.
    Let''s go ahead and add another feature to our example. Instead of printing to
    the console, let''s give the user some feedback based on what they input:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will add a paragraph tag below the input that will hold our answer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will add to the `onmessage` handler of `worker`, just like we did inside
    of the `worker`, to listen for events from the `worker`. When we get some data,
    we will populate the answer with the values returned:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will change our `worker` code to send the data utilizing the `postMessage`
    method to send the primes back to the main thread:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This also showcases that we do not need to add the `self` piece to call methods
    that are on the global scope. Just like the window is the global scope for the
    main thread, `self` is the global scope for the worker threads.
  prefs: []
  type: TYPE_NORMAL
- en: With this example, we have explored the `postMessage` method and seen how we
    can send data between a worker to the thread that spawned it, but what if we had
    multiple tabs that we wanted to communicate with? What if we had multiple workers
    that we wanted to send messages to?
  prefs: []
  type: TYPE_NORMAL
- en: 'One way of dealing with this is to just keep track of all of the workers and
    loop through them, sending the data out like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In the `test.js` file, we just console log the message and say which worker
    we are referencing by name. This can easily get out of hand since we would need
    to keep track of which workers are still alive and which ones have been removed.
    Another way of handling this would be to broadcast the data out on a channel.
    Luckily, we have an API for that, called the `BroadcastChannel` API.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the document on the MDN site states ([https://developer.mozilla.org/en-US/docs/Web/API/Broadcast_Channel_API](https://developer.mozilla.org/en-US/docs/Web/API/Broadcast_Channel_API)),
    all we need to do is create a `BroadcastChannel` object by passing a single argument
    into its constructor, the name of the channel. Whoever calls it first creates
    the channel and then anyone can listen in on it. Sending and receiving data is
    as simple as our `postMessage` and `onmessage` examples have been. The following
    takes our previous code for our test interface and, instead of needing to keep
    track of all the workers, just broadcasts the data out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, in our `workers`, all we need to do is listen in on `BroadcastChannel`
    instead of listening in on our own message handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We have now simplified the process of sending and receiving a message between
    multiple workers and even multiple tabs that have the same host. What makes this
    system great is that we can have some workers based on some criteria listen in
    on one channel and others listen in on another. We could then have a global channel
    to send commands that any of them could respond to. Let''s go ahead and make a
    simple adjustment to our primes program. Instead of sending the data to a single
    dedicated worker, we will have four workers; two of them will handle even numbers
    and the other two will handle odd numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We update our main code to launch four workers. We will name them based on
    whether the number is even or not:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We change what happens upon an input, sending the even numbers to the even
    channel and the odd numbers to the odd channel:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We create three channels: one for the even numbers, one for the odd numbers,
    and one for a global send to all workers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We add a new button to kill all of the workers and hook it up to broadcast
    on the global channel:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We change our worker to handle messages based on its name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'When we do get a message on one of these channels, we respond just like we
    have been:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'If we receive a message on the global channel, we check to see whether it is
    the `quit` message. If it is, then kill the worker:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, back on the main thread, we will listen in on the even and odd channels
    for data. When there is data, we handle it almost exactly like before:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: One thing to note is how our workers and the main thread handle data coming
    in on the odd and even channels. Since we are broadcasting, we need to make sure
    it is the data that we want. In the case of the workers, we only want numbers
    and, in the case of our main thread, we only want to see arrays.
  prefs: []
  type: TYPE_NORMAL
- en: The `BroadcastChannel` API only works with the same origin. This means that
    we cannot communicate between two different sites, only with pages under the domain.
  prefs: []
  type: TYPE_NORMAL
- en: While this is an overly complex example of the `BroadcastChannel` mechanism,
    it should showcase how we can easily decouple workers from their parents and make
    them easy to send data to without looping through them. Now, we will return to
    the `postMessage` method and look at that `transferrable` property and what it
    means for sending and receiving data.
  prefs: []
  type: TYPE_NORMAL
- en: Sending binary data in the browser
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While message passing is a great way to send data, there are some problems
    when it comes to sending very large objects across the channel. For instance,
    let''s say we have a dedicated worker that makes requests on our behalf and also
    adds some data to the worker from a cache. It could potentially have thousands
    of records. While the worker would already be taking up quite a bit of memory,
    as soon as we utilize `postMessage` we will see two things:'
  prefs: []
  type: TYPE_NORMAL
- en: The amount of time it takes to move the object is going to be long
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our memory is going to increase dramatically
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The reason for this is the structured clone algorithm that browsers use to send
    the data. Essentially, instead of just moving the data across the channel, it
    is going to serialize and deserialize our object, essentially creating multiple
    copies of it. On top of this, we have no idea when the garbage collector is going
    to run as we know it is non-deterministic.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can actually see the copying process in the browser. If we create a worker
    called `largeObject.js` and move a giant payload, we can measure the time it takes
    by utilizing the `Date.now()` method. On top of this, we can utilize the record
    system in the developer''s tools, as we learned in [Chapter 1](28196d54-886b-4b9c-9974-190c0800c971.xhtml),
    *Tools for High Performance on the Web*, to profile the amount of memory that
    we use. Let''s set this test case up:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new worker and assign it a large object. In this case, we are going
    to use a 100,000-element array that is storing objects inside of it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We now add to our HTML file some code to launch this worker and listen for
    the message. We will mark when the message arrives and then we will profile the
    code to see the increase in memory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: If we now load this up into our browser and profile our code, we should see
    results similar to the following. The message took anywhere between 800 ms to
    1.7 s, and the heap size was anywhere between 80 MB and 100 MB. While this case
    is definitely out of the bounds of most people, it showcases some issues with
    this type of message passing.
  prefs: []
  type: TYPE_NORMAL
- en: A solution to this is to use the transferrable portion of the `postMessage`
    method. This allows us to *send* a binary data type across the channel and, instead
    of copying it, the channel actually just transfers the object. This means that
    the sender no longer has access to it, but the receiver does. A way to think about
    this is that the sender puts the data in a holding location and tells the receiver
    where it is at. At this point, the sender can no longer access it. The receiver
    receives all of the data and notices that it has a location to look for data.
    It goes to this location and grabs it, thereby fulfilling the data transfer mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go ahead and code a simple example. Let''s take our heavy worker and
    populate it with a bunch of data, in this case, a list of numbers from 1 to 1,000,000:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We create an `Int32Array` with 1,000,000 elements. We then add all of the numbers
    1 through 1,000,000 in it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'We will then send that data by utilizing the transferrable portion of `postMessage`.
    Note that we have to get the underlying `ArrayBuffer`. We will discuss this shortly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We will receive the data on the main thread and write out the length of that
    data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: We will notice that the time it took to transfer this large chunk of data was
    almost unnoticeable. This is because of the preceding theory where it just boxes
    the data and puts it to the side for the received.
  prefs: []
  type: TYPE_NORMAL
- en: An aside is needed for typed arrays and `ArrayBuffers`. The `ArrayBuffers` can
    be thought of as buffers in Node.js. They are the lowest form of storing data
    and directly hold the bytes of some data. But, to truly utilize them, we need
    to put a *view* on the `ArrayBuffer`. This means that we need to give meaning
    to that `ArrayBuffer`. In our case, we are saying that it stores signed 32-bit
    integers. We can put all sorts of views over `ArrayBuffer`, just like how we can
    interpret buffers in Node.js in different ways. The best way to think about this
    is that `ArrayBuffer` is the low-level system that we really don't want to utilize
    and that the views are the system that gives meaning to the underlying data.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this in mind, if we check out the byte length of the `Int32Array` on the
    worker side, we will see that it is zero. We no longer have access to that data,
    just as we said. To further utilize this feature before heading on to `SharedWorkers`
    and `SharedArrayBuffers`, we will modify our factorization program to utilize
    this transferrable property to send the factors across:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will utilize almost the exact same logic, except instead of sending over
    the array that we have, we will send over `Int32Array`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we will update our receiving end code to handle `ArrayBuffers` being sent
    instead of just an array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: If we test this code out, we will see that it works just the same, but we are
    no longer copying the data across, we are just giving it to the main thread, thereby
    making the message passing faster and making it utilize less memory.
  prefs: []
  type: TYPE_NORMAL
- en: The main idea is that, if we are just sending results or we need to be as quick
    as possible, we should try to utilize the transferrable system for sending data.
    If we have to use the data in the worker after sending it, or there is not a simple
    way to send the data (we have no serialization technique), we can utilize the
    normal `postMessage` system.
  prefs: []
  type: TYPE_NORMAL
- en: Just because we can use the transferrable system to reduce memory footprint,
    it could cause times to increase based on the amount of data transformation we
    need to apply. If we already have binary data, this is great, but if we have JSON
    data that needs to be moved, it may be better to just transfer it in that form
    instead of having to go through many intermediary transformations.
  prefs: []
  type: TYPE_NORMAL
- en: With all of these ideas, let's take a look at the `SharedWorker` system and
    `SharedArrayBuffer` system. Both of these systems, especially the `SharedArrayBuffer`,
    have led to some issues in the past (we will discuss this in the following section),
    but if we utilize them carefully we will be able to leverage their capability
    of being a good message-passing and data-sharing mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: Sharing data and workers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While most of the time we want to keep the boundaries up between our workers
    and tabs of our applications, there will be times when we want to just share the
    data or even the worker among every instance. When this is the case, we can utilize
    two systems, `SharedWorker` and `SharedArrayBuffer`.
  prefs: []
  type: TYPE_NORMAL
- en: '`SharedWorker` is just what it sounds like, when one spins up, just like `BroadcastChannel`,
    and someone else makes the same call to create a `SharedWorker`, it will just
    connect to the already created instance. Let''s go ahead and do just this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will create a new file for the `SharedWorker` JavaScript code. Inside of
    here, put some general computing functions such as adding and subtracting:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Inside of one of our current workers'' code, start up `SharedWorker`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: We will already see a problem. Our system states that `SharedWorker` is not
    found. To utilize `SharedWorker`, we have to start it in a window. So now, we
    will have to move that start code to our main page.
  prefs: []
  type: TYPE_NORMAL
- en: 'Move the start code into the main page and then pass the port to one of the
    workers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: We now run into another problem. Since we wanted to pass the port to the worker
    and not have access to it in the main window, we utilized the transferrable system.
    However, since we only had a single reference at that time, once we send it to
    one worker, we can't send it again. Instead, let's start one worker and turn our
    `BroadcastChannel` system off.
  prefs: []
  type: TYPE_NORMAL
- en: 'Comment out our `BroadcastChannels` and all of our looping code. Let''s only
    start a single worker up in this window:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'With these changes, we will have to simplify our dedicated worker. We will
    just respond to events on our message channel like before:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we have the `SharedWorker` port in a single worker, but what did all of
    this solve for us? Now, we can have multiple tabs open at the same time and get
    the data to every single one of them. To see this, let''s hook a handler up to
    `sharedPort`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can update our `SharedWorker` to respond once a connection happens,
    like the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'With this, we will see a message come back to our workers. We now have our
    `SharedWorker` up and running and communicating directly with our `DedicatedWorker`!
    However, there is still one problem: why did we not see the log from our `SharedWorker`?
    Well, our `SharedWorker` lives in a different context than our `DedicatedWorker`
    and our main thread. To get access to our `SharedWorker`, we can go to the URL
    `chrome://inspect/#workers` and then locate it. Right now, we did not call it
    anything so it should be called `untitled`, but when we click the `inspect` option
    underneath it, we now have a debug context for the worker.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have connected our `SharedWorker` to the DOM context, and we have connected
    every `DedicatedWorker` to that `SharedWorker`, but we need to be able to send
    messages to each `DedicatedWorker`. Let''s go ahead and add this code:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will need to keep track of all of the workers that connected to us
    through the `SharedWorker`. Add the following code to the bottom of our `onconnect`
    listener:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will add some HTML to our document so we can send the `add`, `multiply`,
    `divide`, and `subtract` requests along with two new number inputs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will pass this information through the `DedicatedWorker` to the `SharedWorker`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, our `SharedWorker` will run the corresponding operation and pass it
    back to the `DedicatedWorker`, which will log the data to the console:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: With all of this, we can now have multiple tabs of our application open that
    are all sharing the same preceding math system! This is overkill for this type
    of application, but it could be useful when we need to perform complex operations
    in our application that span multiple windows or tabs. This could be something
    that utilizes the GPU and we only want to do this once. Let's go ahead and wrap
    this section up with an overview of `SharedArrayBuffer`. However, one thing to
    remember is that a `SharedWorker` is a single thread held by all tabs, whereas
    a `DedicatedWorker` is a thread per tab/window. While sharing a worker can be
    beneficial for some tasks explained previously, it can also slow down other tasks
    if multiple tabs are utilizing it at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: '`SharedArrayBuffer` allows all of our instances to share the same block of
    memory. Just as a transferrable object can have different owners based on passing
    the memory to another worker, a `SharedArrayBuffer` allows different contexts
    to share the same piece. This allows for updates to propagate across all of our
    instances and has almost instant updates for some types of data, but it also has
    many pitfalls associated with it.'
  prefs: []
  type: TYPE_NORMAL
- en: This is as close as we will most likely get to `SharedMemory` in other languages.
    To properly utilize `SharedArrayBuffer`, we will need to utilize the Atomics API.
    Again, not diving directly into the detail behind the Atomics API, it makes sure
    that operations happen in the correct sequence and that they are guaranteed to
    update what they need to without anyone overriding them during their update.
  prefs: []
  type: TYPE_NORMAL
- en: Again, we are starting to get into details where it can be hard to fully understand
    what is happening. One good way to think of the Atomics API is a system where
    many people are sharing a piece of paper. They all take turns writing on it and
    reading what others wrote down.
  prefs: []
  type: TYPE_NORMAL
- en: However, one of the downfalls is that they are only allowed to write a single
    character at a time. Because of this, someone else may write something in their
    location while they are still trying to finish writing their word, or someone
    may read their incomplete phrase. We need a mechanism for people to be able to
    write the entire word that they want, or read the entire section, before someone
    starts writing. This is the job of the Atomics API.
  prefs: []
  type: TYPE_NORMAL
- en: '`SharedArrayBuffer` does suffer from issues related to browsers not supporting
    it (currently, only Chrome supports it without a flag), to issues where we might
    want to use the Atomics API (`SharedWorker` cannot send it to the main thread
    or the dedicated workers due to security issues).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To set up a basic example of `SharedArrayBuffer` in action, we will share a
    buffer between the main thread and a worker. When we send a request to the worker,
    we will update the number that is inside that worker by one. Updating this number
    should be visible to the main thread since they are sharing the buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a simple worker and using the `onmessage` handler check whether it received
    a number or not. If it is, we will increment the data in the `SharedArrayBuffer`.
    Otherwise, the data is the `SharedArrayBuffer` coming from the main thread:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, on our main thread, we are going to add a new button that says `Increment`.
    When this is clicked, it will send a message to the dedicated worker to increment
    the current number:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, when the worker updates the buffer on its side, we will constantly be
    checking `SharedArrayBuffer` if there is an update. We will always just put the
    number inside of the number paragraph element that we showed in the previous code
    snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, to kick all of this off, we will create a `SharedArrayBuffer` on the
    main thread and send it to the worker once we have launched it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: With this, we can see that our value is now incrementing even though we are
    not sending any data from the worker to the main thread! This is the power of
    shared memory. Now, as stated previously, we are quite limited with the Atomics
    API since we cannot use the `wait` and `notify` systems on the main thread and
    we cannot use `SharedArrayBuffer` inside of a `SharedWorker`, but it can be useful
    for systems that are only reading data.
  prefs: []
  type: TYPE_NORMAL
- en: In these cases, we may update the `SharedArrayBuffer` and then send a message
    to the main thread that we updated it, or it may already be a Web API that takes
    `SharedArrayBuffers` such as the WebGL rendering context. While the preceding
    example is not very useful, it does showcase how we might be able to use the shared
    system in the future if the ability to spawn and use `SharedArrayBuffer` in a
    `SharedWorker` is available again. Next, we will focus on building a singular
    cache that all the workers can share.
  prefs: []
  type: TYPE_NORMAL
- en: Building a simple shared cache
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With everything that we have learned, we are going to focus on a use case that
    is quite prevalent in reporting systems and most types of operation GUIs—a large
    chunk of data that needs to have other data added to it (some call this decorating
    the data and others call this attribution). An example of this is that we have
    the buy and sell orders for a list of customers.
  prefs: []
  type: TYPE_NORMAL
- en: 'This data may come back in the following manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'With this data, we may want to add some context that the customer ID is associated
    with. We could go about this in two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we could have a join operation done in the database that adds the required
    information for the user.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second, and the one we will be illustrating here, is adding this data on the
    frontend when we get the base-level query. This means when our application starts,
    we would fetch all of this attribution data and store it in some background cache.
    Next, when we make a request, we will also make a request to the cache for the
    corresponding data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For us to achieve the second option, we will implement two of the technologies
    that we learned previously, the `SharedWorker` and the `postMessage` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We create a base-level HTML file that has a template for each row of data.
    We will not go into a deep dive of creating a web component as we did in [Chapter
    3](da1a0a36-4261-43f1-a42b-a9d94284dc9f.xhtml), *Vanilla Land – Looking at the
    Modern Web*, but we will use it to create our table rows on demand:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'We set up some pointers to our template and table so we can do quick inserts.
    On top of this, we can create a placeholder for the `SharedWorker` that we are
    about to create:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'With this basic setup, we can create our `SharedWorker` and give it some base-level
    data. To do this, we are going to use the website [https://www.mockaroo.com/](https://www.mockaroo.com/).
    This will allow us to create a bunch of random data without having to think of
    it ourselves. We can change the data to whatever we want but, in our case, we
    will go with the following options:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`id`: Row number'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`full_name`: Full name'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`email`: Email address'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`phone`: Phone'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`zipcode`: Digit sequence: `######`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With these options filled in, we can change the format to JSON and save by
    clicking Download Data. With this done, we can build out our `SharedWorker`. Similar
    to our other `SharedWorker`, we will take the `onconnect` handler and add an `onmessage`
    handler for the port that comes in:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we launch our `SharedWorker` back in our HTML file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, when our `SharedWorker` is launched, we will load the file by utilizing
    `importScripts`. This allows us to load in outside JavaScript files, just like
    we would do in HTML, with the `script` tag. To do this, we will need to modify
    the JSON file to point the object to a variable and rename it to a JavaScript
    file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have brought the cache of data in, we will respond to messages
    sent from the ports. We will expect only arrays of numbers. These will correspond
    to the ID that is associated with a user. For now, we will loop through all of
    the items in our dictionary to see whether we have them. If we do, we will add
    them to an array that we will respond with:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'With this, we will need to add the corresponding code inside of our HTML file.
    We will add a button that is going to send 100 random IDs to our `SharedWorker`.
    This will simulate when we make a request and get back the IDs associated with
    the data. The simulation function looks like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'With the preceding simulation, we can now add in our input for a request and
    then send that to our `SharedWorker`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we are currently posting the wrong data to our `SharedWorker`. We only
    want to post the IDs, but how are we going to tie our request to the responses
    from our `SharedWorker`? We will need to slightly modify the structure that we
    have for our `request` and `response` methods. We will now tie an ID to our message
    so we can have the `SharedWorker` post that back to us. This way, we can have
    a map on the frontend of requests and the IDs associated with them. Make the following
    changes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'With these changes, we still need to make sure we only pass the IDs to the
    `SharedWorker`. We can pull these off from the request before we send it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we need to handle the data coming back to us inside of our HTML file. First,
    we attach an `onmessage` handler to the port:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we grab the associated buy/sell order from our map and populate it
    with the returned cache data. Once we have done this, we just have to clone our
    row template and fill in the corresponding fields:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: With the preceding example, we have created a shared cache that any page that
    has the same domain can use. While there are certain optimizations (we could store
    the data as a map and have the ID as the key), we are still going to run a bit
    faster than having to potentially wait on a database connection (especially when
    we are in places that have limited bandwidth).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This entire chapter has been focused on offloading tasks from the main thread
    to other threads of work. We have looked at dedicated workers that only a single
    page has. We have then taken a look at how we can broadcast messages between multiple
    workers without having to loop through the respective ports.
  prefs: []
  type: TYPE_NORMAL
- en: Then we saw how we can share a worker on the same domain utilizing `SharedWorker`
    and also looked at how we can share a data source utilizing `SharedArrayBuffer`.
    Finally, we took a practical look at creating a shared cache that anyone has access
    to.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will take this concept of caching and handling requests
    one step further by utilizing `ServiceWorker`.
  prefs: []
  type: TYPE_NORMAL
