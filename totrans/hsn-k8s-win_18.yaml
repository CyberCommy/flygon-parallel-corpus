- en: Monitoring Kubernetes Applications Using Prometheus
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes as a containers orchestrator is a complex, distributed system that
    requires monitoring and alerting to function properly at scale. At the same time,
    you need to monitor your applications running on Kubernetes in the same manner—if
    you do not have monitoring and alerting in place, you have no idea how your application
    behaves, whether any failures occur, or whether you should scale up your workload.
    In fact, the challenges connected with monitoring and alerting are among the most
    often-reported blockers for the adoption of Kubernetes by enterprises.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, over the years, the market has boomed with multiple solutions for
    log aggregation, telemetry gathering, alerting, and even dedicated **Application
    Performance Management** (**APM**) systems. We can choose from different Software-as-a-Service
    (**SaaS**) solutions or open source systems that can be hosted on-premises, all
    dedicated just for Kubernetes clusters!
  prefs: []
  type: TYPE_NORMAL
- en: 'But there is the other side of the coin: we are constrained to solutions that
    can support Windows containers and Windows-based Kubernetes nodes. Production-grade
    support for Windows in Kubernetes is very recent and there are no turnkey solutions
    that work just out of the box. Therefore, this chapter aims to provide an overview
    of the available monitoring solutions for Kubernetes in general and explore how
    you can implement your own solution that supports Windows nodes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Available monitoring solutions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provisioning observable Windows nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying Prometheus using a Helm chart
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Windows Performance Counters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring .NET applications using `prometheus-net`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring dashboards and alerts in Grafana
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you will need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Windows 10 Pro, Enterprise, or Education (version 1903 or later, 64-bit) installed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microsoft Visual Studio 2019 Community (or any other edition) if you want to
    edit the source code for the application and debug it—Visual Studio Code has limited
    support for classic .NET Framework
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Helm installed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An Azure account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Windows/Linux Kubernetes cluster deployed using AKS Engine, ready to deploy
    the voting application from the previous chapter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To follow along, you will need your own Azure account to create Azure resources
    for the Kubernetes cluster. If you haven't already created the account for the
    previous chapters, you can read more about how to obtain a limited free account
    for personal use here: [https://azure.microsoft.com/en-us/free/](https://azure.microsoft.com/en-us/free/).
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a Kubernetes cluster using AKS Engine has been covered in [Chapter
    8](ab695a0d-05dc-48f8-8c41-bbd167cfbfa6.xhtml), *Deploying a Hybrid Azure Kubernetes
    Service Engine Cluster*. The voting application Deployment to Kubernetes has been
    covered in [Chapter 10](4e5931bc-4267-4631-a5fe-bc140827257d.xhtml), *Deploying
    Microsoft SQL Server 2019 and ASP.NET MVC Application*.
  prefs: []
  type: TYPE_NORMAL
- en: You can download the latest code samples for this chapter from the official
    GitHub repository: [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14).
  prefs: []
  type: TYPE_NORMAL
- en: Available monitoring solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The word monitoring is commonly used as an umbrella term that covers the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Observability**: Providing observability for your components means exposing information
    about their inner state so that you can access the data easily and do reasoning
    about the actual state of your components. In other words, if something is observable,
    you can understand it. A well-known example of a feature that provides observability
    is logging. Your applications produce logs so that you can examine the flow and
    the current state of your application. There are three pillars of observability:
    logging, distributed tracing, and metrics. Distributed tracing provides insight
    into the flow of a request going through multiple services, for example, using
    correlation IDs. Metrics can be just numeric information exposed by your application,
    for example, counters or gauges.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring:** This means collecting observable data for your components and
    storing it so that it can be analyzed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Analysis and Alerting:** Based on collected monitoring data, you can perform
    analysis, create rules when a component is considered unhealthy, and configure
    alerting for your team. More complex scenarios involve, for example, anomaly detection
    and machine learning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In Kubernetes, monitoring has even more dimensions than monitoring a single
    application. Generally, you can divide the monitoring of a Kubernetes cluster
    into the following separate areas:'
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring hardware and operating system infrastructure of Kubernetes nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring container runtime
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring Kubernetes components and resources themselves
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring containerized applications running in the cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And finally, you can look at monitoring systems from the perspective of how
    the solution is hosted and related to Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**On-premises** **monitoring**: Using your own cloud or bare-metal infrastructure,
    you either provide a separate cluster just for running monitoring tools or use
    the same cluster as for applications. The second solution is much easier but can
    be considered only for small Kubernetes clusters. You want to separate application
    and monitoring workloads; you especially don''t want monitoring to negatively influence
    your application''s performance. An example of this approach is deploying your
    own Prometheus ([https://prometheus.io/](https://prometheus.io/)) instance to
    collect metrics in your Kubernetes cluster, together with a log analytics solution
    such as the **Elasticsearch, Logstash, Kibana** (**ELK**) stack ([https://www.elastic.co/what-is/elk-stack](https://www.elastic.co/what-is/elk-stack)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Internal SaaS** **monitoring**: If you are running in the cloud, you can
    use SaaS offerings provided by your cloud service provider, for example, on Azure,
    you can use Azure Monitor ([https://azure.microsoft.com/en-us/services/monitor/](https://azure.microsoft.com/en-us/services/monitor/)).
    Such solutions often easily integrate with other managed services, such as AKS.
    Additionally, for log monitoring, you can leverage Log Analytics in Azure Monitor
    ([https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/get-started-portal](https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/get-started-portal)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**External SaaS monitoring**: In this case, you use a dedicated, generic SaaS
    offering from an external company that can monitor your cluster running in any
    cloud or even on-premises. The market of monitoring platforms is big—well-known
    examples are New Relic ([https://newrelic.com/platform](https://newrelic.com/platform))
    and Dynatrace ([https://www.dynatrace.com/technologies/kubernetes-monitoring/](https://www.dynatrace.com/technologies/kubernetes-monitoring/)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generally, using internal SaaS monitoring is cheaper than external SaaS but
    you risk more vendor lock-in and increase your dependency ona given cloud service
    provider. Using on-premises monitoring, which you deploy yourself, is the most
    flexible and cheapest, but you have to consider the management and operations
    overhead that comes with an additional large application.
  prefs: []
  type: TYPE_NORMAL
- en: There is still the question of what to monitor. You can learn more about the
    Four Golden Signals in the following online book from Google: [https://landing.google.com/sre/sre-book/chapters/monitoring-distributed-systems/](https://landing.google.com/sre/sre-book/chapters/monitoring-distributed-systems/).
    Find out about the **USE** (short for**Utilization Saturation and Errors**) method
    in the following article: [http://www.brendangregg.com/usemethod.html](http://www.brendangregg.com/usemethod.html).
  prefs: []
  type: TYPE_NORMAL
- en: And now, hybrid Windows/Linux Kubernetes clusters come into the picture. It
    is important to know that monitoring Windows machines is quite different from
    monitoring Linux machines—you cannot use the same monitoring agents; they have
    to be dedicated to a given operating system.
  prefs: []
  type: TYPE_NORMAL
- en: Even in the case of Docker, the way it integrates into the operating system
    is different from Linux and Windows, which also means that the container runtime
    monitoring must be done differently. This is the reason why currently there are no
    turnkey solutions for monitoring Windows nodes in Kubernetes. The closest to providing
    this is the Container Monitoring solution in Azure Monitor ([https://docs.microsoft.com/en-us/azure/azure-monitor/insights/containers](https://docs.microsoft.com/en-us/azure/azure-monitor/insights/containers)),
    which can provide telemetry data for Windows containers but does not integrate
    with hybrid AKS or AKS Engine yet. You can still, of course, configure it manually
    on the machines that are part of AKS Engine.
  prefs: []
  type: TYPE_NORMAL
- en: So, what other solution do we have? As a more generic solution, we propose deploying
    a Prometheus instance that will be able to monitor metrics from Linux workloads
    by default and can be extended to monitor Windows nodes and containers.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed tracing and aggregating logs in your cluster are complex monitoring
    topics on their own. In this book, we will cover metrics monitoring only. If you
    are interested in logging solutions for Kubernetes, please check the official
    documentation: [https://kubernetes.io/docs/concepts/cluster-administration/logging/](https://kubernetes.io/docs/concepts/cluster-administration/logging/).
    For distributed tracing, consider reading about Jaeger: [https://www.jaegertracing.io/](https://www.jaegertracing.io/).
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at how we can provide metric monitoring for hybrid Kubernetes
    clusters using Prometheus.
  prefs: []
  type: TYPE_NORMAL
- en: Prometheus and monitoring Windows nodes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Prometheus ([https://prometheus.io/](https://prometheus.io/)) is an open source
    monitoring system for metrics, which uses the PromQL language for exploring time
    series data. It utilizes the concept of exporters and the HTTP pull model where
    exporters expose the data on a specified HTTP endpoint and are periodically scraped
    by the Prometheus server. Alternatively, it can use the HTTP push model, which
    is generally not recommended but sometimes useful. The format used for exposing
    metrics is a simple text format where each line represents one value of a metric,
    which has roughly the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Prometheus stores all data as time series, which are streams of readings for
    the same metric throughout the time—the exporters expose only the current value
    of a metric and Prometheus is responsible for storing the history as a time series.
    In this example, `http_requests_total` is the name of the metric, `method` is
    a label name, `"post"` is the label value, and `190` is the value of the metric
    right now. Labels are used for providing dimensions for your time series data,
    which can then be used for various operations such as filtering and aggregating
    in PromQL. The general format for a single reading is `<metric name>{<label name>=<label
    value>, ...} <metric_value>`.
  prefs: []
  type: TYPE_NORMAL
- en: You can read more about this format in the official documentation: [https://github.com/prometheus/docs/blob/master/content/docs/instrumenting/exposition_formats.md](https://github.com/prometheus/docs/blob/master/content/docs/instrumenting/exposition_formats.md)[. ](https://github.com/prometheus/docs/blob/master/content/docs/instrumenting/exposition_formats.md)
  prefs: []
  type: TYPE_NORMAL
- en: 'On top of Prometheus, you will commonly use Alertmanager for configuring alerting
    and Grafana ([https://grafana.com/](https://grafana.com/)) or Kibana ([https://www.elastic.co/products/kibana](https://www.elastic.co/products/kibana))
    for dashboards and visualizations. The following diagram shows the architecture
    of Prometheus at a high level and how it monitors Linux workloads running in Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/959c13db-97a5-495b-8d3d-26cc3b30e464.png)'
  prefs: []
  type: TYPE_IMG
- en: Common Prometheus architecture for monitoring Linux containers on Kubernetes
  prefs: []
  type: TYPE_NORMAL
- en: 'Apart from standard Prometheus components, there are two key exporters running on
    eachLinux node in the cluster: **cAdvisor**, which exposes container runtime metrics,
    and **Node** **Exporter**,which is responsible for exposing the operating system
    and hardware metrics. For Windows, we can use a similar scheme but we need to
    use different exporters, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/df756732-0303-496d-8a54-2d0270aef7ec.png)'
  prefs: []
  type: TYPE_IMG
- en: Possible Prometheus architecture for monitoring Windows containers on Kubernetes
  prefs: []
  type: TYPE_NORMAL
- en: In this case, to expose OS and hardware metrics, we use WMI Exporter, which
    is dedicated to Windows machines. It can also expose some Docker metrics, but
    we additionally can turn on the experimentalfeature of exposing metrics with Docker
    Engine natively, without an additional exporter. You can read more about this
    Docker feature in the documentation: [https://docs.docker.com/config/thirdparty/prometheus/](https://docs.docker.com/config/thirdparty/prometheus/).
  prefs: []
  type: TYPE_NORMAL
- en: Generally, on Windows, it is more problematic to deploy exporters as Kubernetes
    DaemonSets that gather OS metrics. As mentioned in the previous chapters, on Windows,
    you cannot run privileged containers so you will not have access to container
    runtime information. This is the main reason why monitoring Windows containers
    in Kubernetes is a bit harder than Linux containers—we have to configure the exporters
    outside of the Kubernetes cluster, directly on the host. Now, let's see how you
    can achieve that in an on-premises scenario and AKS Engine.
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning observable Windows nodes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The HTTP pull model that Prometheus uses perfectly aligns with the separation
    of concerns between observability and monitoring itself. The component or machine
    is responsible for exposing appropriate data and metrics—it allows being observed—and
    Prometheus periodically consumes the available data in the process called scraping.
    This means that if you have a way of exposing metrics in Prometheus format at
    some HTTP endpoint, you can use Prometheus for monitoring! It can be hardware
    telemetry exposed by a system service or even your own metrics accessible by an
    additional HTTP endpoint in your .NET application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, there is the question of how to gather the metrics data on the Windows
    operating system and expose it. We are interested in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Hardware-related metrics, for example, CPU, memory, network, and I/O metrics
    for the host machine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metrics for processes and the host operating system itself and performance counters
    in general
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metrics for the container runtime itself
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metrics for individual containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the case of bare-metal machines, additionally, information about hardware
    metrics such as CPU temperature and ECC memory correction counts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For Prometheus, the support for exporters on Windows is still expanding but
    currently, we can already collect most of the preceding metrics. In general, WMI
    Exporter ([https://github.com/martinlindhe/wmi_exporter](https://github.com/martinlindhe/wmi_exporter))
    is the recommended exporter for collecting all hardware-related and OS-related
    metrics on Windows. For the Docker runtime and containers, we can use an experimental
    feature of Docker ([https://docs.docker.com/config/thirdparty/prometheus/](https://docs.docker.com/config/thirdparty/prometheus/))
    that enables exposing the metrics in Prometheus format. Additionally, WMI Exporter
    can expose some useful Docker containers metrics when the container collector
    is enabled in the configuration.
  prefs: []
  type: TYPE_NORMAL
- en: If you are interested in any other Windows Performance Counters, you can use
    Telegraf ([https://www.influxdata.com/time-series-platform/telegraf/](https://www.influxdata.com/time-series-platform/telegraf/))
    to expose them as metrics in Prometheus format. We will do that in the next sections
    as there are very valid use cases for monitoring Windows Performance Counters
    on the host as well as inside a container.
  prefs: []
  type: TYPE_NORMAL
- en: Installing WMI Exporter and enabling Metrics Server in Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, we know a bit of the theory of how to make a Windows machine observable
    for Prometheus and which components can fulfill our requirements. The installation
    of WMI Exporter is fairly simple if you use Chocolatey:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This command will install the exporter with the default configuration and expose
    the metrics at the endpoint, `http://0.0.0.0:9182`, as described in the documentation
    for the package: [https://chocolatey.org/packages/prometheus-wmi-exporter.install](https://chocolatey.org/packages/prometheus-wmi-exporter.install).
    For our use case, we need some specific collectors enabled and this information
    can be passed to the installer as a parameter. Additionally, we should make the
    installation unattended and install Chocolatey if it is missing on the machine—our
    PowerShell script would look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'To enable Metrics Server, in Docker Engine at `http://0.0.0.0:9323`, we can
    create another small PowerShell script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, you have to consider how you are going to perform the installation. For
    on-premises Deployments, consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: If you use automation for creating your Kubernetes cluster, for example, Ansible,
    then you can add additional post-configuration steps.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you use bare-metal images or VM images for your machines in the cluster,
    you can embed the installation steps in the image provisioning process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you manage your machines using Ansible or PowerShell Desired State Configuration,
    you can also trigger the installation using these tools.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the case of cloud Deployments, everything depends on whether you are using
    managed or unmanaged clusters:'
  prefs: []
  type: TYPE_NORMAL
- en: For managed Deployments such as AKS, you are limited to what the service allows;
    for example, you can use VMSS with Custom Script Extensions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For unmanaged Deployments, you can use the same techniques as for on-premises
    Deployments, for example, providing a custom VM image with preinstalled services,
    or use solutions specifically for your cloud service provider.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For AKS Engine specifically, you have three options:'
  prefs: []
  type: TYPE_NORMAL
- en: For development and testing purposes, you can use RDP or SSH to connect to the
    Windows machine and perform the installation manually.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use a custom VM image for Windows nodes ([https://github.com/Azure/aks-engine/blob/master/docs/topics/windows-vhd.md](https://github.com/Azure/aks-engine/blob/master/docs/topics/windows-vhd.md)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use AKS Engine extensions ([https://github.com/Azure/aks-engine/blob/master/docs/topics/extensions.md](https://github.com/Azure/aks-engine/blob/master/docs/topics/extensions.md)),
    which are implemented as Custom Script Extensions running as a part of the Deployment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are going to demonstrate how you can customize your AKS Engine cluster Deployment
    using a dedicated extension.
  prefs: []
  type: TYPE_NORMAL
- en: Using extensions for AKS Engine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AKS Engine extensions are a feature that enables additional customization steps
    as post-provisioning steps in the Deployment. For example, you can execute any
    PowerShell script that you provide through the extensions repository. The repository
    can be any HTTP server that follows a convention in directory naming—this also
    includes raw GitHub repository access endpoints. To learn more about how the extensions
    work, please refer to the official documentation: [https://github.com/Azure/aks-engine/blob/master/docs/topics/extensions.md](https://github.com/Azure/aks-engine/blob/master/docs/topics/extensions.md).
    You can use the `winrm` extension as a good base to understand the implementation
    details: [https://github.com/Azure/aks-engine/tree/master/extensions/winrm](https://github.com/Azure/aks-engine/tree/master/extensions/winrm).
  prefs: []
  type: TYPE_NORMAL
- en: Using extensions is possible during the cluster Deployment only. You cannot
    enable an extension on a running cluster. Additionally, due to the SQL Server
    Helm chart requiring four volumes to be mounted on a single node, we need to use
    a larger VM type for Linux nodes, for example, Standard_D4_v3, which supports
    up to eight volumes. You can read more about the maximum number of volumes mounted
    per VM in the documentation: [https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes-general](https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes-general).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the GitHub repository for this book, you can find an extension that installs
    WMI Exporter and enables Docker Metrics Server on Windows: [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/03_aks-engine-windows-extensions/extensions/prometheus-exporters](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/03_aks-engine-windows-extensions/extensions/prometheus-exporters/).
    Let''s see how the extension is built and how to deploy a new AKS Engine cluster
    with the extension:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The PowerShell script, `v1/installExporters.ps1`, performs the custom installation
    logic and has the following contents:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: It will install WMI Exporter using Chocolatey, enable the Metrics Server for
    Docker, and restart Docker afterward.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `v1/template.json` JSON file contains an ARM template that triggers the
    PowerShell script, the key part of which is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This configures properties for the Custom Script Extension, which will download
    the installation script and execute it with parameters that you pass in the cluster
    apimodel.
  prefs: []
  type: TYPE_NORMAL
- en: '`v1/template-link.json` is a generic file that has placeholders to be replaced
    by AKS Engine. In this way, your template will be linked to the Deployment.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, create a GitHub repository and push the extension. Ensure that you follow
    the directory naming convention, for example, the full path in the repository
    to `template.json` should be `extensions/prometheus-exporters/v1/template.json`.
    In the examples, we are going to use the following GitHub repository: [https://github.com/ptylenda/aks-engine-windows-extensions](https://github.com/ptylenda/aks-engine-windows-extensions).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, modify your AKS Engine cluster apimodel so that it uses the extension
    for all Windows nodes ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/04_aks-engine-cluster-with-extensions/kubernetes-windows-template.json](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/04_aks-engine-cluster-with-extensions/kubernetes-windows-template.json))
    and ensure that you are using `vmSize` for the Linux node pool, which is capable
    of mounting more than four volumes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: As `rootURL`, you need to provide the HTTP address for raw access to your GitHub
    repository with the extension. Additionally, we are passing `'/EnabledCollectors:cpu,cs,container,dns,logical_disk,logon,memory,net,os,process,service,system,tcp'`
    as parameters to the extension, which will be used when executing the PowerShell
    script.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, deploy the cluster in the same way as in the previous chapters. You can
    also use our usual PowerShell script: [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/04_aks-engine-cluster-with-extensions/CreateAKSEngineClusterWithWindowsNodes.ps1](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/04_aks-engine-cluster-with-extensions/CreateAKSEngineClusterWithWindowsNodes.ps1).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When the Deployment is finished, use the `kubectl get nodes -o wide` command
    to determine the private IP of one of your Windows nodes, for example, `10.240.0.65`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'SSH to the master node using the `ssh azureuser@<dnsPrefix>.<azureLocation>.cloudapp.azure.com` command and
    check whether the Windows node exports metrics on ports `9323` and `9182`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Congratulations! Now your Windows nodes in AKS Engine cluster are exposing metrics
    that can be scraped by Prometheus. In the next section, we will install Prometheus
    in our cluster and configure it to monitor both Linux and Windows nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying Prometheus using a Helm chart
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our cluster infrastructure is now observable—we can deploy Prometheus with
    appropriate configuration files and start monitoring the cluster. To deploy Prometheus,
    we have several options:'
  prefs: []
  type: TYPE_NORMAL
- en: Deploy it manually using multiple manifest files.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the `stable/prometheus` Helm chart ([https://github.com/helm/charts/tree/master/stable/prometheus](https://github.com/helm/charts/tree/master/stable/prometheus)).
    This chart provides Prometheus, Alertmanager, Pushgateway, Node Exporter (for
    Linux nodes), and kube-state-metrics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the `stable/prometheus-operator` Helm chart ([https://github.com/helm/charts/tree/master/stable/prometheus-operator](https://github.com/helm/charts/tree/master/stable/prometheus-operator))
    or `kube-prometheus` ([https://github.com/coreos/kube-prometheus](https://github.com/coreos/kube-prometheus)).
    These solutions aim at providing a way to quickly provision multiple Prometheus
    clusters in your Kubernetes cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In our case, the best choice is to use the `stable/prometheus` Helm chart as
    it requires minimum configuration and is not as complex as the generic Prometheus
    Operator. In production environments, running at a large scale, you should definitely
    consider using Prometheus Operator so that you can easily deploy multiple Prometheus
    clusters for different needs.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Helm charts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To deploy Prometheus using Helm chart, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to deploy our monitoring solution in a separate namespace named
    `monitoring`. Additionally, we need `StorageClass` defined for Prometheus data
    persistence. Create the `prereq.yaml` manifest file with the following contents:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Apply the manifest file using the `kubectl apply -f .\prereq.yaml` command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, we need to define values for the `stable/prometheus` Helm chart ([https://github.com/prometheus/prometheus](https://github.com/prometheus/prometheus)).
    This chart is highly configurable, so check whether you need to override any additional
    values. Create the `helm-values_prometheus.yaml` file and start editing it with
    the following contents ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/05_helm_prometheus/helm-values_prometheus.yaml](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/05_helm_prometheus/helm-values_prometheus.yaml)):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The most important part is ensuring that the proper `nodeSelector` is set for
    all components so that the Pods do not get accidentally scheduled on Windows machines.
    Additionally, we need to provide the name of `storageClass`, which will be used
    for handling PVCs. Another solution could be setting `azure-disk` as the default
    `storageClass` in the cluster. In the Helm chart configuration, you can also influence
    scraping settings, such as how often you would like to execute the scrape jobs.
    And finally, we are exposing both Prometheus and Alertmanager using the `LoadBalancer`
    Service—this is, of course, valid only for development and testing purposes in
    order not to use `kubectl proxy` (which requires additional configuration for
    Grafana) or use jump boxes.
  prefs: []
  type: TYPE_NORMAL
- en: For production scenarios, consider either limiting access to Prometheus to a
    private network or expose it behind Ingress, use HTTPS, and provide a safe authentication
    method. For example, you can integrate Nginx Ingress with Azure Active Directory
    ([https://kubernetes.github.io/ingress-nginx/examples/auth/oauth-external-auth/](https://kubernetes.github.io/ingress-nginx/examples/auth/oauth-external-auth/)).
  prefs: []
  type: TYPE_NORMAL
- en: Be careful when setting small `scrape_interval` values. Scraping in too short
    intervals may cause excessive load for your nodes and Pods and result in instability
    of the system. You should always evaluate how expensive your exporters are in
    terms of CPU usage and RAM memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Continue editing the `helm-values_prometheus.yaml` file and provide scraping
    configuration for Prometheus. We need to ensure that our WMI Exporter and Docker
    Engine metrics server are scraped by the Prometheus server. You can see the following
    configuration for the Docker Engine metrics server only; the configuration for
    WMI Exporter is almost the same apart from the port number:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Prometheus scrape configurations can get a bit complex; you can check the official
    documentation for a detailed explanation: [https://prometheus.io/docs/prometheus/latest/configuration/configuration/](https://prometheus.io/docs/prometheus/latest/configuration/configuration/).
    The basic configuration scrapes API resources that are annotated with `prometheus.io/scrape:
    ''true''`, so, for example, if you want your own application Pod to be scraped,
    you need to use this annotation (together with `prometheus.io/port`). Additionally,
    you can configure scraping based on API resources directly (`kubernetes_sd_configs`),
    in this case, `node`. After that, we perform various operations on the labels
    that were returned by the API for the node: we ensure that the final value of
    the `__address__` special label contains the required `9323` port, and we define `__metrics_path__`
    as `/metrics` so in the end, we will be scraping this HTTP endpoint: `http://<nodeAddress>:9323/metrics`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `values` file to install the Helm chart for Prometheus as the `prometheus`
    release:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'While the installation proceeds, you can already define the `helm-values_grafana.yaml`
    values file for the `stable/grafana` Helm chart, which we are going to use to
    deploy Grafana for Prometheus:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Similarly, we need to ensure that Grafana is scheduled on Linux nodes only.
    Again, we expose the Service using load balancer—you should consider a different
    strategy for production Deployments or at least provide proper authentication
    for this public endpoint. The last important thing is ensuring that our Prometheus
    instance is added as the default data source in Grafana. Here, you should use
    the Service name to use discovery via the DNS name.
  prefs: []
  type: TYPE_NORMAL
- en: 'Install the `stable/grafana` Helm chart as the `grafana` release using the
    following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, wait for all Pods to be ready and services to receive external IPs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, you have three web UIs that you can access:'
  prefs: []
  type: TYPE_NORMAL
- en: The Prometheus server (in our example, accessible at `http://40.78.42.14`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alertmanager (`http://40.78.81.58`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grafana (`http://104.40.19.54`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Verifying the Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Verify whether you can access your external IPs for the Services and perform
    some basic operations:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the web UI for your Prometheus server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to Status and choose Targets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Scroll down to the `windows-nodes-docker-metrics-server` and `windows-nodes-wmi-exporter
    targets` scraped by the jobs. They should be green and be executed without errors—if
    this is not the case, you need to verify your scraping configuration. For debugging
    purposes, you can introduce changes directly to the appropriate ConfigMap in the
    cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/24f22213-a81b-49db-8c42-c9e19b2b4e1e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Navigate to Graph in the menu at the top and switch to the Graph tab below
    the Execute button. Run an example query, `rate(wmi_net_bytes_total[60s])`, which
    plots the average number of bytes received by and sent to Windows nodes per seconds
    based on the last 60 seconds of the `wmi_net_bytes_total` counter metric:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/917ed898-b0d8-43e7-aae8-dde7d2032748.png)'
  prefs: []
  type: TYPE_IMG
- en: Open the Grafana web UI and log in with the credentials that you provided in
    the Helm chart.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click + in the menu and choose Dashboard, then select Add Query.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Enter an example PromQL query, `wmi_memory_available_bytes / (1024 * 1024 *
    1024)`, which will plot the available memory on Windows nodes in GB:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/cbee5da2-ea08-45ab-93be-1bed3201b7bd.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, we have a confirmation that our monitoring setup is working correctly!
    You can explore PromQL in depth in the official documentation: [https://prometheus.io/docs/prometheus/latest/querying/basics/](https://prometheus.io/docs/prometheus/latest/querying/basics/).
    It is a broad and powerful language that can implement most of your **Service
    Level Indicators** (**SLIs**) to monitor your **Service Level Objectives** (**SLOs**).
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will explore how you can configure exporting of any
    Windows Performance Counter using Telegraf.
  prefs: []
  type: TYPE_NORMAL
- en: Windows Performance Counters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Windows provides a feature called Performance Counters, which are used to provide
    information on how well the operating system, service, application, or driver
    is performing. Normally, you use **Windows Management Instrumentation** (**WMI**)
    to get individual metrics values and use more advanced applications such as Perfmon
    for visualizing the performance data locally. For .NET Framework applications,
    you can read multiple counters provided directly by the runtime; you can find
    a list of the counters in the documentation: [https://docs.microsoft.com/en-us/dotnet/framework/debug-trace-profile/performance-counters](https://docs.microsoft.com/en-us/dotnet/framework/debug-trace-profile/performance-counters).
    Having access to these metrics, you can easily monitor unusual spikes in the number
    of exceptions thrown (even without analyzing logs) or analyze garbage collection
    issues. On top of that, many classic .NET Framework applications expose their
    own Performance Counters.
  prefs: []
  type: TYPE_NORMAL
- en: 'For Kubernetes, in addition to the standard Performance Counters collected
    by WMI Exporter (custom queries are not supported yet: [https://github.com/martinlindhe/wmi_exporter/issues/87](https://github.com/martinlindhe/wmi_exporter/issues/87)),
    there are two scenarios that you can consider:'
  prefs: []
  type: TYPE_NORMAL
- en: Collecting Performance Counters for applications running in a container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collecting more Performance Counters from the Windows host machine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both of these can be solved using Telegraf ([https://github.com/influxdata/telegraf](https://github.com/influxdata/telegraf)),
    which is a generic, extensible agent for collecting, processing, aggregating,
    and writing metrics. One of the input plugins that it supports is `win_perf_counter`
    ([https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_perf_counters](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_perf_counters)),
    which can collect and transform any Performance Counters available on Windows.
    At the same time, Telegraf is capable of exposing the collected metrics in the
    Prometheus format using the `prometheus_client` output plugin ([https://github.com/influxdata/telegraf/tree/master/plugins/outputs/prometheus_client](https://github.com/influxdata/telegraf/tree/master/plugins/outputs/prometheus_client)).
    The complete solution requires preparing a configuration file, installing Telegraf
    as a Windows service, and ensuring that Prometheus scrapes the new endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you would like to collect more Performance Counters from the host machine,
    on AKS Engine, you can achieve it using custom extensions, exactly as we did for
    WMI Exporter and the Docker metrics server. We will demonstrate the first scenario:
    how you can enrich your Docker image so that your container running on Kubernetes
    exposes more metrics for Prometheus. Please note that you have to always consider
    whether it is a valid use case for you—embedding Telegraf in every single container
    in the cluster comes with increased CPU usage and RAM memory footprint. A general
    rule of thumb is that you should use this approach only for the key components
    that may require investigating complex performance problems or as an ad hoc action
    for debugging purposes.'
  prefs: []
  type: TYPE_NORMAL
- en: Extending a Docker image with the Telegraf service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The installation process for Telegraf on Windows is simple: it requires unzipping
    the file, providing a proper configuration file, and registering Telegraf as a
    Windows service. To build a new version of Docker image for the voting application,
    which exposes Performance Counters at port `9273`, you can use the source code
    from the GitHub repository ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/06_voting-application-telegraf](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/06_voting-application-telegraf))
    or execute the following steps on the previous version of the source code:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the root directory, create a new file, `telegraf.conf`, which contains the
    Telegraf configuration. You can find the contents of this file here: [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/06_voting-application-telegraf/telegraf.conf](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/06_voting-application-telegraf/telegraf.conf).
    We are presenting the significant parts only in the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: We are using the `prometheus_client` output plugin and the `win_perf_counters`
    input plugin, which has a gathering of multiple Performance Counters configured.
  prefs: []
  type: TYPE_NORMAL
- en: Add this file to `votingapplication.csproj` to include it in the build output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Modify the `Dockerfile.production` file so that it includes the part that installs
    Telegraf, right at the beginning of the `runtime` stage:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The preceding commands download the latest release of Telegraf, install it as
    a Windows service, and provide the configuration from the previous steps.
  prefs: []
  type: TYPE_NORMAL
- en: Build the image with the tag 1.6.0 and push it to Docker Hub as in the previous
    chapters. In our case, it will be `packtpubkubernetesonwindows/voting-application:1.6.0`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Telegraf configuration can be modified at container runtime by mounting
    a custom ConfigMap into the `C:\telegraf\telegraf.d` directory in the container.
    This is a perfect use case for ConfigMaps.
  prefs: []
  type: TYPE_NORMAL
- en: Now, the Docker image is ready and it can be used in the Helm chart for the
    voting application.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying an observable version of the voting application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To be able to scrape Performance Counters exposed by Telegraf in the container,
    we need to update the Helm chart to include the new tag for the Docker image and
    update the Pod annotations for scraping. You can find the ready Helm chart at: [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/07_voting-application-telegraf-helm](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/07_voting-application-telegraf-helm)
    or follow these steps using the previous version:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a PowerShell window in the root directory of the Helm chart.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the `Chart.yaml` file, increment `appVersion` to be equal with the Docker
    image tag `1.6.0`. Also, increment the version of the chart itself to `0.3.0`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `templates\service.yaml` file, add `annotations` for the Service so
    that Prometheus can start scrapping all Pods behind the Service at port `9273`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Update the `templates\deployment.yaml` file so that the voting application
    frontend Pod exposes port `9273` where Telegraf exports the data at the `/metrics`
    endpoint:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Ensure that the `dev-helm` namespace exists. Create the `dev-helm.yaml` manifest
    file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Apply the manifest file using the `kubectl apply -f .\dev-helm.yaml` command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The Helm chart is ready to be deployed. Execute the following command in the
    root directory of the Helm chart for the voting application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Alternatively, if you have already installed a previous version of this chart
    in your cluster, use the `helm upgrade` command with the same arguments.
  prefs: []
  type: TYPE_NORMAL
- en: Wait for the Deployment to finish; you can observe the progress in another PowerShell
    window using the `kubectl get pods -n dev-helm -w` command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'At this point, the new version of the voting application is deployed to the
    cluster and Prometheus is already scraping the Pods using the `kubernetes-service-endpoints`
    scraping job, which is defined in the default configuration. Let''s verify whether
    everything is working correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate in the web browser to the external IP for the voting application and
    create some traffic by using the website for a few minutes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the Prometheus server external IP in the web browser, open the Graph panel,
    and change the tab to Graph.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The Telegraf configuration is set up to output all metrics with the `win_`
    prefix. Let''s query one of these metrics, for example, `win_aspnet_app_Requests_Failed`,
    which is a counter for the number of failed requests in the ASP.NET application.
    Use the `rate(win_aspnet_app_Requests_Failed{app_kubernetes_io_name="voting-application"}[5m])` query,
    which gives the average per-second rate of failed requests in the last five minutes
    for the voting application for each Pod separately:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/6e13ec99-9e84-49d2-828f-cbe91a6193ff.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, you may be wondering why we see a sudden increase in the number of failed
    requests at some point—you will most likely see the same situation in your Prometheus.
    The answer is failed health checks (readiness probes) for a few minutes after
    deploying the Helm chart. As you probably remember, the SQL Server Helm chart
    requires up to 10 minutes to fully deploy. This means that, for this interval
    in time, the readiness probe for the voting application Pods will fail with an
    HTTP 500 status code.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating `rate` and `irate` requires at least two data points per interval
    in the time series. This means that you should use the interval value at least
    two times larger than the scraping interval. Otherwise, you will see missing data
    in the graph.
  prefs: []
  type: TYPE_NORMAL
- en: You can explore the other Performance Counters that we have exposed for each
    Pod—this configuration of Telegraf gets a large number of counters, such as the
    number of exceptions thrown in .NET CLR, the number of locks in .NET CLR (this
    may be very useful for detecting heavy-locking scenarios!), .NET CLR garbage collection
    statistics, or IIS performance counters.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next section, we will add the last piece of the monitoring puzzle: exposing
    your own metrics directly from the .NET Framework application using the `prometheus-net`
    NuGet package.'
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring .NET applications using prometheus-net
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As part of your monitoring infrastructure, you need to expose custom metrics,
    directly from your application, which provides additional instrumentation and
    insights into your business logic. The most popular programming languages have
    bindings for Prometheus—for C#, one of the libraries that provides integration
    with Prometheus is `prometheus-net` ([https://github.com/prometheus-net/prometheus-net](https://github.com/prometheus-net/prometheus-net)).
    You can use it with the classic .NET Framework and .NET Core as it is targeting
    .NET Standard 2.0\. The features include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Exporting counters and gauges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measuring operation duration and creating a summary or histogram
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracking in-progress operations and creating gauges with the number of concurrently
    executed code blocks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exception counting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additionally, for ASP.NET Core applications, you can use a dedicated middleware
    package ([https://www.nuget.org/packages/prometheus-net.AspNetCore](https://www.nuget.org/packages/prometheus-net.AspNetCore))
    to export ASP.NET metrics. Unfortunately for classic ASP.NET MVC, there is no
    support for this feature, but it is possible to implement a similar functionality
    manually.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the NuGet package and adding metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The library is provided as a NuGet package ([https://www.nuget.org/packages/prometheus-net](https://www.nuget.org/packages/prometheus-net)).
    To enable `prometheus-net` in the voting application, please follow the following
    steps or alternatively, you can use the ready version of source code available
    at: [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/08_voting-application-prometheus-net](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/08_voting-application-prometheus-net):'
  prefs: []
  type: TYPE_NORMAL
- en: Open the voting application solution in Visual Studio 2019.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click the VotingApplication project and choose Manage NuGet Packages....
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the `prometheus-net` package and install it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We need to start an HTTP listener for exporting metrics. In the `Global.asax.cs`
    file ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/08_voting-application-prometheus-net/Global.asax.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/08_voting-application-prometheus-net/Global.asax.cs)),
    in the `Application_Start` method at the beginning, add the following lines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This will expose the metrics at port `9274` at the `/metrics` endpoint at all
    network interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using a custom HTTP listener inside an application running on IIS requires
    adding a network ACL rule to allow using this port for IIS AppPool user. Therefore,
    we need to extend the `Dockerfile.production` file to include the following command,
    for example, after Telegraf installation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Right now, the application is exposing very basic .NET performance counters.
    We would like to add some custom metrics that will be specific for our voting
    application. As an example, we are going to add two metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Counter**: This is for the number of votes that have been added to the database
    since the start of the application. We can then use the counter to, for example,
    calculate the average number of votes added per time interval.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Histogram**:This is forthe duration to retrieve survey results and summarize
    them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To do that, please follow the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `SurveyController` class ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/08_voting-application-prometheus-net/Controllers/SurveysController.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/08_voting-application-prometheus-net/Controllers/SurveysController.cs)),
    define two metrics, `DbAddedVotesCount` and `GetSurveyResultOperationDuration`,
    as `static readonly` fields:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Increment the `DbAddedVotesCount` counter in the `Vote` controller action,
    just after adding each `Vote` to the database:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Measure the time of getting survey results to create the histogram. In the `Results`
    Controller Action, wrap the call to `GetSurveyResult` into the `using` block and
    use `GetSurveyResultOperationDuration` to measure the time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'After these changes, at the metrics export endpoint, you will see your new
    metrics:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Build a new version of Docker image, tag it as `1.7.0`, and push to Docker Hub.
    We are going to use the `packtpubkubernetesonwindows/voting-application:1.7.0`
    Docker image in the next section.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As you can see, adding the functionality for exporting your own metrics is quite
    simple and self-explanatory—you do not need to introduce significant changes to
    your existing code base!
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's deploy the new version of our application and test the new metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the new version of the voting application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have to modify the Helm chart in a similar way as we did in the last section.
    The Docker image has to be updated and new scraping port registered in annotations
    for the service—due to Prometheus not supporting multiple ports in a single scraping
    job ([https://github.com/prometheus/prometheus/issues/3756](https://github.com/prometheus/prometheus/issues/3756)),
    we need to add a second job which will use the new port. You can find the ready
    Helm chart at: [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/09_voting-application-prometheus-net-helm](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/09_voting-application-prometheus-net-helm) or
    follow these steps using the previous version:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the PowerShell window in the root directory of the Helm chart.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the `Chart.yaml` file, increment `appVersion` to be equal to the Docker image
    tag, `1.7.0`. Also, increment the `version` of the chart to `0.4.0`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `templates\service.yaml` file, add a new custom annotation, `prometheus.io/secondary-port`,
    for the Service for port `9274`. We will use this annotation in the new scraping
    job:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Update the `templates\deployment.yaml` file so that the voting application
    frontend Pod exposes port `9274` where the application exposes metrics data at the `/metrics` endpoint:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The Helm chart is ready. The Helm release for the voting application can be
    upgraded—execute the following command in the root directory of the Helm chart
    for the voting application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Wait for the Deployment to finish, you can observe the progress in another PowerShell
    window using the `kubectl get pods -n dev-helm -w` command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The last step is adding a Prometheus scrape job that will handle `prometheus.io/secondary-port`
    annotations. In the future, it should be easier to use multiple ports for scraping,
    but for now, you have to add multiple jobs for such purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `helm-values_prometheus.yaml` file ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/10_helm_prometheus-net/helm-values_prometheus.yaml](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/10_helm_prometheus-net/helm-values_prometheus.yaml))
    for the Prometheus Helm chart, add another extra scrape job. This job should have
    almost exactly the same definition as the default `kubernetes-service-endpoints`,
    which is present in [https://github.com/helm/charts/blob/master/stable/prometheus/values.yaml](https://github.com/helm/charts/blob/master/stable/prometheus/values.yaml) but
    with additional filtering:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The following actions will keep only the targets that have the `prometheus.io/secondary-port`
    annotation defined and use it to define the final `__address__` for scraping.
  prefs: []
  type: TYPE_NORMAL
- en: 'Upgrade the Helm release for Prometheus:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: When the upgrade is finished, the only resource that gets updated is the ConfigMap, `prometheus-server`.
    You need to wait a short while before Prometheus reloads the configuration.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the Prometheus web UI, navigate to Status and Targets and verify that scraping
    of the new port works correctly; you should see the `kubernetes-service-endpoints-secondary-ports`
    job with a green status:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/62032637-3245-4cb8-b4c3-f7adf67b2af5.png)'
  prefs: []
  type: TYPE_IMG
- en: Open the voting application web UI and add some votes over a few minutes' time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the Prometheus web UI in the Graph tab, run an example query to verify that
    the solution works. For example, use `sum(votingapplication_db_added_votes)` to
    get the total number of votes added to the database from all Pods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/e3b783f9-ce68-4d56-ab53-40b0287fac5b.png)'
  prefs: []
  type: TYPE_IMG
- en: Our solution works! In this way, you can export any metrics that you define
    in your application code and create much more complex queries that can be used
    for monitoring and analysis purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Now, it's time to configure a dashboard in Grafana and add some alerts.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring dashboards and alerts in Grafana
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The web UI of the Prometheus server is very limited and in most cases is used
    just for performing basic ad hoc queries and checking the configuration. To create
    more advanced visualizations of the data in Prometheus, you can use Grafana ([https://grafana.com/](https://grafana.com/)),
    which is an open source analytics and monitoring solution with support for multiple
    databases. In the previous sections, we have already deployed Grafana using a
    Helm chart together with Prometheus.
  prefs: []
  type: TYPE_NORMAL
- en: 'Grafana offers multiple ways to visualize your monitoring data—ranging from
    simple **line** charts and gauges to complex heatmaps. You can find more information
    about how to create the visualizations in the official documentation: [https://grafana.com/docs/grafana/latest/](https://grafana.com/docs/grafana/latest/).
    For our application, we will demonstrate how to configure an example dashboard
    with the following visualizations:'
  prefs: []
  type: TYPE_NORMAL
- en: A line graph for CPU usage for Windows nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A gauge for the average number of requests per second handled by IIS in the
    last 5 minutes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A line graph showing the number of votes added to the database in the last 5
    minutes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A heatmap for visualizing the histogram of the duration of retrieving survey
    results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of course, these graphs will not be enough to fully monitor your application
    but we would like to show the general principle of how to create the dashboards.
  prefs: []
  type: TYPE_NORMAL
- en: Adding visualizations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, let''s create the dashboard and add the first visualization for CPU
    usage for Windows nodes. Please perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the Grafana web UI and log in with the credentials provided in the
    Helm chart release. The default is user `admin` and password `P@ssword`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the side panel, click the + button and choose Dashboard.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the Save Dashboard button and provide `voting application` as the name.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose Add Query.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Provide the following query in the first metric: `100 - (avg by (instance) (irate(wmi_cpu_time_total{mode="idle"}[2m]))
    * 100)`. This query calculates the average CPU usage in the last two minutes using
    counters for the total CPU idle time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In Legend, provide `{{instance}}` to use the node hostname as label.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the left panel, choose Visualization. For the Y axis, in Unit choose Misc
    and select percent(0-100).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'From the left panel, choose General. Change the Title to `Average CPU usage`.
    Your graph should show the CPU utilization for both Windows nodes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/7a23e50d-3c25-4292-89c8-cd57a08a1a88.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The next step is creating the gauge for the average number of requests per
    second handled by IIS in the last 5 minutes. Follow the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Return to the dashboard view, click Add Panel, and choose Add Query.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Provide the following query in the first metric: `sum((rate(win_aspnet_app_Requests_Total[5m])))
    by (app_kubernetes_io_instance)`. This query calculates the per-second rate of
    requests in a 5-minute interval per each Pod and summarizes it globally by Kubernetes
    applications.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the left panel, choose Visualization. Choose Gauge.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the Display area, select Calc to be Last (not null) and in the Field area,
    change Unit to Throughput > request/sec (reqps).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'From the left panel, choose General. Change the Title to `IIS average number
    of requests per second in the last 5m`. Your gauge is showing the current average
    number of requests per second:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/dcb8f239-125b-4324-87c5-0c3f50480ae2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We are going to add the third visualization, which shows a line graph with the
    number of votes added to the database in the last five minutes. Please follow
    these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Return to the dashboard view, click Add Panel, and choose Add Query.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Provide the following query in the first metric: `sum(irate(votingapplication_db_added_votes[5m]))
    by (app_kubernetes_io_instance) * 300`. This query calculates the rate of increase
    of the number of votes in a 5-minute interval per Pod and summarizes it globally
    by Kubernetes application. We need to multiply by `300` (5 minutes) as `irate`
    calculates the rate per second.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set Legend format to `Votes in the last 5 minutes`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'From the left panel, choose General. Change the Title to `Number of votes added
    to the database in the last 5m`. Now your graph should look like the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/3ee5af6b-c88a-4b1b-8079-0569ed13003a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And finally, we are going to add the last visualization, which is a heatmap
    for visualizing the histogram of the duration of retrieving survey results. Heatmaps
    are the most effective way of visualizing histogram changes over time and, recently,
    Grafana was extended with native support for heatmaps for Prometheus histogram
    metrics. To create the visualization, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Return to the dashboard view, click Add Panel, and choose Add Query.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Provide the following query in the first metric: `sum(increase(votingapplication_getsurveyresult_duration_seconds_bucket[2m]))
    by (le)`. This query will transform our histogram data—we determine the absolute
    increase rate for each bucket in the last two minutes and summarize each bucket
    with the `le` label, which is the bucket identifier (`le` is short for **less
    or equal**—Prometheus histograms are cumulative). In this way, we have buckets
    that are global per whole application, not individual Pods.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change Legend format to `{{le}}` and set Format to `Heatmap`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the left panel, choose Visualization. Choose Heatmap.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the Y Axis area, for Unit, choose Time > seconds (s) and for Format choose
    Time series buckets. Set Decimals to `1` to have neat numbers display. Set Space
    to `0` and Round to `2`—our heatmap has a relatively large number of buckets,
    so it will make the display much smoother.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the Display area, turn on Show legend and Hide zero.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'From the left panel, choose General. Change the Title to `Heatmap for duration
    of getting survey results`. Check your heatmap, especially after stressing the
    main web page in multiple browser tabs with autorefresh! Heatmaps generally look
    better in the dark theme (which you can change in the Configuration menu globally):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/e1008a8e-6d1b-4753-b83d-5429e1945e24.png)'
  prefs: []
  type: TYPE_IMG
- en: You can clearly see how this operation was performing during stress testing
    with around 300 requests per minute.
  prefs: []
  type: TYPE_NORMAL
- en: 'And lastly, return to the dashboard view, save all changes, and reorder the
    visualizations as you wish:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/a5bfd5a6-da09-47a0-af08-80ab5f6e7705.png)'
  prefs: []
  type: TYPE_IMG
- en: In the next subsection, we will show how to configure email alerting in Grafana.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring alerting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Grafana, apart from creating visualizations and dashboards, is capable of defining alerting
    rules and sending notifications to multiple channels. You can find a list of supported
    notification channels in the official documentation: [https://grafana.com/docs/grafana/latest/alerting/notifications/](https://grafana.com/docs/grafana/latest/alerting/notifications/).
    The alerts are tied to particular visualizations so you need to have a proper
    visualization for your use case first. We are going to demonstrate how to create
    an alert for high CPU usage on a node.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to configure an email notification channel, so please follow
    these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Grafana requires SMTP configuration to send emails. Obtain these details for
    your email provider and modify the Grafana Helm chart values file, `helm-values_grafana.yaml`,
    so that it contains the node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Please note that if you would like to use Gmail, you will need to generate an
    app password if you have 2FA enabled.
  prefs: []
  type: TYPE_NORMAL
- en: 'Upgrade the Helm release for Grafana:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: After the upgrade is finished, navigate to the Grafana web UI. From the left
    panel, open Alerting and select Notification channels.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click New channel.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fill in the Name, select type Email, and provide email addresses.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click Send Test to test whether your SMTP configuration is correct. If you have
    any problems, check the logs for the Grafana Pod. After a few minutes, you should
    receive the test email in your inbox.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'When you have confirmed that your notification channel is working correctly,
    we can continue with creating the alert itself. We would like to receive an alert
    when average CPU usage on a node is above 80 percent for more than five minutes.
    Please follow these steps to configure such an alert:'
  prefs: []
  type: TYPE_NORMAL
- en: Open our dashboard and choose the Average CPU usage visualization. From the
    menu for the visualization, choose Edit.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the left panel, open Alert and click Create Alert.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Configure the alert as shown in the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/11fe4ac2-3e68-4a9b-ab71-2ebed85a5874.png)'
  prefs: []
  type: TYPE_IMG
- en: Choose your notification channel and optionally customize the notification message.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save the dashboard. You will notice that the dashboard has a heart icon indicating
    the alert status.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, we need to test our rule by creating some load. We can reuse our `StressCpu`
    action that we created in the previous chapters. Follow these steps to perform
    the test:'
  prefs: []
  type: TYPE_NORMAL
- en: In your web browser, navigate to `http://<applicationExternalIp>/Home/StressCpu?value=100` and
    repeat this action a few times to ensure that a few Pods start to stress the node
    enough.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Check the dashboard. You will notice that the health is still green but the
    metric is already in the red zone:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/243aeff0-3922-46aa-ace8-69fea39d69cd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Wait for five minutes from the point when the average usage for the last five
    minutes is above 80 percent. You should receive an email via your notification
    channel:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/2c59c431-414c-4afd-95e8-d32fd01c49f7.png)'
  prefs: []
  type: TYPE_IMG
- en: Congratulations! You have successfully configured dashboards for the voting
    application in Grafana and tested alerting features for our monitoring system.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this long chapter, you learned how to set up monitoring of your application
    running in Windows containers on Kubernetes. First, we took a look at available
    monitoring solutions and determined which fit our use case with Windows nodes—the
    best choice currently is using a dedicated instance of Prometheus together with
    Grafana. Next, you learned how to make Windows nodes observable in terms of hardware,
    operating system, and container runtime using WMI Exporter and the experimental
    Docker Engine metrics service. We have shown how you can install and configure
    these agents on an AKS Engine cluster using extensions.
  prefs: []
  type: TYPE_NORMAL
- en: The next step was the Deployment of Prometheus and Grafana using Helm charts.
    You needed to ensure that Prometheus scraping jobs are capable of discovering
    the new metrics endpoints on Windows nodes. After that, we focused on monitoring inside the
    container and Windows Performance Counters—we exposed several counters using Telegraf
    and configured scraping of the new endpoint by Prometheus. Additionally, you learned
    how to use the `prometheus-net` library to export custom metrics to Prometheus
    directly from your application code. And finally, as the cherry on top, we showed
    you how to configure a sample dashboard in Grafana for the voting application
    and how to enable email alerting for high CPU usage on Windows nodes.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will focus on disaster recovery and the Kubernetes backup strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why is observability the key concept in monitoring solutions?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What components can you use to monitor Windows nodes using Prometheus?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When should you use Prometheus Operator?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why do you need to configure extra scrape jobs in Prometheus for Windows nodes?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can you export any Windows Performance Counters from Windows containers
    to Prometheus?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the benefit of using the `prometheus-net` library?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can you configure more than one port for scraping a single Service in Prometheus?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the benefits of using a heatmap for the visualization of Prometheus
    histograms?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can find answers to these questions in the *Assessments* of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information about Kubernetes features and monitoring the cluster in
    general, please refer to the following Packt books:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*The Complete Kubernetes Guide* ([https://www.packtpub.com/virtualization-and-cloud/complete-kubernetes-guide](https://www.packtpub.com/virtualization-and-cloud/complete-kubernetes-guide)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Getting Started with Kubernetes - Third Edition* ([https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition](https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Kubernetes for Developers* ([https://www.packtpub.com/virtualization-and-cloud/kubernetes-developers](https://www.packtpub.com/virtualization-and-cloud/kubernetes-developers)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can learn more about Prometheus in the following Packt book:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Hands-On Infrastructure Monitoring with Prometheus* ([https://www.packtpub.com/virtualization-and-cloud/hands-infrastructure-monitoring-prometheus](https://www.packtpub.com/virtualization-and-cloud/hands-infrastructure-monitoring-prometheus)[).](https://www.packtpub.com/virtualization-and-cloud/hands-infrastructure-monitoring-prometheus)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
