- en: Scaling Your Application
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展您的应用程序
- en: '"Evolution is a process of constant branching and expansion."'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: “进化是一个不断分支和扩张的过程。”
- en: '- Stephen Jay Gould'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '- Stephen Jay Gould'
- en: 'Scalability and performance are not the same things:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展性和性能并不是相同的东西：
- en: '"The terms "performance" and "scalability" are commonly used interchangeably,'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: “‘性能’和‘可扩展性’这两个术语通常可以互换使用，
- en: 'but the two are distinct: performance measures the speed with which a single
    request can be executed, while scalability measures the ability of a request to
    maintain its performance under increasing load. For example, the performance of
    a request may be reported as generating a valid response within three seconds,
    but the scalability of the request measures the request''s ability to maintain
    that three-second response time as the user load increases."'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 但这两者是不同的：性能衡量的是单个请求执行的速度，而可扩展性衡量的是请求在负载增加时保持其性能的能力。例如，一个请求的性能可能被报告为在三秒内生成有效响应，但请求的可扩展性衡量的是请求在用户负载增加时保持这三秒的响应时间的能力。”
- en: '- Steven Haines, "Pro Java EE 5"'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '- Steven Haines，《Pro Java EE 5》'
- en: In the last chapter, we looked at how Node clusters might be used to increase
    the performance of an application. Through the use of clusters of processes and
    workers, we learned how to efficiently deliver results in the face of many simultaneous
    requests. We learned to scale Node *vertically*, keeping the same footprint (a
    single server) and increasing throughput by piling on the power of the available
    CPUs.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们看到了Node集群如何用于提高应用程序的性能。通过使用进程和工作进程的集群，我们学会了如何在面对许多同时请求时高效地交付结果。我们学会了垂直扩展Node，通过堆叠可用CPU的性能来增加吞吐量，保持相同的占用空间（单个服务器）。
- en: In this chapter, we will focus on *horizontal* scalability; the idea is that
    an application composed of self-sufficient and independent units (servers) can
    be scaled by adding more units without altering the application's code.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将专注于*横向*可扩展性；其思想是由自给自足和独立的单元（服务器）组成的应用程序可以通过添加更多单元而无需改变应用程序的代码来进行扩展。
- en: We want to create an architecture within which any number of optimized and encapsulated
    Node-powered servers can be added or subtracted in response to changing demands,
    dynamically scaling without ever requiring a system rewrite. We want to share
    work across different systems, pushing requests to the OS, to another server,
    to a third-party service, while coordinating those I/O operations intelligently
    using Node's evented approach to concurrency.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望创建一个架构，其中任意数量的优化和封装的Node驱动服务器可以根据不断变化的需求进行添加或减少，动态扩展而无需进行系统重写。我们希望在不同系统之间共享工作，将请求推送到操作系统、另一个服务器、第三方服务，同时使用Node的事件驱动并发方式智能地协调这些I/O操作。
- en: Through architectural parallelism, our systems can manage increased data volume
    more efficiently. Specialized systems can be isolated when necessary, even independently
    scaled or otherwise clustered.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 通过架构的并行性，我们的系统可以更有效地管理增加的数据量。必要时，专门的系统可以被隔离，甚至可以独立扩展或以其他方式进行集群化。
- en: Node is particularly well-suited to handle two key aspects of horizontally-scaled
    architectures.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Node特别适合处理横向扩展架构的两个关键方面。
- en: Firstly, Node enforces non-blocking I/O, such that the seizing up of any one
    unit will not cause a cascade of locking that brings down an entire application.
    As no single I/O operation will block the entire system, integrating third-party
    services can be done with confidence, encouraging a decoupled architecture.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，Node强制执行非阻塞I/O，这样任何一个单元的卡住都不会导致整个应用程序崩溃。由于没有任何单一的I/O操作会阻塞整个系统，因此可以放心地集成第三方服务，鼓励解耦的架构。
- en: Secondly, Node places great importance on supporting as many fast network communication
    protocols as possible. Whether through a shared database, a shared filesystem,
    or a message queue, Node's efficient network and `Stream` layers allow many servers
    to synchronize their efforts in balancing load. Being able to efficiently manage
    shared socket connections, for instance, helps when scaling out a cluster of servers
    as much as it does a cluster of processes.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，Node非常重视支持尽可能多的快速网络通信协议。无论是通过共享数据库、共享文件系统还是消息队列，Node的高效网络和“Stream”层允许许多服务器在平衡负载方面同步它们的努力。例如，能够高效地管理共享套接字连接有助于在扩展服务器集群和进程集群时使用。
- en: In this chapter, we will look at how to balance traffic between many servers
    running Node, how these distinct servers can communicate, and how these clusters
    can bind to and benefit from specialized cloud services.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨如何在运行Node的许多服务器之间平衡流量，这些不同的服务器如何进行通信，以及这些集群如何绑定并从专门的云服务中获益。
- en: When to scale?
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时进行扩展？
- en: The theory around application scaling is a complex and interesting topic that
    continues to be refined and expanded. A comprehensive discussion of the topic
    will require several books, curated for different environments and needs. For
    our purposes, we will simply learn how to recognize when scaling up (or even scaling
    down) is necessary.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 关于应用程序扩展的理论是一个复杂而有趣的话题，它不断得到完善和扩展。对于不同的环境和需求，全面讨论这个话题将需要几本书。对于我们的目的，我们只需学会如何识别何时需要进行扩展（甚至缩减）。
- en: Having a flexible architecture that can add and subtract resources as needed
    is essential to a resilient scaling strategy. A vertical scaling solution does
    not always suffice (simply adding memory or CPUs will not deliver the necessary
    improvements). When should horizontal scaling be considered?
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个灵活的架构，可以根据需要添加和减少资源，对于一个具有弹性的扩展策略至关重要。垂直扩展的解决方案并不总是足够（简单地添加内存或CPU不会带来必要的改进）。何时应考虑横向扩展？
- en: It is essential that you are able to monitor your servers. One simple but useful
    way to check the CPU and memory usage commanded by Node processes running on a
    server is to use the Unix `ps` (*process status*) command, for example, `ps aux
    | grep node`. A more robust solution is to install an interactive process manager,
    such as HTOP ([http://hisham.hm/htop/](http://hisham.hm/htop/)) for Unix systems,
    or Process Explorer for Windows-based systems ([https://docs.microsoft.com/en-us/sysinternals/downloads/process-explorer](https://docs.microsoft.com/en-us/sysinternals/downloads/process-explorer)).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 监控服务器是至关重要的。检查服务器上运行的Node进程所占用的CPU和内存使用情况的一个简单但有用的方法是使用Unix的`ps`（*进程状态*）命令，例如，`ps
    aux | grep node`。更健壮的解决方案是安装一个交互式进程管理器，比如Unix系统的HTOP（[http://hisham.hm/htop/](http://hisham.hm/htop/)）或基于Windows的系统的Process
    Explorer（[https://docs.microsoft.com/en-us/sysinternals/downloads/process-explorer](https://docs.microsoft.com/en-us/sysinternals/downloads/process-explorer)）。
- en: Network latency
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络延迟
- en: When network response times are exceeding some threshold, such as each request
    taking several seconds, it is likely that the system has gone well past a stable
    state.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 当网络响应时间超过某个阈值时，比如每个请求花费几秒钟，很可能系统已经远远超过了稳定状态。
- en: While the easiest way to discover this problem is to wait for customer complaints
    about slow websites, it is better to create controlled stress tests against an
    equivalent application environment or server.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然发现这个问题最简单的方法是等待客户对网站速度慢的投诉，但最好是针对等效的应用环境或服务器创建受控的压力测试。
- en: '**AB** (**Apache Bench**) is a simple and straightforward way to do blunt stress
    tests against a server. This tool can be configured in many ways, but the kind
    of test you would do for measuring the network response times for your server
    is generally straightforward.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**AB**（**Apache Bench**）是一种对服务器进行粗略压力测试的简单直接的方式。这个工具可以以多种方式进行配置，但通常用于测量服务器的网络响应时间的测试是比较直接的。'
- en: 'For example, let''s test the response times for this simple Node server:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们测试一下这个简单的Node服务器的响应时间：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here''s how one might test running 10,000 requests against that server, with
    a concurrency of 100 (the number of simultaneous requests):'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何对该服务器运行10,000个请求进行测试，并发数为100（即同时请求的数量）：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'If all goes well, you will receive a report similar to this:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，您将收到类似于这样的报告：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: There is a lot of useful information contained in this report. In particular,
    one should be looking for failed requests and the percentage of long-running requests.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这份报告中包含了很多有用的信息。特别是，应该寻找失败的请求和长时间运行的请求的百分比。
- en: Much more sophisticated testing systems exist, but `ab` is a good quick-and-dirty
    snapshot of performance. Get in the habit of creating testing environments that
    mirror your production systems and test them.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 存在更复杂的测试系统，但`ab`是性能的一个快速脏快照。养成创建与生产系统相似的测试环境并对其进行测试的习惯。
- en: 'Running `ab` on the same server running the Node process you are testing will,
    of course, impact the test speeds. The test runner itself uses a lot of server
    resources, so your results will be misleading. Full documentation for ab can be
    found at: [https://httpd.apache.org/docs/2.4/programs/ab.html](https://httpd.apache.org/docs/2.4/programs/ab.html).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行Node进程的同一台服务器上运行`ab`，当然会影响测试速度。测试运行程序本身会占用大量服务器资源，因此您的结果将是误导性的。`ab`的完整文档可以在此找到：[https://httpd.apache.org/docs/2.4/programs/ab.html](https://httpd.apache.org/docs/2.4/programs/ab.html)。
- en: Hot CPUs
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 热CPU
- en: When CPU usage begins to nudge maximums, start to think about increasing the
    number of units processing client requests. Remember that while adding one new
    CPU to a single-CPU machine will bring immediate and enormous improvements, adding
    another CPU to a 32-core machine will not necessarily bring an equal improvement.
    Slowdowns are not always about slow calculations.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当CPU使用率开始接近最大值时，开始考虑增加处理客户端请求的单位数量。请记住，虽然在单CPU机器上添加一个新的CPU会带来立即和巨大的改进，但在32核机器上添加另一个CPU不一定会带来同等的改进。减速并不总是由于计算速度慢造成的。
- en: 'As mentioned earlier, `htop` is a great way to get a quick overview of your
    server''s performance. As it visualizes the load being put on each core in real
    time, it is a great way to get an idea of what is happening. Additionally, the
    load average of your server is nicely summarized with three values. This is a
    happy server:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，`htop`是了解服务器性能的一个很好的方式。它实时可视化了每个核心所承受的负载，这是了解发生了什么的一个很好的方式。此外，服务器的负载平均值以三个值的形式得到了很好的总结。这是一个良好的服务器：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: What do these values mean? What is a "good" or a "bad" load average?
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值代表什么？什么是“好”的或“坏”的负载平均值？
- en: All three numbers are measuring CPU usage, presenting measurements taken at
    one, five, and fifteen-minute intervals. Generally, it can be expected that short-term
    load will be higher than long-term load. If, on an average, your server is not
    overly stressed over time, it is likely that clients are having a good experience.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个数字都是在衡量CPU使用率，呈现了一分钟、五分钟和十五分钟间隔的测量值。通常情况下，短期负载会比长期负载更高。如果平均而言，您的服务器随着时间的推移并没有过度紧张，那么客户很可能会有良好的体验。
- en: On a single-core machine, load average should remain between 0.00 and 1.00\.
    Any request will take *some* time—the question is whether the request is taking
    *more time than necessary*—and whether there are delays due to excessive load.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在单核机器上，负载平均值应保持在0.00和1.00之间。任何请求都会花费一些时间，问题是请求是否花费了比必要更多的时间，以及是否由于负载过大而出现了延迟。
- en: If a CPU can be thought of as a pipe, a measurement of 0.00 means that there
    is no excessive friction, or delay, in pushing through a drop of water. A measurement
    of 1.00 indicates that our pipe is at its capacity; water is flowing smoothly,
    but any additional attempts to push water through will be faced with delays, or
    backpressure. This translates into latency on the network, with new requests joining
    an ever-growing queue.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将CPU视为管道，测量值为0.00意味着推送一滴水时没有过多的摩擦或延迟。测量值为1.00表示我们的管道已经达到容量；水流畅地流动，但任何额外的推送水的尝试都将面临延迟或背压。这会转化为网络上的延迟，新请求加入不断增长的队列。
- en: A multicore machine simply multiplies the measurement boundary. A machine with
    four cores is at its capacity when load average reaches 4.00.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 多核机器只是将测量边界乘以。当负载平均值达到4.00时，拥有四个核心的机器已经达到容量。
- en: How you choose to react to load averages depends on the specifics of an application.
    It is not unusual for servers running mathematical models to see their CPU averages
    hit maximum capacity; in such cases, you want *all* available resources dedicated
    to performing calculations. A file server running at capacity, on the other hand,
    is likely worth investigating.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 您选择如何对负载平均值做出反应取决于应用程序的具体情况。对于运行数学模型的服务器来说，看到它们的CPU平均值达到最大容量并不罕见；在这种情况下，您希望*所有*可用资源都专门用于执行计算。另一方面，运行在容量上限的文件服务器可能值得调查。
- en: Generally, a load average above 0.60 should be investigated. Things are not
    urgent, but there may be a problem around the corner. A server that regularly
    reaches 1.00 after all known optimizations have been made is a clear candidate
    for scaling, as of course is any server exceeding that average.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，负载平均值超过0.60应该进行调查。事情并不紧急，但可能会有问题。一个经过所有已知优化后仍经常达到1.00的服务器显然是扩展的候选者，当然，任何超过这个平均值的服务器也是如此。
- en: 'Node also offers native process information via the `os` module:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Node还通过`os`模块提供本机进程信息：
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Socket usage
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 套接字使用
- en: 'When the number of persistent socket connections begins to grow past the capacity
    of any single Node server, however optimized, it will be necessary to think about
    spreading out the servers handling user sockets. Using `socket.io`, it is possible
    to check the number of connected clients at any time using the following command:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当持久套接字连接的数量开始超过任何单个Node服务器的容量时，无论优化多少，都需要考虑将处理用户套接字的服务器分散开来。使用`socket.io`，可以使用以下命令随时检查连接的客户端数量：
- en: '[PRE5]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In general, it is best to track web socket connection counts within the application,
    via some sort of tracking/logging system.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，最好通过应用程序内的某种跟踪/日志系统来跟踪Web套接字连接计数。
- en: Many file descriptors
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 许多文件描述符
- en: When the number of file descriptors opened in an OS hovers close to its limit,
    it is likely that an excessive number of Node processes are active, files are
    open, or other file descriptors (such as sockets or named pipes) are in play.
    If these high numbers are not due to bugs or a bad design, it is time to add a
    new server.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 当操作系统打开的文件描述符数量接近其限制时，很可能有过多的Node进程活动，文件已打开，或者其他文件描述符（如套接字或命名管道）正在使用中。如果这些高数字不是由于错误或糟糕的设计，那么是时候添加一个新的服务器了。
- en: 'Checking the number of open file descriptors of any kind can be accomplished
    using `lsof`:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`lsof`来检查任何类型的打开文件描述符的数量：
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Data creep
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据蔓延
- en: When the amount of data being managed by a single database server begins to
    exceed many millions of rows or many gigabytes of memory, it is time to think
    about scaling. Here, you might choose to simply dedicate a single server to your
    database, begin to share databases, or even move into a managed cloud storage
    solution earlier rather than later. Recovering from a data layer failure is rarely
    a quick fix, and in general, it is dangerous to have a single point of failure
    for something as important as *all of your data*.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当单个数据库服务器管理的数据量开始超过数百万行或数千兆字节的内存时，就是考虑扩展的时候了。在这里，您可以选择简单地将单个服务器专用于您的数据库，开始共享数据库，甚至在早期而不是晚期转移到托管的云存储解决方案。从数据层故障中恢复很少是一个快速的修复，一般来说，对于像*所有您的数据*这样重要的事情，有一个单一的故障点是危险的。
- en: 'If you''re using Redis, the `info` command will provide most of the data you
    will need, to make these decisions. Consider the following example:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在使用Redis，`info`命令将提供大部分您需要的数据，以做出这些决定。考虑以下示例：
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'More information on `INFO` can be found at: [https://redis.io/commands/INFO](https://redis.io/commands/INFO).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 有关`INFO`的更多信息，请参阅：[https://redis.io/commands/INFO](https://redis.io/commands/INFO)。
- en: 'For MongoDB, you might use the `db.stats()` command:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于MongoDB，您可以使用`db.stats()`命令：
- en: '[PRE8]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Passing the argument `1024` flags `stats` to display all values in kilobytes.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 传递参数`1024`标记`stats`以以千字节显示所有值。
- en: 'More information can be found at: [https://docs.mongodb.com/v3.4/reference/method/db.stats/](https://docs.mongodb.com/v3.4/reference/method/db.stats/)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 更多信息请参阅：[https://docs.mongodb.com/v3.4/reference/method/db.stats/](https://docs.mongodb.com/v3.4/reference/method/db.stats/)
- en: Tools for monitoring servers
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务器监控工具
- en: There are several tools available for monitoring servers, but few designed specifically
    for Node. One strong candidate is **N|Solid** ([https://nodesource.com/products/nsolid](https://nodesource.com/products/nsolid)),
    a company staffed by many key contributors to Node's core. This cloud service
    is easily integrated with a Node app, offering a useful dashboard visualizing
    CPU usage, average response times, and more.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种可用于监控服务器的工具，但很少有专门为Node设计的。一个强有力的候选者是**N|Solid** ([https://nodesource.com/products/nsolid](https://nodesource.com/products/nsolid))，这是一个由许多Node核心的关键贡献者组成的公司。这个云服务很容易与Node应用集成，提供一个有用的仪表板，可视化CPU使用情况、平均响应时间等。
- en: 'Other good monitoring tools to consider are listed in the following:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 其他值得考虑的监控工具列在以下：
- en: '**Nagios**: [https://www.nagios.org](https://www.nagios.org)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Nagios**: [https://www.nagios.org](https://www.nagios.org)'
- en: '**Munin**: [http://munin-monitoring.org/](http://munin-monitoring.org/)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Munin**: [http://munin-monitoring.org/](http://munin-monitoring.org/)'
- en: '**Monit**: [https://mmonit.com/](https://mmonit.com/)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Monit**: [https://mmonit.com/](https://mmonit.com/)'
- en: '**NewRelic**: [https://newrelic.com/nodejs](https://newrelic.com/nodejs)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Keymetrics**: [https://keymetrics.io/](https://keymetrics.io/)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running multiple Node servers
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is easy to purchase several servers and then to run some Node processes on
    them. However, how can those distinct servers be coordinated such that they form
    part of a single application? One aspect of this problem concerns clustering multiple
    identical servers around a single entry point. How can client connections be shared
    across a pool of servers?
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '**Horizontal scaling** is the process of splitting up your architecture into
    network-distinct nodes and coordinating them. *Cloud computing* relates here,
    and simply means locating some of the functionality an application running on
    a server somewhere on a remote server, running somewhere else. Without a single
    point of failure (so the theory goes) the general system is more robust. The *parking
    lot problem* is another consideration that Walmart likely faces—during shopping
    holidays, you will need many thousands of parking spots, but during the rest of
    the year, this investment in empty space is hard to justify. In terms of servers,
    the ability to dynamically scale both up and down argues against building fixed
    vertical silos. Adding hardware to a running server is also a more complicated
    process than spinning up and seamlessly linking another virtual machine to your
    application.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: File serving speeds are, of course, not the only reason you might use a proxy
    server like NGINX. It is often true that network topology characteristics make
    a reverse proxy the better choice, especially when the centralization of common
    services, such as compression, makes sense. The point is simply that Node should
    not be excluded solely due to outdated biases about its ability to efficiently
    serve files.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Forward and reverse proxies
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **proxy** is someone or something acting on behalf of another.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: A **forward proxy** normally works on behalf of clients in a private network,
    brokering requests to an outside network, such as retrieving data from the internet.
    Earlier in this book, we looked at how one might set up a proxy server using Node,
    where the Node server functioned as an intermediary, forwarding requests from
    clients to other network servers, usually via the internet.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: 'Early web providers such as AOL functioned in the following way:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fc316c7a-de5c-4f91-a7ea-6f9c909a5543.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
- en: Network administrators use forward proxies when they must restrict access to
    the outside world, that is, the internet. If network users are downloading malware
    from `somebadwebsite.com` via an email attachment, the administrator can block
    access to that location. Restrictions on access to social networking sites might
    be imposed on an office network. Some countries even restrict access to public
    websites in this way.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: 'A **reverse proxy**, not surprisingly, works in the opposite way, accepting
    requests from a public network and servicing those requests within a private network
    the client has little much visibility into. Direct access to servers by clients
    is first delegated to a reverse proxy:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e27712db-31b9-4716-ad25-1e40a6ae8e44.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
- en: This is the type of proxy we might use to balance requests from clients across
    many Node servers. Client *X* does not communicate with any given server directly.
    A broker *Y* is the point of first contact, able to direct *X* to a server that
    is under less load, or that is located closer to *X*, or is in some other way
    the best server for *X* to access at this time.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: We will now take a look at how to implement reverse proxies when scaling Node,
    discussing implementations that use **NGINX** (pronounced as **Engine X**), a
    popular choice when load balancing Node servers, and those using native Node modules.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Using the http-proxy module
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For many years, it was recommended that a web server (such as NGINX) be placed
    in front of Node servers. The claim was that mature web servers handle static
    file transfers more efficiently. While this may have been true for earlier Node
    versions (which also suffered from the bugs that new technologies face), it is
    no longer necessarily true in terms of pure speed. More importantly, using **Content
    Delivery Networks** (**CDN**) and other *edge* services the static files your
    application might need will already be cached—your server won't be serving these
    files, to begin with.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，人们建议在Node服务器前面放置一个Web服务器（如NGINX）。理由是成熟的Web服务器能更有效地处理静态文件传输。虽然这对于早期的Node版本可能是真的（这些版本也受到新技术面临的错误的影响），但从纯速度来说，这不一定再是真的。更重要的是，使用内容交付网络（CDN）和其他边缘服务，你的应用程序可能需要的静态文件已经被缓存了，你的服务器本来就不会提供这些文件。
- en: Node is designed to facilitate the creation of network software, so it comes
    as no surprise that several proxying modules have been developed. A popular production-grade
    Node proxy is **http-proxy**. Let's take a look at how we would use it to balance
    requests to different Node servers.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Node旨在促进网络软件的创建，因此并不奇怪会开发出几个代理模块。一个受欢迎的生产级Node代理是http-proxy。让我们看看如何使用它来平衡对不同Node服务器的请求。
- en: 'The entirety of our routing stack will be provided by Node. One Node server
    will be running our proxy, listening on port `80`. We''ll cover the following
    three scenarios:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的整个路由堆栈将由Node提供。一个Node服务器将运行我们的代理，监听端口`80`。我们将涵盖以下三种情况：
- en: Running multiple Node servers on separate ports on the same machine
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在同一台机器上运行多个不同端口的Node服务器
- en: Using one box as a pure router, proxying to external URLs
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用一个盒子作为纯路由器，代理到外部URL
- en: Creating a basic round-robin load balancer
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个基本的轮询负载均衡器
- en: 'As an initial example, let''s look at how to use this module to redirect requests:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个初始示例，让我们看看如何使用这个模块来重定向请求：
- en: '[PRE9]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: By starting this server on port `80` of our local machine, we are able redirect the
    user to another URL.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在本地机器的端口`80`上启动此服务器，我们能够将用户重定向到另一个URL。
- en: 'To run several distinct Node servers, each responding to a different URL, on
    a single machine, one simply has to define a router:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 要在单台机器上运行几个不同的Node服务器，每个服务器响应不同的URL，只需定义一个路由器：
- en: '[PRE10]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: For each of your distinct websites, you can now point your DNS name servers
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 对于你的不同网站，现在可以指向你的DNS名称服务器
- en: '(via ANAME or CNAME records) to the same endpoint (wherever this Node program
    is running), and they will resolve to different Node servers. This is handy when
    you want to run several websites but don''t want to create a new physical server
    for each one. Another strategy is to handle different paths within the same website
    on different Node servers:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: （通过ANAME或CNAME记录）到相同的端点（无论这个Node程序在哪里运行），它们将解析到不同的Node服务器。当你想运行几个网站但不想为每个网站创建一个新的物理服务器时，这很方便。另一种策略是在同一个网站中处理不同路径在不同的Node服务器上：
- en: '[PRE11]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This allows specialized functionality in your application to be handled by uniquely
    configured servers.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这允许你的应用程序中的专门功能由独特配置的服务器处理。
- en: 'Setting up a load balancer is also straightforward. As we''ll see later with
    NGINX''s **upstream** directive, we simply provide a list of servers to be balanced:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 设置负载均衡器也很简单。正如我们稍后将在NGINX的upstream指令中看到的那样，我们只需提供要平衡的服务器列表：
- en: '[PRE12]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In this example, we treat servers equally, cycling through them in order. After
    the selected server is proxied, it is returned to the *rear* of the list.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们平等对待服务器，按顺序循环使用它们。选择的服务器被代理后，它将返回到列表的末尾。
- en: It should be clear that this example can be easily extended to accommodate other
    directives, such as NGINX's **weight**.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，这个例子可以很容易地扩展到适应其他指令，比如NGINX的weight。
- en: 'The `redbird` module is an extremely advanced reverse proxy built on top of **http-proxy**.
    Among other things, it has built-in support for automatic SSL certificate generation
    and HTTP/2 support. Learn more at: [https://github.com/OptimalBits/redbird](https://github.com/OptimalBits/redbird).'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: redbird模块是建立在http-proxy之上的一个非常先进的反向代理。除其他功能外，它还内置了自动SSL证书生成和HTTP/2支持。了解更多信息：[https://github.com/OptimalBits/redbird](https://github.com/OptimalBits/redbird)。
- en: Deploying a NGINX load balancer on Digital Ocean
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Digital Ocean上部署NGINX负载均衡器
- en: As Node is so efficient, most websites or applications can accommodate all of
    their scaling needs in the vertical dimension. Node can handle enormous levels
    of traffic using only a few CPUs and an unexceptional volume of memory.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Node非常高效，大多数网站或应用程序可以在垂直维度上满足其所有扩展需求。Node可以使用少量CPU和普通内存处理大量流量。
- en: 'NGINX is a very popular high-performance web server that is often used as a
    proxy server. There is some serendipity in the fact that NGINX is a popular choice with Node
    developers, given its design:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: NGINX是一个非常受欢迎的高性能Web服务器，通常用作代理服务器。NGINX与Node开发人员的设计非常相似，这是一种巧合：
- en: As mentioned on [http://www.linuxjournal.com/magazine/nginx-high-performance-web-server-and-reverse-proxy](http://www.linuxjournal.com/magazine/nginx-high-performance-web-server-and-reverse-proxy),
    "NGINX is able to serve more requests per second with [fewer] resources because
    of its architecture. It consists of a master process, which delegates work to
    one or more worker processes. Each worker handles multiple requests in an event-driven
    or asynchronous manner using special functionality from the Linux kernel (epoll/select/poll).
    This allows NGINX to handle a large number of concurrent requests quickly with
    very little overhead."
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如[http://www.linuxjournal.com/magazine/nginx-high-performance-web-server-and-reverse-proxy](http://www.linuxjournal.com/magazine/nginx-high-performance-web-server-and-reverse-proxy)所述，“NGINX能够以更少的资源处理更多的请求，因为它的架构。它由一个主进程组成，将工作委托给一个或多个工作进程。每个工作进程使用Linux内核的特殊功能（epoll/select/poll）以事件驱动或异步方式处理多个请求。这使得NGINX能够快速处理大量并发请求，几乎没有额外开销。”
- en: NGINX also makes load balancing very easy. In the following examples, we will
    see how proxying through NGINX comes with load balancing *out of the box.*
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Digital Ocean is a cloud hosting provider that is inexpensive and easy to set
    up. We will build an NGINX load balancer on this service.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: 'To sign up, visit: [https://www.digitalocean.com](https://www.digitalocean.com).
    The basic package (at the time of this writing) incurs a five dollar fee, but
    promotion codes are regularly made available; a simple web search should result
    in a usable code. Create and verify an account to get started.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Digital Ocean packages are described as droplets, with certain characteristics—amount
    of storage space, transfer limits, and so on. A basic package is sufficient for
    our needs. Also, you will indicate a hosting region as well as the OS to install
    in your droplet (in this example, we’ll use the latest version of Ubuntu). Create
    a droplet, and check your email for login instructions. You’re done!
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: You will receive full login information for your instance. You can now open
    a Terminal and SSH into your box using those login credentials.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: On your initial login, you might want to update your packages. For Ubuntu, you
    would run `apt-get update` and `apt-get upgrade`. Other package managers have
    similar commands (such as `yum update` for RHEL/CentOs).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Before we begin to install, let’s change our root password and create a non-root
    user (it is unsafe to expose root to external logins and software installs). To
    change your root password, type `passwd` and follow the instructions in your Terminal.
    To create a new user, enter `adduser <new user name>` (for example, `adduser john`).
    Follow the instructions.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'One more step: we want to give some administrative privileges to our new user,
    as we’ll be installing software as that user. In Unix parlance, you want to give
    `sudo` access to this new user. Instructions on how to do this are easy to find
    for whichever OS you’ve chosen. Essentially, you will want to change the `/etc/sudoers`
    file. Remember to do this using a command such as `lvisudo`; do not edit the sudoers
    file by hand! You may also want to restrict root logins and do other SSH access
    management at this point.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: After successfully executing ` sudo -i` in your Terminal, you will be able to
    enter commands without prefixing each one with `sudo`. The following examples
    assume that you’ve done this.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll now create a NGINX load balancer frontend for two Node servers. This
    means we will create three droplets: one for the balancer, and an additional two
    droplets to serve as Node servers. At the end, we will end up with an architecture
    that looks something like this:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a7b32bd5-9ec9-49f2-92b2-3ebc005f8a39.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
- en: Installing and configuring NGINX
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s install NGINX and Node/npm. If you''re still logged in as root, log out
    and reauthenticate as the new user you’ve just created. To install NGINX (on Ubuntu),
    simply type this:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Most other Unix package managers will have NGINX installers.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: 'To start NGINX, use this:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Full documentation for NGINX can be found at: [https://www.nginx.com/resources/wiki/start/](https://www.nginx.com/resources/wiki/start/).'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 'You should now be able to point your browser to the IP you were assigned (check
    your inbox if you''ve forgotten) and see something like this:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0c104d17-f129-4b82-8901-142c313ab105.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
- en: Now, let's set up the two servers that NGINX will balance.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: 'Create an additional two droplets in Digital Ocean. You will *not* install
    NGINX on these severs. Configure permissions on these servers as we did earlier,
    and install Node in both droplets. An easy way to manage your Node installation
    is using *Tim Caswell''s* **NVM** (Node Version Manager). NVM is essentially a
    bash script that provides a set of command-line tools facilitating Node version
    management, allowing you to easily switch between versions. To install it, run
    the following command in your Terminal:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now, install your preferred Node version:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You might want to add a command to your `.bashrc` or `.profile` file to ensure
    that a certain node version is used each time you start a shell:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能希望在`.bashrc`或`.profile`文件中添加一个命令，以确保每次启动shell时都使用某个特定的node版本：
- en: '[PRE17]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'To test our system, we need to set up Node servers on both of these machines.
    Create the following program file on each server, changing `**` to something unique
    on each (such as *one* and *two*):'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试我们的系统，我们需要在这两台机器上设置Node服务器。在每台服务器上创建以下程序文件，将`**`更改为每个服务器上的唯一内容（例如*one*和*two*）：
- en: '[PRE18]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Start this file on each server (`node serverfile.js`). Each server will now
    answer on port `8080`. You should now be able to reach this server by pointing
    a browser to each droplet’s IP:8080\. Once you have two servers responding with
    distinct messages, we can set up the NGINX load balancer.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在每台服务器上启动此文件（`node serverfile.js`）。每台服务器现在将在端口`8080`上回答。您现在应该能够通过将浏览器指向每个Droplet的IP:8080\来访问此服务器。一旦有两台服务器响应不同的消息，我们就可以设置NGINX负载均衡器。
- en: 'Load balancing across servers is straightforward with NGINX. You need simply
    indicate, in the NGINX configuration script, which upstream servers should be
    balanced. The two Node servers we''ve just created will be the upstream servers.
    NGINX will be configured to balance requests to each:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 使用NGINX进行服务器之间的负载均衡非常简单。您只需在NGINX配置脚本中指示应该平衡的上游服务器。我们刚刚创建的两个Node服务器将成为上游服务器。NGINX将被配置为平衡对每个请求：
- en: '![](img/59ceb3dd-08f4-42e3-9c88-19ae3e47824c.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](img/59ceb3dd-08f4-42e3-9c88-19ae3e47824c.png)'
- en: Each request will be handled first by NGINX, which will check its *upstream*
    configuration, and based on how it is configured, will (reverse) proxy requests
    to upstream servers that will actually handle the request.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 每个请求将首先由NGINX处理，NGINX将检查其*上游*配置，并根据其配置方式，将请求（反向）代理到实际处理请求的上游服务器。
- en: You will find the default NGINX server configuration file on your balancer droplet
    at `/etc/nginx/sites-available/default`.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在负载均衡器Droplet上的`/etc/nginx/sites-available/default`找到默认的NGINX服务器配置文件。
- en: In production, you'll likely want to create a custom directory and configuration
    file, but for our purposes, we'll simply modify the default configuration file
    (you might want to make a backup before you start modifying it).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产中，您可能希望创建一个自定义目录和配置文件，但出于我们的目的，我们将简单地修改默认配置文件（在开始修改之前，您可能需要备份）。
- en: 'At the top of the NGINX configuration file, we want to define some *upstream*
    servers that will be candidates for redirection. This is simply a map with the
    `lb-servers` arbitrary key, to be referenced in the server definition that follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在NGINX配置文件的顶部，我们希望定义一些*上游*服务器，这些服务器将成为重定向的候选者。这只是一个带有`lb-servers`任意键的映射，将在随后的服务器定义中引用：
- en: '[PRE19]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now that we''ve established the candidate map, we need to configure NGINX such
    that it will forward requests in a balanced way to each of the members of lb-servers:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经建立了候选映射，我们需要配置NGINX，以便它以平衡的方式将请求转发到lb-servers的每个成员：
- en: '[PRE20]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The key line is this one:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 关键一行是这一行：
- en: '[PRE21]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Note how the name `lb-servers` matches the name of our upstream definition.
    This should make what is happening clear: an NGINX server listening on port `80`
    will pass the request on to a server definition as contained in lb-servers. If
    the upstream definition has only one server in it, that server gets all the traffic.
    If several servers are defined, NGINX attempts to distribute traffic evenly among
    them.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意名称`lb-servers`与我们上游定义的名称匹配。这应该清楚地说明正在发生的事情：监听端口`80`的NGINX服务器将将请求传递给包含在lb-servers中的服务器定义。如果上游定义中只有一个服务器，则该服务器将获得所有流量。如果定义了多个服务器，NGINX将尝试在它们之间均匀分配流量。
- en: It is also possible to balance load across several *local servers* using the
    same technique. One would simple run different Node servers on different ports,
    such as `server 127.0.0.1:8001` and `server 127.0.0.1:8002`.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以使用相同的技术在几个*本地服务器*之间平衡负载。可以在不同的端口上运行不同的Node服务器，例如`server 127.0.0.1:8001`和`server
    127.0.0.1:8002`。
- en: 'Go ahead and change the NGINX configuration (consulting the `nginx.config`
    file in the code bundle for this book if you get stuck). Once you''ve changed
    it, restart NGINX with the following command:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 继续更改NGINX配置（如果遇到困难，请查阅本书代码包中的`nginx.config`文件）。更改后，使用以下命令重新启动NGINX：
- en: '[PRE22]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Alternatively, if you prefer, use this:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果您愿意，可以使用此方法：
- en: '[PRE23]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Assuming that the other two droplets running Node servers are active, you should
    now be able to point your browser to your NGINX-enabled droplet and see messages
    from those servers!
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 假设另外两个运行Node服务器的Droplet处于活动状态，您现在应该能够将浏览器指向启用了NGINX的Droplet，并查看来自这些服务器的消息！
- en: As we will likely want more precise control over how traffic is distributed
    across our upstream servers, there are further directives that can be applied
    to upstream server definitions.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们可能希望更精确地控制流量如何分布到上游服务器，因此有进一步的指令可以应用于上游服务器定义。
- en: 'NGINX balances load using a weighted round-robin algorithm. In order to control
    the relative weighting of traffic distribution, we use the weight directive:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: NGINX使用加权轮询算法进行负载平衡。为了控制流量分布的相对权重，我们使用权重指令：
- en: '[PRE24]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This definition tells NGINX to distribute twice as much load to the second server
    as to the first. Servers with more memory or CPUs might be favored, for example.
    Another way to use this system is to create an A/B testing scenario, where one
    server containing a proposed new design receives some small fraction of total
    traffic, such that metrics on the testing server (sales, downloads, engagement
    length, and so forth) can be compared against the wider average.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 该定义告诉NGINX将负载分配给第二个服务器的量是第一个服务器的两倍。例如，具有更多内存或CPU的服务器可能会受到青睐。使用此系统的另一种方法是创建A/B测试场景，其中包含建议的新设计的一个服务器接收总流量的一小部分，以便可以将测试服务器的指标（销售额、下载量、参与时长等）与更广泛的平均值进行比较。
- en: 'Three other useful directives are available, which work together to manage
    connection failures:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他三个有用的指令，它们一起工作以管理连接故障：
- en: '`max_fails`: The number of times communication with a server fails prior to
    marking that server as inoperative. The period of time within which these failures
    must occur is defined by `fail_timeout`.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_fails`：与服务器通信失败多少次之前将该服务器标记为无法运行。这些失败必须发生的时间段由`fail_timeout`定义。'
- en: '`fail_timeout`: The time slice during which `max_fails` must occur, indicating
    that a server is inoperative. This number also indicates the amount of time after
    a server is marked inoperative that NGINX will again attempt to reach the flagged
    server.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fail_timeout`：服务器无法运行时必须发生`max_fails`的时间片。这个数字还表示在标记服务器无法运行后，NGINX再次尝试到达被标记的服务器之前的时间。'
- en: 'Consider this example:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下例子：
- en: '[PRE25]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '`backup`: A server marked with this directive will only be called when and
    if *all* the other listed servers are unavailable.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`backup`：带有这个指令的服务器只有在*所有*其他列出的服务器不可用时才会被调用。'
- en: 'Additionally, there are some directives for the upstream definition that add
    some control over how clients are directed to upstream servers:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，有一些用于上游定义的指令，可以对客户端如何被引导到上游服务器进行一些控制：
- en: '`least_conn`: Pass a request to the server with the least connections. This
    provides a slightly smarter balancing, taking into consideration server load as
    well as weighting.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`least_conn`：将请求传递给连接最少的服务器。这提供了稍微更智能的负载均衡，考虑了服务器负载以及权重。'
- en: '`ip_hash`: The idea here is to create a hash of each connecting IP, and to
    ensure that requests from a given client are always passed to the same server.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ip_hash`：这里的想法是为每个连接的IP创建一个哈希，并确保来自给定客户端的请求始终传递到同一台服务器。'
- en: 'Another commonly used tool for balancing Node servers is the dedicated load
    balancer HAProxy, available at: [http://www.haproxy.org](http://www.haproxy.org).'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 用于平衡Node服务器的另一个常用工具是专用负载均衡器HAProxy，网址为：[http://www.haproxy.org](http://www.haproxy.org)。
- en: Message queues – RabbitMQ
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消息队列-RabbitMQ
- en: One of the best ways to ensure that distributed servers maintain a dependable
    communication channel is to bundle the complexity of remote procedure calls into
    a distinct unit-a messaging queue. When one process wishes to send a message to
    another process, the message can simply be placed on this queue-like a to-do list
    for your application, with the queue service doing the work of ensuring that messages
    get delivered as well as delivering any important replies back to the original
    sender.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 确保分布式服务器保持可靠的通信渠道的最佳方法之一是将远程过程调用的复杂性捆绑到一个独立的单元中-一个消息队列。当一个进程希望向另一个进程发送消息时，消息可以简单地放在这个队列上-就像应用程序的待办事项列表一样，队列服务负责确保消息被传递以及将任何重要的回复传递回原始发送者。
- en: There are a few enterprise-grade message queues available, many of them deploying
    **AMQP** **(Advanced Message Queueing Protocol)**. We will focus on a very stable
    and well-known implementation—RabbitMQ.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些企业级消息队列可用，其中许多部署了**AMQP** **(高级消息队列协议)**。我们将专注于一个非常稳定和知名的实现-RabbitMQ。
- en: 'To install RabbitMQ in your environment, follow the instructions found at:
    [https://www.rabbitmq.com/download.html](https://www.rabbitmq.com/download.html).'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 要在您的环境中安装RabbitMQ，请按照以下网址找到的说明进行操作：[https://www.rabbitmq.com/download.html](https://www.rabbitmq.com/download.html)。
- en: 'Once installed, you will start the RabbitMQ server with this command:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，您可以使用以下命令启动RabbitMQ服务器：
- en: '[PRE26]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'To interact with RabbitMQ using Node, we will use the `node-amqp` module created
    by *Theo Schlossnagle*:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Node与RabbitMQ进行交互，我们将使用*Theo Schlossnagle*创建的`node-amqp`模块：
- en: '[PRE27]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'To use a message queue, one must first create a consumer—a binding to RabbitMQ
    that will listen for messages published to the queue. The most basic consumer
    will listen for all messages:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用消息队列，必须首先创建一个消费者-一个绑定到RabbitMQ的监听发布到队列的消息。最基本的消费者将监听所有消息：
- en: '[PRE28]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We are now listening for messages from the RabbitMQ server bound to port `5672`.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在正在监听来自绑定到端口`5672`的RabbitMQ服务器的消息。
- en: Once this consumer establishes a connection, it will establish the name of the
    queue it will listen to, and should `bind` to an `exchange`. In this example,
    we create a topic `exchange` (the default), giving it a unique name. We also indicate
    that we would like to listen for *all* messages via `#`. All that is left to do
    is subscribe to the queue, receiving a message object. We will learn more about
    the message object as we progress. For now, note the important `data` property,
    containing sent messages.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦这个消费者建立了连接，它将建立它将要监听的队列的名称，并且应该`绑定`到一个`交换机`。在这个例子中，我们创建了一个主题`交换机`（默认），给它一个唯一的名称。我们还指示我们想要通过`#`监听*所有*消息。剩下要做的就是订阅队列，接收一个消息对象。随着我们的进展，我们会了解更多关于消息对象的信息。现在，注意重要的`data`属性，其中包含发送的消息。
- en: 'Now that we have established a consumer, let''s publish a message to the exchange.
    If all goes well, we will see the sent message appear in our console:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经建立了一个消费者，让我们向交换机发布一条消息。如果一切顺利，我们将在控制台中看到发送的消息：
- en: '[PRE29]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We have already learned enough to implement useful scaling tools. If we have
    a number of distributed Node processes, even on different physical servers, each
    can reliably send messages to one another via RabbitMQ. Each process simply needs
    to implement an **exchange queue subscriber** to receive messages, and an **exchange
    publisher** to send messages.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经学到足够的知识来实现有用的扩展工具。如果我们有多个分布式的Node进程，甚至在不同的物理服务器上，每个进程都可以通过RabbitMQ可靠地向彼此发送消息。每个进程只需要实现一个**交换队列订阅者**来接收消息，以及一个**交换发布者**来发送消息。
- en: Types of exchanges
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交换机的类型
- en: 'RabbitMQ provides three types of exchanges: **direct**, **fanout**, and **topic**.
    The differences appear in the way each type of exchange processes **routing keys**—the
    first argument sent to `exchange.publish`.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ提供三种类型的交换机：**直连**，**扇出**和**主题**。这些差异体现在每种类型的交换机如何处理**路由键**-发送到`exchange.publish`的第一个参数。
- en: 'A direct exchange matches routing keys directly. A queue binding like the following
    one matches *only* messages sent to `''room-1''`:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 直连交换机直接匹配路由键。像下面这样的队列绑定*只*匹配发送到`'room-1'`的消息：
- en: '[PRE30]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: As no parsing is necessary, direct exchanges are able to process more messages
    than topic exchanges in a set period of time.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: A fanout exchange is indiscriminate; it routes messages to all the queues bound
    to it, ignoring routing keys. This type of exchange is used for wide broadcasts.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: A topic exchange matches routing keys based on the wildcards `#` and `*`. Unlike
    other types, routing keys for topic exchanges *must* be composed of words separated
    by dots, `"animals.dogs.poodle"`, for example. A `#` matches zero or more words;
    it will match every message (as we saw in the previous example), just like a fanout
    exchange. The other wildcard is *, and this matches *exactly* one word.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Direct and fanout exchanges can be implemented using nearly the same code as
    the given topic exchange example, requiring only that the exchange type be changed,
    and bind operations be aware of how they will be associated with routing keys
    (fanout subscribers receive all messages, regardless of the key; for direct, the
    routing key must match directly).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: 'This last example should drive home how topic exchanges work. We will create
    three queues with different matching rules, filtering the messages each queue
    receives from the exchange:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The `node-amqp` module contains further methods for controlling connections,
    queues, and exchanges; in particular, it contains methods for removing queues
    from exchanges, and subscribers from queues. Generally, changing the makeup of
    a running queue on the fly can lead to unexpected errors, so use these with caution.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: 'To learn more about the AMQP (and the options available when setting up with
    `node-amqp`), visit: [http://www.rabbitmq.com/tutorials/amqp-concepts.html](http://www.rabbitmq.com/tutorials/amqp-concepts.html).'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: Using Node's UDP module
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**UDP** **(User Datagram Protocol)** is a lightweight core internet messaging
    protocol, enabling servers to pass around concise **datagrams**. UDP was designed
    with a minimum of protocol overhead, forgoing delivery, ordering, and duplication
    prevention mechanisms in favor of ensuring high performance. UDP is a good choice
    when perfect reliability is not required and high-speed transmission is, such
    as what is found in networked video games and videoconferencing applications.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: This is not to say that UDP is normally unreliable. In most applications, it
    delivers messages with high probability. It is simply not suitable when *perfect*
    reliability is needed, such as in a banking application. It is an excellent candidate
    for monitoring and logging applications, and for non-critical messaging services.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating a UDP server with Node is straightforward:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The `bind` command takes three arguments, which are as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '**port**: The `Integer` port number.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**address**: This is an optional address. If this is not specified, the OS
    will try to listen on all addresses (which is often what you want). You might
    also try using `0.0.0.0` explicitly.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**callback**: This is an optional callback, which receives no arguments.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This socket will now emit a `message` event whenever it receives a datagram
    via the `41234` port. The event callback receives the message itself as a first
    parameter, and a map of packet information as the second:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '**address**: The originating IP'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**family**: One of IPv4 or IPv6'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**port**: The originating port'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**size**: The size of the message in bytes'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This map is similar to the map returned when calling `socket.address()`.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the message and listening events, a UDP socket also emits a **close**
    and **error** event, the latter receiving an `Error` object whenever an error
    occurs. To close a UDP socket (and trigger the close event), use `server.close()`.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: 'Sending a message is even easier:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The `send` method takes the `client.send(buffer, offset, length, port, host,
    callback)` form:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '`buffer`: A Buffer containing the datagram to be sent.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`offset`: An Integer indicating the position in buffer where the datagram begins.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`length`: The number of bytes in a datagram. In combination with **offset**,
    this value identifies the full datagram within buffer.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`port`: An Integer identifying the destination port.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`address`: A String indicating the destination IP for the datagram.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback`: An optional callback function, called after the send has taken
    place.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The size of a datagram cannot exceed 65507 bytes, which is equal to *2^16-1*
    (65535) bytes, minus the 8 bytes used by the UDP header minus the 20 bytes used
    by the IP header.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: We now have another candidate for inter-process messaging. It will be rather
    easy to set up a monitoring server for our node application, listening on a UDP
    socket for program updates and stats sent from other processes. The protocol speed
    is fast enough for real-time systems, and any packet loss or other UDP hiccups
    will be insignificant taken as a percentage of total volume over time.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: 'Taking the idea of broadcasting further, we can also use the `dgram` module
    to create a multicast server. A **multicast** is simply a one-to-many server broadcast.
    We can broadcast to a range of IPs that have been permanently reserved as multicast
    addresses:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: As can be found on [http://www.iana.org/assignments/multicast-addresses/multicast-addresses.xhtml](http://www.iana.org/assignments/multicast-addresses/multicast-addresses.xhtml),
    "Host Extensions for IP Multicasting [RFC1112] specifies the extensions required
    of a host implementation of the Internet Protocol (IP) to support multicasting.
    The multicast addresses are in the range 224.0.0.0 through 239.255.255.255."
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, the range between `224.0.0.0` and `224.0.0.255` is further reserved
    for special routing protocols. Also, certain port numbers are allocated for use
    by UDP (and TCP), a list of which can be found at: [https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers](https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers).'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: The upshot of all this fascinating information is the knowledge that there is
    a block of IPs and ports reserved for UDP and/or multicasting, and we will use
    some of them to implement multicasting over UDP with Node.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: UDP multicasting with Node
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The only difference between setting up a multicasting UDP server and a *standard*
    one is binding to a special UDP port for sending, and indicating that we''d like
    to listen to *all* available network adapters. Our multicasting server initialization
    looks like the following code snippet:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Once we've decided on a multicast port and an address and have bound, we catch
    the `listenng` event and configure our server. The most important command is `socket.addMembership`,
    which tells the kernel to join the multicast group at `multicastAddress`. Other
    UDP sockets can now subscribe to the multicast group at this address.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: Datagrams hop through networks just like any network packet. The `setMulticastTTL`
    method is used to set the maximum number of hops (Time To Live) a datagram is
    allowed to make before it is abandoned, and not delivered. The acceptable range
    is 0-255, with the default being one (1) on most systems. This is not normally
    a setting one needs to worry about, but it is available when precise limits make
    sense, such as when packets are cheap and hops are costly.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: If you'd like to also allow listening on the local interface, use `socket.setBroadcast(true)`
    and `socket.setMulticastLoopback(true)`. This is normally not necessary.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: 'We will eventually use this server to broadcast messages to all UDP listeners
    on `multicastAddress`. For now, let''s create two clients that will listen for
    multicasts:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We now have two clients listening to the same multicast port. All that is left
    to do is the multicasting. In this example, we will use `setTimeout` to send a
    counter value every second:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The counter values will produce something like the following:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We have two clients listening to broadcasts from a specific group. Let''s add
    another client, listening on a different group, let''s say at multicast address
    `230.3.2.1`:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'As our server currently broadcasts messages to a different address, we will
    need to change our server configuration and add this new address with another
    `addMembership` call:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We can now send to *both* addresses:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Nothing stops the client from broadcasting to others in the group, or even
    members of another group:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Any node process that has an address on our network interface can now listen
    on a UDP multicast address for messages, providing a fast and elegant inter-process
    communication system.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: Using Amazon Web Services in your application
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As a few thousand users become a few million users, as databases scale to terabytes
    of data, the cost and complexity of maintaining an application begins to overwhelm
    teams with insufficient experience, funding, and/or time. When faced with rapid
    growth, it is sometimes useful to delegate responsibilities for one or more aspects
    of your application to cloud-based service providers. **AWS****(Amazon Web Services)**
    is just such a suite of cloud-computing services, offered by [amazon.com](http://amazon.com).
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: You will need an AWS account in order to use these examples. All the services
    we will explore are free or nearly free for low-volume development uses. To create
    an account on AWS, visit the following link: [https://aws.amazon.com/](https://aws.amazon.com/).
    Once you have created an account, you will be able to manage all of your services
    via the AWS console: [https://aws.amazon.com/console/](https://aws.amazon.com/console/)
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section we will learn how to use three popular AWS services:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: For storing documents and files we will connect with Amazon **S3**
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**(Simple Storage Service)**'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: Amazon's Key/Value database, **DynamoDB**
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To manage a large volume of e-mail, we will leverage Amazon's **SES**
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**(Simple Email Service)**'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: To access these services we will use the AWS SDK for Node, which can be found
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: at the following link: [https://github.com/aws/aws-sdk-js](https://github.com/aws/aws-sdk-js)
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: 'To install the module run the following command:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Full documentation for the `aws-sdk` module can be found at: [https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/index.html](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/index.html).'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: Authenticating
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Developers registered with AWS are assigned two identifiers:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: A public **Access Key ID** (a 20-character, alphanumeric sequence).
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **Secret Access Key** (a 40-character sequence). It is very important to keep
    your Secret Key private.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon also provides developers with the ability to identify the region with
    which to communicate, such as `"us-east-1"`. This allows developers to target
    the closest servers (regional endpoint) for their requests.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: The regional endpoint and both authentication keys are necessary to make requests.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: 'For a breakdown of regional endpoints, visit: [https://docs.aws.amazon.com/general/latest/gr/rande.html](https://docs.aws.amazon.com/general/latest/gr/rande.html).'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: 'As we will be using the same credentials in each of the following examples,
    let''s create a single `config.json` file that is reused:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We also configure the specific API versions we will use for services. Should
    Amazon's services API change, this will ensure that our code will continue to
    work.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: 'An AWS session can now be initialized with just two lines of code. Assume that
    these two lines exist prior to any of the example code that follows:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Errors
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When experimenting with these services, it is likely that error codes will
    appear on occasion. Due to their complexity, and the nature of cloud computing,
    these services can sometimes emit surprising or unexpected errors. For example,
    because S3 can only promise eventual consistency in some regions and situations,
    attempting to read a key that has just been written to may not always succeed.
    We will be exploring the complete list of error codes for each service, and they
    can be found at the following locations:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '**S3:**[ https://docs.aws.amazon.com/AmazonS3/latest/API/ErrorResponses.html](https://docs.aws.amazon.com/AmazonS3/latest/API/ErrorResponses.html)'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DynamoDB: **[http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html](http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html)'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SES: **[https://docs.aws.amazon.com/ses/latest/DeveloperGuide/api-error-codes.html](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/api-error-codes.html)
    and [https://docs.aws.amazon.com/ses/latest/DeveloperGuide/smtp-response-codes.html](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/smtp-response-codes.html)'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As it will be difficult in the beginning to predict where errors might arise,
    it is important to employ the `domain` module or other error-checking code as
    you proceed.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, a subtle but fundamental aspect of Amazon''s security and consistency
    model is the strict synchronization of its web server time and time as understood
    by a server making requests. A discrepancy of 15 minutes is the maximum allowed.
    While this seems like a long time, in fact time drift is very common. When developing
    watch out for 403: Forbidden errors that resemble one of the following:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '`SignatureDoesNotMatch`: This error means that the signature has expired'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RequestTimeTooSkewed`: The difference between the request time and the current
    time is too large'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If such errors are encountered, the internal time of the server making requests
    may have drifted. If so, that server''s time will need to be synchronized. On
    Unix, one can use the **NTP****(Network Time Protocol)** to achieve synchrony.
    One solution is to use the following commands:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'For more information on NTP and time synchronization, visit: [http://www.pool.ntp.org/en/use.html](http://www.pool.ntp.org/en/use.html).'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: Let's start using AWS services, beginning with the distributed file service,
    S3.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: Using S3 to store files
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: S3 can be used to store any file one expects to be able to store on a filesystem.
    Most commonly, it is used to store media files such as images and videos. S3 is
    an excellent document storage system as well, especially well-suited for storing
    small JSON objects or similar data objects.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: Also, S3 objects are accessible via HTTP, which makes retrieval very natural,
    and REST methods such as PUT/DELETE/UPDATE are supported. S3 works very much like
    one would expect a typical file server to work, is spread across servers that
    span the globe, and offers storage capacity that is, for all practical purposes,
    limitless.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: S3 uses the concept of a **bucket** as a sort of corollary to *hard drive*.
    Each S3 account can contain 100 buckets (this is a hard limit), with no limits
    on the number of files contained in each bucket.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: Working with buckets
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Creating a bucket is easy:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'We will receive a data map containing the `Location` bucket, and a `RequestId`:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'It is likely that many different operations will be made against a bucket.
    As a convenience, the `aws-sdk` allows a bucket name to be automatically defined
    in the parameter list for all further operations:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Use `listBuckets` to fetch an array of the existing buckets:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Bucket names are global to all S3 users. No single user of S3 can use a bucket
    name that another user has claimed. If I have a bucket named `foo`, no other S3
    user can ever use that bucket name. This is a gotcha that many miss.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: Working with objects
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s add a document to the `nodejs-book` bucket on S3:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'If the PUT is successful, its callback will receive an object similar to the
    following:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'You are encouraged to consult the SDK documentation and experiment with all
    the parameters that `putObject` accepts. Here, we focus on the only two required
    fields, and a few useful and common ones:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: '`Key`: A name to uniquely identify your file within this bucket.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Body`: A Buffer, String, or Stream comprising the file body.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ServerSideEncryption`: Whether to encrypt the file within S3\. The only current
    option is AES256 (which is a good one!).'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ContentType`: Standard MIME type.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ContentLength`: A String indicating the destination IP for the datagram.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ACL`: Canned access permissions, such as `private` or `public-read-write`.
    Consult the S3 documentation.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It is a good idea to have the `Key` object resemble a filesystem path, helping
    with sorting and retrieval later on. In fact, Amazon''s S3 console reflects this
    pattern in its UI:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1d16565b-7ef5-48cb-b02b-7e7548a362b8.png)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
- en: 'Let''s stream an image up to S3:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'As we gave this image `public-read` permissions, it will be accessible at:
    [https://s3.amazonaws.com/nodejs-book/demos/putObject/testimage.jpg](https://s3.amazonaws.com/nodejs-book/demos/putObject/testimage.jpg).'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: 'Fetching an object from S3 and streaming it onto a local filesystem is even
    easier:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Alternatively, we can catch data events on the HTTP chunked transfer:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'To delete an object, do this:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'To delete multiple objects, pass an Array (to a maximum of 1,000 objects):'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Using AWS with a Node server
  id: totrans-328
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Putting together what we know about Node servers, streaming file data through
    pipes, and HTTP, it should be clear how to mount S3 as a filesystem in just a
    few lines of code:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'A standard Node HTTP server receives a request URL. We first attempt a HEAD
    operation using the `aws-sdk` method `headObject`, accomplishing two things:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: We'll determine whther the file is available
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will have the header information necessary to build a response
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After handling any non-200 status code errors, we only need to set our response
    headers and stream the file back to the requester, as previously demonstrated.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: Such a system can also operate as a **fail-safe**, in both directions; should
    S3, or the file, be unavailable, we might bind to another filesystem, streaming
    from there. Conversely, if our preferred local filesystem fails, we might fall
    through to our backup S3 filesystem.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: Refer to the `amazon/s3-redirect.js` file in the code bundle available at the
    Packt website for an example of using 302 redirects to similarly mount an AWS
    filesystem.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: S3 is a powerful data storage system with even more advanced features than those
    we've covered, such as object versioning, download payment management, and setting
    up objects as torrent files. With its support for streams, the `aws-sdk` module
    makes it easy for Node developers to work with S3 as if it was a local filesystem.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: Getting and setting data with DynamoDB
  id: totrans-338
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**DynamoDB** (**DDB**) is a NoSQL database providing very high throughput and
    predictability that can be easily scaled. DDB is designed for **data-intensive**
    applications, performing massive map/reduce and other analytical queries with
    low latency and reliably. That being said, it is also an excellent database solution
    for general web applications.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: 'The whitepaper announcing DynamoDB was highly influential, sparking a real
    interest in NoSQL databases, and inspiring many, including **Apache** **Cassandra**.
    The paper deals with advanced concepts, but rewards careful study; it is available
    at: [http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf](http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf).'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: A Dynamo database is a collection of tables, which is a collection of items,
    which are a collection of attributes. Each item in a table (or row, if you prefer)
    must have a primary key, functioning as an index for the table. Each item can
    have any number of attributes (up to a limit of 65 KB) in addition to the primary
    key.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: 'This is an item with five attributes, one attribute serving as the primary
    key (`Id`):'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Let''s create a table with both a primary and a secondary key:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The callback will receive an object similar to this:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Table creation/deletion is not immediate; you are essentially queueing up the
    creation of a table (note `TableStatus`). At some point in the (near) future,
    the table will exist. As DDB table definitions cannot be changed without deleting
    the table and rebuilding it, in practice, this delay is not something that should
    impact your application—build once, and then work with items.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: DDB tables must be given a schema indicating the item attributes that will function
    as keys, defined by `KeySchema`. Each attribute in `KeySchema` can be either a
    `RANGE` or a `HASH`. There must be one such index; there can be at most two. Each
    added item must contain any defined keys, with as many additional attributes as
    desired.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: Each item in `KeySchema` must be matched in count by the items in `AttributeDefinitions`.
    In `AttributeDefinitions`, each attribute can be either a number (`"N"`) or a
    string (`"S"`). When adding or modifying attributes, it is always necessary to
    identify attributes by its type as well as by the name.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: 'To add an item, use the following:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'In addition to our primary and (optional) secondary keys, we want to add other
    attributes to our item. Each must be given one of the following types:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: '`S`: A String'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`N`: A Number'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`B`: A Base64-encoded string'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SS`: An Array of Strings (String set)'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`NS`: An Array of Numbers (Number set)'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BS`: An Array of Base64-encoded strings (Base64 set)'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All items will need to have the same number of columns; again, dynamic schemas
    are *not* a feature of DDB.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: 'Assume that we''ve created a table that looks like the following table:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: '| **Id** | **Date** | **Action** | **Cart** | **UserId** |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
- en: '| 123 | 1375314738466 | buy | { "song1", "song2" } | DD9DDD8892 |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
- en: '| 124 | 1375314738467 | buy | { "song2", "song4" } | DD9EDD8892 |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
- en: '| 125 | 1375314738468 | buy | { "song12", "song6" } | DD9EDD8890 |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
- en: Now, let's perform some search operations.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: Searching the database
  id: totrans-367
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two types of search operations available: **query** and **scan**.
    A scan on a table with a single primary key will, without exception, search every
    item in a table, returning those matching your search criteria. This can be very
    slow on anything but small databases. A query is a direct key lookup. We''ll look
    at queries first. Note that in this example, we will assume that this table has
    only one primary key.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: 'To fetch the `Action` and `Cart` attributes for item `124`, we use the following
    code:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'This will return the following:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: To select all attributes, simply omit the `AttributesToGet` definition.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: A scan is more expensive, but allows more involved searches. The usefulness
    of secondary keys is particularly pronounced when doing scans, allowing us to
    avoid the overhead of scanning the entire table. In our first example of scan,
    we will work as if there is only a primary key. Then, we will show how to filter
    the scan using the secondary key.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: 'To get all the records whose `Cart` attribute contains `song2`, use the following
    code:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: This will return all attribute values for items with `Id` 123 and 124.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now use our secondary key to filter this further:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: This new filter limits results to item 124.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: Sending mail via SES
  id: totrans-381
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Amazon describes the problems SES is designed to solve in this way:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: '"Building large-scale email solutions to send marketing and transactional messages
    is often a complex and costly challenge for businesses. To optimize the percentage
    of emails that are successfully delivered, businesses must deal with hassles such
    as email server management, network configuration, and meeting rigorous Internet
    Service Provider (ISP) standards for email content."'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: Apart from the typical network scaling problems inherent in growing any system,
    providing email services is made particularly difficult due to the prevalence
    of spam. It is very hard to send a large number of unsolicited emails without
    ending up blacklisted, even when the recipients are amenable to receiving them.
    Spam control systems are automated; your service must be listed in the *whitelists*,
    which is used by various email providers and spam trackers in order to avoid having
    a low percentage of your emails end up somewhere other than your customer's inbox.
    A mail service must have a good reputation with the right people or it becomes
    nearly useless.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: Amazon's SES service has the necessary reputation, providing application developers
    with cloud-based e-mail service which is reliable and able to handle a nearly
    infinite volume of e-mail. In this section we will learn how SES can be used by
    a Node application as a reliable mail delivery service.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that you have SES access by visiting your developer console. When you
    first sign up with SES, you will be given *Sandbox* access. When in this mode,
    you are limited to using only Amazon's mailbox simulator, or sending email to
    address you have verified (such as one's own). You may request production access,
    but for our purposes, you will only need to verify an email address to test with.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: 'As the cost of using a service such as SES will increase as your mail volume
    increases, you might want to periodically check your quotas:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'To send a message, do this:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The callback will receive something like the following output:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Multiple recipients, HTML body contents, and all the other features one would
    expect from a mail service are available.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: Using Twilio to create an SMS bot on Heroku
  id: totrans-394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are going to be building an application that works as a customer service
    application, whereby customer service agents can field SMS requests from customers
    and respond to them. There will be two parts to the system.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 1 : A client application, running on your local machine, which spins up
    a React-powered web interface that displays incoming SMS messages, indicates the
    sentiment of the message (is the customer angry? Happy?) and allows you to respond
    to the message. Note that even though this server is running on a local machine,
    it could just as well be deployed to Heroku, or somewhere else -- the goal is
    to demonstrate how many servers in different locations can intelligently communicate
    with each other.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Part 2 : A *switchboard* that fields messages arriving via the Twilio SMS gateway,
    processes them, and distributes messages across any number of client servers --
    if you have 10 customer service representatives connected to the switchboard using
    the client application, messages the switchboard receives will be spread across
    these clients evenly. This second application will be deployed on Heroku.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You will first need to get an account on **Heroku**, a cloud server provider
    similar to Digital Ocean: [http://www.heroku.com](http://www.heroku.com)'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: Heroku provides free accounts, so you will be able to build out the following
    application without any cost to you.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: Once you have your account, log in and download the Heroku CLI for your system: [https://devcenter.heroku.com/articles/getting-started-with-nodejs#set-up](https://devcenter.heroku.com/articles/getting-started-with-nodejs#set-up).
    Follow the steps on that page to log in to the command line toolbelt for Heroku.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
- en: Make sure you have Git installed ([https://git-scm.com/book/en/v2/Getting-Started-Installing-Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)).
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a directory on your local file system, and clone the following two repositories
    into that folder:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/sandro-pasquali/thankyou](https://github.com/sandro-pasquali/thankyou)'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://github.com/sandro-pasquali/switchboard](https://github.com/sandro-pasquali/switchboard)'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *thankyou *repository is the client application. You will now deploy the *switchboard*
    repository to Heroku.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: 'Using your Terminal navigate to the *switchboard* repository and deploy a copy
    to Heroku:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'You should see something like the following displayed in your Terminal:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3742c243-35e8-497b-8b4f-cc12e582c705.png)'
  id: totrans-409
  prefs: []
  type: TYPE_IMG
- en: 'Heroku has established a Git endpoint on your server. Now, run the following
    command:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'You will see a list of two elements returned: *heroku* and *origin*. These
    are the two remote branches that your local *switchboard* repository is tracking,
    the one on Heroku and the one you originally cloned from.'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is to push your local repository into the Heroku repository:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'You should see a lot of installation instructions. When everything completes
    successfully navigate to your application URL. You should see that there is an
    *Application Error*. Heroku provides complete logs for your application. Let''s
    access them now to discover what went wrong:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'To keep a running tail of log activity on your Heroku server, use:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: '**` > heroku logs --tail`**'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: You should see several errors around the absence of environment variables, especially
    for Twilio. The application expects these to be set in the application environment,
    and they haven't been. Let's do that now.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: Using Twilio webhooks to receive and send SMS messages
  id: totrans-420
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The switchboard application ultimately provides a single service—to set up a
    REST-enabled endpoint that Twilio can call with SMS messages received on the number
    you've registered. It stores a log of those messages on a per-phone-number basis
    in LevelDB (a very fast key/value storage library), broadcasting new messages
    to clients connected to the switchboard.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: 'The logical flow of the entire application will look like this:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/41dc79a2-620b-464c-911c-cf54e2030a86.png)'
  id: totrans-423
  prefs: []
  type: TYPE_IMG
- en: We can see that the logic of our application begins with an SMS from Twilio,
    and supports responses from clients. This is the basic pattern for constructing
    a *NoUI*, or pure SMS application. This pattern is growing in popularity, often
    seen in the form of chat bots, AI-enabled assistants, and so on. We'll dig deeper
    into the application soon.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: Right now, we need to enable the Twilio bridge.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: To start, you will need to create a test account on Twilio to get some API variables.
    Go to [https://www.twilio.com](https://www.twilio.com) and sign up for a test
    account. Ensure that you set up a test phone number; we'll be sending SMS messages
    to that number.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you''ve done that, grab your Twilio API keys from the account Dashboard,
    your phone number, and your phone number SID. Now you''ll need to add that information
    to the environment variables for Heroku, along with some other keys. Go to your
    Heroku dashboard, find your instance, click on it, and navigate to Settings |
    Reveal Config Vars:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/04197e4a-5fa5-470a-9412-e5172e94c99f.png)'
  id: totrans-428
  prefs: []
  type: TYPE_IMG
- en: 'This is where you add key/value pairs to `process.env` in your running Node
    process. Add the following key/value pairs:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
- en: '`TWILIO_AUTH_TOKEN` / <your auth token>'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TWILIO_SID` / <your sid>'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TWILIO_PHONE_NUMBER_SID` / <your phone # sid>'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TWILIO_DEFAULT_FROM` / <your assigned phone number>'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SOCK_PORT` / `8080`'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`URL` / <your server URL (with no trailing slash)'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you've saved these new environment variables, your application will automatically
    restart on Heroku. Try your application URL again. If everything is working, you
    should see a message like Switchboard is active.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: You can quickly load your application into a browser from the command line with **`> heroku open`**.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: While we will not be using the shell, you can log in to your Heroku box via
    your Terminal with `> heroku run bash`.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
- en: 'To communicate with Twilio, we''ll be using the official Node library at: [https://github.com/twilio/twilio-node](https://github.com/twilio/twilio-node).
    The important code can be found in the `router/sms/` folder of the switchboard
    repository. This module will allow us to register a webhook to receive messages, and
    to respond to those messages.'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's build the switchboard.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
- en: The switchboard
  id: totrans-441
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The switchboard will have a single responsibility—to communicate with Twilio.
    Since we're using webhooks, we'll need to create a server that can catch POST
    data from Twilio. For the web server, we'll use the `restify` package ([http://www.restify.com](http://www.restify.com)).
    This is a very fast Node server implementation that is designed specifically for
    fast, high-load REST-based APIs. Since the switchboard is solely focused on handling
    incoming messages from Twilio, and its outbound traffic is through WebSockets,
    there is no need for a *higher-level* server like Express, which is designed to
    facilitate the presentation of views through templates, sessions, and so forth.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at the code instantiating a restify server that accepts POST messages
    from Twilio containing SMS message data, and the socket server to bind clients
    to the switchboard:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'With very little code, we''ve set up a web server and extended it with a socket
    server (using the excellent `ws` module, which you can grab at: [https://github.com/websockets/ws](https://github.com/websockets/ws)).
    You are encouraged to look at the code in the switchboard repository, where the
    details of how client connections are managed should be easy to follow. In particular,
    investigate the `router/Db/index.js` file, where a `levelDB` connection is established
    and an API for storing message histories (`api.addToNumberHistory`) is defined.
    For our purposes, note the `server.get` method, which establishes a handler for
    GET requests used simply as a *ping* service should we need to check whether the
    switchboard is available. We''ll add the important webhook route next.'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
- en: 'The Twilio webhook code is presented with the following line:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  id: totrans-447
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'The code in that file looks like this:'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  id: totrans-449
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Given that we''re connecting to and using a global SMS gateway, the code is
    surprisingly simple. After instantiating an instance of the Twilio API using the
    environment variables we set earlier on Heroku, we can conveniently use this API
    to programmatically establish a webhook, avoiding the manual process of logging
    into a Twilio dashboard:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: More importantly, this technique allows us to dynamically reconfigure the Twilio
    endpoint Twilio; it is always nice to be able to *hot swap* handlers should naming,
    or something else, change.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
- en: 'The body that Twilio POSTs and we will be receiving looks something like this:'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  id: totrans-454
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: In the hook handler, we grab the key info—the number of the sender and the message—storing
    them in `levelDB` via the `api.addToNumberHistory` method (which returns a Promise).
    Now we are ready to inform a client of the message. How do we do that?
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
- en: Clients are connected via a websocket. We can, after writing to the DB, simply
    send the message to the client in the same function body. However, now our code
    is starting to become complex, taking on two responsibilities (receiving and sending)
    rather than just one (receiving). It may seem like a small matter, but this is
    the sort of place where feature creep appears—maybe next we add logging in this
    function, and so on. Also, if we are responsible for notifying clients of new
    messages, we'll also be required to confirm that a database write was successful;
    this is often not clear cut, false positives not being out of the ordinary.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of doing that, let''s create a notification system that broadcasts
    changesets. Whenever a new message is written to the DB—a confirmed write—announce
    that update event, and register an event handler. In our intial server code, this
    functionality is bound using the following line:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  id: totrans-458
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'The code to catch changesets and broadcast them uses *Domenic Tarr''s* `level-live-stream`
    package:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  id: totrans-460
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: Using `level-live-stream`, we are able to concentrate our logic on the right
    event—a confirmed write to the database—leaving this *microservice* responsible
    solely for finding an available client and sending them the updated message history.
    Note that the way clients are stored and referenced in this example is not at
    all definitive. You might want to continue with the *do one thing well* philosophy
    and create another small service solely responsible for brokering connections.
    For example, we might remove all the client code from this example and create
    another service exposing a `getNextAvailableClient` method. This type of compositional
    strategy orchestrating microservices will be discussed further in the next chapter.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now receive, store, and broadcast incoming SMS messages. There is only
    one bit of functionality left—sending client responses back to Twilio, continuing
    the SMS conversation. The composition of these responses is performed by the *thankyou*
    application we''ll be discussing next. Ultimately, however, those responses are
    directed by the switchboard (recall the preceding sequence diagram), and the following
    is the very short code that you can use to send SMS messages through the Twilio
    gateway:'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'You should recall an *on message* listener for the websocket registered in
    our base server code, which uses the preceding functionality to respond to callers.
    We can now expand that listener:'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  id: totrans-465
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: We see `addToNumberHistory` here again since responses are of course part of
    the conversation history. Once the outgoing message is added to the database record,
    send it along via Twilio. Did you note something? That's only one of the things
    we have to do. The other is send the updated message history *back to the client*
    so that this response can appear in their view of the history. Typically, this
    is done using some client JavaScript that, when the client types a response and
    clicks on *send*, it optimistically updates the client state in the hope the message
    makes it to the switchboard. What does it not, though?
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
- en: We see how the changeset approach helps here. If the client message fails to
    reach the switchboard or otherwise fails, the `levelDB` will never be updated
    and the client's history state will not be out of sync with the canonical history
    represented by the data layer. While this may not matter so much in a trivial
    application like this one, it will matter if you're building transactional software.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's walk through the other half of the application—the *thankyou* client.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
- en: The ThankYou interface
  id: totrans-469
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To recap, we want to create a system whereby a switchboard receives SMS messages
    and passes them along to *service representatives* running a conversational interface
    on their local laptop or similar. This client is defined in the `thankyou` repository,
    and will look like this:'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a0f0409d-094e-4e6d-8361-8d3ea78df642.png)'
  id: totrans-471
  prefs: []
  type: TYPE_IMG
- en: Here, we see the message history the switchboard manages, and the interface
    for sending back responses. Importantly, there are icons indicating the sentiment
    (the winking happiness, the sad anger), of the messages as well as their timestamp
    in a human readable format (*a few seconds ago*). The goal for `thankyou` will
    be to catch incoming (and outgoing) messages, run sentiment analysis on the message
    stream, and display the results. We'll use React to build the UI.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
- en: React requires a build system, and we're using **Browserify**, **Gulp**, and
    **BrowserSync**. How those technologies work is beyond the scope of this chapter.
    Go over the contents of `gulpfile.js` and the `/source` directory of the `thankyou`
    repository. There are many online tutorials for these popular technologies.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
- en: 'As we are serving a real UI, for this project, we will use Express to build
    our Node server. Still, the server is very simple. It is only responsible for
    serving the single view just pictured, which is contained in a single `index.html`
    file:'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  id: totrans-475
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: React components are bundled by the build system into `components.js`; JavaScript
    files are similarly bundled into `app.js`, as stylesheets are into `app.css`.
    The jQuery DOM manipulation library is used for simple element effects and for
    managing the message composer. As mentioned, we won't be going deep into client
    JavaScript. It will be useful to take a brief look at the React component used
    to construct the timeline, as this component is ultimately what will be receiving
    new messages from the switchboard.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the main UI component powering `thankyou`:'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  id: totrans-478
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: Even if you don't know React, you should be able to see that the `MessageHistory`
    component extends the `Timeline` component. The `Timeline` component is responsible
    for maintaining the application state, or in our case, the current message history.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the key UI code in `MessageHistory`:'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  id: totrans-481
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'You may recall the message history that switchboard works with:'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  id: totrans-483
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'This is the section in the `MessageHistory` where that data is rendered into
    UI views. We won''t go too much farther into the UI code, but you should note
    a property that switchboard did not generate: `it.sentiment`. Keep that in mind
    that as we go over how thankyou communicates data with switchboard.'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the switchboard receives and sends messages over WebSockets, `Timeline`
    has such a reference:'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  id: totrans-486
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'The socket code was included in our `index.html` file:'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  id: totrans-488
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'Also, it looks like this:'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  id: totrans-490
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'This code puts the `ws` reference in the browser global scope on the client
    (`window.ws`). While generally not the best practice, for our simple UI, this
    makes it easy for React components to grab the same socket reference. This reference
    is also used in the `MessageComposer` component, which accepts responses from
    the client:'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  id: totrans-492
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: This component renders a text area, into which responses can be composed and
    sent, via socket, to the switchboard.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's look at how the client server communicates with the client UI, brokering
    communication with the switchboard.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: 'The client server is defined in `router/index.js`:'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  id: totrans-496
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'This is a standard Express setup. Note the following line:'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  id: totrans-498
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'This is the main broker logic. Recalling the application sequence diagram,
    here is where switchboard messages are received and passed along, through another
    socket, to the UI and ultimately, the React renderer. Similarly, the server listens
    for messages from the UI and passes those along to the switchboard:'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  id: totrans-500
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: This should make sense now, given the *switchboard* design. Starting at the
    bottom, we see that when the client socket server `localClientSS` receives a message,
    it validates and passes the message along to the *switchboard*, where it will
    be added to the message history for the phone number this client is handling.
    More interesting is the code to receive messages from the switchboard, which performs
    sentiment analysis and converts timestamps into human readable sentences.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
- en: 'To perform these transformations, the payload received from the *switchboard*
    (an Array in JSON format) is converted into an object stream using the `arrayToStream.js`
    module. Streams are covered in [Chapter 3](c7665bc9-3f44-4d7c-8318-61f9dfe962b3.xhtml), *Streaming
    Data Across Nodes and Clients*; we''re simply creating a `Readable` Stream that
    pipes each element in the array as a distinct object. The real fun begins when
    we apply transformations. Let''s look at the code to do sentiment analysis (which
    processes the `''message''` property of the history object), using the `through2`
    module ([https://github.com/rvagg/through2](https://github.com/rvagg/through2))
    to simplify the creation and design of a transform stream, and of course, the
    sentiment module ([https://github.com/thisandagain/sentiment](https://github.com/thisandagain/sentiment))
    to gauge the mood of the message:'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  id: totrans-503
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: The functionality is straightforward; for each object in the history array sent
    from the switchboard, determine the sentiment score for the message. Negative
    scores are *bad*, along the range from very bad (*devil*) to *unhappy*. We similarly
    score positive sentiments along a range from very good (*wink*) to *happy*. A
    new `sentiment` property is added to the message object, and as we saw earlier
    when considering the `MessageHistory` component, this will set which icon the
    message receives in the UI.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
- en: If you want to continue development of this application on your own, you should
    fork the repositories onto your own GitHub account, and repeat the process with
    these personal repositories. This will allow you to push changes and otherwise
    modify the application to suit your own needs.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
- en: The coordination of *switchboard* and *thankyou* should give you some ideas
    on how to use services, sockets, REST endpoints, and third-party APIs to distribute
    functionality, helping you scale through adding (or removing) components, across
    the stack. By using transform streams, you can apply "on the fly" stream data
    transformations without blocking, managing data models on your servers, and leaving
    layout to the UI itself.
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-507
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Big data applications have placed significant responsibility on developers of
    network applications to prepare for scale. Node has offered help in creating a
    network-friendly application development environment that can easily connect to
    other devices on a network, such as cloud services and, in particular, other Node
    servers.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we learned some good strategies for scaling Node servers, from
    analyzing CPU usage to communicating across processes. With our new knowledge
    of message queues and UDP, we can build networks of Node servers scaling horizontally,
    letting us handle more and more traffic by simply replicating the existing nodes.
    Having investigated load balancing and proxying with both Node and NGINX, we can
    confidently add capacity to our applications. When matched with the cloud services
    provided by Digital Ocean, AWS, and Twilio, we can attempt enterprise-scale development,
    data storage, and broadcast at a low cost and without adding much complexity to
    our application.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
- en: As our applications grow, we will need to maintain continuous awareness of how
    each part as well as the whole is behaving. As we keep adding new components and
    functionality, some local, some through the cloud, some maybe even written in
    another language, how do we, as developers, intelligently track and plan additions
    and other changes? In the next chapter, we will learn about microservices, a way
    of developing one application out of many, small, cooperating horizontally-distributed
    network services.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
