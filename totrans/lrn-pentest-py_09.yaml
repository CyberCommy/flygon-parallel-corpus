- en: Chapter 9. Automating Reports and Tasks with Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We covered in previous chapters a good amount of information that highlights
    where Python can help optimize technical fieldwork. We even showed methods in
    which Python can be used to automate follow-on tasks from one process to another.
    Each of these will help you better spend your time on priority tasks. This is
    important because there are three things that potentially limit the successful
    completion of a penetration test: the time an assessor has to complete the assessment,
    the limits of the scope of the penetration test, and the skill of the assessor.
    In this chapter, we are going to show you how to automate tasks such as parsing
    **eXtensible Markup Language** (**XML**) to generate reports from tool data.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding how to parse XML files for reports
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are going to use `nmap` XMLs as an example to show how you can parse data
    into a useable format. Our end goal will be to place the data in a Python dictionary
    of unique results. We can then use that data to build structured outputs that
    we find useful. To begin, we need an XML file that can be parsed and reviewed.
    Run an `nmap` scan of your localhost with the `nmap -oX test 127.0.0.1` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'This will produce a file that highlights the two open ports using XML markup
    language, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding how to parse XML files for reports](img/B04315_09_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: With an actual XML file, we can review the components of the data structure.
    Understanding how an XML file is designed will better prepare you to generate
    the code that will read it. Specifically, the descriptions here are based on what
    the `etree` library classifies the components of an XML file as. The `etree` library
    handles the XML data conceptually like a tree, with relevant branches, subbranches,
    and even twigs. In computer science terms, we call this a parent-child relationship.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `etree` library, you are going to load the data into variables. These
    variables will hold composite pieces of data within themselves. These are referred
    to as **elements**, which can be further dissected to find useful information.
    For example, if you load the root of an XML nmap structure into a variable and
    then print it, you will see the reference and a tag that describes the element
    and the data within it, as seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding how to parse XML files for reports](img/B04315_09_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Additional details related to the `etree` library can be found at [https://docs.python.org/2/library/xml.etree.elementtree.html](https://docs.python.org/2/library/xml.etree.elementtree.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'Each element can have a parent-child relationship with other nodes and even
    sub-children nodes, known as grandchildren. Each node holds the information that
    we are trying to parse. A node typically has a tag, which is the description of
    the data it holds, and an attribute, which is the actual data. To better highlight
    how this information is presented in XML, we have captured an element of the nmap
    XML, the hostname''s node, and a single resulting child, as seen here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding how to parse XML files for reports](img/B04315_09_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As you look at an XML file, you may notice that you can have multiple nodes
    within an element. For example, a host may have a number of different hostnames
    for the same **Internet Protocol** (**IP**) address due to multiple references.
    As such, to iterate over all the nodes of an element, you need to use a for loop
    to capture all the possible data components. The parsing of this data is for producing
    an output, which is only as good as the data samples you have.
  prefs: []
  type: TYPE_NORMAL
- en: This means that you should take multiple sample XML files to get a better cross-section
    of information. The point is to get the majority of the possible data combinations.
    Even with samples that should cover the majority of issues that you will run into,
    there will be examples that are not accounted for. So, do not get discouraged
    if your script breaks in the middle of its use. Trace the errors and determine
    what needs to be adjusted.
  prefs: []
  type: TYPE_NORMAL
- en: For our tests, we are going to use multiple `nmap` scans and our Kali instance
    and output the details to XML file.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Python has a fantastic library, called `libnmap`, that can be used to run and
    schedule scans and even help parse output files to generate reports. More details
    on this can be found at [https://libnmap.readthedocs.org/en/latest/](https://libnmap.readthedocs.org/en/latest/).
    We could use this library to parse the output and generate a report, but this
    library works only for `nmap`. If you want to parse other XML outputs from other
    tools to add details to a more manageable format, this library will not help you.
  prefs: []
  type: TYPE_NORMAL
- en: When we are getting ready to write a parser, the first stage is to map the file
    that we are going to parse. So, we take notes of the likely ways in which we need
    to have our script interact with the output. After mapping the file, we place
    several `print` statements throughout the file to show what elements our script
    has stopped or broken its processing at. To better understand each element, you
    should load the example XMLs into a tool that allows proper XML viewing. Notepad++
    works very well, provided you have the XML tools plugin installed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have loaded the file into Notepad++, you should collapse the XML tree
    down to its root. The following screenshot shows that the root of this tree is
    `nmaprun`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding how to parse XML files for reports](img/B04315_09_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: After you expand it once, you get a number of subnodes, which can be further
    expanded and broken down.
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding how to parse XML files for reports](img/B04315_09_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: From these details, we see that we have to load the XML file into the handler
    and then walk through the host element. We should, however, consider the fact
    that this is a single host, so there will only be one host element. As such, we
    should iterate through the host element with a `for` loop to capture other hosts
    that would be scanned in future iterations.
  prefs: []
  type: TYPE_NORMAL
- en: When the host element is expanded, we can find that there are nodes for the
    address, hostnames, ports, and the time. The nodes we are interested in would
    be the address, hostnames, and ports. Both the hostnames and ports nodes are expandable,
    which means that they probably need to be iterated as well.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can iterate through any node with a for loop even if there is only one entry.
    This ensures you will capture all the information in child nodes and prevent the
    breaking of the parser.
  prefs: []
  type: TYPE_NORMAL
- en: 'This screenshot highlights the details of the expanded XML tree, with the details
    that we care about:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding how to parse XML files for reports](img/B04315_09_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: For the address, we can see there are different address types, as highlighted
    by the `addrtype` tag. In nmap XML outputs, you will find the `ipv4`, `ipv6`,
    and `mac` addresses. If you want different address types in your output, you can
    get them by pulling the data with simple `if-then` statements and then loading
    it into the appropriate variables. If you just want an address to be loaded into
    a variable regardless of the type, you will have to create an order of precedence.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `nmap` tool may or may not find a hostname for each target scanned. This
    depends on how the scanner attempted to retrieve the information. For example,
    if **Domain Name Service** (**DNS**) requests were enabled or the scan was against
    the localhost, a hostname may have been identified. Other instances of scans may
    not identify an actual hostname. We have to build our script to take into consideration
    the different outputs that may be provided depending on the scan. Our localhost
    scan, as seen in the following screenshot, did provide a hostname, so we have
    information that we can extract in this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding how to parse XML files for reports](img/B04315_09_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Thus, we have determined that we are going to load the hostnames and addresses
    into variables. We are going to look at the `ports` element to identify the parent
    and child node data we are going to extract. The XML nodes in this area of the
    tree have a large amount of data since they have to be represented by numerous
    tags and attributes, as shown in this screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding how to parse XML files for reports](img/B04315_09_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: While looking at the details of these nodes, we should consider what components
    we would like to extract. We know that we will have to iterate all the ports,
    and we can uniquely identify the ports by the `portid` tag, which represents the
    port number, but we have to consider what data is useful to us as assessors. The
    protocol of the port, such as **Transmission Control Protocol** (**TCP**) and
    **User Datagram Protocol** (**UDP**), is useful. Also, the state of the port and
    whether it is `open`, `closed`, `filtered`, or `open|filtered` is important. Finally,
    the name of the service that may have been identified would be good to catalogue
    in a report.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Remember that a service name may be inaccurate, depending on the type of scan.
    If there is no service detection, nmap uses the defaults described in Linux's
    `/etc/services` file for those ports. So, if you are generating reports for a
    client as part of a footprinting exercise, make sure that you enable some form
    of service detection. Otherwise, the data that you provide could be considered
    inaccurate.
  prefs: []
  type: TYPE_NORMAL
- en: After reviewing the XML file, we have determined that in addition to the addresses
    and hostnames, we are also going to capture every port number, the protocol, the
    service attached to it, and the state. With these details, we can consider how
    we want to format our report. As previous images have shown, data from the nmap
    XMLs is not narrative in format, so a Microsoft Word document will not be as useful
    as a spreadsheet—potentially.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, we have to consider the manner in which the data will be represented
    in the report: a line per host or a line per port. There are benefits and trade-offs
    for each of these representations. A line-by-line host representation means that
    composite information is easy to represent, but if we want to filter our data,
    we can only filter on unique information about the host or port groups, and not
    on individual ports.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To make this more useful, each line in the spreadsheet will represent a port,
    which means that the particulars of each port can be represented on a line. This
    can help our clients filter on each item that we extract from the XML to include
    the hostname, address, port, service name, protocol, and port state. The following
    screenshot shows what we will be working towards:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding how to parse XML files for reports](img/B04315_09_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Since we are writing a parser and a report generator, it would be good to create
    two separate classes to handle this information. The added benefit is that the
    XML parser can be instantiated, which means that we can use the parser to run
    against more than one XML file and then combine combine each iteration into holistic
    and unique results. This is extremely beneficial for us, since we typically run
    more than one `nmap` scan during an engagement, and combining results and eliminating
    duplicates can be a rather laborious process. Again, this is an ideal example
    in which scripting can make our lives easier.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding how to create a Python class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is a lot of misunderstanding among new Python enthusiasts regarding how
    to generate Python classes. Python's manner of dealing with classes and instance
    variables is slightly different from that of many other languages. This is not
    a bad thing; in fact, once you get used to the way the language works, you can
    start understanding the reasons for the way the classes are defined as well thought
    out.
  prefs: []
  type: TYPE_NORMAL
- en: If you search for the topic of Python and self on the Internet, you will find
    extensive opinions on the use of the defined variable that is placed at the beginning
    of nonstatic functions in Python classes, you will see extensive opinions about
    it. These range from why it is a great concept that makes life easier, to the
    fact that it is difficult to contend with and makes creating multithreaded scripts
    a chore. Typically, confusion originates from developers who move from another
    language to Python. Regardless of which side of the fence you will fall on, the
    examples provided in this chapter are a way of building Python classes.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the next chapter, we will highlight the multithreading of scripts, which
    requires a fundamental understanding of how Python classes work.
  prefs: []
  type: TYPE_NORMAL
- en: Guido van Rossum, the creator of Python, has responded to some of the criticism
    related to self in a blog post, available at [http://neopythonic.blogspot.com/2008/10/why-explicit-self-has-to-stay.html](http://neopythonic.blogspot.com/2008/10/why-explicit-self-has-to-stay.html).
    To help you stay focused on this section of the book, extensive definitions of
    Python classes, imports, and objects will not be repeated, as they are already
    well-defined. If you would like additional detailed information related to Python
    classes, you can find it at [http://learnpythonthehardway.org/book](http://learnpythonthehardway.org/book).
    Specifically, exercises 40 through 44 do a pretty good job at explaining the "Pythonic"
    concepts about classes and object-oriented principles, which include inheritance
    and composition.
  prefs: []
  type: TYPE_NORMAL
- en: Previously, we described how to write the naming conventions for a class that
    is Pythonic, so we will not repeat that here. Instead, we are going to focus on
    a couple of items that will be required in our script. First, we are going to
    define our class and our first function—the `__init__` function.
  prefs: []
  type: TYPE_NORMAL
- en: The `__init__` function is what is used during the instantiation of the class.
    This means that a class is called to create an object that can be referenced through
    the running script as a variable. The `__init__` function helps define the initial
    details of that object, where it basically acts as the constructor for a Python
    class. To help put this in perspective, the `__del__` function is the opposite,
    as it is the destructor in Python.
  prefs: []
  type: TYPE_NORMAL
- en: If a function is going to use the details of the instance, the first parameter
    passed has to be a consistent variable, which is typically called `self`. If you
    want, you can call it something else, but that is not Pythonic. If a function
    does not have this variable, then the instantiated values cannot be used directly
    within that function. All values that follow the `self` variable in the `__init__`
    function are what would be directly passed to the class during its instantiation.
    Other languages pass these values through hidden parameters; Python does this
    using `self`. Now that you have understood the basics of a Python script, we can
    start building our parsing script.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Python script to parse an Nmap XML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The class we are defining for this example is extremely simple in nature. It
    will have only three functions: `__init__`, a function that processes the passed
    data, and finally, a function that returns the processed data. We are going to
    set up the class to accept the nmap XML file and the verbosity level, and if none
    of it is passed, it defaults to `0`. The following is the definition of the actual
    class and the `__init__` function for the nmap parser:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now we are going to define the function that will do the work for this class.
    As you will notice, we do not need to pass any variables in the function, as they
    are contained within `self`. In larger scripts, I personally add comments to the
    beginning of functions to explain what is being done. In this way, when I have
    to add some more functionality into them years later, I do not have to lose time
    deciphering hundreds of lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As with the previous chapters, the full script can be found on the GitHub page
    at [https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/nmap_parser.py](https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/nmap_parser.py).
  prefs: []
  type: TYPE_NORMAL
- en: 'The run function tests to make sure that it can open the XML file, and then
    loads it into a variable using the `etree` library''s `parse` function. The function
    then defines the initial necessary variables and gets the root of the XML tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Next, we build a `for` loop that iterates through each host and defines the
    hostname as `Unknown hostname` for each cycle initially. This is done to prevent
    a hostname from one host from being recorded for another host. Similar blanking
    is done for the addresses prior to trying to retrieve them. You can see in the
    following code that a nested `for` loop iterates through the host address node.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each attribute of each `addrtype` tag is loaded into the `temp` variable. This
    value is then tested to see what type of address will be extracted. Next, the
    `addr` tag''s attribute is loaded into the variables appropriate for its address
    type, such as `hwaddress`, and `address` for **Internet Protocol version 4 (IPv4)**,
    and `addressv6` for **IP version 6 (IPv6)**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'For hostnames, we did something slightly different. We could have created another
    `for` loop to try and identify all available hostnames per host, but most scans
    have only one or no hostname. To show a different way to grab data from an XML
    file, you can see that the `hostname` node is loaded into the appropriately named
    variable by first identifying the parent elements `hostnames`, and then the child
    element `hostname`. If the script does not find a `hostname`, we again set the
    variable to `Unknown hostname`:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This script is set up as a teaching concept, but we also want to be prepared
    for future changes, if necessary. Keeping this in mind, if we wish to later change
    the way we extract the hostname direct node extraction to a `for` loop, we can.
    This was prepared in the script by loading the identified hostname into a hostname
    list prior to the next code section. Normally, this would not be needed for the
    way in which we extracted the hostname. It is easier to prepare the script for
    a future change here than to go back and change everything related to the loading
    of the attribute throughout the rest of the code afterwards.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have captured how to identify the hostname, we are going to try
    and capture all the ports for each host. We do this by iterating over all the
    `port` nodes and loading them into the item variable. Next, we extract from the
    node the attributes of `state`, `servicename`, `protocol`, and `portid`. Then,
    these values are loaded into a `services` list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, there is a list of values with all the services for each host. We are
    going to break it out to a dictionary for easy reference. So, we generate a `for`
    loop that iterates through the length of the list, reloads each `services` value
    into a temporary variable, and then loads it into the instance''s `self.hosts`
    dictionary using the value of the iteration as a key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'At the end of this function, we add a simple test case to verify that the data
    was discovered, and it can be presented if the verbosity is turned up:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'With the primary processing function complete, the next step is to create a
    function that can return the specific instance''s `hosts` data. This function
    simply returns the value of `self.hosts` when called:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We have shown repeatedly the basic variable value setting through arguments
    and options, so to save space, the details of this code in the `nmap_parser.py`
    script are not covered here; they can be found online. Instead of that, we are
    going to show how we to process multiple XML files through our class instances.
  prefs: []
  type: TYPE_NORMAL
- en: It starts out very simply. We test to see whether our XML files that were loaded
    by arguments have any commas in the variable `xml`. If they do, it means that
    the user has provided a comma-delimitated list of XML files to be processed. So,
    we are going to split by the comma and load the values into `xml_list` for processing.
    Then, we are going to test each XML file and verify that it is an `nmap` XML file
    by loading the XML file into a variable with `etree.parse`, getting the root of
    the file, and then checking the attribute value of the `scanner` tag.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we get `nmap`, we know that the file is an nmap XML. If not, we exit the
    script with an appropriate error message. If there are no errors, we call the
    `Nmap_parser` class and instantiate it as an object with the current XML file
    and the verbosity level. Then, we append it to a list. So basically, the XML file
    is passed to the `Nmap_parser` class and the object itself is stored in the hosts
    list. This allows us to easily process multiple XML files and store the object
    for later manipulation, as necessary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Each of these instances' data that was loaded into the dictionary may have duplicate
    information within it. Just think of what it is like during a penetration test;
    when you scan for specific weaknesses, you often look over the same IP addresses.
    Each time you run the scan, you may find the same ports and services and the relevant
    states. For that data to be normalized, it needs to be combined and duplicates
    need to be eliminated.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, when dealing with typical internal IP addresses or **Request For
    Comment** (**RFC**) 1918 addresses, a `10.0.0.1` address could be in many different
    internal networks. So, if you use this script to combine results from multiple
    networks, you may be combining results that are not actually duplicates. Keep
    this in mind when you actually execute the script.
  prefs: []
  type: TYPE_NORMAL
- en: 'So now, we load a temporary variable with each instance of data in a `for`
    loop. This will create a `count` of all the values in the dictionary and, in turn,
    use this as the reference for each value set. A new dictionary called `hosts_dict`
    is used to store this data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have a dictionary with data that is ordered by a simple reference,
    we can use it to eliminate duplicates. What we do now is iterate through the newly
    formed dictionary and create key-value pairs within tuples. Each tuple is then
    loaded into the list, which allows the data to be sorted.
  prefs: []
  type: TYPE_NORMAL
- en: We again iterate through the list, which breaks down the two values stored in
    the tuple into a new key-value pair. Functionally, we are manipulating the way
    we normally store data in Python data structures to easily remove duplicates.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we perform a straight comparison of the current value, which is the list
    of port data with the `processed_hosts` dictionary values. This is the new and
    final dictionary that contains the verified unique values discovered from all
    the XML files.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This list of port data was stored as the second value in a tuple that was nested
    within the `temp` list.
  prefs: []
  type: TYPE_NORMAL
- en: 'If a value has already been found in the `processed_hosts` dictionary, we continue
    the loop with `continue`, without loading the details into the dictionary. Had
    the value not been in the dictionary, we would have added it to the dictionary
    using the new counter, `key`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we test and make sure that the data is properly ordered and presented in
    our new data structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Running the script produces the following results, which show that we have
    successfully extracted the data and formatted it into a useful structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating a Python script to parse an Nmap XML](img/B04315_09_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We can now comment out the loop that prints the data and use our data structure
    to create an Excel spreadsheet. To do this, we are going to create our own local
    module, which can then be used within this script. The script will be called to
    generate the Excel spreadsheet. To do this, we need to know the name by which
    we are going to call it and how we would like to reference it. Then, we create
    the relevant `import` statement at the top of the `nmap_parser.py` for the Python
    module, which we will call `nmap_doc_generator.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we replace the printing of the dictionary at the bottom of the `nmap_parser.py`
    script with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The simple flag was added to the list of options to allow the spreadsheet to
    be output in different formats, if you like. This tool can be useful in real penetration
    tests and for final reports. Everyone has a preference when it comes to what output
    is easier to read and what colors are appropriate for the branding of their reports
    for whatever organization they work for.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Python script to generate Excel spreadsheets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now we create our new module. It can be imported into the `nmap_parser.py`
    script. The script is very simple thanks the `xlsxwriter` library, which we can
    again install with `pip`. The following code brings the script by setting up the
    necessary libraries so that we can generate the Excel spreadsheet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create the class and the constructor for `Nmap_doc_generator`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we create the function that will be executed for the instance. From this
    function, a secondary function called `generate_xlsx` is executed. This function
    is created in this manner so that we can use this very module for other report
    types in future, if desired. All that we would have to do is create additional
    functions that can be invoked with options supplied when the `nmap_parser.py`
    script is run. That''s beyond the scope of this example, however, so the extent
    of the `run` function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The next function we define is `generate_xlsx`, which includes all the features
    required to generate the Excel spreadsheet. The first thing we need to do is define
    the actual workbook, the worksheet, and the formatting within. We begin this by
    setting the actual filename extension, if none exists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we start creating the actual row formats, beginning with the header row.
    We highlight it as a bold row with two different possible colors, depending on
    whether the simple flag is set or not:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can identify the actual color number that you want in your spreadsheet using
    a Microsoft-like color selection tool. It can be found at [http://www.w3schools.com/tags/ref_colorpicker.asp](http://www.w3schools.com/tags/ref_colorpicker.asp).
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we want to configure this as a spreadsheet—so that it can have alternating
    colors—we are going to set two additional formatting configurations. Like the
    previous formatting configuration, this will be saved as variables that can easily
    be referenced depending on the whether the row is even or odd. Even rows will
    be white, since the header row has a color fill, and odd rows will have a color
    fill. So, when the `simple` variable is set, we are going to change the color
    of the odd row. The following code highlights this logic structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'With the formatting defined, we now have to set the column widths and headings,
    and these will be used throughout the rest of the spreadsheet. There is a bit
    of trial and error here, as the column widths should be wide enough for the data
    that will be populated in the spreadsheet and properly represent the headings
    without unnecessarily scaling out off the screen. Defining the column width is
    done by range, the starting column number, the ending column number, and finally
    the size of the column width. These three comma-delimited values are placed in
    the `set_column` function parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'With the columns defined, set the starting location for the rows and the columns,
    populate the header rows, and make the data present in them filterable. Think
    about how useful it is to look for hosts with open JBoss ports or if a client
    wants to know the ports that have been successfully filtered by the perimeter
    firewall:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'So, with the formatting defined, we can actually start populating the spreadsheet
    with the relevant data. To do this we create a `for` loop that populates the `key`
    and `value` variables. In this instance of report generation, key is not useful
    for the spreadsheet, since none of the data from it is used to generate the spreadsheet.
    On the other hand, the `value` variable contains the list of results from the
    `nmap_parser.py` script. So, we populate the six relevant value representations
    in positional variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: At the end of each iteration, we are going to increment the row counter. Otherwise,
    if we did this at the beginning, we would be writing blank rows between data rows.
    To start the processing, we need to determine whether the row is even or odd,
    as this changes the formatting, as mentioned before. The easiest way to do this
    is to use the modulus operator, or `%`, which divides the left operand by the
    right operand and returns the remainder.
  prefs: []
  type: TYPE_NORMAL
- en: 'If there is no remainder, we know that it is even, and as such, so is the row.
    Otherwise, the row is odd and we need to use the requisite format. Instead of
    writing the entire function row writing operation twice, we are again going to
    use a temporary variable that will hold the current row format, called `temp_format`,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can write the data from left to right. Each component of the data goes
    into the next column, which means that we take the column value of `0` and add
    `1` to it each time we write data to the row. This allows us to easily span the
    spreadsheet from left to right without having to manipulate multiple values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we close the workbook that writes the file to the current working
    directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'All the necessary script components and modules have been created, which means
    that we can generate our Excel spreadsheet from the `nmap` XML outputs. In the
    arguments of the `nmap_parser.py` script, we set a default filename to `xml_output`,
    but we can pass other values as necessary. The following is the output from the
    help of the `nmap_parser.py` script:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating a Python script to generate Excel spreadsheets](img/B04315_09_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'With this detailed information we can now execute the script against the four
    different `nmap` scan XMLs that we have created as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating a Python script to generate Excel spreadsheets](img/B04315_09_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The output of the script is this Excel spreadsheet:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating a Python script to generate Excel spreadsheets](img/B04315_09_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Instead, if we set the simple flag and create a new spreadsheet with a different
    filename, we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating a Python script to generate Excel spreadsheets](img/B04315_09_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'This creates the new spreadsheet, `xml_output2.xlsx`, with the simple format,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating a Python script to generate Excel spreadsheets](img/B04315_09_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The code for this module can be found at [https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/nmap_doc_generator.py](https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/nmap_doc_generator.py).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Parsing nmap XML is extremely useful, but consider how helpful this capability
    is for reading and organizing other security tool outputs as well. We showed you
    how to create Python classes, parse XML structures, and generate unique datasets.
    By the end of all of this, we were able to create an Excel spreadsheet that can
    represent data in a filterable format. In the next chapter, we will highlight
    how to add multithreading capabilities and permanency to our Python scripts.
  prefs: []
  type: TYPE_NORMAL
