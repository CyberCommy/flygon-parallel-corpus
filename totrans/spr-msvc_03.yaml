- en: Chapter 3. Applying Microservices Concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices are good, but can also be an evil if they are not properly conceived.
    Wrong microservice interpretations could lead to irrecoverable failures.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will examine the technical challenges around practical implementations
    of microservices. It will also provide guidelines around critical design decisions
    for successful microservices development. The solutions and patterns for a number
    of commonly raised concerns around microservices will also be examined. This chapter
    will also review the challenges in enterprise scale microservices development,
    and how to overcome those challenges. More importantly, a capability model for
    a microservices ecosystem will be established at the end.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter you will learn about the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Trade-offs between different design choices and patterns to be considered when
    developing microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Challenges and anti-patterns in developing enterprise grade microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A capability model for a microservices ecosystem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Patterns and common design decisions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices have gained enormous popularity in recent years. They have evolved
    as the preferred choice of architects, putting SOA into the backyards. While acknowledging
    the fact that microservices are a vehicle for developing scalable cloud native
    systems, successful microservices need to be carefully designed to avoid catastrophes.
    Microservices are not the one-size-fits-all, universal solution for all architecture
    problems.
  prefs: []
  type: TYPE_NORMAL
- en: Generally speaking, microservices are a great choice for building a lightweight,
    modular, scalable, and distributed system of systems. Over-engineering, wrong
    use cases, and misinterpretations could easily turn the system into a disaster.
    While selecting the right use cases is paramount in developing a successful microservice,
    it is equally important to take the right design decisions by carrying out an
    appropriate trade-off analysis. A number of factors are to be considered when
    designing microservices, as detailed in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Establishing appropriate microservice boundaries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the most common questions relating to microservices is regarding the
    size of the service. How big (mini-monolithic) or how small (nano service) can
    a microservice be, or is there anything like right-sized services? Does size really
    matter?
  prefs: []
  type: TYPE_NORMAL
- en: A quick answer could be "one REST endpoint per microservice", or "less than
    300 lines of code", or "a component that performs a single responsibility". But
    before we pick up any of these answers, there is lot more analysis to be done
    to understand the boundaries for our services.
  prefs: []
  type: TYPE_NORMAL
- en: '**Domain-driven design** (**DDD**) defines the concept of a **bounded context**.
    A bounded context is a subdomain or a subsystem of a larger domain or system that
    is responsible for performing a particular function.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Read more about DDD at [http://domainlanguage.com/ddd/](http://domainlanguage.com/ddd/).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram is an example of the domain model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Establishing appropriate microservice boundaries](img/B05447_03_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In a finance back office, system invoices, accounting, billing, and the like
    represent different bounded contexts. These bounded contexts are strongly isolated
    domains that are closely aligned with business capabilities. In the financial
    domain, the invoices, accounting, and billing are different business capabilities
    often handled by different subunits under the finance department.
  prefs: []
  type: TYPE_NORMAL
- en: A bounded context is a good way to determine the boundaries of microservices.
    Each bounded context could be mapped to a single microservice. In the real world,
    communication between bounded contexts are typically less coupled, and often,
    disconnected.
  prefs: []
  type: TYPE_NORMAL
- en: Even though real world organizational boundaries are the simplest mechanisms
    for establishing a bounded context, these may prove wrong in some cases due to
    inherent problems within the organization's structures. For example, a business
    capability may be delivered through different channels such as front offices,
    online, roaming agents, and so on. In many organizations, the business units may
    be organized based on delivery channels rather than the actual underlying business
    capabilities. In such cases, organization boundaries may not provide accurate
    service boundaries.
  prefs: []
  type: TYPE_NORMAL
- en: A top-down domain decomposition could be another way to establish the right
    bounded contexts.
  prefs: []
  type: TYPE_NORMAL
- en: There is no silver bullet to establish microservices boundaries, and often,
    this is quite challenging. Establishing boundaries is much easier in the scenario
    of monolithic application to microservices migration, as the service boundaries
    and dependencies are known from the existing system. On the other hand, in a green
    field microservices development, the dependencies are hard to establish upfront.
  prefs: []
  type: TYPE_NORMAL
- en: The most pragmatic way to design microservices boundaries is to run the scenario
    at hand through a number of possible options, just like a service litmus test.
    Keep in mind that there may be multiple conditions matching a given scenario that
    will lead to a trade-off analysis.
  prefs: []
  type: TYPE_NORMAL
- en: The following scenarios could help in defining the microservice boundaries.
  prefs: []
  type: TYPE_NORMAL
- en: Autonomous functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If the function under review is autonomous by nature, then it can be taken as
    a microservices boundary. Autonomous services typically would have fewer dependencies
    on external functions. They accept input, use its internal logic and data for
    computation, and return a result. All utility functions such as an encryption
    engine or a notification engine are straightforward candidates.
  prefs: []
  type: TYPE_NORMAL
- en: A delivery service that accepts an order, processes it, and then informs the
    trucking service is another example of an autonomous service. An online flight
    search based on cached seat availability information is yet another example of
    an autonomous function.
  prefs: []
  type: TYPE_NORMAL
- en: Size of a deployable unit
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Most of the microservices ecosystems will take advantage of automation, such
    as automatic integration, delivery, deployment, and scaling. Microservices covering
    broader functions result in larger deployment units. Large deployment units pose
    challenges in automatic file copy, file download, deployment, and start up times.
    For instance, the size of a service increases with the density of the functions
    that it implements.
  prefs: []
  type: TYPE_NORMAL
- en: A good microservice ensures that the size of its deployable units remains manageable.
  prefs: []
  type: TYPE_NORMAL
- en: Most appropriate function or subdomain
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is important to analyze what would be the most useful component to detach
    from the monolithic application. This is particularly applicable when breaking
    monolithic applications into microservices. This could be based on parameters
    such as resource-intensiveness, cost of ownership, business benefits, or flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: In a typical hotel booking system, approximately 50-60% of the requests are
    search-based. In this case, moving out the search function could immediately bring
    in flexibility, business benefits, cost reduction, resource free up, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Polyglot architecture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the key characteristics of microservices is its support for polyglot
    architecture. In order to meet different non-functional and functional requirements,
    components may require different treatments. It could be different architectures,
    different technologies, different deployment topologies, and so on. When components
    are identified, review them against the requirement for polyglot architectures.
  prefs: []
  type: TYPE_NORMAL
- en: In the hotel booking scenario mentioned earlier, a Booking microservice may
    need transactional integrity, whereas a Search microservice may not. In this case,
    the Booking microservice may use an ACID compliance database such as MySQL, whereas
    the Search microservice may use an eventual consistent database such as Cassandra.
  prefs: []
  type: TYPE_NORMAL
- en: Selective scaling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Selective scaling is related to the previously discussed polyglot architecture.
    In this context, all functional modules may not require the same level of scalability.
    Sometimes, it may be appropriate to determine boundaries based on scalability
    requirements.
  prefs: []
  type: TYPE_NORMAL
- en: For example, in the hotel booking scenario, the Search microservice has to scale
    considerably more than many of the other services such as the Booking microservice
    or the Notification microservice due to the higher velocity of search requests.
    In this case, a separate Search microservice could run on top of an Elasticsearch
    or an in-memory data grid for better response.
  prefs: []
  type: TYPE_NORMAL
- en: Small, agile teams
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Microservices enable Agile development with small, focused teams developing
    different parts of the pie. There could be scenarios where parts of the systems
    are built by different organizations, or even across different geographies, or
    by teams with varying skill sets. This approach is a common practice, for example,
    in manufacturing industries.
  prefs: []
  type: TYPE_NORMAL
- en: In the microservices world, each of these teams builds different microservices,
    and then assembles them together. Though this is not the desired way to break
    down the system, organizations may end up in such situations. Hence, this approach
    cannot be completely ruled out.
  prefs: []
  type: TYPE_NORMAL
- en: In an online product search scenario, a service could provide personalized options
    based on what the customer is looking for. This may require complex machine learning
    algorithms, and hence need a specialist team. In this scenario, this function
    could be built as a microservice by a separate specialist team.
  prefs: []
  type: TYPE_NORMAL
- en: Single responsibility
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In theory, the single responsibility principle could be applied at a method,
    at a class, or at a service. However, in the context of microservices, it does
    not necessarily map to a single service or endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: A more practical approach could be to translate single responsibility into single
    business capability or a single technical capability. As per the *single responsibility*
    principle, one responsibility cannot be shared by multiple microservices. Similarly,
    one microservice should not perform multiple responsibilities.
  prefs: []
  type: TYPE_NORMAL
- en: There could, however, be special cases where a single business capability is
    divided across multiple services. One of such cases is managing the customer profile,
    where there could be situations where you may use two different microservices
    for managing reads and writes using a **Command Query Responsibility Segregation**
    (**CQRS**) approach to achieve some of the quality attributes.
  prefs: []
  type: TYPE_NORMAL
- en: Replicability or changeability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Innovation and speed are of the utmost importance in IT delivery. Microservices
    boundaries should be identified in such a way that each microservice is easily
    detachable from the overall system, with minimal cost of re-writing. If part of
    the system is just an experiment, it should ideally be isolated as a microservice.
  prefs: []
  type: TYPE_NORMAL
- en: An organization may develop a recommendation engine or a customer ranking engine
    as an experiment. If the business value is not realized, then throw away that
    service, or replace it with another one.
  prefs: []
  type: TYPE_NORMAL
- en: Many organizations follow the startup model, where importance is given to meeting
    functions and quick delivery. These organizations may not worry too much about
    the architecture and technologies. Instead, the focus will be on what tools or
    technologies can deliver solutions faster. Organizations increasingly choose the
    approach of developing **Minimum Viable Products** (**MVPs**) by putting together
    a few services, and allowing the system to evolve. Microservices play a vital
    role in such cases where the system evolves, and services gradually get rewritten
    or replaced.
  prefs: []
  type: TYPE_NORMAL
- en: Coupling and cohesion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Coupling and cohesion are two of the most important parameters for deciding
    service boundaries. Dependencies between microservices have to be evaluated carefully
    to avoid highly coupled interfaces. A functional decomposition, together with
    a modeled dependency tree, could help in establishing a microservices boundary.
    Avoiding too chatty services, too many synchronous request-response calls, and
    cyclic synchronous dependencies are three key points, as these could easily break
    the system. A successful equation is to keep high cohesion within a microservice,
    and loose coupling between microservices. In addition to this, ensure that transaction
    boundaries are not stretched across microservices. A first class microservice
    will react upon receiving an event as an input, execute a number of internal functions,
    and finally send out another event. As part of the compute function, it may read
    and write data to its own local store.
  prefs: []
  type: TYPE_NORMAL
- en: Think microservice as a product
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: DDD also recommends mapping a bounded context to a product. As per DDD, each
    bounded context is an ideal candidate for a product. Think about a microservice
    as a product by itself. When microservice boundaries are established, assess them
    from a product's point of view to see whether they really stack up as product.
    It is much easier for business users to think boundaries from a product point
    of view. A product boundary may have many parameters, such as a targeted community,
    flexibility in deployment, sell-ability, reusability, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Designing communication styles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Communication between microservices can be designed either in synchronous (request-response)
    or asynchronous (fire and forget) styles.
  prefs: []
  type: TYPE_NORMAL
- en: Synchronous style communication
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following diagram shows an example request/response style service:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Synchronous style communication](img/B05447_03_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In synchronous communication, there is no shared state or object. When a caller
    requests a service, it passes the required information and waits for a response.
    This approach has a number of advantages.
  prefs: []
  type: TYPE_NORMAL
- en: An application is stateless, and from a high availability standpoint, many active
    instances can be up and running, accepting traffic. Since there are no other infrastructure
    dependencies such as a shared messaging server, there are management fewer overheads.
    In case of an error at any stage, the error will be propagated back to the caller
    immediately, leaving the system in a consistent state, without compromising data
    integrity.
  prefs: []
  type: TYPE_NORMAL
- en: The downside in a synchronous request-response communication is that the user
    or the caller has to wait until the requested process gets completed. As a result,
    the calling thread will wait for a response, and hence, this style could limit
    the scalability of the system.
  prefs: []
  type: TYPE_NORMAL
- en: A synchronous style adds hard dependencies between microservices. If one service
    in the service chain fails, then the entire service chain will fail. In order
    for a service to succeed, all dependent services have to be up and running. Many
    of the failure scenarios have to be handled using timeouts and loops.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous style communication
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following diagram is a service designed to accept an asynchronous message
    as input, and send the response asynchronously for others to consume:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Asynchronous style communication](img/B05447_03_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The asynchronous style is based on reactive event loop semantics which decouple
    microservices. This approach provides higher levels of scalability, because services
    are independent, and can internally spawn threads to handle an increase in load.
    When overloaded, messages will be queued in a messaging server for later processing.
    That means that if there is a slowdown in one of the services, it will not impact
    the entire chain. This provides higher levels of decoupling between services,
    and therefore maintenance and testing will be simpler.
  prefs: []
  type: TYPE_NORMAL
- en: The downside is that it has a dependency to an external messaging server. It
    is complex to handle the fault tolerance of a messaging server. Messaging typically
    works with an active/passive semantics. Hence, handling continuous availability
    of messaging systems is harder to achieve. Since messaging typically uses persistence,
    a higher level of I/O handling and tuning is required.
  prefs: []
  type: TYPE_NORMAL
- en: How to decide which style to choose?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Both approaches have their own merits and constraints. It is not possible to
    develop a system with just one approach. A combination of both approaches is required
    based on the use cases. In principle, the asynchronous approach is great for building
    true, scalable microservice systems. However, attempting to model everything as
    asynchronous leads to complex system designs.
  prefs: []
  type: TYPE_NORMAL
- en: How does the following example look in the context where an end user clicks
    on a UI to get profile details?
  prefs: []
  type: TYPE_NORMAL
- en: '![How to decide which style to choose?](img/B05447_03_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This is perhaps a simple query to the backend system to get a result in a request-response
    model. This can also be modeled in an asynchronous style by pushing a message
    to an input queue, and waiting for a response in an output queue till a response
    is received for the given correlation ID. However, though we use asynchronous
    messaging, the user is still blocked for the entire duration of the query.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another use case is that of a user clicking on a UI to search hotels, which
    is depicted in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to decide which style to choose?](img/B05447_03_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This is very similar to the previous scenario. However, in this case, we assume
    that this business function triggers a number of activities internally before
    returning the list of hotels back to the user. For example, when the system receives
    this request, it calculates the customer ranking, gets offers based on the destination,
    gets recommendations based on customer preferences, optimizes the prices based
    on customer values and revenue factors, and so on. In this case, we have an opportunity
    to do many of these activities in parallel so that we can aggregate all these
    results before presenting them to the customer. As shown in the preceding diagram,
    virtually any computational logic could be plugged in to the search pipeline listening
    to the **IN** queue.
  prefs: []
  type: TYPE_NORMAL
- en: An effective approach in this case is to start with a synchronous request response,
    and refactor later to introduce an asynchronous style when there is value in doing
    that.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example shows a fully asynchronous style of service interactions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to decide which style to choose?](img/B05447_03_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The service is triggered when the user clicks on the booking function. It is
    again, by nature, a synchronous style communication. When booking is successful,
    it sends a message to the customer's e-mail address, sends a message to the hotel's
    booking system, updates the cached inventory, updates the loyalty points system,
    prepares an invoice, and perhaps more. Instead of pushing the user into a long
    wait state, a better approach is to break the service into pieces. Let the user
    wait till a booking record is created by the Booking Service. On successful completion,
    a booking event will be published, and return a confirmation message back to the
    user. Subsequently, all other activities will happen in parallel, asynchronously.
  prefs: []
  type: TYPE_NORMAL
- en: In all three examples, the user has to wait for a response. With the new web
    application frameworks, it is possible to send requests asynchronously, and define
    the callback method, or set an observer for getting a response. Therefore, the
    users won't be fully blocked from executing other activities.
  prefs: []
  type: TYPE_NORMAL
- en: In general, an asynchronous style is always better in the microservices world,
    but identifying the right pattern should be purely based on merits. If there are
    no merits in modeling a transaction in an asynchronous style, then use the synchronous
    style till you find an appealing case. Use reactive programming frameworks to
    avoid complexity when modeling user-driven requests, modeled in an asynchronous
    style.
  prefs: []
  type: TYPE_NORMAL
- en: Orchestration of microservices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Composability is one of the service design principles. This leads to confusion
    around who is responsible for the composing services. In the SOA world, ESBs are
    responsible for composing a set of finely-grained services. In some organizations,
    ESBs play the role of a proxy, and service providers themselves compose and expose
    coarse-grained services. In the SOA world, there are two approaches for handling
    such situations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first approach is orchestration, which is depicted in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Orchestration of microservices](img/B05447_03_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the orchestration approach, multiple services are stitched together to get
    a complete function. A central brain acts as the orchestrator. As shown in the
    diagram, the order service is a composite service that will orchestrate other
    services. There could be sequential as well as parallel branches from the master
    process. Each task will be fulfilled by an atomic task service, typically a web
    service. In the SOA world, ESBs play the role of orchestration. The orchestrated
    service will be exposed by ESBs as a composite service.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second approach is choreography, which is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Orchestration of microservices](img/B05447_03_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the choreography approach, there is no central brain. An event, a booking
    event in this case, is published by a producer, a number of consumers wait for
    the event, and independently apply different logics on the incoming event. Sometimes,
    events could even be nested where the consumers can send another event which will
    be consumed by another service. In the SOA world, the caller pushes a message
    to the ESB, and the downstream flow will be automatically determined by the consuming
    services.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices are autonomous. This essentially means that in an ideal situation,
    all required components to complete their function should be within the service.
    This includes the database, orchestration of its internal services, intrinsic
    state management, and so on. The service endpoints provide coarse-grained APIs.
    This is perfectly fine as long as there are no external touch points required.
    But in reality, microservices may need to talk to other microservices to fulfil
    their function.
  prefs: []
  type: TYPE_NORMAL
- en: In such cases, choreography is the preferred approach for connecting multiple
    microservices together. Following the autonomy principle, a component sitting
    outside a microservice and controlling the flow is not the desired option. If
    the use case can be modeled in choreographic style, that would be the best possible
    way to handle the situation.
  prefs: []
  type: TYPE_NORMAL
- en: 'But it may not be possible to model choreography in all cases. This is depicted
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Orchestration of microservices](img/B05447_03_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding example, Reservation and Customer are two microservices, with
    clearly segregated functional responsibilities. A case could arise when Reservation
    would want to get Customer preferences while creating a reservation. These are
    quite normal scenarios when developing complex systems.
  prefs: []
  type: TYPE_NORMAL
- en: Can we move Customer to Reservation so that Reservation will be complete by
    itself? If Customer and Reservation are identified as two microservices based
    on various factors, it may not be a good idea to move Customer to Reservation.
    In such a case, we will meet another monolithic application sooner or later.
  prefs: []
  type: TYPE_NORMAL
- en: 'Can we make the Reservation to Customer call asynchronous? This example is
    shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Orchestration of microservices](img/B05447_03_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Customer preference is required for Reservation to progress, and hence, it may
    require a synchronous blocking call to Customer. Retrofitting this by modeling
    asynchronously does not really make sense.
  prefs: []
  type: TYPE_NORMAL
- en: Can we take out just the orchestration bit, and create another composite microservice,
    which then composes Reservation and Customer?
  prefs: []
  type: TYPE_NORMAL
- en: '![Orchestration of microservices](img/B05447_03_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This is acceptable in the approach for composing multiple components within
    a microservice. But creating a composite microservice may not be a good idea.
    We will end up creating many microservices with no business alignment, which would
    not be autonomous, and could result in many fine-grained microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Can we duplicate customer preference by keeping a slave copy of the preference
    data into Reservation?
  prefs: []
  type: TYPE_NORMAL
- en: '![Orchestration of microservices](img/B05447_03_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Changes will be propagated whenever there is a change in the master. In this
    case, Reservation can use customer preference without fanning out a call. It is
    a valid thought, but we need to carefully analyze this. Today we replicate customer
    preference, but in another scenario, we may want to reach out to customer service
    to see whether the customer is black-listed from reserving. We have to be extremely
    careful in deciding what data to duplicate. This could add to the complexity.
  prefs: []
  type: TYPE_NORMAL
- en: How many endpoints in a microservice?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In many situations, developers are confused with the number of endpoints per
    microservice. The question really is whether to limit each microservice with one
    endpoint or multiple endpoints:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How many endpoints in a microservice?](img/B05447_03_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The number of endpoints is not really a decision point. In some cases, there
    may be only one endpoint, whereas in some other cases, there could be more than
    one endpoint in a microservice. For instance, consider a sensor data service which
    collects sensor information, and has two logical endpoints: create and read. But
    in order to handle CQRS, we may create two separate physical microservices as
    shown in the case of **Booking** in the preceding diagram. Polyglot architecture
    could be another scenario where we may split endpoints into different microservices.'
  prefs: []
  type: TYPE_NORMAL
- en: Considering a notification engine, notifications will be send out in response
    to an event. The process of notification such as preparation of data, identification
    of a person, and delivery mechanisms, are different for different events. Moreover,
    we may want to scale each of these processes differently at different time windows.
    In such situations, we may decide to break each notification endpoint in to a
    separate microservice.
  prefs: []
  type: TYPE_NORMAL
- en: In yet another example, a Loyalty Points microservice may have multiple services
    such as accrue, redeem, transfer, and balance. We may not want to treat each of
    these services differently. All of these services are connected and use the points
    table for data. If we go with one endpoint per service, we will end up in a situation
    where many fine-grained services access data from the same data store or replicated
    copies of the same data store.
  prefs: []
  type: TYPE_NORMAL
- en: In short, the number of endpoints is not a design decision. One microservice
    may host one or more endpoints. Designing appropriate bounded context for a microservice
    is more important.
  prefs: []
  type: TYPE_NORMAL
- en: One microservice per VM or multiple?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One microservice could be deployed in multiple **Virtual Machines** (**VMs**)
    by replicating the deployment for scalability and availability. This is a no brainer.
    The question is whether multiple microservices could be deployed in one virtual
    machine? There are pros and cons for this approach. This question typically arises
    when the services are simple, and the traffic volume is less.
  prefs: []
  type: TYPE_NORMAL
- en: Consider an example where we have a couple of microservices, and the overall
    transaction per minute is less than 10\. Also assume that the smallest possible
    VM size available is 2-core 8 GB RAM. A further assumption is that in such cases,
    a 2-core 8 GB VM can handle 10-15 transactions per minute without any performance
    concerns. If we use different VMs for each microservice, it may not be cost effective,
    and we will end up paying more for infrastructure and license, since many vendors
    charge based on the number of cores.
  prefs: []
  type: TYPE_NORMAL
- en: 'The simplest way to approach this problem is to ask a few questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Does the VM have enough capacity to run both services under peak usage?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do we want to treat these services differently to achieve SLAs (selective scaling)?
    For example, for scalability, if we have an all-in-one VM, we will have to replicate
    VMs which replicate all services.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are there any conflicting resource requirements? For example, different OS versions,
    JDK versions, and others.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If all your answers are *No*, then perhaps we can start with collocated deployment,
    until we encounter a scenario to change the deployment topology. However, we will
    have to ensure that these services are not sharing anything, and are running as
    independent OS processes.
  prefs: []
  type: TYPE_NORMAL
- en: Having said that, in an organization with matured virtualized infrastructure
    or cloud infrastructure, this may not be a huge concern. In such environments,
    the developers need not worry about where the services are running. Developers
    may not even think about capacity planning. Services will be deployed in a compute
    cloud. Based on the infrastructure availability, SLAs and the nature of the service,
    the infrastructure self-manages deployments. AWS Lambda is a good example of such
    a service.
  prefs: []
  type: TYPE_NORMAL
- en: Rules engine – shared or embedded?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Rules are an essential part of any system. For example, an offer eligibility
    service may execute a number of rules before making a yes or no decision. Either
    we hand code rules, or we may use a rules engine. Many enterprises manage rules
    centrally in a rules repository as well as execute them centrally. These enterprise
    rule engines are primarily used for providing the business an opportunity to author
    and manage rules as well as reuse rules from the central repository. **Drools**
    is one of the popular open source rules engines. IBM, FICO, and Bosch are some
    of the pioneers in the commercial space. These rule engines improve productivity,
    enable reuse of rules, facts, vocabularies, and provide faster rule execution
    using the rete algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the context of microservices, a central rules engine means fanning out calls
    from microservices to the central rules engine. This also means that the service
    logic is now in two places, some within the service, and some external to the
    service. Nevertheless, the objective in the context of microservices is to reduce
    external dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Rules engine – shared or embedded?](img/B05447_03_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If the rules are simple enough, few in numbers, only used within the boundaries
    of a service, and not exposed to business users for authoring, then it may be
    better to hand-code business rules than rely on an enterprise rule engine:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Rules engine – shared or embedded?](img/B05447_03_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If the rules are complex, limited to a service context, and not given to business
    users, then it is better to use an embedded rules engine within the service:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Rules engine – shared or embedded?](img/B05447_03_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: If the rules are managed and authored by business, or if the rules are complex,
    or if we are reusing rules from other service domains, then a central authoring
    repository with a locally embedded execution engine could be a better choice.
  prefs: []
  type: TYPE_NORMAL
- en: Note that this has to be carefully evaluated since all vendors may not support
    the local rule execution approach, and there could be technology dependencies
    such as running rules only within a specific application server, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Role of BPM and workflows
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Business Process Management** (**BPM**) and **Intelligent Business Process
    Management** (**iBPM**) are tool suites for designing, executing, and monitoring
    business processes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Typical use cases for BPM are:'
  prefs: []
  type: TYPE_NORMAL
- en: Coordinating a long-running business process, where some processes are realized
    by existing assets, whereas some other areas may be niche, and there is no concrete
    implementation of the processes being in place. BPM allows composing both types,
    and provides an end-to-end automated process. This often involves systems and
    human interactions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Process-centric organizations, such as those that have implemented Six Sigma,
    want to monitor their processes for continuous improvement on efficiency.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Process re-engineering with a top-down approach by redefining the business process
    of an organization.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There could be two scenarios where BPM fits in the microservices world:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Role of BPM and workflows](img/B05447_03_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The first scenario is business process re-engineering, or threading an end-to-end
    long running business process, as stated earlier. In this case, BPM operates at
    a higher level, where it may automate a cross-functional, long-running business
    process by stitching a number of coarse-grained microservices, existing legacy
    connectors, and human interactions. As shown in the preceding diagram, the loan
    approval BPM invokes microservices as well as legacy application services. It
    also integrates human tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, microservices are headless services that implement a subprocess.
    From the microservices'' perspective, BPM is just another consumer. Care needs
    to be taken in this approach to avoid accepting a shared state from a BPM process
    as well as moving business logic to BPM:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Role of BPM and workflows](img/B05447_03_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The second scenario is monitoring processes, and optimizing them for efficiency.
    This goes hand in hand with a completely automated, asynchronously choreographed
    microservices ecosystem. In this case, microservices and BPM work as independent
    ecosystems. Microservices send events at various timeframes such as the start
    of a process, state changes, end of a process, and so on. These events are used
    by the BPM engine to plot and monitor process states. We may not require a full-fledged
    BPM solution for this, as we are only mocking a business process to monitor its
    efficiency. In this case, the order delivery process is not a BPM implementation,
    but it is more of a monitoring dashboard that captures and displays the progress
    of the process.
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, BPM could still be used at a higher level for composing multiple
    microservices in situations where end-to-end cross-functional business processes
    are modeled by automating systems and human interactions. A better and simpler
    approach is to have a business process dashboard to which microservices feed state
    change events as mentioned in the second scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Can microservices share data stores?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In principle, microservices should abstract presentation, business logic, and
    data stores. If the services are broken as per the guidelines, each microservice
    logically could use an independent database:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Can microservices share data stores?](img/B05447_03_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding diagram, both **Product** and **Order** microservices share
    one database and one data model. Shared data models, shared schema, and shared
    tables are recipes for disasters when developing microservices. This may be good
    at the beginning, but when developing complex microservices, we tend to add relationships
    between data models, add join queries, and so on. This can result in tightly coupled
    physical data models.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the services have only a few tables, it may not be worth investing a full
    instance of a database like an Oracle database instance. In such cases, a schema
    level segregation is good enough to start with:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Can microservices share data stores?](img/B05447_03_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'There could be scenarios where we tend to think of using a shared database
    for multiple services. Taking an example of a customer data repository or master
    data managed at the enterprise level, the customer registration and customer segmentation
    microservices logically share the same customer data repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Can microservices share data stores?](img/B05447_03_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As shown in the preceding diagram, an alternate approach in this scenario is
    to separate the transactional data store for microservices from the enterprise
    data repository by adding a local transactional data store for these services.
    This will help the services to have flexibility in remodeling the local data store
    optimized for its purpose. The enterprise customer repository sends change events
    when there is any change in the customer data repository. Similarly, if there
    is any change in any of the transactional data stores, the changes have to be
    sent to the central customer repository.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up transaction boundaries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Transactions in operational systems are used to maintain the consistency of
    data stored in an RDBMS by grouping a number of operations together into one atomic
    block. They either commit or rollback the entire operation. Distributed systems
    follow the concept of distributed transactions with a two-phase commit. This is
    particularly required if heterogeneous components such as an RPC service, JMS,
    and so on participate in a transaction.
  prefs: []
  type: TYPE_NORMAL
- en: Is there a place for transactions in microservices? Transactions are not bad,
    but one should use transactions carefully, by analyzing what we are trying do.
  prefs: []
  type: TYPE_NORMAL
- en: For a given microservice, an RDBMS like MySQL may be selected as a backing store
    to ensure 100% data integrity, for example, a stock or inventory management service
    where data integrity is key. It is appropriate to define transaction boundaries
    within the microsystem using local transactions. However, distributed global transactions
    should be avoided in the microservices context. Proper dependency analysis is
    required to ensure that transaction boundaries do not span across two different
    microservices as much as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Altering use cases to simplify transactional requirements
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Eventual consistency is a better option than distributed transactions that span
    across multiple microservices. Eventual consistency reduces a lot of overheads,
    but application developers may need to re-think the way they write application
    code. This could include remodeling functions, sequencing operations to minimize
    failures, batching insert and modify operations, remodeling data structure, and
    finally, compensating operations that negate the effect.
  prefs: []
  type: TYPE_NORMAL
- en: A classical problem is that of the last room selling scenario in a hotel booking
    use case. What if there is only one room left, and there are multiple customers
    booking this singe available room? A business model change sometimes makes this
    scenario less impactful. We could set an "under booking profile", where the actual
    number of bookable rooms can go below the actual number of rooms (*bookable =
    available - 3*) in anticipation of some cancellations. Anything in this range
    will be accepted as "subject to confirmation", and customers will be charged only
    if payment is confirmed. Bookings will be confirmed in a set time window.
  prefs: []
  type: TYPE_NORMAL
- en: Now consider the scenario where we are creating customer profiles in a NoSQL
    database like CouchDB. In more traditional approaches with RDBMS, we insert a
    customer first, and then insert the customer's address, profile details, then
    preferences, all in one transaction. When using NoSQL, we may not do the same
    steps. Instead, we may prepare a JSON object with all the details, and insert
    this into CouchDB in one go. In this second case, no explicit transaction boundaries
    are required.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed transaction scenarios
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The ideal scenario is to use local transactions within a microservice if required,
    and completely avoid distributed transactions. There could be scenarios where
    at the end of the execution of one service, we may want to send a message to another
    microservice. For example, say a tour reservation has a wheelchair request. Once
    the reservation is successful, we will have to send a message for the wheelchair
    booking to another microservice that handles ancillary bookings. The reservation
    request itself will run on a local transaction. If sending this message fails,
    we are still in the transaction boundary, and we can roll back the entire transaction.
    What if we create a reservation and send the message, but after sending the message,
    we encounter an error in the reservation, the reservation transaction fails, and
    subsequently, the reservation record is rolled back? Now we end up in a situation
    where we''ve unnecessarily created an orphan wheelchair booking:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Distributed transaction scenarios](img/B05447_03_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: There are a couple of ways we can address this scenario. The first approach
    is to delay sending the message till the end. This ensures that there are less
    chances for any failure after sending the message. Still, if failure occurs after
    sending the message, then the exception handling routine is run, that is, we send
    a compensating message to reverse the wheelchair booking.
  prefs: []
  type: TYPE_NORMAL
- en: Service endpoint design consideration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the important aspects of microservices is service design. Service design
    has two key elements: contract design and protocol selection.'
  prefs: []
  type: TYPE_NORMAL
- en: Contract design
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first and foremost principle of service design is simplicity. The services
    should be designed for consumers to consume. A complex service contract reduces
    the usability of the service. The **KISS** (**Keep It Simple Stupid**) principle
    helps us to build better quality services faster, and reduces the cost of maintenance
    and replacement. The **YAGNI** (**You Ain't Gonna Need It**) is another principle
    supporting this idea. Predicting future requirements and building systems are,
    in reality, not future-proofed. This results in large upfront investment as well
    as higher cost of maintenance.
  prefs: []
  type: TYPE_NORMAL
- en: Evolutionary design is a great concept. Do just enough design to satisfy today's
    wants, and keep changing and refactoring the design to accommodate new features
    as and when they are required. Having said that, this may not be simple unless
    there is a strong governance in place.
  prefs: []
  type: TYPE_NORMAL
- en: '**Consumer Driven Contracts** (**CDC**) is a great idea that supports evolutionary
    design. In many cases, when the service contract gets changed, all consuming applications
    have to undergo testing. This makes change difficult. CDC helps in building confidence
    in consumer applications. CDC advocates each consumer to provide their expectation
    to the provider in the form of test cases so that the provider uses them as integration
    tests whenever the service contract is changed.'
  prefs: []
  type: TYPE_NORMAL
- en: Postel's law is also relevant in this scenario. Postel's law primarily addresses
    TCP communications; however, this is also equally applicable to service design.
    When it comes to service design, service providers should be as flexible as possible
    when accepting consumer requests, whereas service consumers should stick to the
    contract as agreed with the provider.
  prefs: []
  type: TYPE_NORMAL
- en: Protocol selection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the SOA world, HTTP/SOAP, and messaging were kinds of default service protocols
    for service interactions. Microservices follow the same design principles for
    service interaction. Loose coupling is one of the core principles in the microservices
    world too.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices fragment applications into many physically independent deployable
    services. This not only increases the communication cost, it is also susceptible
    to network failures. This could also result in poor performance of services.
  prefs: []
  type: TYPE_NORMAL
- en: Message-oriented services
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If we choose an asynchronous style of communication, the user is disconnected,
    and therefore, response times are not directly impacted. In such cases, we may
    use standard JMS or AMQP protocols for communication with JSON as payload. Messaging
    over HTTP is also popular, as it reduces complexity. Many new entrants in messaging
    services support HTTP-based communication. Asynchronous REST is also possible,
    and is handy when calling long-running services.
  prefs: []
  type: TYPE_NORMAL
- en: HTTP and REST endpoints
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Communication over HTTP is always better for interoperability, protocol handling,
    traffic routing, load balancing, security systems, and the like. Since HTTP is
    stateless, it is more compatible for handling stateless services with no affinity.
    Most of the development frameworks, testing tools, runtime containers, security
    systems, and so on are friendlier towards HTTP.
  prefs: []
  type: TYPE_NORMAL
- en: With the popularity and acceptance of REST and JSON, it is the default choice
    for microservice developers. The HTTP/REST/JSON protocol stack makes building
    interoperable systems very easy and friendly. HATEOAS is one of the design patterns
    emerging for designing progressive rendering and self-service navigations. As
    discussed in the previous chapter, HATEOAS provides a mechanism to link resources
    together so that the consumer can navigate between resources. RFC 5988 – Web Linking
    is another upcoming standard.
  prefs: []
  type: TYPE_NORMAL
- en: Optimized communication protocols
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If the service response times are stringent, then we need to pay special attention
    to the communication aspects. In such cases, we may choose alternate protocols
    such as Avro, Protocol Buffers, or Thrift for communicating between services.
    But this limits the interoperability of services. The trade-off is between performance
    and interoperability requirements. Custom binary protocols need careful evaluation
    as they bind native objects on both sides—consumer and producer. This could run
    into release management issues such as class version mismatch in Java-based RPC
    style communications.
  prefs: []
  type: TYPE_NORMAL
- en: API documentations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Last thing: a good API is not only simple, but should also have enough documentation
    for the consumers. There are many tools available today for documenting REST-based
    services like Swagger, RAML, and API Blueprint.'
  prefs: []
  type: TYPE_NORMAL
- en: Handling shared libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The principle behind microservices is that they should be autonomous and self-contained.
    In order to adhere to this principle, there may be situations where we will have
    to duplicate code and libraries. These could be either technical libraries or
    functional components.
  prefs: []
  type: TYPE_NORMAL
- en: '![Handling shared libraries](img/B05447_03_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: For example, the eligibility for a flight upgrade will be checked at the time
    of check-in as well as when boarding. If check-in and boarding are two different
    microservices, we may have to duplicate the eligibility rules in both the services.
    This was the trade-off between adding a dependency versus code duplication.
  prefs: []
  type: TYPE_NORMAL
- en: It may be easy to embed code as compared to adding an additional dependency,
    as it enables better release management and performance. But this is against the
    DRY principle.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**DRY principle**'
  prefs: []
  type: TYPE_NORMAL
- en: Every piece of knowledge must have a single, unambiguous, authoritative representation
    within a system.
  prefs: []
  type: TYPE_NORMAL
- en: 'The downside of this approach is that in case of a bug or an enhancement on
    the shared library, it has to be upgraded in more than one place. This may not
    be a severe setback as each service can contain a different version of the shared
    library:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Handling shared libraries](img/B05447_03_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: An alternative option of developing the shared library as another microservice
    itself needs careful analysis. If it is not qualified as a microservice from the
    business capability point of view, then it may add more complexity than its usefulness.
    The trade-off analysis is between overheads in communication versus duplicating
    the libraries in multiple services.
  prefs: []
  type: TYPE_NORMAL
- en: User interfaces in microservices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The microservices principle advocates a microservice as a vertical slice from
    the database to presentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![User interfaces in microservices](img/B05447_03_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In reality, we get requirements to build quick UI and mobile applications mashing
    up the existing APIs. This is not uncommon in the modern scenario, where a business
    wants quick turnaround time from IT:'
  prefs: []
  type: TYPE_NORMAL
- en: '![User interfaces in microservices](img/B05447_03_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Penetration of mobile applications is one of the causes of this approach. In
    many organizations, there will be mobile development teams sitting close to the
    business team, developing rapid mobile applications by combining and mashing up
    APIs from multiple sources, both internal and external. In such situations, we
    may just expose services, and leave it for the mobile teams to realize in the
    way the business wants. In this case, we will build headless microservices, and
    leave it to the mobile teams to build a presentation layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another category of problem is that the business may want to build consolidated
    web applications targeted to communities:'
  prefs: []
  type: TYPE_NORMAL
- en: '![User interfaces in microservices](img/B05447_03_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: For example, the business may want to develop a departure control application
    targeting airport users. A departure control web application may have functions
    such as check-in, lounge management, boarding, and so on. These may be designed
    as independent microservices. But from the business standpoint, it all needs to
    be clubbed into a single web application. In such cases, we will have to build
    web applications by mashing up services from the backend.
  prefs: []
  type: TYPE_NORMAL
- en: One approach is to build a container web application or a placeholder web application,
    which links to multiple microservices at the backend. In this case, we develop
    full stack microservices, but the screens coming out of this could be embedded
    in to another placeholder web application. One of the advantages of this approach
    is that you can have multiple placeholder web applications targeting different
    user communities, as shown in the preceding diagram. We may use an API gateway
    to avoid those crisscross connections. We will explore the API gateway in the
    next section.
  prefs: []
  type: TYPE_NORMAL
- en: Use of API gateways in microservices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the advancement of client-side JavaScript frameworks like AngularJS, the
    server is expected to expose RESTful services. This could lead to two issues.
    The first issue is the mismatch in contract expectations. The second issue is
    multiple calls to the server to render a page.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start with the contract mismatch case. For example, `GetCustomer` may return
    a JSON with many fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding case, `Name`, `Address`, and `Contact` are nested JSON objects.
    But a mobile client may expect only basic information such as first name, and
    last name. In the SOA world, an ESB or a mobile middleware did this job of transformation
    of data for the client. The default approach in microservices is to get all the
    elements of `Customer`, and then the client takes up the responsibility to filter
    the elements. In this case, the overhead is on the network.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several approaches we can think about to solve this case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In the first approach, minimal information is sent with links as explained in
    the section on HATEOAS. In the preceding case, for customer ID `1`, there are
    three links, which will help the client to access specific data elements. The
    example is a simple logical representation, not the actual JSON. The mobile client
    in this case will get basic customer information. The client further uses the
    links to get the additional required information.
  prefs: []
  type: TYPE_NORMAL
- en: The second approach is used when the client makes the REST call; it also sends
    the required fields as part of the query string. In this scenario, the client
    sends a request with `firstname` and `lastname` as the query string to indicate
    that the client only requires these two fields. The downside is that it ends up
    in complex server-side logic as it has to filter based on the fields. The server
    has to send different elements based on the incoming query.
  prefs: []
  type: TYPE_NORMAL
- en: 'The third approach is to introduce a level of indirection. In this, a gateway
    component sits between the client and the server, and transforms data as per the
    consumer''s specification. This is a better approach as we do not compromise on
    the backend service contract. This leads to what is called UI services. In many
    cases, the API gateway acts as a proxy to the backend, exposing a set of consumer-specific
    APIs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Use of API gateways in microservices](img/B05447_03_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: There are two ways we can deploy an API gateway. The first one is one API gateway
    per microservice as shown in diagram **A**. The second approach (diagram **B**)
    is to have a common API gateway for multiple services. The choice really depends
    on what we are looking for. If we are using an API gateway as a reverse proxy,
    then off-the-shelf gateways such as Apigee, Mashery, and the like could be used
    as a shared platform. If we need fine-grained control over traffic shaping and
    complex transformations, then per service custom API gateways may be more useful.
  prefs: []
  type: TYPE_NORMAL
- en: A related problem is that we will have to make many calls from the client to
    the server. If we refer to our holiday example in [Chapter 1](ch01.html "Chapter 1. Demystifying
    Microservices"), *Demystifying Microservices*, you know that for rendering each
    widget, we had to make a call to the server. Though we transfer only data, it
    can still add a significant overhead on the network. This approach is not fully
    wrong, as in many cases, we use responsive design and progressive design. The
    data will be loaded on demand, based on user navigations. In order to do this,
    each widget in the client should make independent calls to the server in a lazy
    mode. If bandwidth is an issue, then an API gateway is the solution. An API gateway
    acts as a middleman to compose and transform APIs from multiple microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Use of ESB and iPaaS with microservices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Theoretically, SOA is not all about ESBs, but the reality is that ESBs have
    always been at the center of many SOA implementations. What would be the role
    of an ESB in the microservices world?
  prefs: []
  type: TYPE_NORMAL
- en: In general, microservices are fully cloud native systems with smaller footprints.
    The lightweight characteristics of microservices enable automation of deployments,
    scaling, and so on. On the contrary, enterprise ESBs are heavyweight in nature,
    and most of the commercial ESBs are not cloud friendly. The key features of an
    ESB are protocol mediation, transformation, orchestration, and application adaptors.
    In a typical microservices ecosystem, we may not need any of these features.
  prefs: []
  type: TYPE_NORMAL
- en: The limited ESB capabilities that are relevant for microservices are already
    available with more lightweight tools such as an API gateway. Orchestration is
    moved from the central bus to the microservices themselves. Therefore, there is
    no centralized orchestration capability expected in the case of microservices.
    Since the services are set up to accept more universal message exchange styles
    using REST/JSON calls, no protocol mediation is required. The last piece of capability
    that we get from ESBs are the adaptors to connect back to the legacy systems.
    In the case of microservices, the service itself provides a concrete implementation,
    and hence, there are no legacy connectors required. For these reasons, there is
    no natural space for ESBs in the microservices world.
  prefs: []
  type: TYPE_NORMAL
- en: Many organizations established ESBs as the backbone for their application integrations
    (EAI). Enterprise architecture policies in such organizations are built around
    ESBs. There could be a number of enterprise-level policies such as auditing, logging,
    security, validation, and so on that would have been in place when integrating
    using ESB. Microservices, however, advocate a more decentralized governance. ESBs
    will be an overkill if integrated with microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Not all services are microservices. Enterprises have legacy applications, vendor
    applications, and so on. Legacy services use ESBs to connect with microservices.
    ESBs still hold their place for legacy integration and vendor applications to
    integrate at the enterprise level.
  prefs: []
  type: TYPE_NORMAL
- en: With the advancement of clouds, the capabilities of ESBs are not sufficient
    to manage integration between clouds, cloud to on-premise, and so on. **Integration
    Platform as a Service** (**iPaaS**) is evolving as the next generation application
    integration platform, which further reduces the role of ESBs. In typical deployments,
    iPaaS invokes API gateways to access microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Service versioning considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we allow services to evolve, one of the important aspect to consider is
    service versioning. Service versioning should be considered upfront, and not as
    an afterthought. Versioning helps us to release new services without breaking
    the existing consumers. Both the old version and the new version will be deployed
    side by side.
  prefs: []
  type: TYPE_NORMAL
- en: 'Semantic versions are widely used for service versioning. A semantic version
    has three components: **major**, **minor**, and **patch**. Major is used when
    there is a breaking change, minor is used when there is a backward compatible
    change, and patch is used when there is a backward compatible bug fix.'
  prefs: []
  type: TYPE_NORMAL
- en: Versioning could get complicated when there is more than one service in a microservice.
    It is always simple to version services at the service level compared to the operations
    level. If there is a change in one of the operations, the service is upgraded
    and deployed to V2\. The version change is applicable to all operations in the
    service. This is the notion of immutable services.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three different ways in which we can version REST services:'
  prefs: []
  type: TYPE_NORMAL
- en: URI versioning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Media type versioning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Custom header
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In URI versioning, the version number is included in the URL itself. In this
    case, we just need to be worried about the major versions only. Hence, if there
    is a minor version change or a patch, the consumers do not need to worry about
    the changes. It is a good practice to alias the latest version to a non-versioned
    URI, which is done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'A slightly different approach is to use the version number as part of the URL
    parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In case of media type versioning, the version is set by the client on the HTTP
    `Accept` header as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'A less effective approach for versioning is to set the version in the custom
    header:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In the URI approach, it is simple for the clients to consume services. But this
    has some inherent issues such as the fact that versioning-nested URI resources
    could be complex. Indeed, migrating clients is slightly complex as compared to
    media type approaches, with caching issues for multiple versions of the services,
    and others. However, these issues are not significant enough for us to not go
    with a URI approach. Most of the big Internet players such as Google, Twitter,
    LinkedIn, and Salesforce are following the URI approach.
  prefs: []
  type: TYPE_NORMAL
- en: Design for cross origin
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With microservices, there is no guarantee that the services will run from the
    same host or same domain. Composite UI web applications may call multiple microservices
    for accomplishing a task, and these could come from different domains and hosts.
  prefs: []
  type: TYPE_NORMAL
- en: CORS allows browser clients to send requests to services hosted on different
    domains. This is essential in a microservices-based architecture.
  prefs: []
  type: TYPE_NORMAL
- en: One approach is to enable all microservices to allow cross origin requests from
    other trusted domains. The second approach is to use an API gateway as a single
    trusted domain for the clients.
  prefs: []
  type: TYPE_NORMAL
- en: Handling shared reference data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When breaking large applications, one of the common issues which we see is the
    management of master data or reference data. Reference data is more like shared
    data required between different microservices. City master, country master, and
    so on will be used in many services such as flight schedules, reservations, and
    others.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few ways in which we can solve this. For instance, in the case
    of relatively static, never changing data, then every service can hardcode this
    data within all the microservices themselves:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Handling shared reference data](img/B05447_03_29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Another approach, as shown in the preceding diagram, is to build it as another
    microservice. This is good, clean, and neat, but the downside is that every service
    may need to call the master data multiple times. As shown in the diagram for the
    **Search** and **Booking** example, there are transactional microservices, which
    use the **Geography** microservice to access shared data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Handling shared reference data](img/B05447_03_30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Another option is to replicate the data with every microservice. There is no
    single owner, but each service has its required master data. When there is an
    update, all the services are updated. This is extremely performance friendly,
    but one has to duplicate the code in all the services. It is also complex to keep
    data in sync across all microservices. This approach makes sense if the code base
    and data is simple or the data is more static.
  prefs: []
  type: TYPE_NORMAL
- en: '![Handling shared reference data](img/B05447_03_31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Yet another approach is similar to the first approach, but each service has
    a local near cache of the required data, which will be loaded incrementally. A
    local embedded cache such as Ehcache or data grids like Hazelcast or Infinispan
    could also be used based on the data volumes. This is the most preferred approach
    for a large number of microservices that have dependency on the master data.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices and bulk operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since we have broken monolithic applications into smaller, focused services,
    it is no longer possible to use join queries across microservice data stores.
    This could lead to situations where one service may need many records from other
    services to perform its function.
  prefs: []
  type: TYPE_NORMAL
- en: '![Microservices and bulk operations](img/B05447_03_32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'For example, a monthly billing function needs the invoices of many customers
    to process the billing. To make it a bit more complicated, invoices may have many
    orders. When we break billing, invoices, and orders into three different microservices,
    the challenge that arises is that the **Billing** service has to query the **Invoices**
    service for each customer to get all the invoices, and then for each invoice,
    call the **Order** service for getting the orders. This is not a good solution,
    as the number of calls that goes to other microservices are high:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Microservices and bulk operations](img/B05447_03_33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: There are two ways we can think about for solving this. The first approach is
    to pre-aggregate data as and when it is created. When an order is created, an
    event is sent out. Upon receiving the event, the **Billing** microservice keeps
    aggregating data internally for monthly processing. In this case, there is no
    need for the **Billing** microservice to go out for processing. The downside of
    this approach is that there is duplication of data.
  prefs: []
  type: TYPE_NORMAL
- en: A second approach, when pre-aggregation is not possible, is to use batch APIs.
    In such cases, we call `GetAllInvoices`, then we use multiple batches, and each
    batch further uses parallel threads to get orders. Spring Batch is useful in these
    situations.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, you learned about the right design decisions to be
    taken, and the trade-offs to be applied. In this section, we will review some
    of the challenges with microservices, and how to address them for a successful
    microservice development.
  prefs: []
  type: TYPE_NORMAL
- en: Data islands
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Microservices abstract their own local transactional store, which is used for
    their own transactional purposes. The type of store and the data structure will
    be optimized for the services offered by the microservice.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if we want to develop a customer relationship graph, we may use
    a graph database like Neo4j, OrientDB, and the like. A predictive text search
    to find out a customer based on any related information such as passport number,
    address, e-mail, phone, and so on could be best realized using an indexed search
    database like Elasticsearch or Solr.
  prefs: []
  type: TYPE_NORMAL
- en: 'This will place us into a unique situation of fragmenting data into heterogeneous
    data islands. For example, Customer, Loyalty Points, Reservations, and others
    are different microservices, and hence, use different databases. What if we want
    to do a near real-time analysis of all high value customers by combining data
    from all three data stores? This was easy with a monolithic application, because
    all the data was present in a single database:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Data islands](img/B05447_03_34.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In order to satisfy this requirement, a data warehouse or a data lake is required.
    Traditional data warehouses like Oracle, Teradata, and others are used primarily
    for batch reporting. But with NoSQL databases (like Hadoop) and microbatching
    techniques, near real-time analytics is possible with the concept of data lakes.
    Unlike the traditional warehouses that are purpose-built for batch reporting,
    data lakes store raw data without assuming how the data is going to be used. Now
    the question really is how to port the data from microservices into data lakes.
  prefs: []
  type: TYPE_NORMAL
- en: Data porting from microservices to a data lake or a data warehouse can be done
    in many ways. Traditional ETL could be one of the options. Since we allow backdoor
    entry with ETL, and break the abstraction, this is not considered an effective
    way for data movement. A better approach is to send events from microservices
    as and when they occur, for example, customer registration, customer update events,
    and so on. Data ingestion tools consume these events, and propagate the state
    change to the data lake appropriately. The data ingestion tools are highly scalable
    platforms such as Spring Cloud Data Flow, Kafka, Flume, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Logging and monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Log files are a good piece of information for analysis and debugging. Since
    each microservice is deployed independently, they emit separate logs, maybe to
    a local disk. This results in fragmented logs. When we scale services across multiple
    machines, each service instance could produce separate log files. This makes it
    extremely difficult to debug and understand the behavior of the services through
    log mining.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examining **Order**, **Delivery**, and **Notification** as three different
    microservices, we find no way to correlate a customer transaction that runs across
    all three of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Logging and monitoring](img/B05447_03_35.jpg)'
  prefs: []
  type: TYPE_IMG
- en: When implementing microservices, we need a capability to ship logs from each
    service to a centrally managed log repository. With this approach, services do
    not have to rely on the local disk or local I/Os. A second advantage is that the
    log files are centrally managed, and are available for all sorts of analysis such
    as historical, real time, and trending. By introducing a correlation ID, end-to-end
    transactions can be easily tracked.
  prefs: []
  type: TYPE_NORMAL
- en: With a large number of microservices, and with multiple versions and service
    instances, it would be difficult to find out which service is running on which
    server, what's the health of these services, the service dependencies, and so
    on. This was much easier with monolithic applications that are tagged against
    a specific or a fixed set of servers.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from understanding the deployment topology and health, it also poses a
    challenge in identifying service behaviors, debugging, and identifying hotspots.
    Strong monitoring capabilities are required to manage such an infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: We will cover the logging and monitoring aspects in [Chapter 7](ch07.html "Chapter 7. Logging
    and Monitoring Microservices"), *Logging and Monitoring Microservices*.
  prefs: []
  type: TYPE_NORMAL
- en: Dependency management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Dependency management is one of the key issues in large microservice deployments.
    How do we identify and reduce the impact of a change? How do we know whether all
    the dependent services are up and running? How will the service behave if one
    of the dependent services is not available?
  prefs: []
  type: TYPE_NORMAL
- en: 'Too many dependencies could raise challenges in microservices. Four important
    design aspects are stated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Reducing dependencies by properly designing service boundaries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reducing impacts by designing dependencies as loosely coupled as possible. Also,
    designing service interactions through asynchronous communication styles.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tackling dependency issues using patterns such as circuit breakers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring dependencies using visual dependency graphs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Organization culture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the biggest challenges in microservices implementation is the organization
    culture. To harness the speed of delivery of microservices, the organization should
    adopt Agile development processes, continuous integration, automated QA checks,
    automated delivery pipelines, automated deployments, and automatic infrastructure
    provisioning.
  prefs: []
  type: TYPE_NORMAL
- en: Organizations following a waterfall development or heavyweight release management
    processes with infrequent release cycles are a challenge for microservices development.
    Insufficient automation is also a challenge for microservices deployment.
  prefs: []
  type: TYPE_NORMAL
- en: In short, Cloud and DevOps are supporting facets of microservice development.
    These are essential for successful microservices implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Governance challenges
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Microservices impose decentralized governance, and this is quite in contrast
    with the traditional SOA governance. Organizations may find it hard to come up
    with this change, and that could negatively impact the microservices development.
  prefs: []
  type: TYPE_NORMAL
- en: There are number of challenges that comes with a decentralized governance model.
    How do we understand who is consuming a service? How do we ensure service reuse?
    How do we define which services are available in the organization? How do we ensure
    enforcement of enterprise polices?
  prefs: []
  type: TYPE_NORMAL
- en: The first thing is to have a set of standards, best practices, and guidelines
    on how to implement better services. These should be available to the organization
    in the form of standard libraries, tools, and techniques. This ensures that the
    services developed are top quality, and that they are developed in a consistent
    manner.
  prefs: []
  type: TYPE_NORMAL
- en: The second important consideration is to have a place where all stakeholders
    can not only see all the services, but also their documentations, contracts, and
    service-level agreements. Swagger and API Blueprint are commonly used for handling
    these requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Operation overheads
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Microservices deployment generally increases the number of deployable units
    and virtual machines (or containers). This adds significant management overheads
    and increases the cost of operations.
  prefs: []
  type: TYPE_NORMAL
- en: With a single application, a dedicated number of containers or virtual machines
    in an on-premise data center may not make much sense unless the business benefit
    is very high. The cost generally goes down with economies of scale. A large number
    of microservices that are deployed in a shared infrastructure which is fully automated
    makes more sense, since these microservices are not tagged against any specific
    VMs or containers. Capabilities around infrastructure automation, provisioning,
    containerized deployment, and so on are essential for large scale microservices
    deployments. Without this automation, it would result in a significant operation
    overhead and increased cost.
  prefs: []
  type: TYPE_NORMAL
- en: With many microservices, the number of **configurable items** (**CIs**) becomes
    too high, and the number of servers in which these CIs are deployed might also
    be unpredictable. This makes it extremely difficult to manage data in a traditional
    **Configuration Management Database** (**CMDB**). In many cases, it is more useful
    to dynamically discover the current running topology than a statically configured
    CMDB-style deployment topology.
  prefs: []
  type: TYPE_NORMAL
- en: Testing microservices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Microservices also pose a challenge for the testability of services. In order
    to achieve a full-service functionality, one service may rely on another service,
    and that, in turn, on another service—either synchronously or asynchronously.
    The issue is how do we test an end-to-end service to evaluate its behavior? The
    dependent services may or may not be available at the time of testing.
  prefs: []
  type: TYPE_NORMAL
- en: Service virtualization or service mocking is one of the techniques used for
    testing services without actual dependencies. In testing environments, when the
    services are not available, mock services can simulate the behavior of the actual
    service. The microservices ecosystem needs service virtualization capabilities.
    However, this may not give full confidence, as there may by many corner cases
    that mock services do not simulate, especially when there are deep dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: Another approach, as discussed earlier, is to use a consumer driven contract.
    The translated integration test cases can cover more or less all corner cases
    of the service invocation.
  prefs: []
  type: TYPE_NORMAL
- en: Test automation, appropriate performance testing, and continuous delivery approaches
    such as A/B testing, future flags, canary testing, blue-green deployments, and
    red-black deployments, all reduce the risks of production releases.
  prefs: []
  type: TYPE_NORMAL
- en: Infrastructure provisioning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As briefly touched on under operation overheads, manual deployment could severely
    challenge the microservices rollouts. If a deployment has manual elements, the
    deployer or operational administrators should know the running topology, manually
    reroute traffic, and then deploy the application one by one till all services
    are upgraded. With many server instances running, this could lead to significant
    operational overheads. Moreover, the chances of errors are high in this manual
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices require a supporting elastic cloud-like infrastructure which can
    automatically provision VMs or containers, automatically deploy applications,
    adjust traffic flows, replicate new version to all instances, and gracefully phase
    out older versions. The automation also takes care of scaling up elastically by
    adding containers or VMs on demand, and scaling down when the load falls below
    threshold.
  prefs: []
  type: TYPE_NORMAL
- en: In a large deployment environment with many microservices, we may also need
    additional tools to manage VMs or containers that can further initiate or destroy
    services automatically.
  prefs: []
  type: TYPE_NORMAL
- en: The microservices capability model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we conclude this chapter, we will review a capability model for microservices
    based on the design guidelines and common pattern and solutions described in this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram depicts the microservices capability model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The microservices capability model](img/B05447_03_36.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The capability model is broadly classified in to four areas:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Core capabilities**: These are part of the microservices themselves'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Supporting capabilities**: These are software solutions supporting core microservice
    implementations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Infrastructure capabilities**: These are infrastructure level expectations
    for a successful microservices implementation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Governance capabilities**: These are more of process, people, and reference
    information'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Core capabilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The core capabilities are explained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Service listeners** (HTTP/messaging): If microservices are enabled for a
    HTTP-based service endpoint, then the HTTP listener is embedded within the microservices,
    thereby eliminating the need to have any external application server requirement.
    The HTTP listener is started at the time of the application startup. If the microservice
    is based on asynchronous communication, then instead of an HTTP listener, a message
    listener is started. Optionally, other protocols could also be considered. There
    may not be any listeners if the microservice is a scheduled service. Spring Boot
    and Spring Cloud Streams provide this capability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Storage capability**: The microservices have some kind of storage mechanisms
    to store state or transactional data pertaining to the business capability. This
    is optional, depending on the capabilities that are implemented. The storage could
    be either a physical storage (RDBMS such as MySQL; NoSQL such as Hadoop, Cassandra,
    Neo 4J, Elasticsearch, and so on), or it could be an in-memory store (cache like
    Ehcache, data grids like Hazelcast, Infinispan, and so on)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Business capability definition**: This is the core of microservices, where
    the business logic is implemented. This could be implemented in any applicable
    language such as Java, Scala, Conjure, Erlang, and so on. All required business
    logic to fulfill the function will be embedded within the microservices themselves.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Event sourcing**: Microservices send out state changes to the external world
    without really worrying about the targeted consumers of these events. These events
    could be consumed by other microservices, audit services, replication services,
    or external applications, and the like. This allows other microservices and applications
    to respond to state changes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service endpoints and communication protocols**: These define the APIs for
    external consumers to consume. These could be synchronous endpoints or asynchronous
    endpoints. Synchronous endpoints could be based on REST/JSON or any other protocols
    such as Avro, Thrift, Protocol Buffers, and so on. Asynchronous endpoints are
    through Spring Cloud Streams backed by RabbitMQ, other messaging servers, or other
    messaging style implementations such as ZeroMQ.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**API gateway**: The API gateway provides a level of indirection by either
    proxying service endpoints or composing multiple service endpoints. The API gateway
    is also useful for policy enforcements. It may also provide real time load balancing
    capabilities. There are many API gateways available in the market. Spring Cloud
    Zuul, Mashery, Apigee, and 3scale are some examples of the API gateway providers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User interfaces**: Generally, user interfaces are also part of microservices
    for users to interact with the business capabilities realized by the microservices.
    These could be implemented in any technology, and are channel- and device-agnostic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Infrastructure capabilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Certain infrastructure capabilities are required for a successful deployment,
    and managing large scale microservices. When deploying microservices at scale,
    not having proper infrastructure capabilities can be challenging, and can lead
    to failures:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cloud**: Microservices implementation is difficult in a traditional data
    center environment with long lead times to provision infrastructures. Even a large
    number of infrastructures dedicated per microservice may not be very cost effective.
    Managing them internally in a data center may increase the cost of ownership and
    cost of operations. A cloud-like infrastructure is better for microservices deployment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Containers or virtual machines**: Managing large physical machines is not
    cost effective, and they are also hard to manage. With physical machines, it is
    also hard to handle automatic fault tolerance. Virtualization is adopted by many
    organizations because of its ability to provide optimal use of physical resources.
    It also provides resource isolation. It also reduces the overheads in managing
    large physical infrastructure components. Containers are the next generation of
    virtual machines. VMWare, Citrix, and so on provide virtual machine technologies.
    Docker, Drawbridge, Rocket, and LXD are some of the containerizer technologies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cluster control and provisioning**: Once we have a large number of containers
    or virtual machines, it is hard to manage and maintain them automatically. Cluster
    control tools provide a uniform operating environment on top of the containers,
    and share the available capacity across multiple services. Apache Mesos and Kubernetes
    are examples of cluster control systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Application lifecycle management**: Application lifecycle management tools
    help to invoke applications when a new container is launched, or kill the application
    when the container shuts down. Application life cycle management allows for script
    application deployments and releases. It automatically detects failure scenario,
    and responds to those failures thereby ensuring the availability of the application.
    This works in conjunction with the cluster control software. Marathon partially
    addresses this capability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supporting capabilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Supporting capabilities are not directly linked to microservices, but they
    are essential for large scale microservices development:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Software defined load balancer**: The load balancer should be smart enough
    to understand the changes in the deployment topology, and respond accordingly.
    This moves away from the traditional approach of configuring static IP addresses,
    domain aliases, or cluster addresses in the load balancer. When new servers are
    added to the environment, it should automatically detect this, and include them
    in the logical cluster by avoiding any manual interactions. Similarly, if a service
    instance is unavailable, it should take it out from the load balancer. A combination
    of Ribbon, Eureka, and Zuul provide this capability in Spring Cloud Netflix.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Central log management**: As explored earlier in this chapter, a capability
    is required to centralize all logs emitted by service instances with the correlation
    IDs. This helps in debugging, identifying performance bottlenecks, and predictive
    analysis. The result of this is fed back into the life cycle manager to take corrective
    actions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service registry**: A service registry provides a runtime environment for
    services to automatically publish their availability at runtime. A registry will
    be a good source of information to understand the services topology at any point.
    Eureka from Spring Cloud, Zookeeper, and Etcd are some of the service registry
    tools available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security service**: A distributed microservices ecosystem requires a central
    server for managing service security. This includes service authentication and
    token services. OAuth2-based services are widely used for microservices security.
    Spring Security and Spring Security OAuth are good candidates for building this
    capability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service configuration**: All service configurations should be externalized
    as discussed in the Twelve-Factor application principles. A central service for
    all configurations is a good choice. Spring Cloud Config server, and Archaius
    are out-of-the-box configuration servers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Testing tools (anti-fragile, RUM, and so on)**: Netflix uses Simian Army
    for anti-fragile testing. Matured services need consistent challenges to see the
    reliability of the services, and how good fallback mechanisms are. Simian Army
    components create various error scenarios to explore the behavior of the system
    under failure scenarios.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring and dashboards**: Microservices also require a strong monitoring
    mechanism. This is not just at the infrastructure-level monitoring but also at
    the service level. Spring Cloud Netflix Turbine, Hysterix Dashboard, and the like
    provide service level information. End-to-end monitoring tools like AppDynamic,
    New Relic, Dynatrace, and other tools like statd, Sensu, and Spigo could add value
    to microservices monitoring.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dependency and CI management**: We also need tools to discover runtime topologies,
    service dependencies, and to manage configurable items. A graph-based CMDB is
    the most obvious tool to manage these scenarios.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data lake**: As discussed earlier in this chapter, we need a mechanism to
    combine data stored in different microservices, and perform near real-time analytics.
    A data lake is a good choice for achieving this. Data ingestion tools like Spring
    Cloud Data Flow, Flume, and Kafka are used to consume data. HDFS, Cassandra, and
    the like are used for storing data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reliable messaging**: If the communication is asynchronous, we may need a
    reliable messaging infrastructure service such as RabbitMQ or any other reliable
    messaging service. Cloud messaging or messaging as a service is a popular choice
    in Internet scale message-based service endpoints.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Process and governance capabilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The last piece in the puzzle is the process and governance capabilities that
    are required for microservices:'
  prefs: []
  type: TYPE_NORMAL
- en: '**DevOps**: The key to successful implementation of microservices is to adopt
    DevOps. DevOps compliment microservices development by supporting Agile development,
    high velocity delivery, automation, and better change management.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DevOps tools**: DevOps tools for Agile development, continuous integration,
    continuous delivery, and continuous deployment are essential for successful delivery
    of microservices. A lot of emphasis is required on automated functioning, real
    user testing, synthetic testing, integration, release, and performance testing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Microservices repository**: A microservices repository is where the versioned
    binaries of microservices are placed. These could be a simple Nexus repository
    or a container repository such as a Docker registry.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Microservice documentation**: It is important to have all microservices properly
    documented. Swagger or API Blueprint are helpful in achieving good microservices
    documentation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reference architecture and libraries**: The reference architecture provides
    a blueprint at the organization level to ensure that the services are developed
    according to certain standards and guidelines in a consistent manner. Many of
    these could then be translated to a number of reusable libraries that enforce
    service development philosophies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about handling practical scenarios that will arise
    in microservices development.
  prefs: []
  type: TYPE_NORMAL
- en: You learned various solution options and patterns that could be applied to solve
    common microservices problems. We reviewed a number of challenges when developing
    large scale microservices, and how to address those challenges effectively.
  prefs: []
  type: TYPE_NORMAL
- en: We also built a capability reference model for a microservices-based ecosystem.
    The capability model helps in addressing gaps when building Internet scale microservices.
    The capability model learned in this chapter will be the backbone for this book.
    The remaining chapters will deep dive into the capability model.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will take a real-world problem and model it using the
    microservices architecture to see how to translate our learnings into practice.
  prefs: []
  type: TYPE_NORMAL
