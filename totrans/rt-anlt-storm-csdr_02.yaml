- en: Chapter 2. Getting Started with Your First Topology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter is dedicated to guiding you through the steps to set up the environment
    for the execution of a Storm topology. The intent is to prepare the user sandbox
    and get you steered toward executing some of the sample code and understanding
    the working of various components. All the concepts will be accompanied by code
    snippets and a "try it yourself" section so that you are equipped to understand
    the components in a practical manner and are ready to explore and harness the
    power of this wonderful technology.
  prefs: []
  type: TYPE_NORMAL
- en: 'The topics that will be covered in this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Storm topology and components
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Executing the sample Storm topology
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Executing the topology in distributed mode
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of the chapter, you will be able to understand the components and
    data flow in a topology, understand the simple word count topology, and execute
    it in the local and distributed modes. You will also be able to tweak the starter
    project topologies to add your own flavor to them.
  prefs: []
  type: TYPE_NORMAL
- en: Prerequisites for setting up Storm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The prerequisites for executing the setup and execution steps are enlisted
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: For a local mode setup, you need Maven, Git, Eclipse, and Java
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For a distributed setup, you need the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Linux or Ubuntu setup or a distributed setup can leverage PowerShell or Cygwin
    over their Windows systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having more than one system or virtual machines using the VMware player would
    help
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can refer to the following links and follow the process laid out to set
    up the various open source components required to set up Storm and deploy the
    components explained in this segment of the book:'
  prefs: []
  type: TYPE_NORMAL
- en: For Java, [https://java.com/en/download/index.jsp](https://java.com/en/download/index.jsp)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For Eclipse, [https://www.eclipse.org/downloads/](https://www.eclipse.org/downloads/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For Cygwin, [http://cygwin.com/install.html](http://cygwin.com/install.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For Git, [https://help.github.com/articles/set-up-git](https://help.github.com/articles/set-up-git)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Components of a Storm topology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A Storm topology consists of two basic components: a spout and one or more
    bolts. These building blocks are tied together using streams; it is over these
    streams that endless arrays of tuples flow.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s discuss the topology with a simple analogy, as depicted in the diagram
    and explained thereafter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Components of a Storm topology](img/00010.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: In our example topology, we have a big processing unit for roasted chips where
    the input, *raw potato*, is consumed by the spout, and there are various bolts
    such as a peeler bolt, slicer bolt, and roasting bolt that perform the tasks as
    their name suggests. There are various assembly lines or workers that move the
    chips from the peeler unit to the shredder and beyond; in our case, we have streams
    to link and wire in the spout and bolts with each other. Now the basic unit of
    exchange between the peeler and shredder is a peeled potato, and between the shredder
    units and roasting units is a sliced potato. This is analogous to a tuple, the
    datum of information exchange between spouts and bolts.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a closer look at the building blocks of the Storm topology.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The basic unit of data interchange within Storm is called a *tuple*; this is
    sometimes also referred to as an *event*.
  prefs: []
  type: TYPE_NORMAL
- en: Spouts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A spout is the collection funnel of a topology; it feeds events or tuples into
    the topology. It can be considered as the input source to the Storm processing
    unit—the topology.
  prefs: []
  type: TYPE_NORMAL
- en: The spout reads messages from external sources such as a queue, file, port,
    and so on. Also, the spout emits them into the stream, which in turn passes them
    to the bolts. It's the task of the Storm spout to track each event or tuple throughout
    its processing through the **Directed Acyclic Graph** (**DAG**). The Storm framework
    then sends and generates either acknowledgement or failure notifications based
    on the outcome of the execution of tuples in the topology. This mechanism gives
    the guaranteed processing feature to Storm. Based on the required functionality,
    spouts can be programmed or configured to be reliable or unreliable. A reliable
    spout plays back the failed events into the topology.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram depicts the same flow, graphically:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Spouts](img/00011.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: All Storm spouts are implemented to be able to emit tuples on one or more stream
    bolts. As in the preceding diagram, a spout can emit tuples to both bolt **A**
    and **C**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each spout should implement the **IRichSpout** interface. The following are
    important methods to know in context with spout:'
  prefs: []
  type: TYPE_NORMAL
- en: '`nextTuple()`: This is the method that keeps on polling the external source
    for new events; for instance, the queue in the preceding example. On every poll,
    if the method finds an event, it is emitted to the topology through a stream,
    and if there is no new event, the method simply returns.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ack()`: This method is called when the tuple emitted by the spout has been
    successfully processed by the topology.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fail()`: This method is called when a tuple emitted by the spout is not successfully
    processed within the specified timeout. In this case, for reliable spouts, the
    spout traces and tracks each tuple with the `messageIds` event, which are then
    re-emitted to the topology to be reprocessed. For instance, in the preceding figure,
    the failed tuple is emitted again.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For unreliable spouts, the tuples are not tracked using `messageIds` and the
    methods such as `ack()` and `fail()` don't hold any value as the spout doesn't
    track the tuples for successful processing. These topologies are identified as
    unreliable.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: IRichSpout is an interface provided by Storm that provides the details of the
    contracts or methods to be implemented by topology spouts.
  prefs: []
  type: TYPE_NORMAL
- en: Bolts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Bolts are the processing units of a topology. They are the components of the
    topology that perform one or more of the following tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Parsing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transformation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aggregation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Joins
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Database interaction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The entire process being performed by the topology is generally divided into
    smaller tasks and subtasks, each preferably performed by a different bolt to exploit
    the power of the parallel distributed processing of Storm.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at the following figure that captures a real-time use case where
    the location coordinates from various airplanes are tracked and processed to ascertain
    whether they are moving on the correct trajectory:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Bolts](img/00012.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, the flight location coordinates are sent by sensors in the plane, which
    are collated at log servers and fed into a Storm topology. The Storm topology
    is broken into the following bolts that can act on the tuples emitted by the spout:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The parse event bolt**: This bolt filters and transforms the event emitted
    by the spout. It converts the information into a decipherable format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The location bolt**: This is the bolt that extracts the location coordinates
    from the tuples it receives from the parse bolt and then sends them across to
    the next bolt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The verify bolt**: This is the bolt that verifies the location coordinates
    sent by the location bolt against the predefined trajectory of the plane, and
    if it detects deviation, it sends a tuple to the alert bolt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The alert bolt**: This bolt is the actor that informs the external systems,
    such as the air controller in our case, about the anomaly or deviation detected
    in the flight path.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Owing to the nature of real-time use cases, such as the one depicted in the
    preceding figure, speed and accuracy of computation is of utmost importance, and
    that's the reason that makes Storm a strong technological choice for the implementation
    of such solutions.
  prefs: []
  type: TYPE_NORMAL
- en: The total processing logic gets broken down into smaller tasks that are executed
    in bolts; configuring tasks and parallelism in bolts lets the engineers attain
    the right kind of performance for the solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'One bolt can listen to multiple streams and it can emit to multiple other bolts
    on different streams. As depicted in the figure in the *Sprouts* section:'
  prefs: []
  type: TYPE_NORMAL
- en: Bolt-A emits to Bolt-B and Bolt-C
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bolt-D subscribes to streams from Bolt-C and Bolt-B
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The common interfaces provided by Storm to be implemented by user-defined bolts
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: IRichBolt
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IBasicBolt
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The difference in these two interfaces depends upon whether reliable messaging
    and transactional support are required or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main methods used by the bolts are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`prepare()`: This is the method that is called when the bolt is initialized.
    Fundamentally, the Storm topology runs forever and the bolt once initialized will
    not terminate till the topology is killed. This method is generally used to initialize
    connections and read other static information, which is required during the entire
    life cycle of the bolt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`execute()`: This is the method that performs the functioning and processing
    logic defined on the bolt. It is executed for every tuple.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Streams
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Stream can be defined as a sequence of tuples or events that are unbounded by
    nature. These streams are generally created in a parallel and distributed manner
    across the topology. Streams can be called the wiring or information flow channels
    between the spout and bolts. These are carriers of unprocessed, semiprocessed,
    and processed information to and from various task-performing components such
    as bolts and spouts. Streams are configured while encoding the topology using
    a schema that gives names to the fields in the stream's tuple.
  prefs: []
  type: TYPE_NORMAL
- en: Tuples – the data model in Storm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A tuple is the basic and constituent data structure in Storm. It's a named list
    of values that starts its journey from the spout. It's then emitted from streams
    to bolts, then from bolts to other bolts, where various stages of processing are
    executed. On successful completion of all intended processing, as per the topology
    definition, the tuples are acked back to the spout.
  prefs: []
  type: TYPE_NORMAL
- en: Executing a sample Storm topology – local mode
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we start this section, the assumption is that you have gone through the
    prerequisites and installed the expected components.
  prefs: []
  type: TYPE_NORMAL
- en: WordCount topology from the Storm-starter project
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand the components described in the previous section, let''s download
    the Storm-starter project and execute a sample topology:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Storm-starter project can be downloaded using the following Git command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, you need to import the project into your Eclipse workspace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start Eclipse.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the **File** menu and select the **Import** wizard.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the **Import** wizard, select **Existing Maven Projects**.![WordCount topology
    from the Storm-starter project](img/00013.jpeg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **pom.xml** in the Storm-starter project and specify it as `<download-folder>/starter/incubator-storm/examples/storm-starter`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the project has been successfully imported, the Eclipse folder structure
    will look like the following screenshot:![WordCount topology from the Storm-starter
    project](img/00014.jpeg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Execute the topology using the run command and you should be able to see the
    output as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![WordCount topology from the Storm-starter project](img/00015.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'To understand the functioning of the topology, let''s take a look at the code
    and understand the flow and functioning of each component in the topology:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '`setSpout –RandomSentenceSpout`: This generates random sentences. Please note
    that we are using a property called parallelism hint, which is set to `5` here.
    This is the property that identifies how many instances of this component will
    be spawned at the time of submitting the topology. In our example, we will have
    five instances of the spout.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`setBolt`: We use this method to add two bolts to the topology: `SplitSentenceBolt`,
    which splits the sentence into words, and `WordCountBolt`, which counts the words.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other noteworthy items in the preceding code snippet are `suffleGrouping` and
    `fieldsGrouping`; we shall discuss these in detail in the next chapter; for now,
    understand that these are the components that control routing of tuples to various
    bolts in the topology.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Executing the topology in the distributed mode
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To set up Storm in distributed mode, we will need to perform the following steps.
  prefs: []
  type: TYPE_NORMAL
- en: Set up Zookeeper (V 3.3.5) for Storm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The coordination of a Storm topology is maintained by a Zookeeper cluster. The
    utilization of Zookeeper is not very high, as it just maintains the runnable state
    of the Storm cluster. In most cases, a single Zookeeper node should suffice, but
    in production scenarios, at least a three-node Zookeeper cluster is recommended
    so that a single node doesn't become a single point of failure.
  prefs: []
  type: TYPE_NORMAL
- en: For reliable Zookeeper service, deploy Zookeeper in a cluster known as an **ensemble**.
    As long as the majority of the ensemble is up, the service will be available.
    One of the nodes in the ensemble is automatically selected as a leader and others
    as followers. If the leader goes down, one of the follower nodes becomes the leader.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps on all the machines that will be part of the Zookeeper
    ensemble to set up the Zookeeper cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: Download the most recent stable release (version 3.3.5) from the Apache Zookeeper
    site.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a `zookeeper` directory under `/usr/local`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Extract the downloaded TAR file to the `/usr/local` location. Use the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Zookeeper needs a directory to store its data. Create `/usr/local/zookeeper/tmp`
    to store this data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a configuration file, `zoo.cfg`, under `/usr/local/zookeeper/zookeeper-3.3.5/conf`.
    The following properties will go in it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`tickTime`: This is the number of milliseconds of each tick (for example, 2000).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`initLimit`: This is the number of ticks that the initial synchronization phase
    can take (for example, 5).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`syncLimit`: This is the number of ticks that can pass between sending a request
    and getting an acknowledgement (for example, 2).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dataDir`: This is the directory where the snapshot is stored (for example,
    `/usr/local/zookeeper/tmp`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clientPort`: This is the port at which the Zookeeper clients will connect
    to the port (for example, 2182).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`server.id=host:port:port`: Every machine that is part of the Zookeeper ensemble
    should know about every other machine in the ensemble. This is accomplished with
    the series of lines of the `server.id=host:port:port` form (for example, `server.1:<IP_ADDRESS_OF_ZOOKEEPER_NODE_1>:2888:3888`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Repeat the preceding steps or copy the distribution to other machines that will
    be part of the Zookeeper cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a file with the name `myid` in the directory specified by the `datadir`
    property. The `myid` file consists of a single line containing only the text of
    that machine's ID (1 in the server and 1 in `zoo.cfg`). So, `myid` of server 1
    will contain the text `1` and nothing else. The ID must be unique within the ensemble
    and should have a value between 1 and 255\. The path of the `myid` file in this
    case is `vi /usr/local/zookeeper/tmp/myid`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Edit the `~/.bashrc` file and add an environment variable for the Zookeeper
    home and add its bin directory to the `PATH` environment variable:![Set up Zookeeper
    (V 3.3.5) for Storm](img/00016.jpeg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Source the `~/`.`bashrc` file after making changes. This step is required to
    make sure that the changes that are made to `bashrc` are applied to the current
    terminal session:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Start the Zookeeper daemon on each node by executing the following command
    from `$ZOOKEEPER_HOME`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Stop the Zookeeper daemon on each node by executing the following command from
    `$ZOOKEEPER_HOME`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The Zookeeper status can be checked by running the following command from `$ZOOKEEPER_HOME`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The output for the different modes is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: If running in the standalone mode (only a single machine is part of the Zookeeper
    ensemble cluster), the following output will be seen on the console:![Set up Zookeeper
    (V 3.3.5) for Storm](img/00017.jpeg)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If running in the clustered mode, the following output is seen on the leader
    node:![Set up Zookeeper (V 3.3.5) for Storm](img/00018.jpeg)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If running in the clustered mode, the following output is seen on the follower
    node:![Set up Zookeeper (V 3.3.5) for Storm](img/00019.jpeg)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By default, the Zookeeper log (`zookeeper.out`) is created at the same location
    from where its instance is started. This completes the Zookeeper cluster setup.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Storm in the distributed mode
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following steps to set up Storm in distributed mode:'
  prefs: []
  type: TYPE_NORMAL
- en: Download the `Storm-0.9.2-incubating.zip` package from the GitHub Storm site.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create the directories `storm` and `storm/tmp` under `/usr/local`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the following directories for logs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Extract the ZIP file on Nimbus and the worker machines from the directory at
    `/usr/local`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Make the following changes at `/usr/local/storm/storm-0.9.2-incubating/conf/storm.yaml`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`storm.zookeeper.servers`: This is a list of the hosts in the Zookeeper cluster
    for the Storm cluster:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '`storm.zookeeper.port`: This is the port on which the Zookeeper cluster is
    running:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '`storm.local.dir`: The Nimbus and the supervisor require a location on the
    local disk to store a small amount of data related to configurations and execution
    details of the topology. Please make sure to create the directory and assign read/write
    permissions on all Storm nodes. For our installation, we are going to create this
    directory in the `/usr/local/storm/tmp` location:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '`nimbus.host`: The nodes need to know which machine is the master in order
    to download topology jars and confs. This property is used for this purpose:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '`java.library.path`: This is the load path for the native libraries that Storm
    uses (ZeroMQ and JZMQ). The default of `/usr/local/lib:/opt/local/lib:/usr/lib`
    should be fine for most installations, so validate the libraries in the previously
    mentioned locations before moving forward.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`storm.messaging.netty`: Storm''s Netty-based transport has been overhauled
    to significantly improve performance through better utilization of thread, CPU,
    and network resources, particularly in cases where message sizes are small. In
    order to provide Netty support, the following configurations need to be added:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The `storm.yaml` snippet from our Storm cluster installation is as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Set the `STORM_HOME` environment in the `~/.bashrc` file and add Storm's `bin`
    directory in the `PATH` environment variable. This is added to execute Storm binaries
    from any location.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Copy the `Storm.yaml` file to the `bin` folder of the Storm installation on
    the Nimbus machine using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Launching Storm daemons
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that the Storm cluster is set, we will be required to start three processes
    on respective Storm nodes. They are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Nimbus:** Start Nimbus as the background process on the machine identified
    as the master node by running the following command from `$STORM_HOME`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '**Supervisor:** Supervisors can be started in a similar way Nimbus is started.
    Run the following command from `$STORM_HOME`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '**UI:** The Storm UI is a web application to check the Storm cluster, which
    contains the Nimbus/Supervisor status. It also lists all the running topologies
    and their details. The UI can be enabled by using the following command from `$STORM_HOME`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The UI can be accessed through `http://<IP_ADDRESS_OF_NIMBUS>:8080`.
  prefs: []
  type: TYPE_NORMAL
- en: Executing the topology from Command Prompt
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once the UI is visible and all the daemons are started, the topology can be
    submitted on Nimbus using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The Storm UI with the `WordCount` topology running in distributed mode is shown
    here. It depicts the topology state, uptime, and other details (we shall discuss
    the features of the UI in detail in a later chapter). We can kill the topology
    from the UI.
  prefs: []
  type: TYPE_NORMAL
- en: '![Executing the topology from Command Prompt](img/00020.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Tweaking the WordCount topology to customize it
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have deployed the `WordCount` topology in distributed mode, let''s
    tweak the code in the bolts a bit to write `WordCount` onto a file. To achieve
    this, we will proceed with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We intend to create a new bolt, `FileWriterBolt`, to achieve this. Open `WordCountTopology.java`
    and add the following snippet to `WordCountTopology.java`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Next we have to make changes to the `main()` method to use this new bolt instead
    of `WordCount Bolt()`; here is the snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Next, you can execute the topology using Eclipse, run it as Java, and the output
    will be saved into a file called `wordCount.txt` in your home directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To run in distributed mode, use the following steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Compile the topology changes to generate a new Storm-starter project using
    the following command line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Copy `storm-starter-0.0.1-SNAPSHOT-jar-with-dependencies.jar` from the target
    folder under the starter project to Nimbus, let's say, at `/home/admin/topology/`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Submit the topology using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The output will be the same as the `WordCount` topology executed in the figure
    in the preceding section.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Quiz time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Q.1\. State whether the following statements are true or false:'
  prefs: []
  type: TYPE_NORMAL
- en: All Storm topologies are reliable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A topology generally has multiple spouts.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A topology generally has multiple bolts.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: One bolt can emit on only one stream.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Q.2\. Fill in the blanks:'
  prefs: []
  type: TYPE_NORMAL
- en: _______________ is the template to create the topology.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: _______________ specifies how many instances of a particular bolt or spout are
    spawned.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The ___________ daemon of Storm is analogous to the job tracker of Hadoop.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Q.3\. Perform the following task:'
  prefs: []
  type: TYPE_NORMAL
- en: Make changes to the `WordCount` topology of the Storm-starter project to `RandomSentenceSpout`
    so that it's able to read sentences from a file at a specified location.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have set up the Storm ensemble. You were introduced to the
    various building blocks of a Storm topology such as bolts, spouts, and the wiring
    template—topology builder. We executed and understood the `WordCount` topology
    and also made some amendments to it.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will read and understand about stream groupings, anchoring,
    and acking. That will also lead us to reliable and non-reliable mechanisms in
    the topologies under the Storm framework.
  prefs: []
  type: TYPE_NORMAL
