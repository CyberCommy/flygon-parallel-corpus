- en: Going Serverless
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have explored so far, Microservices offer a great alternative architecture
    with which we can approach the application development scenario. With the advantages
    of having faster release cycles, easy-to-launch new features and high scalability,
    the Microservices are a compelling choice for developers. But all of these Microservices
    still run in a server-based environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running in a server-based environment is useful in terms of the response times
    of the applications because there is always a service that is ready to accept
    an incoming request. But there is one disadvantage: If there are no users, the
    applications keep on consuming system resources.'
  prefs: []
  type: TYPE_NORMAL
- en: Recently, application developers have started to make a move toward a new approach
    of application development. This approach of development focuses on the applications
    being event-driven and launches an action based on the occurrence of some event.
    These kinds of applications are known as serverless applications because they
    do not keep on running when there is no user and an instance of them launches
    only when there has been some event that has occurred.
  prefs: []
  type: TYPE_NORMAL
- en: As we move through this chapter, we will take a look at this serverless approach
    of application development and how it is changing the development scenario.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a reader of this chapter, you will get to learn about the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The serverless approach to application development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The process that powers the serverless architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a serverless application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Benefits of the serverless approach
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The code listings in this book can be found under `chapter13` directory at [https://github.com/PacktPublishing/Hands-On-Enterprise-Application-Development-with-Python](https://github.com/PacktPublishing/Hands-On-Enterprise-Application-Development-with-Python)[.](https://github.com/PacktPublishing/Hands-On-Enterprise-Application-Development-with-Python)
  prefs: []
  type: TYPE_NORMAL
- en: 'The code samples can be cloned by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Additionally, for the code to execute successfully, some additional software
    will be required:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Docker**: Docker is required as a dependency to run the OpenWhisk software
    platform for the deployment of the serverless applications. To install `docker`
    on your platform, please take a look at [https://docs.docker.com/install/](https://docs.docker.com/install/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Apache OpenWhisk**: Apache OpenWhisk provides an open source platform for
    ...'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The serverless approach to application development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In recent years, as developers, we have grown accustomed to the traditional
    ways of building applications and handling their deployments on the production
    infrastructure. In this traditional architecture, we developed applications where
    the application takes in a request from the **Client**, checks whether the **Client**
    is authorized to perform that action, and then moves on to executing that action.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the application was developed, we deployed it over a platform that would
    be compatible with our application. This involves the choice of the operating
    system, the kind of the infrastructure where this platform will be running, for
    example a bare-metal server, a VM, or a container, and then we maintained the
    infrastructure by handling its scalability and fixing any issues that may arise.
    For example, a simple system that manages employee payroll inside an organization
    will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/b9a3bf94-69b6-4b8e-ae0d-61a80b4794e3.png)'
  prefs: []
  type: TYPE_IMG
- en: In this case, the application keeps running on a server, waiting for the requests
    to come, and acting on them as they arrive.
  prefs: []
  type: TYPE_NORMAL
- en: This kind of approach, though highly useful, usually pulls the developers from
    their main task of writing the logic to achieve a particular outcome from the
    system, and makes them focus on a lot of areas that involve tasks related to the
    infrastructure management and scalability.
  prefs: []
  type: TYPE_NORMAL
- en: Now imagine an architecture that would allow developers to focus on just writing
    the logic behind a particular business process without worrying about where that
    logic will be executed and how it will scale.
  prefs: []
  type: TYPE_NORMAL
- en: 'The serverless approach to building applications provides these features. The
    way this works in serverless is through the introduction of two new techniques
    to application development:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Backend as a service** (**BaaS**): BaaS is a new cloud computing offering
    that provides the application developers with the functionality of linking their
    applications with the backend services through the use of APIs, so as to provide
    some common feature sets, such as user authentication and data storage. It differs
    from the general architecture of application development in that these services
    provided by the backend may not need to be developed by the application developers
    themselves, but access to these services is enabled through the use of APIs exposed
    by these services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Function as a service** (**FaaS**): FaaS is another category of cloud computing
    that allows developers to focus on writing the application logic without worrying
    about where this logic will execute. In FaaS, the applications run in a stateless
    and ephemeral manner where the infrastructure they might be executing in may be
    valid only for a few invocations, which may be as little as a single invocation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the serverless architecture of application development, the applications
    are usually developed as functions that are executed as a response to a certain
    event. These functions execute in their own stateless containers, which may exist
    in the infrastructure for only a few invocations. We will take a look at how the
    serverless applications work in the later sections of this chapter. For a quick
    reference, if we had to implement the Payroll system as a serverless application;
    the following diagram shows how the architecture of the system would look:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/2ae4e988-e8d6-4deb-8780-16aebbe431cb.png)'
  prefs: []
  type: TYPE_IMG
- en: As we can see, our serverless payroll application contains both the features
    of a BaaS offering where the **Client** directly interacts with the **Auth DB**
    through the APIs exposed by the **Auth DB** and the **Payslip** generation, and
    employee search runs in a FaaS offering where they are stored as functions and
    executed only when a particular event happens.
  prefs: []
  type: TYPE_NORMAL
- en: Both of these functions do not maintain any kind of state, such that they can
    run in ephemeral containers that may only last for a short amount of time.
  prefs: []
  type: TYPE_NORMAL
- en: So now, let's take a look at the components that power the serverless architecture
    and how the serverless architecture works to have a better understanding of how
    we can develop applications that best utilize the serverless architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Components of serverless architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have seen, the serverless architecture provides us a way to develop applications
    where we are only responsible for writing the logic behind the applications, and
    relieves us of the worry of how the infrastructure will be managed for running
    the application and how the application will scale up and down based on the number
    of requests.
  prefs: []
  type: TYPE_NORMAL
- en: But what powers this architecture? Let's try to spend some time taking a look
    at how the different components inside the architecture work to provide a serverless
    development approach toward application development.
  prefs: []
  type: TYPE_NORMAL
- en: As discussed earlier, the serverless approach to application development is
    made possible through the use of two technologies that have came into existence
    ...
  prefs: []
  type: TYPE_NORMAL
- en: Backend as a service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most of the applications that we develop share a common set of functionalities.
    These functionalities may include the implementation of a user authentication
    database, providing a way for storage and retrieval of files, or sending notifications
    either through the use of emails or push notifications.
  prefs: []
  type: TYPE_NORMAL
- en: Most of the time, these functionalities are built into the application by introducing
    new components inside the application with which the other components can interact.
    The same is true for the Microservices-based applications, where these features
    are implemented, as different Microservices and the other Microservices interact
    with these services to achieve a certain outcome.
  prefs: []
  type: TYPE_NORMAL
- en: In the BaaS approach, we decouple these functionalities from the application
    by integrating these functionalities through the use of third-party cloud providers.
    When this happens, our applications usually integrate these functionalities through
    the use of the APIs that are provided by the third-party providers.
  prefs: []
  type: TYPE_NORMAL
- en: To understand this better, let's take a look at the serverless payroll-management
    system we introduced earlier. In this system, we have made the user authentication
    a disjointed part of our application by leveraging the BaaS offering provided
    by a third-party.
  prefs: []
  type: TYPE_NORMAL
- en: In this approach, our user authentication system and any of the data associated
    with it is managed by a third-party provider. This provider exposes some of the
    APIs for the service, which we can use to integrate the service with our application.
  prefs: []
  type: TYPE_NORMAL
- en: In our example, we exposed part of the user authentication service to the client
    through the use of the APIs exposed by the service. This allows the client to
    perform the user authentication directly with the service without going through
    the whole backend of the application. The second place where we used the BaaS
    offering was when we linked the employee search function with the user authentication
    service to retrieve a particular employee based on some criteria.
  prefs: []
  type: TYPE_NORMAL
- en: 'This concept of BaaS provides us with several advantages, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reduced development time:** With BaaS, the developers of an application need
    not worry about the development for the common set of functionalities that they
    can consume directly from the third-party service providers by using the APIs
    provided by the service provider.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ease of operations:** Since the service and the infrastructure related to
    the service is managed by the cloud computing provider only, this reduced the
    complexity of managing the service and the operations it provides, allowing for
    reduced operational headaches.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ease of scalability:** The services provided by the cloud computing provider
    are managed directly by them, allowing for easy scalability, which is now done
    by the provider only.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flexibility of integration:** The services provided by the provider are usually
    integrated through the use of APIs. If the necessary API for the service integration
    is available for a provided platform, the platform can easily integrate with the
    service without worrying about the complexities behind the integration and hence
    allowing for support in different kinds of applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Function as a service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: FaaS is an interesting concept and one of the main technologies that powers
    the serverless architecture. Inside this approach, we develop the backend code
    without worrying about how that code will be deployed and where it will be executed.
  prefs: []
  type: TYPE_NORMAL
- en: The applications aimed for FaaS are just like any other application that does
    not require any kind of special framework for their development and execution.
    The only difference that comes between an FaaS application and a regular application
    that is deployed on the servers is the fact that FaaS applications have a severe
    limitation in terms of maintaining their state and the amount of time they can
    execute for. So, let's take a deeper dive into these two main aspects of having
    your ...
  prefs: []
  type: TYPE_NORMAL
- en: The restrictions on state management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the FaaS model, the different parts of the application are built as separate
    functions where each function is executed on the occurrence of a certain event.
    When the application is supposed to be deployed, the cloud provider automatically
    manages the infrastructure where the application will run and how the application
    will scale up.
  prefs: []
  type: TYPE_NORMAL
- en: In comparison to the traditional applications that, once deployed, start a server
    process and are ready to accept the incoming connections, the FaaS-based applications
    are started dynamically as a response to a certain input. Once the event occurs,
    the function starts and executes, waits for some time, and then the instance in
    which the function is executing is terminated. Now, this makes the process a bit
    interesting because the time for which the function is present in the infrastructure
    is limited and there is no guarantee that the same instance of the function will
    also handle the next call.
  prefs: []
  type: TYPE_NORMAL
- en: This makes the state management, that is, the management of local data for a
    currently-executing operation, a challenging task inside FaaS-based offerings,
    which severely limits what local data we can store inside a function instance
    while it is executing.
  prefs: []
  type: TYPE_NORMAL
- en: For dealing with such a scenario, we depend upon an external offering that can
    store the state data for us. This may include the use of an external database
    or a caching server where the data can be persisted for future reference.
  prefs: []
  type: TYPE_NORMAL
- en: Restrictions on execution times
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once a function starts executing inside an FaaS offering, it has only a limited
    amount of time in which it needs to complete its execution. Most of the famous
    cloud service providers have a limit set on their infrastructure for how long
    a function inside an FaaS offering can execute. For example, if we choose the
    most renowned FaaS offering by AWS, the AWS Lambda, the maximum duration for which
    a function can execute is limited to five minutes. This limit may vary marginally
    on the other providers but won't be too high.
  prefs: []
  type: TYPE_NORMAL
- en: Now this makes an interesting case for us as application developers. If one
    of the application components that we are trying to implement as a function may
    take a significantly long time to ...
  prefs: []
  type: TYPE_NORMAL
- en: Executing functions inside FaaS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once we have developed our applications in the form of functions, we need a
    place to host and run it. This hosting place for the functions is provided by
    the cloud service provider. Now, once we have successfully hosted these functions
    and implemented rules when a particular function should execute, it is the duty
    of the cloud provider to handle the correct execution of these functions.
  prefs: []
  type: TYPE_NORMAL
- en: Now, when these functions have to execute, the cloud provider determines the
    correct environment that will be required to execute a particular function. Once
    this environment has been determined, the cloud provider launches an ephemeral
    container inside which the function code resides. This container provides the
    function a complete isolation from the other functions that might be executing
    in the environment. Now, once the container has launched successfully, this function
    executes, and provides a response back.
  prefs: []
  type: TYPE_NORMAL
- en: The interesting part happens once the function has completed its execution.
    Once the function has completed execution, the cloud provider can either terminate
    the container instance in which the function was running or it can keep it alive
    to handle newer requests. Most of the time, the decision is taken based on the
    frequency of the requests that are arriving and the kind of policies that have
    been set by the user.
  prefs: []
  type: TYPE_NORMAL
- en: If a function instance is still running and waiting, a new incoming request
    might be redirected to that instance only, whereas if there are no ideal instances
    of a function running, the cloud provider will launch a new instance and redirect
    the request to that instance.
  prefs: []
  type: TYPE_NORMAL
- en: With this, we have a good idea of how FaaS works inside the serverless architecture
    and how it enables us to develop serverless applications. But how are these functions
    actually triggered? This brings us to another important component that comprises
    the serverless offerings. Let's take a look at what it is.
  prefs: []
  type: TYPE_NORMAL
- en: API gateways in the serverless architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 11](34b7ccb4-5bbc-474e-a70c-13ef8c1ae237.xhtml), *Taking the Microservices
    Approac*h, when we went through the concept of Microservices, we got introduced
    to API Gateways and how they help in the development of Microservices. These API
    gateways also play an important role in the development of the applications based
    upon the serverless architectures.
  prefs: []
  type: TYPE_NORMAL
- en: The API gateways are nothing but HTTP servers that embed the information about
    certain API endpoints of an application and associate these endpoints with some
    handlers. Once a request is made to a certain API endpoint, the handler associated
    with the API endpoint is called to handle the request.
  prefs: []
  type: TYPE_NORMAL
- en: In the serverless architecture, the handlers that are associated with a particular
    API endpoint ...
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the execution of a serverless application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we've learned that a serverless application is built in the form of
    functions that execute based on the occurrence of some event. Also, these functions
    do not stay alive forever. Instead, these functions are brought into execution
    as requirements arise. So, how does the provider handle the execution of these
    functions when a request comes in? Let's take a look.
  prefs: []
  type: TYPE_NORMAL
- en: Cold-starting a function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When the application has been freshly deployed, it is pretty easy to imagine
    that there will be no instances of the function that will be executing currently.
    When a new request comes in that asks for the functionality provided by the function
    we have just deployed on the infrastructure. Now, the cloud provider systems are
    notified that there are no running instances of the function that can handle the
    incoming request.
  prefs: []
  type: TYPE_NORMAL
- en: Once the provider system is made aware of the situation, it spawns up a new
    instance with the function code inside it. This instance now starts to execute
    the function based on the parameters provided in the request and a response is
    generated by the function and sent back to the requesting client. ...
  prefs: []
  type: TYPE_NORMAL
- en: Hot-starting a function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Completely opposite to the cold start, where a new instance of the function
    needs to be created and brought up to the execution, the hot start of the function
    utilizes the existing instance of the function that is already running in the
    infrastructure of the provider. When this happens, an incoming request does not
    have to spend time waiting for a new instance to spawn up before the request can
    be handled. This allows for the request to be processed quickly.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is one thing that needs to be noted here: even in the case of a hot start
    of a function, the state from the previous execution of the function is not stored.'
  prefs: []
  type: TYPE_NORMAL
- en: Now we know about one of the major factors on which the performance of a function
    may depend. Let's now move forward and build our first serverless application.
  prefs: []
  type: TYPE_NORMAL
- en: Building our first serverless application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With our basic knowledge of the serverless architecture and how it works, it's
    now time for us to develop our first serverless application. For this tutorial,
    we are going to use the Apache OpenWhisk project, which will help us run our demo
    application on our local development system. So, let's take a look at what Apache
    OpenWhisk has to offer us and how we can utilize the platform for our benefit.
  prefs: []
  type: TYPE_NORMAL
- en: A quick introduction to Apache OpenWhisk
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Apache OpenWhisk platform provides us with the features and functionality
    that allow us to set up our own platform for running serverless applications.
    The project provides the functionality for executing functions based on the triggering
    of certain events in the environment.
  prefs: []
  type: TYPE_NORMAL
- en: The execution of these functions happens inside the docker containers, and the
    OpenWhisk platform manages the deployment and scaling of these functions inside
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some of the features provided by the platform:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Easy-to-use tools:** The platform provides a number of tools that allow us
    to easily package and port the application to run on the OpenWhisk platform, with
    the exception of having the application follow a set of conventions as defined
    by the platform.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Isolation using containers:** The platform isolates the different functions
    through the use of docker containers, such that every function runs inside its
    own isolated environment so as to avoid any kind of environmental-dependency conflicts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Support for a wide variety of languages:** The OpenWhisk platform provides
    us with a number of supported language platforms that we can use to build our
    serverless application. This also includes the use of binary executables built
    using Go, C++, and Rust.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Built-in API Gateway:** The OpenWhisk package comes with its own built-in
    API gateway, allowing us to easily integrate the applications through the use
    of RESTful API endpoints.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of these functionalities make OpenWhisk a great platform for running the
    serverless applications, be it on the cloud or in your local development environment.
  prefs: []
  type: TYPE_NORMAL
- en: But, before we start building the application, we need to have OpenWhisk deployed
    on our system. To deploy the project, please follow the steps in the *Technical
    requirements* section at the beginning of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: For the demo, we are going to build an application that queries the GitHub API
    for us and retrieves the repositories that are associated with our user account.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the development environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we start writing the code for our application, we need to have some dependencies
    in place. So, let's build the environment and then move on to writing the code
    that will power our application.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a first step, let''s create a directory that will contain all the files
    related to our project. Let''s call this folder `github_demo`. The following command
    gets the folder in place for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have the directory setup done, let''s move into the directory and set
    up a few things:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Once this is done, we can now set up our project. Before we start writing the
    code, let's get the virtual environment setup done, which will help us to keep
    our project dependencies segregated. ...
  prefs: []
  type: TYPE_NORMAL
- en: Building our configuration file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For the purpose of this application, we are going to use a configuration file
    to store our user-account-related data, which will allow us to authenticate to
    the `Github` API. For this, inside our project directory, create a new file named
    `config.ini` with the following contents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Once we have the configuration file setup complete, let's move on to writing
    our application code, which will interact with `Github` to get our `repos`.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating with the GitHub API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we''re coming to the actual part of our application, let''s get started
    with writing the code. The following code snippet describes the code we use to
    query the `Github` API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Getting the code ready to run with OpenWhisk
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the code ready, it's now time to get it into a format that OpenWhisk can
    execute.
  prefs: []
  type: TYPE_NORMAL
- en: 'For any function to execute inside OpenWhisk, the code should be called from
    the `__main__.py` file. So, let''s create the file and add the following contents
    to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'With the code in place, let''s try to understand what we did here. First, we
    imported the `get_repos` function that we created in the `github_demo.py` file,
    which helps to retrieve the contents from the `Github` API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we define the `main()` function, which is called by the OpenWhisk, to
    execute the code. Any code that is present inside the main function is directly
    executed by the OpenWhisk. So, we use this method to call our `get_repos()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Once this is done, we are on the verge of getting our application ready for
    the deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Taking the final steps toward deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have just a few more steps before we can deploy our application. For the
    successful installation of the app, let''s create a file that stores the dependencies
    required for running our project. The following command helps us get the dependencies
    in place:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'With the requirements packaged, now let''s package our project so that it can
    be deployed to OpenWhisk. For this, running the following command helps in creating
    a package of different project components:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: With this, we are now all set to deploy our application to OpenWhisk.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying to OpenWhisk
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once we have the package ready for deployment, we need to run a few commands
    provided by OpenWhisk to get the package up and running on the platform.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a first step, we have to execute the following command to get the package
    uploaded on the OpenWhisk:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Once this command is executed, the package will be uploaded to the OpenWhisk
    platform and will be ready to run.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, to invoke the application, we can run the following command, which will
    execute the application in an asynchronous manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Once this is done, our application starts executing in an asynchronous manner.
    By running asynchronously, we mean that the execution of the command won't wait
    until the end of the execution of the function, but rather will provide an action
    activation ID that can be used to track the results of the invocation.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's take a look at how OpenWhisk handles the execution of this application
    after the application has been deployed.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the execution of application Inside Openwhisk
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the demo application in place, it's time for us to understand how the execution
    of this application works behind the scenes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Behind the successful execution of the application, there are several steps
    involved which start from the `wsk action invoke` command that we ran to execute
    our application. So, let''s take a look at the steps that happened behind the
    scenes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Making the API call:** Every action that we build to deploy on OpenWhisk
    is mapped as an API endpoint that will invoke the action. When we run `wsk action
    invoke`*,* the command makes a call to the API endpoint that has been mapped for
    the provided function. This call is then intercepted by Nginx inside OpenWhisk,
    which acts ...'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Advantages of going serverless
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With an understanding of how serverless applications work, now it''s time for
    us to take a look at the advantages provided by this development approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reduced development efforts:** By using the services provided by the third-party
    cloud providers, we can reduce the development efforts for some of the common
    functionalities that are found inside an application, such as user authentication,
    notification, and file storage. All of these functionalities can be implemented
    through the use of the APIs provided by the cloud providers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Less operational complexity:** The execution and scaling of a serverless
    application is managed by the cloud service provider, which takes away the operational
    complexities of managing our own infrastructure to handle the execution of the
    application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**High availability:** The applications built in the serverless manner provide
    high availability due to the fact that the infrastructure is managed by the cloud
    provider, which can have the application run in different data centers across
    the world, hence reducing the chance that the application''s uptime will be affected
    in case one of the data centers is experiencing some issues.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Optimized resource allocation:** Since a function is executed only when a
    certain event occurs, the allocation of resources happens only when a particular
    function is being executed, which optimizes the usage of resources across the
    infrastructure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Choice of programming languages:** Most of the serverless solutions provide
    a wide support for the different types of programming languages that are available,
    which allows us to implement our solutions with the best-possible technology stack
    that will work with the application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this, we now have enough points that can convince us to choose the serverless
    development approach in case our needs align with the development methodology
    that needs to be followed for building a serverless application.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we moved through this chapter, we took a look at how the serverless architecture
    is becoming the new trend in the development of the applications, and how this
    architecture works. We covered the different components of the serverless architecture
    and went through the concepts of Backend as a Service and Function as a Service,
    which power the serverless architecture. We then looked at the role of API Gateways
    in the architecture and how the API Gateway in serverless applications differs
    from the one we used in Microservices.
  prefs: []
  type: TYPE_NORMAL
- en: After that, we took a tour of building our first serverless application and
    ran it through Apache OpenWhisk, which provides an open source platform for running
    serverless applications. Here, we also took a deep ...
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What are the advantages provided by the serverless architecture?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does BaaS help is the development of applications?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does an API Gateway help in the execution of serverless applications?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are some of the things that make it hard to port an application into a
    serverless format?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Did you find the idea of serverless architecture interesting? Take a look at
    *Building Serverless Applications with Python* by *Jalem Raj Rohit*, *Packt Publishing*,
    and dive deeper into the serverless architecture.
  prefs: []
  type: TYPE_NORMAL
