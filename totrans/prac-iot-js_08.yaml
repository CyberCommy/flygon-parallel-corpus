- en: Raspberry Pi Image Streaming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to look at live video streaming with Raspberry
    Pi 3 and Raspberry Pi camera. We are going to stream live video from Raspberry
    Pi 3 to our web browser and access this feed from anywhere in the world. As a
    next step, we are going to add a motion detector to the current setup and if the
    motion is detected, we then start streaming the video. In this chapter, we will
    go through the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding MJPEGs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up Raspberry Pi with Raspberry Pi camera
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stream the images from the camera to the dashboard in real time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Capturing video in motion
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MJPEG
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Quoting from Wikipedia, [https://en.wikipedia.org/wiki/Motion_JPEG](https://en.wikipedia.org/wiki/Motion_JPEG).
  prefs: []
  type: TYPE_NORMAL
- en: In multimedia, Motion JPEG (M-JPEG or MJPEG) is a video compression format in
    which each video frame or interlaced field of a digital video sequence is compressed
    separately as a JPEG image. Originally developed for multimedia PC applications,
    M-JPEG is now used by video-capture devices such as digital cameras, IP cameras,
    and webcams, as well as by non-linear video editing systems. It is natively supported
    by the QuickTime Player, the PlayStation console, and web browsersÂ such as Safari,
    Google Chrome, Mozilla Firefox and Microsoft Edge.
  prefs: []
  type: TYPE_NORMAL
- en: As described previously, we are going to capture a series of images, every `100ms`
    apart and stream the image binary data on a topic to the API engine, where we
    override an existing image with the latest image.
  prefs: []
  type: TYPE_NORMAL
- en: This streaming system is very simple and old-fashioned. There are no rewinds
    or pauses while streaming. We can always see the last frame.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a high level of understanding of what we are going to achieve,
    let us get started.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Raspberry Pi
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Raspberry Pi 3 set up with Raspberry Pi camera is quite simple. You can purchase
    a Raspberry Pi 3 camera ([https://www.raspberrypi.org/products/camera-module-v2/](https://www.raspberrypi.org/products/camera-module-v2/))
    from any of the popular online vendors. Then you can follow this video to setup:
    camera board setup: [https://www.youtube.com/watch?v=GImeVqHQzsE](https://www.youtube.com/watch?v=GImeVqHQzsE).'
  prefs: []
  type: TYPE_NORMAL
- en: 'My camera setup is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00108.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: I have used a stand and hoisted my camera on top of it.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the camera
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have the camera connected and powered by the Raspberry Pi 3, we
    will set up the camera, as shown in the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'From inside the Raspberry Pi, launch a new terminal and run:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This will launch the Raspberry Pi configuration screen. Select Interfacing
    options:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../images/00109.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'On the next screen, select P1 Camera and enable it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../images/00110.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: This will trigger a reboot, complete the reboot and log back into the Pi.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once your camera is set up, we will test it.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the camera
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that the camera is set up and powered, let''s test it. Open a new terminal
    and `cd` on the desktop. Then run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This will take a screenshot in the present working directory, `Desktop`. The
    screen will look something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00111.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, `test.jpg` is created on the `Desktop` and when I double-click
    it shows a picture of the glass wall of my office.
  prefs: []
  type: TYPE_NORMAL
- en: Developing the logic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we are able to test the camera, we will integrate this setup with our
    IoT platform. We are going to stream these images `100ms` apart continuously to
    our API engine and then through web sockets update the UI on the web.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started, we will make a copy of `chapter4` and dump it into a folder
    named `chapter8`. Inside the `chapter8` folder, open `pi/index.js` and update
    it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: As we can see from the preceding code, we are waiting for the MQTT connection
    to be completed, once the connection is completed, we call `startStreaming()`
    to start streaming. Inside `startStreaming()`, we are calling `raspistill.timelapse()`
    passing in `100ms`, as time difference between each click and `0` indicates that
    the capture should continue perpetually.
  prefs: []
  type: TYPE_NORMAL
- en: Once the image is captured, we construct the `data2Send` object with a random
    ID, the image buffer, and the device `macAddress`. Before publishing to the image
    topic, we stringify the `data2Send` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, move this file to Raspberry Pi''s `pi-client` folder, present on the desktop.
    And from inside Raspberry Pi''s, `pi-client` folder, run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: These two commands will install the `node-raspistill` and other node modules
    present inside the `package.json` file.
  prefs: []
  type: TYPE_NORMAL
- en: With this, we are done with the setup of the Raspberry Pi and the camera. In
    the next section, we will update the API engine to accept the live streaming of
    images.
  prefs: []
  type: TYPE_NORMAL
- en: Updating the API engine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we are done with the Raspberry Pi setup, we will update the API engine
    to accept the incoming data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we are going to do is update `api-engine/server/mqtt/index.js`
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As we can see from the preceding code, inside the message event of MQTT, we
    have added a new topic named `image`. Inside this topic, we extract the string
    format of the image buffer and convert it back to the image binary data. Then
    using the `fs` module, we overwrite the same image again and again.
  prefs: []
  type: TYPE_NORMAL
- en: We also keep saving the data simultaneously to MongoDB and this will trigger
    a socket emit.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the next step, we need to create a folder named `stream` inside the `mqtt`
    folder. And inside this folder, drop an image present here: `http://www.iconarchive.com/show/small-n-flat-icons-by-paomedia/sign-ban-icon.html.`
    This image will be shown if there is no feed available for a camera.'
  prefs: []
  type: TYPE_NORMAL
- en: All the images will be saved inside the `stream` folder and the same image will
    be updated for the same device, as mentioned earlier, there will not be any rewinds
    or replays.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, the images get saved inside the `stream` folder and we need to expose
    an end point to send this image to the request clients. For that, open `api-engine/server/routes.js`
    and add the following to the `module.exports` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This will take care of dispatching the image to the client (web, desktop, and
    mobile).
  prefs: []
  type: TYPE_NORMAL
- en: With this, we are done with setting up the API engine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Save all the files and start the broker, API engine, and the `pi-client`. If
    everything is successfully set up, we should see the data being posted from the
    Raspberry Pi:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00112.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'And the same data appearing in the API engine:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00113.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: At this point, the images are being captured and sent to the API engine over
    MQTTs. The next step is to view these images in real time.
  prefs: []
  type: TYPE_NORMAL
- en: Updating the web app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that the data is streaming to the API engine, we will show it on the web
    app. Open `web-app/src/app/device/device.component.html` and update it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are displaying the image that we have created in real time. Next,
    update `web-app/src/app/device/device.component.ts` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we are constructing the image URL and pointing it to the API engine. Save
    all the files and launch the web app by running the following command from inside
    the `web-app` folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'If everything works as expected, upon navigating to the VIEW DEVICE page, we
    should see the video stream very slowly. I am monitoring a cup placed in front
    of my chair as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00114.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Updating the desktop app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that the web app is done, we are going to build the same and deploy it inside
    our desktop app.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started, head back to the terminal/prompt of the `web-app` folder and
    run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This will create a new folder inside the `web-app` folder named `dist`. The
    contents of the `dist` folder should be along the lines of:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'All the code we have written is finally bundled into the preceding files. We
    will grab all the files (not the `dist` folder) present inside the `dist` folder
    and then paste it inside the `desktop-app/app` folder. The final structure of
    the `desktop-app` after the preceding changes will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'To test drive, run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'And then when we navigate to the VIEW DEVICE page, we should see:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00115.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: With this we are done with the development of the desktop app. In the next section,
    we will update the mobile app.
  prefs: []
  type: TYPE_NORMAL
- en: Updating the mobile app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last section, we have updated the desktop app. In this section, we are
    going to update the mobile app template to stream images.
  prefs: []
  type: TYPE_NORMAL
- en: 'First we are going to update the view-device template. Update `mobile-app/src/pages/view-device/view-device.html`
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The logic for displaying the image stream on a mobile is the same as web/desktop.
    Next, update `mobile-app/src/pages/view-device/view-device.ts` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Save all the files and run the mobile app either by using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Or by using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'And we should see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00116.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: With this we are done with displaying the data from the camera on the mobile
    app.
  prefs: []
  type: TYPE_NORMAL
- en: Motion-based video capture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we could see that the stream was kind of choppy, slow, and not real time,
    another probable solution is to put a motion detector along with our Raspberry
    Pi and camera. Then when a motion is identified, we start taking a video for 10
    seconds. Then we email this video to the user as an attachment.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we will start updating our existing code.
  prefs: []
  type: TYPE_NORMAL
- en: Updating the Raspberry Pi
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To get started, we will update our Raspberry Pi setup to accommodate an HC-SR501
    PIR sensor. You can find a PIR sensor here: [https://www.amazon.com/Motion-HC-SR501-Infrared-Arduino-Raspberry/dp/B00M1H7KBW/ref=sr_1_4_a_it](https://www.amazon.com/Motion-HC-SR501-Infrared-Arduino-Raspberry/dp/B00M1H7KBW/ref=sr_1_4_a_it).'
  prefs: []
  type: TYPE_NORMAL
- en: We will connect the PIR sensor to the Raspberry Pi on pin 17 and the camera
    to the camera slot as we have seen earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the connections are made as previously discussed, update `pi/index.js`
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: As we can see from the preceding code, we have marked GPIO 17 as an input pin
    and assigned it to a variable named `pir`. Next, using `pir.watch()`, we keep
    looking for a change in value on the motion detector. If the motion detector has
    detected some change, we will check if the value is `1`, which indicates that
    a motion is triggered. Then using `raspivid` we record a 5 second video and email
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the logic needed to send an email from Raspberry Pi 3, create a new file
    named `mailer.js` at the root of the `pi-client` folder and update it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We are using nodemailer to send an email. Update the credentials as applicable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we are going to test this setup.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we are done with the setup, let us test it. Power Raspberry Pi, upload
    the code if not done already, and run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the code is running, trigger a motion. This will start the camera recording
    and save the video for five seconds. Then this video will be emailed to the user.
    The following is a list of the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00117.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The received email would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00118.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: This is an alternative of using Raspberry Pi 3 for surveillance.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have seen two methods of surveillance using Raspberry Pi.
    The first approach is where we have streamed images to the API engine and then
    visualized the same on the mobile web and desktop applications using MJPEG. The
    second approach is to detect a motion and then start recording a video. Then email
    this video as an attachment. The two approaches can be combined together as well
    and the MJPEG streaming can be started if a motion is detected in approach one.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 9](part0143.html#48C0E0-ce91715363d04669bca1c1545beb57ee), *Smart
    Surveillance*, we are going to take this to the next level, we are going to add
    face recognition on top of our captures and perform face recognition (not face
    detection) using the AWS Rekognition platform.
  prefs: []
  type: TYPE_NORMAL
