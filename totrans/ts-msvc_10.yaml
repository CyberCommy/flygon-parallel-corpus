- en: Hardening Your Application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is very difficult to get security right. There always seems to be some open
    door for intruders to sneak in. Security mistakes are made all the time, such
    as the famous **WannaCry ransomware attack** (causing $5 billion of damage), **Ethereum
    theft** ($32 million heist), and so on. Such attacks always make us take extra
    steps toward security to avoid such disasters. As microservices are dynamic, any
    of the instances can go down leading to business loss.
  prefs: []
  type: TYPE_NORMAL
- en: 'With a focus on handling security and autoscaling, this chapter explores some
    security fundamentals and microservice best practices to make the system more
    secure and robust, and make it easy to handle any amount of traffic. With the
    advent of containers, we will be looking at security at the container level too,
    as well as the application level. This chapter also focuses on autoscaling with
    the aim of making the application available at any time to handle any load, with
    zero downtime during new deployments. This chapter covers the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Questions you should be asking while applying a security mechanism
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security best practices for individual services/applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security best practices for containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling your application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Questions you should be asking while applying security
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a constantly evolving world, we can't have a predefined set of rules to apply
    in microservice design. Rather, we can have some predefined questions that we
    can ask ourselves to evaluate the overall system and processes. The following
    sections list of all the standard questions at various levels, which we can use
    as an evaluation checklist. Later, we will be upgrading our security as a solution
    to these questions.
  prefs: []
  type: TYPE_NORMAL
- en: Core application/core microservice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will begin at the very core—our microservice. Whenever we write any microservice
    to satisfy any business capability, once it is designed, we need to take care
    of whether the service is exposed to any vulnerabilities or not. The following
    questions can be asked to get a general idea about security at the application
    level:'
  prefs: []
  type: TYPE_NORMAL
- en: Is the system properly secured at all places or just at the boundaries?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If an intruder sneaks in, is the system powerful enough to detect that intruder
    and throw him out?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How easy is it for an intruder to get inside the network by mimicking the usual
    behavior, get access to traffic, or overload traffic?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does each microservice trust other microservices even if they call them too
    much?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does your service contract have authentication or does the network handle authentication?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the identity of the caller passed along to each of the microservices or is
    it just lost at the gateway?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the measures to ensure that SQL injection doesn't occur?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the system updated enough to store passwords in encrypted form?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we need to upgrade any password storage algorithm, can it be done without
    mass disruption to users?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How is private and sensitive data handled in the system?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can your logging solution detect and analyze security breaches?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Middleware
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next level is our **middleware**. It''s the central place or starting point,
    where all services will pass through. We need to make sure that middleware is
    secured and cannot be exposed to any risk, as it has various parameters such as
    messaging middleware, database access configured, and so on:'
  prefs: []
  type: TYPE_NORMAL
- en: Do we have the least privilege principle (that is, single database login across
    all services)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does each service have access to only the data that it needs?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If an intruder gets access to service database credentials, how much data access
    will they get?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do we have a single messaging middleware across all services?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the messaging middleware or service bus have login credentials?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the legacy system put the microservice system at risk?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: API Gateway
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next level is our API Gateway. A gateway plays an important part in microservices
    as it is the starting point of any request and is used by all microservices as
    a means of communication between them. Hence, it should not be exposed to any
    other security vulnerabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: Is there a TLS implementation?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the TLS implementation remove downgrade attacks or weak cipher attacks?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do you make sure that internal websites and admin URLs are abstracted to
    the internet?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What information is circulated through the authentication APIs of your gateway
    service?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do the rest of the services trust the gateway too much or can they find out
    when the gateway is breached?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Team and operational activities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The final phase is team and operational activities. Being distributed in nature,
    every team works independently. In this case, it becomes an essential prerequisite
    that each team has enough security training. The following questions help us to
    evaluate security at the operational level:'
  prefs: []
  type: TYPE_NORMAL
- en: How are security activities baked in to every development team?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do you ensure that everyone is aware of common security principles?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What security training do you give to the team and do you update them regarding
    any vulnerabilities?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What automation level do you use to ensure security controls are always in place?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we will look at how we can harden the application and container,
    and go through various security best practices.
  prefs: []
  type: TYPE_NORMAL
- en: Security best practices for individual services/applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A microservice architecture shifts around complexity. Instead of having a single
    very complicated system, there are a bunch of simple services with complicated
    interactions. Our goal is to make sure that complexity stays in check and within
    boundaries. Security is really hard to get right. There are countless ways to
    break into an application. Node.js is no different. In this section, we are going
    to look at the techniques to prevent security vulnerabilities. This section is
    meant to act as a basic checklist to ensure that our microservice addresses some
    of the biggest security threats. So, let's get started.
  prefs: []
  type: TYPE_NORMAL
- en: Checking for known security vulnerabilities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Due to a wealth of modules available in `npm`, we can directly work on the
    application and rely on the ecosystem for ready-made solutions. However, due to
    the huge modules, larger security vulnerabilities can occur at any time even for
    mature popular frameworks. In this section, we will look at some valuable tools
    that ensure no vulnerabilities are present in the packages that the application
    relies on, or even while updating:'
  prefs: []
  type: TYPE_NORMAL
- en: Auditjs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A simple utility that audits an `npm` project using the OSS index v2 REST API
    to identify known vulnerabilities and outdated package versions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using this is very simple:'
  prefs: []
  type: TYPE_NORMAL
- en: Install it as a `dev` dependency `npm install auditjs --save-dev`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add audit scripts in the `npm` scripts:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Run the `npm run audit` command. The full example can be seen in the extracted
    folder under the `chapter 10/auditjs` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For more information you can visit the link [https://www.npmjs.com/package/auditjs](https://www.npmjs.com/package/auditjs) .
  prefs: []
  type: TYPE_NORMAL
- en: Snyk.io
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is another module that we can use to vet any modules against the vulnerability
    database maintained by `synk.io`. The major advantage of this module is that we
    do not need to install this for auditing. This module can be used as a pre-check
    before using any third-party module:'
  prefs: []
  type: TYPE_NORMAL
- en: Install it globally—`npm install snyk -g`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once installed, you will need to authenticate it by hitting `snyk auth`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once `snyk` is set up, you can now vet any module using `synk test <module_name>`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For more information you can visit the link [https://www.npmjs.com/package/snyk](https://www.npmjs.com/package/snyk).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some useful commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `snyk wizard` | Finds and fixes known vulnerabilities in a project |'
  prefs: []
  type: TYPE_TB
- en: '| `snyk protect` | Applies patches and suppresses vulnerabilities |'
  prefs: []
  type: TYPE_TB
- en: '| `snyk monitor` | Records the state of dependencies, so that whenever new
    vulnerabilities or patches are launched, we can be alerted |'
  prefs: []
  type: TYPE_TB
- en: 'Here is some further reading:'
  prefs: []
  type: TYPE_NORMAL
- en: There are lots of other modules available (we saw Node security earlier)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`retire.js` ([https://retirejs.github.io/retire.js/](https://retirejs.github.io/retire.js/))
    is yet another module that does similar vulnerabilities checking, and it can even
    be used as a command-line scanner, `grunt`/`gulp` plugin, Chrome or Firefox extension,
    and so on'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preventing brute force attacks or flooding by adding rate limiters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Brute force attacks are common and often serve as a last resort for the hacker.
    They systematically enumerate all possible candidates for a solution and check
    whether each candidate satisfies the problems statement or not. To protect against
    this kind of attack, we have to implement some kind of rate limiting algorithm,
    which will effectively block an IP address from making an outrageous amount of
    requests, thus blocking the possibility of accidentally crashing the application.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the rate-limiting implementation under the `Chapter 10/rate-limiter`
    folder, where we used the rate limiting algorithm with the Redis database.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install `express-limiter` and `redis`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the redis client and set express-limiter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, run the program. It will limit requests to `100` requests per hour, after
    which it will start to throw `429: Too Many Requests`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Protecting against evil regular expressions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the most commonly occurring vulnerabilities is a poorly formed regular
    expression. A regex, if it takes exponential time when applied to non-matching
    inputs, is termed an evil regex and should be prevented. An evil regex contains
    groupings with repetitions, alterations with overlappings, and words inside the
    repeated group. Let''s look at an example, `Regex : (b+)+, ([a-zA-Z]+)*,(a|aa)+`,
    and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: All these regexes are exposed to input `bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb!`.
    These repetitions can be a hindrance as it may take seconds or even minutes to
    complete. Due to the event loop of Node.js, the execution won't go ahead, which
    will effectively result in the server freezing as the application is completely
    stopped from running. To prevent such disasters, we should use the safe-regex
    tool ([https://www.npmjs.com/package/safe-regex](https://www.npmjs.com/package/safe-regex)).
    It detects potentially catastrophic exponential time regular expressions.
  prefs: []
  type: TYPE_NORMAL
- en: You can check the source code in the `safe-regex` folder. You can check the
    regex by just typing `node safe.js '<whatever-my-regex>'`.
  prefs: []
  type: TYPE_NORMAL
- en: Blocking cross-site request forgeries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A common way to intrude in an application is by putting data into the application
    via unsafe sites through a common phishing technique known as cross-site request
    forgery. An intruder making a phishing attempt can initiate a request via a form
    or other input that creates a request for an application through inputs exposed
    by the application.
  prefs: []
  type: TYPE_NORMAL
- en: To harden the application against this kind of attack, we can use CSRF token
    implementation. Every time a user makes a request, a new CSRF token is generated
    and added to the user's cookie. This token should be added as a value to the inputs
    in an applications template and this will be validated against the token the CSRF
    library generates when the user sends information. NPM provides the `csurf` module
    ([https://www.npmjs.com/package/csurf](https://www.npmjs.com/package/csurf)),
    which can be used in express middleware directly and we can play accordingly with
    the `csurf` token.
  prefs: []
  type: TYPE_NORMAL
- en: Tightening session cookies and effective session management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The focus of the secure use of cookies cannot be understated in an application.
    This especially applies to stateful services that need to maintain a state across
    a stateless protocol such as HTTP. Express has a default cookie setting that can
    be configured or manually tightened to enhance security. There are various options:'
  prefs: []
  type: TYPE_NORMAL
- en: '`secret`: A secret string with which the cookie has to be salted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`name`: Name of the cookie.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`httpOnly`: This basically flags cookies, so that they can be accessible by
    issuing a web server in order to prevent session hijacking.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`secure`: This requires TLS/SSL to allow a cookie to be used only in HTTPS
    requests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`domain`: This indicates specific domains only, from which the cookie can be
    accessed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`path`: The path cookie is accepted from an application''s domain.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`expires`: The expiration date of the cookie that is being set. If a timely
    expiration is not available, the resource consumption will be very high and resources
    will never be freed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the following example, we will securely set cookies using express-session
    and thus have effective session management. You can follow along with the example
    under `typescript-express-session`:'
  prefs: []
  type: TYPE_NORMAL
- en: Clone `first-microservice` from [Chapter 2](c1987454-3c62-4e25-abf5-28a9abf833e8.xhtml), *Gearing
    up for the Journey*, and install `express-session` and `@types/express-session`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In `express.ts`, add the following code, which will make our application use
    cookies with the following secured parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This module effectively helps us to handle stateful sessions by providing various
    options, such as cookie flags, cookie scopes, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Adding helmet to configure security headers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `helmet` module ([https://www.npmjs.com/package/helmet](https://www.npmjs.com/package/helmet))
    is a collection of 11 security modules that prevents a varying number of attacks
    against an express microservice. It''s easy to use, as we just have to add two
    lines of code. Adding some basic configurations can help to protect the application
    against possible security mishaps. You can use helmet by simply adding:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The source code for this can be found in `chapter-10/typescript-express-session`.
  prefs: []
  type: TYPE_NORMAL
- en: The `helmet` module has a whopping 12 packages that act as some middleware to
    block malicious parties from breaking or using an application. These headers include
    headers for `helmet-csp` (headers for content security policy HTTP header), `dns-prefetch`
    protocols, `frameguards`, `hide-powered-by`, `hpkp`, `hsts`, `ienoopen`, `nocache`,
    `dont-sniff-mimetype`, `referrer-policy`, `x-xss protections`, `frameguard` to
    prevent `clickjackings`, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Another option for securing headers is `lusca` ([https://www.npmjs.com/package/lusca](https://www.npmjs.com/package/lusca)),
    which can be used in combination with express-session. An example can be found
    in the `chapter-10 /express-lusca` directory.
  prefs: []
  type: TYPE_NORMAL
- en: Avoiding parameter pollution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In Node.js, if there are no defined standards for handling multiple parameters
    of the same name, the de facto standard is to treat those values as an array.
    This is extremely useful because for a single name when the expected outcome is
    a string, it types changes to an array if multiple parameters with the same name
    are passed. If this isn't accounted for in query handling, the application will
    crash and bring the whole thing down, making this a possible DoS vector. For example,
    check this link: `http://whatever-url:8080/my-end-point?name=parth&name=ghiya`.
    [](http://whatever-url:8080/my-end-point?name=parth&name=ghiya)
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, when we try to read `req.query.name`, we expect it to be a string, but
    instead we get an array, `[''parth'',''ghiya'']`, which will bring down the application
    if not handled with care. To ensure that the application won''t fail you, we can
    do the following things:'
  prefs: []
  type: TYPE_NORMAL
- en: Various policies implement polluting mechanisms differently; for example, some
    may take the first occurrence, some may take the last occurrence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use TypeScript types to validate the request. If the types fail, stop the request
    by giving parameters errors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure that parameters in HTTP GET, PUT, or POST are encoded.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strict Regexp must be followed in URL rewriting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can check the complete list and how it is handled at [https://www.owasp.org/index.php/Testing_for_HTTP_Parameter_pollution_(OTG-INPVAL-004)](https://www.owasp.org/index.php/Testing_for_HTTP_Parameter_pollution_(OTG-INPVAL-004)).
  prefs: []
  type: TYPE_NORMAL
- en: Securing transmission
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If an application has any moving parts (HTTP methods such as POST, PUT, and
    DELETE) that include anything right from logging or sending a tweet which mutates
    the information from the client, using HTTPs is a vital implementation to make
    sure that the information isn''t modified in mid-transit. Cost can be an easy
    excuse for not investing in an SSL certificate. But now there are new, completely
    free, SSL certificate resources, such as **Let''s Encrypt** ([https://letsencrypt.org/](https://letsencrypt.org/)).
    Also, a Node.js application should not be directly exposed to the internet and
    SSL termination should be handled prior to the request coming to Node.js. Using
    NGINX to do this is a highly recommended option, as it is specially designed to
    terminate SSL more efficiently than Node.js. To effectively set an express application
    behind a proxy, refer to this: [http://expressjs.com/en/4x/api.html#trust.proxy.options.table](http://expressjs.com/en/4x/api.html#trust.proxy.options.table).
    Once the HTTP is set up, we can use `nmap`, `sslyze`, or `OpenSSL` to test HTTP
    certificate transmission.'
  prefs: []
  type: TYPE_NORMAL
- en: Preventing command injection/SQL injection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An injection attack can occur when an intruder sends text-based attacks that
    exploit the syntax of an interpreter. SQL injection consists of the injection
    of a partial or complete SQL query through user input, which can expose sensitive
    information and can be destructive as well. Similarly, command injection is a
    technique that can be used by an attacker to run OS commands on a remote web server.
    Through this approach, even passwords can be exposed. To filter against these
    kinds of attack, we should always filter and sanitize user inputs. Using JavaScript
    statements such as eval is also another way to opens up a door to injection attacks.
    To prevent these attacks, we can use `node-postgres` if you are using `postgres`
    ([https://www.npmjs.com/package/pg](https://www.npmjs.com/package/pg)), which
    provides positional query parameters. Common techniques to defend against injection
    include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: To escape SQL injection, one of the techniques that can be used is escaping
    user input. Many libraries provide this out of the box.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parameterizing SQL queries is another way to avoid SQL injection, where you
    create a using positional query parameters and fill in the positional query parameters
    with values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eval()` with user input is one of the ways to inject commands and should not
    be used at all (in the next section, we will write a `linter`, which will avoid
    this).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarly, the express application is vulnerable to MongoDB attacks. Not explicitly
    setting the query selector will result in our data being vulnerable to a simple
    query.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We have `db.users.find({user: user, pass: pass})`, where `user` and `pass`
    are coming from a POST request body. Now being type-less, we can simply pass query
    parameters inside this query, such as `{"user": {"$gt": ""},"pass": {"$gt": ""}}`,
    which will return all users along with their passwords. To resolve this, we need
    to explicitly pass the query selector, which will make our query `db.users.find({user:
    { $in: [user] }, pass: { $in: [pass] }})`.'
  prefs: []
  type: TYPE_NORMAL
- en: TSLint/static code analyzers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will look at one of the ways to analyze all the written
    code and check it against a list of security vulnerabilities. We will include
    this as one of the stages of our deployment plan. We will write a `linter`, have
    a `.tslint` file where all the rules to be checked against are mentioned, and
    then we will run the lint. So, let''s get started. **TsLint** is one way to check
    and validate the source code. It is a static analysis code tool that runs on Node.js
    in order to keep your source code clean, find possible bugs, uncover security
    issues, and enforce a consistent style across all your teams:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Clone our `first-typescript-microservices` from [Chapter 2](c1987454-3c62-4e25-abf5-28a9abf833e8.xhtml), *Gearing
    up for the Journey* and inside it, add the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will write `tslint.json` with the basic rules that we want to evaluate
    it against. Copy the rules from [https://github.com/Microsoft/tslint-microsoft-contrib/blob/master/recommended_ruleset.js](https://github.com/Microsoft/tslint-microsoft-contrib/blob/master/recommended_ruleset.js).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we will write an initialization script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We can now leverage this script anywhere because when we run this, it will throw
    an output of all the errors found while evaluating against that rule set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can add a `--fix` flag in the preceding script, which will automatically
    take the necessary measures in most cases.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can find the source code under the `chapter 10/tslinter` folder. In this
    section, we looked at some of the things that need to be done when hardening our
    application against all sorts of possible attacks. In the next section, we will
    have a look at some of the container-level securities that can be applied.
  prefs: []
  type: TYPE_NORMAL
- en: Security best practices for containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the advent of containers, cloud-native applications and infrastructure
    need quite a different approach to security. Let's have a look at the best practices.
    This is the age of the **cloud-native** approach. The cloud-native approach refers
    to a process that packages software in standard units called containers and arranges
    these units in microservices that communicate with each other to form applications.
    It ensures that running applications are fully automated for the greater good—standard
    speed, agility, and scalability. Let's look at the security considerations that
    need to be addressed to have a comprehensive security program.
  prefs: []
  type: TYPE_NORMAL
- en: Securing container builds and standardizing deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This phase focuses on applying control to developer workflows and continuous
    integration and deployment pipelines to mitigate the security issues that may occur
    after containers have been launched. Here is the standard set of practices:'
  prefs: []
  type: TYPE_NORMAL
- en: Apply a single responsibility rule even at the container level. A container
    image should only have the essential software and application code needed to minimize
    the attack surface of every container launched from the image.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Images should be scanned for known vulnerabilities and exposures. There is a
    common vulnerabilities and exposure database (just like the application level)
    on which we can validate the image ([https://github.com/arminc/clair-scanner](https://github.com/arminc/clair-scanner)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once images are built, they should be digitally signed. **Signing images** ([https://docs.docker.com/datacenter/dtr/2.4/guides/user/manage-images/sign-images/#initialize-the-trust-metadata](https://docs.docker.com/datacenter/dtr/2.4/guides/user/manage-images/sign-images/#initialize-the-trust-metadata))
    with private keys provides assurances that each image used to launch a container
    was created by a trusted party.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As containers running on a host share the same OS, it is of utmost importance
    that they start with a restricted set of capabilities. Use modules such as SELinux.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use secret management techniques (a technique through which secrets such as
    sensitive data are only distributed to the containers that use them when they
    need them).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Securing containers at runtime
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For runtime phase security, we need to check the following things—visibility,
    detection, response, prevention, stopping containers that violate policies, and
    so on. Here are some of the important factors that need to be taken care of:'
  prefs: []
  type: TYPE_NORMAL
- en: Analyze microservice and containers behavior
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Relate distributed threat indicators, and ascertain whether a single container
    is contaminated or it is spread across many containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Intercept to block unauthorized container engine commands
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automate actions for responses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are some of the essentials we need to do to ensure that our containers
    are safe against any vulnerabilities. In the next section, we will see a general
    checklist that can be used during our overall microservice development phase.
  prefs: []
  type: TYPE_NORMAL
- en: Security checklist
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices development is a platform of standard tools combined with lots
    of supporting tools and everything is on the move. In this section, we will look
    at an overall checklist, which we can use to validate our development, or which
    can give us a general idea of our microservice development.
  prefs: []
  type: TYPE_NORMAL
- en: Service necessities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first and primary level of development is individual microservice development,
    satisfying some business capability. The following a checklist can be used while
    developing microservices:'
  prefs: []
  type: TYPE_NORMAL
- en: Services should be developed and deployed independently
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Services should not have shared data; they should have their own private data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Services should be small enough that they are focused and can add big value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data should be stored in databases and service instances should not be stored
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Work should be offloaded to asynchronous workers whenever possible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load balancers should be introduced to distribute work
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security should be layered and we don't need to reinvent the wheel; for example,
    OAuth can be used to maintain user identity and access control
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security updates should be automated
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A distributed firewall with centralized control should be used (such as Project
    Calico)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring tools, such as Prometheus, should be used
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security scanners should be used for containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service interactions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next level is communication among microservices. When microservices communicate
    among themselves, a checklist should be followed. This checklist helps to ensure
    that if any service fails, then the failure is contained and it doesn''t spread
    through the entire system:'
  prefs: []
  type: TYPE_NORMAL
- en: Data should be transported in a serialized format, such as JSON or protobuf
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Error codes should be used carefully and actions should be taken accordingly
    on them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: APIs should be simple, effective, and the contract should be clear
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A service discovery mechanism should be implemented to find other services easily
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decentralized interactions over centralized orchestrators should be preferred
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: APIs should be versioned
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Circuit breakers help to stop the error propagating throughout the entire system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service interactions should only be through exposed endpoints
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Authenticating all APIs and passing them through middleware gives a clearer
    picture of usage patterns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connection pools can reduce downstream impacts instead of sudden request spikes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Development phase
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next phase to take care of is during development. This checklist adheres
    to the 12 factor standards. The following checklist is of development standards,
    which help in a smoother development process:'
  prefs: []
  type: TYPE_NORMAL
- en: A common source code control platform should be used
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There should be separate prod environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A release less, release it faster principle should be followed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shared libraries are painful to maintain
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simple services are easy to replace
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The deployment checklist focuses on the deployment era. It indicates how containers
    and images help in quicker deployments. It advises on key values and property
    configurations to manage deployments in different environments:'
  prefs: []
  type: TYPE_NORMAL
- en: Images and containers should be used
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configure a mechanism to deploy any version of any service on any environment
    (CI/CD plus proper Git branches and tags)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuration should be managed outside the deployment package, such as environment
    variables, key-value stores, external URL links, and so on
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The operational checklist contains a list of best practices to be done at an
    operational level to make the after-release life of a system easy. It advises
    using centralized logs, monitoring software, and more. It shows how automation
    can make life easier:'
  prefs: []
  type: TYPE_NORMAL
- en: All logs should be in one place (ELK stack)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A common monitoring platform for all services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stateless services can easily be autoscaled, as we don't have to replicate the
    session everywhere
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automation is the key to quick development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That's pretty much it! In the next section, we will cover scalability and look
    at some of the scalability tools available before concluding the book.
  prefs: []
  type: TYPE_NORMAL
- en: Scalability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Today, in the world of competitive marketing, an organization's key point is
    to have their system up and running. Any failure or downtime directly impacts
    business and revenue; hence, high availability is a factor that cannot be overlooked.
    Day by day, the mountain of information is growing thanks to the in-depth use
    of technology and the numerous ways we use it. Because of this, load average goes
    beyond the roof. Day by day, data is growing exponentially.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, it is unpredictable that data cannot exceed up to some limit
    or a variety of users won't depart out of bounds. Scalability is a preferable
    solution to handle and meet unexpected demands at any point in time. Scalability
    can scale horizontally (we scale by adding more machines to a pool of resources)
    and vertically (we scale by adding more CPU/RAM to an existing machine). In terms
    of data, spanning database and loads of application queries over multiple servers.
    We can add instances in order to handle load, descale after period of time, and
    so on. It is easy to add horsepower to the cluster to handle the load. Cluster
    servers instantly handle failures and manage the failover part to keep your system
    available almost all the time. If one server goes down, it will redirect the user's
    request to another node and perform the requested operation. In this section,
    we will look at two of the most famous tools—Kubernetes and the AWS Load Balancer.
  prefs: []
  type: TYPE_NORMAL
- en: AWS Load Balancer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For load balancing, we should understand **Amazon Web Services Elastic Load
    Balancer** (**ELB**), which can help us to leverage load balancing. We should
    understand AWS ELB specifically; however, most of the concepts remain the same
    for the rest of the load balancing alternatives available. There are various alternatives
    available to achieve load balancing. A few of them are HAProxy, Apache Web Server,
    NGINX Http server, Pound, Google Cloud Load balancing, F5 Load Balancer, Barracuda
    Load Balancer, and many more. In general, the following is the architecture that
    depicts the flow of load balancing:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6894138b-b329-4769-9f88-717f6ab46e70.png)'
  prefs: []
  type: TYPE_IMG
- en: Load balancer
  prefs: []
  type: TYPE_NORMAL
- en: An ELB is one of the many available AWS services, which works to distribute
    incoming network traffic or application traffic to EC2 instances available in
    the network automatically. ELB also keeps an eye on the health of EC2 instances
    to provide high availability for the application by automatically adding or removing
    EC2 instances. It sends traffic only to instances that are available and in a
    healthy state. You can also configure ELB for internal load balancing or public-facing
    load balancing. ELB it becomes the face of the EC2 instances running behind wherever
    your application resides. Depending on the status or availability of the instances,
    a health check would mark it as either `InService`—if it's in a healthy state,
    or `OutOfService`—if it's in an unhealthy state. The load balancer would route
    traffic only to instances that are healthy. With the help of this health check,
    a load balancer provides us with a fault tolerant proof application and ensures
    the application's high availability 24/7, based on our configured parameters (high
    traffic, high resource utilization, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: Benefits of using a load balancer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A load balancer helps us to provide a fault tolerant application, much better
    high availability, flexibility to the application, and security too, as we wouldn't
    be exposing backend systems directly to the user. Let's have a quick glance at
    some of the benefits of having a load balancer.
  prefs: []
  type: TYPE_NORMAL
- en: Fault tolerance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A load balancer helps to monitor the health of the backend instances. If one
    of the instances is unavailable, it would be marked as unavailable. Similarly,
    if the instances are healthy, it would be available to serve the requests. Traffic
    would be routed only to available healthy instances. This provides a fault tolerant
    application so the traffic reaching the application is not affected when we have
    unavailable instances in the backend. However, if none of your systems are unavailable
    in the backend to serve requests, the load balancer marks all the instances as
    unhealthy and users will be affected by an unavailable application.
  prefs: []
  type: TYPE_NORMAL
- en: High availability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What if we have an application running without a load balancer? If the number
    of requests to the application increases, our instances might not be able to handle
    the load of the requests and the performance of the application would deteriorate.
    Not only this, it might also affect the availability of the application. If we
    have a load balancer, it can route the traffic based on a round-robin method to
    all the instances and can easily distribute the load across the instances. This
    helps to overcome a situation of high availability and not restricting limited
    instances to be flooded with unexpected spikes, which might impact the business.
  prefs: []
  type: TYPE_NORMAL
- en: Flexibility
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although we discussed fault tolerance and high availability with presumed instances,
    our requests might go beyond the expected limit of the application. In fact, they
    can be below the limit as well. Either of these may lead to a business loss in
    terms of the additional cost of running instances or degraded application performance.
    To manage either of these scenarios, many load balancers, especially in public
    clouds such as AWS ELB, Google Cloud Load Balancing, and a few more, provide the
    flexibility to have the auto-scaling of instances based on certain criteria, such
    as memory or CPU utilization, which can, add or remove a number of instances in
    the load balancer when it scales up or down. Load balancing with such features
    helps to ensure that we manage unexpected spikes of either high or low efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: Security
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Load balancers can also be configured to be not only public-facing instances;
    they can be configured to be private-facing instances as well. This can help in
    cases when there is a secured network or site-to-site VPN tunnel. This helps to
    guard our instances against public interfaces and limit them only to a private
    network. With the help of a private-facing load balancer, we can also configure
    for internal routing of backend systems without exposing them to the internet.
  prefs: []
  type: TYPE_NORMAL
- en: A load balancer has various features, such as configuring protocols, sticky
    sessions, connection draining, idle connection timeout, metrics, access logs,
    host-based routing, path-based routing, load balancing to multiple ports on the
    same instance, and HTTP/2 support.
  prefs: []
  type: TYPE_NORMAL
- en: We looked at many features of load balancers, but we have one more important
    feature to look at. Yes, you are right; it's the health check. Health checks work
    as heartbeats for the load balancer and our application. Let's have look at health
    checks in a bit more detail to understand why they are heartbeats for the load
    balancer.
  prefs: []
  type: TYPE_NORMAL
- en: Health check parameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To discover and maintain the availability of EC2 instances, a load balancer
    periodically sends pings (attempted connections) or sends test requests to test
    EC2 instances. These checks are called health check parameters. The following
    is a list of all health check parameters. Health checks help us to determine if
    an instance is healthy or unhealthy. Let us look at a few of the common configuration
    options available in health checks for most load balancers. The configuration
    options naming convention will vary from one load balancer to another; however,
    conceptually the following configuration parameters are available.
  prefs: []
  type: TYPE_NORMAL
- en: Unhealthy threshold
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In unhealthy attempts, it is expected to validate by the number of times the
    load balancer doesn't get a positive response from the backend. For instance,
    if we have configured a value of five unhealthy attempts, the load balancer would
    mark the instance unhealthy only if it doesn't get five healthy responses from
    the instance.
  prefs: []
  type: TYPE_NORMAL
- en: Healthy threshold
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is exactly opposite to unhealthy attempts; it is expected to validate by
    the number of times the load balancer gets a positive response from the backend.
    For instance, if we have configured a value of two healthy attempts, the load
    balancer would mark the instance available only if it gets two healthy responses
    from the instance.
  prefs: []
  type: TYPE_NORMAL
- en: Timeout
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A health check may be configured to check a URI. Let's say `/login.html` is
    supposed to be checked by a load balancer for a healthy response but doesn't respond
    within the time specified in the timeout. It would be considered an unhealthy
    response. This configuration would help us if there is an instance that may be
    affected due to limited system resource availability and not responding as per
    the expected time which we would have expected. Ideally, it is suggested to configure
    the timeout near to the actual response time from the instance for effective use.
  prefs: []
  type: TYPE_NORMAL
- en: Health check protocol
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can configure the health protocol type in diverse ways. We can have a health
    check based on a HTTP response, HTTPS response, TCP response, or HTTP/HTTPS body
    response. These are the most commonly available health check types, available
    in most load balancers.
  prefs: []
  type: TYPE_NORMAL
- en: Health check port
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can also configure health check ports. We can configure health checks based
    on various protocols, as we have just discussed, but if we have custom ports for
    the application, the load balancer can be configured accordingly. For instance,
    if we have an HTTP server in our backend instance running on port `81` instead
    of the default port `80`, we can configure HTTP as the health check protocol with
    the custom port `81` defined in the health check port.
  prefs: []
  type: TYPE_NORMAL
- en: Interval
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This configuration parameter determines after how much time a health check should
    count heart beats for our backend instances. In general, it is configured in seconds,
    so if we configure an interval of 10 seconds, the load balancer will keep on repeating
    its check every 10 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring a load balancer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we know about our health check parameters, let''s configure a load
    balancer. You will need to create an account on AWS and launch one instance:'
  prefs: []
  type: TYPE_NORMAL
- en: Open up your instance and then go to the Load Balancing | Load balancers tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a load balancer. You will be able to choose from an application load
    balancer, network load balancer, or classic load balancer. The uses of these are
    shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/10681f34-fa79-4852-a499-a2adcac13b9c.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Types of load balancer
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is to configure the load balancer and add health checks as per
    your requirements. All the steps can be seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3a06ce28-6a7f-481a-8fcb-c52d5a45f2aa.png)'
  prefs: []
  type: TYPE_IMG
- en: Configuring the ELB Load Balancer
  prefs: []
  type: TYPE_NORMAL
- en: You can specify the health parameters as per the theory discussed. Health checks
    ensure that request traffic is shifted away from failed instances.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Autoscaling – practical hands on with AWS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, we will do **autoscaling** using *AWS autoscaling groups*, a load balancer,
    and configuration properties. So, let''s get started. Here is the overall process
    that we are going to follow:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a launch configuration that will run our `first-typescript microservice`
    from [Chapter 2](c1987454-3c62-4e25-abf5-28a9abf833e8.xhtml), *Gearing up for
    the Journey*, to start the HTTP server
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an autoscaling group
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an autoscaling policy to increase instances by two when the CPU load
    is greater than 20% for a minute
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the criteria for removing the autoscaling group.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Auto-terminate the instances
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: So, let's get our hands dirty.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the launch configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Log in to the AWS console and navigate to the EC2 dashboard. Select the launch
    configuration to start the wizard. Create the launch configuration accordingly
    to the wizard:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d2a680c1-5e05-4da3-a9ea-4b87ef43ff72.png)'
  prefs: []
  type: TYPE_IMG
- en: Launch configuration
  prefs: []
  type: TYPE_NORMAL
- en: We should have EC2 instances ready to host our `first-typescript-microservices`
    application.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an autoscaling group and configuring it with autoscaling policies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we have a blueprint ready, we need the building base that is our autoscaling
    group. Create an autoscaling group and the following instance will appear. Enter
    appropriate values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bdcfca7f-f0d2-41b7-90d1-315dcfc26b02.png)'
  prefs: []
  type: TYPE_IMG
- en: Creating an autoscaling group
  prefs: []
  type: TYPE_NORMAL
- en: 'This is how the wizard will look for configuring scale-up and scale-down strategies:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b4e12a4b-4fe9-4d43-9b13-2ce2f887bfd4.png)'
  prefs: []
  type: TYPE_IMG
- en: Autoscaling and auto terminating policies
  prefs: []
  type: TYPE_NORMAL
- en: After reviewing, click OK and your AWS scaling group is now ready.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an application load balancer and adding a target group
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next step is to create an application load balancer and attach a target
    group to it. So, create a new ELB (we can use the one we created earlier for health
    check configurations). Add a name for the target group and in Step 5 of the figure
    (Configuring ELB Load Balancer), register the instances that were launched by
    the autoscaling group:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d86a585a-dcbc-4c78-bc76-3b2cc4297c19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Attaching instances to load balancers
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to associate this target group with our autoscaling group.
    To do this, edit your autoscaling group and add the target group by name (there
    should be an autocomplete dropdown). We are all done with configuring AWS.
  prefs: []
  type: TYPE_NORMAL
- en: Time to test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To do load testing, I would prefer a simple load test module ([https://www.npmjs.com/package/loadtest](https://www.npmjs.com/package/loadtest))
    rather than setting up the entirety of Jmeter. Install the module by simply installing `npm
    install loadtest -g`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, just to run the stress test, we can hit the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Here, `-c` means concurrent requests and `--rps` means requests per second for
    each client. This will trigger an alarm to increase the CPU count by 2\. Go to
    the AWS console after the alert time/wait period has elapsed to check your newly
    created instances. You will be able to see instances when the load has increased
    and after the load has decreased, it will automatically start to drain and terminate.
  prefs: []
  type: TYPE_NORMAL
- en: We successfully autoscaled our instances up and down based on policies.
  prefs: []
  type: TYPE_NORMAL
- en: AWS has an interesting terminology—spot instances. These enables us to reuse
    unused EC2 instances, which can lower our EC2 instances significantly. Since the
    span of autoscaled instance is not that large, using a spot instance while scaling
    up is highly advantageous, and beneficial from a monetary perspective too.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling with Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes is an open source system for automating deployments, scaling, and
    managing containerized applications. At the time of writing this book, the Kubernetes
    Version was **1.9.2**. In this section, we will look at some of the basic features
    provided by Kubernetes and the terms used in it. So, let's get started.
  prefs: []
  type: TYPE_NORMAL
- en: What problem does Kubernetes solve?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With Docker, we have commands such as `docker run`, `docker build`, or `docker
    stop`. Unlike these commands, which perform operations on a single container,
    there is no command like docker deploy to push new images to a group of hosts.
    To solve this problem, Kubernetes is one of the most promising tools. Kubernetes
    provides powerful abstractions that completely decouple application-wise operations,
    such as deployment and scaling. Kubernetes sees the underlying infrastructure
    as a sea of computers in which we can put containers.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes has a client-server architecture, where the Kubernetes server runs
    on the cluster on which we deploy our application. We interact with the Kubernetes
    server using the *kubectl CLI*:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pods:** Our running containerized application with environment variables
    such as disks. Pods are born and die quickly, such as at deployment times.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Node:** A node is a physical or virtual machine running Kubernetes, on which
    pods can be scheduled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Secret:** We separate out our credentials from environment variables.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service:** This exposes our running pods by labeling them to other applications
    or to the outside world on the desired IP and port.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For development purposes, we can use *minikube* and *kubectl*. At the production
    level, the ideal way is to use **GCP's** (**Google Cloud Platform's**) inbuilt
    Kubernetes. Trying to run `minikube` and `kubectl` inside VMBox wont be possible
    as it would become nested virtualization. You can download Kubernetes on NativeOS
    as per instructions found here [https://kubernetes.io/docs/setup/](https://kubernetes.io/docs/setup/).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will get our application running with Kubernetes before
    winding up. You will need a Google Cloud Platform account for this exercise. Google
    provides a $300 credit free tier. So, let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: Kubectl is a CLI tool for running commands against Kubernetes and we need the
    Google Cloud SDK. Install the Google Cloud SDK and Kubectl, and initialize your
    SDK with the `gcloud init` command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The next step is to set up a project, so create one project in the web UI and
    set the default project ID while working with the CLI by running:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Revisit [Chapter 2](c1987454-3c62-4e25-abf5-28a9abf833e8.xhtml), *Gearing up
    for the Journey*, to gather the `docker build` and `docker run` commands locally:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will create a cluster with three instances where we will deploy our
    application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'For example, the `gcloud container clusters create hello-world-cluster --zone
    us-east1-b --machine-type f1-micro`. `F1-mico` is the smallest available unit.
    We can connect the `kubectl` client Kubernetes server with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have a Docker image and server cluster, in which we want to to deploy
    the image and start the containers. So, build and then upload the image using
    the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'To deploy, create the following `deployment.yml` file from following `gist`
    ([https://gist.github.com/insanityrules/ef1d556721173b7815e09c24bd9355b1](https://gist.github.com/insanityrules/ef1d556721173b7815e09c24bd9355b1)),
    which will create two pods. To apply this, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Now, when you do `kubectl get pods`, you will get three pods. To check the logs
    of the system, we can hit `kubectl logs {pod-name}`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To expose it to the internet and to add scalability to the load balancer, hit
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: In this section, we deployed our application on Kubernetes with three replicas
    on which we can autoscale or close down unwanted instances, just like AWS.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we went through our hardening layer. We looked at all the vulnerabilities
    our service is exposed to, and we learned about how to address them. We looked
    at some fundamentals, such as rate limiting, session handling, how to prevent
    parameter pollution, and more. We got acquainted with security at the container
    level and went through all the best practices for handling microservice security
    before moving on to scalability. We looked at Kubernetes and the Amazon load balancer,
    and got hands-on with both.
  prefs: []
  type: TYPE_NORMAL
- en: So far, you have learned how to build microservices using TpeScript on the Node.js
    platform and learned about all the aspects of microservice development, right
    from developing, the API Gateway, service registry, discovery, inter-service communication,
    Swagger, deployment, and testing. The objective of the book was to give you a
    practical hands-on guide to the microservice development and an understanding
    of the basic aspects to get you up and running. I really hope this book covers
    the empty space that is missing in the Node.js community, when compared to the
    Spring Cloud and Java community.
  prefs: []
  type: TYPE_NORMAL
