- en: 11\. Serverless functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Serverless and serverless functions have gained tremendous traction over the
    past few years. Cloud services such as Azure Functions, AWS Lambda, and GCP Cloud
    Run have made it very easy for developers to run their code as serverless functions.
  prefs: []
  type: TYPE_NORMAL
- en: The word *serverless* refers to any solution where you don't need to manage
    servers. Serverless functions refer to a subset of serverless computing, where
    you can run your code as a function on-demand. This means that your code in the
    function will only run and be executed when there is a *demand*. This architectural
    style is called event-driven architecture. In an event-driven architecture, the
    event consumers are triggered when there is an event. In the case of serverless
    functions, the event consumers will be these serverless functions. An event can
    be anything from a message on a queue to a new object uploaded to storage, or
    even an HTTP call.
  prefs: []
  type: TYPE_NORMAL
- en: Serverless functions are frequently used for backend processing. A common example
    of serverless functions is creating thumbnails of a picture that is uploaded to
    storage. Since you cannot predict how many pictures will be uploaded and when
    they will be uploaded, it is hard to plan traditional infrastructure and how many
    servers you should have available for this process. If you implement the creation
    of that thumbnail as a serverless function, this function will be called on each
    picture that is uploaded. You don't have to plan the number of functions since
    each new picture will trigger a new function to be executed.
  prefs: []
  type: TYPE_NORMAL
- en: This automatic scaling is just one benefit of using serverless functions. As
    you saw in the previous example, functions will automatically scale to meet increased
    or decreased demand. Additionally, each function can scale independently from
    other functions. Another benefit of serverless functions is the ease of use for
    developers. Serverless functions allow code to be deployed without worrying about
    managing servers and middleware. Finally, in public cloud serverless functions,
    you pay per execution of the function. This means that you pay each time your
    functions is run, and you are charged nothing for the idle time when your function
    is not run.
  prefs: []
  type: TYPE_NORMAL
- en: 'The popularity of public cloud serverless functions platforms has caused multiple
    open-source frameworks to be created to enable users to create serverless functions
    on top of Kubernetes. In this chapter, you will learn how to deploy serverless
    functions on **Azure Kubernetes Services** (**AKS**) directly using the open-source
    version of Azure Functions. You will start by running a simple function that is
    triggered based on an HTTP message. Afterward, you will install a function''s
    autoscaler feature on your cluster. You will also integrate AKS-deployed applications
    with Azure storage queues. We will be covering the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Overview of different functions platforms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying an HTTP-triggered function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying a queue-triggered function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's start this chapter by exploring the multiple function platforms that are
    available for Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple functions platforms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Functions platforms, such as Azure Functions, AWS Lambda, and Google Cloud Functions,
    have gained tremendously in popularity. The ability to run code without thinking
    about servers and having virtually limitless scale is very popular. The downside
    of using a cloud provider's functions implementation is that you are locked into
    their infrastructure and their programming model. Also, you can only run your
    functions in the public cloud and not in your own datacenter.
  prefs: []
  type: TYPE_NORMAL
- en: 'A number of open-source functions frameworks have been launched to solve these
    downsides. There are a number of popular frameworks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Serverless** ([https://serverless.com/](https://serverless.com/)): A Node.js-based
    serverless application framework that can deploy and manage functions on multiple
    cloud providers, including Azure. Kubernetes support is provided via Kubeless.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**OpenFaaS** ([https://www.openfaas.com/](https://www.openfaas.com/)): OpenFaaS
    is a serverless framework that is Kubernetes-native. It can run on either managed
    Kubernetes environments such as AKS, or on a self-hosted cluster. OpenFaaS is
    also available as a managed cloud service using OpenFaaSCloud. The platform is
    written in the Go language.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fission.io** ([https://fission.io/](https://fission.io/)): Fission is written
    in the Go language and is Kubernetes-native. It is a serverless framework backed
    by the company Platform9\.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Apache OpenWhisk** ([https://openwhisk.apache.org/](https://openwhisk.apache.org/)):
    OpenWhisk is an open-source, distributed serverless platform maintained by the
    Apache organization. It can be run on Kubernetes, Mesos, and Docker Compose. It
    is primarily written in the Scala language.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Knative** ([https://cloud.google.com/knative/](https://cloud.google.com/knative/)):
    Knative is a serverless functions platform written in the Go language and developed
    by Google. You can run Knative functions either fully managed on Google Cloud
    or on your own Kubernetes cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microsoft has taken an interesting strategy with its functions platform. Microsoft
    operates Azure Functions as a managed service on Azure and has open-sourced the
    complete solution and made it available to run on any system ([https://github.com/Azure/azure-functions-host](https://github.com/Azure/azure-functions-host)).
    This also makes the Azure Functions programming model available on top of Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft has also released an additional open-source project in partnership
    with Red Hat called **Kubernetes Event-driven Autoscaling** (**KEDA**) to make
    scaling functions on top of Kubernetes easier. **KEDA** is a custom autoscaler
    that can allow Deployments to scale to and from 0 Pods. Scaling from 0 to 1 Pod
    is important so that your application can start processing events. Scaling down
    to 0 instances is useful for preserving resources in your cluster. Scaling to
    and from 0 Pods is not possible using the default **Horizontal Pod Autoscaler
    (HPA)** in Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: KEDA also makes additional metrics available to the Kubernetes HPA to make scaling
    decisions based on metrics from outside the cluster (for example, the number of
    messages in a queue).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We introduced and explained the HPA in *Chapter 4*, *Scaling your application*.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will deploy Azure Functions to Kubernetes in two examples:'
  prefs: []
  type: TYPE_NORMAL
- en: An HTTP-triggered function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A queue-triggered function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before we start, we need to set up an **Azure Container Registry** (**ACR**)
    and a development machine. The ACR will be used to store custom Docker images
    that contain the functions we will develop. We will use a development machine
    to build the functions and create Docker images.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up prerequisites
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will set up the prerequisites we need in order to build
    and run functions. We need a container registry and a development machine.
  prefs: []
  type: TYPE_NORMAL
- en: We introduced container images and a container registry in *Chapter 1*, *Introduction
    to Docker and Kubernetes*, in the section on *Docker images*. A container image
    contains all the software required to start an actual running container. In this
    chapter, we will build custom Docker images that contain our functions. We need
    a place to store these images so that Kubernetes can pull these images and run
    the containers at scale. We will use the Azure Container Registry for this. Azure
    Container Registry is a private container registry that is fully managed by Azure.
  prefs: []
  type: TYPE_NORMAL
- en: Up to now in this book, we have run all the examples on the Azure Cloud Shell.
    For the example in this chapter, we need a separate development machine because
    the Azure Cloud Shell doesn't allow you to build Docker images. We will create
    a new development machine on Azure to do these tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Let's begin by creating an ACR.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Container Registry
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Azure Functions on Kubernetes needs an image registry to store its container
    images. In this section, we will create an ACR and configure our Kubernetes cluster
    to have access to this cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: In the Azure search bar, look for `container registry` and click on **Container
    registries**:![Entering the keyword "container registry" in the Azure search bar
    to find and select container registries.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](image/Figure_11.1.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.1: Looking for Container registries in the search bar'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Click the **Add** button on the top to create a new registry. Provide the details
    to create the registry. The registry name needs to be globally unique, so consider
    adding your initials to the registry name. It is recommended to create the registry
    in the same location as your cluster. Select the **Create** button to create the
    registry:![Entering details such as registry name, subscription, resource group,
    location, and SKU in the Create container registry window.](image/Figure_11.2.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 11.2: Providing the details to create the registry'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'When your registry is created, open up Cloud Shell so that we can configure
    our AKS cluster to get access to our container registry. Use the following command
    to give AKS permissions on your registry:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We now have an ACR that is integrated with AKS. In the next section, we will
    create a development machine that will be used to build the Azure functions.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a development machine
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we will create a development machine and install the tools
    necessary to run Azure functions on this machine:'
  prefs: []
  type: TYPE_NORMAL
- en: Docker runtime
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure CLI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubectl
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To ensure a consistent experience, we will be creating a virtual machine (VM)
    on Azure that will be used for development. If you prefer to run the sample on
    your local machine, you can install all the required tools locally.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s get started with creating the machine:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To start, we will generate a set of ssh keys that will be used to connect to
    the VM:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: You will be prompted for a location and a passphrase. Keep the default location
    and input an empty passphrase.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If you followed the example in *Chapter 10*, *Securing your AKS cluster*, where
    we created an Azure AD integrated cluster, you can skip step 1 as you will already
    have a set of SSH keys.
  prefs: []
  type: TYPE_NORMAL
- en: If you prefer to reuse the SSH keys that you already have, you can do that as
    well.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now create our development machine. We will create an Ubuntu VM using
    the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This will take a couple of minutes to complete. Once the VM is created, Cloud
    Shell should show you its public IP, as displayed in *Figure 11.3*:![Output displaying
    details such as Location, MAC address, power state, private IP and the public
    IP of the Ubuntu VM. The output shows the public IPaddress of the VM.](image/Figure_11.3.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 11.3: Connecting to the machine''s public IP'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Connect to the VM using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: You will be prompted whether you trust the machine's identity. Type `yes` to
    confirm.
  prefs: []
  type: TYPE_NORMAL
- en: 'You''re now connected to a new machine on Azure. On this machine, we will begin
    by installing Docker:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'To verify that Docker is installed and running, you can run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This should show you the `hello-world` message from Docker:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Output of the sudodocker run hello-world command displaying the message "Hello!
    from Docker".](image/Figure_11.4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.4: Running hello-world with Docker'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'To make the operation smoother, we will add our user to the Docker group, which
    will no longer require `sudo` in front of the Docker commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You should now be able to run the `hello-world` command without `sudo`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will install the Azure CLI on this development machine. You can install
    the CLI using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Verify that the CLI was installed successfully by logging in:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This will display a login code that you need to enter at [https://microsoft.com/devicelogin](https://microsoft.com/devicelogin):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Output of the az CLI command instructing the user to enter the code using
    a web browser.](image/Figure_11.5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.5: Logging in to the az CLI'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Browse to that website and paste in the login code that was provided to you
    to enable you to log in to Cloud Shell. Make sure to do this in a browser you
    are logged into with the user who has access to your Azure subscription.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now use the CLI to authenticate our machine to ACR. This can be done
    using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This will show you a warning that the password will be stored unencrypted. You
    can ignore that for the purpose of this demonstration.
  prefs: []
  type: TYPE_NORMAL
- en: 'The credentials to ACR expire after a certain time. If you run into the following
    error during this demonstration, you can log in to ACR again using the preceding
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Error message stating that there was failure pushing the Docker image and
    that authentication is required.](image/Figure_11.6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.6: If this error is encountered, you can resolve this by logging
    into ACR again'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Next, we''ll install `kubectl` on our machine. The `az` CLI has a shortcut
    to install the CLI, which we will use:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s verify that `kubectl` can connect to our cluster. For this, we''ll first
    get the credentials and then execute a `kubectl` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can install the Azure Functions tools on this machine. To do this,
    run the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If you are running a newer version of Ubuntu than 18.04, please make sure that
    you download the correct `dpkg` package by changing the URL in the first step
    to reflect your Ubuntu version.
  prefs: []
  type: TYPE_NORMAL
- en: We now have the prerequisites to start our work with functions on Kubernetes.
    We created an ACR to store our custom Docker images, and we have a development
    machine that we will use to create and build Azure functions. In the next section,
    we will build a first function that is HTTP triggered.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an HTTP-triggered Azure function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this first example, we will create an HTTP-triggered Azure function. This
    means that you can browse to the page hosting the actual function:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin, we will create a new directory and navigate to that directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will initialize a function using the following command. The `--docker`
    parameter specifies that we will build our function as a Docker container. This
    will result in a Dockerfile being created for us. We will select the Python language,
    option `3` in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This will create the required files for our function to work:'
  prefs: []
  type: TYPE_NORMAL
- en: '![After running the funcinit --docker command,four options are provided: dotnet,
    node, python, and powershell. We select option 3.](image/Figure_11.7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.7: Creating a Python function'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Next, we will create the actual function. Enter the following code and select
    the fifth option, `HTTP trigger`, and name the function `python-http`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This should result in an output like *Figure 11.8*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The output of the func new command returns nine options. We select the option
    5: HTTP trigger.](image/Figure_11.8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.8: Creating an HTTP-triggered function'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The code of the function is stored in the directory called `python-http`. We
    are not going to make code changes to the function. If you want to check out the
    source code of the function, you can run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We will need to make one change to a function''s configuration file. By default,
    functions require an authenticated request. We will change this to anonymous for
    our demo. We will make the change in `vi` by executing the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We will replace the `authLevel` on line 5 with `anonymous`. To make that change,
    execute the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Press *I* to go into insert mode.
  prefs: []
  type: TYPE_NORMAL
- en: 'Remove `function` and replace it with `anonymous`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![In the python-http/function.json file, we change authlevel to anonymous.](image/Figure_11.9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.9: Changing the function to anonymous'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Hit *Esc*, type `:wq!`, and then *Enter* to save and quit `vi`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We changed the authentication requirement for our function to `anonymous`. This
    will make our demo easier to execute. If you plan to release functions to production,
    you need to carefully consider this setting, since this controls who has access
    to your function.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are now ready to deploy our function to AKS. We can deploy the function
    using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This will cause the function''s runtime to do a couple of steps. First, it
    will build a container image, then it will push that image to our registry, and
    finally it will deploy the function to Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Output of the funckubernetes deploy command showing docker build, docker
    push, and the creation of a secret, a service, and a deployment.](image/Figure_11.10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.10: Deploying the function to AKS'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This will create a regular Pod on top of Kubernetes. To check the Pods, you
    can run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Once that Pod is in a running state, you can get the public IP of the Service
    that was deployed and connect to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Open a web browser and browse to `http://<external-ip>/api/python-http?name=handsonaks`.
    You should see a web page showing you *Hello handsonaks!*, which is what our function
    is supposed to show:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Browser printing the message "Hello handsonaks!"](image/Figure_11.11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.11: Our function is working correctly'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We have now created a function with an HTTP trigger. Let''s clean up this Deployment
    before moving to the next section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: In this section, we created a sample function using an HTTP trigger. Let's take
    that one step further and integrate a new function with storage queues and set
    up an autoscaler.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a queue-triggered function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, we created a sample HTTP function. In a real-world
    use case, queues are often used to pass messages between different components
    of an application. A function can be triggered based on messages in a queue to
    then perform additional processing on these messages.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we'll create a function that is integrated with storage queues
    to consume events. We will also configure KEDA to allow scaling to/from 0 Pods
    in case of low traffic.
  prefs: []
  type: TYPE_NORMAL
- en: We still start by creating a queue in Azure.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a queue
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will create a new storage account and a new queue in that
    storage account. We will connect functions to that queue in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: To begin, we will create a storage account. Look for `storage` in the Azure
    search bar and select **Storage accounts**:![Searching for storage accounts by
    entering "storage" in the Azure search bar.](image/Figure_11.12.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 11.12: Looking for storage in the Azure search bar'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Click the **Add** button on the top to create a new account. Provide the details
    to create the storage account. The storage account name has to be globally unique,
    so consider adding your initials. It is recommended to create the storage account
    in the same region as your AKS cluster. Finally, to save on costs, you are recommended
    to downgrade the replication setting to **Locally-redundant storage (LRS)**:![Entering
    the storage account details,such as Subscription, resource group, storage account
    name, location, performance, account kind, replication, and access tier within
    the Basics tab.](image/Figure_11.13.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 11.13: Providing the details to create the storage account'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If you're ready, click the **Review and Create** button at the bottom. In the
    review screen, select **Create** to start the creation process.
  prefs: []
  type: TYPE_NORMAL
- en: It will take about a minute to create the storage account. Once it is created,
    open the account by clicking on the **go to resource** button. In the storage
    account blade, go to **Access keys**, and copy the primary connection string.
    Note down this string for now:![Navigating to the Access keys tab in the left
    panel and copying the primary connection string.](image/Figure_11.14.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 11.14: Copying the primary connection string'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For production use cases, it is not recommended to connect to Azure storage
    using the access key. Any user with that access key has full access to the storage
    account and can read and delete all files on it. It is recommended to either generate
    a **shared access signatures** (**SAS**) token to connect to storage or to use
    Azure AD-integrated security. To learn more about SAS token authentication to
    storage, refer to [https://docs.microsoft.com/rest/api/storageservices/delegate-access-with-shared-access-signature](https://docs.microsoft.com/rest/api/storageservices/delegate-access-with-shared-access-signature).
    To learn more about Azure AD authentication to Azure storage, please refer to
    [https://docs.microsoft.com/rest/api/storageservices/authorize-with-azure-active-directory](https://docs.microsoft.com/rest/api/storageservices/authorize-with-azure-active-directory).
  prefs: []
  type: TYPE_NORMAL
- en: The final step is to create our queue in the storage account. Look for `queue`
    in the left-hand navigation, click the **+Queue** button to adda queue, and provide
    it with a name. To follow along with this demo, call the queue `function`:![Creating
    a new queue within the storage account.](image/Figure_11.15.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 11.15: Creating a new queue'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We have now created a storage account in Azure and have its connection string.
    We created a queue in this storage account. In the next section, we will create
    a function that will consume messages from the queue.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a queue-triggered function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the previous section, we created a queue on Azure. In this section, we will
    create a new function that will watch this queue. We will need to configure this
    function with the connection string to this queue:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will begin by creating a new directory and navigating to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can create the function. We will start with the initialization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'This should result in the output shown in *Figure 11.16*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The output of the funcinit --docker command asks for two configuration settings.
    We answer the first with 2 (node) and the second with 1 (JavaScript).](image/Figure_11.16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.16: Initializing a new function'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Following the initialization, we can create the actual function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'This should result in the output shown in *Figure 11.17*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating the actual function with the func new command and then selecting
    option 10, Azure queue storage trigger for the template.](image/Figure_11.17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.17: Creating a new function'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We will now need to make a couple of configuration changes. We need to provide
    functions with the connection string to Azure storage and provide the queue name.
    First, open the `local.settings.json` file to configure the connection strings
    for storage:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'To make the changes, follow these instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: Hit *I* to go into insert mode.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On the line of `AzureWebJobsStorage` (line 6), replace the value with the connection
    string you copied earlier. Add a comma to the end of this line.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Add a new line and then add the following text on that line:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '![Changing the value for the AzureWebJobsStorageparameter and adding QueueConnString
    by editing the local.settings.json file.](image/Figure_11.18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.18: Editing the local.settings.json file'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Save and close the file by hitting the *Esc* key, type `:wq!`, and then press
    *Enter*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The next file we need to edit is the function configuration itself. Here, we
    will refer to the connection string from earlier, and provide the queue name.
    To do that, use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'To make the changes, follow these instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: Hit *I* to go into insert mode.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On line7, change the queue name to the name of the queue we created (`function`).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On line 8, add `QueueConnString` to the connection field:![Editing the js-queue/function.json
    file to enter the queueName and pointing the connection to QueueConnString.](image/Figure_11.19.jpg)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Figure 11.19: Editing the js-queue/function.json file'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Save and close the file by hitting the *Esc* key, type `:wq!`, and then press
    *Enter*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We are now ready to publish our function to Kubernetes. We will start the publishing
    by setting up KEDA on our Kubernetes cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This will set up KEDA on our cluster. The installation doesn''t take long.
    To verify that installation was successful, make sure that the KEDA Pod is running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now deploy our function to Kubernetes. We will configure KEDA to look
    at the number of queue messages every 5 seconds (`polling-interval=5`) to have
    a maximum of 15 replicas (`max-replicas=15`), and to wait 15 seconds before removing
    Pods (`cooldown-period=15`). To deploy and configure KEDA, use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'To verify the Deployment, you can run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This will show you all the resources that were deployed. As you can see in
    *Figure 11.20*, this Deployment creates a Deployment, ReplicaSet, and an HPA.
    In the HPA, you should see that there are no replicas currently running:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Output of the kubectl get all command showing that three objects were created,
    and highlighting that the horizontal pod autoscaler has zero replicas running
    currently.](image/Figure_11.20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.20: The Deployment created three objects, and we have zero replicas
    running now'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We will create a message in the queue now to wake up the Deployment and create
    a Pod. To see the scaling event, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: To create a message in the queue, we are going to open a new cloud shell session.
    To open a new session, select the *Open new session* button in the cloud shell:![Selecting
    the Open new session button in the Bash window.](image/Figure_11.21.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 11.21: Opening a new cloud shell instance'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: On this new shell, run the following command to create a message in the queue.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'After creating this message, switch back to the previous shell. It might take
    a couple of seconds, but soon enough, your HPA should scale to 1 replica. Afterward,
    it should also scale back down to 0 replicas:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Executing the kubectl get hpa -w command and verifying that KEDA scaled our
    Pods from 0 to 1 when we created a message in the queue, and back down to 0 when
    there were no messages left.](image/Figure_11.22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.22: With one message in the queue, KEDA scales from 0 to 1 and back
    to 0 replicas'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We have now created a function that is triggered on the number of messages in
    a queue. We were able to verify that KEDA scaled our Pods from 0 to 1 when we
    created a message in the queue, and back down to 0 when there were no messages
    left. In the next section, we will execute a scale test, and we will create multiple
    messages in the queue and see how the functions react.
  prefs: []
  type: TYPE_NORMAL
- en: Scale testing functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the previous section, we saw how functions reacted when there was a single
    message in the queue. In this example, we are going to send 1,000 messages into
    the queue and see how KEDA will first scale out our function, and then scale back
    in, and eventually scale back down to zero:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the current cloud shell, watch the HPA using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: To start pushing the messages, we are going to open a new cloud shell session.
    To open a new session, select the *Open new session* button in the cloud shell:![Hitting
    the Open new session button to open a new Cloud Shell instance.](image/Figure_11.23.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 11.23: Opening a new cloud shell instance'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'To send the 1,000 messages into the queue, we have provided a Python script
    called `sendMessages.py`, in the code bundle. Cloud Shell already has Python and
    pip (the Python package manager) installed. To be able to run this script, you
    will first need to install two dependencies:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'When those are installed, open the `sendMessages.py` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Edit the storage connection string on line 4 to your connection string:'
  prefs: []
  type: TYPE_NORMAL
- en: '![In the sendMessages.py file, editing the storage connection string on line
    4 to our connection string.](image/Figure_11.24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.24: Pasting in your connection string for your storage account on
    line 4'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Once you have pasted in your connection string, you can execute the Python
    script and send 1,000 messages to your queue:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: While the messages are being sent, switch back to the previous cloud shell instance
    and watch KEDA scale from 0 to 1, and then watch the HPA scale to the maximum
    of 15 replicas. The HPA uses metrics provided by KEDA to take the scaling decisions.
    Kubernetes, by default, doesn't know about the number of messages in an Azure
    storage queue that KEDA provides to the HPA.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the queue is empty, KEDA will scale back down to 0 replicas:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Executing the kubectl get hpa -w command shows that the HPA will scale replicas
    from 0 to first 1, then to 4, 8, and 15, and finally back to 0.](image/Figure_11.25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.25: KEDA will scale from 0 to 1, and the HPA will scale to 15 Pods'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This concludes our examples of running serverless functions on top of Kubernetes.
    Let''s make sure to clean up our Deployments. Run the following command from within
    the development machine we created (the final step will delete this VM. If you
    want to keep the VM, don''t run the final step):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The deletion of KEDA will show a couple of errors. That is because we only installed
    a subset of KEDA on top of our cluster, and the removal process tries to delete
    all components.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we ran a function that was triggered by messages on a storage
    queue on top of Kubernetes. We used a component called KEDA to achieve scaling
    in our cluster. We saw how KEDA can scale from 0 to 1 and back down to 0\. We
    also saw how the HPA can use metrics provided by KEDA to scale out a Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we deployed serverless functions on top of our Kubernetes cluster.
    To achieve this, we first created a development machine and an Azure Container
    Registry.
  prefs: []
  type: TYPE_NORMAL
- en: We started our functions Deployments by deploying a function that used an HTTP
    trigger. The Azure Functions core tools were used to create that function and
    to deploy it to Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Afterward, we installed an additional component on our Kubernetes cluster called
    KEDA. KEDA allows serverless scaling in Kubernetes: it allows Deployments to and
    from 0 Pods, and it also provides additional metrics to the **Horizontal Pod Autoscaler**
    (**HPA**). We used a function that was triggered on messages in an Azure storage
    queue.'
  prefs: []
  type: TYPE_NORMAL
- en: This chapter also concludes the book. Throughout this book, we've introduced
    AKS through multiple hands-on examples. The first part of the book focused on
    getting applications up and running. We created an AKS cluster, deployed multiple
    applications and learned how to scale those applications.
  prefs: []
  type: TYPE_NORMAL
- en: The second part of the book focused on the operational aspects of running AKS.
    We discussed common failures and how to solve them, integrated applications with
    Azure AD, and looked into the monitoring of the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: In the final part of the book, we looked into advanced integration of AKS with
    other Azure services. We integrated our AKS cluster with Azure databases and Azure
    Event Hubs, we secured our cluster, and finally, we developed Azure Functions
    on top of our AKS cluster.
  prefs: []
  type: TYPE_NORMAL
- en: As a result of finishing this book, you should now be ready to build and run
    your applications at scale on top of AKS.
  prefs: []
  type: TYPE_NORMAL
