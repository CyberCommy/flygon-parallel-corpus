- en: A Production-Ready Cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last chapter, we spent some time thinking about a framework for planning
    a Kubernetes cluster. Hopefully, it should be clear to you that, when building
    a cluster, there are lots of decisions to make based on the requirements of the
    systems you are running.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will take a much more practical approach to this problem.
    Instead of trying to cover the myriad options available to us, I will start by
    making some choices, and then we will build a fully functional cluster that will
    serve as a base configuration to build upon for many different use cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Terraform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preparing node images and a node group
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provisioning add-ons
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The information contained within this chapter is just one possible way that
    you could approach building and managing a cluster. When building a Kubernetes
    cluster, there are many choices to be made, and almost as many tools that could
    be chosen. For the purposes of this chapter, I have chosen to use tools that make
    it simple to illustrate the process of building a cluster. If you or your team
    has a preference for using different tools, then the concepts and architecture
    outlined in this chapter will transfer quite easily to other tools.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we are going to launch our cluster in a way that will make
    it more suitable for production workloads. Much of what we do here will be familiar
    to you from [Chapter 3](4e7f067a-f87f-4a36-be63-eb3bde02ba81.xhtml), *Reach for
    the Cloud*, but we are going to build on the process we outlined there in two
    key ways. Firstly, when building infrastructure that you depend on, it is very
    important that you are able to quickly roll out a new instance of your infrastructure
    in a manner that is repeatable. We want to be able to do this because it makes
    it simple to test changes that we want to make to our infrastructure in a risk-free
    way. By automating the provisioning of a Kubernetes cluster, we enable the patterns
    of immutable infrastructure that we previously discussed. Instead of risking upgrading
    or changing our production infrastructure, we can quickly provision a replacement
    cluster that we can then test before moving our workloads to the new cluster.
  prefs: []
  type: TYPE_NORMAL
- en: In order to achieve this, we are going to use the Terraform infrastructure provisioning
    tool to interact with AWS. Terraform allows us to define our infrastructure as
    code using a programming language of sorts. By defining our infrastructure as
    code, we are able to use tools such as version control and follow other software
    development practices to manage the evolution of our infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we are about to make a lot of decisions about what a Kubernetes
    cluster running on AWS should look like and how it should be managed. For the
    purposes of this chapter and the example that we will be dealing with, I have
    the following requirements in mind.
  prefs: []
  type: TYPE_NORMAL
- en: '**Illustrative**: We will see what a Kubernetes cluster that meets the requirements
    of an average production use case might look like. This cluster reflects the decisions
    that I have personally taken when designing Kubernetes clusters that are intended
    for real production use. In order to make this chapter as clear and easy to understand
    as I can, I have tried to keep the cluster and its configuration as simple as
    possible.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flexible**: We will create something that you can treat as a template and
    add to or alter to meet your needs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Extendable**: Whenever you are designing a Kubernetes cluster (or indeed
    any infrastructure), you should think about the decisions that you make now that
    might prevent you from extending or expanding that infrastructure later.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clearly, when you are building your own cluster, you should have a much more
    concrete idea of your requirements so that you will be able to tailor your cluster
    to your own needs. The cluster we will build here will be a great starting point
    for any production-ready system that you can then customize and add to as required.
  prefs: []
  type: TYPE_NORMAL
- en: Much of the configuration in this chapter has been shortened. You can check
    out the full configuration used in this chapter at [https://github.com/PacktPublishing/Kubernetes-on-AWS/tree/master/chapter07](https://github.com/PacktPublishing/Kubernetes-on-AWS/tree/master/chapter07).
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with Terraform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Terraform is a command-line tool that you can run on your workstation to make
    changes to your infrastructure. Terraform is a single binary that just needs to
    be installed onto your path.
  prefs: []
  type: TYPE_NORMAL
- en: You can download Terraform from [https://www.terraform.io/downloads.html](https://www.terraform.io/downloads.html) for
    six different operating systems, including macOS, Windows, and Linux. Download
    the ZIP file for your operating system, extract it, and then copy the Terraform
    binary to a location on your path.
  prefs: []
  type: TYPE_NORMAL
- en: Terraform uses files with the `.tf` extension to describe your infrastructure.
    Because Terraform supports the management of resources on many different cloud
    platforms, it can contain the concepts of the relevant providers, which are loaded
    as required to support the different APIs exposed by the different cloud providers.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s configure the AWS Terraform provider in order to be ready to
    build a Kubernetes cluster. Create a new directory to hold the Terraform configuration
    for your Kubernetes cluster, and then create a file where we will configure the
    AWS provider, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Save the file, and then run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: When you use a supported provider, Terraform can discover and download the required
    plugin for you. Note that we have already configured the provider with an AWS
    region of `us-west-2`, as this is the region where we will be launching our cluster
    in this example.
  prefs: []
  type: TYPE_NORMAL
- en: In order for Terraform to communicate with the AWS API, you will need to provide
    the AWS provider with some credentials. We learned how to obtain credentials in
    [Chapter 3](4e7f067a-f87f-4a36-be63-eb3bde02ba81.xhtml), *Reach for the Cloud*.
    If you followed the advice in [Chapter 3](4e7f067a-f87f-4a36-be63-eb3bde02ba81.xhtml), *Reach
    for the Cloud*, and set your credentials up with the `aws configure` command,
    then Terraform will read your default credentials from your local config file.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, Terraform can read AWS credentials from the `AWS_ACCESS_KEY_ID`
    and `AWS_SECRET_ACCESS_KEY` environment variables, or, if you are running Terraform
    on an EC2 instance, it can use the credentials provided by an EC2 instance role.
  prefs: []
  type: TYPE_NORMAL
- en: It is also possible to statically configure the credentials by adding an `access_key`
    and`secret_key` parameter inline in the AWS provider block, but I wouldn't really
    recommend this practice as it makes it much harder to check your configuration
    into a version control system.
  prefs: []
  type: TYPE_NORMAL
- en: By default, Terraform uses a local file called `terraform.tfstate` to keep track
    of the state of your infrastructure. This is so that it can keep track of the
    changes you have made to the configuration since you last ran Terraform.
  prefs: []
  type: TYPE_NORMAL
- en: If you are going to be the only person managing your infrastructure, then this
    might be acceptable, but you would need to securely back up the state file. It
    should be considered sensitive, and Terraform won't function correctly if you
    lose it.
  prefs: []
  type: TYPE_NORMAL
- en: If you are using AWS, I would recommend using S3 as a backend. You can read
    about how to set this up in the Terraform documentation at [https://www.terraform.io/docs/backends/types/s3.html](https://www.terraform.io/docs/backends/types/s3.html).
    If configured correctly, S3 storage is highly secure, and if you are working on
    a team, then you can utilize a DynamoDB table as a lock to ensure that multiple
    instances of Terraform are not running at the same time. If you want to make use
    of this, set the configuration in the `backend.tf` file, otherwise delete that
    file.
  prefs: []
  type: TYPE_NORMAL
- en: Variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Terraform allows us to define variables in order to make our configuration more
    reusable. This is particularly useful if you later want to use your configuration
    as a module in order to define multiple clusters. We won't cover that in this
    chapter, but we can follow best practices and define some key variables to allow
    you to simply shape the cluster to meet your needs.
  prefs: []
  type: TYPE_NORMAL
- en: It is standard to create a `variables.tf` file to include all of the variables
    in your project. This is helpful because it acts as high-level documentation about
    how your configuration can be controlled.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, between choosing descriptive names for my variables and adding
    the optional description field, the whole file is quite self-explanatory. Because
    I have provided defaults for each variable, we can run Terraform without passing
    any values for these variables, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Networking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will start by creating a config file to describe the network setup for our
    Kubernetes cluster. You might recognize the design of this network, as it is quite
    similar the one we manually created in [Chapter 3](4e7f067a-f87f-4a36-be63-eb3bde02ba81.xhtml),
    *Reach for the Cloud*, but with a few additions to make it more suitable for a
    production setup.
  prefs: []
  type: TYPE_NORMAL
- en: Terraform configuration files can be documented with comments, and to better
    illustrate this configuration, I have provided some commentary in the form of
    comments. You will notice that they are surrounded by `/*` and `*/`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to support high availability, we are going to create subnets for more
    than one availability zone, as shown in the following code. Here, we are using
    two, but if you wanted even greater resiliency, you can easily add another availability
    zone to the `availability_zones` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We are going to provision two subnets for each of the availability zones we
    are using for our cluster. A public subnet which have a direct route to the internet
    where Kubernetes will provision load balancers that are accessible to the internet.
    And a private subnet that will be used by Kubernetes to assign IP addresses to
    pods.
  prefs: []
  type: TYPE_NORMAL
- en: Because the address space available in the private subnets will be the limiting
    factor on the number of pods that Kubernetes will be able to launch, we provision
    a large address range with 16382 available IP addresses. This should allow our
    cluster some room for expansion.
  prefs: []
  type: TYPE_NORMAL
- en: If you are only planning to run internal services that are not be accessible
    to the internet, then you might be able to skip the public subnets. You can find
    the full `networking.tf` file in the example files for this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Plan and apply
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Terraform allows us to incrementally build our infrastructure by adding to and
    changing the code that defines it. Then if you wish, as you go through this chapter,
    you can build up your configuration piece by piece, or you can use Terraform to
    build your whole cluster in one go.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever you use Terraform to make a change to your infrastructure, it first
    produces a plan of the changes that it is going to make, and then it applies this
    plan. This two-stage operation is ideal when modifying production infrastructure
    as it gives you the opportunity to review the changes that will actually be applied
    to your cluster before they are made.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have saved your networking configuration to a file, we can follow a
    few steps to safely provision our infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can check for syntax errors in the configuration by running the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'If your configuration is good, then there will be no output, but if there are
    syntax errors with your file(s), you should see an error message explaining the
    issue. For example, a missing closing brace might cause an error such as `Error
    parsing networking.tf: object expected closing RBRACE got: EOF`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have ensured that your files are correctly formatted for Terraform,
    you can create a plan for the changes to your infrastructure using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This command will output a summary of the changes that will be made to your
    infrastructure if this plan is run. The `-out` flag is optional, but it is a good
    idea because it allows us to apply exactly these changes later on. If you were
    paying attention to the output when you ran the Terraform plan, then you should
    have seen a message like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: When you run `terraform apply` with a precomputed plan, it will make the changes
    that were outlined when the plan was generated. You could also run `terraform
    plan` command without pregenerating a plan, but in this case, it will still plan
    the changes and then prompt you before applying them.
  prefs: []
  type: TYPE_NORMAL
- en: Terraform computes the dependencies between the different resources in your
    infrastructure—for example, it ensures that the VPC is created before the route
    tables and other resources are created. Some resources can take a few seconds
    to create, but Terraform will wait until they are available before moving on to
    create dependent resources.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to remove a resource that Terraform has created in your AWS account,
    you can just delete the definition from the relevant `.tf` file and then plan
    and apply your changes. When you are testing a Terraform configuration, it can
    be useful to remove all of the resources created by a particular configuration
    in order to test provisioning your infrastructure from scratch. If you need to
    do this, the `terraform destroy` command is very useful; it will remove all of
    the resources that are defined in your Terraform files from your infrastructure.
    However, be aware that this could cause essential resources to be terminated and
    removed, and so you shouldn't use this method on a running production system.
    Before any resources are removed, Terraform will list them and then ask you whether
    you want to remove them.
  prefs: []
  type: TYPE_NORMAL
- en: Control Plane
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to provide a resilient and reliable Kubernetes Control Plane for our
    cluster, we are going to make our first big departure from the simple cluster
    that we built in [Chapter 3](4e7f067a-f87f-4a36-be63-eb3bde02ba81.xhtml), *Reach
    for the Cloud*.
  prefs: []
  type: TYPE_NORMAL
- en: As we learned in [Chapter 1](19821a2b-bb32-408d-9f21-256dce5d644e.xhtml), *Google's
    Infrastructure for the Rest of Us*, the key components of the Kubernetes Control
    Plane are the backing etcd store, the API server, the scheduler, and the controller
    manager. If we want to build and manage a resilient control plane, we need to
    manage running these components across multiple instances, ideally spread across
    several availability zones.
  prefs: []
  type: TYPE_NORMAL
- en: Because the API server is stateless, and the scheduler and controller manager
    have built-in leader election facilities, it is relatively simple to run multiple
    instances on AWS, for example, by using an autoscaling group.
  prefs: []
  type: TYPE_NORMAL
- en: Running production-grade etcd is slightly trickier because etcd should be carefully
    managed when adding or removing nodes to avoid data loss and downtime. Successfully
    running an etcd cluster is quite a difficult task on AWS, and requires either
    manual operation or complex automation.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily for us, AWS has developed a service that removes nearly all of the operational
    complexity involved in provisioning the Kubernetes Control Plane—**Amazon EKS**,
    or to use the full name, the Amazon Elastic Container Service for Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: With EKS, AWS will manage and run the components that make up the Kubernetes
    Control Plane on your behalf across multiple availability zones, thus avoiding
    any single points of failure. With EKS, you no longer have to worry about performing
    or automating the operational tasks required for running a stable etcd cluster.
  prefs: []
  type: TYPE_NORMAL
- en: We should bear in mind that, with EKS, a key part of the infrastructure of our
    cluster is now managed by a third party. You should be comfortable with the fact
    that AWS can do a better job than your own team of providing a resilient control
    plane. This doesn't preclude you from designing your cluster to be somewhat resistant
    to the failure of the control plane—for example, if the kubelet cannot connect
    to the control plane, then the running containers will remain running until the
    control plane becomes available again. You should make sure that any additional
    components you add to your cluster can cope with temporary downtime in a similar
    fashion.
  prefs: []
  type: TYPE_NORMAL
- en: EKS reduces the amount of effort required to manage the most complex parts of
    Kubernetes (the control plane), thereby reducing the time (and money) required
    to design your cluster, and to maintain it. Moreover, for even a modestly sized
    cluster, the cost of the EKS service is significantly lower than the equivalent
    cost of running your own control plane across multiple EC2 instances.
  prefs: []
  type: TYPE_NORMAL
- en: In order for the Kubernetes Control Plane to manage resources in your AWS account,
    you need to provide EKS with an IAM role that will be assumed by EKS itself.
  prefs: []
  type: TYPE_NORMAL
- en: EKS creates network interfaces within your VPC to allow the Kubernetes Control
    Plane to communicate with the kubelet in order to provide services such as **log
    streaming** and **exec**. To control this communication, we need to supply EKS
    with a security group when it is launched. You can find the full Terraform configuration
    used to provision the control plane in `control_plane.tf` in the example files
    for this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We can use the Terraform resource for the EKS cluster to query it in order to
    fetch the endpoint for the Kubernetes API and the certificate authority that is
    used to access it.
  prefs: []
  type: TYPE_NORMAL
- en: This information, combined with Terraform's templating facilities, allows us
    to generate a `kubeconfig` file with the information required to connect to the
    Kubernetes API provided by EKS. We can use this later to provision add-on components.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want, you could also use this file to connect to the cluster manually
    with kubectl, either by copying the file to the default location at `~/.kube/config`
    or by passing its location to kubectl with the `--kubeconfig` flag or the `KUBECONFIG`
    environment variable, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `KUBECONFIG` environment variable can be useful if you are managing multiple
    clusters, as you can easily load multiple configs by separating their paths; for
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '`export KUBECONFIG=$HOME/.kube/config:/path/to/other/conf`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Preparing node images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we did in [Chapter 3](4e7f067a-f87f-4a36-be63-eb3bde02ba81.xhtml), *Reach
    for the Cloud*, we will now be preparing an AMI for the worker nodes in our cluster.
    However, we will improve this process by automating it with **Packer**. Packer
    is a tool that makes it simple to build machine images on AWS (and other platforms).
  prefs: []
  type: TYPE_NORMAL
- en: Installing Packer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just like Terraform, Packer is distributed as a single binary that just needs
    to be copied to a location on your path. You can find detailed installation instructions
    on the Packer website at [https://www.packer.io/intro/getting-started/install.html](https://www.packer.io/intro/getting-started/install.html).
  prefs: []
  type: TYPE_NORMAL
- en: Once you have installed Packer, you can run `packer version` to check that you
    have correctly copied it into to your path.
  prefs: []
  type: TYPE_NORMAL
- en: Packer configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Packer is configured with a JSON-formatted configuration file, that you can
    see at `ami/node.json`.
  prefs: []
  type: TYPE_NORMAL
- en: There are three parts to the example configuration here. The first is a list
    of variables. Here, we are using variables to store the version numbers of the
    important software that we are going to install in our image. This will make it
    simple to build and test images with updated versions of the Kubernetes software
    when it becomes available in the future.
  prefs: []
  type: TYPE_NORMAL
- en: The second part of the configuration configures the builder. Packer allows us
    to choose to build our image with one or more builders that support building images
    for different cloud providers. Since we want to build an image to use on AWS,
    we are using the `amazon-ebs` builder, which creates an image by launching a temporary
    EC2 instance and then creating an AMI from the contents of its root EBS volume
    (just like the manual procedure we followed in [Chapter 3](4e7f067a-f87f-4a36-be63-eb3bde02ba81.xhtml),
    *Reach for the Cloud*). This builder configuration allows us to choose the base
    image that our machine will be based on; here, we are using an official Ubuntu
    server image, a trusted source. The `ami-name` field in the builder configuration
    defines the name that the outputted image will be given. We have included the
    version of the Kubernetes software used and a timestamp to ensure that this image
    name is unique. Having a unique image name lets us define precisely which image
    to use when we deploy servers using it.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we configure a provisioner to install the software that our image will
    require. Packer supports many different provisioners that can install software,
    including full configuration-management systems such as Chef or Ansible. To keep
    this example simple, we will automate the installation of the software that we
    need by using a shell script. Packer will upload the configured script to the
    builder instance and then execute it via SSH.
  prefs: []
  type: TYPE_NORMAL
- en: We are just using a simple shell script, but if your organization already has
    a configuration-management tool in use, then you might prefer to use that to install
    the software that your image needs, especially as it makes it simple to include
    your organization's base configuration.
  prefs: []
  type: TYPE_NORMAL
- en: In this script, we are installing the software and configuration that our worker
    nodes will need to join an EKS cluster and function correctly, as shown in the
    following list. In a real deployment, there may be other tools and configurations
    that you wish to add in addition to these.
  prefs: []
  type: TYPE_NORMAL
- en: '**Docker**: Docker is currently the best tested and most common container runtime
    to use with Kubernetes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kubelet**: The Kubernetes node agent'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ekstrap**: Configures the kubelet to connect to the EKS cluster endpoint'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**aws-iam-authenticator**: Allows the node to authenticate with the EKS cluster
    using the node''s IAM credentials'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We install these elements using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you have prepared the configuration for Packer, you can use the `packer
    build` command to build the AMI in your AWS account, as shown in the following
    code. This will start a temporary EC2 instance. Save the new AMI into your account
    and clean up the temporary instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: If your organization uses a continuous integration service, you might want to
    configure it to build your node image on a regular schedule in order to pick up
    security updates to the base operating system.
  prefs: []
  type: TYPE_NORMAL
- en: Node group
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have prepared an image for the worker nodes in our cluster, we can
    set up an autoscaling group to manage the launching of the EC2 instances that
    will form our cluster.
  prefs: []
  type: TYPE_NORMAL
- en: EKS doesn't tie us to managing our nodes in any particular way, so autoscaling
    groups are not the only option for managing the nodes in our cluster, but using
    them is one of the simplest ways of managing multiple worker instances in our
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: If you wanted to use multiple instance types in your cluster, you could repeat
    the launch configuration and autoscaling group configuration for each instance
    type that you wanted to use. In this configuration, we are launching `c5.large`
    instances on demand, but you should refer back to [Chapter 6](cb29a916-0f55-4fa9-816d-2322a86e1ccc.xhtml), *Planning
    for Production*, for more information about choosing appropriate instance sizes
    for your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first part of the configuration sets up an IAM role for our instances to
    use. This is simple because AWS provides managed policies that have the permissions
    required by Kubernetes. The `AmazonEKSWorkerNodePolicy` code phrase allows the
    kubelet to query information about EC2 instances, attached volumes, and network
    settings, and to query information about EKS clusters. The `AmazonEKS_CNI_Policy`
    provides the permissions required by the `vpc-cni-k8s` network plugin to attach
    network interfaces to the instance and assign new IP addresses to those interfaces.
    The `AmazonEC2ContainerRegistryReadOnly` policy allows the instance to pull Docker
    images from the AWS Elastic Container Registry (you can read more about using
    this in [Chapter 10](250f70f9-eb26-41a8-aa97-51563aa16de8.xhtml), *Managing Container
    Images*). We will also manually specify a policy that will allow the `kube2iam`
    tool to assume roles in order to provide credentials to applications running on
    the cluster, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Before our worker nodes can register themselves with the Kubernetes API server,
    they need to have the correct permissions to do so. In EKS, the mapping between
    IAM roles and users is configured by submitting a config map to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: You can read more about how to map IAM users and roles to Kubernetes permissions
    in the EKS documentation at [https://docs.aws.amazon.com/eks/latest/userguide/add-user-role.html](https://docs.aws.amazon.com/eks/latest/userguide/add-user-role.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'Terraform will use the `kubeconfig` file that we produced while setting up
    the control plane in order to submit this configuration to the cluster using `kubectl`
    via the local-exec provisioner, as shown in the following `nodes.tf` continued
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Next, we need to prepare security groups to control the network traffic to and
    from our nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will set up a number of rules to allow the following communication flows
    that are required for our cluster to function correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: Nodes need to communicate with each other for intracluster pod and service communication.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Kubelet running on the nodes needs to connect to the Kubernetes API server
    in order to read and update information about the state of the cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The control plane needs to connect to the Kubelet API on port `10250`; this
    is used for functionalities such as `kubectl exec` and `kubectl logs.`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In order to use the proxy functionality of the API to proxy traffic to pods
    and services, the control plane needs to connect to pods that are running in the
    cluster. In this example, we are opening all of the ports, but if, for example,
    you only open unprivileged ports on your pods, then you would only need to allow
    traffic to ports above 1024.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We set these rules up using the following code. The code for `nodes.tf` is
    continued:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have prepared the infrastructure to run our nodes, we can prepare
    a launch configuration and assign it to an autoscaling group to actually launch
    our nodes, as shown in the following code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Clearly, the instance type and disk size I have chosen here might not suit
    your cluster, so you will want to refer back to the information in [Chapter 6](cb29a916-0f55-4fa9-816d-2322a86e1ccc.xhtml), *Planning
    for Production*, when choosing an instance size for your cluster. The disk size
    required will be largely dependent on the average image size of your applications.
    The code for `nodes.tf` is continued:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The `kubernetes.io/cluster/<node name>` tag is used by the `ekstrap` tool to
    discover the EKS endpoint in order to register the node with the cluster and by
    the `kubelet` to verify that it has connected to the correct cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning add-ons
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Much of the power of Kubernetes comes from the fact that it is easy to extend
    by adding additional services to provide additional functionality.
  prefs: []
  type: TYPE_NORMAL
- en: We are going to look at an example of this by deploying `kube2iam`. This is
    a daemon that runs on every node in our cluster and intercepts calls to the AWS
    metadata service that are made by processes running in our pods.
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple way to provision a service like this is by using a DaemonSet to run
    a pod on every node in the cluster, as shown in the following code. This approach
    is already used in our cluster to deploy the `aws-vpc-cni` networking plugin to
    every node and to run `kube-proxy`, the Kubernetes component that runs on every
    node and that is responsible for routing traffic that is destined for service
    IPs to the underlying pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Managing change
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Managing your Kubernetes clusters with a tool like Terraform offers a lot of
    advantages over the manual approach that we explored in [Chapter 3](4e7f067a-f87f-4a36-be63-eb3bde02ba81.xhtml),
    *Reach for the Cloud*. Being able to quickly and easily repeat the process of
    provisioning a cluster is very useful when you want to test changes to your configuration,
    or even when you come to upgrade the version of Kubernetes that your cluster is
    running.
  prefs: []
  type: TYPE_NORMAL
- en: The other key advantage of defining your infrastructure as code, is that you
    can use a version control tool to keep track of the changes that you make to your
    infrastructure over time. One of the key advantages to this is that every time
    you make a change, you can leave a commit message. Decisions that you make now
    might seem obvious, but having a record of why you chose to do something a certain
    way will certainly help you and others who have to work with your configuration
    in the future, especially as those others may not have the same context that you
    had when you made your changes.
  prefs: []
  type: TYPE_NORMAL
- en: A lot has been written about writing good commit messages by many software engineers.
    The best piece of advice is to make sure that you include as much information
    as is required to explain why your change was needed. Your future self will thank
    you if you have to return to the configuration months later.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider this commit message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Also consider this commit message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The first commit message is bad because it just explains what you did, and that
    should be obvious just by looking at how the configuration changed. The second
    message gives a lot more information. Importantly, the second message explains
    why the change needed to be made and gives some information that will be useful
    for anyone making changes to the cluster in the future. Without this important
    context, you might wonder why port `80` was opened and worry about what might
    happen if you changed that information.
  prefs: []
  type: TYPE_NORMAL
- en: Operating a Kubernetes cluster in a production setting is not just about how
    you launch the cluster on day one; it's about making sure that you can update
    and extend the cluster over time to continue to meet the requirements of your
    organization.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The cluster that we have built in this chapter is still quite simple, and really
    reflects a starting point that we can build upon in the following chapters. However,
    it does meet the following essential requirements for production readiness:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reliability**: By using EKS, we have provisioned a reliable control plane
    that we can depend upon to manage our cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability**: By operating our nodes via an autoscaling group, we can make
    it simple to add extra capacity to our cluster in seconds.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Maintainability**: By defining our infrastructure as code using Terraform,
    we have made it simple to manage our cluster in the future. By setting up a build
    process for the AMI used by our node machines, we are able to quickly rebuild
    the image to pull in security updates and updated versions of our node software.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
