- en: Chapter 2. Inserting, Updating, and Deleting Documents from Solr
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will start this chapter by discussing the Solr schema. We will explore the
    default schema provided by Solr. Further, we will explore:'
  prefs: []
  type: TYPE_NORMAL
- en: Pushing sample data into Solr
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding sample documents to the Solr index
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using PHP to add documents to the Solr index
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Updating documents in Solr using PHP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deleting documents in Solr using PHP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using commit, rollback, and index optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Solr schema
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Solr schema mostly consists of fields and field types. It defines the fields
    that are to be stored in the Solr index and the processing that should happen
    on data being indexed or searched in those fields. Internally, the schema is used
    to assign properties to the fields used for creating a document that is to be
    indexed using the Lucene API. The default schema available with Solr can be located
    in `<solr_home>/example/solr/collection1/conf/schema.xml`. Here, `collection1`
    is the name of the core.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A Solr server can have multiple cores and each core can have its own schema.
  prefs: []
  type: TYPE_NORMAL
- en: Let us open up the `schema.xml` file and go through it. In the XML file, we
    can see that there is a section for fields inside which there are multiple fields.
    Also, there is another section for types. The types section contains different
    entries of `fieldType`, which define the type of field in terms of how the field
    will be processed during indexing and during query. Let us understand how to create
    a `fieldType` entry.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `fieldType` entry consists of a name attribute that is used in field definitions.
    The class attribute defines the behavior of the `fieldType` entry. Some other
    attributes are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`sortMissingLast`: If set to true this attribute will cause documents without
    the field to come after documents that have this field.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sortMissingFirst`: If set to true this attribute will cause documents without
    the field to come before documents that have this field.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`precisionStep`: Lower values of `precisionstep` means more precisions, more
    terms in the index, larger index, and faster range queries. `0` disables indexing
    at different precision levels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`positionIncrementGap`: It defines the positions between the last token of
    one entry and the first token of next entry in a multivalued field. Let us take
    an example.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suppose there are two values in a multivalued field in a document. The first
    value is `aa bb` and the second value is `xx yy`. Ideally, the positions assigned
    to these tokens during indexing will be `0`, `1`, `2`, and `3` for tokens `aa`,
    `bb`, `xx`, and `yy` respectively.
  prefs: []
  type: TYPE_NORMAL
- en: A search for `bb xx` will give this document in its result. To prevent this
    from happening, we have to give a large `positionIncrementGap` say `100`. Now
    the positions assigned to these tokens will be `0`, `1`, `100`, and `101` for
    tokens `aa`, `bb`, `xx`, and `yy`. A search for `bb xx` will not give results
    as `bb` and `xx` are not near to each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `FieldType` entries are either primitive such as `String`, `Int`, `Boolean`,
    `Double`, `Float`, or a derived field type. A derived field type can contain analyzer
    sections for defining the processing that will happen during either indexing or
    query. Each analyzer section consists of a single **tokenizer** and multiple filters.
    They define how data is processed. For example, there is a `fieldType text_ws`
    where the **analyzer** is a `WhiteSpaceTokenizerFactory`. So any data being indexed
    or searched in a field of the `text_ws` type will have the data broken over white
    space into multiple tokens. Another `fieldType text_general` has separate analyzer
    entries for indexes and queries. During analysis for indexing the data is passed
    through a tokenizer known as `StandardTokenizerFactory` and then through multiple
    filters. Following are filters that we use:'
  prefs: []
  type: TYPE_NORMAL
- en: '`StopFilterFactory`: This filters are used for removal of stop words that are
    defined in `stopwords.txt`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SynonymFilterFactory`: This filters are used for assigning synonyms to words
    that are defined in `index_synonyms.txt`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LowerCaseFilterFactory`: This filter is used for converting the text in all
    the tokens to lowercase'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarly, there are different analyses happening to the query on this field
    during search. And that is defined by the analyzer of the type query.
  prefs: []
  type: TYPE_NORMAL
- en: Most of the field types that are required are generally provided in the default
    schema. But we can go ahead and create a new field type if we feel a need for
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each field consists of a name and a type, which are mandatory, and some other
    attributes. Let''s run through the attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`name`: This attribute displays the name of the field.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`type`: This attribute defines the type of the field. All types are defined
    as the `fieldType` entries we discussed before.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`indexed` : This attribute is true if the data in this field has to be indexed.
    The text in indexed fields is broken into tokens and an index is created from
    the tokens, which can be used for searching the document based on these tokens.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stored` : This attribute is true if the data in this field also needs to be
    stored. Data that has been indexed cannot be used to construct the original text.
    So text in fields are stored separately for retrieving original text of the document.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`multivalued` : This attribute is true if the field contains multiple values
    within a single document. An example of multiple values associated with a document
    is **tags**. A document can have multiple tags and for search on any of the tags,
    the same document has to be returned.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`required` : This attribute is true if the field is mandatory to be populated
    for every document during index creation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition to normal fields, the schema consists of some dynamic fields, which
    add flexibility in defining the field's names. For example, a dynamic field by
    the name of `*_i` will match any field ending with `_i`, for example, `genre_i`
    or `xyz_i`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some other sections in the schema are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**uniqueKey**: This section defines a field to be unique and mandatory. This
    field will be used to enforce uniqueness among all documents.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**copyField**: This section can be used to copy multiple fields into a single
    field. So we can have multiple text fields with different field types and a super
    field where all text fields are copied for a generic search among all fields.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding sample documents to the Solr index
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let us push in some sample data into Solr. Go to `<solr_dir>/example/exampledocs`.
    Execute the following commands to add all sample documents into our Solr index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To check how many documents have been indexed go to the following URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This is a query to Solr that asks to return all the documents in the index.
    The `numFound` field in the XML output specifies the number of documents in our
    Solr index.
  prefs: []
  type: TYPE_NORMAL
- en: '![Adding sample documents to the Solr index](graphics/4920_02_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We are working with the default schema. To check the schema, go to the following
    URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the content of a sample schema file `schema.xml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Adding sample documents to the Solr index](graphics/4920_02_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We can see that there are multiple fields: `id`, `title`, `subject`, `description`,
    `author`, and others. Configuring Solr is all about designing the schema to suit
    the field requirements. We can also see that the `id` field is unique.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can insert documents in Solr via the `post.jar` program as seen earlier.
    To do this, we would need to create an XML, CSV, or JSON file specifying the fields
    and values in the document. Once the file is ready, we can simply call one of
    the earlier mentioned commands to insert the document in the file into Solr. The
    XML format for the file is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The `post.jar` file is a program for processing multiple documents in a file.
    We can use it if we have a large number of documents to insert and the documents
    are in a CSV, XML, or JSON format. The PHP code used to insert documents in Solr
    in turn creates a Solr URL and makes a `curl` call with appropriate data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Using PHP to add documents to the Solr index
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let us see the code to add documents to Solr using the Solarium library. When
    we execute the following query we can see that there are three books of the author
    *George R R Martin* in our Solr index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Let us add the remaining two books, which have also been published to our index:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a solarium client using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Create an instance of the update query using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Create the documents you want to add and add fields to the document.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Similarly, another document `$doc2` can be created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that the `id` field is unique. So we will have to keep different `id` field
    for different documents that we add to Solr.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add documents to the update query followed by the `commit` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, execute the following query:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let us execute the code using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: After executing the code, the search for martin gives five results
  prefs: []
  type: TYPE_NORMAL
- en: 'To add a single document, we can call the `addDocument` function to the update
    query instance using the following line of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Updating documents in Solr using PHP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let us see how we can use PHP code along with Solarium library to update documents
    in Solr.
  prefs: []
  type: TYPE_NORMAL
- en: First check if there are any documents with the word `smith` in our index.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: We can see `numFound=0`, which means that there are no such documents. Let us
    add a book to our index with the last name of the author as `smith`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run the same select query again, we can see that now there is one document
    in our index with the author as `Smith`. Let us now update the author''s name
    to `Jack Smith` and the price tag to `7.59`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: On running the same query again, we can see that now the author name and price
    is updated in our index on Solr.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The process to update a document in Solr is similar to that of adding a document
    in Solr except for the fact that we have to set the `overwrite` flag to `true`.
    If no parameter is set, Solarium will not pass any flag to Solr. But on the Solr
    end, the `overwrite` flag is by default set to `true`. So any document to Solr
    will replace a previous document with the same unique key.
  prefs: []
  type: TYPE_NORMAL
- en: Solr internally does not have an update command. In order to update a document,
    when we provide the unique key and the overwrite flag, Solr internally deletes
    and inserts the document again.
  prefs: []
  type: TYPE_NORMAL
- en: We will need to add all fields of the document again, even fields that are not
    required to be updated. Since Solr will be deleting the complete document and
    inserting the new document.
  prefs: []
  type: TYPE_NORMAL
- en: Another interesting parameter in the method signature is the commit within time.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code asks Solr to overwrite the document and commit within 10
    seconds. This is explained later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We can also use the `addDocuments(array($doc1, $doc2))` command to update multiple
    documents in a single call.
  prefs: []
  type: TYPE_NORMAL
- en: Deleting documents in Solr using PHP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now let us go ahead and delete this document from Solr.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, if we run the following query on Solr, the document is not found:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: What we did here was that we created a query in Solr to search for all documents
    where the author field contains the `smith` word and then passed it as a delete
    query.
  prefs: []
  type: TYPE_NORMAL
- en: We can add multiple delete queries via the `addDeleteQueries` method. This can
    be used to delete multiple sets of documents in a single call.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: When this query is executed, all documents where the author field is either
    `Burst` or `Alexander` are deleted from the index.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to deleting by a query, we can also delete by ID. Each book that
    we have added to our index has an `id` field, which we have marked as unique.
    To delete by ID, simply call the `addDeleteById($id)` function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: We can also use the `addDeleteByIds(array $ids)` to delete multiple documents
    in a single go.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In addition to using PHP code to delete documents, we can also use `curl` calls
    to delete a document by ID or by query. The curl call to delete by ID is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'And the `curl` call to delete by query is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a simple way of deleting all documents from the Solr index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Commit, rollback, and index optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `commitWithin` parameter that we have been passing as arguments to our `addDocument()`
    function specifies the time for the commit to happen for this add document operation.
    This leaves the control of when to do the commit to Solr itself. Solr optimizes
    the number of commits to a minimum while still fulfilling the update latency requirements.
  prefs: []
  type: TYPE_NORMAL
- en: The rollback option is exposed via the `addRollback()` function. Rollback can
    be done since the last commit and before current commit. Once a commit has been
    done, the changes cannot be rolled back.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Index optimization is one of the tasks that is not necessarily required. But
    an optimized index has better performance than a non-optimized index. To optimize
    an index using the PHP code, we can use the `addOptimize(boolean $softCommit,
    boolean $waitSearcher, int $maxSegments)` function. It has parameters to enable
    soft commit, wait until a new searcher is opened and number of segments to optimize
    to. Also note that index optimization slows down the execution of all other queries
    on Solr.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: For more advanced options, we can also use the `addParam()` function to add
    key value pairs to the query string.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: It is generally advisable to combine multiple commands in a single request.
    The commands are executed in the order in which they are added to the request.
    But we should also take care not to build huge queries that exceed the limit of
    a request. Use rollbacks in exception scenarios to avoid partial updates/deletes
    when running bulk queries and perform commit separately.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding piece of code if the `update` query throws an exception, then
    it is rolled back.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter we started off by discussing the Solr schema. We got a basic
    understanding of how the Solr schema works. We then added some sample documents
    to our Solr index. Then we saw multiple pieces of code to add, update, and delete
    documents to our Solr index. We also saw how to use cURL to delete documents.
    We discussed how commit and rollback work on the Solr index. We also saw an example
    of how to use rollback in our code. We discussed index optimization using PHP
    code and the benefits of optimizing the Solr index.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter we will see how to execute search queries on Solr using
    PHP code and explore different query modes available with Solr.
  prefs: []
  type: TYPE_NORMAL
