- en: Real-Time Processing and Storm Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the exponential growth in the amount of data being generated and advanced
    data-capturing capabilities, enterprises are facing the challenge of making sense
    out of this mountain of raw data. On the batch processing front, Hadoop has emerged
    as the go-to framework to deal with big data. Until recently, there has been a
    void when one looks for frameworks to build real-time stream processing applications.
    Such applications have become an integral part of a lot of businesses as they
    enable them to respond swiftly to events and adapt to changing situations. Examples
    of this are monitoring social media to analyze public response to any new product
    that you launch and predicting the outcome of an election based on the sentiments
    of election-related posts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Organizations are collecting a large volume of data from external sources and
    want to evaluate/process the data in real time to get market trends, detect fraud,
    identify user behavior, and so on. The need for real-time processing is increasing
    day by day and we require a real-time system/platform that should support the
    following features:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scalable**: The platform should be horizontally scalable without any down
    time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fault tolerance**: The platform should be able to process the data even after
    some of the nodes in a cluster go down.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**No data lost**: The platform should provide the guaranteed processing of
    messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**High throughput**: The system should be able to support millions of records
    per second and also support any size of messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Easy to operate**: The system should have easy installation and operation.
    Also, the expansion of clusters should be an easy process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multiple languages**: The platform should support multiple languages. The
    end user should be able to write code in different languages. For example, a user
    can write code in Python, Scala, Java, and so on. Also, we can execute different
    language code inside the one cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cluster isolation**: The system should support isolation so that dedicated
    processes can be assigned to dedicated machines for processing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Storm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apache Storm has emerged as the platform of choice for industry leaders to develop
    distributed, real-time, data processing platforms. It provides a set of primitives
    that can be used to develop applications that can process a very large amount
    of data in real time in a highly scalable manner.
  prefs: []
  type: TYPE_NORMAL
- en: 'Storm is to real-time processing what Hadoop is to batch processing. It is
    open source software, and managed by Apache Software Foundation. It has been deployed
    to meet real-time processing needs by companies such as Twitter, Yahoo!, and Flipboard.
    Storm was first developed by Nathan Marz at BackType, a company that provided
    social search applications. Later, BackType was acquired by Twitter, and it is
    a critical part of their infrastructure. Storm can be used for the following use
    cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Stream processing**: Storm is used to process a stream of data and update
    a variety of databases in real time. This processing occurs in real time and the
    processing speed needs to match the input data speed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Continuous computation**: Storm can do continuous computation on data streams
    and stream the results to clients in real time. This might require processing
    each message as it comes in or creating small batches over a short time. An example
    of continuous computation is streaming trending topics on Twitter into browsers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distributed RPC**: Storm can parallelize an intense query so that you can
    compute it in real time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Real-time analytics**: Storm can analyze and respond to data that comes from
    different data sources as they happen in real time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is a Storm?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Features of Storm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Architecture and components of a Storm cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Terminologies of Storm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Programming language
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operation modes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Features of Storm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are some of the features of Storm that make it a perfect solution
    to process streams of data in real time:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Fast**: Storm has been reported to process up to 1 million tuples/records
    per second per node.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Horizontally scalable**: Being fast is a necessary feature to build a high
    volume/velocity data processing platform, but a single node will have an upper
    limit on the number of events that it can process per second. A node represents
    a single machine in your setup that executes Storm applications. Storm, being
    a distributed platform, allows you to add more nodes to your Storm cluster and
    increase the processing capacity of your application. Also, it is linearly scalable,
    which means that you can double the processing capacity by doubling the nodes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fault tolerant**: Units of work are executed by worker processes in a Storm
    cluster. When a worker dies, Storm will restart that worker, and if the node on
    which the worker is running dies, Storm will restart that worker on some other
    node in the cluster. This feature will be covered in more detail in [Chapter 3](part0056.html#1LCVG0-6149dd15e07b443593cc93f2eb31ee7b),
    *Storm Parallelism and Data Partitioning*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Guaranteed data processing**: Storm provides strong guarantees that each
    message entering a Storm process will be processed at least once. In the event
    of failures, Storm will replay the lost tuples/records. Also, it can be configured
    so that each message will be processed only once.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Easy to operate**: Storm is simple to deploy and manage. Once the cluster
    is deployed, it requires little maintenance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Programming language agnostic**: Even though the Storm platform runs on **Java
    virtual machine** (**JVM**), the applications that run over it can be written
    in any programming language that can read and write to standard input and output
    streams.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storm components
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Storm cluster follows a master-slave model where the master and slave processes
    are coordinated through ZooKeeper. The following are the components of a Storm
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Nimbus
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Nimbus node is the master in a Storm cluster. It is responsible for distributing
    the application code across various worker nodes, assigning tasks to different
    machines, monitoring tasks for any failures, and restarting them as and when required.
  prefs: []
  type: TYPE_NORMAL
- en: Nimbus is stateless and stores all of its data in ZooKeeper. There is a single
    Nimbus node in a Storm cluster. If the active node goes down, then the passive
    node will become an Active node. It is designed to be fail-fast, so when the active
    Nimbus dies, the passive node will become an active node, or the down node can
    be restarted without having any effect on the tasks already running on the worker
    nodes. This is unlike Hadoop, where if the JobTracker dies, all the running jobs
    are left in an inconsistent state and need to be executed again. The Storm workers
    can work smoothly even if all the Nimbus nodes go down but the user can't submit
    any new jobs into the cluster or the cluster will not be able to reassign the
    failed workers to another node.
  prefs: []
  type: TYPE_NORMAL
- en: Supervisor nodes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Supervisor nodes are the worker nodes in a Storm cluster. Each supervisor node
    runs a supervisor daemon that is responsible for creating, starting, and stopping
    worker processes to execute the tasks assigned to that node. Like Nimbus, a supervisor
    daemon is also fail-fast and stores all of its states in ZooKeeper so that it
    can be restarted without any state loss. A single supervisor daemon normally handles
    multiple worker processes running on that machine.
  prefs: []
  type: TYPE_NORMAL
- en: The ZooKeeper cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In any distributed application, various processes need to coordinate with each
    other and share some configuration information. ZooKeeper is an application that
    provides all these services in a reliable manner. As a distributed application,
    Storm also uses a ZooKeeper cluster to coordinate various processes. All of the
    states associated with the cluster and the various tasks submitted to Storm are
    stored in ZooKeeper. Nimbus and supervisor nodes do not communicate directly with
    each other, but through ZooKeeper. As all data is stored in ZooKeeper, both Nimbus
    and the supervisor daemons can be killed abruptly without adversely affecting
    the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an architecture diagram of a Storm cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00005.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The Storm data model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The basic unit of data that can be processed by a Storm application is called
    a tuple. Each tuple consists of a predefined list of fields. The value of each
    field can be a byte, char, integer, long, float, double, Boolean, or byte array.
    Storm also provides an API to define your own datatypes, which can be serialized
    as fields in a tuple.
  prefs: []
  type: TYPE_NORMAL
- en: A tuple is dynamically typed, that is, you just need to define the names of
    the fields in a tuple and not their datatype. The choice of dynamic typing helps
    to simplify the API and makes it easy to use. Also, since a processing unit in
    Storm can process multiple types of tuples, it's not practical to declare field
    types.
  prefs: []
  type: TYPE_NORMAL
- en: Each of the fields in a tuple can be accessed by its name, `getValueByField(String)`,
    or its positional index, `getValue(int)`, in the tuple. Tuples also provide convenient
    methods such as `getIntegerByField(String)` that save you from typecasting the
    objects. For example, if you have a *Fraction (numerator, denominator)* tuple,
    representing fractional numbers, then you can get the value of the numerator by
    either using `getIntegerByField("numerator")` or `getInteger(0)`.
  prefs: []
  type: TYPE_NORMAL
- en: You can see the full set of operations supported by `org.apache.storm.tuple.Tuple`
    in the Java doc that is located at [https://storm.apache.org/releases/1.0.2/javadocs/org/apache/storm/tuple/Tuple.html](https://storm.apache.org/releases/1.0.2/javadocs/org/apache/storm/tuple/Tuple.html).
  prefs: []
  type: TYPE_NORMAL
- en: Definition of a Storm topology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In Storm terminology, a topology is an abstraction that defines the graph of
    the computation. You create a Storm topology and deploy it on a Storm cluster
    to process data. A topology can be represented by a direct acyclic graph, where
    each node does some kind of processing and forwards it to the next node(s) in
    the flow. The following diagram is a sample Storm topology:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00006.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following are the components of a Storm topology:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Tuple**: A single message/record that flows between the different instances
    of a topology is called a tuple.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stream**: The key abstraction in Storm is that of a stream. A stream is an
    unbounded sequence of tuples that can be processed in parallel by Storm. Each
    stream can be processed by a single or multiple types of bolts (the processing
    units in Storm, which are defined later in this section). Thus, Storm can also
    be viewed as a platform to transform streams. In the preceding diagram, streams
    are represented by arrows. Each stream in a Storm application is given an ID and
    the bolts can produce and consume tuples from these streams on the basis of their
    ID. Each stream also has an associated schema for the tuples that will flow through
    it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spout**: A spout is the source of tuples in a Storm topology. It is responsible
    for reading or listening to data from an external source, for example, by reading
    from a log file or listening for new messages in a queue and publishing them--emitting
    in Storm terminology into streams. A spout can emit multiple streams, each of
    a different schema. For example, it can read records of 10 fields from a log file
    and emit them as different streams of seven-fields tuples and four-fields tuples
    each.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `org.apache.storm.spout.ISpout` interface is the interface used to define
    spouts. If you are writing your topology in Java, then you should use `org.apache.storm.topology.IRichSpout`
    as it declares methods to use with the `TopologyBuilder` API. Whenever a spout
    emits a tuple, Storm tracks all the tuples generated while processing this tuple,
    and when the execution of all the tuples in the graph of this source tuple is
    complete, it will send an acknowledgement back to the spout. This tracking happens
    only if a message ID was provided when emitting the tuple. If null was used as
    the message ID, this tracking will not happen.
  prefs: []
  type: TYPE_NORMAL
- en: A tuple processing timeout can also be defined for a topology, and if a tuple
    is not processed within the specified timeout, a fail message will be sent back
    to the spout. Again, this will happen only if you define a message ID. A small
    performance gain can be extracted out of Storm at the risk of some data loss by
    disabling the message acknowledgements, which can be done by skipping the message
    ID while emitting tuples.
  prefs: []
  type: TYPE_NORMAL
- en: 'The important methods of spout are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`nextTuple()`: This method is called by Storm to get the next tuple from the
    input source. Inside this method, you will have the logic of reading data from
    external sources and emitting them to an instance of `org.apache.storm.spout.ISpoutOutputCollector`.
    The schema for streams can be declared by using the `declareStream` method of
    `org.apache.storm.topology.OutputFieldsDeclarer`.'
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: If a spout wants to emit data to more than one stream, it can declare multiple
    streams using the `declareStream` method and specify a stream ID while emitting
    the tuple. If there are no more tuples to emit at the moment, this method will
    not be blocked. Also, if this method does not emit a tuple, then Storm will wait
    for 1 millisecond before calling it again. This waiting time can be configured
    using the `topology.sleep.spout.wait.strategy.time.ms` setting.
  prefs: []
  type: TYPE_NORMAL
- en: '`ack(Object msgId)`: This method is invoked by Storm when the tuple with the
    given message ID is completely processed by the topology. At this point, the user
    should mark the message as processed and do the required cleaning up, such as
    removing the message from the message queue so that it does not get processed
    again.'
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fail(Object msgId)`: This method is invoked by Storm when it identifies that
    the tuple with the given message ID has not been processed successfully or has
    timed out of the configured interval. In such scenarios, the user should do the
    required processing so that the messages can be emitted again by the `nextTuple`
    method. A common way to do this is to put the message back in the incoming message
    queue.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`open()`: This method is called only once--when the spout is initialized. If
    it is required to connect to an external source for the input data, define the
    logic to connect to the external source in the open method, and then keep fetching
    the data from this external source in the `nextTuple` method to emit it further.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another point to note while writing your spout is that none of the methods should
    be blocking, as Storm calls all the methods in the same thread. Every spout has
    an internal buffer to keep track of the status of the tuples emitted so far. The
    spout will keep the tuples in this buffer until they are either acknowledged or
    failed, calling the `ack` or `fail` method, respectively. Storm will call the
    `nextTuple` method only when this buffer is not full.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bolt**: A bolt is the processing powerhouse of a Storm topology and is responsible
    for transforming a stream. Ideally, each bolt in the topology should be doing
    a simple transformation of the tuples, and many such bolts can coordinate with
    each other to exhibit a complex transformation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `org.apache.storm.task.IBolt` interface is preferably used to define bolts,
    and if a topology is written in Java, you should use the `org.apache.storm.topology.IRichBolt`
    interface. A bolt can subscribe to multiple streams of other components--either
    spouts or other bolts--in the topology and similarly can emit output to multiple
    streams. Output streams can be declared using the `declareStream` method of `org.apache.storm.topology.OutputFieldsDeclarer`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The important methods of a bolt are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`execute(Tuple input)`: This method is executed for each tuple that comes through
    the subscribed input streams. In this method, you can do whatever processing is
    required for the tuple and then produce the output either in the form of emitting
    more tuples to the declared output streams, or other things such as persisting
    the results in a database.'
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: You are not required to process the tuple as soon as this method is called,
    and the tuples can be held until required. For example, while joining two streams,
    when a tuple arrives you can hold it until its counterpart also comes, and then
    you can emit the joined tuple.
  prefs: []
  type: TYPE_NORMAL
- en: The metadata associated with the tuple can be retrieved by the various methods
    defined in the `Tuple` interface. If a message ID is associated with a tuple,
    the execute method must publish an `ack` or `fail` event using `OutputCollector`
    for the bolt, or else Storm will not know whether the tuple was processed successfully.
    The `org.apache.storm.topology.IBasicBolt` interface is a convenient interface
    that sends an acknowledgement automatically after the completion of the execute
    method. If a fail event is to be sent, this method should throw `org.apache.storm.topology.FailedException`.
  prefs: []
  type: TYPE_NORMAL
- en: '`prepare(Map stormConf, TopologyContext context, OutputCollector collector)`:
    A bolt can be executed by multiple workers in a Storm topology. The instance of
    a bolt is created on the client machine and then serialized and submitted to Nimbus.
    When Nimbus creates the worker instances for the topology, it sends this serialized
    bolt to the workers. The work will desterilize the bolt and call the `prepare`
    method. In this method, you should make sure the bolt is properly configured to
    execute tuples. Any state that you want to maintain can be stored as instance
    variables for the bolt that can be serialized/deserialized later.'
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: Operation modes in Storm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Operation modes indicate how the topology is deployed in Storm. Storm supports
    two types of operation modes to execute the Storm topology:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Local mode**: In local mode, Storm topologies run on the local machine in
    a single JVM. This mode simulates a Storm cluster in a single JVM and is used
    for the testing and debugging of a topology.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Remote mode**: In remote mode, we will use the Storm client to submit the
    topology to the master along with all the necessary code required to execute the
    topology. Nimbus will then take care of distributing your code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next chapter, we are going to cover both local and remote mode in more
    detail, along with a sample example.
  prefs: []
  type: TYPE_NORMAL
- en: Programming languages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Storm was designed from the ground up to be usable with any programming language.
    At the core of Storm is a thrift definition for defining and submitting topologies.
    Since thrift can be used in any language, topologies can be defined and submitted
    in any language.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, spouts and bolts can be defined in any language. Non-JVM spouts and
    bolts communicate with Storm over a JSON-based protocol over `stdin`/`stdout`.
    Adapters that implement this protocol exist for Ruby, Python, JavaScript, and
    Perl. You can refer to [https://github.com/apache/storm/tree/master/storm-multilang](https://github.com/apache/storm/tree/master/storm-multilang)
    to find out about the implementation of these adapters.
  prefs: []
  type: TYPE_NORMAL
- en: Storm-starter has an example topology, [https://github.com/apache/storm/tree/master/examples/storm-starter/multilang/resources](https://github.com/apache/storm/tree/master/examples/storm-starter/multilang/resources),
    which implements one of the bolts in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced you to the basics of Storm and the various components
    that make up a Storm cluster. We saw a definition of different deployment/operation
    modes in which a Storm cluster can operate.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will set up a single and three-node Storm cluster and
    see how we can deploy the topology on a Storm cluster. We will also see different
    types of stream groupings supported by Storm and the guaranteed message semantic
    provided by Storm.
  prefs: []
  type: TYPE_NORMAL
