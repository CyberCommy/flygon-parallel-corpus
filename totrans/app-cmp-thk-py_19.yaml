- en: '*Chapter 16*: Advanced Applied Computational Thinking Problems'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will continue providing examples in multiple areas for
    applications of the Python programming language and computational thinking. We
    will be exploring multiple areas, such as geometric tessellations, creating models
    of housing data, creating electric fields, analyzing genetic data, analyzing stocks,
    creating a **convolutional neural network** (**CNN**), and more. We will use what
    we''ve learned so far in relation to **computational thinking** and the **Python**
    programming language to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Create tessellations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyze biological data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyze data for specific populations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create models of housing data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create electric field lines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyze generic data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyze stocks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a convolutional neural network (CNN)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After reading this chapter, you'll have learned how to perform various different
    analyses in working with data, creating tables and graphs that help to analyze
    existing data, as well as create training and testing models to help predict outcomes
    based on existing large datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will need the latest version of Python installed to run the code in this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will need the following libraries and packages installed for Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '**NLTK**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cairos**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pandas**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Matplotlib**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Seaborn**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can find the full source code used in this chapter here: [https://github.com/PacktPublishing/Applied-Computational-Thinking-with-Python/tree/master/Chapter16](https://github.com/PacktPublishing/Applied-Computational-Thinking-with-Python/tree/master/Chapter16)'
  prefs: []
  type: TYPE_NORMAL
- en: Problem 1 – Using Python to create tessellations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to provide an example using the `cairo` library
    for Python. We are going to create a **tessellation**, more specifically, a sample
    of a **Penrose tiling**. Because this is a straightforward problem, we are going
    to define our parameters using the computational thinking process, but not adhere
    to it precisely.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s talk about the `cairo` library. Once the `pip install cairo`
    command is successful, you''ll need to perform one more step to include all the
    components needed. Use `pip install pycairo` to add the necessary components.
    The `cairo` and `pycairo` packages are graphics libraries that work with Python.
    For more information, you can visit their web page: [https://cairographics.org/pycairo](https://cairographics.org/pycairo).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s define some things. A **tessellation** is a tiling that uses shapes
    that do not overlap to create patterns. Tessellations are often explored in geometry
    courses. For our example, we will create a Penrose tiling pattern using two triangles.
    We will also get to define our space and the number of sub-divisions we want the
    shapes to undergo. The more sub-divisions, the smaller the pattern in the space
    defined. Let''s take a look at the algorithm (the file `ch16_tessellation.py`
    contains the full algorithm discussed here0:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we''ll do is import the necessary packages and libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ch16_tessellation.py
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we want to define our canvas and the number of sub-divisions. Note that
    we chose `4` for our example. In *Figure 16.1*, you''ll see the example from this
    snippet as well as two additional examples changing the sub-divisions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: For the tessellation, we need to define the **Golden Ratio**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The golden ratio is also known as the golden mean or divine proportion (among
    other names). The ratio is approximately 1.618\. As an example, if we were talking
    about a line segment divided into two parts, then the length of the larger segment
    divided by the length of the smaller segment would be equal to the sum of the
    segments divided by the larger segment: ![](image/Formula_B15413_16_001.png).
    For the tessellation, we''ll need to define that golden ratio.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we use functions to define what happens when our triangles sub-divide:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we defined the function to sub-divide the triangles.
    The function contains a conditional statement to identify the color of the triangles
    prior to finding the ratio.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create the wheel of the triangles, we need to append the triangles to a
    group. Because Python is an object-oriented programming language, we can easily
    do that by creating an empty list and then appending the shapes using loops:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we have to prepare the canvas we''ll use for our tessellation. Notice that
    we use the `cairo` functions to define the parameters using the variables we defined
    in the beginning of the algorithm. Here, we use `canvas_size`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we have to define the two triangles we''ll be using. In this case, our
    triangles are teal and purple, but you can change the RGB values in them, that
    is, if you''d like to test different colors:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code creates the teal triangles and the purple triangles. Each
    is defined with the RGB values and created with paths and lines.
  prefs: []
  type: TYPE_NORMAL
- en: 'The rotated triangles make a tile pattern, that is, our tessellation. The tiles
    are also separated by a border. The color of the border is also defined in the
    loop that follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we want the algorithm to create an image file with our tessellation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows three variations using different numbers of
    sub-divisions for our algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.1 – Sample tessellations'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.01_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.1 – Sample tessellations
  prefs: []
  type: TYPE_NORMAL
- en: As you can see from the preceding images, the larger the number of sub-divisions,
    the smaller the tile pattern becomes to fit into our defined canvas size.
  prefs: []
  type: TYPE_NORMAL
- en: As you play with the algorithm, consider changing the canvas size, the sub-divisions,
    and the colors. If you want an additional challenge, try changing the triangle
    pattern to another polygon.
  prefs: []
  type: TYPE_NORMAL
- en: Problem 2 – Using Python in biological data analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this particular problem, we'll be using the `Breast_cancer_data.csv` file,
    which can be found on **Kaggle** ([https://www.kaggle.com/nsaravana/breast-cancer?select=breast-cancer.csv](https://www.kaggle.com/nsaravana/breast-cancer?select=breast-cancer.csv)).
    The file has also been uploaded to the book's GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: When looking at data, sometimes we want to make comparisons with the data we
    currently have, or we want to use it for predictions in machine learning. In this
    case, we're going to look at how we can present another type of plot, the **scatterplot**,
    using two specific values of columns in our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Let's imagine you received this data and already determined that your mean perimeter
    and mean textures are better predictors than the other values in the columns.
    Your goal now is to create an algorithm that will analyze the values for those
    two columns by comparing them using a scatterplot. Our goal is only to get that
    scatterplot. For additional analysis and machine learning applications, feel free
    to explore [*Chapter 13*](B15413_13_Final_SK_ePub.xhtml#_idTextAnchor174), *Using
    Classification and Clusters*, and [*Chapter 14*](B15413_14_Final_SK_ePub.xhtml#_idTextAnchor184),
    *Using Computational Thinking and Python in Statistical Analyses*, for additional
    help.
  prefs: []
  type: TYPE_NORMAL
- en: 'The full code for this problem can be found in the file `ch16_BreastCancerSample.py`.
    We can now start to design our algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin as we normally do with data, importing the libraries we''ll use. Note
    that we are using two display libraries here, the `matplotlib` and `seaborn` libraries.
    This is the first time we''ll use `seaborn`. We are using `seaborn` because the
    additional work, such as finding regression lines, is handled easily with the
    help of this library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we''re going to find the `.csv` file. Remember that you can always establish
    the directory first. Otherwise, make sure you include the full location of the
    file. Since our directories are different, make sure you change that before running
    the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice the `dataset.head()` command in the algorithm. If we run the code up
    until that point only, then we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.2 – Table showing the heading values'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.02_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.2 – Table showing the heading values
  prefs: []
  type: TYPE_NORMAL
- en: The `dataset.isnull().sum()` command helps us see whether we have empty data
    points or values.
  prefs: []
  type: TYPE_NORMAL
- en: If we have many null points, we can clean the dataset before we start the analysis.
    This data is clean, as can be seen from the following output if we run the program
    up until `dataset.isnull().sum()`, as can be seen in the following screenshot:![Figure
    16.3 – Output of the null check
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](image/Figure_16.03_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.3 – Output of the null check
  prefs: []
  type: TYPE_NORMAL
- en: 'Since there are no missing values, as seen in the preceding screenshot, we''re
    going to continue to our next snippet, where we''ll create the `count` variable
    for diagnosis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The `count` variable is created in the preceding snippet, meaning we can create
    a bar graph using the values of the diagnosis, whether it was malignant or benign.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet creates that bar graph and shows us the resulting
    output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Take a look at the following screenshot, which shows the bar graph using the
    diagnosis values. As you can see, the bar graph shows the count of **malignant**
    tumors versus **benign** tumors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.4 – Malignant versus benign diagnosis bar graph'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.04_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.4 – Malignant versus benign diagnosis bar graph
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have that information and the bar graph, we can start looking at
    other combinations and comparisons using the values from our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can run a different analysis to see which are more relevant, but for now,
    we are just going to use the perimeter mean and texture mean to create our scatterplot.
    The following code snippet shows how to create those using the `seaborn` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have created our scatterplot, the algorithm will return the following
    output, which shows the mean perimeter scatterplot compared with the mean texture
    scatterplot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.5 – Mean perimeter versus mean texture scatterplot'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.05_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.5 – Mean perimeter versus mean texture scatterplot
  prefs: []
  type: TYPE_NORMAL
- en: We are going to pause here for this data analysis. However, please note that
    you can take this example much further. In fact, you can find multiple applications
    and analyses done in Kaggle with this particular dataset and how some developers
    and coders incorporated machine learning in order to make predictions. The world
    of bioinformatics is wide and data science applications are continuing to grow.
    The use of Python in these problems is helpful due to its ease of use and applicable
    libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Problem 3 – Using Python to analyze data for specific populations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this section, we'll state our problem this way—the year is 2020 and the
    world is overwhelmed by a pandemic due to the **SARS-COV-19** virus, also known
    as **coronavirus** or **COVID-19**. The data is available widely and we are trying
    to look at what's happening in a specific location, in particular, how the number
    of deaths are growing for that location. We find the New York Times GitHub repository,
    which contains the COVID-19 data, and download the master data, which is updated
    daily. Let's look at what we need to do and how we find it.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the specific problem to analyze and identify the population
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This problem is broad. *Too broad!* So let's first look at 1 location and for
    only 1 month. For example, let's choose Puerto Rico and the month of October.
    From the master `.csv` file, we've pulled only the data specific for Puerto Rico
    and added it to our repository. Again, the master can be found in the New York
    Times, covid-19-data repository, and you can perform multiple analyses using the
    full data, a specific state, or even a specific county.
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, we''re going to concentrate on creating a visual for the data for
    deaths specific to Puerto Rico in October 2020\. From just looking at the data,
    we see that the deaths are rising. Take a look at the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.6 – Data for the first 20 days of October 2020 in Puerto Rico'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.06_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.6 – Data for the first 20 days of October 2020 in Puerto Rico
  prefs: []
  type: TYPE_NORMAL
- en: As you can see from the preceding screenshot, the **deaths** column continues
    to rise, as does the number of cases, which we will take a look at a little later
    in this problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'While data read in a table format can be helpful, a visual representation is
    critical if we were to present this information, especially if we want to identify
    trends and influence policy changes. So let''s take a look at how we''d create
    a scatterplot for this particular data. The full file can be found in `ch16_CovidPR.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'As always when working with data, we need to make sure we import the libraries
    we''ll be using:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we''ll need to get our file. Remember, there are multiple ways to do
    this. You can give Python the full location of your file or you can first identify
    the directory and only provide the filename. Please make sure you change the location
    of the `.csv` file you''ll be using before running the program:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'After identifying the file, we''ll just create a simple scatterplot using the
    dates as our *x*-axis, and the deaths as our *y*-axis. The next few commands in
    this code snippet are done to make it easier to read the chart, such as the *y*-axis
    label, the rotation of the *x-tick* marks, and the title of the chart. The *x-tick*
    marks are the division marks for the horizontal axis, or *x*-axis. You can see
    the *x-tick* marks and the labels in *Figure 16.6*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from the preceding code snippet, we also created an image file
    for us to use later, if needed. The chart will show on our screen, as can be seen
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.7 – Deaths per day during October 2020 due to COVID-19 in Puerto
    Rico'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.07_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.7 – Deaths per day during October 2020 due to COVID-19 in Puerto Rico
  prefs: []
  type: TYPE_NORMAL
- en: This is a helpful chart to see that the number of deaths is increasing at a
    steady pace. There are more things we can do, such as try to determine the regression,
    which is another functionality we can do with Python using the `numpy` library,
    which you are welcome to work out!
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, we''re going to take a look at the cases by date. The code is the
    same as previously, except that our *y*-axis and title will be different. The
    full code can be found in the `ch16_CovidPR_2` file. As the code is very similar,
    we are not sharing it here. However, our resulting graph can be seen in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.8 – Cases per day during October 2020 due to COVID-19 in Puerto
    Rico'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.08_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.8 – Cases per day during October 2020 due to COVID-19 in Puerto Rico
  prefs: []
  type: TYPE_NORMAL
- en: As you can see from the preceding screenshot, the number of cases has continued
    to rise each day in Puerto Rico. There are multiple things we could do with these
    two graphs; analyzing their regressions, verifying additional trends by looking
    at other monthly data, and so on. You've now seen how to create a simple plot
    to display the data based on your `.csv` file; the rest is up to you. We will
    look at a new problem in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Problem 4 – Using Python to create models of housing data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's take a look at a problem where we want to display trends and information
    about the housing market in Brooklyn, New York. The dataset includes information
    from the NYC Housing Sales Data for 2003-2017\. The dataset used has the information
    merged in a usable format and can be found on Kaggle here ([https://www.kaggle.com/tianhwu/brooklynhomes2003to2017](https://www.kaggle.com/tianhwu/brooklynhomes2003to2017)).
    In addition, a copy of the `.csv` file can be found in the GitHub repository under
    the name `brooklyn_sales_map.csv`.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have a large data file for this particular problem. We can look at information
    by neighborhood, sale prices by year, compare the year built to the neighborhood
    to find trends, history, and so on. We could spend hours, days, and weeks just
    on this one dataset. So let's try to focus our energy into what we are going to
    accomplish with this example. For this, we're going to create two visual models.
    The first is a horizontal bar graph of housing percentages in a sale range according
    to the year of sale. The second is a bar graph that shows the price range by the
    neighborhoods where houses were sold.
  prefs: []
  type: TYPE_NORMAL
- en: The horizontal bar graph can help display the data in a much clearer way so
    that we can see house price ranges and whether there are significant changes.
    The vertical bar graph can show us those same price ranges by neighborhood, so
    we can see whether there are significant changes depending on the neighborhoods
    where the houses were sold.
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm and visual representations of data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s take a look at the code snippet. The full file can be found in the GitHub
    repository under `ch16_housingBrooklyn.py`. As usual, don''t forget to update
    the file location in the file before trying to run the program:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For this particular program, we''ll need the `pandas` and `matplotlib` libraries,
    so we need to import them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to read our file. This is where you''ll need to update this code
    in order to run it from your machine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we''re going to create our `bins`. These are our range of values and we''ll
    call them when we are creating the charts, as you can see under `df[''price_range'']`
    within the following few lines of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we''re going to define a function, where we are going to convert some of
    the data. Notice that we run that function on each of the years from the dataset
    to find our percent total, which we''ll use later on for `housing_df`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding snippet helps us to create the first of the two models. This
    one is a horizontal bar graph. We labeled all the axes and the graph, and then,
    in the next line shown in the preceding code snippet, we also defined the color
    map we''ll use for this graph, in this case, `''Spectral''`. You can play with
    the color mappings available for easier reading. Take a look at our first graph,
    shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.9 – Housing sales in Brooklyn by year'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.09_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.9 – Housing sales in Brooklyn by year
  prefs: []
  type: TYPE_NORMAL
- en: Notice that we use percentages in the preceding screenshot. This allows us to
    show how much of the sales were in each price range, but it does not show us the
    actual number of sales in each price range. Those two things are quite different.
    Here, we are looking for trends. The percentage of sales that were higher than
    $1,000,000 has consistently increased after a slight dip from **2008** to **2009**.
    In **2017**, a much larger percentage of sales was above that price point than
    in **2003**.
  prefs: []
  type: TYPE_NORMAL
- en: But that's total sales. If we were only looking at this graph without looking
    at the numbers as well, we wouldn't know whether fewer houses were sold in total
    in 2017, for example. Again, the important thing to note here is that this graph
    is extremely helpful for understanding the share of housing selling under each
    price range, but that's all this graph really gives us. Now let's look at the
    remaining code from our file.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this next snippet, we create our second graph, which uses our information
    to produce a vertical bar graph with the percentages within each price range for
    each neighborhood:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This graph shows us the price range in each neighborhood using a bar graph.
    Let''s take a look at our second graph in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.10 – Pricing by neighborhoods in Brooklyn from 2003-2017'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.10_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.10 – Pricing by neighborhoods in Brooklyn from 2003-2017
  prefs: []
  type: TYPE_NORMAL
- en: As you can see from the preceding screenshot, we get some important information
    that is additional or more detailed than that in *Figure 16.1*. In this case,
    the data is provided by neighborhood and the breakdown is provided by price range
    in those neighborhoods.
  prefs: []
  type: TYPE_NORMAL
- en: When we look at a large dataset, we can create multiple different models and
    even use them to predict values moving forward. Take a look at the data available
    in the `.csv` file and try to create some different representations using other
    data, such as commercial versus residential sales, tax class breakdowns, and more.
  prefs: []
  type: TYPE_NORMAL
- en: Problem 5 – Using Python to create electric field lines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, let''s look at some applications of Python for engineering
    and, in particular, physics. We are going to be creating an **electric field lines
    plot**. *Why would we want to create that kind of plot and what exactly is it?*
    An electric field happens when there is an electric charge. We use vectors to
    show these electric fields for every point in space. In physics, an electric field
    is an electric force per unit charge. Take a look at what that field looks like
    for a positive point charge and a negative point charge, as shown in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.11 – Electric field sample'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.11_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.11 – Electric field sample
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, an electric field line will begin at the charge or end at the
    charge. If it begins at the charge, it is positive, while it if ends at the charge,
    it is negative, as can be seen in the preceding screenshot. There are a fewer
    number of lines for a lesser charge and more lines for a larger charge. In addition,
    the lines will be closer for a larger charge than for a smaller charge.
  prefs: []
  type: TYPE_NORMAL
- en: 'For our problem, we want to create an electric field lines plot for any number
    of charges. So let''s take a look at what that would look like in the following
    code file. Note that we''ve broken the code down to explain various sections,
    but the full file can be found in the GitHub repository:'
  prefs: []
  type: TYPE_NORMAL
- en: 'As usual, first, we''ll begin by importing the necessary libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ch16_electricFieldLines.py
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we''ll set up our *x* and *y* axes by defining some variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code snippet, we work on defining our grid and setting up the
    coordinates. Then we create the mesh grid. The `meshgrid()` function returns matrices
    of coordinates from vector coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: 'After we have set our coordinates and set our mesh grid, we can start defining
    what happens with our charges. First, we''ll need to identify how many charges
    will be plotted:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from the preceding snippet of code, after we identified the number
    of charges, we created two empty lists. Then we added coordinates to those lists
    based on the number of charges using nested `for` loops.
  prefs: []
  type: TYPE_NORMAL
- en: 'After we do the necessary math to get our coordinates and vectors, we can then
    go ahead and plot our electric field lines graph. We''ll use a `quiver` plot,
    which is a `matplotlib` graphic we can use for creating vector fields:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s important to always add labels to our graphs and plots, as this will
    make the information more readable, especially for those who do not know what
    the code behind this means or what the graphs and plots represent. When we run
    our code snippet, we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.12 – Electric field lines for eight charges'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.12_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.12 – Electric field lines for eight charges
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see in our plot, there are positive and negative charges. Take a
    look at the bottom right-hand corner charge in the graph. That charge is negative,
    as the arrows are pointing toward the charge. The *left-most* charge, which has
    been zoomed-in, shown as follows, shows a positive charge, as the arrows are pointing
    away from the charge:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.13 – Zoomed positive charge'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.13_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.13 – Zoomed positive charge
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at one final graphic, shown in the following screenshot,
    with an electric field lines plot that has three charges:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 16.14 – Electric field lines with three charges'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.14_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.14 – Electric field lines with three charges
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, this particular plot contains two positive charges and one negative
    charge. If we ran this again, we may get three positive charges, for example,
    as each time we run the algorithm, we get a new representation with random values
    for positive and negative charges.
  prefs: []
  type: TYPE_NORMAL
- en: These kinds of fields and learning how to use vectors and quiver plots can help
    us represent a lot of information. In the case of electric field lines, we can
    learn a lot about the charges, direction, and the strength of those charges with
    a simple visual plot.
  prefs: []
  type: TYPE_NORMAL
- en: Take a look at the code snippet in the GitHub repository and try changing some
    of the parameters, such as the size of the plot and the number of charges. The
    more practice you get with these plots and altering some of the parameters, the
    easier they become to create.
  prefs: []
  type: TYPE_NORMAL
- en: Problem 6 – Using Python to analyze genetic data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's shift focus to looking at a larger dataset. You're working with laboratory
    mice and get data for **trisomy mice** and protein expressions in these mice.
    We've truncated some of the data from the public domain file in Kaggle for this
    due to its huge size. We're only focusing on six protein expressions for the mice
    and again, only the trisomy (**Down syndrome**) mice in the study. The full file
    can be found in Kaggle at [https://www.kaggle.com/ruslankl/mice-protein-expression](https://www.kaggle.com/ruslankl/mice-protein-expression).
    The truncated file can be found in our GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: Let's say you don't know where to start with this data. *What should you even
    be looking at?* Well, that's often the first thing we encounter in data science.
    We don't always get to be part of the study design or data collection. Many times,
    we receive large data files and need to figure out what to look for, how to tackle
    the problem, whatever we decide the problem is, and how to display the information
    in the best possible way.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, this is your reminder to change the location of the file before you attempt
    to run this program. This very simple program can be found in the `ch16_pairplots.py`
    file. Let''s begin with the algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `seaborn` library can help us a bit just to get us started. We can create
    `pairplot()`, which will correlate the numerical data in the `.csv` file using
    histograms and scatterplots. It''s kind of like a fantastic magic trick. We can
    use two lines of code to see what we see. Take a look at the two lines that are
    needed to generate *Figure 16.7* (note that there''s actually four lines of code,
    but I''m not counting the two lines I''m using to import my libraries):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Be patient when you run this program. The algorithm may be simple, but what
    it''s doing in the background isn''t so simple. Take a look at the following screenshot
    to see our pairplot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.15 – Pairplot of protein expressions in trisomy mice with the treatment
    variable'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.15_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.15 – Pairplot of protein expressions in trisomy mice with the treatment
    variable
  prefs: []
  type: TYPE_NORMAL
- en: Notice that our data has two colors based on the treatment, which is an injection
    of memantine or saline, respectively. From the plots, we can see that some of
    the proteins seem to have a higher correlation than others. Let's pause on that
    for a second.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now say that our goal wasn''t to check on the expression based on the
    treatment, but rather the class. Then we can run the code, but first we change
    the hue to `class` in our algorithm. The result is shown as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 16.16 - Pairplot of protein expressions in trisomy mice with the class
    variable'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.16_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.16 - Pairplot of protein expressions in trisomy mice with the class
    variable
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the plots are extremely similar. Where the plots do differ, however,
    is in the identification of where each of the points lies based on another characteristic.
    For example, in the `class` variable chart, we have four colors because there
    are four classes of mice in our particular dataset.
  prefs: []
  type: TYPE_NORMAL
- en: They are, namely, **t-CS-s**, which refers to the mice stimulated to learn (shock)
    and injected with saline; **t-CS-m**, which refers to the mice stimulated to learn
    (shock) and injected with memantine; **t-SC-s**, which refers to mice not stimulated
    to learn and injected with saline; and **t-SC-m**, which refers to mice not stimulated
    to learn and injected with memantine.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at our correlations, we can see that there are strong positive correlations
    between many of the proteins, such as **NR2A_N** and **BDNF_N**. Whether or not
    that's relevant, whether it matters in our study, and whether it's not significant
    is something that we'd have to take into consideration if this were our study.
    Once we see the plots, we can then choose to explore the information further.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another type of plot that can be helpful when looking at this dataset is the
    boxplot. We can use the boxplot to see the protein expression level by class for
    a protein we want to look at more closely. Let''s take the `NR2A_N` protein. Using
    the `seaborn` boxplot, we can create a plot for this particular protein using
    the code in the `ch16_boxplot.py` file. As always, check the file location first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we identify the things we want to compare, which, in
    this case, are the protein and the class. We''ll then create the boxplot using
    our `seaborn` library, which can be seen as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.17 – Boxplot of the NR2A_N protein expression by class'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.17_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.17 – Boxplot of the NR2A_N protein expression by class
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see from the graph, the distributions for our trisomy mice vary
    by class, with the mice that were not stimulated to learn and injected with saline
    showing a wider range in the expression of this protein. Let''s try changing that
    protein to one of our others in the dataset, that is, the **ITSN1_N** protein.
    The following screenshot shows the resulting boxplot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.18 – Boxplot of the ITSN1_N protein expression by class'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.18_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.18 – Boxplot of the ITSN1_N protein expression by class
  prefs: []
  type: TYPE_NORMAL
- en: In this particular boxplot, we can identify outliers in the **t-CS-m** and **t-SC-m**
    classes, that is, both mice classes that were injected with memantine. That may
    tell us to seek more information about any relationship between the memantine
    injections and that particular protein. *If we were to look at non-trisomy mice,
    would these spreads of data (range) hold for that protein if the other elements
    were the same?* Those are some of the things we would ask ourselves in looking
    at datasets such as this one.
  prefs: []
  type: TYPE_NORMAL
- en: If you remember, the computational thinking process is rarely a straight line.
    If we identify things we want to consider in our algorithm, we don't just leave
    our algorithm alone and decide it was already done, so we won't change it. We
    go back to identify what we need again, make the necessary changes to our design,
    and create our algorithm again. That's more closely what happens when we are dealing
    with larger datasets. We look at some initial visualizations, maybe create a few
    different types of plots, run some statistical analysis, and then decide where
    to go next with the data. This is just a glimpse into what is possible with Python.
  prefs: []
  type: TYPE_NORMAL
- en: Problem 7 – Using Python to analyze stocks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Time to play with some stocks. You can access a lot of data through **Quandl**,
    which allows for the use of a free API for educational uses. There are also premium
    datasets available. We're sticking to educational purposes, so that should be
    enough for our requirements.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this problem, we''re going to learn how to pull data from Quandl and look
    at the VZ stock prices. **VZ** is the code for **Verizon** stock prices. We''re
    going to use them to predict the prices using `quandl`, which is a package for
    Python in addition to being a website full of useful information. Let''s take
    a look at how we grab the information we want. The full code, minus the API key,
    can be found in our repository under the `ch16_stockAnalysis.py` file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at how we can import the data. You''ll need your own API
    for this. If you want to check another stock, say for `AMZN`, you''d substitute
    `''EOD/VZ''` with `''WIKI/AMZ''`, for example. **AMZN** is the code for **Amazon**
    stock. But let''s take a look at our `VZ` set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'When we run the preceding code, we get the table for the first five values
    in our dataset. The following screenshot shows our table of values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.19 – EOD/VZ stock table'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.19_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.19 – EOD/VZ stock table
  prefs: []
  type: TYPE_NORMAL
- en: 'Now say we only wanted to focus on the adjusted close value in order to later
    make predictions. Then we can use the following code snippet to do so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'After running the preceding code, our adjusted table can be seen as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.20 – EOD/VZ adjusted close stock value table'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.20_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.20 – EOD/VZ adjusted close stock value table
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've learned to pull current data, we're going to now work with a
    dataset that we've placed in the GitHub repository so that we can ensure that
    you are able to replicate the results. You can then try to do this for current
    data using the Quandl API.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at the dataset with the filename `VZ.csv`. This contains the
    same data for VZ from 1983 to April 2020\. *What do we want from this dataset?*
    We want to make some predictions. So let's build that model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the code is fairly large, so the file with everything you need (minus
    the file location on *line 15*, which you''ll need to add), is in `ch16_predictionsModel.py`.
    But let''s take a look at some of the snippets of code from that file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet will create a plot for our existing data in the
    dataset. It selects the `Date` column from the file and sets that as the index
    value. Then it creates a figure and adds the labels for the graph and axes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'We''re not looking at a model yet. We haven''t defined our training data. We''re
    just looking at what happened to our stock prices from **1983** to **2020**, shown
    as follows. Note that the first tick mark label states **1984**. Our data can
    be seen to start just slightly before **1984**. The tick marks are every 4 years
    since 1980, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.21 – Closing price over time for VZ stock'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.21_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.21 – Closing price over time for VZ stock
  prefs: []
  type: TYPE_NORMAL
- en: Notice from the preceding chart that stock prices are not linear in any way.
    They rise, fall, and rise again. A predictive model will require a lot of data
    in order for us to prepare the best predictions possible. Our dataset has 9,166
    rows of data. That's going to come in handy in a second.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at another snippet of code that we''ll be using:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Notice the `750` value in the `train_data=VZ3[0:750,:]` line of code. That means
    I'm using just the first 750 rows of 9,166 possible rows of data to train my model.
    This isn't so great.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the following screenshot, which shows the results when
    we run this prediction model. Note that we did choose to copy the original information
    into our graphic. Python will point that out as a possible thing we want to fix.
    That''s up to you to do so. For now, having the original data available as overlaid
    for our graph provides us with a great visual for comparison purposes as regards
    our model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.22 – Closing price predictions'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.22_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.22 – Closing price predictions
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in the preceding graphic, shown in orange here, we have the original,
    copied values. The green shows the predictions made by our model. They're not
    terrible, but they're not as tight as they could be.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see what happens when we use 7,500 rows of data instead, which is roughly
    82% of the data available. As a note, the file in the GitHub repository uses the
    value of 7,500, but feel free to change and adjust those so you can test the accuracy
    of your model. The following graph shows our results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 16.23 – Prediction model using 7,500 rows of data'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.23_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.23 – Prediction model using 7,500 rows of data
  prefs: []
  type: TYPE_NORMAL
- en: Notice how much closer the real lines and the prediction lines are in this model.
    That's because the more data we have to train our model with, the better our predictions
    will become.
  prefs: []
  type: TYPE_NORMAL
- en: Before we move on from this example, note that we did not cover the entirety
    of the code file here. Some of the code has been discussed in other areas of this
    book, so we focused on the parts of the algorithm that were new and critical to
    the algorithm solution due to the complexity of the algorithm. The final piece
    of that code file does use a **Long Short-Term Memory (LSTM)** model. An LSTM
    model is a type of artificial recurrent neural network. We use this model in machine
    learning to create deep learning models.
  prefs: []
  type: TYPE_NORMAL
- en: '*Will our models actually predict the price of the stock?* No. Otherwise, we''d
    all have an easier time with the market. But models can get really good at predicting
    not the price, but whether or not the price will go up or down.'
  prefs: []
  type: TYPE_NORMAL
- en: Problem 8 – Using Python to create a convolutional neural network (CNN)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we're going to take a look at a problem that uses **artificial
    intelligence** (**AI**). More specifically, we're going to work on creating a
    **convolutional neural network**, or **CNN**. *So what is a CNN?* A CNN is a **Deep
    Learning algorithm**. CNNs take images as input. The image is then processed and
    given importance based on predetermined conditions that will help us differentiate
    and classify the images.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the process involved in the convolutional
    neural network:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.24 – Convolutional neural network process'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.24_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.24 – Convolutional neural network process
  prefs: []
  type: TYPE_NORMAL
- en: The CNN is created in order to simplify how we categorize the images without
    sacrificing accuracy in terms of the predictions we want to be able to get from
    our image analyses. It's like if we were applying a filter. Once we apply the
    filter, we can see the characteristics. The preceding diagram shows a simplified
    schematic for this process.
  prefs: []
  type: TYPE_NORMAL
- en: The problem we're going to be diving into is handwriting training and analysis.
    Thinking about the computational thinking process, what we're really trying to
    do is analyze handwriting as accurately as possible. To do so, we analyze hundreds
    or thousands of images to create and train our model. The more images we use,
    the more accurate our model will be.
  prefs: []
  type: TYPE_NORMAL
- en: For our model, we're going to use a dataset that contains 70,000 images. The
    first 60,000 images are used for training, while we'll use the other 10,000 for
    testing. The full code can be found in the `ch16_CNN_mnist.py` file. We'll take
    a look at some of the snippets from that code and also use some adjustments to
    show additional components. You can run the file in the GitHub repository without
    making changes as long as you have all the necessary libraries and packages installed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start designing the model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s first take a look at a snippet of code that will upload the dataset,
    and then show the first item in the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'We used the index `0` in the training set to see that first image. The `cmap`
    property will make the colormap gray. You can adapt that and adjust it, as needed.
    As a side note, for those who have trouble seeing color or have particular color
    needs, changing the colormap can make a significant difference to how the images
    are perceived. Let''s take a look at that first image in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.25 – First image in the MNIST training set'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.25_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.25 – First image in the MNIST training set
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see from the preceding screenshot, this is a handwriting sample,
    most likely of the number **5**. We can run the program a few more times with
    different indexes to see some other samples in our dataset. The following screenshot
    shows some of those samples and their corresponding indexes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.26 – Sample images in the dataset by index'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.26_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.26 – Sample images in the dataset by index
  prefs: []
  type: TYPE_NORMAL
- en: The data we are using is not quantitative, it is qualitative. We are looking
    at images, so we are in need of a process that can analyze those images. To do
    so, we use **One-Hot encoding**, which replaces integer encoded variables with
    new binary variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we''ve looked at what we''re working with, let''s reshape and encode
    our model using the following code snippet. As a reminder, the full code can be
    found in the repository, but some of the components will be slightly different
    (such as our file will not be testing the images in the dataset):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we are dividing the images into training and test sets. Then
    we encode them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have performed one-hot encoding, we can create our model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code snippet, we used a `softmax` function. The `softmax` function
    is sometimes referred to as a normalized exponential function. We use it to normalize
    the output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s train the model. We''re going to first fit the model and then validate
    the data. Take a look at this code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: So here's one of the great things about training and testing. That is, when
    we understand and practice with them, we realize it takes just a few lines of
    code to do some pretty amazing things. The preceding two lines of code (the third
    is a comment) will make some great things happen and allow our algorithm to test
    other images.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can predict the images in the dataset. We''ll start with the last four,
    because everyone starts with the same four numbers, so I want to start backward
    this time. As a note, be patient. There are thousands of images to get through
    in this algorithm. While the epochs are running, you''ll have a clock that will
    tell you how long until the information is processed. For this particular algorithm,
    it takes just a few minutes. Let''s take a look at the snippet of code we''ll
    need in order to run that prediction:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'When we run this code, we get a pretty intense array of numbers. Take a look
    at the following screenshot. We have highlighted a key piece of the code for discussion:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.27 – Model predictions for the CNN image'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.27_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.27 – Model predictions for the CNN image
  prefs: []
  type: TYPE_NORMAL
- en: So, I can tell you that the first number predicted is 3\. *How would we know
    that the number represents 3?* Because each list represents the digits 0 to 9\.
    So imagine replacing the first list with [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]. So if
    we think of this as indexes, the number with the **01** (which is highlighted
    in the preceding screenshot) at the end of the number is in index 3, which is
    the number 3\. So our numbers are 3, 4, 5, and 6\.
  prefs: []
  type: TYPE_NORMAL
- en: '*But do you trust the model?* We can just go ahead and return to that snippet
    of code at the beginning of this discussion and print our results. Remember to
    change the code slightly to print your test images, and not the training images,
    as shown in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'When running the code, remember you will need to run it for each of the indexes
    to see the images. The following screenshot shows the images for each of the relevant
    indexes of the test images:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.28 – Testing data verification images'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_16.28_B15413.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 16.28 – Testing data verification images
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, our model predicted the correct values for each of the handwritten
    number images in those indexes.
  prefs: []
  type: TYPE_NORMAL
- en: Before we close this discussion, it would be important to note that these models
    are used fairly extensively right now in websites to verify whether a visitor
    to the site is human or a bot. Some websites will have a **CAPTCHA**, which sometimes
    provides handwritten letters that the user must identify to be allowed to proceed.
    Those CAPTCHAs often use deep learning as well. The applications of CNNs and these
    kinds of models are endless.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we were able to explore more topics in computational thinking,
    especially in dealing with data and deep learning, using the Python programming
    language. We learned how to create pairplots in order to determine the relationship
    between variables in a dataset. We also learned how to produce various types of
    plots to visually represent our datasets. We also learned how to create electric
    field lines using Python. In short, we applied what we'd learned throughout the
    previous chapters and extended our knowledge while working in applied problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'And that''s really what this book sought to do: Show a wide variety of Python
    applications while looking at real problems in context. *Did we cover everything
    Python can do?* That''s fairly impossible, as Python capabilities continue to
    grow because of its ease of use, how easy it is to learn, and how many applications
    continue to be added because of its open source nature. Hopefully, you got to
    work with some new scripts, learned about some of the functions and capabilities
    you still hadn''t explored, and enjoyed exploring these scenarios.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Will we ever be able to say that we''ve created the perfect algorithm?* We,
    the authors of this book, don''t think so. And the reason is that we are always
    thinking about ways to improve. We always question additional applications. We
    always want to make them more efficient. And that''s really what computational
    thinking helps us do. We can analyze, design, test, go back, and see whether we
    did what we wanted, and then refine, redesign, perform tests, and repeat.'
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, after this chapter, you've had a chance to practice and learn about
    more of Python's capabilities. And hopefully, having read this book, you've had
    the opportunity to learn about the importance of computational thinking in programming.
    Thank you for joining us on this journey!
  prefs: []
  type: TYPE_NORMAL
