- en: Understanding Concurrency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Iterators and generators are essential to Go. Utilizing channels and goroutines
    for parallelism and concurrency is idiomatic in Go and is one of the best ways
    to write high-performance, readable code in the language. We are going to first
    talk about some of the basic Go constructs in order to be able to understand how
    to use iterators and generators in the context of Go, followed by deep dives into
    the constructs of the available iterators and generators of the language.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Closures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goroutines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Channels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semaphores
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: WaitGroups
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Iterators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Being able to understand the basic constructs of the Go language and when and
    where to use the proper iterators and generators is essential to writing performant
    Go.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding closures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most important parts of Go is that it is a language that supports
    first-class functions. First-class functions are functions that have the ability
    to be passed to other functions as variables. They can also be returned from other
    functions. This is important to note because we can use them as closures.
  prefs: []
  type: TYPE_NORMAL
- en: Closures are helpful because they are a great way to keep your code DRY as well
    as helping to isolate your data. Keeping datasets small has been a core tenet
    of this book thus far, and that doesn't change in this chapter (nor any subsequent
    chapter). Being able to isolate the data that you wish to manipulate can help
    you to continue to write performant code.
  prefs: []
  type: TYPE_NORMAL
- en: Closures keep a local scope and have access to the outer function's scope and
    parameters, as well as global variables. Closures are functions that reference
    variables outside of their body. These functions have the ability to assign values
    to the referenced variables and access those values, so in turn, we can pass closures
    between functions.
  prefs: []
  type: TYPE_NORMAL
- en: Anonymous functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first step to understanding closures in Go is to understand anonymous functions.
    An anonymous function is created using a variable for the inception of the function.
    They are also functions that don't have a name or identifier, hence the name *anonymous
    functions*.
  prefs: []
  type: TYPE_NORMAL
- en: 'A normal function invocation to print `Hello Go` to the screen would be what
    is shown in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Next, we could call `HelloGo()` and the function would print a `Hello Go` string.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we wanted to instantiate our `HelloGo()` function as an anonymous function,
    we would invoke this as referenced in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Our preceding anonymous function and the `HelloGo()` function are lexically
    similar.
  prefs: []
  type: TYPE_NORMAL
- en: 'We could also store a function as a variable for use later on, as referenced
    in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: All three of these things – the `HelloGo()` function, our anonymous function,
    and the function assigned to the `hello` variable – are lexically similar.
  prefs: []
  type: TYPE_NORMAL
- en: After we've assigned this `hello` variable, we could then call this function
    using a simple invocation of `hello()`, where our preceding defined anonymous
    function would be called and `Hello Go` would be printed to the screen in the
    same fashion that it was printed in our previously called anonymous function.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see how each of these work in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The output from this program shows three print statements, all similar, with
    small differences in print to show how they were returned in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/695a6215-85af-475b-bfc3-4e9110d09d89.png)'
  prefs: []
  type: TYPE_IMG
- en: Anonymous functions are a powerful aspect of Go. As we continue this chapter,
    we'll see how we can build on them to make some very useful things.
  prefs: []
  type: TYPE_NORMAL
- en: Anonymous functions with respect to closures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You may be wondering at this point why it''s prudent to have anonymous functions
    and how they pertain to closures. Once we have our anonymous function, we can
    then utilize a closure in order to reference variables that are declared outside
    of its own definition. We can see this in the code block that follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'When we execute this code, we receive the following resulting output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/14480e66-3518-4501-8e4d-0c64fd8e8580.png)'
  prefs: []
  type: TYPE_IMG
- en: In this code sample, we can see how closures can help with data isolation. The
    `n1` variable is initialized with the `incrementCounter()` function. This anonymous
    function sets `initializedNumber` to `0` and returns an integer that is an incremented
    count of the `initializedNumber` variable.
  prefs: []
  type: TYPE_NORMAL
- en: When we create the `n2` variable, the same process occurs again. A new `incrementCounter`
    anonymous function is called and a new `initializedNumber` variable is returned.
    In our main function, we can note that `n1` and `n2` have separate maintained
    state. We can see that even after the `n1()` function call is invoked for the
    third time. Being able to persist this data between function calls while also
    isolating the data from another call is a powerful part of having anonymous functions.
  prefs: []
  type: TYPE_NORMAL
- en: Closures for nesting and deferring work
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Closures are also often a good way to nest and defer work. In the following
    example, we can see a function closure that allows us to nest work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we can see that we append to the string slice twice and sort
    the result. We will later see how we can nest an anonymous function in a goroutine
    to help improve performance.
  prefs: []
  type: TYPE_NORMAL
- en: HTTP handlers with closures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Closures are also commonly used as middleware in Go HTTP calls. You can wrap
    normal HTTP function calls around a closure in order to add additional information
    to your calls when you need to and reuse middleware for different functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, we''ll set up an HTTP server with four separate routes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`/`: This serves the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An HTTP response with an HTTP 418 status code (derived from the `newStatusCode`
    middleware).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A `Foo:Bar` header (derived from the `addHeader` middleware).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A `Hello PerfGo!` response (derived from the `writeResponse` middleware).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/onlyHeader`: Serves an HTTP response with only the `Foo:Bar` header added.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/onlyStatus`:  Serves an HTTP response with only the status code changed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/admin`: Checks for the presence of a user: `admin` header. If present, it
    prints the admin portal information alongside all the normal pertaining values.
    If not present, it returns an unauthorized response.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These examples have been used because they are easy to grok. Using closures
    for Go in HTTP handlers is also convenient because they can do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Isolate database information from DB calls
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform authorization requests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wrap other functions with isolated data (timing information, for example)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Communicate with other third-party services transparently with acceptable timeouts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Go *Writing Web Applications* document, located at [[https://golang.org/doc/articles/wiki/](https://golang.org/doc/articles/wiki/)],
    gives a bunch of other prime examples of setting up templating, being able to
    live-edit pages, validating user input, and more. Let''s take a look at our example
    code that shows us closures within a HTTP handler in the following code blocks.
    First, we initialize our packages and create an `adminCheck` function, which helps
    us to determine whether or not a user is authorized to use the system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We next set up some other examples, such as serving an HTTP 418 (the `I''m
    a teapot` status code) and adding a `foo:bar` HTTP header and setting a particular
    HTTP response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we wrap it all together with an HTTP handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Our router test examples follow. Here''s the output with a header modification
    and HTTP status code modification:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ec5a3321-759f-4aaf-933e-166db601b2de.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here''s the output with just the header modification:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7398f36f-3215-4d2b-ac6c-e0f32eb1263a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here''s the output with just the status modification:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f47bb2df-dcbc-4450-8e3c-896d5a51f873.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here''s the unauthorized admin output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dab62428-96a3-4228-a69f-713bb72aabb5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here''s the authorized admin output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/36ab738b-e5f3-4a2e-a8d3-f205fac95b2b.png)'
  prefs: []
  type: TYPE_IMG
- en: Being able to add middleware with anonymous functions can help to rapidly iterate
    while keeping code complexity low.  In the next section, we'll explore goroutines.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring goroutines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Go is a language designed with concurrency in mind. Concurrency is the ability
    to execute independent processes. Goroutines are a construct in Go that can help
    with concurrency. They are often referred to as *lightweight threads*—for good
    reason. In other languages, threads are handled by the OS. This, in turn, uses
    a larger-sized call stack and usually handles less concurrency with a given memory
    stack size. Goroutines are functions or methods that run within the Go runtime
    concurrently and don't connect to the underlying OS. The scheduler within the
    Go language manages goroutines' life cycles. The system's scheduler has a lot
    of overhead as well, so limiting the number of threads being utilized can help
    to improve performance.
  prefs: []
  type: TYPE_NORMAL
- en: The Go scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a couple of different pieces involved in the management of goroutine
    life cycles by the Go runtime scheduler. The Go scheduler was changed in its second
    iteration, which was derived from a design document written by Dmitry Vyukov,
    released in Go 1.1\. In this design doc, Vyukov discusses the initial Go scheduler
    and how to implement a work-sharing and work-stealing scheduler, as originally
    prescribed by Dr Robert D. Blumofe and Dr. Charles E. Leiserson in an MIT paper
    entitled, *Scheduling Multithreaded Computations by Work Stealing*. The fundamental
    concept behind this paper is to ensure dynamic, multithreaded computation in order
    to ensure that processors are utilized efficiently while maintaining memory requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Goroutines only have a stack size of 2 KB on inception. This is one of the reasons
    why goroutines are preferred for a lot of concurrent programming—because it is
    much easier to have tens or hundreds of thousands of goroutines in one program.
    Threads in other languages can take up megabytes of space, making them a lot less
    flexible. If more memory is needed, Go's functions have the ability to allocate
    more memory in another place in available memory space to help the goroutine space
    grow. By default, the runtime gives the new stack twice the amount of memory.
  prefs: []
  type: TYPE_NORMAL
- en: Goroutines block a running thread only on system calls. When this occurs, the
    runtime takes another thread from the scheduler struct. These are used for other
    goroutines that are waiting to be executed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Work sharing is a process in which a scheduler migrates new threads to other
    processors for work distribution. Work stealing performs a similar action, but
    in which the underutilized processors steal threads from other processors. Following
    the work-stealing pattern in Go has helped to make the Go scheduler much more
    efficient and, in turn, gives higher throughput to the goroutines that run on
    top of the kernel''s scheduler.  Lastly, Go''s scheduler implements spinning threads. 
    Spinning threads will utilize extra CPU cycles over preempting a thread. Threads
    spin in three different ways:'
  prefs: []
  type: TYPE_NORMAL
- en: When a thread is not attached to a processor.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When making a goroutine ready will unblock an OS thread onto an idle processor.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When a thread is running but no goroutines are attached to it.  This idle thread
    will continue to search for runnable goroutines to execute.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Go scheduler goroutine internals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Go scheduler has three key structures that handle the workload of goroutines:
    the M struct, the P struct, and the G struct.  These three structs work together
    in order to process goroutines in a performant fashion.  Let''s take a look at
    each of these in more depth. If you''d like to take a look at the source code
    for these, it''s available at [https://github.com/golang/go/blob/master/src/runtime/runtime2.go/](https://github.com/golang/go/blob/master/src/runtime/runtime2.go/).'
  prefs: []
  type: TYPE_NORMAL
- en: The M struct
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The M struct is labeled **M** for **machine**. The M struct is a representation
    of an OS thread. It contains a pointer that points to the runnable goroutine global
    queue (defined by the P struct). M retrieves its work from the P struct. M contains
    the free and waiting goroutines that are ready to be executed. Some notable M
    struct parameters are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A goroutine that contains a scheduling stack (go)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Thread local storage** (**tls**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A P struct for executing Go code (p)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The P struct
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This struct is labeled **P** for **processor**. The P struct represents a logical
    processor. This is set by `GOMAXPROCS` (which should be equivalent to the number
    of cores available after Go version 1.5). P maintains a queue of all of the goroutines
    (defined by the G struct). When you invoke a new goroutine using the Go executor,
    this new goroutine gets inserted into P''s queue. If P doesn''t have an associated
    M struct, it will allocate a new M. Some notable P struct parameters are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The P struct ID (id)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A back link to an associated M struct if applicable (m)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A pool of available defer structs (deferpool)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The queue of runnable goroutines (runq)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A struct of available Gs (gFree)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The G struct
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This struct is labeled **G** for **goroutine**. The G struct represents the
    stack parameters of a single goroutine. It includes information on a couple of
    different parameters that are important for a goroutine. G structs get created
    for every new goroutine, as well as goroutines for the runtime. Some notable G
    struct parameters are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The current value of the stack pointers (`stack.lo` and `stack.hi`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The current value of the Go and C stack growth prologues (`stackguard0` and
    `stackguard1`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The current value of the M struct (m)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goroutines in action
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have a basic understanding of the underlying principles of goroutines,
    we can check them out in action. In the following code block, we will see how to invoke
    a goroutine using the `go` call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: During the execution of this function, we only get a partial return of the `printSleep()`
    function wrapped in the goroutine call (printing `HELLO GOPHERS`) before the main
    sleep timer is complete. Why did this happen? If the `main()` goroutine completes,
    it is closed, the program is terminated, and leftover goroutines will not run.
    We were able to get the first nine characters returned because those goroutines
    completed before the main function finished executing. If we change our `const
    t` duration to `14`, we will receive the entire `HELLO GOPHERS` string.  The reason
    behind this is that the `main` function does not get completed before all of the
    goroutines that spawned around `go printSleep()` are executed.  Goroutines are
    powerful only if used correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Another Go built-in that helps with managing concurrent goroutines is Go channels,
    which is the topic we will cover in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing channels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Channels are mechanisms that allow the sending and receiving of values. Channels
    are often used alongside goroutines in order to deliver transfer objects concurrently
    across goroutines. There are two main classifications of channels in Go: unbuffered
    channels and buffered channels.'
  prefs: []
  type: TYPE_NORMAL
- en: Channel internals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Channels are invoked using the `make()` Golang built-in, where an `hchan` struct
    is created. The `hchan` struct contains a count of the data in the queue, the
    size of the queue, an array pointer for the buffer, send and receive indices and
    waiters, and a mutex lock. The following code block illustrates this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This code block is referenced from [https://golang.org/src/runtime/chan.go#L32](https://golang.org/src/runtime/chan.go#L32).
  prefs: []
  type: TYPE_NORMAL
- en: Buffered channels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Buffered channels are channels that have a bounded size. They are typically
    more performant than their unbounded counterparts. They are useful for retrieving
    values from an explicit number of goroutines that you''ve launched. Because they
    are **FIFO** (**first in first out**) queueing mechanisms, they can effectively
    be used as a fixed-size queueing mechanism, and we can process requests in the
    order in which they came in. Channels are created before they are used by invoking
    the `make()` function. Once a buffered channel is created, it is ready and available
    for use. Buffered channels don''t block on incoming writes if there is still room
    in the channel. It''s important to remember that data flows in the direction of
    the arrow within a channel. In our example (the following code block), we perform
    the following actions:'
  prefs: []
  type: TYPE_NORMAL
- en: Write `foo` and `bar` to our `buffered_channel`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check the length of the channel—the length is `2` because we've added two strings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pop `foo` and `bar` off the channel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check the length of the channel—the length is `0` because we've removed both
    strings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add `baz` to our channel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pop `baz` off the channel onto a variable, `out`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Print the resulting `out` variable, which is `baz` (the last element we added
    to the channel)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Close our buffered channel, indicating no more data is to pass across this channel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s have a look at the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This code can be found at [https://github.com/bobstrecansky/HighPerformanceWithGo/blob/master/3-iterators-and-generators/channels/buffered_channel.go](https://github.com/bobstrecansky/HighPerformanceWithGo/blob/master/3-iterators-and-generators/channels/buffered_channel.go).
  prefs: []
  type: TYPE_NORMAL
- en: As we can see in our code block example, we are able to push data to the stack
    and pop data from the stack. It's also important to note that the `len()` built-in
    returns the number of elements that are unread (or queued) within the channel
    buffer. Alongside the `len()` built-in, we can also use the `cap()` built-in to
    deduce the total capacity of the buffer. These two built-ins used in conjunction
    can often be used to know the current state of your channel, especially if it's
    not acting the way you expect it to. It is also good to get in the habit of closing
    channels. When you close a channel, you are letting the Go scheduler know that
    there are no more values that will be sent across that channel. It's also important
    to note that if you attempt to write to a closed channel or a channel that has
    no room left in the queue, your program will panic.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following program panics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll get the error message shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ac43436f-bb84-4120-aa93-6a018f3680f9.png)'
  prefs: []
  type: TYPE_IMG
- en: This is because we attempted to pass data (the `foo` string) to a channel (`ch`)
    that was already closed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following program also panics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll see the following error message:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/388c2dbf-21f0-44a4-bddf-9380ae00be8c.png)'
  prefs: []
  type: TYPE_IMG
- en: The program panics because the goroutine will block and wait. This error is
    then detected by the runtime and the program exits.
  prefs: []
  type: TYPE_NORMAL
- en: Ranges over channels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You may want to know all the values present in your buffered channel. We have
    the ability to do this by invoking a `range` built-in over the channel we''d like
    to check.  Our example in the following code block adds three elements to the
    channel, closes the channel, and then writes all the elements from the channel
    using `fmt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting output shows us all of the values that live in our buffered channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7b342089-1d86-44b5-8cdb-7291667a2a50.png)'
  prefs: []
  type: TYPE_IMG
- en: A reminder—make sure you close the channel.  If we remove the preceding `close(bufferedChannel)`
    function, we will get a deadlock.
  prefs: []
  type: TYPE_NORMAL
- en: Unbuffered channels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unbuffered channels are the default channel configuration in Go. Unbuffered
    channels are flexible because they don't need to have a finite channel size definition.
    They are often best used when the receiver of the data from the channel is slower
    than the sender of the channel of the data. They also block on both read and write,
    as they are synchronous. The sender will block the channel until the receiver
    has received the value. They are often used in conjunction with goroutines to
    ensure that items are processed in the order that they are expected to be processed
    in.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our following example code blocks, we perform the following actions:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a Boolean channel to maintain state
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create an unsorted slice
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sort our slice with the `sortInts()` function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Respond true to our channel so that we can move onto the next part of the function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Search our slice for a given integer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Respond true to our channel so that our transaction occurring over the channel
    is completed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Return the channel value so that our Go function is completed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'First, we import our packages and create a function that sorts integers across
    a channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create a `searchInts` function that searches integers across a channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we tie them all together in our `main` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see our output from this program in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dc8e3fa2-936a-4a43-b2d7-06a7d2dcc4a7.png)'
  prefs: []
  type: TYPE_IMG
- en: This is a great way to use channels to perform actions concurrently.
  prefs: []
  type: TYPE_NORMAL
- en: Selects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Selects are a construct that allow you to combine goroutines and channels in
    a meaningful way. We can multiplex Go functions in order to be able to execute
    a case that occurs when the goroutine is run.  In our example, we create three
    separate channels: a `string` channel, a `bool` channel, and a `rune` channel.
    We next run some anonymous functions in the following code blocks in order to
    populate data in those channels, and use the select built-in to return values
    from the channels.'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we initialize our package and set up three separate channels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We next pass appropriate variables to each of our channels via anonymous functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we pass these through with our `select` statement:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting output from this program can be seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1a2b978b-932d-440d-acc9-76e6d3cef53d.png)'
  prefs: []
  type: TYPE_IMG
- en: You'll notice that the `rune` anonymous function gets returned last here. This
    is due to the sleep that was inserted into that anonymous function. The `select`
    statements will return values that are passed into the channel randomly if multiples
    are ready, and sequentially when the goroutine results are ready.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will learn what semaphores are.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing semaphores
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Semaphores are another method for controlling how goroutines execute parallel
    tasks. Semaphores are convenient because they give us the ability to use a worker
    pool pattern, but we don't need to shut down workers after the work has been completed
    and the workers are idle. The idea of having a weighted semaphore in the Go language
    is relatively new; the sync package implementation of semaphores was implemented
    in early 2017, so it is one of the newest parallel task constructs.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we take the example of a simple loop in the following code block, add 100
    ms of latency to a request, and add an item to an array, we can quickly see that
    the amount of time it takes increases as these tasks are operating in a series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We can create a weighted semaphore implementation with the same constructs.
    We can see that in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we initialize our program and set up our semaphore variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we run through our semaphore code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The difference in execution time between these two functions is quite noticeable
    and can be seen in the following outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b4ce5faa-d65a-4c48-ba59-d0c393bd7725.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The semaphore implementation ran more than twice as fast which is shown in
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/beebc1ba-0328-44b1-8992-00ddff52a5c9.png)'
  prefs: []
  type: TYPE_IMG
- en: The semaphore implementation ran more than twice as fast. This is with only
    five 100 ms blocking sleeps.  Being able to process things in parallel becomes
    more and more important as your scale continues to grow.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will discuss WaitGroups.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding WaitGroups
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: WaitGroups are commonly used in order to validate the fact that multiple goroutines
    have completed.  We do this in order to make sure we have completed all of the
    concurrent work that we expect to complete.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the example in the following code block, we make requests to four websites
    with a `WaitGroup`.  This `WaitGroup` will wait until all of our requests have
    been completed, and will only finish the `main` function after all of the `WaitGroup` values
    have been returned:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we initialize our packages and set up our retrieval function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'In our `main` function, we next use our retrieval function within a goroutine
    using WaitGroups:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from the following output, we receive all the measurements for
    the web requests, their response code, and their respective timings:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c1cffc7b-dea6-45b7-a6b8-033b614b03e3.png)'
  prefs: []
  type: TYPE_IMG
- en: Very often, we expect all our goroutines to finish. WaitGroups can help us with
    this.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we'll discuss the process of iteration.
  prefs: []
  type: TYPE_NORMAL
- en: Iterators and the process of iteration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Iteration is the method of looking through a group of data, usually a list,
    in order to retrieve information from said list. Go has a bunch of different iterator
    patterns, all with benefits and drawbacks:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Iterator** | **Benefit** | **Drawback** |'
  prefs: []
  type: TYPE_TB
- en: '| `for` loop | Simplest implementation | No default concurrency. |'
  prefs: []
  type: TYPE_TB
- en: '| Iterator function with a callback | Simple implementation | Unconventional
    styling for Go; difficult to read. |'
  prefs: []
  type: TYPE_TB
- en: '| Channels | Simple implementation | More expensive computationally than some
    other iterators (with a marginal cost difference). The only iterator that is naturally
    concurrent. |'
  prefs: []
  type: TYPE_TB
- en: '| Stateful iterators | Difficult implementation | A nice caller interface.
    Useful for complex iterators (commonly used in the standard library). |'
  prefs: []
  type: TYPE_TB
- en: It's important to benchmark all of these against one another in order to validate
    assumptions about how long each one takes. In the following tests, we take sums
    of `0` to `n` and run benchmarks against them.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code block has a simple `for` loop iterator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code block has a callback iterator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code blocks will show the  `Next()` incantation. Let''s look
    at it step by step:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we initialize our package variables and structs.  Next, we create a
    `CounterIterator`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'This is followed by a `Next()` function, a `Value()` function, and a `NextLoop()`
    function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The next code block has a buffered channel implementation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The next code block has an unbuffered channel implementation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: After we compile these all together, we can make a test benchmark. This benchmark
    can be found in the following code blocks. Let's look at it step by step again.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, we initialize our package and set up a simple and callback loop benchmark:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This is followed by a next and buffered channel benchmark:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we set up the unbuffered channel benchmark and create loop functions
    for each of the benchmarks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The result of the benchmark can be found in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/853c9c7a-85e3-436c-b9cf-ac131f448b3c.png)'
  prefs: []
  type: TYPE_IMG
- en: The context of these iterator tests is very important. Because we are doing
    simple addition in these tests, a simple construct for iterating is key. If we
    were to add in latency within each call, the concurrent channel iterators would
    perform much better. Concurrency is a powerful thing, especially in the right
    context.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we'll discuss generators.
  prefs: []
  type: TYPE_NORMAL
- en: Briefing on generators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A generator is a routine that returns the next sequential value within a loop
    construct. Generators are commonly used to implement iterators and bring in parallelism.
    Goroutines are utilized in Go in order to implement generators. To implement parallelism
    in Go, we can use generators that run in parallel with consumers to produce values.
    They are typically utilized within a looping construct. Generators can also be
    parallelized themselves. This is typically done when it's expensive to generate
    an output and the output can be generated in any order.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned about many of the basic constructs that are
    used for iterators and generators in Go. Understanding anonymous functions and
    closures helped us to build foundational knowledge about how these functions work. 
    We then learned how goroutines and channels work, and how to implement them fruitfully.
    We also learned about semaphores and WaitGroups, as well as how they play into
    the language. Understanding these skills will help us to parse through information
    in our computer programs in a more effective manner, allowing for more concurrent
    data manipulation. In [Chapter 4](ce982065-5176-4ca4-9346-8bae29d1ccee.xhtml),
    *STL Algorithm Equivalents in Go*, we'll learn about practical implementations
    of the **Standard Templating Library** (**STL**) in Go.
  prefs: []
  type: TYPE_NORMAL
