- en: Boosting a Web Server's Performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amongst the main points that Google had identified as being the first order
    of business of its Faster Web initiative was to update the aging web protocols.
    Many projects around the world were already underway as the new focus of web development
    was shifting from offering more and more features to users, even if these were
    slow, to offering features that were not incompatible with web performance. Google's
    initiative helped to change web development priorities and, thus, allowed existing
    projects to come to light and new projects to be created.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover a few projects that went along with Google''s
    new initiative for the web. Thus, we will cover the following points:'
  prefs: []
  type: TYPE_NORMAL
- en: MOD_SPDY and HTTP/2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PHP-FPM and OPCache
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ESI and Varnish Cache
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Client-side caching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other Faster Web tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MOD_SPDY and HTTP/2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In 2009, Google announced it would start to find ways to update the HTTP protocol
    by making use of a new session protocol named SPDY (`SPeeDY`). This new session
    protocol worked over an underlying TLS presentation layer and allowed for many
    HTTP speed optimizations at the application layer. Using SPDY was as easy as activating
    SSL, installing the `mod_spdy` module on your web server and activating it. No
    modifications to the websites were needed in order to benefit from its features.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, all major browsers were supporting it. SPDY rapidly became a core
    element of the Faster Web and became, in November 2012, the basis of the next
    major revision of the HTTP protocol. Then, in 2015, it was deprecated in favor
    of the new HTTP/2 protocol. The most important optimizations that were introduced
    by SPDY and that would find their way into the new HTTP protocol's specifications
    were multiplexed and prioritized streams, server pushing and header compression.
    Let's have a look at each one of these optimizations in more detail before we
    get into some of the specifics of the HTTP/2 protocol.
  prefs: []
  type: TYPE_NORMAL
- en: Multiplexed and prioritized streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'SPDY''s multiplexed streams feature allowed for mapping multiple requests to
    multiple streams on a single connection. These streams were bidirectional and
    could be initiated by either the client or the server (the server push feature).
    Opening multiple streams over one single connection made it possible to avoid
    the overhead of establishing a new connection on each client/server exchange,
    especially when downloading multiple resources in parallel to complete the rendering
    of a single page. Thus, this first feature made it possible to get rid of the
    limited number of possible connections when using the HTTP/1 protocol:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/4607e136-5765-4972-8a01-6e09b4e07bb2.png)How multiplexed and prioritized
    streams work'
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, SPDY's streams were prioritized. This additional feature allowed the
    client to determine which resources should be sent over the wire first. Thus,
    SPDY avoided the **first-in, first-out **(**FIFO**) issue that arose when trying
    to do server pipelining (that is, the `KeepAlive` directive) within the HTTP/1
    protocol.
  prefs: []
  type: TYPE_NORMAL
- en: Server pushing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As already mentioned, SPDY''s new stream features made it possible for the
    server to push data to the client without responding to a client''s request. This
    made communication bidirectional and allowed the web server to anticipate the
    needs of the client. Indeed, even before the client had done parsing the HTML
    and determined all the files that would be necessary in order to render the page,
    the web server could push the files down the stream to the client, thus reducing
    the number of requests sent by the client in order to fetch all the necessary
    resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/a80f24cc-3844-42b5-aaba-961cbf9953c2.jpg)How the ''server push''
    feature works'
  prefs: []
  type: TYPE_NORMAL
- en: By knowing that many studies show that, on average, most pages need from 70
    to 100 requests against 20 to 30 domains in order to complete their rendering,
    we can easily see how this feature can make the web less verbose and reduce network
    latency in a significant way.
  prefs: []
  type: TYPE_NORMAL
- en: Header compression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: SPDY's third important feature was header compression with `gzip`. By compressing
    the often high number of HTTP headers and reducing them by as much as 85% of their
    original sizes on average, SPDY could cut up to a full second off the load time
    of most HTTP transactions over the wire. Although the use of `gzip` to dynamically
    compress the headers was revealed to be unsafe, the idea of header compression
    remained and was re-implemented in the HTTP/2 protocol due to its great benefits
    to overall web performance.
  prefs: []
  type: TYPE_NORMAL
- en: HTTP/2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Published in May 2015 as RFC 7540 [1], HTTP/2 is the latest major revision of
    the HTTP protocol. It is mostly based on Google's SPDY protocol and offers a new
    binary framing layer that is not backward-compatible with HTTP/1\. As mentioned
    previously, most of its features were developed through the SPDY project. The
    most notable difference between SPDY and HTTP/2 was the way that the new protocol
    compressed its headers. Whereas SPDY relied on dynamically compressing headers
    with `gzip`, the HTTP/2 protocol used a new method named `HPACK`, which made use
    of a fixed Huffman code-based algorithm. This new method was needed in order to
    avoid a problem that was found with SPDY, by which data compression led to the
    possible leakage of private data.
  prefs: []
  type: TYPE_NORMAL
- en: Even though the new protocol reduced the loading time of most web pages by as
    much as two times, many critics voiced their disappointment by pointing out that
    the unrealistic deadlines imposed by Google on the project of updating the HTTP
    protocol made it impossible to base the new version of the protocol on anything
    else but its SPDY project and, thus, causing many missed occasions for further
    improvement of the new HTTP protocol. *Poul-Henning Kamp*, developer of *Varnish
    Cache*, even went on to say that HTTP/2 was inconsistent and that it was overly
    and needlessly complex. Moreover, he stated that it had violated the principle
    of protocol layering by duplicating flow control that should normally take place
    at the transport layer [2]. Finally, many security flaws were found in this new
    protocol, the most notable ones being those unveiled by the cybersecurity firm
    Imperva at the Black Hat USA 2016 conference [3]. These were the slow read attack,
    the dependency cycle attack, the stream multiplexing abuse and the HPACK Bomb.
    Essentially, all these attack vectors could be used to bring a server offline
    by submitting it to a **Denial of Service** (**DoS**) attack or by saturating
    its memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite all of this and the many issues related to encryption, all major web
    servers and browsers have adopted it and now offer support for it. Most of the
    time, if your web server was configured and compiled with the HTTP/2 flag, you
    only need to activate the module in the server’s `/etc/httpd/httpd.conf` file
    to start using it. In the case of the Apache Web server, you must also add the
    `Protocols` directive to the server''s configuration files. Please be aware that
    activating the HTTP/2 protocol on your server will have a considerable impact
    on resource consumption. For example, enabling such a feature on the Apache web
    server will result in the creation of many threads, as the server will serve HTTP/2
    requests by creating dedicated workers in order to process and stream the results
    back to the clients. Here is an example of how you can enable the HTTP/2 module
    in Apache''s `httpd.conf` and `httpd-ssl.conf` configuration files (presuming
    that the `mod_ssl` module has been enabled also):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'For more information on the HTTP/2 protocol, please visit the following address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://developers.google.com/web/fundamentals/performance/http2/](https://developers.google.com/web/fundamentals/performance/http2/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To learn more on Apache''s implementation of the same protocol, please visit
    these links:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://httpd.apache.org/docs/2.4/howto/http2.html](https://httpd.apache.org/docs/2.4/howto/http2.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://httpd.apache.org/docs/2.4/mod/mod_http2.html](https://httpd.apache.org/docs/2.4/mod/mod_http2.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And, finally, to know more about the implementation provided by NGINX, please
    consult their documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://nginx.org/en/docs/http/ngx_http_v2_module.html](http://nginx.org/en/docs/http/ngx_http_v2_module.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PHP-FPM and OPCache
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When talking about the Faster Web, it is certainly important to consider how
    to make sure that the PHP binary itself is being run in an optimized way on web
    servers, considering that PHP is installed on seventy to eighty percent of servers
    around the world.
  prefs: []
  type: TYPE_NORMAL
- en: PHP-FPM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since PHP 5.3, PHP now includes a FastCGI process manager that allows you to
    run much more secure, much faster and more reliable PHP code on web servers. Before
    PHP-FPM, the default way to run PHP code on a web server was usually through the
    `mod_php` module. What makes PHP-FPM so interesting is the possibility for it
    to adapt itself to the number of incoming requests and spawn new processes in
    a pool of workers in order to scale to the growing demand. Moreover, running PHP
    this way allows for better script termination, more graceful server restarts,
    more advanced error reporting and server logging, and fine-grained tuning of the
    PHP environment for each and every PHP pool of workers through the daemonization
    of the PHP binary.
  prefs: []
  type: TYPE_NORMAL
- en: It has been reported by many high-traffic websites that they have seen speed
    performance hikes of the order of 300% when changing from `mod_php` to `PHP-FPM`
    on their production servers. Of course, as Ilia Alshanetsky mentioned in one of
    his presentations[4], when serving static content, many other servers, like lighttpd,
    thttpd, Tux or Boa, can be as much as 400% faster than Apache. But, when it comes
    to dynamic content, no servers can be faster than Apache or NGINX, especially
    when they work in combination with PHP-FPM.
  prefs: []
  type: TYPE_NORMAL
- en: Enabling PHP-FPM on a server is as easy as configuring PHP with the `--enable-fpm`
    switch at compile time. From there, it is a question of determining how to run
    PHP-FPM, depending of performance and security issues. For example, if you are
    in a production environment, you might decide to run PHP-FPM with many pools of
    workers on many servers in order to distribute the workload. Moreover, you might
    prefer running PHP-FPM through a UNIX socket on the server rather than on the
    network loopback (`127.0.0.1`) for performance and security reasons. Indeed, a
    UNIX socket is always faster in any scenario and will offer better security against
    a local network attacker, that could always try to compromise the loopback with
    a socket listener using domain autorizations, by enforcing appropriate access
    controls to ensure connection confidentiality.
  prefs: []
  type: TYPE_NORMAL
- en: Zend OPcache
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since PHP 5.5, opcode caching is now available in PHP's core functionality when
    adding the `--enable-opcache` switch to the configure script at compile time.
  prefs: []
  type: TYPE_NORMAL
- en: Generally speaking, Zend OPcache will make any script from 8% to 80% faster.
    The more time a script's wall time is caused by the PHP binary, the more OPcache
    will make a difference. But, if the script's PHP code is very basic or if PHP
    is slowed down by latency due to I/O, such as a stream to a file or a connection
    to a database, OPcache will only slightly enhance script performance.
  prefs: []
  type: TYPE_NORMAL
- en: In all cases, Zend OPcache will optimize PHP script performance and should be
    enabled on all production servers by default.
  prefs: []
  type: TYPE_NORMAL
- en: Let's have a look at how we could configure the PHP-FPM server included with
    the Linux for the PHP container that is running PHP 7.1.16 (NTS) to use a UNIX
    socket, instead of the network loopback, to establish a connection between Apache
    and PHP. Moreover, let's configure PHP-FPM to use Zend OPcache.
  prefs: []
  type: TYPE_NORMAL
- en: 'Please make sure your container is still running and enter the following commands
    on its CLI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'You can now have a look at the modified `php.ini` file with the *vi* editor
    in order to make sure that the previous settings are no longer commented out and
    that the new `[OPcache]` section has been added to the file. Then, in your favorite
    browser, you should now see the following screen when visiting `http://localhost:8181/phpinfo.php`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/4d7f8662-abf5-403b-8bfa-21105a6039a1.png)Confirmation that Zend
    Opcache is enabled and running'
  prefs: []
  type: TYPE_NORMAL
- en: If you do see the previous screen, you have successfully connected the *Apache*
    server to PHP-FPM through a UNIX socket and enabled *Zend OPcache*.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you wish to test compiling PHP from scratch with the FPM and *OPCache* configuration
    switches within a *Linux for PHP* base image (`asclinux/linuxforphp-8.1:src`),
    please enter the following command in a new Terminal window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: If you wish to accomplish the same thing manually, please visit the *Linux for
    PHP* website for further instructions ([https://linuxforphp.net/cookbook/production](https://linuxforphp.net/cookbook/production)).
  prefs: []
  type: TYPE_NORMAL
- en: ESI and Varnish Cache
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another Faster Web technology is that of the **Edge Side Includes** (**ESI**)
    markup language and HTTP cache servers.
  prefs: []
  type: TYPE_NORMAL
- en: Edge Side Includes (ESI)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Originally formalized as a specification to be approved by the **World Wide
    Web Consortium** (**W3C**) back in 2001, ESI was thought to be a way of stepping
    up to the challenge of web infrastructure scaling by applying edge computing to
    it. Edge computing is a method of optimizing cloud computing by doing data processing
    near the source of the data instead of centralizing all data processing in the
    datacenter. In the case of ESI, the idea was to decentralize web page content
    to the logical extremes of the network in order to avoid having all content requests
    being sent to the web server every time.
  prefs: []
  type: TYPE_NORMAL
- en: The specification called for new HTML tags that would allow HTTP cache servers
    to determine if certain parts of a page needed to be fetched from the original
    web server or if cached versions of those parts could be sent back to the client
    without having to query the server for it. It is possible to think of ESI as a
    sort of HTML include feature that is used to assemble a web page's dynamic content
    from different external sources.
  prefs: []
  type: TYPE_NORMAL
- en: Many HTTP cache servers started using the new markup tags. Some **Content Delivery
    Networks** (**CDN**), such as Akamai, and many HTTP Proxy Servers, such as Varnish,
    Squid and Mongrel ESI, started implementing the specification over the years,
    although most did not implement the entire specification. Also, some of these
    servers, such as Akamai, added additional features that were not in the original
    specification.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, important PHP frameworks, such as *Symfony*, started adding ESI functionality
    within their core configurations, thus allowing the PHP developer to immediately
    start thinking of ESI when developing an application.
  prefs: []
  type: TYPE_NORMAL
- en: Also, browsers started encouraging ESI usage by keeping a local cache of all
    files that were fetched on the web and reusing them when a different website requested
    the same file, for example. Thus, using a CDN-hosted JavaScript file on your website
    brought the advantage of reducing the number of client requests to one's web server
    just to get that same file over and over again.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is very easy to start using `esi:include` tags within your HTML in order
    to cache parts of your web pages. For example, you could use it in this way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Another example would be to use PHP and the *Symfony* framework to automatically
    generate the ESI include tags. This is easily accomplished by having *Symfony*
    trust the *Varnish Cache* server, enabling ESI in your YAML configuration file,
    setting the shared maximum age limit of the web page within its controller's method
    and adding the needed rendering helper methods within the corresponding templates.
    Let's go through these steps one at a time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by having *Symfony* trust the *Varnish Cache* server. In the most recent
    version of *Symfony*, you must add a call to the static `setTrustedProxies()`
    method of the `Request` class. In the `public/index.php` file of your *Symfony*
    installation, add the following lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Depending on the version of *Symfony* and the version of *Varnish* that you
    are using, you might have different steps to follow in order to do so. Please
    consult the following page of the *Symfony* documentation in order to complete
    this first step: [https://symfony.com/doc/current/http_cache/varnish.html](https://symfony.com/doc/current/http_cache/varnish.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, add the following lines to your *Symfony* configuration file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Once done, modify a couple of controllers like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'And, the second one should be modified as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, perform the following modifications within your Twig template:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: You should now be able to see the effects of ESI when loading the pages of your
    *Symfony* application.
  prefs: []
  type: TYPE_NORMAL
- en: In order to get a better grasp of the inner workings of ESI, let's try installing
    and running an HTTP reverse proxy server that partially implements the ESI specification.
  prefs: []
  type: TYPE_NORMAL
- en: Varnish Cache
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the HTTP Reverse Proxy Servers that partially implements ESI is *Varnish
    Cache*. This HTTP Cache Server was originally thought out by its creators, *Poul-Henning
    Kamp*, *Anders Berg* and *Dag-Erling Smørgrav*, as being a highly needed [5] replacement
    for *Squid*, a well-known HTTP forward proxy server (client proxy). It was possible
    to make *Squid* work as a Reverse Proxy (server proxy), but it was very difficult
    to set it up to act in this way.
  prefs: []
  type: TYPE_NORMAL
- en: The original meeting that led to the creation of *Varnish Cache* took place
    in Oslo in February of 2006\. The basic concept behind the project was to find
    a way to quickly manipulate bytes that would be taken from passing network traffic
    and a way to determine what, where and when to cache those bytes. Many years later,
    *Varnish Cache* has become one of the most important HTTP cache servers on the
    web with almost three million websites using it in production [6].
  prefs: []
  type: TYPE_NORMAL
- en: In order to better understand how *Varnish Cache* works, let's take the time
    to install it inside a Linux for the PHP base container.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a new Terminal window, please enter this Docker command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, enter these commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'You should now see the following messages on the CLI:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/b7dd6cc4-a249-4d3e-aa18-52ff033a7293.png)Confirmation that the requested
    Python modules have been installed'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, enter these commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Once done, you should see a screen similar to this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/93630a61-7072-4df1-865e-0fd84744a58c.png)The download of the archive
    containing the source code of Varnish Cache is completed'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, please finish the installation by unpacking, configuring and installing
    *Varnish Cache* with the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Once completed, you should receive the following message:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/3a80a169-63f6-4e67-80d5-b349edbecf52.png)The Varnish Cache daemon
    is now running and waiting for connections'
  prefs: []
  type: TYPE_NORMAL
- en: 'As we mentioned in [Chapter 2](70f061eb-c289-43a1-9945-af4d22d48463.xhtml),
    *Continuous Profiling and Monitoring*, of this book when we were installing the
    *TICK* stack through *Docker* containers, you can get the IP addresses of the
    two containers (the one running the *Apache* server and this new one that is running
    the *Varnish* server), by issuing this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you get the results, you can replace the [IP_ADDRESS_OR_DOMAIN_NAME_OF_WEB_SERVER]
    placeholder in the previous command with the IP address of the container running
    *Apache* (the *Linux for PHP* container). In my case, the IP address of the *Apache*
    Web server is `172.17.0.2` and the IP address of the *Varnish Cache* server is
    `172.17.0.3`. The command would therefore be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Once started, you can point a browser to the IP address of the *Varnish Cache*
    server and you should get the *Apache* Web server''s content. In my case, when
    pointing my browser to `172.17.0.3`, I obtain the expected result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/6b5f3e6e-eddb-4ccd-b8b4-6ad94f1877cd.png)Varnish is caching and
    returning the response obtained from the Apache server'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can confirm that the *Varnish Cache* server is using our *Apache* Web server
    as its backend by issuing the following `curl` command in a new Terminal window
    and piping the results to `grep` in order to see the request and response headers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The result should be similar to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/7049f671-29b2-466a-86bc-ec3ee7bc900b.png)The Varnish Cache headers
    are added to the Apache headers'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the headers show that the *Apache* server is responding via the
    *Varnish Cache* server.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, with proper DNS configuration, it would become possible to redirect all
    the web traffic to the *Varnish Cache* server and use the web server as its backend
    only.
  prefs: []
  type: TYPE_NORMAL
- en: This example shows us how easy it is to configure a *Varnish Cache* server and
    how simple it is to start using it and benefiting from it right away in order
    to quickly boost web server performance.
  prefs: []
  type: TYPE_NORMAL
- en: Client-side caching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s continue with another Faster Web technology, which is client-side caching.
    This form of HTTP caching focuses on reducing the number of requests needed to
    render a page in order to avoid network latency as much as possible. Indeed, large
    responses often need many roundtrips over the network. HTTP client-side caching
    tries to minimize the number of these requests in order to complete the page''s
    rendering. Nowadays, all major browsers offer support for these techniques and
    enabling these technologies on your website is as easy as sending a few additional
    headers or using library files that are already available on **Content Delivery
    Networks** (**CDNs**). Let''s have a look at these two techniques: browser caching
    headers and CDNs.'
  prefs: []
  type: TYPE_NORMAL
- en: Browser caching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Browser caching is based on the idea that it is not necessary to fetch all the
    files included in a response if some of these are exactly the same over a certain
    period of time. The way it works is through headers that are sent by the server
    to the browser in order to instruct it to avoid getting certain pages or files
    within a certain timeframe. Thus, the browser will display content kept within
    its cache rather than fetching the resources over the network within the span
    of that certain period of time, or until the resource changes.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, browser caching relies on cache-control evaluation (expiration model)
    and response validation (validation model). Cache-control evaluation is defined
    as a set of directives that inform the browser of who can cache the response,
    under what circumstances and for how long. Response validation relies on a hash
    token in order to determine if the content of a response has changed or not. It
    also makes it possible for the browser to avoid fetching the results again even
    if cache-control indicates that the cached content has expired. In fact, upon
    receiving the response from the server indicating that the content has not been
    modified, based on the fact that the sent token has not changed on the server,
    the browser simply renews the cache-control and resets the time delay before expiration.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is accomplished through the use of certain response headers. These are
    **Cache-Control** and **ETag** headers. Here is an example of these received headers
    within a response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/046b2eaf-8ccf-42c0-baf5-ee1c70ff042c.png)How browser caching works'
  prefs: []
  type: TYPE_NORMAL
- en: In this example, Cache-Control indicates a **max-age** of **120** seconds and
    sets an **ETag** with value **"e4563ff"**. With these two headers, the browser
    will be able to manage its cache adequately. Thus, enabling browser caching is
    as easy as adding those response headers to the responses returned by the web
    server. In the case of *Apache*, it is a simple question of making sure that the
    FileETag directive was added to the server's configuration file.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is also possible to set the Cache-Control and Expires headers directly using
    the *Symfony* framework in PHP. Specifically, *Symfony*''s response object allows
    you to set all Cache-Control headers using its `setCache()` method. Here is an
    example when using this method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Having seen how easy and simple it is to start using browser HTTP caching, let's
    take the time to see how HTTP caching has other benefits to offer when combined
    with a technology such as HTTP Reverse Proxy server technology.
  prefs: []
  type: TYPE_NORMAL
- en: Content Delivery Networks (CDNs)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Content Delivery Networks are distributed networks of proxy servers that allow
    for high-availability and high-performance distribution of common or popular web
    resources. These resources can be web objects such as text, images and scripts,
    including CSS and JavaScript libraries, downloadable objects, such as files and
    software, and live-streaming or on-demand streaming media. CDNs can therefore
    be used as a sort of internet common cache. Indeed, by using a CDN to host all
    of your library files, you are combining browser HTTP caching with HTTP Reverse
    Proxy caching. This means that if another website or web application is using
    the same library files as you, your user's browser will either use its cached
    versions of the libraries or submit a request to refresh the files to a CDN and
    not your web server. This not only reduces network latency by reducing the number
    of requests needed globally to render the same content, but also takes away a
    part of the workload from your web server by delegating the responsibility of
    refreshing expired browser caches to the CDN's Reverse Proxy cache.
  prefs: []
  type: TYPE_NORMAL
- en: 'This Faster Web solution is very easy to implement. It is often as simple as
    redirecting web traffic to the CDN by modifying your DNS configuration. For example,
    *Cloudflare* ([https://www.cloudflare.com/](https://www.cloudflare.com/)) does
    not require any changes to your web server configuration in order to start using
    its HTTP reverse proxy cache. Once you have registered the original domain name
    and IP address of your web server in the *Cloudflare* interface, you only have
    to modify your DNS settings by having the domain name point to the *Cloudflare*
    servers in order to start using it immediately. Let''s use cURL to query the [https://linuxforphp.net/](https://linuxforphp.net/)
    site, which uses *Cloudflare*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Querying the website should yield the following result, which confirms that
    it is now only accessible through *Cloudflare*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/8c27ad15-75a7-45e9-8e00-64bd6dc6841b.png)Confirmation that the linuxforphp.net
    website is available through Cloudflare'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, *Cloudflare* is indeed enabled and has added Cache-Control and
    Expires to the response headers.
  prefs: []
  type: TYPE_NORMAL
- en: Other Faster Web tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many other Faster Web tools exist that can help you optimize the performance
    of your web applications and websites. Amongst these many tools are those suggested
    by Google on their Faster Web site for developers ([https://developers.google.com/speed/](https://developers.google.com/speed/)).
    One tool that will help you further analyze the performance issues of web applications
    is *PageSpeed Insights*.
  prefs: []
  type: TYPE_NORMAL
- en: This tool quickly identifies any possible performance optimizations for your
    web application, based on the URL you submit. To further analyze the effects of
    using *Cloudflare* for the *Linux for PHP* website, let's submit the URL to the
    *PageSpeed Insights* tool.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the initial results before using *Cloudflare*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/cf0b7345-24ff-490c-b506-dd8b55efa9ac.png)Results of the performance
    analysis of the linuxforphp.net website when NOT using Cloudflare'
  prefs: []
  type: TYPE_NORMAL
- en: 'And, here are the results after adding the *Cloudflare* reverse proxy server:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/72ee142a-8bdc-4159-ab87-096d6923b2f6.png)Results of the performance
    analysis of the linuxforphp.net website when using Cloudflare'
  prefs: []
  type: TYPE_NORMAL
- en: Not only can we see that the general performance of the website is much better,
    but *PageSpeed Insights* also gives suggestions as to how we can further optimize
    the web application.
  prefs: []
  type: TYPE_NORMAL
- en: 'The initial recommendations of this tool, before the switch to *Cloudflare,*
    were as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/3f28ac91-6386-4a0a-afd0-eb25ccbdc22f.png)Suggestions to optimize
    the performance of the linuxforphp.net website when NOT using Cloudflare'
  prefs: []
  type: TYPE_NORMAL
- en: 'And, then, after the switch to *Cloudflare*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/9ac2f43b-8738-4889-ba86-82d0f3d9262e.png)Suggestions to optimize
    the performance of the linuxforphp.net website when using Cloudflare'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the list of optimization suggestions is much shorter, but if
    we were to leverage browser caching for certain specific image files that can
    be found on the site, eliminate some render-blocking JavaScript and CSS, reduce
    image sizes and try to reduce server response time in general, we would most certainly
    get a perfect score!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have covered a few projects that went along with *Google*'s
    new initiative of a Faster Web. We have seen what the HTTP/2 protocol is all about
    and how the SPDY project made it possible, how PHP-FPM and Zend OPCache can help
    you boost the performance of your PHP scripts, how to use ESI technology by setting
    up a Varnish Cache server, how to use client-side caching, and how other Faster
    Web tools can help you out when trying to optimize your web server's performance.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will see how, when everything seems to have been fully
    optimized, we can still go beyond performance.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] [https://tools.ietf.org/html/rfc7540](https://tools.ietf.org/html/rfc7540)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] [https://queue.acm.org/detail.cfm?id=2716278](https://queue.acm.org/detail.cfm?id=2716278)'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] [https://www.imperva.com/docs/Imperva_HII_HTTP2.pdf](https://www.imperva.com/docs/Imperva_HII_HTTP2.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] [https://ilia.ws/files/zend_performance.pdf](https://ilia.ws/files/zend_performance.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[5][ https://varnish-cache.org/docs/trunk/phk/firstdesign.html](https://varnish-cache.org/docs/trunk/phk/firstdesign.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '[6][ https://trends.builtwith.com/web-server](https://trends.builtwith.com/web-server),
    March 2018.'
  prefs: []
  type: TYPE_NORMAL
