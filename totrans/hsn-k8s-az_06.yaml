- en: 4\. Building scalable applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When running an application, the ability to scale and upgrade your application
    is critical. **Scaling** is required to handle additional loads with your application,
    while upgrading is required to keep your application up to date and to be able
    to introduce new functionality.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling on demand is one of the key benefits of using cloud-native applications.
    It also helps optimize resources for your application. If the front-end component
    encounters heavy loads, you can scale the front end alone, while keeping the same
    number of back-end instances. You can increase or reduce the number/size of **Virtual
    Machines** (**VM**) required depending on your workload and peak demand hours.
    This chapter will cover both the scale dimensions in detail.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will show you how to scale the sample guestbook application
    that we introduced in *Chapter 3,* *Application deployment on AKS*. We will first
    scale this application using manual commands, and afterward we'll autoscale it
    using the **Horizontal Pod Autoscaler (HPA)**. The goal is to make you comfortable
    with `kubectl`, which is an important tool for managing applications running on
    top of the **Azure Kubernetes** **Service** (**AKS**). After scaling the application
    itself, we will also scale the cluster. We'll first scale the cluster manually,
    and then use the cluster autoscaler to automatically scale the cluster. In addition,
    in this chapter, you will get a brief introduction to how you can upgrade applications
    running on top of AKS.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Scaling your application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling your cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Upgrading your application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will start this chapter by discussing the different dimensions when it comes
    to scaling applications on top of AKS.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In the previous chapter, we cloned the example files in Cloud Shell. If you
    didn''t do this back then, we recommend doing that now:'
  prefs: []
  type: TYPE_NORMAL
- en: '`git clone` [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Azure---Second-Edition/tree/SecondEdition](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Azure---Second-Edition/tree/SecondEdition)'
  prefs: []
  type: TYPE_NORMAL
- en: 'For this chapter, navigate to the `Chapter04` directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '`cd Chapter04`'
  prefs: []
  type: TYPE_NORMAL
- en: Scaling your application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are two scale dimensions for applications running on top of AKS. The first
    scale dimension is the number of Pods a deployment has, while the second scale
    dimension in AKS is the number of nodes in the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: By adding additional Pods to a deployment, also known as scaling out, you add
    additional compute power to the deployed application. You can either scale out
    your applications manually or have Kubernetes take care of this automatically
    via the HPA. The HPA will watch metrics such as CPU to determine whether Pods
    need to be added to your deployment.
  prefs: []
  type: TYPE_NORMAL
- en: The second scale dimension in AKS is the number of nodes in the cluster. The
    number of nodes in a cluster defines how much CPU and memory are available for
    all the applications running on that cluster. You can scale your cluster either
    manually by changing the number of nodes, or you can use the cluster autoscaler
    to automatically scale out your cluster. The cluster autoscaler will watch the
    cluster for Pods that cannot be scheduled due to resource constraints. If Pods
    cannot be scheduled, it will add nodes to the cluster to ensure that your applications
    can run.
  prefs: []
  type: TYPE_NORMAL
- en: Both scale dimensions will be covered in this chapter. In this section, you
    will learn how you can scale your application. First, you will scale your application
    manually, and then later, you will scale your application automatically.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing scaling of your application
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To demonstrate manual scaling, let''s use the guestbook example that we used
    in the previous chapter. Follow these steps to learn how to implement manual scaling:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install the guestbook by running the `kubectl create` command in the Azure
    command line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: After you have entered the preceding command, you should see something similar,
    as shown in *Figure 4.1*, in your command-line output:![When you execute the command,
    your command-line output will list the services and deployments are created.](image/Figure_4.1.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 4.1: Launching the guestbook application'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Right now, none of the services are publicly accessible. We can verify this
    by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 4.2* shows that none of the services have an external IP:![The output
    screen will display the External-IP column as <none>. This indicates that none
    of the services have a public IP.](image/Figure_4.2.jpg)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 4.2: Output displaying none of the services having a public IP'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'To test out our application, we will expose it publicly. For this, we will
    introduce a new command that will allow you to edit the service in Kubernetes
    without having to change the file on your file system. To start the edit, execute
    the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This will open a `vi` environment. Navigate to the line that now says `type:`
    `ClusterIP` (line 27) and change that to `type: LoadBalancer`, as shown in *Figure
    4.3*. To make that change, hit the *I* button, type your changes, hit the *Esc*
    button, type `:wq!`, and then hit *Enter* to save the changes:![Output displays
    that line 27 is replaced by Type: LoadBalancer.](image/Figure_4.3.jpg)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 4.3: Changing this line to type: LoadBalancer'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Once the changes are saved, you can watch the service object until the public
    IP becomes available. To do this, type the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: It will take a couple of minutes to show you the updated IP. Once you see the
    correct public IP, you can exit the `watch` command by hitting *Ctrl* + *C* (*command
    + C* on Mac):![Using the kubectl get svc -w command, the external-ip of the frontend
    Service will change from <pending> to an actual external IP address.](image/Figure_4.4.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 4.4: Output showing the front-end service getting a public IP'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Type the IP address from the preceding output into your browser navigation
    bar as follows: `http://<EXTERNAL-IP>/`. The result of this is shown in *Figure
    4.5*:![Enter the External-IP obtained from the preceding command to your browser
    navigation bar. A white screen withthe word Guestbook in bold is displayed.](image/Figure_4.5.jpg)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 4.5: Browse to the guestbook application'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The familiar guestbook sample should be visible. This shows that you have successfully
    publicly accessed the guestbook.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have the guestbook application deployed, you can start scaling
    the different components of the application.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling the guestbook front-end component
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Kubernetes gives us the ability to scale each component of an application dynamically.
    In this section, we will show you how to scale the front end of the guestbook
    application. This will cause Kubernetes to add additional Pods to the deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'You can set the number of replicas you want, and Kubernetes takes care of the
    rest. You can even scale it down to zero (one of the tricks used to reload the
    configuration when the application doesn''t support the dynamic reload of configuration).
    To verify that the overall scaling worked correctly, you can use the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This should give you an output as shown in *Figure 4.6*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Upon executing the kubectl get pods command, you will see sixPods are now
    running for the frontend.](image/Figure_4.6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.6: Different Pods running in the guestbook application after scaling
    out'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'As you can see, the front-end service scaled to six Pods. Kubernetes also spread
    these Pods across multiple nodes in the cluster. You can see the nodes that this
    is running on with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate an output as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Executing the kubectl get pods -o wide command displays the nodes on which
    the Pods are running.](image/Figure_4.7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.7: Showing which nodes the Pods are running on'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In this section, you have seen how easy it is to scale Pods with Kubernetes.
    This capability provides a very powerful tool for you to not only dynamically
    adjust your application components, but also provide resilient applications with
    failover capabilities enabled by running multiple instances of components at the
    same time. However, you won't always want to manually scale your application.
    In the next section, you will learn how you can automatically scale your application.
  prefs: []
  type: TYPE_NORMAL
- en: Using the HPA
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Scaling manually is useful when you're working on your cluster. In most cases,
    however, you will want some sort of autoscaling to happen on your application.
    In Kubernetes, you can configure autoscaling of your deployment using an object
    called the **Horizontal Pod Autoscaler** (**HPA**).
  prefs: []
  type: TYPE_NORMAL
- en: The HPA monitors Kubernetes metrics at regular intervals and, based on rules
    you define, autoscales your deployment. For example, you can configure the HPA
    to add additional Pods to your deployment once the CPU utilization of your application
    is above 50%.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, you will configure the HPA to scale the front end of the application
    automatically:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To start the configuration, let''s first manually scale down our deployment
    to 1 instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Next up, we''ll create an HPA. Open up the code editor in Cloud Shell by typing
    `code hpa.yaml` and enter the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s investigate what is configured in this file:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Line 2:** Here, we define that we need `HorizontalPodAutoscaler`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines 6-9**: These lines define the deployment that we want to autoscale.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines 10-11**: Here, we configure the minimum and maximum Pods in our deployment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines 12-16**: Here, we define the metric that Kubernetes will be monitoring,
    in order to do the scaling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Save this file, and create the HPA using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This will create our autoscaler. You can see your autoscaler with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This will initially output something as shown in *Figure 4.8*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Executing kubectl get hpa shows the horizontal pod autoscaler that was created.
    The target shows as <unknown>, indicating the hpa isn''t fully ready yet.](image/Figure_4.8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.8: The target unknown shows that the HPA isn''t ready yet'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'It takes a couple of seconds for the HPA to read the metrics. Wait for the
    return from the HPA to look something similar to the output shown in *Figure 4.9*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Executing kubectl get hpa --watch shows the value of targets change from
    <unknown> to an actual value of 10% in this screenshot.](image/Figure_4.9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.9: Once the target shows a percentage, the HPA is ready'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We''ll now go ahead and do two things: first, we will watch our Pods to see
    whether new Pods are created. Then, we will create a new shell, and create some
    load for our system. Let''s start with the first task – watching our Pods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This will continuously monitor the Pods that get created or terminated.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now create some load in a new shell. In Cloud Shell, hit the button
    to open a new shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Click the icon on the toolbar that has a plus sign on its edge. This button
    opens a new Cloud Shell.](image/Figure_4.10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.10: Use this button to open a new Cloud Shell'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This will open a new tab in your browser with a new session in Cloud Shell.
    We will generate some load for our application from this tab.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will use a program called `hey` to generate this load. `hey` is a
    tiny program that sends loads to a web application. We can install and run `hey`
    using the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The `hey` program will now try to create up to 20 million connections to our
    front end. This will generate CPU loads on our system, which will trigger the
    HPA to start scaling our deployment. It will take a couple of minutes for this
    to trigger a scale action, but at a certain point, you should see multiple Pods
    being created to handle the additional load as shown in *Figure 4.11*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Executing kubectl get pods -w will show new pods of the frontend being created.
    You will see new pods change their status fromPending to ContainerCreating to
    Running.](image/Figure_4.11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.11: New Pods get started by the HPA'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: At this point, you can go ahead and kill the `hey` program by hitting *Ctrl*
    + *C* (*command* + *C* on Mac).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s have a closer look at what our HPA did by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see a few interesting points in the `describe` operation, as shown in
    *Figure 4.12*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Executing the kubectl describe hpa command will generate a detailed view
    of the HPA. You will see the resource load, a message saying TooManyReplicas,
    and the HPA will scale from 1 to 4, to 8, to 10.](image/Figure_4.12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.12: Detailed view of the HPA'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The annotations in *Figure 4.12* are explained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: This shows you the current CPU utilization (132%) versus the desired
    (25%). The current CPU utilization will likely be different in your situation.'
  prefs: []
  type: TYPE_NORMAL
- en: '**2**: This shows you that the current desired replica count is higher than
    the actual maximum we had configured. This ensures that a single deployment doesn''t
    consume all resources in the cluster.'
  prefs: []
  type: TYPE_NORMAL
- en: '**3**: This shows you the scaling actions that the HPA took. It first scaled
    to 4, then to 8, and then to 10 Pods in the deployment.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you wait for a couple of minutes, the HPA should start to scale down. You
    can track this scale-down operation using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This will track the HPA and show you the gradual scaling down of the deployment,
    as displayed in *Figure 4.13*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![When you execute the kubectl get hpa -w command, you will see that the number
    of replicas gradually goes down.](image/Figure_4.13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.13: Watching the HPA scale down'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Before we move on to the next section, let''s clean up the resources we created
    in this section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: In this section, we first manually and then automatically scaled our application.
    However, the cluster resources were static; we ran this on a two-node cluster.
    In many cases, you might also run out of resources on the cluster itself. In the
    next section, we will deal with that issue, and explain how you can scale your
    AKS cluster yourself.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling your cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, we dealt with scaling the application running on top
    of a cluster. In this section, we'll explain how you can scale the actual cluster
    you are running. We will first discuss how you can manually scale your cluster.
    We'll start with scaling down our cluster to one node. Then, we'll configure the
    cluster autoscaler. The cluster autoscaler will monitor our cluster and will scale
    out when there are Pods that cannot be scheduled on our cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Manually scaling your cluster
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can manually scale your AKS cluster by setting a static number of nodes
    for the cluster. The scaling of your cluster can be done either via the Azure
    portal or via the command line.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we'll show you how you can manually scale your cluster by scaling
    the cluster down to one node. This will cause Azure to remove one of the nodes
    from your cluster. First, the workload on the node that is about to be removed
    will be rescheduled onto the other node. Once the workload is safely rescheduled,
    the node will be removed from your cluster, and then the VM will be deleted from
    Azure.
  prefs: []
  type: TYPE_NORMAL
- en: 'To scale your cluster, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the Azure portal and go to your cluster. Once there, go to **Node pools**
    and click on the number below **Node count**, as shown in *Figure 4.14*:![Upon
    opening your cluster on the Azure portal, go to the Node pools tab in the navigation
    pane located on the leftside of the screen. Click on the tab. You will see the
    details of the node. Click on the number 2 onthe Node count tab to change the
    number of nodes.](image/Figure_4.14.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 4.14: Manually scaling the cluster'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This will open a pop-up that will give the option to scale your cluster. For
    our example, we will scale down our cluster to one node, as shown in *Figure 4.15*:![When
    you click on the Node count tab, a pop-up window will appear that will give you
    a choice to scale your cluster. Scale it down to one node.](image/Figure_4.15.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 4.15: Pop-up confirming the new cluster size'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Hit the **Apply** button at the bottom of the screen to save these settings.
    This will cause Azure to remove a node from your cluster. This process will take
    about 5 minutes to complete. You can follow the progress by clicking on the notification
    icon at the top of the Azure portal as follows:![The process of scaling down of
    nodes takes some time. To see the progress, click on the bell icon in the toolbar
    to open the notifications.](image/Figure_4.16.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 4.16: Cluster scaling can be followed using the notifications in the
    Azure portal'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Once this scale-down operation has completed, we will relaunch our guestbook
    application on this small cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we will scale out the guestbook so that it can no longer
    run on our small cluster. We will then configure the cluster autoscaler to scale
    out our cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling your cluster using the cluster autoscaler
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will explore the cluster autoscaler. The cluster autoscaler
    will monitor the deployments in your cluster and scale your cluster to meet your
    application requirements. The cluster autoscaler watches the number of Pods in
    your cluster that cannot be scheduled due to insufficient resources. We will first
    force our deployment to have Pods that cannot be scheduled, and then we will configure
    the cluster autoscaler to automatically scale our cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'To force our cluster to be out of resources, we will—manually—scale up the
    `redis-slave` deployment. To do this, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'You can verify that this command was successful by looking at the Pods in our
    cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This should show you something similar to an output generated in *Figure 4.17*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Executing kubectl get pods will show four pods in thePending state. This
    means they cannot be scheduled on a node.](image/Figure_4.17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.17: Four out of five Pods are pending, meaning they cannot be scheduled'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see, we now have four Pods in a `Pending` state. The `Pending` state
    in Kubernetes means that that Pod cannot be scheduled onto a node. In our case,
    this is due to the cluster being out of resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now configure the cluster autoscaler to automatically scale our cluster.
    As in the manual scaling in the previous section, there are two ways you can configure
    the cluster autoscaler. You can configure it either via the Azure portal—similar
    to how we did the manual scaling—or you can configure it using the **command-line
    interface (CLI)**. In this example, we will use the CLI to enable the cluster
    autoscaler. The following command will configure the cluster autoscaler for our
    cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This command configures the cluster autoscaler on the nodepool we have in our
    cluster. It configures it to have a minimum of one node and a maximum of three
    nodes. This will take a couple of minutes to configure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the cluster autoscaler is configured, you can see it in action by using
    the following command to watch the number of nodes in your cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'It will take about 5 minutes for the new node to show up and become `Ready`
    in the cluster. Once the new node is `Ready`, you can stop watching the nodes
    by hitting *Ctrl* + *C* (*command* + *C* on Mac). You should see an output similar
    to the one in *Figure 4.18*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The kubectl get nodes -w command shows the new node being added to the cluster
    and the status changing from NotReady to Ready.](image/Figure_4.18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.18: The new node joins the cluster'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The new node should ensure that our cluster has sufficient resources to schedule
    the scaled-out `redis-slave` deployment. To verify this, run the following command
    to check the status of the Pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This should show you all the Pods in a `Running` state as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Executing the kubectl get pods command displays the status of all the Pods
    as Running.](image/Figure_4.19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.19: All Pods are now in a Running state'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We will now clean up the resources we created, disable the cluster autoscaler,
    and ensure that our cluster has two nodes for the next examples. To do this, use
    the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The last command from the previous example will show you an error if the cluster
    already has two nodes. You can safely ignore this error.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we first manually scaled down our cluster, and then we used
    the cluster autoscaler to scale out our cluster. We first used the Azure portal
    to scale out the cluster manually, and then we also used the Azure CLI to configure
    the cluster autoscaler. In the next section, we will look into how we can upgrade
    applications running on AKS.
  prefs: []
  type: TYPE_NORMAL
- en: Upgrading your application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using deployments in Kubernetes makes upgrading an application a straightforward
    operation. As with any upgrade, you should have good failbacks in case something
    goes wrong. Most of the issues you will run into will happen during upgrades.
    Cloud-native applications are supposed to make dealing with this relatively easy,
    which is possible if you have a very strong development team that embraces DevOps
    principles.
  prefs: []
  type: TYPE_NORMAL
- en: The State of DevOps report ([https://services.google.com/fh/files/misc/state-of-devops-2019.pdf](https://services.google.com/fh/files/misc/state-of-devops-2019.pdf))
    has reported for multiple years that companies that have high software deployment
    frequency rates have higher availability and stability in their applications as
    well. This might seem counterintuitive, as doing software deployments heightens
    the risk of issues. However, by deploying more frequently and deploying using
    automated DevOps practices, you can limit the impact of software deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are multiple ways we can make updates in a Kubernetes cluster. In this
    section, we will explore the following ways to update Kubernetes resources:'
  prefs: []
  type: TYPE_NORMAL
- en: Upgrading by changing YAML files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Upgrading using `kubectl edit`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Upgrading using `kubectl patch`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Upgrading using Helm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The methods we will describe in the following section work great if you have
    stateless applications. If you have a state stored anywhere, make sure to back
    up that state before you try anything.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start this section by doing the first type of upgrade: changing YAML
    files.'
  prefs: []
  type: TYPE_NORMAL
- en: Upgrading by changing YAML files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to upgrade a Kubernetes service or deployment, we can update the actual
    YAML definition file and apply that to the currently deployed application. Typically,
    we use `kubectl create` to create resources. Similarly, we can use `kubectl apply`
    to make changes to the resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'The deployment detects the changes (if any) and matches the `Running` state
    to the desired state. Let''s see how this is done:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We start with our guestbook application to demonstrate this example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'After a few minutes, all the Pods should be running. Let''s perform our first
    upgrade by changing the service from `ClusterIP` to `LoadBalancer`, as we did
    earlier in the chapter. However, now we will edit our YAML file rather than using
    `kubectl edit`. Edit the YAML file using this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Uncomment line 108 in this file to set the type as `LoadBalancer` and save
    the file. as shown in *Figure 4.20*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The screen displays the edited YAML file. It now displays the Type as LoadBalancer
    on line 108.](image/Figure_4.20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.20: Changing this line in the guestbook-all-in-one YAML file'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Apply the change as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'You can now get the public IP of the service using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Give it a few minutes, and you should be shown the IP as displayed in *Figure
    4.21*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![When you execute the kubectl get svc command, you will see that only the
    frontend service has an External IP.](image/Figure_4.21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.21: Output displaying a public IP'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We will now make another change. We''ll downgrade the front-end image line
    on line 133 from `image: gcr.io/google-samples/gb-frontend:v4` to the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This change can be made by opening the guestbook application in the editor
    by using this familiar command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following command to perform the update and watch the Pods change:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: This will generate the following output:![Executing the kubectl apply -f guestbook-all-in-one.yaml&&kubectl
    get pods -w command generates an output displaying the change in Pods. You will
    see podsbeing created from a new ReplicaSet.](image/Figure_4.22.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 4.22: Pods from a new ReplicaSet are created'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: What you can see here is that the old version of the Pods (based on the old
    ReplicaSet) gets terminated, while the new version gets created.
  prefs: []
  type: TYPE_NORMAL
- en: Running `kubectl get events | grep ReplicaSet` will show the rolling update
    strategy that the deployment uses to update the front-end images as follows:![The
    output will highlight all the ReplicaSet-related events.](image/Figure_4.23.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 4.23: Monitoring Kubernetes events and filtering to only see ReplicaSet-related
    events'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the preceding example, we are making use of a pipe—shown by the `|` sign—and
    the `grep` command. A pipe in Linux is used to send the output of one command
    to the input of another command. In our case, we are sending the output of `kubectl
    get events` to the `grep` command. `grep` is a command in Linux that is used to
    filter text. In our case, we are using the `grep` command to only show us lines
    that contain the word ReplicaSet.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see here that the new ReplicaSet gets scaled up, while the old one
    gets scaled down. You will also see two ReplicaSets for the front end, the new
    one replacing the other one Pod at a time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'This will display an output as shown in *Figure 4.24*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using the kubectl get replicaset command, you can see two different ReplicaSets.](image/Figure_4.24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.24: Two different ReplicaSets'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Kubernetes will also keep a history of your rollout. You can see the rollout
    history using this command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate an output as shown in *Figure 4.25*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The output screen displays the history of the application. It shows the number
    of revisions, the change, and the cause for the change.](image/Figure_4.25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.25: Deployment history of the application'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Since Kubernetes keeps a history of our rollout, this also enables rollback.
    Let''s do a rollback of our deployment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This will trigger a rollback. This means that the new ReplicaSet will be scaled
    down to zero instances, and the old one will be scaled up to three instances again.
    We can verify this using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The resultant output is as shown in *Figure 4.26*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Executing the kubectl get rscommand shows two frontend ReplicaSets. One has
    0 pods and the other has 3 pods.](image/Figure_4.26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.26: The old ReplicaSet now has three Pods, and the new one is scaled
    down to zero'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This shows us, as expected, that the old ReplicaSet is scaled back to three
    instances and the new one is scaled down to zero instances.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let''s clean up again by running the `kubectl delete` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Congratulations! You have completed the upgrade of an application and a rollback
    to a previous version.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, you have used `kubectl apply` to make changes to your application.
    You can similarly also use `kubectl edit` to make changes, which will be explored
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Upgrading an application using kubectl edit
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can make changes to our application running on top of Kubernetes by using
    `kubectl edit`. You used this previously in this chapter. When running `kubectl
    edit`, the `vi` editor will be opened for you, which will allow you to make changes
    directly against the object in Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s redeploy our guestbook application without a public load balancer and
    use `kubectl` to create the load balancer:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You will start by deploying the guestbook application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'To start the edit, execute the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'This will open a `vi` environment. Navigate to the line that now says `type:`
    `ClusterIP` (line 27) and change that to `type: LoadBalancer`, as shown in *Figure
    4.27*. To make that change, hit the *I* button, type your changes, hit the *Esc*
    button, type `:wq!`, and then hit *Enter* to save the changes:![Output shows that
    line 27 is replaced by Type: LoadBalancer.](image/Figure_4.3.jpg)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 4.27: Changing this line to type: LoadBalancer'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Once the changes are saved, you can watch the service object until the public
    IP becomes available. To do this, type the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: It will take a couple of minutes to show you the updated IP. Once you see the
    right public IP, you can exit the `watch` command by hitting *Ctrl* + *C* (*command*
    + *C* on Mac)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is an example of using `kubectl edit` to make changes to a Kubernetes object.
    This command will open up a text editor to interactively make changes. This means
    that you need to interact with the text editor to make the changes. This will
    not work in an automated environment. To make automated changes, you can use the
    `kubectl patch` command.
  prefs: []
  type: TYPE_NORMAL
- en: Upgrading an application using kubectl patch
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the previous example, you used a text editor to make the changes to Kubernetes.
    In this example, you will use the `kubectl patch` command to make changes to resources
    on Kubernetes. The `patch` command is particularly useful in automated systems,
    such as in a script or in a continuous integration/continuous deployment system.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two main ways in which to use `kubectl patch`, either by creating
    a file containing your changes (called a patch file) or by providing the changes
    inline. We''ll explore both approaches. First, in this example, we''ll change
    the image of the front end from `v4` to `v3` using a patch file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start this example by creating a file called `frontend-image-patch.yaml`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the following text as a patch in that file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: This patch file uses the same YAML layout as typical YAML files. The main thing
    about a patch file is that it only has to contain the changes and doesn't have
    to be capable of deploying the whole resource.
  prefs: []
  type: TYPE_NORMAL
- en: 'To apply the patch, use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'This command does two things: first, it reads the `frontend-image-patch.yaml`
    file, and then it passes that to the `patch` command to execute the change.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can verify the changes by describing the front-end deployment and looking
    for the `Image` section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'This will display an output as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![After the Patch command is executed, you can use the kubectl describe deployment
    frontend command to verify the changes. You should see the path of the new image.](image/Figure_4.28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.28: After the patch, we are running the old image'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This was an example of using the `patch` command using a patch file. You can
    also apply a patch directly on the command line without creating a YAML file.
    In this case, you would describe the change in JSON rather than in YAML.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s run through an example in which we will revert the image change back
    to `v4`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to patch the image back to `v4`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'You can verify this change by describing the deployment and looking for the
    `Image` section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'This will display an output as shown in *Figure 4.29*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![After applying another patch command, you will see the new version of the
    image.](image/Figure_4.29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.29: After another patch, we are running the new version again'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Before we move on to the next example, let''s remove the guestbook application
    from our cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: So far, you have explored three ways of upgrading Kubernetes applications. First,
    you made changes to the actual YAML file and applied them using `kubectl apply`.
    Afterward, you used `kubectl edit` and `kubectl patch` to make more changes. In
    the final section of this chapter, we will use Helm to upgrade our application.
  prefs: []
  type: TYPE_NORMAL
- en: Upgrading applications using Helm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This section will explain how to perform upgrades using Helm operators:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'We will force an update of the image of the `WordPress` container. Let''s first
    check the version of the current image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'In our case, the image version is `10.3.21-debian-10-r0` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The output displays the 10.3.21-debian-10-r0 as the current version of the
    StatefulSet.](image/Figure_4.30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.30: Getting the current image of the StatefulSet'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Let's look at the tags from [https://hub.docker.com/r/bitnami/mariadb/tags](https://hub.docker.com/r/bitnami/mariadb/tags)
    and select another tag. In our case, we will select the `10.3.22-debian-10-r9`
    tag to update our StatefulSet.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, in order to update the MariaDB container image, we need to get the
    root password for the server and the password for the database. We can get these
    passwords in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate an output as shown in *Figure 4.31*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The output will display a base64-encoded version of the password and the
    root password of the MariaDB which we need to update the container image.](image/Figure_4.31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.31: The encrypted secrets that MariaDB uses'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In order to get the decoded password, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: This will show us the decoded root password and the decoded database password.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can update the image tag with Helm and then watch the Pods change using
    the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'This will update the image of our MariaDB and make a new Pod start. Running
    `describe` on the new Pod and grepping for `Image` will show us the new image
    version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate an output as shown in *Figure 4.32*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A new version of the image will be displayed upon executing the kubectl describe
    pod wp-mariadb-0 | grep Image command.](image/Figure_4.32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.32: Showing the new image'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Finally, clean up by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Thus, we have upgraded our application using Helm. As you have seen in this
    example, upgrading using Helm can be done by using the `--set` operator. This
    makes performing upgrades and multiple deployments using Helm so efficient.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This was a chapter with tons of information. Our goal was to show you how to
    scale deployments with Kubernetes. We did this by showing you how to create multiple
    instances of your application.
  prefs: []
  type: TYPE_NORMAL
- en: We started the chapter by looking at how to define the use of a load balancer
    and leverage the deployment scale feature in Kubernetes to achieve scalability.
    With this type of scalability, we also achieve failover by using a load balancer
    and multiple instances of the software for stateless applications. We also looked
    into using the HPA to automatically scale our deployment based on load.
  prefs: []
  type: TYPE_NORMAL
- en: After that, we also looked into how we can scale the cluster itself. First,
    we manually scaled our cluster, and afterward we used a cluster autoscaler to
    scale our cluster based on application demand.
  prefs: []
  type: TYPE_NORMAL
- en: We finished the chapter by looking into different ways to upgrade a deployed
    application. First, we explored manually updating YAML files. Then, we delved
    into two additional `kubectl` commands (`edit` and `patch`) that can be used to
    make changes. Finally, we showed how Helm can be used to perform these upgrades.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at common failures you can see while deploying
    applications to AKS and how to fix them.
  prefs: []
  type: TYPE_NORMAL
