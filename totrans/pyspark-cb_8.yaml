- en: GraphFrames – Graph Theory with PySpark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover how to work with GraphFrames for Apache Spark.
    You will learn the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: A quick primer on graph theory and GraphFrames for Apache Spark
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing GraphFrames
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preparing the data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building the graph
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running queries against the graph
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the graph
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using PageRank to determine airport ranks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding the fewest number of connections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing your graph
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Graphs enable solving certain data problems more easily and intuitively. At
    the core of a graph lies concepts of edges, nodes (or vertices), and their properties.
    For example, the following are two seemingly disconnected graphs. The left one
    represents a social network and the relationship (the *edges* of the graph) between
    friends (the *vertices* of the graph), while the right one is a graph that represents
    restaurant recommendations. Note that the vertices for our restaurant recommendations
    are not only the restaurants themselves but also the cuisine type (for example,
    Ramen) and location (for example, Vancouver, B.C., Canada); these are the properties
    of the vertices. This ability to assign nodes to virtually anything and use edges
    to define the relationship between these nodes is the greatest virtue of graphs,
    that is, their flexibility:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00168.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'This flexibility allows us to conceptually connect these two seemingly disparate
    graphs into one common graph. In this case, we can join the social network with
    restaurant recommendations, in which the edges (that is, connections) between
    the friends and the restaurants are through their ratings:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00169.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'For example, if Isabella wants to find a great ramen restaurant (vertex: cuisine
    type) in Vancouver (vertex: location), then traversing her friends'' reviews (edge:
    ratings), she will most likely choose Kintaro Ramen (vertex: restaurant) as both
    Samantha (vertex: friend) and Juliette (vertex: friend) have rated the restaurant
    favorably.'
  prefs: []
  type: TYPE_NORMAL
- en: While graphs are intuitive and flexible, one of the key problems with a graph
    is that its traversal and computation of graph algorithms are often resource intensive
    and slow. With GraphFrames for Apache Spark, you are able to leverage the speed
    and performance of Apache Spark DataFrames to traverse and compute your graphs
    in a distributed and performant manner.
  prefs: []
  type: TYPE_NORMAL
- en: Installing GraphFrames
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Under the hood of GraphFrames are two Spark DataFrames: one for the vertices
    and other one for the edges. GraphFrames might be thought of as the next generation
    of Spark''s GraphX library, with some major improvements over the latter:'
  prefs: []
  type: TYPE_NORMAL
- en: GraphFrames leverages the performance optimizations and simplicity of the DataFrame
    API.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By using the DataFrame API, GraphFrames can be interacted with through Python,
    Java, and Scala APIs. In contrast, GraphX was only available through the Scala
    interface.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can find the latest information on GraphFrames within the GraphFrames overview
    at [https://graphframes.github.io/](https://graphframes.github.io/).
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We require a working installation of Spark. This means that you would have
    followed the steps outlined in [Chapter 1](part0026.html#OPEK0-dc04965c02e747b9b9a057725c821827),
    *Installing and Configuring Spark*. As a reminder, to start the PySpark shell
    for your local Spark cluster, you can run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Where `n` is the number of cores.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you are running your job from a Spark CLI (for example, `spark-shell`, `pyspark`, `spark-sql`,
    or `spark-submit`), you can use the `–-packages` command, which will extract,
    compile, and execute the necessary code for you to use the GraphFrames package.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, to use the latest GraphFrames package (which, at the time of writing
    this book, is version 0.5) with Spark 2.1 and Scala 2.11 with `spark-shell`, the
    command is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: However, in order to use GraphFrames with Spark 2.3, you need to build the package
    from sources.
  prefs: []
  type: TYPE_NORMAL
- en: Check out the steps outlined here: [https://github.com/graphframes/graphframes/issues/267](https://github.com/graphframes/graphframes/issues/267).
  prefs: []
  type: TYPE_NORMAL
- en: If you are using a service such as Databricks, you will need to create a library
    with GraphFrames. For more information, please refer to how to create a library in
    Databricks at [https://docs.databricks.com/user-guide/libraries.html](https://docs.databricks.com/user-guide/libraries.html),
    and how to install a GraphFrames Spark package at [https://cdn2.hubspot.net/hubfs/438089/notebooks/help/Setup_graphframes_package.html](https://cdn2.hubspot.net/hubfs/438089/notebooks/help/Setup_graphframes_package.html).
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can install a package such as GraphFrames by building it off the GraphFrames
    GitHub repository at [https://github.com/graphframes/graphframes](https://github.com/graphframes/graphframes),
    but an easier way is to utilize the GraphFrames Spark package which is available
    at [https://spark-packages.org/package/graphframes/graphframes](https://spark-packages.org/package/graphframes/graphframes).
    Spark Packages is a repository that contains an index of third-party packages
    for Apache Spark. By using Spark packages, PySpark will download the latest version
    of the GraphFrames Spark package, compile it, and then execute it within the context
    of your Spark job.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you include the GraphFrames package using the following command, notice
    the call `graphframes` console output, denoting that the package is being pulled
    in from the `spark-packages` repository for compilation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Preparing the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The example scenario we will use for the cookbook is on-time flight performance
    data (that is, flights scenario) that will make use of two sets of data:'
  prefs: []
  type: TYPE_NORMAL
- en: Airline On-Time Performance and Causes of Flight Delays, available at [http://bit.ly/2ccJPPM](http://bit.ly/2ccJPPM).
    These datasets contain information about scheduled and actual departure and arrival
    times of flights, and the delay causes. The data is represented as reported by
    US air carriers and is collected by the Office of Airline Information, **Bureau
    of Transportation Statistics** (**BTS**).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenFlights, airport and airline data available at [http://openflights.org/data.html](http://openflights.org/data.html).
    This dataset contains the list of US airport data, including the IATA code, airport
    name, and airport location.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will create two DataFrames: one for the airports and one for the flights.
    The `airports` DataFrame will make up our vertices and the `flights` DataFrames
    will represent all the edges of our GraphFrame.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you are running this locally, please copy the linked files to your local
    folder; for the purpose of this recipe, we''ll call the location `/data`:'
  prefs: []
  type: TYPE_NORMAL
- en: Airline On-Time Performance and Causes at [http://bit.ly/2xs0XLH](http://bit.ly/2xs0XLH)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenFlights—Airports and airline data at [http://bit.ly/2J1CU7D](http://bit.ly/2J1CU7D)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are using Databricks, the data is already loaded into the `/databricks-datasets`
    folder; the location of the files can be found at `/databricks-datasets/flights/airport-codes-na.txt`
    and `/databricks-datasets/flights/departuredelays.csv` for airports and flights
    data, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To prepare our data for our graph, we will initially clean up the data and
    include only the airport codes that exist within the available flight data. That
    is, we exclude any airports that do not exist in the `DepartureDelays.csv` dataset.
    The upcoming recipe executes the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Sets the file paths to the files you had downloaded
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creates the `apts` and `deptDelays` DataFrames by reading the CSV files and
    inferring the schema, configured with headers
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `iata` contains only the airport codes (the `IATA` column) that exist in
    the `deptDelays` DataFrame
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Joins the `iata` and `apts` DataFrames to create the `apts_df` DataFrame
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The reason we filter out the data to create the `airports` DataFrame is that
    when we create our GraphFrame in the following recipes, we will only have vertices
    with edges for our graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The two key concepts used for this code snippet are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`spark.read.csv`: This `SparkSession` method returns a `DataFrameReader` object
    that encompasses the classes and functions that will allow us to read CSV files
    from a filesystem'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`spark.sql`: This allows us to execute Spark SQL statements'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more information, please refer to the preceding chapters on Spark DataFrames,
    or refer to the PySpark master documentation of the `pyspark.sql` module at [http://spark.apache.org/docs/2.3.0/api/python/pyspark.sql.html](http://spark.apache.org/docs/2.3.0/api/python/pyspark.sql.html).
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we read the data into our GraphFrame, let''s create one more DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: It creates a `tripid` column that allows us to uniquely identify each trip.
    Note that this is a bit of a hack as we had converted the date (each trip has
    a unique date in this dataset) into an int column.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `date` column isn't really a traditional date per se as it is in the format
    of `MMYYHHmm`. Therefore, we first apply a `udf` to convert it into a proper format
    (the `toDate(...)` method). We then convert it into an actual timestamp format.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Re-casts the `delay` and `distance` columns into integer values as opposed to
    string.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following sections, we will be using the airport codes (the `iata` column)
    as our vertex. To create the edges for our graph, we will need to specify the
    IATA codes for the source (originating airport) and destination (destination airport).
    The `join` statement and renaming of `f.origin` as `src` and `f.destination` as
    `dst` are in preparation for creating the GraphFrame to specify the edges (they
    are explicitly looking for the `src` and `dst` columns).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building the graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the preceding sections, you installed GraphFrames and built the DataFrames
    required for the graph; now, you can start building the graph itself.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first component of this recipe involves importing the necessary libraries,
    in this case, the PySpark SQL functions (`pyspark.sql.functions`) and GraphFrames
    (`graphframes`). In the previous recipe, we had created the `src` and `dst` columns
    as part of creating the `deptsDelays_geo` DataFrame. When creating edges within
    GraphFrames, it is specifically looking for the `src` and `dst` columns to create
    the edges as per `edges`. Similarly, GraphFrames is looking for the column `id` to
    represent the graph vertex (as well as join to the `src` and `dst` columns). Therefore,
    when creating the vertexes, `vertices`, we rename the `IATA` column to `id`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Note that `edges` and `vertices` are DataFrames containing the edges and vertices
    of the graph, respectively. You can check this by viewing the data as noted in
    the following screenshots (in this case, we're using the `display` command within
    Databricks).
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the command `display(vertices)` shows the `id` (IATA code), `City`,
    `State`, and `Country` columns of the `vertices` DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00170.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Meanwhile, the command `display(edges)` shows the `tripid`, `delay`, `src`,
    `dst`, `city_dst`, and `state_dst` of the `edges` DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00171.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The final statement, `GraphFrame(vertices, edges)`, performs the task of merging
    the two DataFrames into our GraphFrame, `graph`.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As noted in the previous section, when creating a GraphFrame, it specifically
    looks for the following columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '`id`: This identifies the vertex and will join to the `src` and `dst` columns.
    In our example, the IATA code `LAX` (representing **Los Angeles Airport**) is
    one of many airports that make up the vertices in our graph (`graph`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`src`: The source vertex of our graph''s edges; for example, a flight from
    Los Angeles to New York has `src = LAX`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dst`: The destination vertex of our graph''s edges; for example, a flight
    from Los Angeles to New York has `dst = JFK`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By creating the two DataFrames (`vertices` and `edges`) where the attributes
    follow the previously noted naming convention, we can invoke the GraphFrame to
    create our graph, utilizing the performance optimizations of the two DataFrames
    underneath.
  prefs: []
  type: TYPE_NORMAL
- en: Running queries against the graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you have created your graph, start off by creating and running some
    simple queries against your GraphFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ensure that you have created the `graph` GraphFrame (derived from the `vertices`
    and `edges` DataFrames) from the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s start with some simple count queries to determine the number of airports
    (nodes or vertices; remember?) and the number of flights (the edges), which can
    be determined by applying `count()`. The call to `count()` is similar to a DataFrame
    except that you also need to include whether you are counting `vertices` or `edges`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of these queries should be similar to the following output, denoting
    the 279 vertices (that is, airports) and more than 1.3 million edges (that is,
    flights):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to DataFrames, you can also execute the `filter` and `groupBy` clauses
    to better understand the number of delayed flights. To understand the number of
    on-time or early flights, we use the filter where `delay <= 0`; the delayed flights,
    on the other hand, show `delay > 0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Diving further, you can filter for delayed flights (`delay > 0`) departing
    from San Francisco (`src = ''SFO''`) grouped by the destination airports, sorting
    by average delay descending (`desc("avg(delay)")`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00172.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'If you are using the Databricks notebooks, you can visualize the GraphFrame
    queries. For example, we can determine the destination states with `delay > 100`
    minutes departing from Seattle using the following query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code produces the following map. The darker the blue hue, the
    more the delay that the flights experienced. From the following graph, you can
    see that most of the delayed flights departing Seattle have their destination
    within the state of California:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00173.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As noted in previous sections, GraphFrames are built on top of two DataFrames:
    one for vertices and one for edges. This simply means that GraphFrames take advantage
    of the same performance optimizations as DataFrames (unlike the older GraphX).
    Just as importantly, they also take on many components of the Spark SQL syntax.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To easily understand the complex relationship of city airports and the flights
    between each of them, we can use the concept of **motifs** to find patterns of
    airports connected by flights. The result is a DataFrame in which the column names
    are given by the motif keys.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To make it easier to view our data within the context of Motifs, let''s first
    create a smaller version of the `graph` GraphFrame called `graphSmall`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To execute a Motif, execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The result of this query can be seen as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00174.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Output of the motif query
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There is a lot to unpack with this example motif query, so let''s start with
    the query itself.  The first part of the query is to establish what our Motif
    is, which is to establish that we are looking for the relationships between vertices
    `(a)`, `(b)`, and `(c)`. Specifically, we''re concerned with the edges between
    the two sets of vertices, between `(a)` and `(b)`, as represented by `[ab]`, and
    between vertices `(b)` and `(c)` as represented by `[bc]`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'For example, we are trying to determine all the flights between two different
    cities where Los Angeles is the layover city (for example, Seattle - Los Angeles
    -> New York, Portland - Los Angeles -> Atlanta, and so on):'
  prefs: []
  type: TYPE_NORMAL
- en: '`(b)`: This represents the city of Los Angeles'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`(a)`: This represent the originating cities, such as Seattle and Portland
    in this example'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`[ab]`: This represents the flights, such as Seattle - Los Angeles and Portland
    - Los Angeles in this example'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`(c)`: This represents the destination cities, such as New York and Atlanta
    in this example'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`[bc]`: This represents the flights, such as Los Angeles -> New York and Los
    Angeles -> Atlanta in this example'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that this last statement is an oversimplification of flights because it
    isn''t taking into account which flights are valid connector flights. Also, recall
    that `tripid` was generated based on time in the format of `MMDDHHMM` converted
    to an integer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The output displayed in the preceding subsection denotes all the flights where
    the stopover was San Francisco and there were flight delays of greater than 500
    minutes for either flights arriving or leaving `SFO`. Digging further into a single
    flight, let''s review the output of the first row, though we have pivoted it to
    make it easier to review:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Vertices** | **Values** |'
  prefs: []
  type: TYPE_TB
- en: '| `[ab]` |'
  prefs: []
  type: TYPE_TB
- en: '`tripid: 2021900`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`delay: 39`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`src: STL`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dst: SFO`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| `(a)` |'
  prefs: []
  type: TYPE_TB
- en: '`id: STL`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`City: St. Louis`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`State: MO`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Country: USA`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| `(b)` |'
  prefs: []
  type: TYPE_TB
- en: '`id: SFO`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`City: San Francisco`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`State: CA`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Country: USA`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| `[bc]` |'
  prefs: []
  type: TYPE_TB
- en: '`tripid: 2030906`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`delay: 516`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`src: SFO`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dst: PHL`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| `(c)` |'
  prefs: []
  type: TYPE_TB
- en: '`id: PHL`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`City: Philadelphia`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`State: PA`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Country: USA`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: As noted previously, `[ab]` and `[bc]` are the flights while `[a]`, `[b]`, and
    `[c]` are the airports. In this example, the flight departing from St. Louis (`STL`)
    to San Francisco had a delay of 39 minutes, but its potential connecting flight
    to Philadelphia (`PHL`) had a delay of 516 minutes. As you dig through the results,
    you can see a lot of different potential flight patterns between originating and
    final destination cities centered around San Francisco as the primary stop over.
    This query will become more complicated as you take on even larger hub cities
    such as Atlanta, Dallas, and Chicago.
  prefs: []
  type: TYPE_NORMAL
- en: Using PageRank to determine airport ranking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'PageRank is an algorithm popularized by the Google Search Engine and created
    by Larry Page. Ian Rogers says (see [http://www.cs.princeton.edu/~chazelle/courses/BIB/pagerank.htm](http://www.cs.princeton.edu/~chazelle/courses/BIB/pagerank.htm)):'
  prefs: []
  type: TYPE_NORMAL
- en: '"(...)PageRank is a “vote”, by all the other pages on the Web, about how important
    a page is. A link to a page counts as a vote of support. If there’s no link there’s
    no support (but it’s an abstention from voting rather than a vote against the
    page)."'
  prefs: []
  type: TYPE_NORMAL
- en: As you might imagine, this method can be applied to other problems and not only
    to ranking web pages. In our context, we can use it to determine airport ranking.
    To achieve this, we can use the number of flights and connections to and from
    various airports included that are in this departure delay dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ensure that you have created the `graph` GraphFrame from the preceding subsections.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Execute the following code snippet to determine the most important airport
    in our dataset via the PageRank algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from the output in the following graph, Atlanta, Dallas, and
    Chicago are the top three most important cities (note that this dataset contains
    US data only):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00175.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At the time of writing this book,, the current version of GraphFrames is v0.5,
    which contains two implementations of PageRank:'
  prefs: []
  type: TYPE_NORMAL
- en: The one we are using utilizes the GraphFrame interface and runs PageRank for
    a fixed number of iterations by setting `maxIter`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another version uses the `org.apache.spark.graphx.Pregel` interface and runs
    PageRank until convergence by setting `tol`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more information, please refer to the GraphFrames Scala documentation on
    PageRank at [https://graphframes.github.io/api/scala/index.html#org.graphframes.lib.PageRank](https://graphframes.github.io/api/scala/index.html#org.graphframes.lib.PageRank).
  prefs: []
  type: TYPE_NORMAL
- en: 'As noted previously, we are using the standalone GraphFrame version of PageRank
    by setting:'
  prefs: []
  type: TYPE_NORMAL
- en: '`resetProbability`: This is currently set to the default value of `0.15`, which represents
    the probability of resetting to a random vertex. If the value is too high, it
    means that it will take longer to complete its calculation, but if the value is
    too low, the calculations may overshoot and not converge.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`maxIter`: For this demo, we have set the value to `5`; the higher the number,
    the higher the probability of a more precise calculation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding the fewest number of connections
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you're flying to many cities, one of the recurring problems is to determine
    either the shortest path between two cities or the shortest time of travel. From
    the viewpoint of the airline traveler, the aim is to find the shortest set of
    flights between two cities. From the viewpoint of the airline, determining how
    to route their passengers between cities as efficiently as possible increases
    customer satisfaction and lowers prices (less fuel, wear and tear on equipment,
    ease for the flight crew, and so on). Within the context of GraphFrames and graph
    algorithms, one approach would be to use the **breadth first search** (**BFS**)
    algorithm to help us find the shortest path between these airports.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ensure that you have created the `graph` GraphFrame from the preceding subsections.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s start using our BFS algorithm to determine whether there are any direct
    flights between `SFO` and `SEA`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can tell from the output, there are many direct flights between Seattle
    (`SEA`) and San Francisco (`SFO`):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00176.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When calling the BFS algorithm, the key parameters are `fromExpr`, `toExpr`,
    and `maxPathLength`. As our vertices contain the airports, to understand the number
    of direct flights from Seattle to San Francisco, we will specify:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The `maxPathLength` is the parameter used to specify the maximum number of edges
    between the two vertices. If `maxPathLength = 1`, it means that we have only one
    edge between the two vertices. That is, there is only one flight between the two
    airports or a direct flight between those two cities. Increasing this value means
    BFS will attempt to find multiple connections between your two cities. For example,
    if we were to specify `maxPathLength = 2`, this would mean two edges or two flights
    between Seattle and San Francisco. That indicates a layover city, for example,
    SEA - POR -> SFO, SEA - LAS -> SFO, SEA - DEN -> SFO, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'What if you want to find connections between two cities that typically do not
    have direct flights? For example, let''s find out the possible routes between
    San Francisco and Buffalo:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The `OK` in this case indicates that there are no direct flights between San
    Francisco and Buffalo as we could not retrieve a single edge (at least from this
    dataset). But to find out whether there are any layover flights, just change `maxPathLength
    = 2` (to indicate a single stopover city):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see here, there are many flights with a single stopover connecting
    San Francisco and Buffalo:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00177.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'But what is the most common layover between San Francisco and Buffalo? Looking
    at the preceding results, it seems like Minneapolis, but looks can be deceiving.
    Instead, run the following query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from the following graph, JFK is the most common transfer point
    between these two cities:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00178.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Visualizing the graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the preceding recipes, we have been visualizing our flights using Databrick
    notebook's native visualizations (for example, bar chart, line chart, maps, and
    so on). But we have not yet visualized our graph as a graph. In this section,
    we will leverage Mike Bostock's Airports D3.js visualization ([https://mbostock.github.io/d3/talk/20111116/airports.html](https://mbostock.github.io/d3/talk/20111116/airports.html))
    within our Databricks notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ensure that you have created the `graph` GraphFrame and the source `deptsDelays_GEO`
    DataFrame from the preceding subsections.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will be leveraging our Python Databricks notebook, but we will include the
    following Scala cell. At the top level here''s the flow of the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'In the next cell, you will call the following Scala cell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Which results in the following visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00179.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The `force` function has the following definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Recall that we call this function in the next cell using the following code
    snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The height and width are readily apparent, but the key call out is that we use
    a Spark SQL query against the `deptsDelays_GEO` DataFrame to define the edges
    (that is, the source and destination IATA codes). As the IATA codes are already
    defined within the calls within `showGraph`, we already have the vertices of our
    visualization. Note that as we had already created the DataFrame `deptsDelays_GEO`,
    even though it was created using PySpark, it is accessible by Scala within the
    same Databricks notebook.
  prefs: []
  type: TYPE_NORMAL
