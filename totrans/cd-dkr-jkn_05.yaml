- en: Automated Acceptance Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We already configured the commit phase of the Continuous Delivery process and
    now it's time to address the acceptance testing phase, which is usually the most
    challenging part. By gradually extending the pipeline, we will see different aspects
    of a well-done acceptance testing automation.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following points:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the acceptance testing process and its difficulties
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explaining the idea of the artifact repository
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating the Docker registry on Docker Hub
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing and securing private Docker registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing acceptance testing in the Jenkins pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing and exploring Docker Compose
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Docker Compose in the acceptance testing process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing acceptance tests with users
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing acceptance testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Acceptance testing is a test performed to determine if the business requirements
    or contracts are met. It involves black-box testing against a complete system
    from a user perspective and its positive result should imply the acceptance of
    the software delivery. Sometimes, also called **UAT** (**user acceptance testing**),
    end user testing, or beta testing, it is a phase of the development process when
    software meets the *real-world* audience.
  prefs: []
  type: TYPE_NORMAL
- en: Many projects rely on manual steps performed by QAs or users to verify the functional
    and nonfunctional requirements, but still, it's way more reasonable to run them
    as programmed repeatable operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Automated acceptance tests, however, can be considered difficult due to their
    specifics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**User-facing**: They need to be written together with a user, which requires
    an understanding between two worlds, technical and non-technical.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dependencies integration**: The tested application should be run together
    with its dependencies in order to check whether the system as a whole works properly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Environment identity**: Staging (testing) and production environments should
    be identical to ensure that when run in production, the application also behaves
    as expected.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Application identity**: Application should be built only once and the same
    binary should be transferred to production. That guarantees no changes in code
    between testing and releasing and eliminates the risk of different building environments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Relevance and consequences**: If acceptance test passes, it should be clear
    that the application is ready for release from the user perspective.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We address all these difficulties in different sections of this chapter. Application
    identity can be achieved by building the Docker image only once and using Docker
    registry for its storage and versioning. Docker Compose helps with the dependencies
    integration providing a way to build a group of containerized applications working
    together. Creating tests in a user-facing manner is explained in the *Writing
    acceptance tests* section, and the environment identity is addressed by the Docker
    tool itself and can be also improved by other tools described in the next chapter.
    Concerning the relevance and consequences, the only good answer is to keep in
    mind that acceptance tests must always be of a high quality.
  prefs: []
  type: TYPE_NORMAL
- en: Acceptance testing can have multiple meanings; in this book, we treat acceptance
    testing as a complete integration test from a user perspective, excluding nonfunctional
    testing, such as performance, load, and recovery.
  prefs: []
  type: TYPE_NORMAL
- en: Docker registry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker registry is a storage for Docker images. To be precise, it is a stateless
    server application that allows the images to be published (pushed) and later retrieved
    (pulled) when needed. We have already seen an example of the registry while running
    the official Docker images, such as `jenkins`. We pulled the images from Docker
    Hub, which is an official cloud-based Docker registry. Having a separate server
    to store, load, and search software packages is a more general concept called
    the software repository or, even more general, the artifact repository. Let's
    look closer at this idea.
  prefs: []
  type: TYPE_NORMAL
- en: Artifact repository
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While the source control management stores the source code, the artifact repository
    is dedicated for storing software binary artifacts, for example, compiled libraries
    or components, later used to build a complete application. Why do we need to store
    binaries on a separate server using a separate tool?
  prefs: []
  type: TYPE_NORMAL
- en: '**File size**: Artifact files can be large, so the systems need to be optimized
    for their download and upload.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Versions**: Each uploaded artifact needs to have a version that makes it
    easy to browse and use. Not all versions, however, have to be stored forever;
    for example, if there was a bug detected, we may not be interested in the related
    artifact and remove it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Revision mapping**: Each artifact should point to exactly one revision of
    the source control and, what''s more, the binary creation process should be repeatable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Packages**: Artifacts are stored in the compiled and compressed form so that
    these time-consuming steps need not be repeated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Access control**: Users can be restricted differently to the source code
    and artifact binary access.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clients**: Users of the artifact repository can be developers outside the
    team or organization, who want to use the library via its public API.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use cases**: Artifact binaries are used to guarantee that exactly the same
    built version is deployed to every environment to ease the rollback procedure
    in case of failure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The most popular artifact repositories are JFrog Artifactory and Sonatype Nexus.
  prefs: []
  type: TYPE_NORMAL
- en: The artifact repository plays a special role in the Continuous Delivery process
    because it guarantees that the same binary is used throughout all pipeline steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at the following figure presenting how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/60334691-bdc8-4953-9758-40f5983827d8.png)'
  prefs: []
  type: TYPE_IMG
- en: The **Developer** pushes a change to the **source code repository**, which triggers
    the pipeline build. As the last step of the **Commit Stage**, a binary is created
    and stored in the artifact repository. Afterward, during all other stages of the
    delivery process, the same binary is pulled and used.
  prefs: []
  type: TYPE_NORMAL
- en: The built binary is often called the **release candidate** and the process of
    moving binary to the next stage is called **promotion**.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the programming language and technologies, the binary formats can
    differ.
  prefs: []
  type: TYPE_NORMAL
- en: For example, in the case of Java, usually, JAR files are stored and, in the
    case of Ruby, gem files. We work with Docker, so we will store Docker images as
    artifacts, and the tool to store Docker images is called Docker registry.
  prefs: []
  type: TYPE_NORMAL
- en: Some teams maintain two repositories at the same time, artifact repository for
    JAR files and Docker registry for Docker images. While it may be useful during
    the first phase of the Docker introduction, there is no good reason to maintain
    both forever.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Docker registry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, we need to install a Docker registry. There are a number of options available,
    but two of them are more common than others, cloud-based Docker Hub registry and
    your own private Docker registry. Let's dig into them.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Hub
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Docker Hub is a cloud-based service that provides Docker registry and other
    features such as building images, testing them, and pulling code directly from
    the code repository. Docker Hub is cloud-hosted, so it does not really need any
    installation process. All you need to do is create a Docker Hub account:'
  prefs: []
  type: TYPE_NORMAL
- en: Open [https://hub.docker.com/](https://hub.docker.com/) in a browser.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fill in the password, email address, and Docker ID.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After receiving an email and clicking the activation link, the account is created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Docker Hub is definitely the simplest option to start with, and it allows storing
    both private and public images.
  prefs: []
  type: TYPE_NORMAL
- en: Private Docker registry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker Hub may not always be acceptable. It is not free for enterprises and,
    what's even more important, a lot of companies have policies not to store their
    software outside their own network. In this case, the only option is to install
    a private Docker registry.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Docker registry installation process is quick and simple, however, making
    it secure and available in public requires setting up access restriction and the
    domain certificate. This is why we split this section into three parts:'
  prefs: []
  type: TYPE_NORMAL
- en: Installing the Docker registry application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding domain certificate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding access restriction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing the Docker registry application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Docker registry is available as a Docker image. To start this, we can run the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: By default, the registry data is stored as a docker volume in the default host
    filesystem's directory. To change it, you can add `-v <host_directory>:/var/lib/registry`.
    Another alternative is to use a volume container.
  prefs: []
  type: TYPE_NORMAL
- en: The command starts the registry and makes it accessible via port 5000\. The
    `registry` container is started from the registry image (version 2). The `--restart=always` option
    causes the container to automatically restart whenever it's down.
  prefs: []
  type: TYPE_NORMAL
- en: Consider setting up a load balancer and starting a few Docker registry containers
    in case of a large number of users.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a domain certificate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If the registry is run on the localhost, then everything works fine and no other
    installation steps are required. However, in most cases, we want to have a dedicated
    server for the registry, so that the images are widely available. In that case,
    Docker requires securing the registry with SSL/TLS. The process is very similar
    to the public web server configuration and, similarly, it's highly recommended
    having the certificate signed by CA (certificate authority). If obtaining the
    CA-signed certificate is not an option, then we can self-sign a certificate or
    use the `--insecure-registry` flag.
  prefs: []
  type: TYPE_NORMAL
- en: You can read about creating and using self-signed certificates at [https://docs.docker.com/registry/insecure/#using-self-signed-certificates](https://docs.docker.com/registry/insecure/#using-self-signed-certificates).
  prefs: []
  type: TYPE_NORMAL
- en: Having the certificates either signed by CA or self-signed, we can move `domain.crt` and
    `domain.key` to the `certs` directory and start the registry.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In case of a self-signed certificate, clients have to explicitly trust the certificate.
    In order to do this, they can copy the `domain.crt` file to `/etc/docker/certs.d/<docker_host_domain>:5000/ca.crt`.
  prefs: []
  type: TYPE_NORMAL
- en: Using the `--insecure-registry` flag is not recommended since it provides no
    security at all.
  prefs: []
  type: TYPE_NORMAL
- en: Adding an access restriction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unless we use the registry inside a well-secured private network, we should
    configure the authentication.
  prefs: []
  type: TYPE_NORMAL
- en: 'The simplest way to do this is to create a user with a password using the `htpasswd`
    tool from the `registry` image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The command runs the `htpasswd` tool to create the `auth/passwords` file (with
    one user inside). Then, we can run the registry with that one user authorized
    to access it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The command, in addition to setting the certificates, creates the access restriction
    limited to the users specified in the `auth/passwords` file.
  prefs: []
  type: TYPE_NORMAL
- en: As a result, before using the registry, a client needs to specify the username
    and password.
  prefs: []
  type: TYPE_NORMAL
- en: Access restriction doesn't work in the case of the `--insecure-registry` flag.
  prefs: []
  type: TYPE_NORMAL
- en: Other Docker registries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker Hub and private registry are not the only possibilities when it comes
    to Docker-based artifact repositories.
  prefs: []
  type: TYPE_NORMAL
- en: 'The other options are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**General-purpose repositories**: Widely-used general-purpose repositories,
    such as JFrog Artifactory or Sonatype Nexus, implement the Docker registry API.
    Their advantage is that one server can store both Docker images and other artifacts
    (for example, JAR files). These systems are also mature and provide enterprise
    integration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud-based registries**: Docker Hub is not the only cloud provider. Most
    cloud-oriented services offer Docker registries in the cloud, for example, Google
    Cloud or AWS.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Custom registries**: The Docker registry API is open, so it''s possible to
    implement custom solutions. What''s more, images can be exported to files, so
    it''s feasible to store images simply as files.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Docker registry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When the registry is configured, we can show how to work with it in three steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Building an image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pushing the image to the registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pulling the image from the registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building an image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s use the example from [Chapter 2](aa58c16d-41c0-4364-9eae-26b60a05c510.xhtml),
    *Introducing Docker*, and build an image with Ubuntu and the Python interpreter
    installed. In a new directory, we need to create a Dockerfile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can build the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Pushing the image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to push the created image, we need to tag it according to the naming
    convention:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The "`registry_address`" can be:'
  prefs: []
  type: TYPE_NORMAL
- en: User name in case of Docker Hub
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Domain name or IP address with port for a private registry (for example, `localhost:5000`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In most cases, `<tag>` is in the form of image/application version.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s tag the image to use Docker Hub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We could have also tagged the image in the `build` command: `"docker`'
  prefs: []
  type: TYPE_NORMAL
- en: '`build -t leszko/ubuntu_with_python:1 . "`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If the repository has access restriction configured, we need to authorize it
    first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: It's possible to use the `docker login` command without parameters and Docker
    would ask interactively for the username and password.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can store the image in the registry using the `push` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Note that there is no need to specify the registry address because Docker uses
    the naming convention to resolve it. The image is stored, and we can check it
    using the Docker Hub web interface available at [https://hub.docker.com](https://hub.docker.com).
  prefs: []
  type: TYPE_NORMAL
- en: Pulling the image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To demonstrate how the registry works, we can remove the image locally and
    retrieve it from the registry:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that the image has been removed using the `docker images` command.
    Then, let''s retrieve the image back from the registry:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: If you use the free Docker Hub account, you may need to change the `ubuntu_with_python` repository
    to public before pulling it.
  prefs: []
  type: TYPE_NORMAL
- en: We can confirm the image is back with the `docker images` command.
  prefs: []
  type: TYPE_NORMAL
- en: When we have the registry configured and understand how it works, we can see
    how to use it inside the Continuous Delivery pipeline and build the acceptance
    testing stage.
  prefs: []
  type: TYPE_NORMAL
- en: Acceptance test in pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We already understood the idea behind acceptance testing and know how to configure
    Docker registry, so we are ready for its first implementation inside the Jenkins
    pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at the figure that presents the process we will use:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/0a20aa8e-7116-4a9b-97ef-d619265b0725.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The process goes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The developer pushes a code change to GitHub.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Jenkins detects the change, triggers the build, and checks out the current code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Jenkins executes the commit phase and builds the Docker image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Jenkins pushes the image to Docker registry.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Jenkins runs the Docker container in the staging environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Staging the Docker host needs to pull the image from the Docker registry.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Jenkins runs the acceptance test suite against the application running in the
    staging environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For the sake of simplicity, we will run the Docker container locally (and not
    on a separate staging server). In order to run it remotely, we need to use the
    `-H` option or to configure the `DOCKER_HOST` environment variable. We will cover
    this part in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s continue the pipeline we started in the previous chapter and add three
    more stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Docker build`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Docker push`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Acceptance test`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep in mind that you need to have the Docker tool installed on the Jenkins
    executor (agent slave or master, in the case of slave-less configuration) so that
    it is able to build Docker images.
  prefs: []
  type: TYPE_NORMAL
- en: If you use dynamically provisioned Docker slaves, then there is no mature Docker
    image provided yet. You can build it yourself or use the `leszko/jenkins-docker-slave` image.
    You also need to mark the `privileged` option in the Docker agent configuration.
    This solution, however, has some drawbacks, so before using it in production,
    read the [http://jpetazzo.github.io/2015/09/03/do-not-use-docker-in-docker-for-ci/](http://jpetazzo.github.io/2015/09/03/do-not-use-docker-in-docker-for-ci/).
  prefs: []
  type: TYPE_NORMAL
- en: The Docker build stage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We would like to run the calculator project as a Docker container, so we need
    to create Dockerfile and add the `"Docker build"` stage to Jenkinsfile.
  prefs: []
  type: TYPE_NORMAL
- en: Adding Dockerfile
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s create Dockerfile in the root directory of the calculator project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The default build directory for Gradle is `build/libs/`, and `calculator-0.0.1-SNAPSHOT.jar` is
    the complete application packaged into one JAR file. Note that Gradle automatically
    versioned the application using the Maven-style version `0.0.1-SNAPSHOT`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Dockerfile uses a base image that contains JDK 8 (`frolvlad/alpine-oraclejdk8:slim`).
    It also copies the application JAR (created by Gradle) and runs it. Let''s check
    if the application builds and runs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Using the preceding commands, we've built the application, built the Docker
    image, and run the Docker container. After a while, we should be able to open
    the browser to `http://localhost:8080/sum?a=1&b=2` and see `3` as a result.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can stop the container and push the Dockerfile to the GitHub repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Adding the Docker build to the pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The last step we need is adding the `"Docker build"` stage to Jenkinsfile. Usually,
    the JAR packaging is also declared as a separate `Package` stage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: We don't explicitly version the image, but each image has a unique hash ID.
    We will cover the explicit versioning in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Note that we used the Docker registry name in the image tag. There is no need
    to have the image tagged twice `calculator `and `leszko/calculator`.
  prefs: []
  type: TYPE_NORMAL
- en: When we commit and push Jenkinsfile, the pipeline build should start automatically
    and we should see all boxes green. This means that the Docker image has been built
    successfully.
  prefs: []
  type: TYPE_NORMAL
- en: There is also a Gradle plugin for Docker that allows executing the Docker operations
    within Gradle scripts. You can see an example at: [https://spring.io/guides/gs/spring-boot-docker/](https://spring.io/guides/gs/spring-boot-docker/).
  prefs: []
  type: TYPE_NORMAL
- en: The Docker push stage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When the image is ready, we can store it in the registry. The `Docker push`
    stage is very simple. It''s enough to add the following code to Jenkinsfile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: If Docker registry has the access restricted, then first we need to log in using
    the `docker login` command. Needless to say, the credentials must be well secured,
    for example, using a dedicated credential store as described on the official Docker
    page: [https://docs.docker.com/engine/reference/commandline/login/#credentials-store](https://docs.docker.com/engine/reference/commandline/login/#credentials-store).
  prefs: []
  type: TYPE_NORMAL
- en: As always, pushing changes to the GitHub repository triggers Jenkins to start
    the build and, after a while, we should have the image automatically stored in
    the registry.
  prefs: []
  type: TYPE_NORMAL
- en: Acceptance testing stage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To perform acceptance testing, first, we need to deploy the application to the
    staging environment and then run the acceptance test suite against it.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a staging deployment to the pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s add a stage to run the `calculator` container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: After running this stage, the `calculator` container is running as a daemon,
    publishing its port as `8765` and being removed automatically when stopped.
  prefs: []
  type: TYPE_NORMAL
- en: Adding an acceptance test to the pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Acceptance testing usually requires running a dedicated black-box test suite
    that checks the behavior of the system. We will cover it in the *Writing acceptance
    tests *section. At the moment, for the sake of simplicity, let's perform acceptance
    testing simply by calling the web service endpoint with the `curl` tool and checking
    the result using the `test` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the root directory of the project, let''s create the `acceptance_test.sh` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We call the `sum` endpoint with parameters `a=1` and `b=2` and expect to receive
    `3` in response.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, the `Acceptance test` stage can look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Since the `docker run -d` command is asynchronous, we need to wait using the
    `sleep` operation to make sure the service is already running.
  prefs: []
  type: TYPE_NORMAL
- en: There is no good way to check if the service is already running. An alternative
    to sleeping could be a script checking every second whether the service has already
    started.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a cleaning stage environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As the last step of acceptance testing, we can add the staging environment
    cleanup. The best place to do this is in the `post` section, to make sure it executes
    even in case of failure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This statement makes sure that the `calculator` container is no longer running
    on the Docker host.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Compose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Life is easy without dependencies. In real-life, however, almost every application
    links to a database, cache, messaging system, or another application. In the case
    of a (micro) service architecture, each service needs a bunch of other services
    to do its work. The monolithic architecture does not eliminate the issue, an application
    usually has some dependencies, at least to the database.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine a newcomer joining your development team; how much time does it take
    to set up the entire development environment and run the application with all
    its dependencies?
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to automated acceptance testing, the dependencies issue is no
    longer only a matter of convenience, but it becomes a necessity. While, during
    unit testing, we could mock the dependencies, the acceptance testing suite requires
    a complete environment. How do we set it up quickly and in a repeatable manner?
    Luckily, Docker Compose is a tool that can help.
  prefs: []
  type: TYPE_NORMAL
- en: What is Docker Compose?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker Compose is a tool for defining, running, and managing multi-container
    Docker applications. Services are defined in a configuration file (a YAML format)
    and can be created and run all together with a single command.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Compose orchestrates containers using standard Docker mechanisms and
    provides a convenient way to specify the entire environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Docker Compose comes with a lot of features, the most interesting are:'
  prefs: []
  type: TYPE_NORMAL
- en: Building a set of services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Launching a set of services together
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing the state of individual services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preserving volume data between runs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling services up and down
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Showing logs of individual services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Caching configuration and recreating changed containers between runs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A detailed description of Docker Compose and its features can be found on the
    official page at: [https://docs.docker.com/compose/](https://docs.docker.com/compose/).
  prefs: []
  type: TYPE_NORMAL
- en: We present the Docker Compose tool starting with the installation process, going
    through the docker-compose.yml configuration file and the `docker-compose` command,
    to end up with the building and scaling features.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Docker Compose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The simplest method to install Docker Compose is to use the pip package manager:'
  prefs: []
  type: TYPE_NORMAL
- en: You can find the pip tool installation guide at [https://pip.pypa.io/en/stable/installing/](https://pip.pypa.io/en/stable/installing/),
    or for Ubuntu, at `sudo apt-get install python-pip`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'To check that Docker Compose is installed, we can run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Installation guidelines for all operating systems can be found at [https://docs.docker.com/compose/install/](https://docs.docker.com/compose/install/).
  prefs: []
  type: TYPE_NORMAL
- en: Defining docker-compose.yml
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `docker-compose.yml` file is used to define the configuration for containers,
    their relations, and runtime properties.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, when Dockerfile specifies how to create a single Docker image,
    then `docker-compose.yml` specifies how to set up the entire environment out of
    Docker images.
  prefs: []
  type: TYPE_NORMAL
- en: There are three versions of the `docker-compose.yml` file format. In this book,
    we use version 3, which is the most current and recommended. Read more at: [https://docs.docker.com/compose/compose-file/compose-versioning/](https://docs.docker.com/compose/compose-file/compose-versioning/).
  prefs: []
  type: TYPE_NORMAL
- en: The `docker-compose.yml` file has a lot of features and all of them can be found
    at the official page: [https://docs.docker.com/compose/compose-file/](https://docs.docker.com/compose/compose-file/).
    We will cover the most important ones in the context of the Continuous Delivery
    process.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start with an example and imagine that our calculator project uses the
    Redis server for caching. In this case, we need an environment with two containers, `calculator` and
    `redis`. In a new directory, let's create the `docker-compose.yml` file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The environment configuration is presented in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/dc2fb242-79fe-404e-bce6-e057c0f11a62.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s see the definition of the two containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**redis**: A container from the latest version of the `redis` image pulled
    from the official Docker Hub.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**calculator**: A container from the latest version of the `calculator` image
    built locally. It publishes the `8080` port to the Docker host (which is a substitute
    for the `-p` option of the `docker` command). The container links to the `redis` container,
    which means that they share the same network and the `redis` IP address is visible
    under the `redis` hostname from inside the `calculator` container.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we like a service to be addressed by a different hostname than its service
    name (for example, by redis-cache apart from redis), then we can create aliases
    using the links keyword.
  prefs: []
  type: TYPE_NORMAL
- en: Using the docker-compose command
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `docker-compose` command reads the definition file and creates the environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The command started two containers, `calculator` and `redis` in the background
    (`-d` option). We can check that the containers are running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The container names are prefixed with the project name `project`, which is
    taken from the name of the directory in which the `docker-compose.yml` file is
    placed. We could specify the project name manually using the `-p <project_name>` option.
    Since Docker Compose is run on top of Docker, we can also use the `docker` command
    to confirm that the containers are running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'When we''re done, we can tear down the environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The example is very simple, but the tool itself is extremely powerful. With
    a short configuration and a bunch of commands, we control the orchestration of
    all services. Before we use Docker Compose for acceptance testing, let''s look
    at two other Docker Compose features: building images and scaling containers.'
  prefs: []
  type: TYPE_NORMAL
- en: Building images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the preceding example, we had to first build the `calculator` image using
    the `docker build` command, and then it could be specified inside docker-compose.yml.
    There is also another approach to let Docker Compose build the image. In that
    case, we need to specify the `build` property instead of `image` in the configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s put the `docker-compose.yml` file in the calculator project''s directory.
    When Dockerfile and Docker Compose configurations are in the same directory, the
    former can look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The `docker-compose build` command builds the image. We can also ask Docker
    Compose to build images before running the containers with the use of the `docker-compose
    --build up` command.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Docker Compose provides the functionality to automatically create multiple
    instances of the same container. We can either specify the `replicas: <number>` parameter
    inside `docker-compose.yml` or use the `docker-compose scale` command.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, let''s run the environment again and replicate the `calculator` container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'We can check which containers are running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Five `calculator` containers are exactly the same, apart from the container
    ID, container name, and published port numbers.
  prefs: []
  type: TYPE_NORMAL
- en: 'They all use the same instance of the Redis container. We can now stop and
    remove all the containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Scaling containers is one of the most impressive Docker Compose features. With
    one command, we can scale up and down the number of clone instances. Docker Compose
    takes care of cleaning up the containers that are no longer used.
  prefs: []
  type: TYPE_NORMAL
- en: We have seen the most interesting functionalities of the Docker Compose tool.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will focus on how to use it in the context of automated
    acceptance testing.
  prefs: []
  type: TYPE_NORMAL
- en: Acceptance testing with Docker Compose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker Compose fits the acceptance testing process perfectly because it enables
    setting up the entire environment with one command. What's more, after the testing
    is performed, the environment can also be cleaned up with one command. If we decide
    to use Docker Compose on production, then the other benefit is that the acceptance
    test uses exactly the same configuration, tools, and commands as the released
    application.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see how to apply Docker Compose for the Jenkins acceptance testing stage,
    let''s continue the calculator project example and add the Redis-based caching
    to the application. Then, we will see two different approaches to run acceptance
    testing: the Jenkins-first method and the Docker-first method.'
  prefs: []
  type: TYPE_NORMAL
- en: Using a multi-container environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker Compose provides dependencies between the containers; in other words,
    it links one container to another container. Technically, this means that containers
    share the same network and that one container is visible from the other. To continue
    our example, we need to add this dependency in the code, and we will do this in
    a few steps.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a Redis client library to Gradle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the `build.gradle` file, add the following configuration to the `dependencies` section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: It adds the Java libraries that take care of the communication with Redis.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a Redis cache configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Add a new file `src/main/java/com/leszko/calculator/CacheConfig.java`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: This a standard Spring cache configuration. Note that for the Redis server address,
    we use the `redis` hostname that is automatically available thanks to the Docker
    Compose linking mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: Adding Spring Boot caching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When the cache is configured, we can finally add caching to our web service.
    In order to do this, we need to change the `src/main/java/com/leszko/calculator/Calculator.java` file
    to look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: From now on, the sum calculations are cached in Redis, and when we call the
    `/sum` endpoint of the `calculator` web service, it will first try to retrieve
    the result from the cache.
  prefs: []
  type: TYPE_NORMAL
- en: Checking the caching environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Assuming that we have our docker-compose.yml in the calculator project''s directory,
    we can now start the containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'We can check the port on which the calculator service is published:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'If we open the browser on `localhost:32783/sum?a=1&b=2`, the calculator service
    should reply `3` and, in the meantime, access the `redis` service and store the
    cached value there. To see that the cache value was really stored in Redis, we
    can access the `redis` container and look inside the Redis database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: The `docker-compose exec` command executed the `redis-cli` (the Redis client
    to browse its database content) command inside the `redis` container. Then, we
    can run `keys *` to print everything that is stored in Redis.
  prefs: []
  type: TYPE_NORMAL
- en: You can play more with the calculator application and open the browser with
    different values to see that the Redis service content increases. After this,
    it's important to tear down the environment with the `docker-compose down` command.
  prefs: []
  type: TYPE_NORMAL
- en: In the next sections, we will see two methods of acceptance tests for the multi-container
    project. Obviously, before we take any action on Jenkins, we need to commit and
    push all the changed files (including `docker-compose.yml`) to GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: Note that, for further steps, Docker Compose has to be installed on Jenkins
    executors.
  prefs: []
  type: TYPE_NORMAL
- en: Method 1 – Jenkins-first acceptance testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first method is to perform acceptance testing in the same way we did in
    the case of a single container application. The only difference is that now we
    have two containers running as presented in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/4d652e64-a061-46a8-ac71-e7dbaa9b6960.png)'
  prefs: []
  type: TYPE_IMG
- en: The `redis` container is not visible from a user perspective, so as a result,
    the only difference between single-container and multi-container acceptance testing
    is that we use the `docker-compose up` command instead of `docker run`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Other Docker commands can be also replaced with their Docker Compose equivalents:
    `docker-compose build` for `docker build` and `docker-compose push` for `docker
    push`. Nevertheless, if we build just one image, then leaving Docker commands
    is fine as well.'
  prefs: []
  type: TYPE_NORMAL
- en: Changing the staging deployment stage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s change the `Deploy to staging` stage to use Docker Compose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'We must change the clean up in exactly the same way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Changing the acceptance test stage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the purpose of using `docker-compose scale`, we didn't specify the port
    number under which our web service would be published. If we did, then the scaling
    process would fail because all clones would try to publish under the same port
    number. On the contrary, we let Docker choose the port. Therefore, we need to
    change the `acceptance_test.sh` script to first find what the port number is and
    then run `curl` with the correct port number.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s figure out how we found the port number:'
  prefs: []
  type: TYPE_NORMAL
- en: The `docker-compose port calculator 8080` command checks under which IP and
    port address the web service is published (it returns, for example, `127.0.0.1:57648`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`cut -d: -f2` selects only port (for example, for `127.0.0.1:57648`, it returns
    `57648`).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can push the change to GitHub and observe the Jenkins results. The idea is
    still the same as with the single-container application, set up the environment,
    run the acceptance test suite, and tear down the environment. Even though this
    acceptance testing method is good and works well, let's look at the alternative
    solution.
  prefs: []
  type: TYPE_NORMAL
- en: Method 2 – Docker-first acceptance testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the Docker-first approach, we create an additional `test` container that
    performs testing from inside the Docker host, as presented in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/78c8fd68-b33a-41f8-9d5a-a8ae5998f5aa.png)'
  prefs: []
  type: TYPE_IMG
- en: This approach facilitates the acceptance test script in terms of retrieving
    the port number and can be easily run without Jenkins. It's also much more in
    the Docker style.
  prefs: []
  type: TYPE_NORMAL
- en: The drawback is that we need to create a separate Dockerfile and Docker Compose
    configuration for the purpose of testing.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Dockerfile for acceptance test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will start by creating a separate Dockerfile for acceptance testing. Let''s
    create a new directory `acceptance` in the calculator project and a Dockerfile
    inside:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: It creates an image that runs the acceptance test.
  prefs: []
  type: TYPE_NORMAL
- en: Creating docker-compose.yml for acceptance test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the same directory, let''s create `docker-compose-acceptance.yml` to provide
    the testing orchestration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'It creates a new container that is linked to the container being tested: `calculator`.
    What''s more, internally it''s always 8080 so that eliminates the need for the
    tricky part of port finding.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating an acceptance test script
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The last missing part is the test script. In the same directory, let''s create
    the `test.sh` file that represents the acceptance test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: It's very similar to the previous acceptance test script, the only difference
    is that we can address the calculator service by the `calculator` hostname and
    that the port number is always `8080`. Also, in this case, we wait inside the
    script, not in the Jenkinsfile.
  prefs: []
  type: TYPE_NORMAL
- en: Running the acceptance test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can run the test locally using the Docker Compose command from the root
    project directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The command uses two Docker Compose configurations to run the `acceptance` project.
    One of the started containers should be called `acceptance_test_1` and be interested
    in its result. We can check its logs with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The log shows that the `curl` command has been successfully called. If we want
    to check whether the test succeeded or failed, we can check the exit code of the
    container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The `0` exit code means that the test succeeded. Any code other than `0` would
    mean that the test failed. After the test is done, we should, as always, tear
    down the environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Changing the acceptance test stage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As the last step, we can add the acceptance test execution to the pipeline.
    Let''s replace the last three stages in Jenkinsfile with one new **Acceptance
    test** stage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, we first build the `test` service. There is no need to build the
    `calculator` image; it''s already done by the previous stages. In the end, we
    should clean up the environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: After adding this to Jenkinsfile, we're done with the second method. We can
    test this by pushing all the changes to GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing method 1 and method 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To sum up, let's compare both solutions. The first approach is the real black-box
    testing from the user perspective in which Jenkins plays the role of a user. The
    advantage is that it's very close to what will be done in production; in the end,
    we will access containers via its Docker host. The second approach tests the application
    from the inside of another container. The solution is somehow more elegant and
    can be run locally in a simple way; however, it requires more files to create
    and does not call the application via its Docker host like it will be later done
    in production.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we step away from Docker and Jenkins and take a closer
    look at the process of writing the acceptance tests themselves.
  prefs: []
  type: TYPE_NORMAL
- en: Writing acceptance tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So far, we used the `curl` command to perform a suite of acceptance tests.
    That is obviously a considerable simplification. Technically speaking, if we write
    a REST web service, then we could write all black-box tests as a big script with
    a number of "curl" calls. This solution would be, however, very difficult to read,
    understand, and maintain. What''s more, the script would be completely incomprehensible
    by non-technical, business-related users. How to address this issue and create
    tests with a good structure, readable by users, and meet its fundamental goal:
    automatically checking if the system is as expected? I will answer this question
    throughout this section.'
  prefs: []
  type: TYPE_NORMAL
- en: Writing user-facing tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Acceptance tests are written with users and should be comprehensible to users.
    This is why the choice of a method for writing them depends on who the customer
    is.
  prefs: []
  type: TYPE_NORMAL
- en: For example, imagine a purely technical person. If you write a web service that
    optimizes the database storing, and your system is used only by other systems
    and read only by other developers, then your tests can be expressed in the same
    way as unit tests. As a rule, the test is good if understood by both, developer
    and user.
  prefs: []
  type: TYPE_NORMAL
- en: 'In real life, most software is written to deliver a specific business value,
    and that business value is defined by non-developers. Therefore, we need a common
    language to collaborate. On one side, there is the business who understands what
    is needed but not how to do it; on the other side, the development team who knows
    how but doesn''t know what. Luckily, there are a number of frameworks that help
    to connect these two worlds, for instance, Cucumber, FitNesse, JBehave, Capybara,
    and many more. They differ from each other, and each of them may be a subject
    for a separate book; however, the general idea of writing acceptance tests is
    the same and can be presented in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/8b572c5e-b2b1-4f86-90b2-a2d60f6f42fc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The **Acceptance Criteria** are written by users (or a product owner as their
    representative) with the help of developers. They are usually written in the form
    of the following scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Developers write the testing implementation called **fixtures** or **step definitions** that
    integrates the human-friendly DSL specification with the programming language.
    As a result, we have an automated test that can be well-integrated into the Continuous
    Delivery pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Needless to add, writing acceptance tests is a continuous agile process, not
    a waterfall one. It requires constant collaboration during which the test specifications
    are improved and maintained by both, developers and business.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of an application with a user interface, it can be tempting to perform
    the acceptance testing directly via the interface (for example, by recording Selenium
    scripts); however, this approach when not done properly can lead to tests that
    are slow and tightly coupled to the interface layer.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see how writing acceptance tests look in practice and how to bind them
    to the Continuous Delivery pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Using the acceptance testing framework
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s use the Cucumber framework and create an acceptance test for the calculator
    project. As previously described, we will do this in three steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating acceptance criteria
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating step definitions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running an automated acceptance test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating acceptance criteria
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s put the business specification in `src/test/resources/feature/calculator.feature`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: This file should be created by users with the help of developers. Note that
    it is written in a way that non-technical people can understand it.
  prefs: []
  type: TYPE_NORMAL
- en: Creating step definitions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next step is to create the Java bindings so that the feature specification
    would be executable. In order to do this, we create a new file `src/test/java/acceptance/StepDefinitions.java`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Each line (`Given`, `When`, and `Then`) from the feature specification file
    is matched by regular expressions with the corresponding method in the Java code.
    The wildcards `(.*)` are passed as parameters. Note that the server address is
    passed as the Java property `calculator.url`. The method performs the following
    actions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`i_have_two_numbers`: Saves parameters as fields'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`the_calculator_sums_them`: Calls the remote calculator service and stores
    the result in a field'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`i_receive_as_a_result`: Asserts that the result is as expected'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running an automated acceptance test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To run an automated test, we need to make a few configurations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Add Java cucumber libraries**: In the `build.gradle` file, add the following
    code to the `dependencies` section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '**Add Gradle target**: In the same file, add the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: This splits the tests into unit (run with `./gradlew test`) and acceptance (run
    with `./gradlew acceptanceTest`).
  prefs: []
  type: TYPE_NORMAL
- en: '**Add JUnit runner**: Add a new file `src/test/java/acceptance/AcceptanceTest.java`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: This is the entry point to the acceptance test suite.
  prefs: []
  type: TYPE_NORMAL
- en: 'After this configuration, if the server is running on the localhost, we can
    test it by executing the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Obviously, we can add this command to our `acceptance_test.sh` instead of the
    `curl` command. This would make the Cucumber acceptance test run in the Jenkins
    pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Acceptance test-driven development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Acceptance tests, like most aspects of the Continuous Delivery process, are
    less about technology and more about people. The test quality depends on, of course,
    the engagement of users and developers, but also, what is maybe less intuitive,
    the time when the tests are created.
  prefs: []
  type: TYPE_NORMAL
- en: The last question to ask is, during which phase of the software development
    life cycle should the acceptance tests be prepared? Or to rephrase it, should
    we create acceptance tests before or after writing the code?
  prefs: []
  type: TYPE_NORMAL
- en: 'Technically speaking, the result is the same; the code is well-covered with
    both, unit and acceptance tests. However, it''s tempting to consider writing tests
    first. The idea of TDD (test-driven development) can be well adapted for acceptance
    testing. If unit tests are written before the code, the result code is cleaner
    and better structured. Analogously, if acceptance tests are written before the
    system feature, the resulting feature corresponds better to the customer''s requirements.
    This process, often called acceptance test-driven development, is presented in
    the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/432d2a13-c759-4399-b9c4-452689af60fe.png)'
  prefs: []
  type: TYPE_IMG
- en: Users, with developers, write the acceptance criteria specification in the human-friendly
    DSL format. Developers write the fixtures and the tests fail. Then, the feature
    development starts using the TDD methodology internally. After the feature is
    completed, the acceptance test should pass, and this is a sign that the feature
    is completed.
  prefs: []
  type: TYPE_NORMAL
- en: A very good practice is to attach the Cucumber feature specification to the
    request ticket in the issue tracking tool (for example, JIRA) so that the feature
    would be always requested together with its acceptance test. Some development
    teams take an even more radical approach and refuse to start the development process
    if no acceptance tests are prepared. There is a lot of sense in that, after all, *how
    can you develop something that the client can't test?*
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We covered a lot of new material throughout this chapter, so to better understand,
    we recommend doing the exercises and creating your own project with acceptance
    tests:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a Ruby-based web service `book-library` to store books:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The acceptance criteria is delivered in the form of the following Cucumber
    feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Write step definitions for the Cucumber test
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: Write the web service (the simplest is to use the Sinatra framework: [http://www.sinatrarb.com/](http://www.sinatrarb.com/),
    but you can also use Ruby on Rails).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The book should have the following attributes: name, author, and ISBN.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The web service should have the following endpoints:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: POST "`/books/`" to add a book
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GET "`books/<isbn>`" to retrieve the book
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The data can be stored in the memory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the end, check if the acceptance test is green.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Add "book-library" as a Docker image to the Docker registry:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an account on Docker Hub.
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
- en: Create Dockerfile for the application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build the Docker image and tag it according to the naming convention.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Push the image to Docker Hub.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Create the Jenkins pipeline to build Docker image, push it to the Docker registry,
    and perform acceptance testing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a `"Docker build"` stage.
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: Create the `Docker login` and `Docker push` stages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a `test` container that performs acceptance testing and use Docker Compose
    to perform the test.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add an `Acceptance test` stage to the pipeline.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run the pipeline and observe the result.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, you learned how to build a complete and functional acceptance
    test stage, which is an essential part of the Continuous Delivery process. The
    key takeaway from the chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Acceptance tests can be difficult to create because they combine technical challenges
    (application dependencies, environment set up) with personal challenges (developers-business
    collaboration).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Acceptance testing frameworks provide a way to write tests in a human-friendly
    language that makes them comprehensible to non-technical people.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker registry is an artifact repository for Docker images.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker registry fits well with the Continuous Delivery process because it provides
    a way to use exactly the same Docker image throughout the stages and environments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Compose orchestrates a group of Docker container interacting together.
    It can also build images and scale containers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Compose can help with setting up a complete environment before running
    a suite of acceptance tests.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Acceptance tests can be written as a Docker image, and Docker Compose can run
    the complete environment together with the tests and provide the results.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next chapter, we will cover the missing stages necessary to complete
    the Continuous Delivery pipeline.
  prefs: []
  type: TYPE_NORMAL
