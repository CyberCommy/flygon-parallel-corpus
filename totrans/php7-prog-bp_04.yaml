- en: Chapter 4. Build a Simple Blog with Search Capability using Elasticsearch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will create a simple blog that can create and delete posts.
    Then we will work on adding some features to our blog such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Implement a very simple blog with CRUD and admin features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Work and install Elasticsearch and Logstash
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Try out the PHP client of Elasticsearch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn to build a tool for working with Elasticsearch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build a cache for searches to our database
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build a chart based on our Elasticsearch information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating the CRUD and admin system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, let's build the SQL of our posts. The database table should contain at
    the very least the post title, post content, post date, and modified and published
    dates.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what the SQL should look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now let's create a function to read the data. A typical blog site has comments
    and some additional metadata for SEO related to the blog post. But in this chapter,
    we won't be creating this part. Anyway, it should be fairly trivial to add a table
    relating to comments data and to have data about SEO metadata about each post
    in another table.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by creating the admin system. We need to log in, so we''ll have
    to create a simple login-logout script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: When you log in to `admin.php`, you set the sessions and are then redirected
    to the CRUD page.
  prefs: []
  type: TYPE_NORMAL
- en: 'The script for the admin CRUD page is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding script, we simply defined some functions that will handle the
    CRUD operations for us. To display the data, we just simply loop through the database
    and output it in a table.
  prefs: []
  type: TYPE_NORMAL
- en: 'The edit and delete pages, which are the scripts needed for a user interface
    and functions to edit or delete the posts, are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`edit.php`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s create the actual functionality for deleting the post. Following is
    how `delete.php` would look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Our logger for PHP, Monolog, will add the posts to the Elasticsearch using the
    Logstash plugin for Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: We'll set up a Logstash plugin, which first checks if the document exists and,
    if not, then inserts it.
  prefs: []
  type: TYPE_NORMAL
- en: To update Elasticsearch, we'll need to perform an **upsert**, which will update
    the same record if it exists, and if it does not exist, it will create a new one.
  prefs: []
  type: TYPE_NORMAL
- en: Also, we've implemented a way to delete the post from being visible in our CRUD,
    but not actually delete it from the database, as we'll need it for retrieval purposes.
  prefs: []
  type: TYPE_NORMAL
- en: For every action that needs to be done, we simply use the `$_GET['id']` to determine
    what we are going to do when that is clicked.
  prefs: []
  type: TYPE_NORMAL
- en: 'Like any blog, we need a front page for the user to display the posts that
    are available to read:'
  prefs: []
  type: TYPE_NORMAL
- en: '`index.php`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we make extensive use of shorthand opening `php` tags
    so that we can focus on the page layout. Notice how it weaves in and out of PHP
    mode, but it looks like we are just using a template, meaning we can see the general
    outline of the HTML markup without getting too much into the details of the PHP
    code.
  prefs: []
  type: TYPE_NORMAL
- en: Seeding the post table
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Without any data, our blog is useless. Therefore, for demonstration purposes,
    we'll just use a seeder script to automatically populate our table with data.
  prefs: []
  type: TYPE_NORMAL
- en: Let's use a popular library for generating fake content, **Faker**, which is
    available at [https://github.com/fzaninotto/Faker](https://github.com/fzaninotto/Faker).
  prefs: []
  type: TYPE_NORMAL
- en: With Faker, all you have to do is load it by providing the required path to
    its `autoload.php` file and load it using composer (`composer require fzaninotto/faker`).
  prefs: []
  type: TYPE_NORMAL
- en: 'The complete script for generating fake content is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Now let's move on to getting acquainted with Elasticsearch, the database search
    engine for our blog posts.
  prefs: []
  type: TYPE_NORMAL
- en: What is Elasticsearch?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Elasticsearch** is a search server. It''s a full-text search engine that
    comes with an HTTP web interface and schema-free JSON documents. What this means
    is that we store new searchable data by using JSON. The API to enter these documents
    uses the HTTP protocol. In this chapter, we will learn how to use PHP and build
    a rich search engine that can do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Set up the Elasticsearch PHP client
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add search data to Elasticsearch for indexing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn how to use keywords for relevance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cache our search results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use Elasticsearch with Logstash to store apache logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parse XML for storage into Elasticsearch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing Elasticsearch and the PHP client
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Creating the web interface for consumption of Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: As far as you need to know, Elasticsearch just needs to be installed by simply
    using the latest source code of Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: 'The installation instructions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://www.elastic.co/](https://www.elastic.co/) and download the source
    file that's related to your computer system, whether it's a Mac OSX, a Linux,
    or a Windows machine.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After downloading the file to your computer, you should run the setup installation
    notes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For example, for Mac OSX and Linux operating systems, you can do the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install Java 1.8.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Download Elasticsearch through curl (in the command line):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Extract the archive and change directory into it:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Start it up:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'An alternative way to install Elasticsearch for Mac OSX is using homebrew,
    which is available at [http://brew.sh/](http://brew.sh/) . Then, install it by
    using brew with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: For Windows operating systems, you just need to click through the wizard installation
    program, as shown in the following screenshot:![Installing Elasticsearch and the
    PHP client](graphics/image_04_001.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once that is installed, you also need to install the **Logstash agent**. The
    Logstash agent is in charge of sending data to Elasticsearch from various input
    sources.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can download it from the Elasticsearch website and follow the installation
    instructions for your computer system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For Linux, you can download a `tar` file and then you just have the other way
    for Linux, that is to use the package manager, which is either `apt-get` or `yum`,
    depending on your flavor of Linux.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You can test Elasticsearch by installing **Postman** and doing a `GET request`
    to `http://localhost:9200`:'
  prefs: []
  type: TYPE_NORMAL
- en: Install Postman by opening Google Chrome and visiting [https://www.getpostman.com/](https://www.getpostman.com/).
    You can install it on Chrome by going to add-ons and searching for Postman.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once Postman is installed, you can register or skip registration:![Installing
    Elasticsearch and the PHP client](graphics/image_04_002.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now try doing a `GET request` to `http://localhost:9200`:![Installing Elasticsearch
    and the PHP client](graphics/image_04_003.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The next step is to try out the PHP client library for Elasticsearch in your
    composer. Following is how to do that:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, include Elasticsearch in your `composer.json` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Get composer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Instantiate a new client by including it in your project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s try indexing a document. To do so, let''s create a PHP file to use
    the PHP client as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also retrieve that document by creating a script with the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'If we''re performing a search, the code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: In a nutshell, the Elasticsearch PHP client makes it easier to insert, search,
    and get a document from Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: Building a PHP Elasticsearch tool
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The aforementioned functionality can be used to create a PHP-backed user interface
    to insert, query, and search for documents using the Elasticsearch PHP client.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a simple bootstrap (an HTML CSS framework) form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This is what the form should look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Building a PHP Elasticsearch tool](graphics/image_04_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'When the user submits the details of the content, we''ll need to catch the
    content, keywords, or tags that the user has inputted. The PHP script that will
    enter the inputs into MySQL and then into our script, which will push it onto
    our Elasticsearch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s try to post this document to Elasticsearch as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Adding documents to our Elasticsearch
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Elasticsearch uses indexes to store each data point into its database. From
    our MySQL database, we need to post the data into Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: Let's discuss how indexing in Elasticsearch actually works. What makes it faster
    than conventional search by MySQL is that it searches the index instead.
  prefs: []
  type: TYPE_NORMAL
- en: How does indexing work in Elasticsearch? It uses the **Apache Lucene** to create
    something called an **inverted index**. An inverted index means that it looks
    up the search terms without having to scan every single entry. It basically means
    that it has a lookup table that lists all the words ever entered the system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an overview of the architecture of the ELK stack:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Adding documents to our Elasticsearch](graphics/image_04_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding diagram, we can see that **INPUT SOURCES**, usually the logs
    or some other data source, goes into **Logstash**. From **Logstash**, it then
    goes into **Elasticsearch**.
  prefs: []
  type: TYPE_NORMAL
- en: Once the data reaches **Elasticsearch**, it goes through some tokenizing and
    filtering. **Tokenizing** is the process of dissecting strings into different
    parts. **Filtering** is when some terms are sorted into separate indexes. For
    example, we may have an Apache log index, and then also have another input source,
    such as **Redis**, pushing into another searchable index.
  prefs: []
  type: TYPE_NORMAL
- en: The searchable index is the reversed index we mentioned previously. A searchable
    index is basically made searchable by storing each term and referring to their
    original content into an index. It's similar to what is done in an indexed database.
    It is the same process when we create primary keys and use it as the index to
    search entire records.
  prefs: []
  type: TYPE_NORMAL
- en: You can have many nodes performing this indexing in a cluster, all handled by
    the Elasticsearch engine. In the preceding diagram, the nodes are labeled **N1**
    to **N4**.
  prefs: []
  type: TYPE_NORMAL
- en: Querying Elasticsearch
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We now understand each part, so how do we query Elasticsearch? First, let's
    get introduced to Elasticsearch. When you start running Elasticsearch, you should
    send an HTTP request to `http://localhost:9200`.
  prefs: []
  type: TYPE_NORMAL
- en: We can do this using the Elasticsearch web API, which allows us to use RESTful
    HTTP requests to the Elasticsearch server. This RESTful API is the only way to
    insert records into Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Logstash
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Logstash is simply the central logging system where all the messages going to
    Elasticsearch will pass through.
  prefs: []
  type: TYPE_NORMAL
- en: 'To set up Logstash, follow the guide that''s available on the Elasticsearch
    website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.elastic.co/guide/en/logstash/current/getting-started-with-logstash.html](https://www.elastic.co/guide/en/logstash/current/getting-started-with-logstash.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Elasticsearch and Logstash work together to get different types of indexed logs
    into Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: We need to create something called a **transport** or middleware between the
    two data points. To do so, we need to set up Logstash. It is known as the **ingestion
    workhorse** for Elasticsearch and much more. It is a data collection engine that
    pipelines data from data source to the destination, which is Elasticsearch. Logstash
    is basically like a simple data pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: We will create a cronjob, which  is basically a background task, that will add
    new entries from our post table and put them into Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: Unix and Linux users who are familiar with the concept of a pipe, | , will be
    familiar with what a pipeline does.
  prefs: []
  type: TYPE_NORMAL
- en: Logstash simply transforms our raw log messages into a format called  **JSON**.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**JSON**, also known as **JavaScript Object Notation**, is a popular format
    for transferring data between web services. It is lightweight, and many programming
    languages, including PHP, have a way to encode and decode JSON-formatted messages.'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the Logstash configuration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The input part of a Logstash configuration is concerned with reading and parsing
    log data correctly. It consists of the input data source and the parser to use.
    Here is a sample configuration where we will read from a `redis` input source:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: But first, to be able to push to `redis`, we should install and use `phpredis`,
    an extension library that allows PHP to insert data into `redis`.
  prefs: []
  type: TYPE_NORMAL
- en: Installing PHP Redis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Installing PHP Redis should be simple. It's available in most package repositories
    for Linux platforms. You can read the documentation on how to install it at [https://github.com/phpredis/phpredis](https://github.com/phpredis/phpredis)
    .
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have it installed, you can test that your PHP Redis installation is
    working by creating the following script and running it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we're able to start a new Redis connection and from
    there set a key called `random` to a number between `5000` and `6000`. Finally,
    we echo out the data that we've just entered by calling `echo $redis->get('random')`.
  prefs: []
  type: TYPE_NORMAL
- en: With that in place, let's create the real PHP code using the logging library
    for PHP, called **Monolog**, to store our logs in Redis.
  prefs: []
  type: TYPE_NORMAL
- en: Let's create a `composer.json` that the logging project will use.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the terminal, let''s run the initialize composer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: It will interactively ask some questions after which it should create a `composer.json`
    file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now install Monolog by typing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s set up the PHP code that will read from our MySQL database and then
    push it over to Elasticsearch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we've created a `redisHandler` with the name of the logs
    to be called `phplogs`. We then set the `LogstashFormatter` instance to use the
    application name `my_app`.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of the script, we create a new `logger` instance, connect it to the
    `redisHandler`, and call the `info()` method of the `logger` to log the data.
  prefs: []
  type: TYPE_NORMAL
- en: Monolog separates the responsibilities of the formatter from the actual logging.
    The `logger` is responsible for creating the messages, and the Formatter formats
    the messages into the appropriate format so that Logstash can understand it. Logstash,
    in turn, pipes it to Elasticsearch, where the data about the log is indexed and
    is stored in the Elasticsearch index for querying later.
  prefs: []
  type: TYPE_NORMAL
- en: That's the wonderful thing about Elasticsearch. As long as you have Logstash,
    you can choose from different input sources for Logstash to process and Elasticsearch
    will do its job of saving the data when Logstash pushes to it.
  prefs: []
  type: TYPE_NORMAL
- en: Encoding and decoding JSON messages
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that we know how to work with the Monolog library, we need to integrate
    it into our blog application. We'll do so by creating a cronjob that will check
    for new blog posts for that day and store them in Elasticsearch through the use
    of a PHP script.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s create a folder called `server_scripts` where we put all our
    cronjobs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, here is our code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Using Logstash, we can read from our `redis` data and let it do its work, which
    would then process it and output it with the following output plugin code for
    Logstash:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Storing Apache logs in Elasticsearch
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Monitoring logs is an important aspect of any web application. Most critical
    systems have what is known as a dashboard, and that is exactly we will build in
    this segment with PHP.
  prefs: []
  type: TYPE_NORMAL
- en: As a bonus to this chapter, let's talk about another logging topic, server logs.
    Sometimes we want to be able to determine the performance of the server at a certain
    time.
  prefs: []
  type: TYPE_NORMAL
- en: Another thing you can do with Elasticsearch is to store Apache logs. For our
    application, we can add this so that we know about our users a little bit more.
  prefs: []
  type: TYPE_NORMAL
- en: This could be useful, for example, if we're interested in monitoring the browser
    a user is using and where users are coming from when they access our site.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do so, we just have to set up some configuration using the Apache input
    plugin as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: A **Kibana** dashboard may be created when you install Kibana from Elasticsearch;
    however, it requires end users to already know how to use the tool to create various
    queries.
  prefs: []
  type: TYPE_NORMAL
- en: However, there is a need to make it simpler for upper management to view the
    data without having to know how to create Kibana dashboards.
  prefs: []
  type: TYPE_NORMAL
- en: For our end users to not have to learn how to use Kibana and create dashboards,
    we will simply query the **ILog** information when the dashboard page is requested.
    For the charting library, we will use a popular library known as **Highcharts**.
    To get the information, however, we will need to create a simple query that will
    return some information to us in JSON format.
  prefs: []
  type: TYPE_NORMAL
- en: Handle the Apache logs, we can create it using PHP Elasticsearch client library.
    It's a simple client library that allows us to query Elasticsearch for information
    that we need, including the number of hits.
  prefs: []
  type: TYPE_NORMAL
- en: We will create a simple histogram for our website to show the number of accesses
    that are logged in our database.
  prefs: []
  type: TYPE_NORMAL
- en: For example, we'll use the PHP Elasticsearch SDK to query Elasticsearch and
    display the Elasticsearch results.
  prefs: []
  type: TYPE_NORMAL
- en: We also have to make the histogram dynamic. Basically, when the user wants to
    select between certain dates, we should be able to set up Highcharts to just get
    the data points and create a graph. If you haven't checked out Highcharts, please
    refer to [http://www.highcharts.com/](http://www.highcharts.com/) .
  prefs: []
  type: TYPE_NORMAL
- en: '![Storing Apache logs in Elasticsearch](graphics/image_04_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Getting filtered data to display with Highcharts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Like any chart user, we sometimes require the ability to filter down whatever
    we see in our graph. Instead of relying on Highcharts to give us controls to filter
    down our data, we should be able to do the filtering by changing the data that
    Highcharts will render.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following Highcharts code, we are adding the following container divider
    for our page; first, we get the data from our Elasticsearch engine using JavaScript:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: This is done is using the filter command of JavaScript and then parsing that
    data into our Highcharts graph. You'll also need to use underscore for the filtering
    function, which will help sort out which data we want to present to the user.
  prefs: []
  type: TYPE_NORMAL
- en: Let's first build the form to filter our Highcharts histogram.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what the HTML code for the search filter in the CRUD view will look
    like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: To enable quick re-rendering of our graph, we have to attach a listener using
    plain old JavaScript every time the filter button is clicked and then simply erase
    the information of the `div` element that contains our Highcharts graph.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following JavaScript code will update the filter using jQuery and underscore
    and the same code in the first bar chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we've included `jquery` and underscore libraries. When
    the button is clicked to focus on some dates, we set `$_GET['date']` through the
    form and then PHP gets the information using a simple trick where we re-render
    the `div` containing the graph by simply flushing the `ihtml` elements inside
    it, and then asking Highcharts to re-render the data.
  prefs: []
  type: TYPE_NORMAL
- en: To make this a little cooler, we can use a CSS animation effect so it looks
    like we're focusing a camera.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be done using the jQuery CSS transform techniques, and then resizing
    it back to normal and reloading a new graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Now we've learned how to filter using JavaScript and allow filtering of the
    JSON data using the filter style. Take note that filter is a relatively new JavaScript
    function; it only got introduced with  **ECMAScript 6**. We've used it to create
    the dashboard that upper management needs to be able to generate reports for their
    own purposes.
  prefs: []
  type: TYPE_NORMAL
- en: We can use the underscore library, which has the filter function.
  prefs: []
  type: TYPE_NORMAL
- en: We'll just load the latest logs that are in Elasticsearch, and then, if we want
    to perform a search, we'll create a way to filter and specify what data to search
    in the logs.
  prefs: []
  type: TYPE_NORMAL
- en: Let's create the Logstash configuration for Apache's logs to be grokked by Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: All we need to do is point the input Logstash configuration to our Apache logs
    location (usually a file in the `/var/log/apache2` directory).
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the basic Logstash configuration for Apache, which reads the Apache
    access log file at `/var/log/apache2/access.log`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: It uses something called a grok filter that matches anything that resembles
    an Apache log format and matches the timestamp to the `dd/MMM/yyyy:HH:mm:ss Z` date
    format.
  prefs: []
  type: TYPE_NORMAL
- en: If you think of Elasticsearch as the end of the rainbow and Apache logs as the
    start of the rainbow, then Logstash is like the rainbow that transports the logs
    from both ends into a format that Elasticsearch can understand.
  prefs: []
  type: TYPE_NORMAL
- en: '**Grokking** is the term used to describe reformatting a message format into
    something that Elasticsearch can interpret. This just means that it will search
    for a pattern and filter match for that pattern in particular, it will look up
    the log''s timestamp and message and other attributes in JSON, which is what Elasticsearch
    then stores in its database.'
  prefs: []
  type: TYPE_NORMAL
- en: Dashboard app for viewing Elasticsearch logs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's now create a dashboard for our blog that will allow us to see the data
    that we have in Elasticsearch, both posts and Apache logs. We'll use the PHP Elasticsearch
    SDK to query Elasticsearch and display the Elasticsearch results.
  prefs: []
  type: TYPE_NORMAL
- en: We'll just load the latest logs that are in Elasticsearch, and then, if we want
    to perform a search, we'll create a way to filter and specify what data to search
    in the logs.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what the search filter form will look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Dashboard app for viewing Elasticsearch logs](graphics/image_04_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In `search.php`, we''ll create a simple form for searching values in Elasticsearch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: When the user clicks on **Submit**, we will then show the results to the user.
  prefs: []
  type: TYPE_NORMAL
- en: Our form should simply show us what records we have for that day for both the
    Apache logs and the blog posts.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is how we query `ElasticSearch` for that information in the command line
    using curl:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we''ll get a JSON response from Elasticsearch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use a REST client (a way to query RESTful API''s in Firefox) as well
    to query the database just specify the `GET` method and the path and set the `q`
    variable in the URL to the parameters you want to search:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Dashboard app for viewing Elasticsearch logs](graphics/image_04_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Simple search engine with result caching
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To install the PHP Redis, visit [https://github.com/phpredis/phpredis](https://github.com/phpredis/phpredis)
    .
  prefs: []
  type: TYPE_NORMAL
- en: 'Every time the user searches, we can save their recent searches in Redis and
    just present those results if they already exist. The implementation might looks
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Redis is a simple dictionary. It stores a key and the value of that key in its
    database. In the preceding code, we use it to store a reference to the user's
    search results so that next time the same search is performed, we can just pull
    what we have from the Redis data.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding code, we converted the search term into a hash so that it can
    be easily identified as the same query that came through and it can be stored
    easily as the key (which should be one string only, no spaces allowed). If after
    hashing we find the key in Redis, then we get it from Redis instead of fetching
    it from the database.
  prefs: []
  type: TYPE_NORMAL
- en: Redis can expire keys by saving the key using the `$redis->setEx` method, which
    allows us to store the key and expire it after *X* number of seconds. In this
    case, we're storing it for 3,600 seconds, which is equivalent to an hour.
  prefs: []
  type: TYPE_NORMAL
- en: Cache basics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The concept of a cache is to return the already searched items back to the user
    so that for other users who are searching for the same exact search results, the
    application should no longer need to do a full database fetch from the MySQL database.
  prefs: []
  type: TYPE_NORMAL
- en: The bad thing with having a cache is that you have to perform cache invalidation.
  prefs: []
  type: TYPE_NORMAL
- en: Cache invalidation of Redis data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Cache invalidation** is when you need to expire and delete the cache data.
    This is because your cache may no longer be real time after a while. Of course,
    after invalidation, you need to renew the data in the cache, which happens when
    there is a new request to the data. The cache invalidation process can take one
    of the following three methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Purge** is when we remove content from the cache data right away.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Refresh** just means get new data and overwrite the already existing data.
    This means that even though there is a match in the cache, we will refresh that
    match with the new information fresh from wherever it comes from.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ban** is basically adding previously cached content to a ban list. When another
    client fetches the same information and, upon checking the blacklist, if it already
    exists, the cached content just gets updated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can run a cronjob continuously in the background that will update every cache
    result with new results for that search.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what the background PHP script that runs every 15 minute might look
    like in crontab:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'To get Logstash to put data in Redis, we just need to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'This is how the PHP script that deletes data from the cache would work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding script, we basically check the `searchDate` searched earlier,
    and if we have it, we set it to expire.
  prefs: []
  type: TYPE_NORMAL
- en: If it also appears in the `previousResults` array, we give that to the user;
    otherwise, we do a new `redis->get` command to get the results for that searched
    date.
  prefs: []
  type: TYPE_NORMAL
- en: Using browser localStorage as cache
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another option for cache storage is to save it in the client browser itself.
    The technology is known as **localStorage**.
  prefs: []
  type: TYPE_NORMAL
- en: We can use it as a simple cache for the user and store the search results, and
    if the user wants to search for the same thing, we just check the localStorage
    cache.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`localStorage` can only store 5 MB of data. But this is quite a lot considering
    that a regular text file is just a few kilobytes.'
  prefs: []
  type: TYPE_NORMAL
- en: We can make use of the `elasticsearch.js` client instead of the PHP client to
    make requests to our Elasticsearch. The browser-compatible version can be downloaded
    from [https://www.elastic.co/guide/en/elasticsearch/client/javascript-api/current/browser-builds.html](https://www.elastic.co/guide/en/elasticsearch/client/javascript-api/current/browser-builds.html)
    .
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also use Bower to install the `elasticsearch.js` client:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'For our purpose, we can take advantage of the jQuery Build by creating a client
    using jQuery:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: We should now be able to use JavaScript to populate the `localStorage`.
  prefs: []
  type: TYPE_NORMAL
- en: Since we are just querying and displaying on the client side, it's a perfect
    match!
  prefs: []
  type: TYPE_NORMAL
- en: Take note that we might not be able to log the data that was searched for by
    using a client-side script. However, we could save the search query history as
    a model containing the items keys that were searched for.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic JavaScript `searchQuery` object would look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'We can test whether the client works by running the following JavaScript file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The results could be cached into `localStorage` by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: We'll populate the results with data we find from `elasticsearch` and then just
    check if the same query was done earlier.
  prefs: []
  type: TYPE_NORMAL
- en: We also need to keep the data fresh. Let's hypothesize that it takes about 15
    minutes before a user gets bored and would refresh the page to try to see new
    information.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the same manner, we check whether the search result have been displayed
    in the past:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Now, whenever we expire the search criteria, say after about 15 minutes, we
    will simply clear the cache and put in the new search results that Elasticsearch
    finds.
  prefs: []
  type: TYPE_NORMAL
- en: Working with streams
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here, we will take advantage of PHP's Monolog library and then stream the data
    instead of pushing complete strings. The nice thing about working with streams
    is that they can easily pipe into Logstash and, in turn, store it into Elasticsearch
    as indexed data. Logstash also has features for creating data streams and streaming
    the data.
  prefs: []
  type: TYPE_NORMAL
- en: We can directly input our data without even using Logstash, using something
    that is known as streams. For more information on streams, refer to [http://php.net/manual/en/book.stream.php](http://php.net/manual/en/book.stream.php)
    .
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, for example, is a way to push some data to Elasticsearch: `http://localhost/dev/streams/php_input.php`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'In `php_input`, we can put the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: We'll be getting `Hello World&foo=bar&name=John`, which means that PHP was able
    to get the very first string as a stream using the PHP input stream.
  prefs: []
  type: TYPE_NORMAL
- en: To play around with PHP streams, let's create a stream using PHP manually. PHP
    developers usually have some experience working with stream data already when
    working with output buffering.
  prefs: []
  type: TYPE_NORMAL
- en: The idea with output buffering is to collect the stream until it's complete
    and then show it to the user.
  prefs: []
  type: TYPE_NORMAL
- en: This is especially useful when the stream isn't finished yet and we need to
    wait for the ending character for the data to be completely transferred.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can push streams into Elasticsearch! This can be done using the Logstash
    input plugin to handle streams. This is how PHP can output to a stream:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Storing and searching XML documents using PHP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can also work with XML documents and insert them into Elasticsearch. To do
    so, we can transform the data into JSON and then push the JSON into Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you can check out the following XML to JSON converter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to check that the XML has been converted correctly to JSON, check
    out the **XML TO JSON Converter** tool at [http://codebeautify.org/xmltojson](http://codebeautify.org/xmltojson)
    ; from there, you can easily check out how to export an XML to JSON:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Storing and searching XML documents using PHP](graphics/image_04_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Using Elasticsearch to search a social network database
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we'll simply use our knowledge to apply it to an existing social
    network built with PHP.
  prefs: []
  type: TYPE_NORMAL
- en: Let's pretend we have users who want to be able to search their social feed.
    Here's where we build a full-blown auto-dropdown search system.
  prefs: []
  type: TYPE_NORMAL
- en: Every time the user posts, we need to be able to store all the data in Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: However, in our search queries, we will match search results to the actual word
    that the user fetched. If it doesn't match the query in each, character-by-character,
    we won't display it.
  prefs: []
  type: TYPE_NORMAL
- en: 'We first need to build the feed. The SQL schema will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '`Post_type` would handle the type of post—photo, video, link, or just plain
    text.'
  prefs: []
  type: TYPE_NORMAL
- en: So, if the user added a type of picture, it would be saved as an image type.
    And when a person searches for a post, they can filter by the type.
  prefs: []
  type: TYPE_NORMAL
- en: 'Every time users save a new photo, or a new post, we will also store the data
    into Elasticsearch, which will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we need to make an input form when the user inserts the preceding new posting.
    We''ll just build the one that can upload a photo with a title or just add text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The `submit_status.php` script will have the following code to save into the
    database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Displaying randomized search engine results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The preceding feed database table is the table that everyone will post to. We
    need to enable randomly showing what's on the feed. We can insert posts into feeds
    instead of storing.
  prefs: []
  type: TYPE_NORMAL
- en: By searching from Elasticsearch and randomly rearranging the data, we can make
    our searches more fun. In a way, this makes sure that people using our social
    network will be able to see random posts in their feed.
  prefs: []
  type: TYPE_NORMAL
- en: To search from the posts, instead of doing a direct query to SQL, we will search
    the Elasticsearch database for the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s figure out how to insert the data into an Elasticsearch index
    called `posts`. With Elasticsearch open, we simply do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: We will probably also want to search our friends, and if we have a ton of friends,
    they won't all be on the feed. So, we just need another index to search called
    the `friends` index.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code, when run in the Linux command line, will allow us to create
    a new `friends` index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'So, we can now store data about our friends using the `friends` index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: We'll usually look for friends of friends and we'll, of course, show that to
    our user if there are any friends with the search query.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this chapter, we discussed how to create a blog system, experimented with
    Elasticsearch, and were able to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a simple blog application and store data in MySQL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Install Logstash and Elasticsearch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Practice working with Elasticsearch using curl
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Get data into Elasticsearch using the PHP Client
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chart information (hits) from Elasticsearch using Highcharts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the `elasticsearch.js` client to query Elasticsearch for information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use Redis and localStorage in the browser to work with caching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
