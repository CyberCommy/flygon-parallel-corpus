- en: Utility Classes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Converting between different time units using `std::ratio`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Converting between absolute and relative times with `std::chrono`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Safely signalizing failure with `std::optional`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying functions on tuples
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quickly composing data structures with `std::tuple`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replacing `void*` with `std::any` for more type safety
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storing different types with `std::variant`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatically handling resources with `std::unique_ptr`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatically handling shared heap memory with `std::shared_ptr`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dealing with weak pointers to shared objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simplifying resource handling of legacy APIs with smart pointers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sharing different member values of the same object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating random numbers and choosing the right random number engine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating random numbers and letting the STL shape specific distributions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter is dedicated to utility classes that are very useful for solving
    very specific tasks. Some of them are indeed so useful that we will most probably
    see them extremely often in any C++ program snippet in the future or have at least
    already seen them sprinkled over all other chapters in this book.
  prefs: []
  type: TYPE_NORMAL
- en: The first two recipes are about measuring and taking the *time*. We will also
    see how to convert between different time units and how to jump between points
    in time.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we will have a look at the `optional`, `variant`, and `any` types (which
    all came with C++14 and C++17) as well as some `tuple` tricks in another five
    recipes.
  prefs: []
  type: TYPE_NORMAL
- en: Since C++11, we also got sophisticated smart pointer types, namely `unique_ptr`,
    `shared_ptr`, and `weak_ptr`, which are an enormously effective help regarding
    *memory management*, which is why we will have a dedicated look at them in five
    recipes.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we will have a panoramic view of the library parts of the STL that
    are about generating *random numbers*. Apart from learning about the most important
    characteristics of the STL's random engines, we will also learn how to apply shaping
    to random numbers in order to get distributions that fit our actual needs.
  prefs: []
  type: TYPE_NORMAL
- en: Converting between different time units using std::ratio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since C++11, the STL contains some new types and functions for taking, measuring,
    and displaying time. This part of the library exists in the `std::chrono` namespace
    and has some sophisticated details.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will concentrate on measuring time spans and how to convert
    the result of the measurement between units, such as seconds, milliseconds, and
    microseconds. The STL provides facilities, which enable us to define our own time
    units and convert between them seamlessly.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will write a little *game* that prompts the user to enter
    a specific word. The time that the user needs to type this word into the keyboard
    is measured and displayed in multiple time units:'
  prefs: []
  type: TYPE_NORMAL
- en: 'At first, we need to include all the necessary headers. For reasons of comfort,
    we declare that we use the `std` namespace by default:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The `chrono::duration` as a type for time durations usually refers to multiples
    or fractions of seconds. All the STL time duration units refer to integer typed
    duration specializations. In this recipe, we are going to specialize on `double`.
    In the recipe after this one, we will concentrate more on the existing time unit
    definitions that are already built into the STL:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'One millisecond is a fraction of a second, so we define this unit by referring
    to seconds. The `ratio_multiply` template parameter applies the STL-predefined
    `milli` factor to `seconds::period`, which gives us the fraction we want. The
    `ratio_multiply` template is basically a meta programming function for multiplying
    ratios:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s the same thing with microseconds. While a millisecond is a `milli`-fraction
    of a second, a microsecond is a `micro`-fraction of a second:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we are going to implement a function, which reads a string from user input
    and measures how long it took the user to type the input. It takes no arguments
    and returns us the user input string as well as the elapsed time, bundled in a
    pair:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to take the time from the beginning of the period during which user
    input occurs and after it. Taking a time snapshot looks like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The actual capturing of user input takes place now. If we are not successful,
    we just return a default-initialized tuple. The caller will see that he got an
    empty input string:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'In the case of success, we continue by taking another time snapshot. Then we
    return the input string and the difference between both time points. Note that
    both are absolute time points, but by calculating the difference, we get a duration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s implement the actual program now. We loop until the user enters the
    input string correctly. In every loop step, we ask the user to please enter the
    string `"C++17"` and, then, call our `get_input` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we check the input. If the input is empty, we interpret this as a request
    to exit the whole program:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'If the user correctly types `"C++17"`, we express our congratulations and then
    print the time the user needed to type the word correctly. The `diff.count()`
    method returns the number of seconds as a floating point number. If we had used
    the original STL `seconds` duration type, then we would have got a *rounded* integer
    value, not a fraction. By feeding the milliseconds or microseconds `constructor`
    with our `diff` variable before calling `count()`, we get the same value transformed
    to a different unit:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'If the user has a typo in the input, we let him try again:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Compiling and running the program leads to the following output. At first,
    with a typo, the program repeatedly asks for the correct input word. After typing
    the word correctly, it displays how long it took us to type it in three different
    time units:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While this section is all about converting between different time units, we
    first had to choose one of the three available clock objects. There is generally
    the choice between `system_clock`, `steady_clock`, and `high_resolution_clock`
    in the `std::chrono` namespace. What are the differences between them? Let''s
    have a closer look:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Clock** | **Characteristics** |'
  prefs: []
  type: TYPE_TB
- en: '| `system_clock` | This represents the system-wide real-time "*wall*" clock.
    It is the right choice if we want to obtain the local time. |'
  prefs: []
  type: TYPE_TB
- en: '| `steady_clock` | This clock is promised to be *monotonic*. This means that
    it will never be set back by any amount of time. This can happen to other clocks
    when their time is corrected by minimal amounts, or even when the time is switched
    between winter and summer time. |'
  prefs: []
  type: TYPE_TB
- en: '| `high_resolution_clock` | This is the clock with the most fine-grained clock
    tick period the STL implementation can provide. |'
  prefs: []
  type: TYPE_TB
- en: Since we measured the time distance, or duration from one absolute point in
    time and the other absolute point in time (which we captured in the variables
    `tic` and `toc`), we are not interested if those points in time were globally
    skewed. Even if the clock was 112 years, 5 hours, 10 minutes, and 1 second (or
    whatever) late or ahead of time, then this does not make a difference on the *difference
    between* them. The only important thing is that after we save the time point `tic`
    and before we save the time point `toc`, the clock must not be micro-adjusted
    (which happens on many systems from time to time) because that would distort our
    measurement. For these requirements, `steady_clock` is the optimal choice. Its
    implementation can be based on the processor's timestamp counter, which always
    counts up monotonously since the system was started.
  prefs: []
  type: TYPE_NORMAL
- en: 'Okay, now with the right time object choice, we are able to save points in
    time via `chrono::steady_clock::now()`. The `now` function returns us a `chrono::time_point<chrono::steady_clock>`
    typed value. The difference between two such values (as in `toc - tic`) is a *time
    span*, or *duration* of type `chrono::duration`. As this is the central type of
    this section, this gets a little complicated now. Let''s have a closer look at
    the template type interface of `duration`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The parameters we can change are called `Rep` and `Period`. `Rep` is easy to
    explain: this is just the numeric variable type that is used to save the time
    value. For the existing STL time units, this is usually `long long int`. In this
    recipe, we chose `double`. Because of our choice, we can save time values in seconds
    by default and then convert them to milli- or microseconds. If we save the time
    duration of `1.2345` seconds in the `chrono::seconds` type, then it would be rounded
    to one full second. This way, we would have to save the time difference between
    `tic` and `toc` in `chrono::microseconds` and could then convert to less-fine-grained
    units. With our `double` choice for `Rep`, we can convert up and down and lose
    only a minimal amount of precision, which does not hurt in this example.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We used `Rep = double` for all our time units, so they differed only in our
    choice of the `Period` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: While `seconds` is the simplest unit to describe, as it works with `Period =
    ratio<1>`, the others have to be adjusted. As one millisecond is a thousandth
    of a second, we multiply the `seconds::period` (which is just a getter function
    to the `Period` parameter) with `milli`, which is a type alias for `std::ratio<1,
    1000>` (`std::ratio<a, b>` represents the fractional value `a/b`). The `ratio_multiply`
    type is basically a *compile time function*, which represents the type that results
    from multiplying one ratio type with another.
  prefs: []
  type: TYPE_NORMAL
- en: 'Maybe this sounds too complicated, so let''s have a look at an example: `ratio_multiply<ratio<2,
    3>, ratio<4, 5>>` results in `ratio<8, 15>` because `(2/3) * (4/5) = 8/15`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our resulting type definitions are equivalent to the following definitions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Having these types lined up, it is easy to convert between them. If we have
    a time duration `d` of type `seconds`, we can transform it to `milliseconds` just
    by feeding it through the constructor of the other type, that is, `milliseconds(d)`.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In other tutorials or books, you might run across `duration_cast` whenever time
    durations are transformed. If we have a duration value of type `chrono::milliseconds`
    and want to transform it to `chrono::hours`, for example, we do indeed need to
    write `duration_cast<chrono::hours>(milliseconds_value)` because these units depend
    on *integer* types. Transforming from fine-grained units to less-fine-grained
    units leads to *precision loss* in that case, which is why we need a `duration_cast`.
    For `double`- or `float`-based duration units, this is not needed.
  prefs: []
  type: TYPE_NORMAL
- en: Converting between absolute and relative times with std::chrono
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Until C++11, it was quite a hassle to take the wall clock time and *just print*
    it, because C++ did not have its own time library. It was always necessary to
    call functions of the C library, which looks very archaic, considering that such
    calls could be encapsulated nicely into their own classes.
  prefs: []
  type: TYPE_NORMAL
- en: Since C++11, the STL provides the `chrono` library, which makes time-related
    tasks much easier to implement.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we are going to take the local time, print it, and play around
    by adding different time offsets, which is a really comfortable thing to do with
    `std::chrono`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are going to save the current time and print it. Additionally, our program
    will add different offsets to the saved time point and print the resulting time
    points too:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The typical include lines come first; then, we declare that we use the `std`
    namespace by default:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We are going to print absolute time points. These will come along in the form
    of the `chrono::time_point` type template, so we will just overload the output
    stream operator for it. There are different ways to print the date and/or time
    part of a time point. We will just use the `%c` standard formatting. We could,
    of course, also print only the time, only the date, only the year, or whatever
    comes to our mind. All the conversions between the different types before we can
    finally apply `put_time` look a bit clunky, but we are only doing this once:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'There are already STL type definitions for `seconds`, `minutes`, `hours`, and
    so on. We will add the `days` type now. This is easy; we just have to specialize
    the `chrono::duration` template by referring to `hours` and multiply with `24`,
    because a full day has 24 hours:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to be able to express a duration in multiples of days in the most
    elegant way, we can define our own `days` literal operator. Now, we can write
    `3_days` to construct a value that represents three days:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'In the actual program, we will take a time snapshot, which we simply print
    afterward. This is very easy and comfortable because we already implemented the
    right operator overload for this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Having saved the current time in the `now` variable, we can add arbitrary durations
    to it and print those too. Let''s add 12 hours to the current time and print what
    time we will have in 12 hours:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'By declaring that we use the `chrono_literals` namespace by default, we unlock
    all the existing duration literals for hours, seconds, and so on. This way, we
    can elegantly print what time it was 12 hours and 15 minutes ago, or 7 days ago:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Compiling and running the program yields the following output. Because we used
    `%c` as the format string for time formatting, we get a pretty complete description
    in a specific format. By playing around with different format strings, we can
    get it in any format we like. Note that the time format is not 12 hours AM/PM
    but 24 hours because the app is run on a European system:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We obtained the current time point from `std::chrono::system_clock`. This STL
    clock class is the only one that can transform its time point values to a time
    structure that can be displayed as a human-readable time description string.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to print such time points, we implemented `operator<<` for output
    streams:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: What happens here first, is that we transform from `chrono::time_point<chrono::system_clock>`
    to `std::time_t`. Values of this type can be transformed to a local wall clock
    relevant time value, which we do with `std::localtime`. This function returns
    us a pointer to a converted value (don't worry about the maintenance of the memory
    behind this pointer; it is a static object not allocated on the heap), which we
    can now finally print.
  prefs: []
  type: TYPE_NORMAL
- en: The `std::put_time` function accepts such an object together with a time format
    string. `"%c"` displays a standard date-time string, such as `Sun Mar 12 11:33:40
    2017`. We could also have written `"%m/%d/%y"`; then the program would have printed
    the time in the format, `03/12/17`. The whole list of existing format string modifiers
    for time is very long, but it is nicely documented to its full extent in the online
    C++ reference.
  prefs: []
  type: TYPE_NORMAL
- en: Aside from printing, we also added time offsets to our time point. This is very
    easy because we can express time durations, such as *12 hours and 15 minutes*
    as `12h + 15min`. The `chrono_literals` namespace already provides handy type
    literals for hours (`h`), minutes (`min`), seconds (`s`), milliseconds (`ms`),
    microseconds (`us`), and nanoseconds (`ns`).
  prefs: []
  type: TYPE_NORMAL
- en: Adding such a duration value to a time point value creates a new time point
    value because these types have the right `operator+` and `operator-` overloads,
    which is why it is so simple to add and display offsets in time.
  prefs: []
  type: TYPE_NORMAL
- en: Safely signalizing failure with std::optional
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When a program communicates with the outside world and relies on values it gets
    from there, then all kinds of failures can happen.
  prefs: []
  type: TYPE_NORMAL
- en: 'This means that whenever we write a function that ought to return a value,
    but that can also possibly fail, then this must be reflected in some change of
    the function interface. We have several possibilities. Let''s see how we can design
    the interface of a function that will return a string, but that could also fail:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use a success-indicating return value and output parameters: `bool get_string(string&);`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Return a pointer (or a smart pointer) that can be set to `nullptr` if there
    is a failure: `string* get_string();`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Throw an exception in the case of failure and leave the function signature
    very simple: `string get_string();`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'All these approaches have different advantages and disadvantages. Since C++17,
    there is a new type that can be used to solve such a problem in a different way:
    `std::optional`. The notion of an optional value comes from purely functional
    programming languages (where they are sometimes called `Maybe` types) and can
    lead to very elegant code.'
  prefs: []
  type: TYPE_NORMAL
- en: We can wrap `optional` around our own types in order to signal *empty* or *erroneous*
    values. In this recipe, we will learn how to do that.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will implement a program that reads integers from the user
    and sums them up. Because the user can always input random things instead of numbers,
    we will see how `optional` can improve our error handling:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we include all the needed headers and declare that we use the `std`
    namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s define an integer type, which, *maybe,* contains a value. The `std::optional`
    type does exactly that. By wrapping any type into `optional`, we give it an additional
    possible state, which reflects that it currently has *no* value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'By having defined an optional integer type, we can express that a function
    that usually returns an integer can also possibly fail. If we take an integer
    from user input, this can possibly fail because the user might not always enter
    an integer even though we asked him to do so. Returning an optional integer is
    perfect in this case. If reading an integer succeeds, we feed it into the `optional<int>`
    constructor. Otherwise, we return a default constructed optional, which signals
    failure or emptiness:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'We can do more than returning integers from functions that can possibly fail.
    What if we calculate the sum of two optional integers? This can only lead to a
    real numeric sum if both the operands contain an actual value. In any other case,
    we return an empty optional variable. This function needs a little more explanation:
    by implicitly transforming the `optional<int>` variables, `a` and `b`, to boolean
    expressions (by writing `!a` and `!b`), we get to know whether they contain actual
    values. If they do, we can access them like pointers or iterators by simply dereferencing
    them with `*a` and `*b`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Adding a normal integer to an optional integer follows the same logic:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now write a program that does something with optional integers. We let
    the user enter two numbers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we add those input numbers and additionally add the value 10 to their
    sum. Since `a` and `b` are optional integers, `sum` will also be an optional integer
    type variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'If `a` and/or `b` do not contain a value, then `sum` cannot possibly contain
    a value either. The nice thing about our optional integers now is that we do not
    need to explicitly check `a` and `b`. What happens when we sum up empty optionals
    is perfectly sane and defined behavior because we defined `operator+` in a safe
    way for those types. This way, we can arbitrarily add many possibly empty optional
    integers, and we''ll only need to check the resulting optional value. If it contains
    a value, then we can safely access and print it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'If the user enters something non-numeric, we error out:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'That''s it. When we compile and run the program, we get the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Running the program again and entering something non-numeric yields the error
    message we prepared for this case:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Working with `optional` is generally very simple and convenient. If we want
    to attach the notion of possible failure or optionality to any type `T`, we can
    just wrap it into `std::optional<T>` and that's it.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever we get such a value from somewhere, we have to check whether it is
    in the empty state or whether it contains a real value. The `bool optional::has_value()`
    function does that for us. If it returns `true`, we may access the value. Accessing
    the value of an optional can be done with `T& optional::value()`.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of always writing `if (x.has_value()) {...}` and `x.value()`, we can
    also write `if (x) {...}` and `*x`. The `std::optional` type defines explicit
    conversion to `bool` and `operator*` in such a way that dealing with an optional
    type is similar to dealing with a pointer.
  prefs: []
  type: TYPE_NORMAL
- en: Another handy operator helper that is good to know is the `operator->` overload
    of `optional`. If we have a `struct Foo { int a; string b; }` type and want to
    access one of its members through an `optional<Foo>` variable, `x`, then we can
    write `x->a` or `x->b`. Of course, we should first check whether `x` actually
    has a value.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we try to access an optional value even though it does not have a value,
    then it will throw `std::logic_error`. This way, it is possible to mess around
    with a lot of optional values without always checking them. Using a `try-``catch`
    clause, we could write code in the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Another gimmick of `std::optional` is `optional::value_or`. If we want to take
    an optional's value and fall back to a default value if it is in the empty state,
    then this is of help. `x = optional_var.value_or(123)` does this job in one concise
    line, where `123` is the fallback default value.
  prefs: []
  type: TYPE_NORMAL
- en: Applying functions on tuples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since C++11, the STL provides `std::tuple`. This type allows us to sporadically
    *bundle* multiple values into a single variable and reach them around. The notion
    of tuples has been there for a long time in a lot of programming languages, and
    some recipes in this book are already devoted to this type because it is extremely
    versatile to use.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, we sometimes end up with values bundled up in a tuple and then need
    to call functions with their individual members. Unpacking the members individually
    for every function argument is very tedious (and error-prone if we introduce a
    typo somewhere). The tedious form looks like this: `func(get<0>(tup), get<1>(tup),
    get<2>(tup), ...);`.'
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, you will learn how to pack and unpack values to and from tuples
    in an elegant way, in order to call some functions that don't know about tuples.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are going to implement a program that packs and unpacks values to and from
    tuples. Then, we will see how to call functions that know nothing about tuples
    with values from tuples:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we include a lot of headers and declare that we use the `std` namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s first define a function that takes multiple parameters describing a
    student and prints them. A lot of legacy- or C-function interfaces look similar.:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'In the actual program, we define a tuple type on the fly and fill it with meaningful
    student data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to print such an object, we can decompose it to its individual members
    and call `print_student` with those individual variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s create a whole set of students in the form of an initializer list of
    student tuples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'We can still relatively comfortably print them all, but in order to decompose
    the tuple, we need to care how many elements such tuples have. If we have to write
    such code, then we will also have to restructure it in case the function call
    interface changes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'We can do better. Without even knowing the argument types of `print_student`
    or the number of members in a student tuple, we can directly forward the tuple''s
    content to the function using `std::apply`. This function accepts a function pointer
    or a function object and a tuple and then *unpacks* the tuple in order to call
    the function with the tuple members as parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'This also works nicely in a loop, of course:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Compiling and running the program shows that both ways work, as we assumed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `std::apply` is a compile-time helper that helps us work more agnostic about
    the types we handle in our code.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine we have a tuple `t` with the values `(123, "abc"s, 456.0)`. This tuple
    has the type, `tuple<int, string, double>`. Additionally, assume that we have
    a function `f` with the signature `int f(int, string, double)` (the types can
    also be references).
  prefs: []
  type: TYPE_NORMAL
- en: Then, we can write `x = apply(f, t)`, which will result in a function call,
    `x = f(123, "abc"s, 456.0)`. The `apply` method does even return to us what `f`
    returns.
  prefs: []
  type: TYPE_NORMAL
- en: Quickly composing data structures with std::tuple
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s have a look at a basic use case for tuples that we most probably already
    know. We can define a structure as follows, in order to just bundle some variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Instead of defining a structure as in the preceding example, we can also define
    a tuple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: We can access its items using the index number of the type from the type list.
    In order to access the first member of a tuple, `t`, we can use `std::get<0>(t)`
    to access the second member we write `std::get<1>`, and so on. If the index number
    is too large, then the compiler will even safely error out.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout the book, we have already used the decomposition capabilities of
    C++17 for tuples. They allow us to decompose a tuple quickly by just writing `auto
    [a, b, c] = some_tuple` in order to access its individual items.
  prefs: []
  type: TYPE_NORMAL
- en: Composing and decomposing single data structures are not the only things we
    can do with tuples. We can also concatenate or split tuples, or do all kinds of
    magic. In this recipe, we will play around with such capabilities in order to
    learn how to do it.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will write a program that can print any tuple on the fly.
    In addition to that, we will write a function that can *zip* tuples together:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to include a number of headers first and then we declare that we use
    the `std` namespace by default:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'As we will be dealing with tuples, it will be interesting to display their
    content. Therefore, we will now implement a very generic function that can print
    any tuple that consists of printable types. The function accepts an output stream
    reference `os`, which will be used to do the actual printing, and a variadic argument
    list, which carries all the tuple members. We decompose all the arguments into
    the first element and put it into the argument, `v`, and the rest, which is stored
    in the argument pack `vs...`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'If there are arguments left in the parameter pack, `vs`, these are printed
    interleaved with `", "` using the `initializer_list` expansion trick. You learned
    about this trick in the [Chapter 21](5eec7af8-298a-4292-b0a8-e0cbcf3d5c81.xhtml),
    *Lambda Expressions*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now print arbitrary sets of arguments by writing `print_args(cout, 1,
    2, "foo", 3, "bar")`, for example. But this has nothing to do with tuples yet.
    In order to print tuples, we overload the stream output operator `<<` for any
    case of tuples by implementing a template function that matches on any tuple specialization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Now it gets a little complicated. We first use a lambda expression that arbitrarily
    accepts many parameters. Whenever it is called, it prepends the `os` argument
    to those arguments and then calls `print_args` with the resulting new list of
    arguments. This means that a call to `capt_tup(...some parameters...)` leads to
    a `print_args(os, ...some parameters...)` call:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can do the actual tuple unpacking magic. We use `std::apply` to unpack
    the tuple. All values will be taken out of the tuple then and lined up as function
    arguments for the function that we provide as the first argument. This just means
    that if we have a tuple, `t = (1, 2, 3)`, and call `apply(capt_tup, t)`, then
    this will lead to a function call, `capt_tup(1, 2, 3)`, which in turn leads to
    the function call, `print_args(os, 1, 2, 3)`. This is just what we need. As a
    nice extra, we surround the printing with parentheses:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Okay, now we wrote some complicated code that will make our life much easier
    when we want to print a tuple. But we can do a lot more with tuples. Let''s, for
    example, write a function that accepts an iterable range, such as a vector or
    a list of numbers, as an argument. This function will then iterate over that range
    and then return us the *sum* of all the numbers in the range and bundle that with
    the *minimum* of all values, the *maximum* of all values, and the numeric *average*
    of them. By packing these four values into a tuple, we can return them as a single
    object without defining an additional structure type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: The `std::minmax_element` function returns us a pair of iterators that respectively
    point to the minimum and maximum values of the input range. The `std::accumulate`
    method sums up all the values in its input range. This is all we need to return
    the four values that fit in our tuple!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Before implementing the main program, we will implement one last magic helper
    function. I call it magic because it really looks complicated at first, but after
    understanding how it works, it will turn out as a really slick and nice helper.
    It will zip two tuples. This means that if we feed it a tuple, `(1, 2, 3)`, and
    another tuple, `(''a'', ''b'', ''c'')`, it will return a tuple `(1, ''a'', 2,
    ''b'', 3, ''c'')`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we arrived at the most complex lines of code of this recipe. We create
    a function object, `z`, which accepts an arbitrary number of arguments. It then
    returns another function object that captures all these arguments in a parameter
    pack, `xs`, but also accepts another arbitrary number of arguments. Let''s sink
    this in for a moment. Within this inner function object, we can access both lists
    of arguments in the form of the parameter packs, `xs` and `ys`. And now let''s
    have a look what we actually do with these parameter packs. The expression, `make_tuple(xs,
    ys)...`, groups the parameter packs item wise. This means that if we have `xs
    = 1, 2, 3` and `ys = ''a'', ''b'', ''c''`, this will result in a new parameter
    pack, `(1, ''a''), (2, ''b''), (3, ''c'')`. This is a comma-separated list of
    three tuples. In order to get them all grouped in *one* tuple, we use `std::tuple_cat`,
    which accepts an arbitrary number of tuples and repacks them into one tuple. This
    way we get a nice `(1, ''a'', 2, ''b'', 3, ''c'')` tuple:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The last step is unwrapping all the values from the input tuples, `a` and `b`,
    and pushing them into `z`. The expression, `apply(z, a)`, puts all the values
    from `a` into the parameter pack `xs`, and `apply(..., b)` puts all the values
    of `b` into the parameter pack `ys`. The resulting tuple is the large zipped one,
    which we return to the caller:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'We invested a considerable amount of lines into helper/library code. Let''s
    now finally put it to use. First, we construct some arbitrary tuples. The `student`
    contains ID, name, and GPA score of a student. The `student_desc` contains strings
    that describe what those fields mean in human-readable form. The `std::make_tuple`
    is a really nice helper because it automatically deduces the type of all the arguments
    and creates a suitable tuple type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s just print what we have. This is really simple because we just implemented
    the right `operator<<` overload for that:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also group both the tuples on the fly with `std::tuple_cat` and print
    them like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also create a new *zipped* tuple with our `zip` function and also print
    it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s not forget our `sum_min_max_avg` function. We create an initializer
    list that contains some numbers and feed it into this function. To make it a little
    bit more complicated, we create another tuple of the same size, which contains
    some describing strings. By zipping these tuples, we get a nice, interleaved output,
    as we will see when we run the program:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Compiling and running the program yields the following output. The first two
    lines are just the individual `student` and `student_desc` tuples. Line 3 is the
    tuple composition we got by using `tuple_cat`. Line 4 contains the zipped student
    tuple. In the last line, we see the sum, minimum, maximum, and average value of
    the numeric list we last created. Because of the zipping, it is really easy to
    see what each value means:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Some of the code in this section is admittedly complicated. We wrote an `operator<<`
    implementation for tuples, which looks very complex but supports all kinds of
    tuples that themselves consist of printable types. Then we implemented the `sum_min_max_avg`
    function, which just returns a tuple. Another very complicated thing to get our
    head around was the function `zip`.
  prefs: []
  type: TYPE_NORMAL
- en: The easiest part was `sum_min_max_avg`. The point about it is that when we define
    a function that returns an instance `tuple<Foo`, `Bar`, `Baz> f()`, we can just
    write `return {foo_instance, bar_instance, baz_instance};` in that function to
    construct such a tuple. If you have trouble understanding the STL algorithms we
    used in the `sum_min_max_avg` function, then you might want to have a look at
    the [Chapter 22](ab657908-ae5c-43bc-bcfb-701cfd3777d5.xhtml), *STL Algorithm Basics*
    of this book, where we already had a closer look at them.
  prefs: []
  type: TYPE_NORMAL
- en: 'The other code was so complicated that we dedicate the specific helpers their
    own subsections:'
  prefs: []
  type: TYPE_NORMAL
- en: operator<< for tuples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we even touched `operator<<` for output streams, we implemented the
    `print_args` function. Due to its variadic argument nature, it accepts any number
    and type of arguments, as long as the first one is an `ostream` instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: This function prints the first item, `v`, and then prints all the other items
    from the parameter pack, `vs`. We print the first item individually because we
    want to have all items interleaved with `", "` but we do not want this string
    leading or trailing the whole list (as in `"1, 2, 3, "` or `", 1, 2, 3"`). We
    learned about the `initializer_list` expansion trick in [Chapter 21](5eec7af8-298a-4292-b0a8-e0cbcf3d5c81.xhtml),
    *Lambda Expressions*, in the recipe *Calling multiple functions with the same
    input*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having that function lined up, we have everything we need in order to print
    tuples. Our `operator<<` implementation looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: The first thing we do is defining the function object, `capt_tup`. When we call
    `capt_tup(foo, bar, whatever)`, this results in the call, `print_args(**os,**
    foo, bar, whatever)`. The only thing this function object does is prepend the
    output stream object `os` to its variadic list of arguments.
  prefs: []
  type: TYPE_NORMAL
- en: Afterward, we use `std::apply` in order to unpack all the items from tuple `t`.
    If this step looks too complicated, please have a look at the recipe before this
    one, which is dedicated to demonstrating how `std::apply` works.
  prefs: []
  type: TYPE_NORMAL
- en: The zip function for tuples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `zip` function accepts two tuples, but looks horribly complicated, although
    it has a very crisp implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: In order to understand this code better, imagine for a moment that the tuple
    `a` carries the values, `1, 2, 3`, and tuple `b` carries the values, `'a', 'b',
    'c'`.
  prefs: []
  type: TYPE_NORMAL
- en: In such a case, calling `apply(z, a)` leads to a function call `z(1, 2, 3)`,
    which returns another function object that captures those values, `1, 2, 3`, in
    the parameter pack `xs`. When this function object is then called with `apply(z(1,
    2, 3), b)`, it gets the values, `'a', 'b', 'c'`, stuffed into the parameter pack,
    `ys`. This is basically the same as if we called `z(1, 2, 3)('a', 'b', 'c')` directly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Okay, now that we have `xs = (1, 2, 3)` and `ys = (''a'', ''b'', ''c'')`, what
    happens then? The expression `tuple_cat(make_tuple(xs, ys) ...)` does the following
    magic; have a look at the diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/54ce6577-8405-4849-a5bb-40c6235b6d5b.png)'
  prefs: []
  type: TYPE_IMG
- en: At first, the items from `xs` and `ys` are zipped together by interleaving them
    pairwise. This "pairwise interleaving" happens in the `make_tuple(xs, ys) ...`
    expression. This initially only leads to a variadic list of tuples with two items
    each. In order to get *one large* tuple, we apply `tuple_cat` on them and then
    we finally get a large concatenated tuple that contains all the members of the
    initial tuples in an interleaved manner.
  prefs: []
  type: TYPE_NORMAL
- en: Replacing void* with std::any for more type safety
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It can happen that we want to store items of *any* type in a variable. For such
    a variable, we then need to be able to check whether it contains *anything*, and
    if it does, we need to be able to distinguish *what* it contains. All this needs
    to happen in a type-safe manner.
  prefs: []
  type: TYPE_NORMAL
- en: In the past, we were basically able to store pointers to various objects in
    a `void*` pointer. A `void` typed pointer alone cannot tell us what kind of object
    it points to, so we would need to handcraft some kind of additional mechanism
    that tells us what to expect. Such code quickly leads to quirky looking and unsafe
    code.
  prefs: []
  type: TYPE_NORMAL
- en: Another addition of C++17 to the STL is the `std::any` type. It is designed
    to hold variables of any kind and provides facilities that enable for type-safe
    inspection and access to it.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will play around with this utility type in order to get a
    feeling of it.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will implement a function that tries to be able to print everything. It
    uses `std::any` as its argument type:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we include some necessary headers and declare that we use the `std`
    namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to reduce the number of angle bracket syntax in the following program,
    we define an alias for `list<int>`, which we will use later:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s implement a function that claims to be able to print anything. The promise
    is that it prints anything provided as an argument in the form of an `std::any`
    variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'The first thing we need to check is if the argument contains *anything* or
    if it is just an empty `any` instance. If it is empty, then there is no sense
    in trying to figure out how to print it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'If it is not empty, we can try to compare it with different types until we
    see a match. The first type to try is `string`. If it is a `string`, we can cast
    `a` to a `string` typed reference using `std::any_cast` and just print it. We
    put the string in quotes for cosmetic reasons:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'If it is not a `string`, it might be an `int`. In case this type matches, we
    can use `any_cast<int>` to obtain the actual `int` value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '`std::any` does not only work with such simple types as `string` and `int`.
    We can also put a whole map or list or whatever composed complex data structure
    into an `any` variable. Let''s see if the input is a list of integers, and if
    it is, we can just print it like we would print a list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'If none of these types match, we run out of type guesses. Let''s give up in
    that case and tell the user that we have no idea how to print this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'In the main function, we can now call this function with arbitrary types. We
    can call it with an empty `any` variable using `{}` or feed it with a string `"abc"`
    or an integer. Because `std::any` can be constructed from such types implicitly,
    there is no syntax overhead. We can even construct a whole list and throw it into
    this function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'If we are going to put objects that are really expensive to copy into an `any`
    variable, we can also perform an *in-place* construction. Let''s try this with
    our list type. The `in_place_type_t<int_list>{}` expression is an empty object
    that gives the constructor of `any` enough information to know what we are going
    to construct. The second parameter, `{1, 2, 3}`, is just an initializer list that
    will be fed to the `int_list` embedded in the `any` variable for construction.
    This way, we avoid unnecessary copies or moves:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Compiling and running the program yields the following output, which is just
    what we expected:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `std::any` type is similar in one regard to `std::optional`--it has a `has_value()`
    method that tells if an instance carries a value or not. But apart from that,
    it can contain literally *anything*, so it is more complex to handle compared
    with `optional`.
  prefs: []
  type: TYPE_NORMAL
- en: Before accessing the content of an `any` variable, we need to find out *what*
    type it carries and, then, *cast* it to that type.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finding out if an `any` instance holds a type `T` value can be done with a
    comparison: `x.type() == typeid(T)`. If this comparison results in `true`, then
    we can use `any_cast` to get at the content.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that `any_cast<T>(x)` returns a *copy* of the internal `T` value in `x`.
    If we want a *reference* in order to avoid copying of complex objects, we need
    to use `any_cast<T&>(x)`. This is what we did when we accessed the internal `string`
    or `list<int>` objects in this section's code.
  prefs: []
  type: TYPE_NORMAL
- en: If we cast an instance of `any` to the wrong type, it will throw an `std::bad_any_cast`
    exception.
  prefs: []
  type: TYPE_NORMAL
- en: Storing different types with std::variant
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are not only `struct` and `class` primitives in C++ that enable us to
    compose types. If we want to express that some variable can hold either some type
    `A` or a type `B` (or `C`, or whatever), we can use `union`. The problem with
    unions is that they cannot tell us they were actually initialized to which of
    the types that they can hold.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: If we call the `func` function with a union that was initialized to hold an
    integer via member `a`, there is nothing that prevents us from accessing it, as
    if it was initialized to store a pointer to a string via member `b`. All kinds
    of bugs can be spread from such code. Before we start to pack our union with an
    auxiliary variable that tells us to what it was initialized in order to gain some
    safety, we can directly use `std::variant`, which came with C++17.
  prefs: []
  type: TYPE_NORMAL
- en: The `variant` is kind of the *new-school*, type-safe, and efficient union type.
    It does not use the heap, so it is as space-efficient and time-efficient as a
    union-based handcrafted solution could be, so we do not have to implement it ourselves.
    It can store anything apart from references, arrays, or the `void` type.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will construct an example that profits from `variant` in
    order to get a feeling of how to use this cool new addition to the STL.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s implement a program that knows the types, `cat` and `dog`, and that
    stores a mixed list of cats and dogs without using any runtime polymorphy:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we include all the needed headers and define that we use the `std` namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we implement two classes that have similar functionality but are not
    related to each other in any other way, in contrast to classes that, for example,
    inherit from the same interface or a similar interface. The first class is `cat`.
    A `cat` object has a name and can say *meow*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'The other class is `dog`. A `dog` object does not say *meow* but *woof*, of
    course:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can define an `animal` type, which is just a type alias to `std::variant<dog,
    cat>`. This is basically the same as an old-school union but has all the extra
    features that `variant` provides:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'Before we write the main program, we implement two helpers first. One helper
    is an animal predicate. By calling `is_type<cat>(...)` or `is_type<dog>(...)`,
    we can find out if an animal variant instance holds a `cat` or a `dog`. The implementation
    just calls `holds_alternative`, which is a generic predicate function for variant
    types:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'The second helper is a structure that acts as a function object. It is a twofold
    function object because it implements `operator()` twice. One implementation is
    an overload that accepts dogs and the other accepts cats. For these types, it
    just calls the `woof` or the `meow` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s put these types and helpers to use. First, we define a list of `animal`
    variant instances and fill it with cats and dogs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we print the contents of the list three times, and each time in a different
    way. One way is using `variant::index()`. Because `animal` is an alias of `variant<dog,
    cat>`, a return value of `0` means that the variant holds a `dog` instance. Index
    `1` means it is a `cat`. The order of the types in the variant specialization
    is the key here. In the switch case block, we access the variant with `get<T>`
    in order to get the actual `cat` or `dog` instance inside:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'Instead of using the numeric index of the type, we can also explicitly ask
    for every type. The `get_if<dog>` returns a `dog`-typed pointer to the internal
    `dog` instance. If there is no `dog` instance inside, then the pointer is `null`.
    This way, we can try to get at different types until we finally succeed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'The last and most elegant way is `variant::visit`. This function accepts a
    function object and a variant instance. The function object must implement different
    overloads for all the possible types the variant can hold. We implemented a structure
    with the right `operator()` overloads before, so we can use it here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'At last, we will count the number of cats and dogs in the variant list. The
    `is_type<T>` predicate can be specialized on `cat` and `dog` and can then be used
    in combination with `std::count_if` to return us the number of instances of this
    type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'Compiling and running the program first yields the same list printed three
    times. After that, we see that the `is_type` predicates combined with `count_if`
    work just fine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `std::variant` type is kind of similar to `std::any` because both can hold
    objects of different types, and we need to distinguish at runtime what exactly
    they hold before we try to access their content.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, `std::variant` is different from `std::any` in the regard
    that we must declare what it shall be able to store in the form of a template
    type list. An instance of `std::variant<A, B, C>` *must* hold one instance of
    type `A`, `B`, or `C`. There is no possibility to hold *none* of them, which means
    that `std::variant` has no notion of *optionality*.
  prefs: []
  type: TYPE_NORMAL
- en: 'A variant of type, `variant<A, B, C>`, mimics a union type that could look
    like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: The problem with unions is that we need to build our own mechanisms to distinguish
    if it was initialized with an `A`, `B`, or `C` variable. The `std::variant` type
    can do this for us without much hassle.
  prefs: []
  type: TYPE_NORMAL
- en: In the code in this section, we used three different ways to handle the content
    of a variant variable.
  prefs: []
  type: TYPE_NORMAL
- en: The first way was the `index()` function of `variant`. For a variant type `variant<A,
    B, C>` it can return index `0` if it was initialized to hold an `A` type, or `1`
    for `B`, or `2` for `C`, and so on for more complex variants.
  prefs: []
  type: TYPE_NORMAL
- en: The next way is the `get_if<T>` function. It accepts the address of a variant
    object and returns a `T`-typed pointer to its content. If the `T` type is wrong,
    then this pointer will be a `null` pointer. It is also possible to call `get<T>(x)`
    on a variant variable in order to get a reference to its content, but if that
    does not succeed, this function throws an exception (before doing such `get`-casts,
    checking for the right type can be done with the Boolean predicate `holds_alternative<T>(x)`).
  prefs: []
  type: TYPE_NORMAL
- en: The last way to access the variant is the `std::visit` function. It accepts
    a function object and a `variant` instance. The `visit` function then checks of
    which type the content of the variant is and then calls the right `operator()`
    overload of the function object.
  prefs: []
  type: TYPE_NORMAL
- en: 'For exactly this purpose, we implemented the `animal_voice` type because it
    can be used in combination with `visit` and `variant<dog, cat>`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: The `visit`-way of accessing variants can be considered the most elegant one
    because the code sections that actually access the variant do not need to be hardcoded
    to the types the variant can hold. This makes our code easier to extend.
  prefs: []
  type: TYPE_NORMAL
- en: The claim that a `variant` type cannot hold *no* value was not completely true.
    By adding the `std::monostate` type to its type list, it can indeed be initialized
    to hold *no* value.
  prefs: []
  type: TYPE_NORMAL
- en: Automatically handling resources with std::unique_ptr
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since C++11, the STL provides smart pointers that really help keep track of
    dynamic memory and its disposal. Even before C++11, there was a class called `auto_ptr`
    that was already able to do automatic memory disposal, but it was easy to use
    the wrong way.
  prefs: []
  type: TYPE_NORMAL
- en: However, with the C++11-generation smart pointers, we seldom need to write `new`
    and `delete` ourselves, which is a really good thing. Smart pointers are a shiny
    example of automatic memory management. If we maintain dynamically allocated objects
    with `unique_ptr`, we are basically safe from memory leaks, because upon its destruction
    this class automatically calls `delete` on the object it maintains.
  prefs: []
  type: TYPE_NORMAL
- en: A unique pointer expresses ownership of the object it points to and follows
    its responsibility of freeing its memory again if it is no longer used. This class
    has the potential of relieving us forever from memory leaks (at least together
    with its companions `shared_ptr` and `weak_ptr`, but in this recipe, we solely
    concentrate on `unique_ptr`). And the best thing is that it imposes *no overhead*
    on space and runtime performance, compared with code with raw pointers and manual
    memory management. (Okay, it still sets its internal raw pointer to `nullptr`
    internally after destruction of the object it points to, which cannot always be
    optimized away. Most manually written code that manages dynamic memory does the
    same, though.)
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will a look at `unique_ptr` and how to use it.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will write a program that shows us how `unique_ptr` handles memory by creating
    a custom type that adds some debug messages upon its construction and destruction.
    Then, we will play around with unique pointers, maintaining dynamically allocated
    instances of it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we include the necessary headers and declare that we use the `std` namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'We are going to implement a little class for the object we are going to manage
    using `unique_ptr`. Its constructor and destructor print to the terminal, so we
    can see later when it is actually automatically deleted:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to see what limitations a function has that accepts unique pointers
    as arguments, we just implement one. It *processes* a Foo item by printing its
    name. Note that while unique pointers are smart, overhead-free, and comfortably
    safe, they can still be `null`. This means that we still have to check them before
    we dereference them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'In the main function, we will open another scope, create two `Foo` objects
    on the heap, and manage both with unique pointers. We create the first one explicitly
    on the heap using the `new` operator and then put it into the constructor of the
    `unique_ptr<Foo>` variable, `p1`. We create the unique pointer, `p2`, by calling
    `make_unique<Foo>` with the arguments we would otherwise directly give the constructor
    of `Foo`. This is the more elegant way because we can use auto type deduction
    and the first time we can access the object, it is already managed by `unique_ptr`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'After we left the scope, both objects are destructed immediately and their
    memory is released to the heap. Let''s have a look at the `process_item` function
    and how to use it with `unique_ptr` now. If we construct a new `Foo` instance,
    managed by a `unique_ptr` in the function call, then its lifetime is reduced to
    the scope of the function. When `process_item` returns, the object is destroyed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'If we want to call `process_item` with an object that already existed before
    the call, then we need to *transfer ownership* because that function takes a `unique_ptr`
    by value, which means that calling it would lead to a copy. But `unique_ptr` cannot
    be copied, it can only be *moved*. Let''s create two new `Foo` objects and move
    one into `process_item`. By looking at the terminal output later, we will see
    that `foo2` is destroyed when `process_item` returns because we transferred ownership
    to it. `foo3` will continue living until the main function returns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s compile and run the program. At first, we see the constructor and destructor
    calls of `foo` and `bar`. They are indeed destroyed just after the program leaves
    the additional scope. Note that the objects are destroyed in the opposite order
    of their creation. The next constructor line comes from `foo1`, which is the item
    we created during the `process_item` call. It is indeed destroyed immediately
    after the function call. Then we created `foo2` and `foo3`. `foo2` is destroyed
    immediately after the `process_item` call where we transferred the ownership.
    The other item, `foo3`, in comparison, is destroyed after the last code line in
    the main function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Handling heap objects with `std::unique_ptr` is really simple. After we initialized
    a unique pointer to hold a pointer to some object, there is *no way* we can accidentally
    *forget* about deleting it on some code path.
  prefs: []
  type: TYPE_NORMAL
- en: If we assign some new pointer to a unique pointer, then it will always first
    delete the old object it pointed to and then store the new pointer. On a unique
    pointer variable, `x`, we can also call `x.reset()` to just delete the object
    it points to immediately without assigning a new pointer. Another equivalent alternative
    to reassigning via `x = new_pointer` is `x.reset(new_pointer)`.
  prefs: []
  type: TYPE_NORMAL
- en: There is indeed one single way to release an object from the management of `unique_ptr`
    without deleting it. The `release` function does that, but using this function
    is not advisable in most situations.
  prefs: []
  type: TYPE_NORMAL
- en: Since pointers need to be checked before they are actually dereferenced, they
    overload the right operators in a way that enables them to mimic raw pointers.
    Conditionals like `if (p) {...}` and `if (p != nullptr) {...}` perform the same
    way as we would check a raw pointer.
  prefs: []
  type: TYPE_NORMAL
- en: Dereferencing a unique pointer can be done via the `get()` function, which returns
    a raw pointer to the object that can be dereferenced, or directly via `operator*`,
    which again mimics raw pointers.
  prefs: []
  type: TYPE_NORMAL
- en: One important characteristic of `unique_ptr` is that its instances cannot be
    *copied* but can be *moved* from one `unique_ptr` variable to the other. This
    is why we had to move an existing unique pointer into the `process_item` function.
    If we were able to copy a unique pointer, then this would mean that the object
    being pointed to is owned by *two* unique pointers, although this contradicts
    the design of a *unique* pointer that is the *only* *owner* (and later the "*deleter"*)
    of the underlying object.
  prefs: []
  type: TYPE_NORMAL
- en: Since there are data structures, such as `unique_ptr` and `shared_ptr`, there
    is rarely any reason to create heap objects directly with `new` and `delete` them
    manually. Use such classes wherever you can! Especially `unique_ptr` imposes *no*
    overhead at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: Automatically handling shared heap memory with std::shared_ptr
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last recipe, we learned how to use `unique_ptr`. This is an enormously
    useful and important class because it helps us manage dynamically allocated objects.
    However, it can only handle *single* ownership. It is not possible to let *multiple*
    objects own the same dynamically allocated object because, then, it would be unclear
    who has to delete it later.
  prefs: []
  type: TYPE_NORMAL
- en: The pointer type, `shared_ptr`, was designed for specifically this case. Shared
    pointers can be *copied* arbitrarily often. An internal reference counting mechanism
    tracks how many objects are still maintaining a pointer to the payload object.
    Only the last shared pointer that goes out of scope will call `delete` on the
    payload object. This way, we can be sure that we do not get memory leaks because
    objects are deleted automatically after use. At the same time, we can be sure
    that they are not deleted too early, or too often (every created object must only
    be deleted *once*).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this recipe, you will learn how to use `shared_ptr` to automatically manage
    dynamic objects that are shared between multiple owners and see what''s different
    when comparing it with `unique_ptr`:'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are going to write a program that is similar to the program we wrote in
    the `unique_ptr` recipe in order to get insights into the usage and principles
    of `shared_ptr`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'At first, we just include the necessary headers and declare that we use the
    `std` namespace by default:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we define a little helper class, which helps us see when instances of
    it are actually created and destroyed. We will manage instances of it with `shared_ptr`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we implement a function that takes a shared pointer to a `Foo` instance
    *by value*. Accepting shared pointers as arguments by value is more interesting
    than accepting them by reference because in this case, they need to be copied,
    which changes their internal reference counter, as we will see:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: 'In the main function, we declare an empty shared pointer. By default constructing
    it, it is effectively a `null` pointer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we open another scope and instantiate two `Foo` objects. We create the
    first one using the `new` operator and then feed it into the constructor of a
    new `shared_ptr`. Then we create the second instance using `make_shared<Foo>`,
    which creates a `Foo` instance from the parameters we provide. This is the more
    elegant method because we can use auto type deduction and the object is already
    managed when we have the chance to access it for the first time. This is very
    similar to the `unique_ptr` recipe at this point:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: Since shared pointers can be shared, they need to track how many parties share
    them. This is done with an internal reference counter or *use* counter. We can
    print its value using `use_count`. The value is exactly `1` at this point because
    we did not copy it yet. We can copy `f1` to `fa`, which increases the use counter
    to `2`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: 'While we''re leaving the scope, the shared pointers `f1` and `f2` are destroyed.
    The `f1` variable''s reference counter is decremented to `1` again, making `fa`
    the only owner of the `Foo` instance. While `f2` is destroyed, its reference counter
    is decremented to `0`. In this case, the `shared_ptr` pointer''s destructor will
    call `delete` on this object, which disposes of it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s call the `f` function with our shared pointer in two different
    ways. At first, we call it naively by copying `fa`. The `f` function will then
    print that the reference counter has the value `2`. In the second call to `f`,
    we move the pointer into the function. This makes `f` the only owner of the object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: 'After `f` is returned, the `Foo` instance is destroyed immediately because
    we do not have ownership of it any longer. Therefore, all the objects are already
    destroyed when the main function returns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: 'Compiling and running the program yields the following output. In the beginning,
    we see `"foo"` and `"bar"` created. After we copied `f1` (which points to `"foo"`),
    its reference counter was incremented to `2`. While leaving the scope, `"bar"`
    is destroyed because the shared pointer to it being the subject of destruction
    is the only owner. The single `1` in the output is the reference count of `fa`,
    which is now the only owner of `"foo"`. Afterward, we called function `f` twice.
    On the first call, we copied `fa` into it, which gave it a reference counter of
    `2` again. On the second call, we moved it into `f`, which did not alter its reference
    counter. Moreover, because `f` is the only owner of `"foo"` at this point, the
    object is destroyed immediately after `f` leaves the scope. This way, no other
    heap objects are destroyed after the last print line in `main`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When constructing and deleting objects, `shared_ptr` works basically like `unique_ptr`.
    Constructing shared pointers works similarly as creating unique pointers (although
    there is a function `make_shared` that creates shared objects as a pendant to
    `unique_ptr` pointer's `make_unique` function).
  prefs: []
  type: TYPE_NORMAL
- en: The major difference from `unique_ptr` is that we can copy the `shared_ptr`
    instances because shared pointers maintain a so-called *control block* together
    with the object they manage. The control block contains a pointer to the payload
    object and a reference counter or *use* counter. If there are `N` number of `shared_ptr`
    instances pointing to the object, then the use counter also has the value `N`.
    Whenever a `shared_ptr` instance is destructed, then its destructor decrements
    this internal use counter. The last shared pointer to such an object will hit
    the condition that it decrements the use counter to `0` during its destruction.
    This is, then, the shared pointer instance, which calls the `delete` operator
    on the payload object! This way, we can't possibly suffer from memory leaks because
    the object's use count is automatically tracked.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate this a bit more, let''s have a look at the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4d305c80-4368-4efd-945c-8a4debac7d23.png)'
  prefs: []
  type: TYPE_IMG
- en: In step 1, we have two `shared_ptr` instances managing an object of type `Foo`.
    The use counter is at value `2`. Then, `shared_ptr2` is destroyed, which decrements
    the use counter to `1`. The `Foo` instance is not destroyed yet because there
    is still the other shared pointer. In step 3, the last shared pointer is destroyed
    too. This leads to the use counter being decremented to `0`. Step 4 happens immediately
    after step 3\. Both the control block and the instance of `Foo` are destroyed
    and their memory is released to the heap.
  prefs: []
  type: TYPE_NORMAL
- en: Equipped with `shared_ptr` and `unique_ptr`, we can automatically deal with
    most dynamically allocated objects without having to worry about memory leaks
    any longer. There is, however, one important caveat to consider--imagine we have
    two objects on the heap that contain shared pointers to each other, and some other
    shared pointer points to one of them from somewhere else. If that external shared
    pointer goes out of scope, then both objects still have the use counters with
    *nonzero* values because they reference *each other*. This leads to a *memory
    leak*. Shared pointers should not be used in this case because such cyclic reference
    chains prevent the use counter of such objects to ever reach `0`.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Look at the following code. What if you are told that it contains a potential
    *memory leak*?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: '"Where is the memory leak?", one might ask, since the newly allocated objects
    `A` and `B` are immediately fed into `shared_ptr` types, and *then* we are safe
    from memory leaks.'
  prefs: []
  type: TYPE_NORMAL
- en: Yes, it is true that we are safe from memory leaks as soon as the pointers are
    captured in the `shared_ptr` instances. The problem is a bit fiddly to grasp.
  prefs: []
  type: TYPE_NORMAL
- en: When we call a function, `f(x(), y(), z())`, the compiler needs to assemble
    code that calls `x()`, `y()`, and `z()` first so that it can forward their return
    values to `f`. What gets us very bad in combination with the example from before
    is that the compiler can execute these function calls to `x`, `y`, and `z` in
    *any* order.
  prefs: []
  type: TYPE_NORMAL
- en: Looking back at the example, what happens if the compiler decides to structure
    the code in a way where at first `new A{}` is called, then `other_function()`,
    and then `new B{}` is called, before the results of these functions are finally
    fed into `function`? If `other_function()` throws an exception, we get a memory
    leak because we still have an unmanaged object, `A`, on the heap because we just
    allocated it but did not have a chance to hand it to the management of `shared_ptr`.
    No matter how we catch the exception, the handle to the object is *gone* and we
    *cannot delete* it!
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two easy ways to circumvent this problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: This way, the objects are already managed by `shared_ptr`, no matter who throws
    what exception afterward.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with weak pointers to shared objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the recipe about `shared_ptr`, we learned how useful and easy to use shared
    pointers are. Together with `unique_ptr`, they pose an invaluable improvement
    for code that needs to manage dynamically allocated objects.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever we copy `shared_ptr`, we increment its internal reference counter.
    As long as we hold our shared pointer copy, the object being pointed to will not
    be deleted. But what if we want some kind of *weak* pointer, which enables us
    to get at the object as long as it exists but does not prevent its destruction?
    And how do we determine if the object still exists, then?
  prefs: []
  type: TYPE_NORMAL
- en: In such situations, `weak_ptr` is our companion. It is a little bit more complicated
    to use than `unique_ptr` and `shared_ptr`, but after following this recipe, we
    will be ready to use it.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will implement a program that maintains objects with `shared_ptr` instances,
    and then, we mix in `weak_ptr` to see how this changes the behavior of smart pointer
    memory handling:'
  prefs: []
  type: TYPE_NORMAL
- en: 'At first, we include the necessary headers and declare that we use the `std`
    namespace by default:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we implement a class that prints a message in its destructor implementation.
    This way, we can simply check when an item is actually destroyed later in the
    program output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s also implement a function that prints information about a weak pointer,
    so we can print a weak pointer''s state at different points of our program. The
    `expired` function of `weak_ptr` tells us if the object it points to still really
    exists, because holding a weak pointer to an object does not prolong its lifetime!
    The `use_count` counter tells us how many `shared_ptr` instances are currently
    pointing to the object in question:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: 'If we want to access the actual object, we need to call the `lock` function.
    It returns us a shared pointer to the object. In case the object does *not exist*
    any longer, the shared pointer we got from it is effectively a `null` pointer.
    We need to check that, and then we can access it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s instantiate an empty weak pointer in the main function and print its
    content which is, of course, empty at first:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: 'In a new scope, we instantiate a new shared pointer with a fresh instance of
    the `Foo` class. Then we copy it to the weak pointer. Note that this will not
    increment the reference count of the shared pointer. The reference counter is
    `1` because only one *shared* pointer owns it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s call the weak pointer function before we *leave* the scope and, again,
    *after* we leave the scope. The `Foo` instance should be destroyed immediately,
    *although* a weak pointer points to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: 'Compiling and running the program yields us three times the output of the `weak_ptr_info`
    function. In the first call, the weak pointer is empty. In the second call, it
    already points to the `Foo` instance we created and is able to dereference it
    after *locking* it. Before the third call, we leave the inner scope, which triggers
    the destructor of the `Foo` instance, as we expected. Afterward, it is not possible
    to get at the content of the deleted `Foo` item via the weak pointer any longer,
    and the weak pointer correctly recognizes that it has expired:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Weak pointers provide us a way to point at an object maintained by shared pointers
    without incrementing its use counter. Okay, a raw pointer could do the same, but
    a raw pointer cannot tell us if it is dangling or not. A weak pointer can!
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to understand how weak pointers as an addition to shared pointers
    work, let''s directly jump to an illustrating diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/583fb0b1-7b58-4bab-ac2a-41fa81b5a685.png)'
  prefs: []
  type: TYPE_IMG
- en: The flow is similar to the diagram in the recipe about shared pointers. In step
    1, we have two shared pointers and a weak pointer pointing to the object of type
    `Foo`. Although there are three objects pointing to it, only the shared pointers
    manipulate its use counter, which is why it has the value `2`. The weak pointer
    only manipulates a *weak counter* of the control block. In steps 2 and 3, the
    shared pointer instances are destroyed, which leads stepwise to a use counter
    of `0`. In step 4, this results in the `Foo` object being deleted, but the control
    block *stays* there. The weak pointer still needs the control block in order to
    distinguish if it dangles or not. Only when the *last* *weak* pointer that still
    points to a control block *also* goes out of scope, the control block is deleted.
  prefs: []
  type: TYPE_NORMAL
- en: We can also say that a dangling weak pointer has *expired*. In order to check
    for this attribute, we can ask `weak_ptr` pointer's `expired` method, which returns
    a boolean value. If it is `true`, then we cannot dereference the weak pointer
    because there is no object to dereference any longer.
  prefs: []
  type: TYPE_NORMAL
- en: In order to dereference a weak pointer, we need to call `lock()`. This is safe
    and convenient because this function returns us a shared pointer. As long as we
    hold this shared pointer, the object behind it cannot vanish because we incremented
    the use counter by locking it. If the object is deleted, shortly before the `lock()`
    call, then the shared pointer it returns is effectively a `null` pointer.
  prefs: []
  type: TYPE_NORMAL
- en: Simplifying resource handling of legacy APIs with smart pointers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Smart pointers (`unique_ptr`, `shared_ptr`, and `weak_ptr`) are extremely useful,
    and it is, in general, safe to say that a programmer should *always* use these
    instead of allocating and freeing memory manually.
  prefs: []
  type: TYPE_NORMAL
- en: But what if objects cannot be allocated using the `new` operator and/or cannot
    be freed again using `delete`? Many legacy libraries come with their own allocation/destruction
    functions. It seems that this would be a problem because we learned that smart
    pointers rely on `new` and `delete`. If the creation and/or destruction of specific
    types of objects relies on specific factory functions' deleter interfaces, does
    this prevent us from getting the humongous benefits of smart pointers?
  prefs: []
  type: TYPE_NORMAL
- en: Not at all. In this recipe, we will see that we only need to perform very minimal
    customizations on smart pointers in order to let them follow specific procedures
    for allocation and destruction of specific objects.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will define a type that cannot be allocated with `new`
    directly and, also, cannot be released again using `delete`. As this prevents
    it from being used with smart pointers directly, we perform the necessary little
    adaptions to instances of `unique_ptr` and `smart_ptr`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'As always, we first include the necessary headers and declare that we use the
    `std` namespace by default:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we declare a class that has its constructor and destructor declared `private`.
    This way, we simulate the problem that we have to access specific functions that
    create and destroy instances of it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: 'The static methods, `create_foo` and `destroy_foo`, then create and destroy
    the `Foo` instances. They work with raw pointers. This simulates the situation
    of a legacy C API, which prevents us from using them with normal `shared_ptr`
    pointers directly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s make such objects manageable by `shared_ptr`. We can, of course,
    put the pointer we get from `create_foo` into the constructor of a shared pointer.
    Only the destruction is tricky because the default deleter of `shared_ptr` would
    do it wrong. The trick is that we can give `shared_ptr` a *custom deleter*. The
    function signature that a deleter function or callable object needs to have is
    already the same as that of the `destroy_foo` function. If the function we need
    to call for destroying the object is more complicated, we can simply wrap it into
    a lambda expression:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that `make_shared_foo` returns a usual `shared_ptr<Foo>` instance because
    giving it a custom deleter did not change its type. This is because `shared_ptr`
    uses virtual function calls to hide such details. Unique pointers do not impose
    any overhead, which makes the same trick unfeasible for them. Here, we need to
    change the type of the `unique_ptr`. As a second template parameter, we give it
    `void (*)(Foo*)`, which is exactly the type of pointer to the function, `destroy_foo`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE125]'
  prefs: []
  type: TYPE_PRE
- en: 'In the main function, we just instantiate both a shared pointer and a unique
    pointer instance. In the program output, we will see if they are really, correctly,
    and automatically destroyed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: 'Compiling and running the program yields the following output, which is luckily
    just what we expected:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Usually, `unique_ptr` and `shared_ptr` just call `delete` on their internal
    pointers, whenever they ought to destroy the object they maintain. In this section,
    we constructed a class which can neither be allocated the C++ way using `x = new
    Foo{123}` nor can it be destructed with `delete x` directly.
  prefs: []
  type: TYPE_NORMAL
- en: The `Foo::create_foo` function just returns a plain raw pointer to a newly constructed
    `Foo` instance, so this causes no further problems because smart pointers work
    with raw pointers anyway.
  prefs: []
  type: TYPE_NORMAL
- en: The problem we had to deal with is that we need to teach `unique_ptr` and `shared_ptr`
    how to *destruct* an object if the default way is *not* the right one.
  prefs: []
  type: TYPE_NORMAL
- en: In that regard, both the smart pointer types differ a little bit. In order to
    define a custom deleter for `unique_ptr`, we have to alter its type. Because the
    type signature of the `Foo` deleter is `void Foo::destroy_foo(Foo*);`, the type
    of the `unique_ptr` maintaining a `Foo` instance must be `unique_ptr<Foo, void
    (*)(Foo*)>`. Now, it can hold a function pointer to `destroy_foo`, which we provide
    it as a second constructor parameter in our `make_unique_foo` function.
  prefs: []
  type: TYPE_NORMAL
- en: If giving `unique_ptr` a custom deleter function forces us to change its type,
    why were we able to do the same with `shared_ptr` *without* changing its type?
    The only thing we had to do there was giving `shared_ptr` a second constructor
    parameter, and that's it. Why can't it be as easy for `unique_ptr` as it is for
    `shared_ptr`?
  prefs: []
  type: TYPE_NORMAL
- en: The reason why it is so simple to just provide `shared_ptr` some kind of callable
    deleter object without altering the shared pointer's type lies in the nature of
    shared pointers, which maintain a control block. The control block of shared pointers
    is an object with virtual functions. This means that the control block of a standard
    shared pointer compared with the type of a control block of a shared pointer with
    a custom deleter is *different*! When we want a unique pointer to use a custom
    deleter, then this changes the type of the unique pointer. When we want a shared
    pointer to use a custom deleter, then this changes the type of the internal *control
    block*, which is invisible to us because this difference is hidden behind a virtual
    function interface.
  prefs: []
  type: TYPE_NORMAL
- en: It would be *possible* to do the same trick with unique pointers, but then,
    this would imply a certain runtime overhead on them. This is not what we want
    because unique pointers promise to be completely *overhead free* at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: Sharing different member values of the same object
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's imagine we are maintaining a shared pointer to some complex, composed,
    and dynamically allocated object. Then, we want to start a new thread that does
    some time-consuming work on a member of this complex object. If we want to release
    this shared pointer now, the object will be deleted while the other thread is
    still accessing it. If we don't want to give the thread object the pointer to
    the whole complex object because that would mess with our nice interface, or for
    other reasons, does this mean that we have to do manual memory management now?
  prefs: []
  type: TYPE_NORMAL
- en: No. It is possible to use shared pointers that on one hand, point to a member
    of a large shared object, while on the other hand, perform automatic memory management
    for the entire initial object.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we will create such a scenario (without threads to keep it
    simple) in order to get a feeling for this handy feature of `shared_ptr`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are going to define a structure that is composed of multiple members. Then,
    we allocate an instance of this structure on the heap that is maintained by a
    shared pointer. From this shared pointer, we obtain more shared pointers that
    do not point to the actual object but to its members:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We include the necessary headers first and then declare that we use the `std`
    namespace by default:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we define a class that has different members. We will let shared pointers
    point to the individual members. In order to be able to see when the class is
    created and destroyed, we let its constructor and destructor print messages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s define shared pointers that have the right types to point to the `name`
    and `age` member variables of a `person` class instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we enter a new scope, create such a person object, and let a shared pointer
    manage it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE131]'
  prefs: []
  type: TYPE_PRE
- en: Then, we let the first two shared pointers point to its name and age members.
    The trick is that we use a specific constructor of `shared_ptr`, which accepts
    a shared pointer and a pointer to a member of the shared object. This way, we
    can manage the object while not pointing at the object itself!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: 'After leaving the scope, we print the person''s name and age values. This is
    only legal if the object is still allocated:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE133]'
  prefs: []
  type: TYPE_PRE
- en: Compiling and running the program yields the following output. From the destructor
    message, we see that the object is indeed still alive and allocated when we access
    the person's name and age values via the member pointers!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we first created a shared pointer that manages a dynamically
    allocated `person` object. Then we made two other smart pointers point to the
    person object, but they both did not *directly* point to the person object itself
    but instead to its members, `name` and `age`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize what kind of scenario we just created, let''s have a look at the
    following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/835d6935-4712-4ccb-9e5c-8ff335816245.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that `shared_ptr1` points to the `person` object directly, while `shared_name`
    and `shared_age` point to the `name` and the `age` members of the same object.
    Apparently, they still manage the object's entire lifetime. This is possible because
    the internal control block pointers still point to the same control block, no
    matter what sub-object the individual shared pointers point to.
  prefs: []
  type: TYPE_NORMAL
- en: In this scenario, the use count of the control block is `3`. This way, the `person`
    object is not destroyed when `shared_ptr1` is destroyed because the other shared
    pointers still own the object.
  prefs: []
  type: TYPE_NORMAL
- en: 'When creating such shared pointer instances that point to members of the shared
    object, the syntax looks a bit strange. In order to obtain a `shared_ptr<string>`
    that points to the name member of a shared person, we need to write the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: In order to get a specific pointer to a member of a shared object, we instantiate
    a shared pointer with a type specialization of the member we want to access. This
    is why we write `shared_ptr<**string**>`. Then, in the constructor, we first provide
    the original shared pointer that maintains the `person` object and, as a second
    argument, the address of the object the new shared pointer will use when we dereference
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Generating random numbers and choosing the right random number engine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to get random numbers for whatever purpose, C++ programmers usually
    basically used the `rand()` function of the C library before C++11\. Since C++11,
    there has been a whole *suite* of random number generators that serve different
    purposes and have different characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: These generators are not completely self-explanatory, so we will have a look
    at all of them in this recipe. In the end, we will see in what ways they differ,
    how to choose the right one, and that we will most probably never use all of them.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will implement a procedure that prints a nice illustrating histogram of the
    numbers a random generator produces. Then, we will run all STL random number generator
    engines through this procedure and learn from the results. This program contains
    many repetitive lines, so it might be advantageous to just copy the source code
    from the code repository accompanying this book on the Internet instead of typing
    all the repetitive code manually.
  prefs: []
  type: TYPE_NORMAL
- en: 'At first, we include all the necessary headers and then declare that we use
    the `std` namespace by default:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we implement a helper function, which helps us maintain and print some
    statistics for each type of random number engine. It accepts two parameters: the
    number of *partitions* and the number of *samples*. We will see immediately what
    these are for. The type of random generator is defined via the template parameter
    `RD`. The first thing we do in this function is define an alias type for the resulting
    numeric type of the numbers the generator returns. We also make sure that we have
    at least 10 partitions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we instantiate an actual generator instance of type `RD`. Then, we define
    a divisor variable called `div`. All random number engines emit random numbers
    within the range from `0` to `RD::max()`. The function argument, `partitions`,
    allows the caller to choose by how many partitions we divide every random number
    range. By dividing the largest possible value by the number of partitions, we
    know how large every partition is:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we instantiate a vector of counter variables. It is exactly as large
    as the number of partitions we have. Then, we get as many random values out of
    the random engine as the variable `samples` says. The expression, `rd()`, gets
    a random number from the generator and shifts its internal state to prepare it
    for returning the next random number. By dividing every random number by `div`,
    we get the partition number it falls into and can increment the right counter
    in the vector of counters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE139]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we have a nice coarse-grained histogram of sample values. In order to print
    it, we need to know a little bit more about its actual counter values. Let''s
    extract its largest value using the `max_element` algorithm. We then divide this
    largest counter value by `100`. This way, we can divide all the counter values
    by `max_div` and print a lot of stars on the terminal without exceeding the width
    of `100`. If the largest counter contains a number less than `100`, because we
    did not use so many samples, we use `max` in order to get a minimal divisor of
    `1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE140]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now print the histogram to the terminal. Every partition gets its own
    line on the terminal. By dividing its counter value by `max_div` and print so
    many asterisk symbols `''*''`, we get histogram lines that fit into the terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE141]'
  prefs: []
  type: TYPE_PRE
- en: 'Okay, that''s it. Now to the main program. We let the user define how many
    partitions and samples should be used:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE142]'
  prefs: []
  type: TYPE_PRE
- en: 'We then read those variables from the command line. Of course, the command
    line consists of strings, which we can convert to numbers using `std::stoull`
    (`stoull` is an abbreviation for **s**tring **to** **u**nsigned **l**ong **l**ong):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE143]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we call our histogram helper function on *every* random number engine the
    STL provides. This makes this recipe very long and repetitive. Better copy the
    example from the Internet. The output of this program is really interesting to
    look at. We start with `random_device`. This device tries to distribute the randomness
    equally over all the possible values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE144]'
  prefs: []
  type: TYPE_PRE
- en: 'The next random engine we try is `default_random_engine`. What kind of engine
    this type refers to is implementation-specific. It can be *any* of the following
    random engines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE145]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we try it on all the other engines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE146]'
  prefs: []
  type: TYPE_PRE
- en: 'Compiling and running the program yields interesting results. We will see a
    long list of output, and we''ll see that all the random engines have different
    characteristics. Let''s first run the program with `10` partitions and only `1000`
    samples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ff7076af-b140-497a-9d23-c4453a43415f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, we run the same program again. This time it is still `10` partitions
    but `1,000,000` samples. It becomes very obvious that the histograms look much
    *cleaner*, when we take more samples from them. This is an important observation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8178317e-d792-4766-be8a-d4e0e6a06d3c.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In general, any random number generator needs to be instantiated as an object
    before use. The resulting object can be called like a function without parameters
    because it overloads `operator()`. Every call will then lead to a new random number.
    It is that simple.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we wrote a program that is much more complex than that in
    order to get a bit more information about random number generators. Please play
    around with the resulting program by launching it with different command-line
    arguments and realize the following facts:'
  prefs: []
  type: TYPE_NORMAL
- en: The more samples we take, the more equal our partition counters appear.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The inequality of the partition counters wildly differs between individual engines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a large number of samples, it becomes apparent that the *performance* of
    the individual random engines differs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run the program with a low amount of samples multiple times. The distribution
    patterns look *the same* all the time--the random engines produce the *same* random
    number sequences repeatedly, which means they are *not random at all*. Such engines
    are called *deterministic* because their random numbers can be predicted. The
    only exception is `std::random_device`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we can see, there are a few characteristics to consider. For most standard
    applications, `std::default_random_engine` will be completely sufficient. Experts
    of cryptography or similarly security-sensitive topics will choose wisely between
    the engines they use, but for us average programmers, this is not too important
    when we write apps with some randomness.
  prefs: []
  type: TYPE_NORMAL
- en: 'We should carry home the following three facts from this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: Usually, `std::default_random_engine` is a good default choice for the average
    application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If we really need non-deterministic random numbers, `std::random_device` provides
    us such.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can feed the constructor of any random engine with a *real* random number
    from `std::random_device` (or maybe a timestamp from the system clock), in order
    to make it produce different random numbers each time. This is called *seeding*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that `std::random_device` *can* possibly fall back to one of the deterministic
    engines if the library has no support for nondeterministic random engines.
  prefs: []
  type: TYPE_NORMAL
- en: Generating random numbers and letting the STL shape specific distributions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last recipe, we learned some bits about the STL random number engines.
    Generating random numbers this or the other way is often only half of the work.
  prefs: []
  type: TYPE_NORMAL
- en: Another question is, what do we need those numbers for? Are we programmatically
    "flipping a coin"? People used to do this using `rand() % 2`, which results in
    values of `0` and `1` that can then be mapped to *head* or *tail*. Fair enough;
    we do not need a library for that (although randomness experts know that just
    using the lowest few bits of a random number does not always lead to high-quality
    random numbers).
  prefs: []
  type: TYPE_NORMAL
- en: What if we want to model a die? Then, we could surely write `(rand() % 6) +
    1`, in order to represent the result after rolling the die. There is still no
    pressing library needed for such simple tasks.
  prefs: []
  type: TYPE_NORMAL
- en: What if we want to model something that happens with an exact probability of
    66%? Okay, then we can come up with a formula like `bool yesno = (rand() % 100
    > 66)`. (Oh wait, should it be `>=`, or is `>` correct?)
  prefs: []
  type: TYPE_NORMAL
- en: Apart from that, how do we model an *unfair* die whose sides do not all have
    the same probability? Or how do we model more complex distributions? Such problems
    can quickly evolve to scientific tasks. In order to concentrate on our primary
    problems, let's have a look at what the STL already provides in order to help
    us.
  prefs: []
  type: TYPE_NORMAL
- en: The STL contains more than a dozen distribution algorithms that can shape random
    numbers for specific needs. In this recipe, we are going to have a very brief
    look at all of them, and a closer look at the most generally useful ones.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are going to generate random numbers, shape them, and print their distribution
    patterns to the terminal. This way, we can get to know all of them and understand
    the most important ones, which is useful if we ever need to model something specific
    with randomness in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: 'At first, we include all the needed headers and declare that we use the `std`
    namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE147]'
  prefs: []
  type: TYPE_PRE
- en: 'For every distribution the STL provides, we will print a histogram in order
    to see its characteristics because every distribution looks very special. It accepts
    a distribution as an argument and the number of samples that shall be taken from
    it. Then, we instantiate the default random engine and a map. The map maps from
    the values we obtained from the distribution to counters that count how often
    which value occurred. The reason for why we always instantiate a random engine
    is that all distributions are just used as a *shaping function* for random numbers
    that still need to be generated by a random engine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE148]'
  prefs: []
  type: TYPE_PRE
- en: We take as many samples as the `samples` variable says and feed the map counters
    with them. This way, we get a nice histogram. While calling `e()` alone would
    get us a raw random number from the random engine, `distro(e)` shapes the random
    numbers through the distribution object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE149]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to get a terminal output that fits into the terminal window, we need
    to know the *largest* counter value. The `max_element` function helps us in finding
    the largest value by comparing all the associated counters in the map and returning
    us an iterator to the largest counter node. Knowing this value, we can determine
    by what value we need to divide all the counter values in order to fit the output
    into the terminal window:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE150]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we loop through the map and print a bar of asterisk symbols `''*''` for
    all counters which have a significant size. We drop the others because some distribution
    engines spread the numbers over such large domains that it would completely flood
    our terminal windows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE151]'
  prefs: []
  type: TYPE_PRE
- en: In the main function, we check if the user provided us exactly one parameter,
    which tells us how many samples to take from each distribution. If the user provided
    none or multiple parameters, we error out.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE152]'
  prefs: []
  type: TYPE_PRE
- en: 'We convert the command-line argument string to a number using `std::stoull`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE153]'
  prefs: []
  type: TYPE_PRE
- en: 'At first, we try the `uniform_int_distribution` and `normal_distribution`.
    These are the most typical distributions used where random numbers are needed.
    Everyone who ever had stochastic as a topic in maths at school will most probably
    have heard about these already. The uniform distribution accepts two values, denoting
    the lower and the upper bound of the range they shall distribute random values
    over. By choosing `0` and `9`, we will get equally often occurring values between
    (including) `0` and `9`. The normal distribution accepts a *mean value* and a
    *standard derivation* as arguments:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE154]'
  prefs: []
  type: TYPE_PRE
- en: 'Another really interesting distribution is `piecewise_constant_distribution`.
    It accepts two input ranges as arguments. The first range contains numbers that
    denote the limits of intervals. By defining it as `0, 5, 10, 30`, we get one interval
    that spans from `0` to `4`, then, an interval that spans from `5` to `9`, and
    the last interval spanning from `10` to `29`. The other input range defines the
    weights of the input ranges. By setting those weights to `0.2, 0.3, 0.5`, the
    intervals are hit by random numbers with the chances of 20%, 30%, and 50%. Within
    every interval, all the values are hit with equal probability:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE155]'
  prefs: []
  type: TYPE_PRE
- en: The `piecewise_linear_distribution` is constructed similarly, but its weight
    characteristics work completely differently. For every interval boundary point,
    there is one weight value. In the transition from one boundary to the other, the
    probability is linearly interpolated. We use the same interval list but a different
    list of weight values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE156]'
  prefs: []
  type: TYPE_PRE
- en: 'The Bernoulli distribution is another important distribution because it distributes
    only *yes/no*, *hit/miss*, or *head/tail* values with a specific probability.
    Its output values are only `0` or `1`. Another interesting distribution, which
    is useful in many cases, is `discrete_distribution`. In our case, we initialize
    it to the discrete values `1, 2, 4, 8`. These values are interpreted as weights
    for the possible output values `0` to `3`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE157]'
  prefs: []
  type: TYPE_PRE
- en: 'There are a lot of different other distribution engines. They are very special
    and useful in very specific situations. If you have never heard about them, they
    *may* not be for you. However, since our program will produce nice distribution
    histograms, we will print them all, for curiosity reasons:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE158]'
  prefs: []
  type: TYPE_PRE
- en: 'Compiling and running the program yields the following output. Let''s first
    run the program with `1000` samples per distribution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/5ba7d1ee-ef21-4b2d-ae4f-6d68d5bc6ab5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Another run with `1,000,000` samples per distribution shows that the histograms
    appear much cleaner and more typical for each distribution. But we also see which
    ones are slow, and which ones are fast, while they are being generated:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/0297daeb-5434-4bf4-8aa6-7f23b5036413.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While we usually do not care too much about the random number engine, as long
    it is fast and produces numbers that are as random as possible, the distribution
    is something we *should* choose wisely, depending on the problem we like to solve
    (or create).
  prefs: []
  type: TYPE_NORMAL
- en: In order to use any distribution, we first need to instantiate a distribution
    object from it. We have seen that different distributions take different constructor
    arguments. In the recipe description, we went a bit too briefly over some distribution
    engines because most of them are too special and/or too complex to cover here.
    But don't worry, they are all documented in detail in the C++ STL documentation.
  prefs: []
  type: TYPE_NORMAL
- en: However, as soon as we have a distribution instantiated, we can call it like
    a function that accepts a random engine object as its only parameter. What happens
    then is that the distribution engine takes a random value from the random engine,
    applies some magic shaping (which completely depends on the choice of the distribution
    engine, of course), and then returns us a *shaped* random value. This leads to
    completely different histograms, as we saw after executing the program.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most comprehensive way to get to know the different distributions is *playing*
    around with the program we just wrote. In addition to that, let''s summarize the
    most important distributions. For all the distributions that occur in our program
    but not in the following table, please consult the C++ STL documentation if you
    are interested:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Distribution** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `uniform_int_distribution` | This distribution accepts a lower and an upper
    bound value as constructor arguments. It does, then, give us random numbers that
    always fall into the interval between (including) those bounds. The probability
    for each of the values in this interval is the same, which gives us a histogram
    with a *flat* shape. This distribution is representative of rolling a *die*, for
    example, because each side of the die has the same probability to occur. |'
  prefs: []
  type: TYPE_TB
- en: '| `normal_distribution` | The normal distribution, or Gauss distribution, occurs
    practically everywhere in nature. Its STL version accepts a mean value and a standard
    derivation value as constructor parameters and forms a *roof*-like shape in the
    histogram. If we compare the body size or IQ of humans or other animals, or the
    grades of students, we will realize that these numbers are also normal-distributed.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `bernoulli_distribution` | The Bernoulli distribution is perfect if we want
    to flip a coin or get a yes/no answer. It emits only the values `0` or `1` and
    its only constructor parameter is the probability for the value of `1`. |'
  prefs: []
  type: TYPE_TB
- en: '| `discrete_distribution` | The discrete distribution is interesting if we
    only want a very limited, discrete set of values for which we want to define the
    probability for every individual value. Its constructor takes a list of weights
    and will emit random numbers with probabilities depending on their weight. If
    we want to model randomly distributed blood groups, of which there are only four
    different ones that have specific probabilities, then this engine is a perfect
    match. |'
  prefs: []
  type: TYPE_TB
