- en: Design Best Practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To wrap up this book, our final chapter will talk about the different best practices
    that you will have to follow in order to design a resilient and failure-proof
    solution. Even though this is the last chapter of this book, it will help you
    as a starting point for what things to consider when, for example, migrating to
    the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will be covering the basics of subjects such the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Moving to the cloud
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container design
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous integration pipelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous deployment pipelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automated testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The topics and practices that we will be covering in this chapter are no where
    near extensive and we will be giving a 10,000 feet overview. With these basics,
    you can start to reinforce your knowledge in each area to make the ultimate design
    decisions for your customers.
  prefs: []
  type: TYPE_NORMAL
- en: Designing for the occasion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our previous chapters, we learned everything we needed for very specific
    solutions. Here, we will be talking about generalities, the basic rules or recommendations
    you need to follow or at least try to adhere to for every design you create. But
    don't be confused by what I’m going to say next; best practices per se do not
    exist. Every solution will have its own identity, its own goals, and its own unique
    characteristics. Always try to satisfy the situation you are in and the business
    needs of your customer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Many solutions, though, will have to comply with certain industry standards,
    as they may handle sensitive information. In these types of scenarios, we already
    have a very well-defined set of rules and policies that our designs have to satisfy.
    This breaks our statement that all designs are different, but again, these are
    very specific scenarios for very specific industries. Some of the standards that
    we need to comply with when dealing with sensitive data are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Health Insurance Portability and Accountability Act** (**HIPAA**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Payment Card Industry Data Security Standards** (**PCI-DSS**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The General Data Protection Regulation** (**GDPR**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These standards are fixed no matter what, locally and internationally, and regulated
    by their respective authorities. But not all design patterns or ways to comply
    with certain solution requirements are as clear as these ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a solutions architect, you will find yourself in many scenarios that will
    help you expand your portfolio and apply it in different solutions. Every design
    you create is only as strong as its weakest link. When you are designing, always
    try to see how you can break your design:'
  prefs: []
  type: TYPE_NORMAL
- en: Where does it have points of failure?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where does it have bottlenecks?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will my servers be able to handle the load?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are a few examples of some questions you need to ask yourself. We need
    to shape our way of thinking and ask ourselves the question *why?* more often.
    Why are we doing what we are doing this way, or that way? It is crucial to question
    ourselves about every decision we make.
  prefs: []
  type: TYPE_NORMAL
- en: Changing our way of thinking is the best thing we can do, as nowadays technologies
    are evolving faster than ever before. Technologies might change over the years,
    and what we implemented today might be totally unusable tomorrow, but our way
    of thinking will allow us to adapt and analyze from all the points necessary for
    us to be successful.
  prefs: []
  type: TYPE_NORMAL
- en: 'Every situation and environment will be different, but at the time of writing
    we can say that you will be dealing with two major types of environments:'
  prefs: []
  type: TYPE_NORMAL
- en: On-premises/bare metal environments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud environments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will be going through the basic considerations that you
    will need to deal with when you're working in these environments.
  prefs: []
  type: TYPE_NORMAL
- en: On-premises environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Linux is adaptable; it can run pretty much anywhere. It wouldn't surprise me
    if I found the Linux kernel on a lawn mower in the next few years. In a world
    where IT is becoming more and more relevant for our daily lives, alongside the
    rise of the Internet of Things, the presence of Linux has spiked like never before.
    Therefore, as Linux architects, we need to be prepared to design with almost everything.
  prefs: []
  type: TYPE_NORMAL
- en: 'In an on-premises environment, we are most probably facing two scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: Bare metal server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Virtual machines** (**VMs**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both of them will be very different, as the options that we will have to make
    our solution more resilient will vary.
  prefs: []
  type: TYPE_NORMAL
- en: Bare metal server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bare metal servers are perfect for workloads that require a considerable amount
    of resources to run. Small workloads will not be efficiently placed on a single
    server; for instance, a small web application that will not be serving a lot of
    user requests has no place on a 64-core 1 TB of RAM physical server. It's a waste
    of resources and a terrible economic decision. Most of the time, 90% of this server
    would be totally idle, wasting precious resources that could be used for something
    else. These types of applications should be put into a VM or containerized altogether.
  prefs: []
  type: TYPE_NORMAL
- en: The first thing that we should understand before moving or creating an infrastructure
    on bare metal are the resource requirements of the application for which you are
    building the infrastructure for.
  prefs: []
  type: TYPE_NORMAL
- en: 'Systems that require lots of resources for data processing and high-performance
    computing will take full advantage of the resources available. Solutions such
    as the following ones are examples of what to run on bare metal servers:'
  prefs: []
  type: TYPE_NORMAL
- en: Type 1/ Type 2 Hypervisors (**Kernel-based Virtual Machine** (**KVM**), **Linux
    containers** (**LXC**), XEN)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linux for SAP HANA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Hadoop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linux for Oracle DB
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Large MongoDB deployments for memory caching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**High-performance computing** (**HPC**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In-house applications that specify that their memory requirements exceed the
    hundreds of GB or hundreds of CPU cores are all better served on a bare metal
    server where RAM/CPU will not be consumed on any other overhead process that is
    not part of the workload that you design that server for.
  prefs: []
  type: TYPE_NORMAL
- en: Virtual machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hypervisors are also better on bare metal servers; since they are going to be
    sharing their resources across multiple hosted VMs, they require large quantities
    of resources. One thing to note is that some of the resources of the hypervisor
    will be consumed by the hypervisor itself, which creates a resource overhead on
    hardware interrupts and other operations.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, when building physical servers, we focus a lot on the CPU cores that
    our application will need. With hypervisors, CPU time is served to VMs on priority
    or a first-come-first-served basis to the available core; depending on how it
    is configured, the CPU resource is shared across the running VMs. On the contrary,
    RAM memory is not shared across the VMs, and we need to be careful in the resource
    balancing that we are implementing. Deploying a server with the necessary CPU
    cores but with enough RAM that can satisfy any period of contention that we can
    face is something to take into account. With hundreds of VMs running on a single
    host, we can run out of memory really quickly and start swapping, and this is
    a situation that we want to avoid.
  prefs: []
  type: TYPE_NORMAL
- en: With resource provisioning, we also need to take into account that if we are
    running a cluster of hypervisors, there can be situations when one of the cluster
    nodes needs to go into maintenance or go down because of an unexpected failure.
    Scenarios such as this are the reason we should always leave some resources to
    be able to manage additional unexpected workloads from VMs that might failover
    due to the aforementioned reasons.
  prefs: []
  type: TYPE_NORMAL
- en: When dealing with hypervisors, you have to be careful, as you will not be running
    just a single workload per physical host. The number and the VMs themselves will
    always vary, unless you have some type of affinity rule configured. Things such
    as how much network bandwidth your network interface cards support are of utmost
    relevance. Depending on the amount of resources of the host hypervisor, tens or
    hundreds of VMs will be sharing the same network hardware to perform their I/O.
    Here is where deciding, for example, whether a 10 GbE network card instead of
    a 1 GbE network card is required.
  prefs: []
  type: TYPE_NORMAL
- en: One more thing to take into consideration when picking the network interfaces
    of your physical host is the type of storage you will be using; for example, if
    you are considering a **network filesystem **(**NFS**) solution or an iSCSI solution,
    you have to keep in mind that, many times, they will be sharing the same interfaces
    such as the ones for the regular network traffic. If you know the infrastructure
    you are designing will have a very congested network and require a good storage
    performance, it is better to have another approach, such as choosing a fibre channel
    storage area network, with its own dedicated hardware just for storage I/O.
  prefs: []
  type: TYPE_NORMAL
- en: Network segmentation is crucial for virtualized environments, management traffic,
    application network traffic, and storage network traffic, which should always
    be segmented. You can achieve this in several ways, such as by provisioning dedicated
    network interface cards for each purpose or via VLAN tagging. Each hypervisor
    will have its own set of tools to achieve segmentation, but the idea behind it
    is the same.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Working with **cloud environments** creates a wide number of options for designing
    IT solutions. Independently from the cloud provider, you will be able to select
    from services such as these:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Infrastructure as a Service** (**IaaS**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Platform as a Service** (**PaaS**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Software as a Service** (**SaaS**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Your choice will depend on the maturity of your customer in cloud architecture
    models. But before we can even talk about design patterns or best practices for
    cloud environments, we need to talk about how you perform the migration of your
    on-premises environment to the cloud or how you can start adopting the cloud as
    the infrastructure for your customer.
  prefs: []
  type: TYPE_NORMAL
- en: The journey to the cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: These migration strategies are adopted from Gartner research. Gartner also calls
    out a fifth strategy called **replace** with SaaS.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following research paper is discussed in this section:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Devise an Effective Cloud Computing Strategy by Answering Five Key Questions, *Gartner,
    David W Cearley, November 2015, refreshed June 23, 2017.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When migrating to the cloud, we don''t have to see the cloud as a destination,
    but rather as a journey. As cheesy as it sounds, it is like that. Every customer’s
    path to the cloud will be different; some paths will be easy and others will be
    painfully hard. It will all depend on what led the customer to take the decision
    to move and how they are deciding to move their infrastructure. Some customers
    might decide not only to move their infrastructure to an IaaS model but also take
    advantage of the move and modernize some of the workloads into a PaaS or even
    a serverless model. Each path will require a different level of preparation, regardless
    of which one they choose. A typical transition can look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3a2d9429-d251-4d44-b863-922c08de6c9b.png)'
  prefs: []
  type: TYPE_IMG
- en: Each step will require a higher degree of changes to be implemented on the applications
    or infrastructure to migrate.
  prefs: []
  type: TYPE_NORMAL
- en: We can see the aforementioned steps as part of a greater journey that begins
    with the assessment of the assets to migrate.
  prefs: []
  type: TYPE_NORMAL
- en: Let's explore each step of the migration in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Assessing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this step, we will evaluate which workloads we want to migrate. After identifying
    the candidates for migration, we should always run an inventory of our VMs or
    physical servers and calculate what the **total cost of ownership** (**TCO**)
    of maintaining the infrastructure is. Things such as hardware cost, support maintenance
    contracts, electricity bills, and even space rental come into play here. This
    will help us to understand how much we will be saving in an eventual migration
    to the cloud. This data is crucial to convince management and any C-level decision
    makers that may have any doubts about the benefits in cost of migrating infrastructure
    to a cloud provider.
  prefs: []
  type: TYPE_NORMAL
- en: 'The ideal scenario to begin a migration is to look for smaller applications
    that don’t require an entire infrastructure to be migrated in order for them to
    be put into production. Applications with few dependencies are perfect to begin
    your assessment. Dependencies such as which servers we need to migrate together,
    and network requirements for our application such as ports and IP operational
    ranges are to be taken into consideration. Questions such as the following will
    help us to prepare for a successful migration:'
  prefs: []
  type: TYPE_NORMAL
- en: Is my Linux distribution endorsed by the cloud provider I am migrating to?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Am I running the Kernel version that's supported by my cloud provider?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do I have to install any additional kernel modules?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does my cloud provider require any type of agent running on my OS?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With these questions answered, we can start performing the actual migration.
  prefs: []
  type: TYPE_NORMAL
- en: Migrating
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When migrating our infrastructure to the cloud, there are four basic ways of
    doing it:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Lift and shift**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Refactor**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rearchitect**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rebuild**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of these methods will take advantage of different services and different
    features of the cloud. Choosing which method to use will depend on many things,
    such as how quickly you need to migrate, how much effort you are willing to undergo
    to migrate, and whether you want to take advantage of the migration and modernize
    your workloads as you migrate.
  prefs: []
  type: TYPE_NORMAL
- en: Lift and shift
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This method is literally a rehost, as you will be moving your on-premises physical
    servers or VMs into VMs in your cloud provider. This method is the easiest and
    quickest of all the methods, because you will be moving your environment and your
    applications as you have them on-premises. No code changes or re-architecture
    of your applications is required for this method. Here, you will only be taking
    advantage of the IaaS advantages of the cloud provider of your choice.
  prefs: []
  type: TYPE_NORMAL
- en: Things such as the agility of having resources at your disposal if you need
    to increment storage or compute on demand and the lack of hardware maintenance
    and administration will be things to take advantage of in this model.
  prefs: []
  type: TYPE_NORMAL
- en: Refactor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With **refactor**, your applications require minimal to no code changes. With
    this method, we can exploit a mix of IaaS and PaaS features. Migrating a three-tier
    web application into a managed middleware and into a managed database is a perfect
    example of this migration model.
  prefs: []
  type: TYPE_NORMAL
- en: With a managed database or managed middleware, we don't have to worry about
    things such as OS management, database engine installation and administration,
    framework updates, security patches, and even configuring additional instances
    for load balancing, as it is all taken care of for us. We just need to upload
    our code and select the framework that we need for it to run. We still can run
    monolithic applications, and very little code changes are required; the main purpose
    of this method is to migrate by taking things such as management and configuration off
    our shoulders, thus increasing the agility of our workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Rearchitecting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Rearchitecting** while migrating does involve heavy changes in our applications,
    but this stage is where we modernize our business.'
  prefs: []
  type: TYPE_NORMAL
- en: We can find ourselves taking apart a monolithic application and breaking it
    into microservices by taking advantage of technologies such as containers and
    Kubernetes. We will be making our applications more portable, scalable, agile,
    and ready to be delivered via methodologies such as DevOps. With microservices,
    containers, and the automation that DevOps brings to the table, you will not only
    have a faster delivery of your applications to production, but you will also be
    using the compute resources on which your application will run more efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Rearchitecting might not be easy, nor is it the quickest way to migrate your
    workloads to the cloud, but it will give you a substantial advantage and cost
    savings in the long run.
  prefs: []
  type: TYPE_NORMAL
- en: Rebuild
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Rearchitecting requires major code changes, but this last migration model is
    all about taking advantage of the movement to the cloud and create what are called
    **cloud-native applications**.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud-native applications are those that take advantage of cloud services such
    as PaaS and SaaS applications that are designed to be run on the cloud. Some of
    them can even be entirely run on serverless computing. Serverless computing is
    to run code directly on a cloud service, or consume an API or a service that is
    already provided by the cloud provider. Combining several services that consume
    one another and work on a common goal or result are what we call cloud-native
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'The whole idea behind moving to the cloud is to save: save economically, save
    in maintenance, save time to recovery by moving into a more resilient and elastic
    platform. But we will not always automatically take advantage of all the benefits
    of it. After moving, we still have some terrain to cover in order to have our
    new cloud workloads completely optimized.'
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Maybe if you had moved your infrastructure via a lift and shift, the move might
    have been easy, and whatever workload was running on that VM is probably already
    in production with not many changes, if any at all. The problem is that your VMs
    are still the same size as they were on your on-premises environment. You are
    still having that VM use a small percentage of its actual total compute resources.
    In the cloud, this is wasting money, as you are paying for the hours that the
    VM is running, but the price that you pay for those hours is based on the total
    amount of resources of that VM, whether you are using 100% of them or not.
  prefs: []
  type: TYPE_NORMAL
- en: This stage is where we actually start performing appropriate sizings and optimizing
    our infrastructure to actually use what we really need to actually take advantage
    of the elasticity of the cloud. All cloud providers have tools and services that
    you can use to monitor the resource consumption of your VM and other services.
    With these tools, we can easily identify and address our sizing requirements in
    a way that is cost-efficient.
  prefs: []
  type: TYPE_NORMAL
- en: The elasticity of the cloud not only allows us to size our resources on demand,
    without having to wait for the IT operations team to allocate or buy new hardware
    in the case that we run out resources in our hypervisors or dedicated physical
    servers.
  prefs: []
  type: TYPE_NORMAL
- en: We can also provision extra VMs or instances of the service that we are consuming
    on demand, based on resource thresholds that we establish. Requests to these resources
    are automatically load balanced to our extra instances so that we only have to
    pay for those extra resources on periods of resource contention.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing is not all about reducing VM sizes for a better price. Other areas
    that we can optimize are management and time to market. Adopting things such as
    PaaS and SaaS can help us achieve this.
  prefs: []
  type: TYPE_NORMAL
- en: Once our applications are running on VMs on the cloud, we can easily start transitioning
    to these more managed services. Managed services help us forget about OS maintenance
    or middleware configurations, and our developers can spend more time actually
    developing and deploying applications rather than fighting with the operations
    team about an update that a library requires to be able to run the latest version
    of the production app, which eventually takes us a faster time to market and less
    money and time spent in management or operating system support contracts.
  prefs: []
  type: TYPE_NORMAL
- en: Faster time to market, less management, and fewer conflicts between operations
    and development are the things that DevOps is all about. We have mentioned DevOps
    in several stages of the migrate phase, but let's take a deeper look into what
    DevOps is and what it's trying to accomplish on a closer level.
  prefs: []
  type: TYPE_NORMAL
- en: DevOps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In synthesis, DevOps is the combination of development and operations. It is
    the union and collaboration between these two IT groups—developers and system
    administrators—that make DevOps possible. Notice that we said collaboration*;* it
    is important to understand that collaboration is the core of DevOps. There is
    not authority behind DevOps, like there is for the scrum framework, for example.
    On the contrary, it has no standard, but it follows a set practices born from
    a cultural exchange between these two groups, to achieve shorter development cycles
    and increased deployment frequency with agile methodologies.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will frequently see the term DevOps misused in different ways, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Position (DevOps Engineer)**: The nature of DevOps is collaboration across
    the operations and developer teams, and therefore DevOps is not a position or
    a specific team that does DevOps.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Set of tools**: The tools that are used to help achieve the goals behind
    DevOps are also confused. Kubernetes, Docker, and Jenkins are all often confused
    with DevOps, but they are only the means to an end.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Standard**: As we mentioned previously, the DevOps movement does not have
    any authority regulating its practices and flow; it is the people who are implementing
    and following a basic set of practices and adapting it to suit its own business
    needs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We now know that DevOps is a cultural movement, and that brings us more frequent
    development cycles, frequency, and integration between operations and development.
    Now, let's understand the problems behind the benefits of adopting DevOps.
  prefs: []
  type: TYPE_NORMAL
- en: Monolithic waterfalls
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The traditional method of developing software applications is called a **waterfall**.
    A waterfall is a linear sequential way of doing software; basically, you go only
    in one direction. It was adopted by software engineering from manufacturing and
    construction industries. The waterfall model steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Requirements
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Design
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implementation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Verification
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Maintenance
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The main problem is that due to the fact that this methodology was invented
    for manufacturing and construction, it is not agile at all. In these industries,
    every change or every problem that you face might cost you a lot, so all the precautions
    before moving on to the next stage have to be taken into consideration. Because
    of this, each stage takes quite a while, and therefore the time to market is reduced
    significantly.
  prefs: []
  type: TYPE_NORMAL
- en: With this methodology, before even starting to create the application, developers
    have to design all the features, and time is spent talking and planning before
    even a line of code is written. These type of scenarios make a lot of sense for
    the origins of this methodology, because if you are building a skyscraper or a
    residential home, you want to know how it will be designed and structured before
    even starting the construction itself. In software development, the quicker you
    get feedback, the quicker you can adapt and make the changes that are necessary
    to fit the needs of your customer. With waterfall, feedback isn't provided until
    the very end, when the product is almost ready and changes are more difficult
    to implement.
  prefs: []
  type: TYPE_NORMAL
- en: Waterfall in its own nature is monolithic and bulky, even though we have different
    teams working on different features of the product, and in the end all these features
    are compiled together to deliver a single big instance of a release. With this
    type of monolith, if there’s a **quality assurance** (**QA**) team, they have
    to test all the features of that release. This takes a lot of time and increases
    the time to market the product even more. The worst case would be that a change
    is needed or a bug gets through QA into production. A rollback will imply the
    full release with all its features together instead of just the one with the bug,
    bringing a lot of risk to the table when it comes to big releases.
  prefs: []
  type: TYPE_NORMAL
- en: Agile solutions to monolithic problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With waterfall, we realize too late that things that we thought that are going
    to work didn’t work as planned in the installation stage, or even later in the
    production stage. Performing those changes implied a whole lot of steps, and course
    correction was slow and painful.
  prefs: []
  type: TYPE_NORMAL
- en: Software evolves quickly, and the needs of our clients might change in the middle
    of the design. That’s why we need a more agile and flexible methodology other
    than waterfall. The quicker we get feedback, the quicker we can adapt and deliver
    the exact expectations of our customers.
  prefs: []
  type: TYPE_NORMAL
- en: This is exactly what the **Agile** methodology is for. Agile seeks to deliver
    the software in multiple releases, each one going through a set of tests and feedback
    in order to obtain it more quickly and make changes and course correction in a
    quicker and more agile way.
  prefs: []
  type: TYPE_NORMAL
- en: Agile was a game changer, but it generated conflicts between **operations**
    and **developers**.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying releases more frequently can be unstandardized and different every
    time, if a different engineer performs the deployment. Let's say you have a deployment
    at night. If the person who is deploying in the morning is a different engineer
    than the one that performed the last deployment, they could have a completely
    different way of deploying the code to production. These types of things generate
    discrepancy and can cause problem. For example, if something happens and it needs
    to be rolled back, a different person rolling it back might not know what the
    steps that were taken in deployment were in order to roll back the changes.
  prefs: []
  type: TYPE_NORMAL
- en: With these releases, system availability can be affected unpredictably. Operations
    engineers are measured by the stability of the systems that they are managing,
    and it's in their interest to keep it that way. Deploying unpredictable changes
    to production is something that they want to avoid. Developers, on the other hand,
    are measured by how quickly they can put their new changes, features, and releases
    into production. You can see how these two teams have completely opposite goals,
    and they almost have to fight each other to fulfil them.
  prefs: []
  type: TYPE_NORMAL
- en: Different goals across teams isolates each team from another. This creates silos,
    and throws the problem or app over the fence. This develops into a non-collaborative
    working environment, where everybody blames one another and things move at an
    even slower pace, instead of solving the problem.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous culture for CI/CD
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, I feel that you have noticed that we haven't talked about any tools
    to make DevOps possible. This is because tools will not solve all these types
    of problems. They will help you and your customers enforce the DevOps culture,
    but they are not what makes DevOps possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Standardization and testing before we deliver our product is essential to Agile
    and DevOps, and tools will help us achieve these two goals. Let’s take a look
    into the Agile workflow and the DevOps workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a look at the Agile workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aee6ce74-5f90-4690-97e0-50ba754b576a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here is how it compares to DevOps:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1e4a7937-d1ea-4444-9564-fb1766d52748.png)'
  prefs: []
  type: TYPE_IMG
- en: It is very clear that both go hand in hand and that they overlap each other,
    as they seek the same goals. DevOps has extra steps, such as operate and monitor,
    which take place after the deployment of the code. These steps are very self-explanatory;
    monitor consists of monitoring our application in production, checking its behavior
    regarding whether it presents any bugs, of whether it is using all the resources
    that were allocated to it. Operate the hardware, VM, or PaaS where it was deployed.
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind **continuous deployment** (**CD**) and **continuous integration**
    (**CI**) is to bring us standardization and the means for us to make sure that
    changes and releases make it into production as quickly as possible with the least
    possible failures. If a failure happens, we can revert quickly and easily as well.
    The whole point of CI/CD is to automate manual processes, and many companies still
    compile releases manually and still send emails to operations with the binaries
    and instructions on how to deploy their code. To achieve CI/CD, we have tools
    that will help us automate the whole build, test, deploy, and release cycle.
  prefs: []
  type: TYPE_NORMAL
- en: A typical pipeline of CI/CD is triggered by a commit to a Git repository, which
    then triggers an automated build process that usually generates an artifact or
    a drop, which triggers automated testing and automated deployment of the application.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at some of the different open source tools, with a brief explanation
    of each and to which stage of the DevOps cycle it belongs to.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is nowhere near an extensive list, and the explanations are a brief summary
    of their purpose:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Code**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Git**: A version control system that allows developers to have a distributed
    repository of their code and track changes across the development cycle.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GitHub, GitLab, Bitbucket**: These three are Git type repositories instead
    of tools. However, they are worth the mentioning, as they are the most used public
    and private repositories of Git that are used in the industry.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Apache subversion** (**SVN**): This is another versioning system. Although
    it is no longer as popular as it was since the release of Git, it is worth mentioning
    that it exists, as you might run into it in legacy environments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Build**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Docker**: Docker, as we discussed in the [Chapter 14](70b68225-f724-4ff8-a1bf-84c77ad23a2b.xhtml),
    *Getting Your Hands Salty*, is a tool you can use to build your container images,
    independent of which language your application is written in. Docker uses **Buildkit**
    under the hood, which can also be used as a standalone product to build the docker
    images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Apache ant**: This tool was the first one to replace the famous Unix build
    binary that was made for Java applications. It uses `xml` to define the steps
    of the build. This tool is mainly for Java applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Apache Maven**: Apache Maven is also another Java build tool, but it came
    to fix problems such as dependency management that Apache Ant lacked.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gradle**: Grade was built on the basis of Apache Ant and Apache Maven, but
    Gradle uses it''s own specific language based on Groovy for defining the steps
    that are required. Gradle is the most modular of all, and mostly all functionalities
    are added through plugins.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Grunt**: This is the Ant or Maven equivalent of JavaScript; it automates
    and runs tasks such as linting, unit testing, minification, and compilation. Grunt
    is highly modular, as there are thousands of plugins available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Selenium**: This is mainly a web application tester that can be run against
    of most modern-day web browsers. With Selenium, you don''t necessarily need to
    know a test programming language as it offers an IDE and the option to use several
    of the most popular programming languages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Apache JMeter**: This is basically a load performance tool that generates
    a heavy load on servers to test static and dynamic content so that you can analyse
    its performance on different load types.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Appium**: On the other hand, Appium not only tests web applications, but
    it can also perform tests on mobile and desktop apps.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Release, Deploy, Manage, Orchestrate, Operate**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Jenkins**: This is probably the most used tool in the DevOps culture. Jenkins
    is an automation server that makes all the steps possible via triggers that call
    the automation of the build and the release process, as well as any automated
    testing that is configured in the pipelines.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ansible**: This is mostly a configuration management tool, but it can also
    help us release our applications via its modularity and provides an easy way of
    developing your own playbooks to run against a set of servers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Puppet**: This is another configuration management tool that helps us maintain
    configurations and manage package patch installations on our environment servers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Helm**: Look at Helm as the `yum` or the `apt` of Kubernetes: on its own,
    it is unable to automate any deployment process, but with the help of tools such
    as Jenkins, you can use it to deploy your own custom charts to Kubernetes, as
    well as keep a release history if a rollback is needed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitor**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Nagios**: This is the classical monitoring centralized tool that monitors
    everything from system performance to the status of services and much more.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prometheus**: A project under the umbrella of the cloud native computing
    foundation. It allows us to create our own metrics and alerting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fluentbit**: This allows you to collect multiple logs and/or data and send
    it to multiple destinations for log gathering or processing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This being the last chapter, we wrapped up with some considerations when designing
    solutions. In this chapter, we went through what we should have in mind when dealing
    with different scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing where and how we'll be deploying our solutions helps us have an idea
    of what sort of requirements might be in place; for example, certain industries
    will have hard requirements that can't be ignored, such as HIPAA, PCI, and GDPR.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we spoke about deploying on-premises solutions and how different workloads
    are better for bare metal and what considerations to have when implementing in
    VMs.
  prefs: []
  type: TYPE_NORMAL
- en: We touched on how moving to the cloud is not as simple as clicking on a portal
    and waiting, but rather how it is a journey, since it allows for the modernization
    of workloads given the plethora of options available in the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Also, we mentioned that there are different methods for migrating existing workloads,
    such as lift and shift, refactor, rearchitect, and rebuild.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we described how DevOps is helping shape the industry by unifying the
    development and operations aspects and how this ties with how CI/CD has changed
    how software is deployed and used.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is HIPAA?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What workloads are preferred to run on bare metal?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Should hypervisors run on bare metal?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do VMs share resources?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is network segmentation?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is lift and shift?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is refactor?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is Rearchitect?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Production of Large Computer Programs**: [http://sunset.usc.edu/csse/TECHRPTS/1983/usccse83-501/usccse83-501.pdf](http://sunset.usc.edu/csse/TECHRPTS/1983/usccse83-501/usccse83-501.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Managing the development of large software systems**: [http://www-scf.usc.edu/~csci201/lectures/Lecture11/royce1970.pdf](http://www-scf.usc.edu/~csci201/lectures/Lecture11/royce1970.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure Migration Center**: [https://azure.microsoft.com/en-gb/migration/get-started/](https://azure.microsoft.com/en-gb/migration/get-started/)'
  prefs: []
  type: TYPE_NORMAL
- en: '**3 Journeys for Migrating a Data Center to Cloud IaaS**: [https://www.gartner.com/smarterwithgartner/3-journeys-for-migrating-a-data-center-to-cloud-iaas/](https://www.gartner.com/smarterwithgartner/3-journeys-for-migrating-a-data-center-to-cloud-iaas/)'
  prefs: []
  type: TYPE_NORMAL
