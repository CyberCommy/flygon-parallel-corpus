- en: Chapter 4. Working with Strings
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章。处理字符串
- en: Text data is the most important and pervasive form of data that modern applications
    deal with. The ability to process text data efficiently through intuitive abstractions
    is a key marker of effectiveness in dealing with text data. Boost has a number
    of libraries dedicated toward effective text processing that enhance and extend
    the capabilities provided by the C++ Standard Library.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 文本数据是现代应用程序处理的最重要和普遍的数据形式。通过直观的抽象有效地处理文本数据的能力是处理文本数据有效性的关键标志。Boost有许多专门用于有效文本处理的库，增强和扩展了C++标准库提供的功能。
- en: 'In this chapter, we will look at three key Boost libraries for processing text
    data. We will start with the Boost String Algorithms library, a library of general-purpose
    algorithms for text data that provides a host of easy text operations, often missed
    in the Standard Library. We will then look at the Boost Tokenizer library, an
    extensible framework for tokenizing string data based on various criteria. Thereafter,
    we will examine a regular expression library for searching and parsing strings,
    Boost.Regex, which has been included in the C++11 standard as well. The following
    topics appear in the following sections:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍三个用于处理文本数据的关键Boost库。我们将从Boost String Algorithms库开始，这是一个通用文本数据算法库，提供了大量易于使用的文本操作，通常在标准库中被忽略。然后我们将介绍Boost
    Tokenizer库，这是一个基于各种标准对字符串数据进行标记的可扩展框架。之后，我们将研究一个用于搜索和解析字符串的正则表达式库Boost.Regex，它也已经包含在C++11标准中。以下主题将出现在以下各节中：
- en: Text processing with Boost String Algorithms library
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Boost String Algorithms库进行文本处理
- en: Splitting text using the Boost Tokenizer library
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Boost Tokenizer库拆分文本
- en: Regular expressions with Boost.Regex
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Boost.Regex进行正则表达式
- en: This chapter should help you get a good grasp of text processing techniques
    available in the Boost libraries. We do not deal with internationalization issues
    in this book, but most of the concepts discussed in this chapter will apply to
    text in languages with writing systems based on non-Latin character sets.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章应该帮助您充分掌握Boost库中可用的文本处理技术。本书不涉及国际化问题，但本章讨论的大部分概念将适用于基于非拉丁字符集的书写系统的语言中的文本。
- en: Text processing with Boost String Algorithms library
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Boost String Algorithms库进行文本处理
- en: 'Text data is commonly represented as a sequence or *string* of characters laid
    out contiguously in memory and terminated by a special marker (the null terminator).
    While the actual data type used to represent a character can vary case by case,
    the C++ Standard Library abstracts the string concept in the class template `std::basic_string`,
    which takes the character data type as a parameter. The `std::basic_string` template
    takes three type parameters:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 文本数据通常表示为内存中连续布置的字符序列或*字符串*，并以特殊标记（空终止符）终止。虽然用于表示字符的实际数据类型可能因情况而异，但C++标准库在类模板`std::basic_string`中抽象了字符串概念，该模板将字符数据类型作为参数。`std::basic_string`模板有三个类型参数：
- en: The character type
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符类型
- en: Some of the intrinsic properties and behaviors of the character type encapsulated
    in a traits class
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 封装在特征类中的字符类型的一些固有属性和行为
- en: An allocator type that is used to allocate the internal data structures for
    `std::basic_string`
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于为`std::basic_string`分配内部数据结构的分配器类型
- en: 'The traits and allocator parameters are defaulted, as shown in the following
    snippet:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 特征和分配器参数被默认设置，如下面的片段所示：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The C++03 Standard Library also provides two specializations of `std::basic_string`:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: C++03标准库还提供了`std::basic_string`的两个特化：
- en: '`std::string` for narrow characters (8-bit `char`)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::string` 用于窄字符（8位 `char`）'
- en: '`std::wstring` for wide characters (16- or 32-bit `wchar_t`)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::wstring` 用于宽字符（16位或32位 `wchar_t`）'
- en: 'In C++11, we have two more:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在C++11中，我们还有两个：
- en: '`std::u16string` (for `u16char_t`)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::u16string`（用于`u16char_t`）'
- en: '`std::u32string` (for `u32char_t`)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::u32string`（用于`u32char_t`）'
- en: In addition to these classes, plain old C-style strings, which are just arrays
    of `char` or `wchar_t` terminated by a null character, are also quite commonly
    used, especially in legacy C++ code.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些类，纯旧的C风格字符串，即由空字符终止的`char`或`wchar_t`数组，也是相当常用的，特别是在传统的C++代码中。
- en: There are two major shortcomings in the Standard Library, which makes dealing
    with text data types overly tedious at times. For one, there is only a limited
    set of readily available algorithms that can be applied to `string` and `wstring`.
    Moreover, most of these algorithms are member functions of `std::basic_string`
    and are not applicable to other string representations like character arrays.
    Even the algorithms available as non-member function templates deal in iterators
    rather than containers, making the code tedious and less flexible.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 标准库中存在两个主要缺陷，使得处理文本数据类型有时过于繁琐。首先，只有一组有限的可用算法可以应用于`string`和`wstring`。此外，大多数这些算法都是`std::basic_string`的成员函数，不适用于其他字符串表示形式，如字符数组。即使作为非成员函数模板可用的算法也处理迭代器而不是容器，使得代码繁琐且不够灵活。
- en: 'Consider how you would convert a string to its uppercase using the C++ Standard
    library:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一下如何使用C++标准库将字符串转换为大写：
- en: '**Listing 4.1: Changing a string to uppercase using std::transform**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**清单4.1：使用std::transform将字符串更改为大写**'
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We use the `std::transform` algorithm to convert a sequence of characters to
    their uppercase forms, using the `toupper` function from the Standard Library
    applied to each character (lines 8-9). The sequence of characters to transform
    is specified by a pair of iterators to the first character of the string `song`
    (`song.begin()`) and one past its last character (`song.end()`)—passed as the
    first two arguments to `std::transform`. The transformed sequence is written back
    in-place starting at `song.begin()`, which is the third argument to `std::transform`.
    You may not see a lot amiss if you have programmed in C++ for a while, but the
    generality of the `transform` function somewhat obscures the expression of intent.
    This is where Boost String Algorithms library helps by providing a slew of useful
    string algorithm function templates that are intuitively named and work effectively,
    sometimes even on different string abstractions. Consider the following alternative
    to the preceding code:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`std::transform`算法将一系列字符转换为它们的大写形式，使用标准库中的`toupper`函数应用于每个字符（第8-9行）。要转换的字符序列由一对迭代器指定，指向字符串“song”的第一个字符（`song.begin()`）和最后一个字符的下一个位置（`song.end()`）——作为`std::transform`的前两个参数传递。转换后的序列被就地写回，从`song.begin()`开始，这是`std::transform`的第三个参数。如果您已经在C++中编程了一段时间，可能不会看到太多问题，但是`transform`函数的普遍性有些掩盖了意图的表达。这就是Boost
    String Algorithms库的作用，它通过提供一系列有用的字符串算法函数模板来帮助，这些函数模板具有直观的命名并且有效地工作，有时甚至可以在不同的字符串抽象上使用。考虑以下替代前面代码的方法：
- en: '**Listing 4.2: Changing a string to uppercase using boost::to_upper**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 清单4.2：使用boost::to_upper将字符串转换为大写
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To convert the string `song` to uppercase, you call `boost::to_upper(song)`
    (line 8). We include the header `boost/algorithm/string.hpp` (line 2) to access
    `boost::to_upper`, which is an algorithm function template from Boost String Algorithms
    library. It is named `to_upper`, not `transform`, and takes just one argument
    instead of four and no iterators—what''s not to like? Also, you can run the same
    code on bare arrays:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 要将字符串“song”转换为大写，可以调用`boost::to_upper(song)`（第8行）。我们包含头文件`boost/algorithm/string.hpp`（第2行）来访问`boost::to_upper`，它是来自Boost
    String Algorithms库的算法函数模板。它被命名为`to_upper`，而不是`transform`，只需要一个参数而不是四个，也没有迭代器——有什么不喜欢的呢？此外，您可以在裸数组上运行相同的代码：
- en: '**Listing 4.3: Changing a character array to uppercase using boost::to_upper**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 清单4.3：使用boost::to_upper将字符数组转换为大写
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: But iterators let you choose the range you want to transform to uppercase and
    here, we only seem to be able to apply anything to the whole string. Actually,
    that's not a problem either as we shall see.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 但是迭代器让您选择要转换为大写的范围，而在这里，我们似乎只能将任何东西应用于整个字符串。实际上，这也不是问题，我们将会看到。
- en: Note
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Boost.Range**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**Boost.Range**'
- en: The algorithms from Boost String Algorithms library actually work on abstractions
    called ranges, not containers or iterators. A **range** is just a sequence of
    elements that can be completely traversed in some order. Loosely speaking, a container
    like `std::string` is a sequence of contiguous single-byte characters and a container
    like `std::list<Foo>` is a sequence of elements of type `Foo`. Thus, they qualify
    as valid ranges.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Boost String Algorithms库中的算法实际上是在称为范围的抽象上工作，而不是在容器或迭代器上工作。一个**范围**只是一系列元素，可以以某种顺序完全遍历。粗略地说，像`std::string`这样的容器是一系列连续的单字节字符，而像`std::list<Foo>`这样的容器是类型为`Foo`的元素序列。因此，它们都符合有效的范围。
- en: A simple range can be represented by a pair of iterators—one pointing to the
    first element in the range, and the other pointing to one past the last element
    in the range. A range can represent the entire sequence of elements in a container.
    Generalizing further, a range can be described as a subsequence of a container,
    that is, a subset of the elements in the container with their relative ordering
    preserved. For example, the subsequence of elements of a container with odd-numbered
    indexes is a valid range. A single iterator pair may not be sufficient to represent
    such a range; we need more constructs to represent them.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的范围可以由一对迭代器表示——一个指向范围中的第一个元素，另一个指向范围中最后一个元素的下一个元素。一个范围可以表示容器中所有元素的序列。进一步概括，范围可以被描述为容器的子序列，即容器中元素的子集，它们的相对顺序被保留。例如，容器中奇数索引的元素子序列是一个有效的范围。单个迭代器对可能不足以表示这样的范围；我们需要更多的构造来表示它们。
- en: The Boost.Range library provides the necessary abstractions and functions needed
    to generate and deal with all kinds of ranges. The class template `boost::iterator_range`
    is used to represent different kinds of ranges using a pair of iterators. The
    algorithms in Boost String Algorithms take parameters that are ranges and also
    return them, enabling chaining of calls, something that is not possible with most
    STL algorithms. We will not venture into too many details of Boost.Range in this
    chapter but will develop an intuitive understanding needed to use ranges with
    the String Algorithms library.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Boost.Range库提供了生成和处理各种范围所需的必要抽象和函数。类模板`boost::iterator_range`用于使用一对迭代器表示不同类型的范围。Boost
    String Algorithms中的算法接受范围作为参数，并返回范围，从而实现调用的链接，这是大多数STL算法无法实现的。在本章中，我们不会深入讨论Boost.Range的细节，但会发展对使用String
    Algorithms库的范围所需的直观理解。
- en: 'If we want to transform the case of only a part of a string, we will need to
    construct a range representing that section. We can use the `boost::iterator_range`
    class template to generate arbitrary ranges. Here is how we do it:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只想转换字符串的一部分大小写，我们需要构造表示该部分的范围。我们可以使用`boost::iterator_range`类模板生成任意范围。下面是我们如何做到的：
- en: '**Listing 4.4: Changing a section of a string to uppercase using to_upper**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 清单4.4：使用to_upper将字符串的一部分转换为大写
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Specifically, we want to construct the range using two iterators to a string.
    So, the type of the range will be `boost::iterator_range<std::string::iterator>`.
    We create a typedef for this rather long type name (lines 8-9). We wish to change
    the word `"sixties"` in the string `"Green-tinted sixties mind"` to uppercase.
    This word starts at index 13 of the string `song` and is seven characters long.
    So, the iterators that define the range containing `"sixties"` are `song.begin()
    + 13` and `song.begin() + 13 + 7`, that is, `song.begin() + 20`. The actual range
    (`range`) is constructed by passing these two iterators to the function template
    `boost::make_iterator_range` (lines 10-11). We pass this range to the `boost::to_upper`
    algorithm, which changes the case of the substring `"sixties"` (line 12), and
    we assert on the expected change (line 13).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们希望使用两个迭代器来构造字符串的范围。因此，范围的类型将是`boost::iterator_range<std::string::iterator>`。我们为这个相当长的类型名称创建了一个typedef（第8-9行）。我们希望将字符串`"Green-tinted
    sixties mind"`中的单词`"sixties"`更改为大写。这个单词从字符串`song`的索引13开始，长度为7个字符。因此，定义包含`"sixties"`的范围的迭代器是`song.begin()
    + 13`和`song.begin() + 13 + 7`，即`song.begin() + 20`。通过将这两个迭代器传递给函数模板`boost::make_iterator_range`（第10-11行）来构造实际范围（`range`）。我们将这个范围传递给`boost::to_upper`算法，它更改了子字符串`"sixties"`的大小写（第12行），并且我们断言预期的更改（第13行）。
- en: 'This may look like a lot of code but remember that you don''t have to construct
    an explicit range when you apply an algorithm to the whole string or container.
    Also, if you are using C++11, the `auto` keyword can help reduce verbosity; thus
    you can replace the highlighted lines (8-11) like this:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能看起来是很多代码，但请记住，当您将算法应用于整个字符串或容器时，您不必构造显式范围。此外，如果您使用C++11，`auto`关键字可以帮助减少冗长；因此，您可以像这样替换突出显示的行（8-11行）：
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: You can learn more about the `auto` keyword in [Appendix](apa.html "Appendix A. C++11
    Language Features Emulation"), *C++11 Language Features Emulation*.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[附录](apa.html "附录 A. C++11语言特性模拟")中了解有关`auto`关键字的更多信息，*C++11语言特性模拟*。
- en: 'Constructing iterator ranges from arrays is not all that different either:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 从数组构造迭代器范围也并不完全不同：
- en: '**Listing 4.5: Changing a section of a char array to uppercase using to_upper**'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**清单4.5：使用to_upper将char数组的一部分更改为大写**'
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The range is defined to be of type `boost::iterator_range<char*>`, the type
    of the iterator for the array being `char*` (line 9). Once again, we can use `auto`
    to eliminate all the syntactic pain if we are on C++11\. We create the iterator
    range using the appropriate offsets (8 and 16), bounding the word `"Taliesyn"`
    (lines 10-11) and transform the range using `boost::to_upper` (line 12).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 范围被定义为`boost::iterator_range<char*>`类型，数组的迭代器类型为`char*`（第9行）。再次，如果我们使用C++11，我们可以使用`auto`来消除所有的语法痛苦。我们使用适当的偏移量（8和16）创建迭代器范围，限定单词`"Taliesyn"`（第10-11行），并使用`boost::to_upper`转换范围（第12行）。
- en: Using Boost String Algorithms
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Boost字符串算法
- en: In this section, we explore the various string algorithms available to us and
    understand the conditions under which they can be applied. Before we look at specific
    algorithms though, we will try to understand the general scheme of things first.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨可用的各种字符串算法，并了解它们可以应用的条件。不过，在我们查看具体算法之前，我们将首先尝试了解事情的一般方案。
- en: 'Consider the algorithm `boost::contains`. It checks whether the string passed,
    as its second argument, is a substring of the string passed as its first argument:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑算法`boost::contains`。它检查作为第二个参数传递的字符串是否是作为第一个参数传递的字符串的子字符串：
- en: '**Listing 4.6: Using boost::contains**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**清单4.6：使用boost::contains**'
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The algorithm `boost::contains` should return true because `"linearize"` contains
    the substring `"near"` (line 8). While this call to `boost::contains` returns
    true, had we set `test` to `"Near"` instead of `"near"`, it would return false.
    If we want to check for substrings without caring about the case, we have to use
    `boost::icontains` instead as a drop-in replacement for `boost::contains`. Like
    `boost::contains`, most algorithms from Boost String Algorithms have a case insensitive
    version with an `i-` prefix.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 算法`boost::contains`应该返回true，因为`"linearize"`包含子字符串`"near"`（第8行）。虽然调用`boost::contains`返回true，但如果我们将`test`设置为`"Near"`而不是`"near"`，它将返回false。如果我们想要检查子字符串而不关心大小写，我们必须使用`boost::icontains`作为`boost::contains`的替代品。与`boost::contains`一样，来自Boost字符串算法的大多数算法都有一个不区分大小写的版本，带有`i-`前缀。
- en: 'Unlike `boost::contains`, some string algorithms generate a modified string
    content based on the string passed to it. For example, `boost::to_lower` converts
    the string content passed to it to lowercase. It does so by changing the string
    in-place thus, modifying its argument. A non-mutating version of the algorithm
    called `boost::to_lower_copy` copies the passed string, transforms the case of
    the copied string, and returns it, without modifying the original string. Such
    non-mutating variants have the `_copy` suffix in their names. Here is a short
    example:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 与`boost::contains`不同，一些字符串算法根据传递给它的字符串生成修改后的字符串内容。例如，`boost::to_lower`将传递给它的字符串内容转换为小写。它通过就地更改字符串来实现这一点，从而修改其参数。算法的非变异版本称为`boost::to_lower_copy`，它复制传递的字符串，转换复制的字符串的大小写，并返回它，而不修改原始字符串。这样的非变异变体在其名称中具有`_copy`后缀。这里是一个简短的例子：
- en: '**Listing 4.7: Using _copy versions of Boost String Algorithms**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**清单4.7：使用_boost字符串算法的_copy版本**'
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The string `str1` is first copied and converted to lowercase using the non-mutating
    variant `boost::to_lower_copy`, and the result is assigned to `str2` (line 7).
    At this point, `str1` remains unchanged. Next, `str1` is converted to lowercase
    in-place, using `boost::to_lower` (line 9). At this point, both `str1` and `str2`
    have the same content (line 10). In most of what follows, we will work with case-sensitive
    variants and mutating variants where applicable, with the understanding that the
    case-insensitive and non-mutating (copy) versions of the algorithms also exist.
    We now start look at specific algorithms.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串`str1`首先被复制并转换为小写，使用非变异变体`boost::to_lower_copy`，结果被赋给`str2`（第7行）。此时，`str1`保持不变。接下来，`str1`被就地转换为小写，使用`boost::to_lower`（第9行）。此时，`str1`和`str2`都具有相同的内容（第10行）。在接下来的大部分内容中，我们将使用区分大小写的变体和适用的变异变体，理解到算法的不区分大小写和非变异（复制）版本也存在。我们现在开始查看特定的算法。
- en: Find algorithms
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 查找算法
- en: There are several variants of *find algorithm* available from the Boost String
    Algorithms library, all of which search for a string or pattern in another input
    string. Each algorithm takes the input string and the search string as parameters,
    converts them to ranges, and then performs the search. Each find-variant returns
    the contiguous subsequence in the input, which matches the search string or pattern,
    as a range. An empty range is returned if no match was found.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 从Boost String Algorithms库中有几种*find算法*的变体可用，所有这些算法都在另一个输入字符串中搜索字符串或模式。每个算法都将输入字符串和搜索字符串作为参数，将它们转换为范围，然后执行搜索。每个find变体都返回与搜索字符串或模式匹配的输入中的连续子序列作为范围。如果没有找到匹配项，则返回一个空范围。
- en: find_first
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: find_first
- en: 'We start by looking at `boost::find_first`, which looks for a string in another
    string:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先看一下`boost::find_first`，它在另一个字符串中查找一个字符串：
- en: '**Listing 4.8: Using boost::find_first**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**清单4.8：使用boost::find_first**'
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We have an array of strings we want to search for, called `needles` (line 8).
    We also have a C-style string called `haystack`, in which we want to look for
    the search strings which contains the text we want to search for (line 7). We
    loop through each string in `needles` and call the `boost::find_first` algorithm
    to look for it in `haystack` (line 11). We check whether the search failed to
    find a match (line 13). If a match was found, then we compute the offset in `haystack`
    where the match was found (line 18). The range `ret` defines a range of the input
    string `haystack`; hence, we can always perform offset computations like `ret.begin()
    – haystack`.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个我们想要搜索的字符串数组，称为`needles`（第8行）。我们还有一个名为`haystack`的C风格字符串，在其中我们想要查找包含我们想要搜索的文本的搜索字符串（第7行）。我们循环遍历`needles`中的每个字符串，并调用`boost::find_first`算法在`haystack`中查找它（第11行）。我们检查搜索是否未能找到匹配项（第13行）。如果找到了匹配项，那么我们计算在`haystack`中找到匹配项的偏移量（第18行）。范围`ret`定义了输入字符串`haystack`的范围；因此，我们总是可以执行偏移计算，比如`ret.begin()
    - haystack`。
- en: The first iteration would be able to find `"little"`, while the second iteration
    would fail to find `"Little"` because `boost::find_first` is case-sensitive. If
    we used `boost::ifind_first` which performs case-insensitive search, then both
    would match.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次迭代将能够找到`"little"`，而第二次迭代将无法找到`"Little"`，因为`boost::find_first`是区分大小写的。如果我们使用`boost::ifind_first`执行不区分大小写的搜索，那么两者都会匹配。
- en: We use the C++11 `auto` keyword to escape writing an ungainly type for `ret`
    (line 11), but if we had to write, it would be `boost::iterator_range<char*>`.
    Note that we can actually stream the range `ret` returned from the algorithm to
    an output stream (line 22).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用C++11的`auto`关键字来避免编写一个笨拙的`ret`类型（第11行），但如果我们不得不写，它将是`boost::iterator_range<char*>`。请注意，我们实际上可以将从算法返回的范围`ret`流式传输到输出流（第22行）。
- en: 'This example illustrates the technique on C-style character arrays but to apply
    it to `std::string` would require surprisingly little change. If `haystack` was
    a `std::string` instance, then the only change will be in the way we calculate
    offsets (line 18):'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子说明了在C风格字符数组上的技术，但将其应用到`std::string`将需要惊人地少的更改。如果`haystack`是一个`std::string`实例，那么唯一的变化将在我们计算偏移量的方式上（第18行）：
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Since `haystack` is not a character array but an `std::string`, the iterator
    to its start is obtained via a call to its `begin()` member function.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`haystack`不是字符数组而是一个`std::string`，所以通过调用其`begin()`成员函数来获得其开始的迭代器。
- en: If we want to find the last instance of the search string in `haystack` instead
    of the first, we can replace `boost::find_first` with `boost::find_last`. If there
    are potentially multiple matching tokens, we may ask for a specific match by index.
    For this, we would need to call `boost::find_nth`, passing it a third argument,
    which would be a zero-based index of the match. We may pass a negative index to
    ask for matches from the end. Thus, passing `-1` would give us the last match,
    `-2` the second-last match, and so on.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要找到`haystack`中搜索字符串的最后一个实例，而不是第一个实例，我们可以用`boost::find_last`替换`boost::find_first`。如果可能有多个匹配的标记，我们可以通过索引要求特定的匹配。为此，我们需要调用`boost::find_nth`，传递第三个参数，这将是匹配的基于零的索引。我们可以传递负索引来要求从末尾匹配。因此，传递`-1`会给我们最后一个匹配，`-2`会给我们倒数第二个匹配，依此类推。
- en: find_all
  id: totrans-71
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: find_all
- en: 'To find all matching substrings in an input string, we must use `boost::find_all`
    and pass it a sequence container to put all the matched substrings into. Here
    is a short example of how to do it:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 要在输入字符串中找到所有匹配的子字符串，我们必须使用`boost::find_all`并将其传递给一个序列容器，以便将所有匹配的子字符串放入其中。以下是如何做的一个简短示例：
- en: '**Listing 4.9: Using boost::find_all to find all matching substrings**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**清单4.9：使用boost::find_all查找所有匹配的子字符串**'
- en: '[PRE11]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We first create a typedef `string_range` for the appropriate range type (lines
    8-9). The `boost::find_all` algorithm copies all the matching ranges into the
    vector of ranges, `matches` (line 14). We iterate over the vector `matches` using
    C++11's new **range-based for-loop** syntax (line 15), and print the offsets at
    which each match was found (line 17). The nifty range-based for-loop declares
    a loop variable `match` to iterate over successive elements of the container `matches`.
    Using the `auto` keyword, the type of `match` is automatically deduced based on
    the type of values contained in `matches`. Using a vector of ranges rather than
    a vector of strings, we are able to calculate the exact offsets in `str` at which
    the matches occur.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: find_token
  id: totrans-76
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One more interesting find algorithm is the `boost::find_token` algorithm. Using
    this algorithm, we can find substrings whose characters satisfy some predicate
    we specify. We can use a set of predefined predicates or define our own, although
    the latter approach requires a fair bit of work, and we will not attempt it in
    this book. In the next example, we search for hexadecimal numbers with four or
    more digits in a string. This will also illustrate how you can use functions to
    perform repeated searches.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: 'For this purpose, we use the `boost::is_xdigit` predicate, which returns true
    if a particular character passed to it is a valid hexadecimal character. Here
    is the sample code:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.10: Finding substrings using boost::find_token and predicates**'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The string `str` contains an interesting hexadecimal token (`0xbeeffed`). We
    pass `str` to `boost::find_token` along with an instance of the predicate `boost::is_xdigit`,
    which identifies valid hexadecimal digits (line 10). We indicate, using `boost::token_compress_on`,
    that contiguous matching characters should be concatenated (line 11); this option
    is turned off by default. The returned range `token` represents the currently
    matched substring. We loop as long as the returned range `token` is not empty,
    that is, `token.begin() != token.end()` (line 12), and print its contents if it
    is longer than 3 in length (line 13). Note the use of the function `boost::size`
    on `token`. This is one of several functions that can be used to compute properties
    of a range like its beginning and end iterators, size, and so on. Also, note that
    we can directly stream a range object like a token to an `ostream` object, such
    as `std::cout`, to print all the characters in the range (line 14).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: In each iteration, we search the remaining string after the match using `find_token`.
    The remaining string is constructed as a range called `remnant` (lines 17-18).
    The beginning of `remnant` is `token.end()`, which is the first position after
    the last matching token. The end of remnant is simply the end of the string `str.end()`.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: iter_find
  id: totrans-83
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Iterating through a string and finding all substrings matching some criterion
    is a common enough use case, and Boost provides an easier way to do this. By using
    `boost::iter_find` algorithm, passing it the input string, a finder functor, and
    a sequence container to hold the matched ranges, we can get the matching substrings
    back in the container passed. Here is the above example rewritten using `boost::iter_find`:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.11: Using boost::iter_find with boost::token_finder**'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The `boost::find_regex` algorithm can search a string for substrings that match
    a regular expression pattern. We will cover this algorithm when we deal with regular
    expressions using Boost.Regex, later in this chapter.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: find
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'There is a generic `boost::find` algorithm in terms of which most of the other
    find algorithms are implemented. Using the available finder-functor templates,
    as part of the string algorithms library, or writing our own, we can make the
    generic `boost::find` string algorithm do a variety of search tasks for us. Here
    is an example of using the `boost::last_finder` functor with `boost::find` algorithm
    to find the last matching substring—exactly what `boost::ifind_last` does. The
    `boost::last_finder` functor and others like it take an optional predicate and
    can be used to influence how character comparisons are done. To simulate the case-insensitive
    comparisons that `ifind_last` does, we need to pass a predicate that compares
    two characters in a case-insensitive way. For this, we use the `boost::is_iequal`
    predicate:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个通用的`boost::find`算法，大多数其他查找算法都是基于它实现的。使用可用的查找器-函数对象模板，作为字符串算法库的一部分，或编写我们自己的模板，我们可以让通用的`boost::find`字符串算法为我们执行各种搜索任务。以下是使用`boost::last_finder`函数对象与`boost::find`算法来查找最后一个匹配子字符串的示例——这正是`boost::ifind_last`所做的。`boost::last_finder`函数对象和类似它的其他函数对象接受一个可选的谓词，并且可以用于影响字符比较的方式。为了模拟`ifind_last`所做的不区分大小写的比较，我们需要传递一个以不区分大小写方式比较两个字符的谓词。为此，我们使用`boost::is_iequal`谓词：
- en: '[PRE14]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We call `boost::find` on `haystack` passing it the `boost::last_finder` functor.
    Since we want `last_finder` to perform case insensitive comparisons, we pass it
    an instance of the `boost::is_iequal` predicate. This works like `boost::ifind_last`
    and is essentially the way it is implemented. You can even pass your own predicates
    for character comparisons. Say you received an encoded message, where each character
    is shifted by 4, and it wraps around so that `a` is `e` and `z` is `d`. You can
    use the `equalsShift` functor in the following code to check whether a particular
    real word exists in the encoded text:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`haystack`上调用`boost::find`，传递`boost::last_finder`函数对象。由于我们希望`last_finder`执行不区分大小写的比较，因此我们传递了`boost::is_iequal`谓词的实例。这类似于`boost::ifind_last`，实际上就是它的实现方式。您甚至可以传递自己的字符比较谓词。假设您收到了一个编码消息，其中每个字符都向后移动了4个位置，并且环绕，因此`a`是`e`，`z`是`d`。您可以使用以下代码中的`equalsShift`函数对象来检查编码文本中是否存在特定的真实单词：
- en: '**Listing 4.12: Using custom predicates with Boost substring finders**'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**清单4.12：使用Boost子字符串查找器的自定义谓词**'
- en: '[PRE15]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Without decoding the whole string contained in the variable `encoded`, we want
    to find a substring of `encoded` that, when decoded would match the string contained
    in the variable `realWord`. In order to do this, we call `boost::find` with two
    arguments, the encoded input string called `encoded` and a predicate that returns
    `true` only if a matching substring is found (line 17-19).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在不解码变量`encoded`中包含的整个字符串的情况下，我们希望找到一个`encoded`的子字符串，解码后与变量`realWord`中包含的字符串匹配。为了做到这一点，我们调用`boost::find`，传递两个参数，编码输入字符串称为`encoded`，以及一个谓词，只有在找到匹配的子字符串时才返回`true`（第17-19行）。
- en: 'For the predicate, we construct a temporary class of type `boost::first_finder`,
    passing two arguments to its constructor: the word to look for is `realWord` and
    a binary predicate `EqualShift(4)`. The `EqualsShift` functor performs a case-insensitive
    comparison of two characters: one from the encoded input and one from the word
    to look up. It returns true if the first character is an encoding of the second
    character, according to the scheme of shifting by a fixed integer N, as described
    earlier (N=4 in our case).'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 对于谓词，我们构造了一个临时类，类型为`boost::first_finder`，将两个参数传递给它的构造函数：要查找的单词是`realWord`，二进制谓词`EqualShift(4)`。`EqualsShift`函数对象执行两个字符的不区分大小写比较：一个来自编码输入，一个来自要查找的单词。如果第一个字符是根据固定整数N进行的编码的第二个字符，则返回true，如前面描述的（在我们的例子中N=4）。
- en: find_head and find_tail
  id: totrans-96
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: find_head和find_tail
- en: 'There are a few more *find* algorithms like `boost::find_head` and `boost::find_tail`,
    which could well have been named `prefix` and `suffix` for that is exactly what
    they do—carve out a prefix or suffix of a specified length from a string:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些*find*算法，比如`boost::find_head`和`boost::find_tail`，它们本来可以被命名为`prefix`和`suffix`，因为它们确实是这样做的——从字符串中切出指定长度的前缀或后缀：
- en: '[PRE16]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: You call `find_head` with the input string and an offset. If the offset is a
    positive number `N`, `find_head` returns the first `N` characters in the input
    string or the whole string if `N` is larger than the size of the string. If the
    offset is a negative number `-N`, `find_head` returns the first `size - N` characters,
    where `size` represents the total number of characters in the string `run`.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 您使用输入字符串和偏移量调用`find_head`。如果偏移量是正数`N`，`find_head`返回输入字符串的前`N`个字符，如果`N`大于字符串的大小，则返回整个字符串。如果偏移量是负数`-N`，`find_head`返回前`size
    - N`个字符，其中`size`表示字符串`run`中的字符总数。
- en: You call `find_tail` with a string and an integer. When a positive integer `N`
    is passed, `find_tail` returns the last `N` characters of the input string or
    the whole string if `N` is larger than the size of the string. When a negative
    integer `-N` is passed, `find_tail` returns the last `size - N` characters in
    the string, where `size` represents the total number of characters in the string,
    an empty string if `N > size`.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 您使用字符串和整数调用`find_tail`。当传递正整数`N`时，`find_tail`返回输入字符串的最后`N`个字符，如果`N`大于字符串的大小，则返回整个字符串。当传递负整数`-N`时，`find_tail`返回字符串中的最后`size
    - N`个字符，其中`size`表示字符串中的字符总数，如果`N > size`，则返回空字符串。
- en: Other algorithms for testing string properties
  id: totrans-101
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 用于测试字符串属性的其他算法
- en: There exist several convenience functions, which make certain common operations
    very easy to code. Algorithms like `boost::starts_with` and `boost::ends_with`
    (and their case-insensitive variants), test whether a particular string is a prefix
    or suffix of another. To determine the dictionary order of two strings, you can
    use `boost::lexicographical_compare`. You can check for equality using `boost::equals`,
    and check whether a string is a substring of another using `boost::contains`.
    Corresponding case-insensitive variants exist for each of these functions, and
    the case-sensitive variants take an optional predicate for comparing characters.
    The Boost online documentation provides an adequately detailed listing of these
    functions and their behavior.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Case-conversion and trimming algorithms
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Changing the case of a string or some part of it and trimming extra whitespace
    that is preceding or trailing a string are very common tasks, which take a bit
    of effort to be done using only the Standard Library. We have already seen `boost::to_upper`,
    `boost::to_lower`, and their copying versions for performing case changes in action.
    In this section, we will apply these algorithms to more interesting ranges and
    also look at trimming algorithms.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Case-conversion algorithms
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'How does one convert alternate characters in a string to uppercase leaving
    the rest untouched? Since the `boost::to_upper` function takes a range, we need
    to somehow generate the range that contains alternate elements from the string.
    The way to do this is to use **range adaptors**. Boost Range library provides
    a number of adaptors that allow the generation of newer patterns of ranges from
    existing ones. The adaptor that we are looking for is the `strided` adaptor that
    allows traversing the range by skipping a fixed number of elements at each step.
    We need to skip just one element per step:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.13: Generating non-contiguous ranges with Boost.Range adaptors**'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In order to apply the `boost::to_upper` algorithm to the even-indexed characters,
    we first generate the correct range. The pipe operator (`operator |`) is overloaded
    to create an intuitive chaining syntax for adaptors, such as `strided`. Using
    the expression `str | strided(2)`, we are essentially applying the `strided` adaptor
    with an argument of `2` to the string `str` to get a range containing the even-indexed
    elements of `str` (line 11). Note that the `strided` adaptor always starts from
    the first character of the input.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: 'The same effect can be achieved by writing:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: I prefer the piped notation, as it seems a lot more expressive, especially when
    more adaptors need to be chained. Following the generation of this `range`, we
    apply `to_upper` to it (line 12) and expectedly, the even-index characters of
    `str` are transformed to uppercase (line 13).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: If we want to perform the same operation, but on all the odd indexes, there
    is one problem we need to solve. The `strided` adaptor takes the number to skip
    between two elements as an argument but always starts from the first character
    of the input. To start from the element at index 1 instead of 0, we have to take
    a slice of the container starting at the element we intend to start from (index
    1 in this case), and then apply `strided` with an argument of `2`.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: 'To take the slice first, we use another adaptor, called `boost::adaptors::sliced`.
    It takes the indexes to the starting location and one past the ending location
    as arguments. In this case, we would like to start from index 1 and slice the
    rest of the container. So, we can write the entire expression like this:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Chaining adaptors in this way is a powerful way to generate ranges on the fly
    with a very readable syntax. The same techniques apply to C-style character arrays
    also.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Trimming algorithms
  id: totrans-117
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'For trimming strings, there are three main algorithms: `boost::trim_left` for
    trimming leading whitespace in a string, `boost::trim_right` for trimming trailing
    whitespace in a string, and `boost::trim` for trimming both. Trimming algorithms
    potentially change the length of the output. Each algorithm has an `_if` variant
    that takes a predicate, which is used to identify what characters to trim. For
    example, if you want to drop only trailing newlines from a string read from the
    console (a frequent chore), you may write an appropriate predicate to identify
    only newlines. Finally, there are copy variants of all these algorithms. If we
    wrote an expanded list of the available algorithms, there would be twelve of them;
    four for `trim_left`: `trim_left`, `trim_left_copy`, `trim_left_if`, and `trim_left_if_copy`;
    and similarly four for `trim_right` and `trim` each. Here is an example of performing
    trims on strings:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 对于修剪字符串，有三种主要的算法：`boost::trim_left`用于修剪字符串中的前导空白，`boost::trim_right`用于修剪字符串中的尾随空白，`boost::trim`用于修剪两者。修剪算法可能会改变输出的长度。每个算法都有一个带有谓词的`_if`变体，该谓词用于识别要修剪的字符。例如，如果您只想从从控制台读取的字符串中删除尾随换行符（经常需要这样做），您可以编写一个适当的谓词来仅识别换行符。最后，所有这些算法都有复制变体。如果我们列出可用算法的扩展列表，将会有十二种算法；`trim_left`有四种：`trim_left`、`trim_left_copy`、`trim_left_if`和`trim_left_if_copy`；`trim_right`和`trim`各有四种。以下是在字符串上执行修剪的示例：
- en: '**Listing 4.14: Using boost::trim and its variants**'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**清单4.14：使用boost::trim及其变体**'
- en: '[PRE20]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'In listing 4.14, we have two strings: `input` with leading and trailing spaces
    (line 12), and `input2` with trailing spaces and a newline at the end (line 13).
    By applying `boost::trim` on the `input`, the leading and trailing spaces are
    trimmed (line 15). If we had applied `boost::trim_right` on `input2`, it would
    have removed all trailing whitespaces, including the spaces and the newline. We
    only wanted to drop the newline, not the spaces; so we wrote a predicate `isNewline`
    to help choose what needs to be trimmed. This technique can be used for non-whitespace
    characters too.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在清单4.14中，我们有两个字符串：`input`具有前导和尾随空格（第12行），`input2`具有尾随空格和末尾的换行符（第13行）。通过在`input`上应用`boost::trim`，前导和尾随空格被修剪（第15行）。如果我们在`input2`上应用`boost::trim_right`，它将删除所有尾随空格，包括空格和换行符。我们只想删除换行符，而不是空格；因此，我们编写了一个谓词`isNewline`来帮助选择需要修剪的内容。这种技术也可以用于非空白字符。
- en: These functions do not work on C-style arrays and the non-copy versions expect
    a member function called `erase`. They work with the `basic_string` specializations
    in the Standard Library, and other classes that provide an `erase` member function
    with similar interface and semantics.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这些函数不适用于C风格数组，非复制版本期望一个名为`erase`的成员函数。它们适用于标准库中的`basic_string`特化，以及提供具有类似接口和语义的`erase`成员函数的其他类。
- en: The replace and erase algorithms
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 替换和删除算法
- en: The replace and erase algorithms are handy functions to perform search and replace
    operations on strings. The basic idea is to find one or more matches for a search
    string and replace the matches with a different string. Erase is a special case
    of replace, when we replace the matches with a null string.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 替换和删除算法是在字符串上执行搜索和替换操作的便捷函数。基本思想是查找一个或多个与搜索字符串匹配的内容，并用不同的字符串替换匹配项。擦除是替换的一种特殊情况，当我们用空字符串替换匹配项时。
- en: 'These operations may change the length of the input when performed in-place
    because the matched content and its replacement may have different lengths. The
    core algorithm in the library is `boost::find_format` in terms of which all other
    algorithms are implemented. The algorithms `boost::replace_first`, `boost::replace_last`,
    `boost::replace_nth`, and `boost::replace_all` respectively replace the first,
    last, nth, or all matching occurrences of a search string in the input with an
    alternative string. The corresponding erase algorithms simply erase the matched
    sections. These algorithms do not work on C-style arrays:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这些操作可能会在原地执行时改变输入的长度，因为匹配的内容及其替换可能具有不同的长度。库中的核心算法是`boost::find_format`，所有其他算法都是基于它实现的。算法`boost::replace_first`、`boost::replace_last`、`boost::replace_nth`和`boost::replace_all`分别用替换字符串替换输入中搜索字符串的第一个、最后一个、第n个或所有匹配的出现。相应的擦除算法简单地擦除匹配的部分。这些算法不适用于C风格数组：
- en: '**Listing 4.15: Using boost::replace and boost::erase variants**'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**清单4.15：使用boost::replace和boost::erase变体**'
- en: '[PRE21]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In listing 4.15, we first use the `boost::replace_first` algorithm to replace
    the first instance of the string `"Hello"` with `"Hola"` (line 9). Had we used
    `boost::replace_all` instead, both instances of `"Hello"` would be replaced, and
    we would get `"Hola, World! Hola folks!"`. We then call `boost::erase_first` to
    remove the remaining `"Hello"` in the string (line 11). Each of these algorithms
    has a case-insensitive variant, which matches in a case-insensitive way. Predictably,
    they are named with an `i-` prefix: `ireplace_first`, `ierase_first`, and so on.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在清单4.15中，我们首先使用`boost::replace_first`算法来将字符串`"Hello"`的第一个实例替换为`"Hola"`（第9行）。如果我们使用`boost::replace_all`，则会替换两个实例的`"Hello"`，并且我们将得到`"Hola,
    World! Hola folks!"`。然后我们调用`boost::erase_first`来删除字符串中剩余的`"Hello"`（第11行）。这些算法中的每一个都有一个不区分大小写的变体，以不区分大小写的方式进行匹配。可以预见地，它们以`i-`前缀命名：`ireplace_first`、`ierase_first`等等。
- en: 'There is a `_copy` variant of each algorithm returning too, a new string rather
    than changing in place. Here is a short illustration:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 每个算法都有一个返回新字符串的`_copy`变体，而不是原地更改。以下是一个简短的示例：
- en: '[PRE22]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Note how the `boost::ireplace_last_copy` variant worked here, matching `"hello"`
    in a case-insensitive manner and performing the replacement in a copy of the input.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意`boost::ireplace_last_copy`变体是如何工作的，以不区分大小写的方式匹配`"hello"`，并在输入的副本中执行替换。
- en: You can replace or erase a prefix or suffix of a string using `boost::replace_head`
    or `boost::replace_tail` (and their erase variants). The `boost::replace_regex`
    and `boost::replace_regex_all` algorithms take a regular expression for finding
    matches, and replace them with a replacement string. The replacement string may
    contain a special syntax to refer back to parts of the matched string, the details
    of which we will defer till the section on Boost.Regex, later in this chapter.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: The split and join algorithms
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Boost provides an algorithm called `boost::split`, which is essentially used
    to split an input string into tokens based on some separators. The algorithm is
    passed an input string, a predicate for identifying separators, and a sequence
    container to store the parsed tokens. Here is an example:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.16: Splitting a string on simple tokens using boost::split**'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The listing 4.16 will list out the four types of dogs that appear in the string
    `dogtypes` separated by commas and spaces (line 9). It uses the `boost::split`
    algorithm to do so. The `dogtypes` string is tokenized using the predicate `boost::is_any_of("
    ,")`, which identifies any space or comma as a separator (line 11).The `boost::token_compress_on`
    option ensures that the `boost::split` algorithm does not return an empty string
    for each adjacent pair of separator characters but clubs them together, treating
    it as a single separator (line 12). If we want to split a string at any punctuation
    mark, we will use `boost::is_punct()` instead of `boost::is_any_of(…)`. However,
    it is a somewhat inflexible scheme of tokenizing with only a limited set of predicates
    available.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: 'If you simply want to split a string using another string as a separator, you
    may use `boost::iter_split` instead:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.17: Using boost::iter_split to tokenize strings**'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The main difference between `boost::split` and `boost::iter_split` is that in
    the latter, you use a finder to identify a separator, which can thus be a specific
    string. Both `boost::iter_split` and `boost::iter_find` take the same kind of
    arguments and use a finder to search for a matching substring, but `boost::iter_split`
    returns tokens that lie between two matching substrings, while its complement
    `boost::iter_find` returns the matching substring.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the `boost::join` and `boost::join_if` algorithms are pretty useful
    when you are trying to string together a sequence of values with some separator
    between successive values. While `boost::join` concatenates all the values in
    the sequence, `boost::join_if` concatenates only those values from the sequence
    that satisfy a passed predicate. Here is `boost::join` in action taking a vector
    of strings and a separator, and returning the joined string:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'In the preceding example, we see yet another useful C++11 feature in action:
    uniform initialization. We initialize the vector `vec` with a sequence of four
    strings enclosed in braces and separated by a comma. This initialization syntax
    works for all STL containers and can be used with regular classes with specific
    types of constructors. Now, if we wanted to pick and choose which strings were
    concatenated and which were not, we would use `boost::join_if` like this:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The `fiveOrLessChars` predicate checks whether the string passed to it is of
    length five or less. Thus, the string `"mongrel"` does not feature in the joined
    string as its length is more than five.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Splitting text using the Boost Tokenizer library
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `boost::split` algorithm, we saw in the last section, splits a string using
    a predicate and puts the tokens into a sequence container. It requires extra storage
    for storing all the tokens, and the user has limited choices for the tokenizing
    criteria used. Splitting a string into a series of tokens based on various criteria
    is a frequent programming requirement, and the Boost.Tokenizer library provides
    an extensible framework for accomplishing this. Also, this does not require extra
    storage for storing tokens. It provides a generic interface to retrieve successive
    tokens from a string. The criterion to split the string into successive tokens
    is passed as a parameter. The Tokenizer library itself provides a few reusable,
    commonly used tokenizing policies for splitting, but, most importantly, it defines
    an interface using which we can write our own splitting policies. It treats the
    input string like a container of tokens from which successive tokens may be parsed
    out.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Tokenizing based on separators
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To begin with, let''s see how we can split a string into its constituent words:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.19: Using Boost Tokenizer to tokenize strings into words**'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The `boost::tokenizer` class template abstracts the tokenization process. We
    create an instance of the default specialization of `boost::tokenizer`, passing
    it our input string `input` (line 10). Next, using the iterator interface of `boost::tokenizer`,
    we split `input` into successive tokens (lines 12-14). In general, you can customize
    how strings are split by passing appropriate tokenizing policies. As we did not
    pass one explicitly to the `boost::tokenizer` template, the default tokenizing
    policy splits the string using whitespace and punctuation as token delimiters
    or separators. The preceding code will print the following output to the standard
    output:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Thus, it splits not only on spaces but also commas and apostrophes; `"I've"`
    is split into `"I"` and `"ve"` due to the apostrophe.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: 'If we wanted to split the input based on spaces and punctuation but not split
    on an apostrophe, we would need to do more. Boost provides a few reusable templates
    for commonly used splitting policies. The `boost::char_delimiter` template splits
    the string using specified characters as delimiters. Here is the code:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.20: Using Boost Tokenizer with boost::char_separator**'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: In this case, we first construct the splitting policy `sep` using the `boost::char_separator`
    template (line 10). Since we are splitting text of type `std::string` whose character
    type is `char`, we must pass `char` as argument to `boost::char_separator` to
    specify that the delimiters are of type `char`. We can also write `boost::char_separator<std::string::value_type>`
    instead of `boost::char_separator<char>` to better express the relationship. We
    construct the list of punctuation marks and whitespace characters we would like
    to use as delimiters and pass it as the constructor argument of `sep`. Finally,
    we construct the tokenizer, passing it the input string `input` and the splitting
    policy `sep`. We iterate through the successive tokens using a range-based for-loop,
    which makes for less verbose code than when using a token iterator.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Tokenizing records with fields containing metacharacters
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `boost::char_delimiter` policy is not the only available splitting policy.
    Consider a comma-separated data format, as shown in the following output:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We have one record per line and three fields per record: the name, age, and
    city of residence of a person. We can parse such records with the `boost::char_separator`
    policy, passing it a comma as a separator character. Now, if we want to make the
    format a little richer, we may include full addresses of people instead of their
    current city. But addresses are longer fields, sometimes with embedded commas,
    and such addresses would break the parsing, which is based on using a comma as
    a separator. So, we decide to quote strings that may have embedded commas:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Quoting itself may not be enough. Some addresses might have quoted strings,
    and we would like to preserve those. To fix this, we decide on using backslash
    (`\`) as an escape character. Here is a fourth record with quoted strings in the
    address:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The trouble now is that it is no longer possible to parse the preceding records
    using the `boost::char_separator` policy. For such records, we should instead
    use `boost::escaped_list_char`. The `boost::escaped_list_char` policy is tailor-made
    for this kind of use. By default, it uses comma (,) as a field separator, double
    quotes (") as the quoting character, and backslash (\) as the escape character.
    To include commas in fields, quote the fields. To include quotes in the fields,
    escape the embedded quotes. We can now attempt to parse the most complex of the
    four persons'' records, as discussed earlier:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.21: Using boost::tokenizer with boost::escaped_list_separator**'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: An instance of `boost::tokenizer<boost::escaped_list_separator<char> >` is created
    (line 12) using the typedef (lines 10-11). This is really the only operative change
    to take care of for this new format. The record, hardcoded in the variable `input`,
    needs some extra level of escaping to be made into a valid C++ string literal
    (lines 7-8).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: 'If the record had a different set of metacharacters, say hyphen (-) for field
    separator, forward slash (/) for quotes, and tilde (~) for escaping, we would
    need to specify these explicitly, as the default options for `boost::escaped_list_separator<<char>
    >` would no longer work. Consider a person named Alon Ben-Ari, aged 35, who lives
    at 11/5 Zamenhoff St., Tel Aviv. Using the specified quote, field separators,
    and escape characters, this could be represented as:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The name field has a hyphen in the last name Ben-Ari. As hyphen is also a field
    separator, the name field must be quoted using forward slashes. The address field
    has a forward slash and since a forward slash is the quote character, the address
    field must be escaped with the escape character (~). Now it is our turn to tokenize
    it:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.22: Using boost::escaped_list_separator with funky delimiters**'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This is the output:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Tokenizing records with fixed-length fields
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One class of data formats that frequently occurs in financial transactions
    and several other domains consists of records at fixed offsets. Consider the following
    record format representing a payment instruction:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Here, the record is barely human readable and is meant for consumption only
    by a program. It has fields at fixed offsets whose meanings must be known by the
    parsing program. The individual fields are described here:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: In order to parse records like these, we use the `boost::offset_separator` splitting
    policy. This class (note that it isn't a template) takes lengths of successive
    tokens to parse in the form of a pair of iterators, bounding the sequence of lengths.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: 'A code example to parse the preceding payment instruction should help illustrate
    the idea:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.23: Tokenizing records with fixed-length fields**'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: We first define an array containing the lengths of successive fields (line 10),
    and use it to initialize an object `ofs` of type `boost::offset_separator` (line
    12). We could have also used a vector instead of an array and passed its `begin()`
    and `end()` iterators to the `offset_separator` constructor. We then create a
    tokenizer, which tokenizes a string based on offsets specified in `ofs` (lines
    13-14), and print the successive tokens using a range-based for-loop (lines 16-18).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: 'This program produces the following output:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: We see listed on successive lines, we see listed the values of the date, time,
    ID, sender SWIFT bank code (an identifier for the sender bank), receiver SWIFT
    bank code, amount, and currency of the transaction.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, what happens if all the fields have been parsed and there is still some
    input left? The default behavior is to start parsing afresh the remaining text,
    applying the length offsets to it from the start. This may make sense for some
    formats and may not make sense for some. If you want to turn this behavior off
    so that the parsing stops once all the length offsets have been used, you should
    pass a third argument to the constructor of `boost::offset_separator`, and its
    value should be `false`, as shown here:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Here, `lengths` is the array of length offsets and `nfields` is the number of
    fields we expect to parse.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: 'Conversely, what happens if the input is shorter than the sum of the lengths?
    The default behavior is to return the last partially parsed field and stop. Suppose
    you have a format in which the payer''s comments are appended to each transaction
    record. A comment is optional and need not be there. If it is there, it may or
    may not have a maximum size limit. The first behavior can be used to parse the
    last comment field by specifying the maximum size, or an arbitrarily large size
    that you don''t expect the comments to reach, and thus leverage the partial parse
    of the last record. Again, if you want to turn this behavior off so that the first
    partial field encountered stops the parsing, you should pass a fourth argument
    of type `bool` to the `boost::offset_separator` constructor and its value should
    be `false`:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Writing your own tokenizer functions
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are many instances when you will need to parse a string according to some
    criteria that are not available in a reusable class or template in Boost. While
    you could use alternative libraries like `boost::split`, you can use the `boost::tokenizer`
    facility by plugging in a custom **token generator**. A token generator class
    encapsulates the tokenizing strategy and is passed as a template argument to `boost::tokenizer`.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: 'A token generator can be defined as a functor that conforms to the following
    requirements:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Is copy-assignable.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is copy-constructible.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Has an overloaded public function call operator (`operator()`) with the following
    signature:'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: This operator is passed two iterators that define a section of a string in which
    it looks for the next token it is passed. If and only if a new token is found,
    it returns true. In such case, it sets its third parameter to the token and its
    first parameter to the first position in the string after the end of the token,
    from where parsing may continue. It returns false if no token is found. We must
    write the logic to identify successive tokens in this function.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Has a public member function `void reset()`. This can be used to clear any member
    variables used to keep parsing state for a string. Then, the same instance of
    the object may be used to parse multiple inputs.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These functions are called by the `boost::tokenizer` implementation, never directly
    by the programmer.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: 'We now write a token generator class to pick from some text, strings that are
    quoted or bracketed. For example, given the string `"I''m taking a train from
    Frankfurt (am Main) to Frankfurt (an der Oder)"`, we want to pick out the tokens
    `"am Main"` and `"an der Oder"`. To simplify our implementation, given strings
    with nested brackets or quotes, only the content of innermost quotes need be retrieved.
    Thus, given the string `"tokenizer<char_separator<char> >"`, it should return
    `"char"`, the innermost bracketed entity. Here is the code for such a class, named
    `qstring_token_generator`:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.24a: The qstring_token_generator interface**'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The `qstring_token_generator` class has a constructor that takes the necessary
    inputs:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: The start and end marker characters, which are by default both double quotes
    (")
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The escape character, which is by default the backslash (\)
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Boolean indicating whether to skip empty tokens, which is by default true
    (lines 6-8)
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The corresponding private variables for storing these values are defined (lines
    18-21). The class uses two additional state variables to keep track of parsing
    state: the `in_token` variable (line 22) which is true while parsing content inside
    quotes and false otherwise, and the `in_escape` variable (line 23) which is true
    if the current character is part of an escape sequence and false otherwise. Here
    is the implementation of the constructor:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.24b: The qstring_token_generator constructor**'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Note that `in_token` and `in_escape` are initialized to false. Each time we
    iterate through the successive tokens in the input using the tokenizer interface,
    the tokenizer implementation calls the token generator to parse the input again.
    To start parsing afresh, any internal parsing state must be reset. The `reset`
    function encapsulates these actions and is called by the tokenizer when new token
    iterators are created.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the implementation of the reset function:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.24c: The qstring_token_generator reset function**'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The reset function makes sure that the internal variables used to maintain parsing
    state are reset appropriately for the parsing to restart.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the parsing algorithm is implemented in the overloaded function call
    operator member (`operator()`). To parse the string, we look for start and end
    markers to identify the start and end of tokens and count-escaped start and end
    markers as part of the tokens, and handle the case where the start and end markers
    are the same characters. We also handle cases where quoted tokens are nested.
    We will write the algorithms in terms of a few helper private functions in `qstring_token_generator`
    class.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.24d: The parsing algorithm helpers**'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: The `start_token` function is meant to be called each time we identify the beginning
    of a new token (line 1). It sets the `in_token` flag to true, increments the iterator
    `next`, and returns its value.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: The `end_token` function is meant to be called each time we identify the end
    of a token (line 7). It sets the `in_token` flag to false, increments the iterator
    `next`, and returns the complete token as a string.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: 'We now need to write the logic to identify the start and end of tokens and
    call the preceding function appropriately. We do this directly in the overloaded
    `operator()`:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.24e: The parsing algorithm**'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: We loop through the successive characters of the input using a while loop (line
    6). For each character, we check whether it is preceded by the escape character
    (line 7), or if it is the start marker (line 10), end marker (line 29), or the
    escape character (line 37).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: If an unescaped start marker is found, and we are not already in the middle
    of parsing a token (line 11), then it potentially represents the start of a new
    token. So, we call `start_token`, note the starting position of the token, and
    continue to the next iteration (lines 12-13). But if we are already in the middle
    of parsing a token, and we find the start marker, then there are two possibilities.
    If the start and end markers happen to be the same, then this represents the end
    of the token (line 15). In this case, we call `end_token` to get the complete
    token and return it unless it is empty and `skip_empty_tokens` is set (lines 16-20).
    If start and end markers are not the same, then a second start marker represents
    a nested token. Since we want to only extract the most nested token, we discard
    the previous token and call `start_token` to indicate that we have the start of
    a new token (lines 25-26).
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: If the end marker is distinct from the start marker, and we find it (line 29),
    then we call `end_token` generating and returning the complete token found, unless
    it is empty and `skip_empty_tokens` is set. Finally, if we find the escape character,
    we set the `in_escape` flag (lines 37-38).
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the `qstring_token_generator` class to tokenize our input string:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.25: Extracting bracketed strings using the custom tokenizer**'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The preceding highlighted code shows the key changes in our code. We define
    a `qstring_token_generator` object that takes a left and right quote character
    (in this case, left and right parentheses) and skips empty tokens (line 4). We
    then create a typedef for `boost::tokenizer<qstring_token_generator>` (line 4),
    create a tokenizer of that type to parse input (line 6), and print successive
    tokens (line 10).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Regular expressions using Boost.Regex
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we write a line of code like `boost::find_first("Where have all the flowers
    gone?", "flowers")`, we are asking for the string `"flowers"` (call it the **needle**)
    to be found in the larger string `"Where have all the flowers gone?"` (call it
    the **haystack**). The needle is the pattern; seven specific characters in a particular
    order whose presence must be looked up in the haystack. Sometimes, however, we
    don't know the exact string we are looking for; we only have an abstract idea
    or a pattern in mind. Regular expressions is a powerful language to express this
    abstract pattern.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: Regular expression syntax
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Regular expressions are strings that encode a pattern of text using a mix of
    regular characters and some characters with special interpretation, collectively
    called *metacharacters*. The Boost.Regex library provides functions that consume
    regular expression strings and generate the logic to search and verify text conforming
    to particular patterns. For example, to define the pattern, "a followed by zero
    or more b's", we use the regular expression `ab*`. This pattern will match text
    like `a`, `ab`, `abb`, `abbb`, and so on.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: Atoms
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At a very basic level, regular expressions consist of groups of one or more
    characters called **atoms**, each with an associated **quantifier** that trails
    the atom and optionally, **anchors** that define how some text is located relative
    to the surrounding text. The quantifier may be implicit. An atom can be a single
    character (or an escaped metacharacter), a **character class**, a string, or a
    **wildcard**. If it is a string, it must be enclosed in parentheses to indicate
    that it is an atom. A wildcard matches any character (other than a newline) and
    is written using the dot (.) metacharacter.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: Quantifiers
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A single atom without a trailing quantifier just matches a single occurrence
    of itself. When present, the trailing quantifier determines the minimum and maximum
    allowed occurrences of the preceding atom. The general quantifier looks like `{m,
    M}`, where `m` denotes minimum and `M` denotes maximum occurrence frequency. Omitting
    the maximum as in `{m,}` indicates that the maximum number of times the atom may
    be present is unbounded. One may also use a single number as `{n}` to match a
    fixed number of instances. More often, we use the following shortcut quantifiers:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '`*`: Equivalent to `{0,}`, called the **Kleene star**. Represents an atom that
    may not occur, or may occur any number of times.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`+`: Equivalent to `{1,}`. Represents an atom that must occur at least once.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`?`: Equivalent to `{0,1}`. Represents an optional atom.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using the above syntax rules, we construct summary examples in the following
    table:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '| Regular Expression | Atoms | Quantifier | Equivalent quantifier | Matching
    text |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
- en: '| W | w | None (implicit) | `{1}` | w |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
- en: '| a* | a | * | `{0,}` | (blank), a, aa, aaa, aaaa, … |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
- en: '| (abba)+ | abba | + | `{1,}` | abba, abbaabba, abbaabbaabba, … |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
- en: '| a?b | a, b | ? | `{0,1}` | b, ab |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
- en: '| (ab){2,4} | (ab) | {2,4} | `{2,4}` | abab, ababab, abababab |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
- en: '| .*x | . and x | * and None | `{0,}` and `{1}` | x and any string ending in
    x |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
- en: By default, quantifiers are *greedy* and match as many characters as possible.
    Thus, given the string `"abracadabra"`, the regular expression `"a.*a"` will match
    the entire string instead of the smaller substrings `"abra"`, `"abraca"`, or `"abracada"`,
    all of which also start and end in `'a'`. If we want to match only the smallest
    matching substring, we need to override the greedy semantics. To do this, we put
    the question mark (?) metacharacter after the quantifier `"a.*?a"`.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: Character classes
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Characters can also be matched against character classes, which are shorthand
    representations of a group of functionally related characters. The following is
    a partial list of predefined character classes in the Boost libraries:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '| Character class | Short form | Meaning | Complement |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
- en: '| [[:digit:]] | `\d` | Any decimal digit (0-9) | \D |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
- en: '| [[:space:]] | `\s` | Any whitespace character | \S |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
- en: '| [[:word:]] | `\w` | Any word character: letter, number, and underscore |
    \W |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
- en: '| [[:lower:]] | `\l` | Any lowercase character |   |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
- en: '| [[:upper:]] | `\u` | Any uppercase character |   |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
- en: '| [[:punct:]] | None | Any punctuation character |   |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
- en: For example, `\d` is a character class that matches a single decimal digit.
    Its complement \`D` matches any single character, except decimal digits. `\s`
    matches a whitespace character and `\S` matches a non-whitespace character. Ad
    hoc character classes can be created with square brackets; `[aeiouAEIOU]` matches
    any character that is an English vowel, `[1-5]` matches a digit between 1 and
    5 both inclusive. The expression `[^2-4]` matches any character except 2, 3, and
    4, and the leading caret inside the square brackets having the effect of negating
    the characters following it. We can combine multiple character classes something
    like—[[:digit:][:lower:]]—to indicate the set of lowercase letters and decimal
    digits.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: Anchors
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Certain metacharacters, referred to as **anchors**, do not match characters
    but can be used to match specific locations in text. For example, a caret (`^`)
    in a regular expression (outside a character class) matches text at the start
    of a line (just after a newline). A dollar(`$`) matches text before the end of
    a line (just before a newline). Also, `\b` represents a word boundary, while `\B`
    matches any location other than a word boundary.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: Sub-expressions
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In general, each character in a string of characters is interpreted as a distinct
    atom. In order to treat a string of characters as a single atom, we must parenthesize
    it. Parenthesized substrings of a regular expression are called **sub-expressions**.
    A quantifier following a sub-expression applies to the entire sub-expression:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: The preceding expression represents a number (`[1-9][0-9]*`) followed by zero
    or more words (`\w+`) separated from it and from each other by one or more whitespace
    characters (`\s+`). The second Kleene star applies to the entire sub-expression
    `\s+\w+` due to the parentheses.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: Regular expression libraries, including Boost.Regex keep track of substrings
    of a string that match the parenthesized sub-expressions. Matched sub-expressions
    can be referred back from within the regular expression using back-references,
    such as `\1`, `\2`, `\3`, and so on. For example, in the previous regular expression,
    the term `\1` matches the leading number, while `\2` matches the last matched
    word with leading spaces. It matches nothing if there are no trailing words. Sub-expressions
    can be nested and are numbered incrementally starting at 1 in the order that their
    left parentheses appear in the string from left to right.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: If you want to use sub-expressions to be able to apply quantifiers and anchors
    to groups of characters, but do not need to capture them for later reference,
    you can use **non-capturing sub-expressions** of the form `(?:expr)`, where the
    leading metacharacter sequence `?:` inside the parentheses indicates that it is
    a non-capturing sub-expression, and `expr` is some valid regular expression. This
    will treat expr as an atom, but will not capture it. Sub-expressions without the
    leading `?:` inside parentheses are thus called **capture groups** or **capturing
    sub-expressions**.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: Disjunctions
  id: totrans-276
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can create a regular expression that is a logical-or of one or more regular
    expressions. To do this, you use the |**disjunction operator**. For example, to
    match a word that contains a mix of lowercase and uppercase characters, you can
    use the expression `(\l|\u)+`.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: You can use the disjunction operator to combine regular expressions and form
    more complex expressions. For example, to match either a word containing upper
    or lowercase characters, or a positive integer, we can use the expression `(\l|\u)+|\d+`.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: Using Boost.Regex to parse regular expressions
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Regular expressions are a rich topic that we have barely scratched the surface
    of in the preceding paragraphs. But this basic familiarity is sufficient for us
    to start using the Boost.Regex library. The Boost.Regex library was one of the
    libraries that was accepted into the C++ 11 Standard and is now part of the C++
    11 Standard Library, minus its ability to handle Unicode characters.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: 'The Boost Regular Expressions library is *not* header-only and requires linking
    against the Boost.Regex shared or static library. It is available from the header
    file `boost/regex.hpp`. On my Linux desktop with Boost libraries installed via
    the native package manager, I use the following command line to build regex programs:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'On Linux systems, where Boost has been installed from source, the header files
    could be under a nonstandard location like `/opt/boost/include` and libraries
    under `/opt/boost/lib`. On such systems, I have to use the following command line
    to build my programs:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: The `-Wl`, `-rpath`, `/opt/boost/lib` directive tells the linker to hard-code
    the path from where shared libraries, like `libboost_regex-mt`, are loaded, and
    helps our program to run without additional settings. On Windows using Visual
    Studio, linking is automatic.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: It uses the `boost::basic_regex` template to model regular expressions and provides
    its specializations `boost::regex` for type `char` and `boost::wregex` for type
    `wchar_t` as typedefs. Using this library, we can check whether a string conforms
    to a pattern or contains a substring conforming to a pattern, extract all substrings
    of a string conforming to a pattern, replace a substring matching a pattern with
    another formatted string, and split a string based on a matching expression to
    name the few most commonly used operations.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: Matching text
  id: totrans-287
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Consider the string `"Alaska area"`. We want to match this against the regular
    expression `a.*a` to see whether the string fits the pattern. To do this, we need
    to call the `boost::regex_match` function, which returns a Boolean true to indicate
    a successful match and false otherwise. Here is the code for it:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.26: Matching a string with a regular expression**'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The regular expression `"a.*a"` is encapsulated in an instance of `boost::regex`.
    When we match the string against this expression, the match fails (line 8) because
    the string starts with an uppercase `''A''`, while the regular expression expects
    a lowercase `''a''` at the start. We could have asked for a case insensitive regular
    expression by constructing and passing `boost::regex::icase` as a flag to the
    `boost::regex` constructor:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Note that we called a different overload of `boost::regex_match`, which takes
    two iterators to a `std::string` (line 8) just to illustrate an alternative signature.
    You can also call `boost::regex_match` with a `const char*` or a `std::string`
    like in listing 4.25\. The outcome of the function is not dependent on the variant.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: Searching text
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If we want to search for substrings of a string that matches a particular regular
    expression, we should use the `boost::regex_search` function instead of `boost::regex_match`.
    Consider the string `"An array of papers from the academia on Alaska area''s fauna"`.
    We want to find all substrings that are part of the same word in this phrase and
    start and end with `''a''`. The regular expression to use would be `a\w*a`. Let
    us see how we can do this using `boost::regex_search`:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.27: Searching for substrings matching a regular expression**'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'This prints the following lines, each with a word or part of the word that
    begins and ends in `''a''`:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: In the code example, we construct the string (line 6), the regular expression
    (line 8), and an instance of `boost::smatch` (line 9), which is a specialization
    of the template `boost::match_results` to be used when the input is of type `std::string`.
    We search for successive matching substrings in a loop, calling `boost::regex_search`.
    We pass to `boost::regex_search` two iterators to the input string, the `smatch`
    instance called `matches`, and the regular expression `r2` (line 13). You must
    pass `const` iterators to `boost::regex_search` (lines 10, 11), or the compilation
    will fail to resolve the function call with a ton of gratuitous messages.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: The object `matches` of type `boost::smatch` stores information about the substring
    that matches a regular expression after a call to `regex_search`. Its `str` member
    returns the substring that was matched by the regular expression. `boost::smatch`
    is a sequence collection of `boost::ssub_match` objects. When a regular expression
    matches a substring, the pair of iterators to the start and one part to the end
    of that substring is stored in an object of type `boost::ssub_match`. This is
    stored at index 0 of `matches` and accessed as `matches[0]`. The members `first`
    and `second` of `ssub_match` are iterators to the start of the match (line 15)
    and one past the end of the match. The member function `length()` returns the
    length of the match (line 16). At the end of each iteration, we set the `start`
    iterator to the first location past the end of the last match (line 17) to begin
    looking for the next match. The `boost::ssub_match` is a specialization of the
    template `boost::sub_match` to be used when the input string is of type `std::string`.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: Suppose that, for each match, we want to extract what lies between the two a's
    at the two ends. To do this, we can use capturing sub-expressions. The regular
    expression would be modified slightly to `a(\\w*)a`. To access what matches the
    parenthesized sub-expression, we again use the `boost::smatch` object. An additional
    `boost::ssub_match` object is constructed for each such sub-expression in the
    regular expression and added to successive indexes of the `boost::smatch` object
    passed. If the sub-expression matched anything in the string, then the start and
    end of the substring matching that sub-expression are stored in the `ssub_match`
    object.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: 'This is how we would use it with the modified regular expression:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.28: Parsing matching substrings and sub-expressions**'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: In the inner loop (line 18), we iterate through all sub-expressions and for
    the ones that match any substring (line 19), we print that matching substring
    using the `str` member function of `boost::ssub_match` (line 20), the offset of
    the substring (line 21), and its length (line 22). The `prefix` and `suffix` methods
    of the `matches` object return respectively, the parts preceding and following
    the matched substring as `boost::ssub_match` objects (lines 15, 16).
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: The `boost::match_results` and `boost::sub_match` templates have different available
    specializations appropriate for different types of inputs, like an array of narrow
    or wide characters, or a specialization of `std::basic_string` (`std::string`
    or `std::wstring`).
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table summarizes these specializations:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: '| Input type | std::match_results specialization | std::sub_match specialization
    |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
- en: '| `std::string` | `std::smatch` | `std::ssub_match` |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
- en: '| `std::wstring` | `std::wmatch` | `std::wsub_match` |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
- en: '| `const char*` | `std::cmatch` | `std::csub_match` |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
- en: '| `const wchar_t*` | `std::wcmatch` | `std::wcsub_match` |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
- en: Tokenizing text using regex
  id: totrans-315
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This is a lot of work to parse an input using a regular expression, and there
    ought to be better abstractions available for the application programmer. Indeed,
    this is the kind of job you can simplify using a `boost::regex_iterator` and `boost::regex_token_iterator`.
    Let us suppose we want to pick all words in the string that start and end in `''a''`.
    Here is a relatively painless way to do it:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.29: Parsing strings using boost::regex_iterator**'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'This program prints the following text to the output, consisting of the three
    words that begin and end in `''a''`:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: The `boost::sregex_iterator` is a specialization of the template `boost::regex_iterator`
    to be used when the input string is of type `std::string`. Its instance `rit`
    is initialized with the string iterators, defining the input string and the regular
    expression used to look for successive tokens (line 10). It is then used to iterate
    through successive tokens like any other iterator (line 12).
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: In the previous example, we didn't deal with sub-expressions. So, let us look
    at an example with sub-expressions. Consider a string `"animal=Llama lives_in=Llama
    and is related_to=vicuna"`. It consists of some key-value pairs separated by the
    equals sign, among other content. If we want to extract all such key-value pairs,
    we can use a regular expression like `\w+=\w+`. We assume that the keys and values
    are single words without embedded punctuation or spaces. If we also want to pick
    out the key and value separately, we can use capture-groups like `(\w+)=(\w+)`
    for sub-expression matching:.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: 'By using the `boost::sregex_token_iterator`, we can actually pick out substrings
    matching individual sub-expressions relatively easily. The `boost::sregex_token_iterator`
    is a specialization of the template `boost::regex_token_iterator` for use with
    input string of type `std::string`. It takes the iterators to the input string,
    regular expression, and optional arguments specifying which sub-expressions to
    iterator over. Here is the code to boot:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.30: Parsing input strings with boost::regex_token_iterator**'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'This code prints the following output:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: You may have noticed that we print the values followed by the keys. We initialize
    a `boost::sregex_token_iterator` using the iterators defining the input string,
    the regular expression, and the array `subindx` specifying the sub-expressions
    we are interested in (line 11). As `subindx` has value `{2, 1}` (line 10), the
    second field is printed before the first. Besides an array, we could have also
    passed a vector of integers identifying the sub-expression indexes, or a single
    integer identifying the index of the only sub-expression we are interested in.
    If we omit this argument, the behavior of `boost::regex_token_iterator` is identical
    to that of `boost::regex_iterator`. The size of the array does not need to be
    passed and is automatically deduced via template argument deduction.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: 'Some algorithms in the Boost String Algorithms library provide convenient wrappers
    around the functionality in Boost.Regex. The `boost::find_all_regex` algorithm
    takes a sequence container, an input string, and a regular expression, and puts
    all substrings of the input string that match the regular expression into the
    sequence container with a single function call. The `boost::split_regex` container
    splits a string into tokens separated by text that matches some regular expression
    and puts the tokens into a sequence container. Here are both in action; `find_all_regex`
    splitting a sentence into words, and `split_regex` splitting a record with pipe
    character separators into fields:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.31: Using find_all_regex and split_regex**'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'This prints the following output:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Note that the first line prints all possible substrings that match the regular
    expression `\w+` (line 11), not just the largest disjoint matching substrings.
    This is because `find_all_regex` finds every matching substring in the input.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: Replacing text
  id: totrans-335
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One frequent use of regular expressions is to search for text and replace matching
    text by other text. For example, we may want to scan a particular paragraph for
    possessive phrases (England's Queen, India's culture, people's choice, and so
    on.) and convert them to an alternative form (Queen of England, culture of India,
    choice of people, and so on). The `boost::regex_replace` function template can
    come in handy for the purpose.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin with, we define the regular expression `\w+''s\s+\w+`. Since we have
    to reorder the phrase, we must capture parts of the match using sub-expressions.
    We use the regular expression `(\w+)''s\s+(\w+)` to match. We can use numbered
    back-references in the replacement string to refer to the submatches, so the replacement
    string is `"\2 of \1"`. We pass these along with the input string to `boost::regex_replace`,
    which returns a string with the matched sections replaced appropriately. Here
    is the code:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 4.32: Finding/Replacing strings with regular expressions**'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'By default, `regex_replace` replaces all matching substrings. If we want to
    replace only the first matching substring instead, then we need to pass `boost::regex_constants::
    format_first_only` as a fourth argument to `regex_replace`.'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: Self-test questions
  id: totrans-341
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For multiple choice questions, choose all options that apply:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: How does Boost Range help Boost Algorithms provide a better interface?
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Any character range expressed as a single argument, not iterator pair
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: b. It is faster than iterator pairs
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: c. It supports C-style arrays, and is extensible to other abstractions
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: d. It provides better exception safety
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: Which algorithm produces the shortest code for searching all substrings matching
    a search string or pattern?
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. `boost::find_all`
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: b. `boost::find_all_regex`
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: c. `boost::find_first`
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: d. `boost::regex_iterator`
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: Which of these are tokenizer functions provided by the Boost Tokenizer library?
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. `boost::char_separator`
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: b. `boost::split`
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: c. `boost::escaped_list_separator`
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: d. `boost::tokenizer`
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: The regular expression `"\ba.*a"` matches which part of the string `"two giant
    anacondas creeping around"`?
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. `"ant anacondas creeping a"`
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: b. `"anacondas creeping a"`
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: c. `"ant anaconda"`
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: d. `"anaconda"`
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: Which of the following is true of `boost::smatch`?
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'a. It is a specialization of `boost:: match_results`'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: b. It stores only matched sub-expressions
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: c. It stores a `boost::ssub_match` object for each sub-expression
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: d. Its `str` member returns the matched substring
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-368
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned the use of miscellaneous functions from the Boost
    String Algorithms library for performing various operations on string data types.
    We then looked at the generic Boost String Tokenizer framework that provides an
    efficient and extensible way to tokenize strings based on criteria that the user
    can define. We finally looked at regular expressions, and the Boost.Regex library
    that provides the ability to match character data against regular expressions,
    search for patterns, tokenize, and replace patterns using regular expressions.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: This chapter should have given you a broad perspective of basic text handling
    facilities available from the Boost libraries. Along the way, we also picked up
    some useful techniques from the Boost Range abstraction. In the next chapter,
    we turn our attention to various data structures available from the Boost libraries.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
