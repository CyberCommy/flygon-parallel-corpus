- en: '*Chapter 16*:'
  prefs: []
  type: TYPE_NORMAL
- en: Concurrency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Developing single-threaded Java applications is rarely feasible. Therefore,
    most of your projects will be multithreaded (that is, they will run in a multithreaded
    environment). This means that, sooner or later, you'll have to tackle certain
    multithreading problems. In other words, at some point, you'll have to get your
    hands dirty with code that manipulates Java threads directly or via dedicated
    APIs.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the most popular questions about Java concurrency (multithreading)
    that occur in general interviews about the Java language. As usual, we will start
    with a brief introduction that covers the main aspects of Java concurrency. Therefore,
    our agenda is straightforward, covering the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Java concurrency (multithreading) in a nutshell
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Questions and coding challenges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's begin with the fundamental knowledge of our topic, Java concurrency. Use
    the following nutshell section to extract answers to some basic questions about
    concurrency, such as *What is concurrency?*, *What is a Java thread?, What is
    multithreading?*, and more.
  prefs: []
  type: TYPE_NORMAL
- en: Technical Requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The codes used in this chapter can be found on GitHub on: [https://github.com/PacktPublishing/The-Complete-Coding-Interview-Guide-in-Java/tree/master/Chapter16](https://github.com/PacktPublishing/The-Complete-Coding-Interview-Guide-in-Java/tree/master/Chapter16)'
  prefs: []
  type: TYPE_NORMAL
- en: Java concurrency (multithreading) in a nutshell
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our computers can run multiple *programs* or *applications* at the same time
    (for example, we can listen to music on a media player and navigate the internet
    at the same time). A *process* is an executing instance of a program or application
    (for example, by double-clicking on the NetBeans icon on your computer, you start
    a process that will run the NetBeans program). Additionally, a *thread* is a *lightweight
    subprocess* that represents the smallest executable unit of work of a process.
    A Java thread has relatively low overhead, and it shares common memory space with
    other threads. A process can have multiple threads with one *main thread*.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The main difference between processes and threads is the fact that threads share
    common memory space while processes don't. By sharing memory, threads shave off
    lots of overhead.
  prefs: []
  type: TYPE_NORMAL
- en: '*Concurrency* is the ability of an application to handle the multiple tasks
    it works on. The program or application can process one task at a time (*sequential
    processing*) or process multiple tasks at the same time (*concurrent processing*).'
  prefs: []
  type: TYPE_NORMAL
- en: Do not confuse concurrency with *parallelism*. *Parallelism* is the ability
    of an application to handle each individual task. The application can process
    each task serially, or it can split the task up into subtasks that can be processed
    in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Concurrency is about **handling** (not doing) lots of things at once, while
    parallelism is about **doing** lots of things at once.
  prefs: []
  type: TYPE_NORMAL
- en: Concurrency is achieved via *multithreading*. *Multithreading* is a technique
    that enables a program or application to handle more than one task at a time and
    to also synchronize those tasks. This means that multithreading allows the maximum
    utilization of a CPU by executing two or more tasks virtually at the same time.
    We say *virtually at the same time* here because the tasks only look like they
    are running simultaneously; however, essentially, they cannot do that. They take
    advantage of CPU *context switching* or the *time slicing* feature of the operating
    system. In other words, CPU time is shared across all running tasks, and each
    task is scheduled to run for a certain period of time. Hence, multithreading is
    the key to *multitasking*.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: With a single-core CPU, we may achieve concurrency but *not* parallelism.
  prefs: []
  type: TYPE_NORMAL
- en: In conclusion, threads can create the illusion of multitasking; however, at
    any given point in time, the CPU is executing only one thread. The CPU switches
    control between the threads so quickly that it creates the illusion that the tasks
    are executed (or advance) in parallel. Actually, they are executed concurrently.
    Nevertheless, with advances in hardware technology, it is now common to have multi-core
    machines and computers. This means that applications can take advantage of these
    architectures and have a dedicated CPU running each thread.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram clarifies the confusion between concurrency and parallelism
    via four threads (**T1**, **T2**, **T3**, and **T4**):'
  prefs: []
  type: TYPE_NORMAL
- en: '![16.1 – Concurrency versus parallelism'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_16.1_B15403.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 16.1 – Concurrency versus parallelism
  prefs: []
  type: TYPE_NORMAL
- en: 'So, an application can be one of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Concurrent but not parallel**: It executes more than one task at the same
    time, but no two tasks are executed at the same time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Parallel but not concurrent**: It executes multiple subtasks of a task in
    a multi-core CPU at the same time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neither parallel nor concurrent**: It executes all of the tasks one at a
    time (sequential execution).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Both parallel and concurrent**: It executes multiple tasks concurrently in
    a multi-core CPU at the same time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A set of homogenous worker threads that are assigned to execute tasks is called
    a *thread pool*. A worker thread that finishes a task is returned to the pool.
    Typically, thread pools are bound to a queue of tasks and can be tuned to the
    size of the threads they hold. Commonly, for optimal performance, the size of
    a thread pool is equal to the number of CPU cores.
  prefs: []
  type: TYPE_NORMAL
- en: The *synchronization* of a multithreaded environment is achieved via *locking*.
    Locking is used to orchestrate and limit access to a resource in a multithreaded
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: If multiple threads can access the same resource without causing errors or unpredictable
    behaviors/results, then we are in a *thread-safe context*. *Thread safety* can
    be achieved via various synchronization techniques (for example, the Java `synchronized`
    keyword).
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's tackle several questions and coding challenges regarding concurrency
    in Java.
  prefs: []
  type: TYPE_NORMAL
- en: Questions and coding challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will cover 20 concurrency questions and coding challenges
    that are very popular in interviews.
  prefs: []
  type: TYPE_NORMAL
- en: You should be aware that Java concurrency is a wide and complex topic that needs
    to be covered in great detail by any Java developer. Having fundamental insights
    about Java concurrency should be enough to pass a general Java language interview,
    but it is not enough for specific interviews (for example, if you apply for a
    job that will imply developing a concurrency API, then you must deep dive into
    this topic and learn advanced concepts – most probably, the interview will be
    concurrency-centric).
  prefs: []
  type: TYPE_NORMAL
- en: Coding challenge 1 – Thread life cycle states
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`Thread`.'
  prefs: []
  type: TYPE_NORMAL
- en: '`Thread.State` enumeration. The possible states of a Java thread can be seen
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![16.2 – Java thread states'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_16.2_B15403.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 16.2 – Java thread states
  prefs: []
  type: TYPE_NORMAL
- en: 'The different lifecycle states of a Java `Thread` are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`NEW` `Thread#start()` method is invoked).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RUNNABLE` `Thread#start()` method, the thread passes from `NEW` to `RUNNABLE`.
    In the `RUNNABLE` state, a thread can be running or ready to run. A thread that
    is waiting for the **JVM** (**Java Virtual Machine**) thread scheduler to allocate
    the necessary resources and time to run is ready to run, but it is not running
    yet. As soon as the CPU is available, the thread scheduler will run the thread.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BLOCKED` `BLOCKED` state. For example, if a thread, *t1*, attempts to enter
    into a synchronized block of code (for example, a block of code marked `synchronized`)
    that is already being accessed by another thread, *t2*, then *t1* is held in the
    `BLOCKED` state until it can acquire the required lock.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`WAITING` `WAITING` state.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TIMED WAITING` `TIMED_WAITING` state.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TERMINATED` `TERMINATE` state.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Besides describing the possible states of a Java thread, the interviewer might
    ask you to code an example for each state. This is why I highly recommended that
    you take your time and analyze the application named *ThreadLifecycleState* (for
    brevity, the code is not listed in the book). The application is structured in
    a very intuitive way, and the leading comments explain each scenario/state.
  prefs: []
  type: TYPE_NORMAL
- en: Coding challenge 2 – Deadlocks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Problem**: Explain deadlock to us and we''ll hire you!'
  prefs: []
  type: TYPE_NORMAL
- en: '**Solution**: Hire me, and I''ll explain it to you.'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we've just described a deadlock.
  prefs: []
  type: TYPE_NORMAL
- en: 'A deadlock can be explained like this: thread *T1* holds the lock, *P*, and
    is trying to acquire the lock, *Q*. At the same time, there is thread *T2* that
    holds the lock, *Q*, and is trying to acquire the lock, *P*. This kind of deadlock
    is known as *circular wait* or *deadly embrace*.'
  prefs: []
  type: TYPE_NORMAL
- en: Java doesn't provide deadlock detection and/or a resolving mechanism (like databases
    have, for example). This means that a deadlock can be very embarrassing for an
    application. A deadlock can partially or completely block an application. This
    leads to significant performance penalties, unexpected behaviors/results, and
    more. Commonly, deadlocks are hard to find and debug, and they force you to restart
    the application.
  prefs: []
  type: TYPE_NORMAL
- en: The best way to avoid race deadlocks is to avoid using nested locks or unnecessary
    locks. Nested locks are quite prone to deadlocks.
  prefs: []
  type: TYPE_NORMAL
- en: A common problem of simulating a deadlock is **The Dining Philosophers** problem.
    You can find a detailed explanation and implementation of this problem in the
    *Java Coding Problems* book ([https://www.packtpub.com/programming/java-coding-problems](https://www.packtpub.com/programming/java-coding-problems)).
    *Java Coding Problems* contains two chapters that are dedicated to Java concurrency
    and are meant to dive deep into this topic using specific problems.
  prefs: []
  type: TYPE_NORMAL
- en: In the code bundle for this book, you can find a simple example of causing a
    deadlock named *Deadlock*.
  prefs: []
  type: TYPE_NORMAL
- en: Coding challenge 3 – Race conditions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Problem**: Explain what *race conditions* are.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Solution**: First of all, we must mention that a snippet/block of code that
    can be executed by multiple threads (that is, executed concurrently) and exposes
    shared resources (for example, shared data) is known as a *critical section*.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Race conditions* occur when threads pass through such critical sections without
    thread synchronization. The threads *race* through the critical section attempting
    to read/write shared resources. Depending on the order in which threads finish
    this race, the application''s output changes (two runs of the application may
    produce different outputs). This leads to inconsistent behavior in the application.'
  prefs: []
  type: TYPE_NORMAL
- en: The best way to avoid race conditions involves the proper synchronization of
    critical sections by using locks, synchronized blocks, atomic/volatile variables,
    synchronizers, and/or message passing.
  prefs: []
  type: TYPE_NORMAL
- en: Coding challenge 4 – reentrant locking
  prefs: []
  type: TYPE_NORMAL
- en: '**Problem**: Explain what is the *reentrant locking* concept.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Solution**: Generally speaking, *reentrant locking* refers to a process that
    can acquire a lock multiple times without deadlocking itself. If a lock is not
    reentrant, then the process can still acquire it. However, when the process tries
    to acquire the lock again, it will be blocked (deadlock). A reentrant lock can
    be acquired by another thread or recursively by the same thread.'
  prefs: []
  type: TYPE_NORMAL
- en: A reentrant lock can be used for a piece of code that doesn't contain updates
    that could break it. If the code contains a shared state that can be updated,
    then acquiring the lock again will corrupt the shared state since the code is
    called while it is executing.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java, a reentrant lock is implemented via the `ReentrantLock` class. A reentrant
    lock acts like this: when the thread enters the lock for the first time, a hold
    count is set to one. Before unlocking, the thread can re-enter the lock causing
    the hold count to be incremented by one for each entry. Each unlock request decrements
    the hold count by one, and, when the hold count is zero, the locked resource is
    opened.'
  prefs: []
  type: TYPE_NORMAL
- en: Coding challenge 5 – Executor and ExecutorService
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`Executor` and `ExecutorService`?'
  prefs: []
  type: TYPE_NORMAL
- en: '`java.util.concurrent` package, there are a number of interfaces that are dedicated
    to executing tasks. The simplest one is named `Executor`. This interface exposes
    a single method named `execute (Runnable command)`.'
  prefs: []
  type: TYPE_NORMAL
- en: A more complex and comprehensive interface, which provides many additional methods,
    is `ExecutorService`. This is an enriched version of `Executor`. Java comes with
    a full-fledged implementation of `ExecutorService`, named `ThreadPoolExecutor`.
  prefs: []
  type: TYPE_NORMAL
- en: In the code bundle for this book, you can find simple examples of using `Executor`
    and `ThreadPoolExecutor` in the application named *ExecutorAndExecutorService*.
  prefs: []
  type: TYPE_NORMAL
- en: Coding challenge 6 – Runnable versus Callable
  prefs: []
  type: TYPE_NORMAL
- en: '`Callable` interface and the `Runnable` interface?'
  prefs: []
  type: TYPE_NORMAL
- en: '`Runnable` interface is a functional interface that contains a single method
    named `run()`. The `run()` method doesn''t take any parameters and returns `void`.
    Moreover, it cannot throw checked exceptions (only `RuntimeException`). These
    statements make `Runnable` suitable in scenarios where we are not looking for
    the result of the thread execution. The `run()` signature is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other hand, the `Callable` interface is a functional interface that
    contains a single method named `call()`. The `call()` method returns a generic
    value and can throw checked exceptions. Typically, `Callable` is used in `ExecutorService`
    instances. It is useful for starting an asynchronous task and then calling the
    returned `Future` instance to get its value. The `Future` interface defines methods
    for obtaining the result generated by a `Callable` object and for managing its
    state. The `call()` signature is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Notice that both of these interfaces represent a task that is intended to be
    executed concurrently by a separate thread.
  prefs: []
  type: TYPE_NORMAL
- en: In the code bundle for this book, you can find simple examples of using `Runnable`
    and `Callable` in the application named *RunnableAndCallable*.
  prefs: []
  type: TYPE_NORMAL
- en: Coding challenge 7 – Starvation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Problem**: Explain what thread *starvation* is.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Solution**: A thread that never (or very rarely) gets CPU time or access
    to the shared resources is a thread that experiences *starvation*. Since it cannot
    obtain regular access to shared resources, this thread cannot progress its job.
    This happens because other threads (so-called *greedy* threads) get access before
    this thread and make the resources unavailable for long periods of time.'
  prefs: []
  type: TYPE_NORMAL
- en: The best way to avoid thread starvation is to use *fair* locks, such as Java
    `ReentrantLock`. A *fair* lock grants access to the thread that has been waiting
    the longest. Having multiple threads run at once while preventing starvation can
    be accomplished via Java `Semaphore`. A *fair* `Semaphore` guarantees the granting
    of permits under contention using FIFO.
  prefs: []
  type: TYPE_NORMAL
- en: Coding challenge 8 – Livelocks
  prefs: []
  type: TYPE_NORMAL
- en: '**Problem**: Explain what thread *livelock* is.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Solution**: A livelock takes place when two threads keep taking actions in
    response to another thread. The threads don''t make any progress with their own
    jobs. Notice that the threads are not blocked; both of them are too busy responding
    to each other to resume work.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of a livelock: imagine two people trying to cross each other
    in a hallway. Mark moves to his right to let Oliver pass, and Oliver moves to
    his left to let Mark pass. Both are now blocking each other. Mark sees that he''s
    blocking Oliver and moves to his left, and Oliver moves to his right after seeing
    that he''s blocking Mark. They never manage to cross each other and keep blocking
    each other.'
  prefs: []
  type: TYPE_NORMAL
- en: We can avoid livelocks via `ReentrantLock`. This way, we can determine which
    thread has been waiting the longest and assign it a lock. If a thread can't acquire
    a lock, it should release the previously acquired locks and try again later.
  prefs: []
  type: TYPE_NORMAL
- en: Coding challenge 9 – Start() versus run()
  prefs: []
  type: TYPE_NORMAL
- en: '`start()` method and the `run()` method in a Java `Thread`.'
  prefs: []
  type: TYPE_NORMAL
- en: '`start()` and `run()` is the fact that the `start()` method creates a new thread
    while the `run()` method doesn''t. The `start()` method creates a new thread and
    calls the block of code written inside the `run()` method of this new thread.
    The `run()` method executes that code on the same thread (that is, the calling
    thread) without creating a new thread.'
  prefs: []
  type: TYPE_NORMAL
- en: Another difference is that calling `start()` twice on the thread object will
    throw an `IllegalStateException`. On the other hand, calling the `run()` method
    twice doesn't lead to an exception.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, novices ignore these differences, and, since the `start()` method
    eventually calls the `run()` method, they believe there is no reason to call the
    `start()` method. Therefore, they call the `run()` method directly.
  prefs: []
  type: TYPE_NORMAL
- en: Coding challenge 10 – Thread versus Runnable
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`Thread` or implement `Runnable`?'
  prefs: []
  type: TYPE_NORMAL
- en: '`java.lang.Thread` or by implementing `java.lang.Runnable`. The preferred way
    to go is to implement `Runnable`.'
  prefs: []
  type: TYPE_NORMAL
- en: Most of the time, we implement a thread just to give it something to run, not
    to overwrite the behavior of the `Thread`. As long as all we want is to give something
    to run to a thread, we definitely should stick to implementing `Runnable`. In
    fact, using `Callable` or `FutureTask` is an even better choice.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to this, by implementing `Runnable`, you can still extend another
    class. By extending `Thread`, you cannot extend another class since Java doesn't
    support multiple inheritances.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, by implementing `Runnable`, we separate the task definition from the
    task execution.
  prefs: []
  type: TYPE_NORMAL
- en: Coding challenge 11 – CountDownLatch versus CyclicBarrier
  prefs: []
  type: TYPE_NORMAL
- en: '`CountDownLatch` and `CyclicBarrier`.'
  prefs: []
  type: TYPE_NORMAL
- en: '`CountDownLatch` and `CyclicBarrier` are two of the five Java *synchronizers*
    next to `Exchanger`, `Semaphore`, and `Phaser`.'
  prefs: []
  type: TYPE_NORMAL
- en: The main difference between `CountDownLatch` and `CyclicBarrier` is the fact
    that a `CountDownLatch` instance cannot be reused once the countdown reaches zero.
    On the other hand, a `CyclicBarrier` instance is reusable. A `CyclicBarrier` instance
    is cyclical because it can be reset and reused. To do this, call the `reset()`
    method after all of the threads waiting at the barrier are released; otherwise,
    `BrokenBarrierException` will be thrown.
  prefs: []
  type: TYPE_NORMAL
- en: Coding challenge 12 – wait() versus sleep()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`wait()` method and the `sleep()` method.'
  prefs: []
  type: TYPE_NORMAL
- en: '`wait()` method and the `sleep()` method is that `wait()` must be called from
    a synchronized context (for example, from a `synchronized` method), while the
    `sleep()` method doesn''t need a synchronized context. Calling `wait()` from a
    non-synchronized context will throw an `IllegalMonitorStateException`.'
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, it is important to mention that `wait()` works on `Object`, while
    `sleep()` works on the current thread. Essentially, `wait()` is a non-`static`
    method defined in `java.lang.Object`, while `sleep()` is a `static` method defined
    in `java.lang.Thread`.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, the `wait()` method releases the lock, while the `sleep()` method
    doesn't release the lock. The `sleep()` method only pauses the current thread
    for a certain period of time. Both of them throw `IntrupptedException` and can
    be interrupted.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the `wait()` method should be called in a loop that decides when the
    lock should be released. On the other hand, it is not recommended that you call
    the `sleep()` method in a loop.
  prefs: []
  type: TYPE_NORMAL
- en: Coding challenge 13 – ConcurrentHashMap versus Hashtable
  prefs: []
  type: TYPE_NORMAL
- en: '`ConcurrentHashMap` faster than `Hashtable`?'
  prefs: []
  type: TYPE_NORMAL
- en: '`ConcurrentHashMap` is faster than `Hashtable` because of its special internal
    design. `ConcurrentHashMap` internally divides a map into segments (or buckets),
    and it locks only a particular segment during an update operation. On the other
    hand, `Hashtable` locks the whole map during an update operation. So, `Hashtable`
    uses a single lock for the whole data, while `ConcurrentHashMap` uses multiple
    locks on different segments (buckets).'
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, reading from a `ConcurrentHashMap` using `get()` is lock-free (no
    locks), while all the `Hashtable` operations are simply `synchronized`.
  prefs: []
  type: TYPE_NORMAL
- en: Coding challenge 14 – ThreadLocal
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`ThreadLocal`?'
  prefs: []
  type: TYPE_NORMAL
- en: '`ThreadLocal` as a means to store and retrieve values for each thread separately.
    A single instance of `ThreadLocal` can store and retrieve the values of multiple
    threads. If thread *A* stores the *x* value and thread *B* stores the *y* value
    in the same instance of `ThreadLocal`, then, later on, thread *A* retrieves the
    *x* value, and thread *B* retrieves the *y* value. Java `ThreadLocal` is typically
    used in the following two scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: To provide per-thread instances (thread safety and memory efficiency)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To provide per-thread context
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Coding challenge 15 – submit() versus execute()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`ExecutorService#submit()` and `Executor#execute()` methods.'
  prefs: []
  type: TYPE_NORMAL
- en: '`Runnable` task for execution, they are not the same. The main difference can
    be observed by simply checking their signatures. Notice that `submit()` returns
    a result (that is, a `Future` object representing the task), while `execute()`
    returns `void`. The returned `Future` object can be used to programmatically cancel
    the running thread later on (prematurely). Moreover, by using the `Future#get()`
    method, we can wait for the task to complete. If we submit a `Callable`, then
    the `Future#get()` method will return the result of calling the `Callable#call()`
    method.'
  prefs: []
  type: TYPE_NORMAL
- en: Coding challenge 16 – interrupted() and isInterrupted()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`interrupted()` and `isInterrupted()` methods.'
  prefs: []
  type: TYPE_NORMAL
- en: '`Thread.interrupt()` method interrupts the current thread and sets this flag
    to `true`.'
  prefs: []
  type: TYPE_NORMAL
- en: The main difference between the `interrupted()` and `isInterrupted()` methods
    is the fact that the `interrupted()` method clears the interrupt status while
    `isInterrupted()` doesn't.
  prefs: []
  type: TYPE_NORMAL
- en: If the thread was interrupted, then `Thread.interrupted()` will return `true`.
    However, besides testing, if the current thread was interrupted, `Thread.interrupted()`
    clears the interrupted status of the thread (that is, sets it to `false`).
  prefs: []
  type: TYPE_NORMAL
- en: The non-`static isInterrupted()` method doesn't change the interrupt status
    flag.
  prefs: []
  type: TYPE_NORMAL
- en: As a rule of thumb, after catching `InterruptedException`, don't forget to restore
    the interrupt by calling `Thread.currentThread().interrupt()`. This way, the caller
    of our code will be aware of the interruption.
  prefs: []
  type: TYPE_NORMAL
- en: Coding challenge 17 – Canceling a thread
  prefs: []
  type: TYPE_NORMAL
- en: '**Problem**: How can we stop or cancel a thread?'
  prefs: []
  type: TYPE_NORMAL
- en: '`volatile` (also known as the lightweight synchronization mechanism). Being
    a `volatile` flag, it is not cached by threads, and operations on it are not reordered
    in memory; therefore, a thread cannot see an old value. Any thread that reads
    a `volatile` field will see the most recently written value. This is exactly what
    we need in order to communicate the cancellation action to all running threads
    that are interested in this action. The following diagram illustrates this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![16.3 – Volatile flag read/write'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_16.3_B15403.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 16.3 – Volatile flag read/write
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the `volatile` variables are not a good fit for read-modify-write
    scenarios. For such scenarios, we will rely on atomic variables (for example,
    `AtomicBoolean`, `AtomicInteger`, and `AtomicReference`).
  prefs: []
  type: TYPE_NORMAL
- en: In the code bundle for this book, you can find an example of canceling a thread.
    The application is named *CancelThread*.
  prefs: []
  type: TYPE_NORMAL
- en: Coding challenge 18 – sharing data between threads
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Problem**: How can we share data between two threads?'
  prefs: []
  type: TYPE_NORMAL
- en: '`BlockingQueue`, `LinkedBlockingQueue`, and `ConcurrentLinkedDeque`. It is
    very convenient to rely on these data structures to share data between threads
    because you don''t have to bother about thread safety and inter-thread communication.'
  prefs: []
  type: TYPE_NORMAL
- en: Coding challenge 19 – ReadWriteLock
  prefs: []
  type: TYPE_NORMAL
- en: '`ReadWriteLock` is in Java.'
  prefs: []
  type: TYPE_NORMAL
- en: '`ReadWriteLock` is to sustain the efficiency and thread safety of reading and
    writing operations in a concurrent environment. It accomplishes this goal via
    the *lock striping* concept. In other words, `ReadWriteLock` uses separate locks
    for reads and writes. More precisely, `ReadWriteLock` keeps a pair of locks: one
    for read-only operations and one for writing operations. As long as there are
    no writer threads, multiple reader threads can hold the read lock simultaneously
    (shared pessimistic lock). A single writer can write at a time (exclusive/pessimistic
    locking). So, `ReadWriteLock` can significantly improve the performance of the
    application.'
  prefs: []
  type: TYPE_NORMAL
- en: Besides `ReadWriteLock`, Java comes with `ReentrantReadWriteLock` and `StampedLock`.
    The `ReentrantReadWriteLock` class adds the *reentrant locking* concept (refer
    to *Coding challenge 4*) to `ReadWriteLock`. On the other hand, `StampedLock`
    performs better than `ReentrantReadWriteLock` and supports optimistic reads. But
    it is not *reentrant*; therefore, it is prone to deadlocks.
  prefs: []
  type: TYPE_NORMAL
- en: Coding challenge 20 – Producer-Consumer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Problem**: Provide an implementation for the famous Producer-Consumer problem.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: This is a favorite problem during any Java multithreading interview!
  prefs: []
  type: TYPE_NORMAL
- en: '**Solution**: The Producer-Consumer problem is a design pattern that can be
    represented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![16.4 – Producer-Consumer design pattern'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_16.4_B15403.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 16.4 – Producer-Consumer design pattern
  prefs: []
  type: TYPE_NORMAL
- en: Most commonly, in this pattern, the producer thread and the consumer thread
    communicate via a queue (the producer enqueues data and the consumer dequeues
    data) and a set of rules specific to the modeled business. This queue is known
    as the *data buffer*. Of course, depending on the process design, other data structures
    can play the role of data buffer as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s assume the following scenario (set of rules):'
  prefs: []
  type: TYPE_NORMAL
- en: If the data buffer is empty, then the producer produces one product (by adding
    it to the data buffer).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the data buffer is not empty, then the consumer consumes one product (by
    removing it from the data buffer).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As long as the data buffer is not empty, the producer waits.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As long as the data buffer is empty, the consumer waits.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, let's solve this scenario via two common approaches. We will start with
    a solution that is based on the `wait()` and `notify()` methods.
  prefs: []
  type: TYPE_NORMAL
- en: Producer-Consumer via wait() and notify()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some interviewers may ask you to implement a `wait()` and `notify()` methods.
    In other words, they don't allow you to use a built-in thread-safe queue such
    as `BlockingQueue`.
  prefs: []
  type: TYPE_NORMAL
- en: For example, let's consider that the data buffer (`queue`) is represented by
    a `LinkedList`, that is, a non-thread-safe data structure. To ensure that this
    shared `LinkedList` is accessible in a thread-safe manner by the producer and
    the consumer, we rely on the `synchronized` keyword.
  prefs: []
  type: TYPE_NORMAL
- en: The producer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If the queue is not empty, then the producer waits until the consumer finishes.
    To do this, the producer relies on the `wait()` method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other hand, if the queue is empty, then the producer enqueues one product
    and notifies the consumer thread via `notify()`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: After adding a product to the queue, the consumer should be ready to consume
    it.
  prefs: []
  type: TYPE_NORMAL
- en: The consumer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If the queue is empty, then the consumer waits until the producer finishes.
    For this, the producer relies on the `wait()` method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other hand, if the queue is not empty, then the consumer dequeues one
    product and notifies the producer thread via `notify()`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The complete code is available in the bundled code, *ProducerConsumerWaitNotify*.
  prefs: []
  type: TYPE_NORMAL
- en: Producer-Consumer via built-in blocking queues
  prefs: []
  type: TYPE_NORMAL
- en: If you can use a built-in blocking queue, then you can choose a `BlockingQueue`
    or even a `TransferQueue`. Both of them are thread-safe. In the following code,
    we use a `TransferQueue` or, more precisely, a `LinkedTransferQueue`.
  prefs: []
  type: TYPE_NORMAL
- en: The producer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The producer waits for the consumer to be available via `hasWaitingConsumer()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: After adding a product to the queue, the consumer should be ready to consume
    it.
  prefs: []
  type: TYPE_NORMAL
- en: The consumer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The consumer uses the `poll()` method with a timeout to extract the product:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The complete code is available in the bundled code, *ProducerConsumerQueue*
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we covered the most popular questions that occur in Java multithreading
    interviews. Nevertheless, Java concurrency is a vast topic, and it is very important
    to deep dive into it. I strongly suggest that you read *Java Concurrency in Practice*
    by Brian Goetz. This is a must-read for any Java developer.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will cover a hot topic: Java functional-style programming.'
  prefs: []
  type: TYPE_NORMAL
