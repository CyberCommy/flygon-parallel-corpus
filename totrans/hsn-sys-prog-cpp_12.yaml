- en: Learning to Program POSIX and C++ Threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, the reader will learn how to program both POSIX and C++ threads.
    We will start by discussing how to program with POSIX threads, and then move on
    to C++ threads, providing a comparison of the APIs for each one.
  prefs: []
  type: TYPE_NORMAL
- en: Then we will present three examples. The first will demonstrate how to use threading
    to perform a parallel computation. The second will demonstrate how to create your
    own high-resolution timer using threading in order to perform benchmarking (albeit
    a timer that is likely not very accurate).
  prefs: []
  type: TYPE_NORMAL
- en: The third and final example will build upon our existing debugging example to
    provide support for multiple clients.
  prefs: []
  type: TYPE_NORMAL
- en: It should be noted that this chapter assumes the reader already has a basic
    understanding of threading, thread synchronization, and the challenges associated
    with race conditions and deadlock. Here, we will only focus on the APIs provided
    by POSIX and C++ for working with threads.
  prefs: []
  type: TYPE_NORMAL
- en: 'The chapter will cover the following:'
  prefs: []
  type: TYPE_NORMAL
- en: POSIX threads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: C++ threads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parallel computation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Benchmarking with threads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thread logging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to follow the examples in this chapter, the reader must have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A Linux-based system capable of compiling and executing C++17 (for example,
    Ubuntu 17.10+)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GCC 7+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CMake 3.6+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An internet connection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To download all the code in this chapter, including the examples and code snippets,
    go to the following link: [https://github.com/PacktPublishing/Hands-On-System-Programming-with-CPP/tree/master/Chapter12](https://github.com/PacktPublishing/Hands-On-System-Programming-with-CPP/tree/master/Chapter12).
  prefs: []
  type: TYPE_NORMAL
- en: Understanding POSIX threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A thread is similar to a process, with the main distinctions being the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Threads are contained within processes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Threads inherently share a memory space with other threads of the same process,
    while processes do not share resources unless explicitly told to (using inter-process
    communication mechanisms)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Like processes, however, threads are scheduled for execution at any time by
    the operating system. This may mean executing in parallel with other threads,
    leading to performance optimizations if properly used, but at the expense of introducing
    threading-specific logic bugs, such as race conditions and deadlock.
  prefs: []
  type: TYPE_NORMAL
- en: The goal of this section is to briefly review POSIX threads. These largely influenced
    the design of C++ threads, which will be discussed later.
  prefs: []
  type: TYPE_NORMAL
- en: The basics of POSIX threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The most basic use of a thread is to create it, and then join the thread, which,
    in effect, waits for the thread to finish its work before returning as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, a `mythread()` function is created with the signature
    `(void *)(*)(void *)`, which is required by POSIX threads. In this example, the
    thread simply outputs to `stdout` and returns.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `main()` function, two threads are created using the `pthread_create()`
    function, which takes the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In this example, a `pthread_t` type is created and passed to the first argument.
    The attribute argument is ignored using a `nullptr`, and so is the argument to
    the thread itself (since it is not used). The only other thing we provide the
    `pthread_create` with function is the thread itself, which is a function pointer
    to our `mythread()` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'To wait for the thread to complete, we use the `pthread_join()` function, which
    takes the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The previously-created `pthread` is provided as the first argument to this function,
    while the return value of the `pthread` is ignored using a `nullptr` (since the
    thread doesn't return a value).
  prefs: []
  type: TYPE_NORMAL
- en: The result of this example is that `Hello World` is output to `stdout` twice
    (since two threads are created).
  prefs: []
  type: TYPE_NORMAL
- en: 'It should be noted that there are several issues with this example, which we
    will only briefly address in this chapter (as entire books can be written on the
    topic of parallel computing):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Type safety**: Both the argument to the thread and its return value are passed
    as a `void *`, completely removing any and all forms of type safety with respect
    to the thread itself. As a result, the `pthread` interface is not C++ Core Guideline
    compliant, and encourages the creation of hard-to-find logic errors. As will be
    demonstrated, C++ largely addresses these issues, albeit using an interface ,
    which, at times, might seem difficult to follow.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Race conditions**: The preceding example does not attempt to address the
    possible race conditions of both threads outputting to `stdout` at the same time.
    As a result, if this example is executed enough times, it is likely that corruption
    with respect to its output would result.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**No input/output**: Often, threads operate on globally-defined data without
    the need for input or output, but it is entirely possible that input and/or output
    may be needed in a different situation. This example doesn''t address how to accomplish
    this.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Threads are implemented differently depending on the operating system, and cross-platform
    software needs to take this into account. Some operating systems implement threads
    as separate processes, while others implement threads as separate, scheduleable
    tasks within a process.
  prefs: []
  type: TYPE_NORMAL
- en: Either way, the POSIX specification dictates that a thread be identifiable,
    regardless of the underlying implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 'To identify a thread, the following may be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding example is identical to the first, with the exception that, instead
    of outputting `Hello World` to `stdout`, we use the `pthread_self()` function
    to output the thread''s identifier. The `pthread_self()` function takes the following
    form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Since the `pthread_t` type is usually implemented using an integer type, in
    our preceding example, we can output the value of this type to `stdout` using
    `std::cout`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To provide support for input and output, the `pthread` API provides a `void
    *` for both the input and the output of the thread function. The following example
    demonstrates how to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the thread function assumes the parameter it is passed is a
    pointer to an integer. It takes the value provided, increments it, and then returns
    it back to the caller (which, in this case, is the `main()` function).
  prefs: []
  type: TYPE_NORMAL
- en: In the `main()` function, we create both an input and an output value, with
    the input being initialized to `42`. A pointer to the input value is provided
    during the creation of the thread, and a pointer to the output value is provided
    while joining the threads.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the resulting value is output to `stdout`. This is `44`, since two
    threads were created, each of which increments the provided input once.
  prefs: []
  type: TYPE_NORMAL
- en: Since both threads are operating on the same integer, it is possible that a
    race condition could corrupt the results of these threads if they happen to execute
    at the same time; a problem that will be addressed later on.
  prefs: []
  type: TYPE_NORMAL
- en: Yielding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One advantage to using threads is that they can execute for a very long time
    without preventing the execution of your main thread/application. The downside
    is that threads that execute without an end can end up consuming too much CPU.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we create a thread that uses a `while(true)` statement,
    which executes as fast as possible, forever. Such a thread would execute until
    the operating system decided to preempt the thread to schedule another thread
    or process, resulting in the output of the thread occurring in a blocked, almost
    serial fashion.
  prefs: []
  type: TYPE_NORMAL
- en: 'In some cases, however, the user might need the thread to perform an action
    and then release its access to the CPU to allow another thread to perform its
    task. To accomplish this, we use the `pthread_yield()` API, which takes the following
    form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, the use of the `yield` function provides each thread
    with an opportunity to execute, resulting in a better-shuffled output of `thread
    1` and `thread 2`.
  prefs: []
  type: TYPE_NORMAL
- en: Although this function is provided, it should be noted that the operating system
    is excellent at handling threads that must perform a lot of work, and `pthread_yield()`
    should only be used when the user explicitly understands how it might provide
    optimization in their specific use case (since overuse of the `pthread_yield()`
    function can actually result in performance degradation).
  prefs: []
  type: TYPE_NORMAL
- en: It should also be noted that `pthread_yield()` is not available on all Unix
    systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to `pthread_yield()`, the POSIX API also provides functions to
    put a thread to sleep if there is nothing to do (resulting in better performance
    and battery life), as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we create a thread that outputs `Hello World` once
    a second by creating a single thread that outputs to `stdout`, and then uses the
    `sleep()` function to put the thread to sleep for a second.
  prefs: []
  type: TYPE_NORMAL
- en: It should be noted that the use of `sleep()` should be handled with care, as
    it is possible for the operating system to race the `sleep()` call by yielding
    before `sleep()` is called.
  prefs: []
  type: TYPE_NORMAL
- en: Synchronization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Race conditions are a common problem when using threads, and solving race conditions
    without introducing deadlock (a thread that can no longer execute due to logic
    bugs with thread synchronization logic) is a complicated topic deserving of its
    own book.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example attempts to demonstrate the issues with potential race
    conditions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: To produce a race condition, we must execute threads fast enough, and for long
    enough (especially on modern hardware), that one thread performs an operation
    on a shared resource when another thread is in the middle of completing its own
    operation on that same shared resource.
  prefs: []
  type: TYPE_NORMAL
- en: There are many, many ways to do this. In the case of the preceding example,
    we have a thread that increments a counter, and then we create `8000` of these
    threads, increasing the chance that a race condition might occur. At some point
    during execution, two threads read the current value of the counter at the exact
    same time, incrementing the value and storing the incremented value at the same
    time. This results in the counter only being incremented once, even though two
    threads were executing.
  prefs: []
  type: TYPE_NORMAL
- en: As a result, and as can be seen from the output of the example, the count in
    some cases is less than `8000`. In these cases, race conditions occurred, resulting
    in corruption.
  prefs: []
  type: TYPE_NORMAL
- en: 'To solve this issue, we must protect the critical region, which, in this case,
    is the part of the thread that uses the shared resource. The following example
    demonstrates one way to do this using a mutex (which ensures mutual exclusion
    to a critical region):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we wrap the critical region with a mutex. A mutex
    leverages atomic operations (operations that are guaranteed by hardware to manipulate
    a shared resource without corruption) to gain access to a critical region, one
    thread at a time.
  prefs: []
  type: TYPE_NORMAL
- en: If a thread attempts to gain access to a critical region while another thread
    is actively using the region, it waits until the thread is complete. Once the
    thread is complete, all the waiting threads race to get access to the critical
    region, and the thread that wins gets access while the remaining threads continue
    to wait. (Each operating system has its own way of implementing this to prevent
    the possibility of starvation; another topic that is beyond of scope of this book.)
  prefs: []
  type: TYPE_NORMAL
- en: As can be seen from the output of the preceding example, the use of a mutex
    around the critical region (in this case, the incrementing of the `count` variable)
    prevents the possibility of a race condition, resulting in `8000` being output
    every time.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with mutexes is that each time the mutex is locked, a thread must
    wait until it is unlocked before it can continue. This is what protects the critical
    region from other threads, but it results in deadlock if the same thread attempts
    to lock the same mutex more than once (for example, when using recursion), or
    if mutexes are locked in the wrong order.
  prefs: []
  type: TYPE_NORMAL
- en: 'To overcome this problem, the POSIX API provides the ability to turn a mutex
    into a recursive mutex, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we are able to lock the mutex more than once without
    causing a deadlock by first setting the mutex to recursive mode using a mutex
    attribute. It should be noted that this additional flexibility typically comes
    with additional overhead.
  prefs: []
  type: TYPE_NORMAL
- en: The last POSIX API we will discuss in this chapter is the condition variable.
    As was demonstrated previously, a mutex may be used to synchronize access to critical
    regions of code. Another form of thread synchronization is to ensure threads execute
    in the proper order, which is what condition variables allow.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, threads 1 and 2 may execute at any time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we create two threads, each outputting to `stdout` in a critical
    region that is guarded using a mutex. The rest of the example is the same as with
    previous examples in this chapter. As shown, `thread 2` is executed first, and
    then `thread 1` (this is largely due to `thread 2` being created first). However,
    there is still the possibility that `thread 1` could have executed first, as there
    is nothing controlling the order in which threads execute.
  prefs: []
  type: TYPE_NORMAL
- en: 'To solve this, the POSIX API provides a condition variable that may be used
    to synchronize the order of threads, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, `thread 1` executes first, and then `thread 2`, even though
    `thread 2` was created first. To accomplish this, we use the `pthread_cond_wait()`
    and `pthread_cond_signal()` functions, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The `pthread_cond_wait()` function takes a pointer to a condition variable,
    and a mutex. When it is executed, it unlocks the mutex and waits for a call to `pthread_cond_signal()`
    to be executed. Once the signal is sent, `pthread_cond_wait()` locks the mutex
    again and continues execution.
  prefs: []
  type: TYPE_NORMAL
- en: The use of the `predicate` variable, which is also guarded by the mutex, is
    used to ensure that any spurious wake-ups are handled. Specifically, it is possible
    for the `pthread_cond_wait()` function to wake up even though the condition variable
    has not yet been signaled. As a result, you must always pair the `pthread_cond_wait()`
    function with a `predicate`.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring C++ threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we learned how POSIX provides support for threads.
    In this section, we will discuss C++ threads, which are largely inspired by POSIX
    threads. They provide similar functionality while simplifying the APIs in some
    ways, and also providing type safety.
  prefs: []
  type: TYPE_NORMAL
- en: The basics of C++ threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To demonstrate the simplicity of C++ threads, the following example, like the
    first example in this chapter, creates two threads and then waits for them to
    finish executing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'There are some notable differences compared to the POSIX version of this example:'
  prefs: []
  type: TYPE_NORMAL
- en: The thread function itself may take on a number of different function signatures,
    and is not limited to `(void *)(*)(void *)`. In this example, the thread function
    uses the `void(*)()` signature.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The constructor of the thread type also creates the thread (no need to define
    the type, and then explicitly create the thread later).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It should be noted that in Linux, the `pthread` library still needs to be linked
    to the example. This is because, under the hood, C++ is using `pthread` instances
    to provide thread support.
  prefs: []
  type: TYPE_NORMAL
- en: 'Like the POSIX version, C++ also provides the ability to get the thread ID,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we use both the `this_thread` namespace and the thread
    itself to get the ID, demonstrating that there are two different ways to query
    a thread's ID (depending on the point of view of the caller).
  prefs: []
  type: TYPE_NORMAL
- en: The input and output of C++ threads is a good example of how C++ threading,
    in some ways, is more complicated than POSIX threading. As was stated, the biggest
    issue with POSIX threads with respect to input and output is a clear lack of type
    safety.
  prefs: []
  type: TYPE_NORMAL
- en: To solve this, C++ provides a concept called C++ futures, which, by itself,
    probably deserves its own chapter. We will describe them here briefly, to give
    the reader some general knowledge of how they work.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we create a `mythread()` function that has the signature
    `int(*)(int)`, which takes a value, adds one, and returns the result (very similar
    to the preceding POSIX example of input and output):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: With C++ futures, we need to first tell C++ the signature type of our thread
    to ensure type safety. To accomplish this in our example (there are many ways
    to leverage the future's APIs, this is simply one of them), we create a `std::packaged_task{}`
    and provide it with our thread function signature.
  prefs: []
  type: TYPE_NORMAL
- en: This does a couple of things. First, it tells the APIs which thread to call,
    and, in addition, it sets storage aside for the result of the thread that can
    be retrieved later using `std::future{}`. Once `std::packaged_task{}` is created,
    we get the `std::future{}` from `packaged_task{}` using the `get_future()` function.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we start the thread by creating a thread object and passing it the `std::packaged_task{}`
    object  created previously.
  prefs: []
  type: TYPE_NORMAL
- en: We can provide the thread with its initial input in the constructor of the thread,
    which takes all of the arguments of the thread as additional, template-based arguments.
    To retrieve the result of the thread, we use `get()` from the future, which is
    valid once the thread has completed and been joined (hence the name *future*).
  prefs: []
  type: TYPE_NORMAL
- en: Although futures are, in some ways, more complicated than simply passing a `void
    *` around, the interface is elegant, allowing for threads to take on any desired
    signature type while also providing type safety. (No `reinterpret_casts()` were
    needed to provide this example, ensuring Core Guideline Compliance and reducing
    the likelihood of hard-to-find logic bugs.)
  prefs: []
  type: TYPE_NORMAL
- en: Yielding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Similar to POSIX threads, C++ threads provide the ability to yield a thread,
    relinquishing the CPU so that other threads that need to perform their tasks may
    do so. This is expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we leverage the `yield()` function provided by the
    `this_thread` namespace, which yields the calling thread. As a result, it is better
    capable of shuffling the output of the thread between the two threads, as previously
    demonstrated.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to yielding, a thread might need to stop its execution for a given
    amount of time. Similar to `sleep()` in POSIX, C++ provides the ability to sleep
    the currently executing thread. The difference with C++ is that a more granular
    API is provided, allowing the user to easily decide which type of granularity
    they prefer (including nanosecond and second resolutions), as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we create a thread that outputs `Hello World` to `stdout`.
    Just prior to outputting to `stdout`, the thread sleeps for a second by calling
    the `sleep_for()` provided by the `this_thread` namespace, and using the second
    literal to define `1` second, resulting in `Hello World` being output to `stdout`
    each second.
  prefs: []
  type: TYPE_NORMAL
- en: Synchronization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another notable difference between POSIX threads and C++ threads is the simplicity
    of thread synchronization. Like the POSIX APIs, C++ provides the ability to create
    a mutex, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we create a thread that increments a shared counter,
    which is surrounded by a C++ `std::mutex{}`, in effect creating a guarded critical
    region. We then create two threads, wait for them to complete, and then output
    the result to `stdout`, which ends up being `2` as we executed two threads.
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem with POSIX threads and the preceding C++ example is seen when a
    thread has to leave a critical region in more than one place, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, the critical region is exited in more than one place,
    and, as a result, the mutex must be unlocked in multiple places to prevent deadlock.
    Although this seems a simple example, an uncountable number of deadlock bugs have
    resulted from simply forgetting to unlock a mutex before returning from a critical
    region.
  prefs: []
  type: TYPE_NORMAL
- en: 'To prevent this problem, C++ provides `std::lock_guard{}`, which provides a
    simple mechanism for unlocking a mutex using **Resource Acquisition Is Initialization**
    (**RAII**) as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we create an RAII-based lock guard in the thread instead
    of manually locking and unlocking the mutex. As a result, in this example, the
    entire thread is in the critical region as the mutex is locked when the guard
    is created and unlocked when the lock goes out of scope (that is, when the thread
    returns).
  prefs: []
  type: TYPE_NORMAL
- en: As demonstrated in the preceding example, it's impossible to accidentally forget
    to unlock the mutex, as unlocking the mutex is handled for us by the lock guard.
  prefs: []
  type: TYPE_NORMAL
- en: 'In some cases, the user might wish the thread to perform other useful work
    while waiting to gain access to a critical region. To accomplish this, `std::mutex{}`
    provides `try_lock()` as an alternative to `lock()`, which returns `false` if
    the lock could not be acquired:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we continue to try to lock the mutex in an endless
    `while` loop. We could, however, perform some additional work if `try_lock()`
    returns `false`, or we could sleep for a given amount of time before trying again,
    thereby reducing stress on the operating system and battery.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you wish to use `try_lock` with a lock guard to prevent the need to manually
    unlock the mutex, you may do so using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we introduce two new features of C++ threads. The first is
    `std::unique_lock{}`, which is similar to `std::lock_guard{}`.
  prefs: []
  type: TYPE_NORMAL
- en: '`std::lock_guard{}` is a simple RAII wrapper around a mutex, while `std::unique_lock`
    provides similar facilities to `std::unique_ptr{}`, in that the resulting lock
    is movable (not copyable), and provides additional APIs above and beyond a simple
    RAII wrapper.'
  prefs: []
  type: TYPE_NORMAL
- en: As a side note, with respect to all of these lock guards, don't forget to define
    the guard's variable, otherwise the lock will be locked and unlocked immediately,
    resulting in hard-to-find bugs.
  prefs: []
  type: TYPE_NORMAL
- en: One of the additional APIs provided by `std::unique_lock` is the ability to
    defer locking the mutex (that is, not locking on the construction of the lock
    itself). This provides the user with the ability to better control when locking
    occurs, using one of the many lock functions, such as `lock()`, `try_lock()`,
    `try_lock_for()`, and `try_lock_until()`.
  prefs: []
  type: TYPE_NORMAL
- en: In our preceding example, we try to lock the critical region, and, if that fails,
    we sleep for a second before trying again. Other modifiers include the `std::adopt_lock{}`
    and `std::try_lock{}` modifiers, which either assume the mutex is already locked,
    or that the constructor tries to lock without blocking.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to regular mutexes, C++ also provides, like POSIX, a recursive
    mutex, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we are capable of creating two lock guards on the same recursive
    lock without creating deadlock (as destructors are executed in reverse order to
    construction, ensuring the locks are unlocked in the proper order).
  prefs: []
  type: TYPE_NORMAL
- en: 'Another common problem with mutexes relates to locking more than one mutex
    at the same time; that is to say, if more than one critical region exists and
    a particular operation must operate on both critical regions at the same time.
    To accomplish this, C++17 added `std::scoped_lock{}`, which is similar to `std::lock_guard{}`,
    but accepts more than one lock, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: In this example, more than one mutex is locked and unlocked using the `std::scoped_lock{}`
    class.
  prefs: []
  type: TYPE_NORMAL
- en: '`std::unique_lock{}` is similar to `std::unique_ptr{}` in that it guards a
    resource and prevents copying. Similar to `std::shared_ptr{}` the mutex APIs also
    provide `std::shared_lock{}`, which provides the ability for more than one thread
    to gain access to the same mutex. The following code demonstrates this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we have two threads—a producer and a consumer. The
    producer (`mythread1`) increments a counter, while the consumer (`mythread2`)
    outputs the count to `stdout`. In the `main()` function we create three threads—one
    producer and two consumers.
  prefs: []
  type: TYPE_NORMAL
- en: We could implement this scenario using a regular `std::mutex`; however, such
    an implementation would be suboptimal as both consumers are not modifying the
    counter, meaning multiple consumers could safely execute simultaneously without
    corrupting the results if they happen to collide (as no modifications are being
    made).
  prefs: []
  type: TYPE_NORMAL
- en: If a regular `std::muted` is used, however, the consumers would have to wait
    on each other, which would also be suboptimal (obviously ignoring the fact that
    `stdout` is also a shared resource that should be treated as its own critical
    region to prevent corruption of `stdout` itself).
  prefs: []
  type: TYPE_NORMAL
- en: In order to solve this problem, we leverage `std::shared_mutex` instead of a
    regular `std::mutex`. In the producer, we lock the mutex using `std::unique_lock{}`,
    which ensures exclusive access to the critical region. In the consumer, however,
    we leverage `std::shared_lock{}`, which only waits on previous locks using `std::unique_lock{}`.
    If the mutex was acquired using `std::shared_lock{}`, the thread continues execution
    without waiting, sharing access to the critical region.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, prior to C++17 with the addition of `std::scoped_lock{}`, the only
    way to lock more than one mutex was to use the `std::lock()` (and friends) functions,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'As with POSIX, C++ also provides the ability to control the order in which
    threads execute, using condition variables. In the following example, we create
    two threads and synchronize the order of their execution using a condition variable,
    similar to the condition variable example for POSIX:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: As shown in the preceding example, although the second thread is created first,
    it executes last. This is accomplished by creating a C++ condition variable. In
    the second thread, we protect the critical region using `std::unique_lock{}`,
    and then we wait for the first thread to signal that it has completed by making
    a call to `notify_one()`.
  prefs: []
  type: TYPE_NORMAL
- en: Once the first thread has completed and notified the second thread, the second
    thread finishes its execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'This same approach also works for more than one thread in broadcast mode using
    C++ threads, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the first thread completes its work and then signals to all
    the remaining threads to complete. The second thread protects the critical region
    with a mutex, and waits for a signal from the first thread.
  prefs: []
  type: TYPE_NORMAL
- en: The problem is that once the first thread executes and signals that it is done,
    the remaining threads will attempt to execute, but only one thread can acquire
    the critical region, resulting in the third thread waiting for the critical region
    to be unlocked and being notified. For this reason, when the second thread is
    complete, it must notify the condition variable again to unlock the remaining
    thread, allowing all three to complete.
  prefs: []
  type: TYPE_NORMAL
- en: 'To overcome this, we will combine everything learned in this section, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: This example is identical to the previous example, with one simple change. Instead
    of `std::mutex{}`, we make use of `std::shared_mutex{},` and `std::shared_lock{}`
    is used to lock the mutex.
  prefs: []
  type: TYPE_NORMAL
- en: In order to be able to use a shared mutex in place of a regular mutex, `std::condition_variable_any{}` must
    be used instead of `std::condition_variable{}`. By using `std::shared_mutex{}`
    instead of `std::mutex{}`, when the first thread signals that it has completed,
    the remaining threads are free to complete their work and process the critical
    region simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, C++ provides a convenient mechanism for calling a function once if
    more than one thread is needed, but allowing only one to execute initialization
    logic (a feature that POSIX also provides but is not covered in this book), as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: In this example, more than one thread is created, but `Hello World` is only
    executed once using the `std::call_once{}` wrapper. It should be noted that although
    this seems simple, `std::call_once{}` ensures that the flag that holds the state
    as to whether or not the wrapped logic has yet to be executed is flipped atomically,
    thereby preventing the possibility of race conditions, however unlikely they might
    be.
  prefs: []
  type: TYPE_NORMAL
- en: Studying an example on parallel computation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this example, we will demonstrate how to perform a parallel computation
    task that will calculate prime numbers, using threading. In this example, the
    following inclusion files and namespaces are required:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Calculating prime values is an expensive operation for large numbers, but thankfully,
    they can be calculated in parallel. It should be noted that in our example, we
    don't attempt to optimize our search algorithm, as our goal here is to provide
    a readable example of threading. There are many methods, some simple, for improving
    the performance of the code in this example.
  prefs: []
  type: TYPE_NORMAL
- en: 'To store the prime numbers that our program finds, we will define the following
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: This class provides a place for us to store each prime number using the `add()`
    function. Once all the primes that we plan to search for are found, we provide
    a `print()` function that is capable of printing the identified prime numbers
    in sorted order.
  prefs: []
  type: TYPE_NORMAL
- en: 'The thread that we will use to check whether a number is a prime number is
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: In this thread, we loop through every possible multiple of the number provided,
    and check to see whether the modulus is `0`. If it is `0`, the number is not a
    prime. If no multiple is found, the number is a prime and it is added to our list.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, in our `protected_main()` function, we search for a set of primes.
    We start by first converting all of our arguments so that they may be processed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: We are expecting three arguments. The first argument will provide the highest
    possible number we wish to check to see whether it is a prime number; the second
    argument is the total number of threads we wish to create to search for prime
    numbers, and the third will determine whether we want to print the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next task is to get the highest possible prime number to search for, as
    well as to get the total number of threads to create. Consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we know how many primes to search for, and how many threads to create,
    we search for our prime numbers as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: In this code, we search for all the primes up to the number provided by the
    user, incrementing by the total number of threads provided by the user. We then
    create a list of threads, providing each thread with the number it should look
    for prime from.
  prefs: []
  type: TYPE_NORMAL
- en: Once all the threads are created, we wait for the threads to finish. It should
    be noted that there are many ways to further optimize this logic, including preventing
    the recreation of threads, thus preventing the overuse of `malloc()`, but this
    example provides a simple mechanism to demonstrate the point of this example.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last thing we do in the `protected_main()` function is check to see whether
    the user wants to see the results, and to print them if so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we execute the `protected_main()` function using our `main()`, and
    catch any exceptions that might arise as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Compiling and testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To compile this code, we leverage the same `CMakeLists.txt` file that we have
    been using for the other examples—find it at the following link: [https://github.com/PacktPublishing/Hands-On-System-Programming-with-CPP/blob/master/Chapter12/CMakeLists.txt](https://github.com/PacktPublishing/Hands-On-System-Programming-with-CPP/blob/master/Chapter12/CMakeLists.txt).
  prefs: []
  type: TYPE_NORMAL
- en: 'With this code in place, we can compile this code using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'To execute the example, run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'As shown in this snippet, the prime numbers up to `20` are identified. To demonstrate
    the effectiveness of threading, execute the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: As can be seen, as the total number of threads decreases, the total amount of
    time the application takes to find the prime numbers increases.
  prefs: []
  type: TYPE_NORMAL
- en: Studying an example on benchmarking with threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In previous chapters, we discussed how to benchmark software using various different
    mechanisms. In this chapter, we will explore creating our own high-resolution
    timer using a thread, instead of using the high-resolution timer provided by the
    C++ chrono APIs.
  prefs: []
  type: TYPE_NORMAL
- en: To accomplish this, we will create a thread with the sole job of counting as
    fast as possible. It should be noted that although this will provide a high-resolution
    timer that is extremely sensitive, it has a lot of disadvantages compared to computer
    architectures such as Intel. These provide hardware instructions with higher resolution
    than is possible here, while being less susceptible to CPU frequency scaling.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, the following inclusion and namespaces are needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'We will store the high-resolution timer in a `count` variable, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: The `enable_counter` Boolean will be used to turn the timer off, while the mutex
    and condition variable will be used to turn the timer on at the correct time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our high-resolution timer will consist of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The timer will notify the condition variable that it is running once it is
    started, and will continue to count until the `enable_counter` flag is set to
    `false`. To time an operation, we will use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: This logic creates the timer thread, and then waits for it to start using the
    condition variable. Once the timer is started, it will execute the function under
    test and then disable the timer and wait for the thread to complete, returning
    the resulting total number of ticks.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our `protected_main()` function, we ask the user for the total number of
    times to loop in a `for` loop, and then time how long it takes to execute the
    `for` loop, outputting the results to `stdout` when we are done, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we execute the `protected_main()` function using our `main()`, and
    catch any exceptions that might arise, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Compiling and testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To compile this code, we leverage the same `CMakeLists.txt` file that we have
    been using for the other examples: [https://github.com/PacktPublishing/Hands-On-System-Programming-with-CPP/blob/master/Chapter12/CMakeLists.txt](https://github.com/PacktPublishing/Hands-On-System-Programming-with-CPP/blob/master/Chapter12/CMakeLists.txt).
  prefs: []
  type: TYPE_NORMAL
- en: 'With this code in place, we can compile this code using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'To execute the code, run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: As shown in this snippet, the example is run with a loop of `1000000` iterations,
    and the number of ticks it took to execute the loop is output to the console.
  prefs: []
  type: TYPE_NORMAL
- en: Studying an example on thread logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The final example in this chapter will build upon our existing debugger example
    to add support for multiple clients. In [Chapter 10](2d0b3ea6-499f-4064-a278-c480d2c74c75.xhtml), *Programming
    POSIX Sockets Using C++*, we added support for networking to the example debugger,
    providing the ability to offload our debugging logs to a server in addition to
    the local system.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with this is that the server could only accept one connection before
    closing, as it didn't have the logic for handling more than one client. In this
    example, we will fix that issue.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start, we will need to define our port and max debug string length, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The server will require the following include statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'As with our previous example, the log file will be defined as global, and a
    mutex will be added to synchronize access to the log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Instead of the `recv()` function being defined in the server, we will define
    it globally to provide easy access to our client threads (each client will spawn
    a new thread):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'As with the `recv()` function, the `log()` function will also be moved out
    of the server and will create our client threads. Each time a connection is made
    by a client, the server will spawn a new thread (the `log()` function), which
    is implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: The only difference with using the `log()` function, compared to the example
    in [Chapter 10](2d0b3ea6-499f-4064-a278-c480d2c74c75.xhtml), *Programming POSIX
    Sockets Using C++*, is the addition of `std::unique_lock{}` to guard access to
    the log (in the event that more than one client attempts to write to the log at
    the same time). The handle is passed to the log function instead of the handle
    being a member of the server, and we flush the log file after each write to ensure
    all the writes are actually written to disk, as we will close the server application
    by killing it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the server is modified to accept incoming connections and spawn threads
    as a result. The server starts with the same logic in the previous example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The server''s constructor creates a socket, and binds the socket to the ports
    identified. The major difference with the server is in the use of the `listen()`
    function, which used to be the `log()` function. Consider the following code for
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: The `listen()` function listens on the socket for new connections. When a connection
    is made, it creates a thread using the `log()` function and provides the `log`
    function with the handle of the new client.
  prefs: []
  type: TYPE_NORMAL
- en: There is no need to ensure the server and or clients are closed properly, as
    TCP will handle this for us, eliminating the need to track each client thread
    once created (that is, there is no need to `join()` the thread when it is complete).
    For this reason, we use the `detach()` function, which tells C++ that a `join()`
    will not take place, and the thread should continue to execute even after the
    thread object is destroyed.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we loop, waiting for more clients to connect.
  prefs: []
  type: TYPE_NORMAL
- en: 'The remaining logic for the server is the same. We create the server in the
    `protected_main()` function and execute the `protected_main()` function in our
    `main()` function, attempting to catch any exceptions that might occur. The following
    code shows this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Finally, the client logic for this example is identical to the client logic
    found in [Chapter 10](2d0b3ea6-499f-4064-a278-c480d2c74c75.xhtml), *Programming
    POSIX Sockets using C++*.
  prefs: []
  type: TYPE_NORMAL
- en: Compiling and testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To compile this code, we leverage the same `CMakeLists.txt` file that we have
    been using for the other examples—[https://github.com/PacktPublishing/Hands-On-System-Programming-with-CPP/blob/master/Chapter11/CMakeLists.txt](https://github.com/PacktPublishing/Hands-On-System-Programming-with-CPP/blob/master/Chapter11/CMakeLists.txt).
  prefs: []
  type: TYPE_NORMAL
- en: 'With this in place, we can compile the code using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'To execute the server, run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'To execute the client, open a new Terminal and run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'As shown in this snippet, when the client is executed, the client and server
    side both output `DEBUG: Hello World` to `stderr`. In addition, the client outputs `Hello
    World` to `stderr` as the second call to `std::clog` is not redirected.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Both log files contain the redirected `DEBUG: Hello World`. Finally, we can
    execute the client more than once, resulting in the server logging the output
    from both clients instead of just one.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed how to program threads using both POSIX and C++
    APIs. We then discussed three examples. The first example demonstrated how to
    use threading to perform a parallel computation, while the second demonstrated
    how to create your own high-resolution timer using threading to perform benchmarking.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the third example built upon our existing debugging example to provide
    support for multiple clients. The next, and final, chapter will discuss the error
    handling features provided by C and C++, including C style error handling and
    exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How do you get the ID of a thread using POSIX? What about when using C++?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the main issue with POSIX thread input and output?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a race condition?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is deadlock?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is `std::future{}` in C++, and what problem is it trying to solve?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the main reason for using `std::call_once()`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between `std::shared_mutex` and `std::mutex`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the purpose of a recursive mutex?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[https://www.packtpub.com/application-development/c17-example](https://www.packtpub.com/application-development/c17-example)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.packtpub.com/application-development/getting-started-c17-programming-video](https://www.packtpub.com/application-development/getting-started-c17-programming-video)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
