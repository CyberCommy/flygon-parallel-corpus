- en: Read/Write Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Reading and writing text data—reading text encoded in any encoding from a file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reading lines of text—reading a text file divided line by line
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reading and writing binary data—reading binary-structured data from a file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zipping a directory—reading and writing a compressed ZIP archive
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pickling and shelving—how to save Python objects on disk
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reading configuration files—how to read configuration files in the `.ini` format
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing XML/HTML content—generating XML/HTML content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reading XML/HTML content—parsing XML/HTML content from a file or string
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reading and writing CSV—reading and writing CSV spreadsheet-like files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reading and writing to a relational database—loading and saving data into a
    `SQLite` database
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The input for your software will come from various sources: command-line options,
    the standard input, the network, and, frequently, files. Reading from an input
    itself is rarely the problem when dealing with external sources of data; some
    input might require a bit more setup, some are more straightforward, but generally
    it''s just a matter of opening it and then reading from it.'
  prefs: []
  type: TYPE_NORMAL
- en: The problem arises with what to do with the data that we read. There are thousands
    of formats out there, each with its own complexities, some are text-based and
    some are binaries. In this chapter, we will set recipes to deal with the most
    common formats that you will probably have to face during your life as a developer.
  prefs: []
  type: TYPE_NORMAL
- en: Reading and writing text data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When reading a text file, we already know we should open it in text mode, which
    is the default Python mode. In this mode, Python will try to decode the content
    of the file according to what `locale.getpreferredencoding` returns as being the
    preferred encoding for our system.
  prefs: []
  type: TYPE_NORMAL
- en: Sadly, the fact that any type of encoding is the preferred encoding for our
    system has nothing to do with what encoding might have been used to save the contents
    of the file. As it might be a file that someone else wrote, or even if we write
    it ourselves, the editor might have saved it in any encoding.
  prefs: []
  type: TYPE_NORMAL
- en: So the only solution is to specify the encoding that should be used to decode
    the file.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `open` function that Python provides accepts an `encoding` argument that
    can be used to properly encode/decode the contents of a file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once the `encoding` option is passed to `open`, the resulting object file will
    know that any string provided to `file.write` must be encoded to the specified
    encoding before storing the actual bytes into the file. This is also true for
    `file.read()`, which will fetch the bytes from the file and decode them with the
    specified encoding before returning them to you.
  prefs: []
  type: TYPE_NORMAL
- en: This allows you to read/write content in files with any encoding independently
    from the one that your system declares as the favorite one.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you're wondering how it might be possible to read a file for which the encoding
    is unknown, well, that's a far more complex problem.
  prefs: []
  type: TYPE_NORMAL
- en: The fact is that unless the file provides some guidance in a header, or something
    equivalent, that can tell you the type of encoding on the content, there is no
    reliable way to know how a file might be encoded.
  prefs: []
  type: TYPE_NORMAL
- en: 'You might try multiple different types of encoding and check which one is able
    to decode the content (doesn''t throw `UnicodeDecodeError`), but the fact that
    a set of bytes decodes to an encoding doesn''t guarantee that it decodes to the
    right result. For example, the `''ì''` character encoded to `utf-8` decodes perfectly
    in `latin-1`, but results in a totally different thing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: If you really want to try guessing the type-encoding of the content, you might
    want to try a library, such as `chardet`, that is able to detect most common types
    of encoding. If the length of the data to decode is long and varied enough, it
    will frequently succeed in detecting the right encoding.
  prefs: []
  type: TYPE_NORMAL
- en: Reading lines of text
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When working with text files, the easiest way to process them is usually by
    line; each line of text is a separate entity and we can build them back by joining
    all lines by `'\n'` or `'\r\n'` depending on the system, thus it would be very
    convenient to have all the lines of a text file available in a list.
  prefs: []
  type: TYPE_NORMAL
- en: There is a very convenient way to grab lines out of a text file that Python
    makes instantly available.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As the `file` object itself is an iterable, we can directly build a list out
    of it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`open` acts as a context manager, returning the resulting object file. It''s
    very convenient to rely on the context manager as, when we are done with our file,
    we need to close it and using `open` as a context manager will actually do that
    for us as soon as we quit the body of `with`.'
  prefs: []
  type: TYPE_NORMAL
- en: The interesting part is that `file` is actually an iterable. When you iterate
    over a file, you get back the lines that are contained within it. So applying
    `list` to it will build a list of all the lines and we can then navigate the resulting
    list as we wish.
  prefs: []
  type: TYPE_NORMAL
- en: Reading and writing binary data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reading text data is already pretty complex as it requires decoding the contents
    of a file, but reading binary data can be far more complex as it requires parsing
    the bytes and their contents to reconstruct the original data that was saved within
    the file.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, you might even have to cope with byte-ordering because, when
    saving a number into a text file, the order the bytes will be written in really
    depends on the system that is writing that file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we want to read the beginning of the TCP header, the specific source
    and destination port, sequence number, and acknowledgment number, which is represented
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The steps for this recipe are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Given a file that contains a dump of a TCP packet (on my computer, I saved it
    as `/tmp/packet.dump`), we can try to read it as binary data and parse its contents.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The Python `struct` module is the perfect tool for reading binary-structured
    data and we can use it to parse our TCP packet as we know the size of each piece:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Being an HTTP connection, the result is what we would expect: `Source Port:
    50291, Destination Port: 80, Sequence Number: 2778997212`, and `Acknowledgment
    Number: 644363807`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The same can be done to write back the binary data by using `struct.pack`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First of all, we opened the file in *binary mode* (the `rb` argument). This
    tells Python to avoid trying to decode the contents of the file as if it was text;
    the content is returned as it is in a `bytes` object.
  prefs: []
  type: TYPE_NORMAL
- en: Then the data we read with `f.read()` is passed to `struct.unpack_from`, which
    is able to decode binary data as a set of numbers, strings, and so on. In our
    case, we used `>` to specify that the data we are reading is in big-endian ordering
    (like all network-related data) and then `HHLL` to state that we want to read
    two unsigned 16-bit numbers and two unsigned 32-bit numbers (the ports and the
    sequence/acknowledgment numbers).
  prefs: []
  type: TYPE_NORMAL
- en: As we used `unpack_from`, any other remaining data is just ignored after the
    four specified numbers are consumed.
  prefs: []
  type: TYPE_NORMAL
- en: The same applies to writing binary data. We opened the file in binary mode,
    packaged the four numbers into a bytes object through `struct.pack`, and wrote
    them to the file.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `struct.pack` and `struct.unpack` functions support many options and formatters
    to define what data should be written/read and how it should be written/read.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most common formatters for byte order are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Character | Byte order |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `=` | native |'
  prefs: []
  type: TYPE_TB
- en: '| `<` | little-endian |'
  prefs: []
  type: TYPE_TB
- en: '| `>` | big-endian |'
  prefs: []
  type: TYPE_TB
- en: If none of those is specified, the data will be encoded in your system native
    byte order and will be aligned as it's naturally aligned in your system memory.
    It's strongly discouraged to save data this way as the only system guaranteed
    to be able to read it back is the one that saved it.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the data itself, each type of data is represented by a single character,
    and each character defines the kind of data (integer, float, string) and its size:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Format | C type | Python type | Size (bytes) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `x` | pad byte | no value |  |'
  prefs: []
  type: TYPE_TB
- en: '| `c` | `char` | bytes of length 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| `b` | signed `char` | integer | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| `B` | unsigned `char` | integer | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| `?` | `_Bool` | bool | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| `h` | `short` | integer | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| `H` | unsigned `short` | integer | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| `i` | `int` | integer | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| `I` | unsigned `int` | integer | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| `l` | `long` | integer | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| `L` | unsigned `long` | integer | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| `q` | `long long` | integer | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| `Q` | unsigned `long long` | integer | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| `n` | `ssize_t` | integer |  |'
  prefs: []
  type: TYPE_TB
- en: '| `N` | `size_t` | integer |  |'
  prefs: []
  type: TYPE_TB
- en: '| `e` | half precision `float` | float | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| `f` | `float` | float | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| `d` | `double` | float | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| `s` | `char[]` | bytes |  |'
  prefs: []
  type: TYPE_TB
- en: '| `p` | `char[]` | bytes |  |'
  prefs: []
  type: TYPE_TB
- en: '| `P` | `void *` | integer |  |'
  prefs: []
  type: TYPE_TB
- en: Zipping a directory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Archive files are a good way to distribute whole directories as if they were
    a single file and to reduce the size of the distributed files.
  prefs: []
  type: TYPE_NORMAL
- en: Python has built-in support for creating ZIP archive files, which can be leveraged
    to compress a whole directory.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The steps for this recipes are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `zipfile` module allows us to create compressed ZIP archives made up of
    multiple files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Using `zipdir` is as simple as providing a name for the `.zip` file that should
    be created and a path for the directory that should be archived:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, I compressed the directory that contains the document trees for
    this book. Once the archive is ready, we can verify its content by opening it
    with `zipfile` again and listing the contained entries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`zipfile.ZipFile` is first opened in write mode with the `ZIP_DEFLATED` compression
    (which means compress the data with the standard ZIP format) as a context. That
    allows us to perform changes to the archive and then flush them and close the
    archive automatically as soon as we exit the body of the context manager.'
  prefs: []
  type: TYPE_NORMAL
- en: Within the context, we rely on `os.walk` to traverse the whole directory and
    all its subdirectories and find all the contained files.
  prefs: []
  type: TYPE_NORMAL
- en: 'For each file found in each directory, we build two paths: the absolute one
    and the relative one.'
  prefs: []
  type: TYPE_NORMAL
- en: The absolute one is required to tell `ZipFile` from where to read the data that
    needs to be added to the archive, and the relative one is used to give a proper
    name to the data we are writing into the archive. This way, each file we write
    into the archive will be named as it was on our disk, but instead of being stored
    with its full path (`/home/amol/pystlcookbook/_build/doctrees/io.doctree`), it
    will be stored with the relative path (`_build/doctrees/io.doctree`), so that
    in case the archive is decompressed, the file will be created relative to the
    directory we are decompressing into, instead of ending up with a long pointless
    path that resembles the one that the file had on my computer.
  prefs: []
  type: TYPE_NORMAL
- en: Once the path of the file and the name that should be used to store it are ready,
    they are provided to `ZipFile.write` to actually write the file into the archive.
  prefs: []
  type: TYPE_NORMAL
- en: Once all the files are written, we exit the context manager and the archive
    is finally flushed.
  prefs: []
  type: TYPE_NORMAL
- en: Pickling and shelving
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If there is a lot of information that your software needs or if you want to
    preserve history across different runs, there is little choice apart from saving
    it somewhere and loading it back on the next run.
  prefs: []
  type: TYPE_NORMAL
- en: Manually saving and loading back data can be tedious and error-prone, especially
    if the data structures are complex.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, Python provides a very convenient module, `shelve`, that allows
    us to save and restore Python objects of any kind as far as it's possible to `pickle`
    them.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Perform the following steps for this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '`shelf`, implemented by `shelve`, can be opened like any other file in Python.
    Once opened, it''s possible to read and write keys into it like a dictionary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Values stored into `shelf` can be read back as a dictionary, too:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Complex values, or even custom classes, can be stored in `shelve`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `shelve` module is implemented as a context manager that manages a `dbm`
    database.
  prefs: []
  type: TYPE_NORMAL
- en: When the context is entered, the database is opened, and the contained objects
    become accessible because `shelf` was a dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each object is stored into the database as a pickled object. That means that
    before storing it, each object is encoded with `pickle` and results in a serialized
    string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: That allows `shelve` to store any kind of Python object, even custom classes,
    as far as they are available again at the time the object is read back.
  prefs: []
  type: TYPE_NORMAL
- en: Then, when the context is exited, all the keys of `shelf` that were changed
    are written back to disk by calling `shelf.sync` when `shelf` is closed.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A few things need attention when working with `shelve`.
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, `shelve` doesn''t track mutations. If you store a mutable object
    (such as `dict` or `list`) in `shelf`, any change you do to it won''t be saved.
    Only changes to the root keys of `shelf` itself are tracked:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This just means that you need to reassign any value you want to mutate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '`shelve` doesn''t allow concurrent read/writes from multiple processes or threads.
    You must wrap the `shelf` access with a lock (such as by using `fcntl.flock`)
    if you want to access the same `shelf` from multiple processes.'
  prefs: []
  type: TYPE_NORMAL
- en: Reading configuration files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When your software has too many options to simply pass them all through the
    command line, or when you want to ensure that your users don't have to manually
    provide them every time they start the application, loading those options from
    a configuration file is one of the most widespread solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Configuration files should be easy to read and write for humans, as they will
    be working with them quite often, and one of the most common requirements is for
    them to allow comments, so that the user can place comments in the configuration
    to write down why some options were set or how some values were computed. This
    way, when the user comes back to the configuration file in six months, they will
    still know the reasons for those options.
  prefs: []
  type: TYPE_NORMAL
- en: For these reasons, usually relying on JSON or machine-machine formats to configure
    options doesn't work very well, so a configuration-specific format is best.
  prefs: []
  type: TYPE_NORMAL
- en: One of the longest-living configuration formats is the `.ini` file, which allows
    us to declare multiple sections with the `[section]` syntax and to set options
    with the `name = value` syntax.
  prefs: []
  type: TYPE_NORMAL
- en: 'A resulting configuration file will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Another great advantage is that we can easily read `.ini` files from Python.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The steps for this recipe are:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Most of the work of loading and parsing `.ini` can be done by the `configparser`
    module itself, but we are going to extend it to implement per-section default
    values and converters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the provided function is as easy as providing a configuration and a schema
    that should be used to parse it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting configuration dictionary, `config`, will contain all the options
    provided in the configuration or declared in the schema, converted to the type
    specified in the schema:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `read_config` function does three major things:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Allows us to parse plain lists of options without sections. This allows us
    to parse simple `config` files:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Applies default values for all options declared in the configuration's `default` schema.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Converts all values to the `type` provided in the schema.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first feature is provided by trapping any `MissingSectionHeaderError` exception
    raised during parsing and automatically adding a `[main]` section if it's missing.
    All the options provided without any section will be recorded under the `main`
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Providing default values is instead done by doing a first pass through all the
    sections and options declared in the schema and setting them to the value provided
    in their `default` or to `None` if no default value is provided.
  prefs: []
  type: TYPE_NORMAL
- en: In a second pass, all the default values are then overridden with the actual
    values stored in the configuration when those exist.
  prefs: []
  type: TYPE_NORMAL
- en: During this second pass, for each value being set, the `type` for that option
    is looked up in the schema. A string such as `getboolean` or `getint` is built
    by prefixing the type with the `get` word. This results in being the name of the
    `configparser` method that needs to be used to parse the configuration option
    into the requested type.
  prefs: []
  type: TYPE_NORMAL
- en: If no `type` was provided, an empty string is used. That results in the plain
    `.get` method being used, which reads the values as text. So not providing a `type`
    means treating the option as a normal string.
  prefs: []
  type: TYPE_NORMAL
- en: All the fetched and converted options are then stored in a dictionary, which
    makes it easier to access the converted values through the `config[section][name]`
    notation without needing to always call an accessor, such as `.getboolean`.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `interpolation=configparser.ExtendedInterpolation()` argument provided to
    the `ConfigParser` object also enables an interpolation mode that allows us to
    refer to values from other sections into the configuration file.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is convenient to avoid having to repeat the same values over and over,
    for example, when providing multiple paths that should all start from the same
    root:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, the syntax allows us to refer to options in other sections:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Another convenient feature of `ConfigParser` is that if you want to make an
    option available in all sections, you can just specify it in the special `[DEFAULT]`
    section.
  prefs: []
  type: TYPE_NORMAL
- en: 'That will make the option available in all other sections unless it''s explicitly
    overwritten in the section itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Writing XML/HTML content
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Writing SGML-based languages is generally not very hard, most languages provide
    utilities to work with them, but if the document gets too big, it's easy to get
    lost when trying to build the tree of elements programmatically.
  prefs: []
  type: TYPE_NORMAL
- en: Ending up with hundreds of `.addChild` or similar calls all after each other
    makes it really hard to understand where we were in the document and what part
    of it we are currently editing.
  prefs: []
  type: TYPE_NORMAL
- en: Thankfully, by joining the Python `ElementTree` module with context managers,
    we can have a solution that allows our code structure to match the structure of
    the XML/HTML we are trying to generate.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this recipe, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create an `XMLDocument` class that represents the tree of an XML/HTML
    document and have `XMLDocumentBuilder` assist in actually building the document
    by allowing us to insert tags and text:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then use our `XMLDocument` to build the document we want. For example,
    we can build web pages in HTML mode:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '`XMLDocument` supports casting to string, so to see the resulting XML, we can
    just print it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the structure of our code matches the nesting of the actual
    XML document, so it's easy to see that anything within `_.tag('body')` is the
    content of our body tag.
  prefs: []
  type: TYPE_NORMAL
- en: 'Writing the resulting document to an actual file can be done by relying on
    the `XMLDocument.write` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The actual document generation is performed by `xml.etree.ElementTree`, but
    if we had to generate the same document with plain `xml.etree.ElementTree`, it
    would have resulted in a bunch of `el.append` calls:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: This makes it really hard to have any understanding of where we are. In this
    example, we were just building a structure, `<html><head><title>This is the title</title></head></html>`,
    but it was already pretty hard to follow that `title` was inside head and so on.
    For a more complex document, it would become impossible.
  prefs: []
  type: TYPE_NORMAL
- en: So while our `XMLDocument` preserves the `root` of the document tree and provides
    support for casting it to string and writing it to a file, the actual work is
    done by `XMLDocumentBuilder`.
  prefs: []
  type: TYPE_NORMAL
- en: '`XMLDocumentBuilder` keeps a stack of nodes to track where we are in the tree
    (`XMLDocumentBuilder._current`). The tail of that list will always tell us which
    tag we''re currently inside.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Calling `XMLDocumentBuilder.text` will add text to the currently active tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code will result in `<html>Some text, and even more</html>` being
    generated.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `XMLDocumentBuilder.tag` method will add a new tag within the currently
    active tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This leads to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The interesting part is that the `XMLDocumentBuilder.tag` method also returns
    a context manager. On entry, it will set the entered tag as the currently active
    one and on exit, it will recover the previously active node.
  prefs: []
  type: TYPE_NORMAL
- en: 'That allows us to nest `XMLDocumentBuilder.tag` calls and generate a tree of
    tags:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'This leads to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The actual document node can be grabbed through `as`, so in previous examples
    we were able to grab the `title` node that was just created and set a text for
    it, but `XMLDocumentBuilder.text` would have worked too because the `title` node
    was now the active element once we entered its context.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is one trick that I frequently apply when using this recipe. It makes
    it a bit harder to understand what's going on, on the Python side, and that's
    the reason why I avoided doing it while explaining the recipe itself, but it makes
    the HTML/XML structure even more readable by getting rid of most Python *noise*.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you assign the `XMLDocumentBuilder.tag` and `XMLDocumentBuilder.text` methods
    to some short names, you can nearly disappear the fact that you are calling Python
    functions and make the XML structure more relevant:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Written this way, the only things you actually see are the HTML tags and their
    content, which makes the document structure more obvious.
  prefs: []
  type: TYPE_NORMAL
- en: Reading XML/HTML content
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reading HTML or XML files allows us to parse web pages' content and to read
    documents or configurations described in XML.
  prefs: []
  type: TYPE_NORMAL
- en: Python has a built-in XML parser, the `ElementTree` module which is perfect
    for parsing XML files, but when HTML is involved, it chokes quickly due to the
    various quirks of HTML.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider trying to parse the following HTML:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'You will quickly face errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Luckily, it's not too hard to adapt the parser to handle at least the most common
    HTML files, such as self-closing/void tags.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You need to perform the following steps for this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ElementTree` by default uses `expat` to parse documents, and then relies on
    `xml.etree.ElementTree.TreeBuilder` to build the DOM of the document.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can replace `XMLParser` based on `expat` with our own parser based on `HTMLParser`
    and have `TreeBuilder` rely on it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Using this parser, we can finally handle our HTML document with success:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We can verify that our `root` node actually contains our original HTML document
    by printing it back:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting `root` document can then be navigated like any other tree of
    `ElementTree.Element`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To build the tree of `ElementTree.Element` objects representing the HTML document,
    we used two classes together: `HTMLParser` to read the HTML text, and `TreeBuilder`
    to build the tree of `ElementTree.Element` objects.'
  prefs: []
  type: TYPE_NORMAL
- en: Every time `HTMLParser` faces an open or closed tag, it will call `handle_starttag`
    and `handle_endtag`. When we face those, we notify `TreeBuilder` that a new element
    must be started and then that the element must be closed.
  prefs: []
  type: TYPE_NORMAL
- en: Concurrently, we keep track of the last tag that was started (so the tag we're
    currently in) in `self._stack`. This way, we can know the currently opened tag
    that hasn't yet been closed. Every time we face a new open tag or a closed tag,
    we check whether the last open tag was a self-closing tag; if it was, we close
    it before opening or closing the new tag.
  prefs: []
  type: TYPE_NORMAL
- en: 'This automatically converts code. Consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'It will be converted to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: As a new open tag was found, after facing a self-closing tag (`<br>`), the `<br>`
    tag is automatically closed.
  prefs: []
  type: TYPE_NORMAL
- en: 'It also handles code such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code is converted into the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: As a different closing tag (`</body>`) is faced right after the `<br>` self-closing
    tag, `<br>` is automatically closed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Even when `handle_data` is called, while processing text inside a tag, if the
    last open tag was a self-closing one, the self-closing tag is automatically closed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Hello World` text is considered as being the content of `<p>` instead
    of being the content of `<br>` because the code was converted to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Finally, once the full document is parsed, calling `ETHTMLParser.close()` will
    terminate the tree built by `TreeBuilder` and will return the resulting root `Element`.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The proposed recipe shows how to use `HTMLParser` to adapt the XML parsing utilities
    to cope with HTML, which is more flexible in rules when compared with XML.
  prefs: []
  type: TYPE_NORMAL
- en: 'While this solution handles mostly commonly written HTML, it won''t cover all
    possible cases. HTML supports some oddities that are sometimes used, such as attributes
    without any value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Or attributes without quotes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'And even some attributes with content but without any closing tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Even though most of these formats are supported, they are rarely used (with
    maybe the exception of attributes without any value, which our parser will just
    report as having a value of `None`), so in most cases, they won't cause trouble.
    But if you really need to parse HTML supporting all the possible oddities, it's
    surely easier to use an external library, such as `lxml` or `html5lib`, that tries
    to behave as much like a browser as possible when facing oddities.
  prefs: []
  type: TYPE_NORMAL
- en: Reading and writing CSV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CSV is considered one of the best exchange formats for tabular data; nearly
    all spreadsheet tools support reading and writing CSV, and it's easy to edit it
    with any plain text editor as it's easy for humans to understand.
  prefs: []
  type: TYPE_NORMAL
- en: Just split and set the values with a comma and you have practically written
    a CSV document.
  prefs: []
  type: TYPE_NORMAL
- en: Python has very good built-in support for reading CSV files, and we can easily
    write or read CSV data through the `csv` module.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will see how it''s possible to read and write a table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see the steps for this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, we will see how to write the specified table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The `table.csv` file will contain the same table that we saw previously, and
    we can read it back using any of the `csv` readers. The most convenient one, when
    your CSV file has headers, is `DictReader`, which will read each row in a dictionary
    with the headers as the keys:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Iterating over `DictReader` will consume the rows, which should print the same
    data we wrote:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CSV files are plain text files, with a few limitations. For example, nothing
    tells us how a newline should be encoded (`\r\n` or `\n`) and nothing tells us
    which encoding should be used, `utf-8` or `ucs-2`. In theory, CSV doesn't even
    state that it must be comma-separated; a lot of software will write it separated
    by `:` or `;`.
  prefs: []
  type: TYPE_NORMAL
- en: That's why you should pay attention to the `encoding` provided to the `open`
    function when reading CSV files. In our example, we knew for sure that `utf8`
    was used, because we wrote the file ourselves, but in other cases, there would
    be no guarantee that any specific encoding was used.
  prefs: []
  type: TYPE_NORMAL
- en: In case you are not sure how the CSV file is formatted, you can try to use the
    `csv.Sniffer` object, which, when applied to the text contained in the CSV file,
    will try to detect the dialect that was used.
  prefs: []
  type: TYPE_NORMAL
- en: Once the dialect is known, you can pass it to `csv.reader` to tell the reader
    to parse the file using that dialect.
  prefs: []
  type: TYPE_NORMAL
- en: Reading/writing a database
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python is often referred to as a language that has *batteries included*, thanks
    to its very complete standard library, and one of the best features it provides
    is reading and writing from a full-featured relational database.
  prefs: []
  type: TYPE_NORMAL
- en: Python ships with the `SQLite` library built in, meaning that we can save and
    read database files stored by `SQLite`.
  prefs: []
  type: TYPE_NORMAL
- en: The usage is pretty straightforward and most of it actually just involves sending
    SQL for execution.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this recipes, the steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `sqlite3` module, it''s possible to create a new database file, create
    a table, and insert entries into it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'The `sqlite3` module also provides support for `cursors`, which allow us to
    stream the results of a query from the database to your own code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'The previous snippet will print all rows stored in our database as `dict`,
    with the keys matching column names, and the values matching the value of each
    column in the row:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`sqlite3.connect` is used to open a database file; the returned object can
    then be used to perform any query against it, being an insertion or a selection.'
  prefs: []
  type: TYPE_NORMAL
- en: The `.execute` method is then used to run any SQL against the opened database.
    The SQL to run is provided as a plain string.
  prefs: []
  type: TYPE_NORMAL
- en: When performing queries, it's usually a bad idea to provide values directly
    in SQL, especially if those values were provided by the user.
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine we write the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: What would have happened if instead of `Italian`, the user provided the string
    `'Italian" OR 1=1 OR "'`? Instead of filtering the results, the user would have
    got access to the full content of the table. It's easy to see how this can become
    a security issue if the query is filtered by user ID and the table contains data
    from multiple users.
  prefs: []
  type: TYPE_NORMAL
- en: Also in case of `executescript` commands, the user would be able to rely on
    the same behavior to actually execute any SQL code, thereby injecting code into
    our own application.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, `sqlite3` provides a way to pass arguments to the SQL queries
    and escape their content, so that even if the user provided malicious input, nothing
    bad would happen.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `?` placeholders in our `INSERT` statements and the `:language` placeholder
    in our `SELECT` statement exist exactly for this purpose: to rely on `sqlite`
    escaping behavior.'
  prefs: []
  type: TYPE_NORMAL
- en: The two are equivalent and it's your choice which one you use. One works with
    tuples while the other works with dictionaries.
  prefs: []
  type: TYPE_NORMAL
- en: When consuming results from the database, they are then provided through `Cursor`.
    You can think of a cursor as something streaming data from the database. Each
    row is read only when you need to access it, thereby avoiding the need to load
    all rows in memory and transfer them all in a single shot.
  prefs: []
  type: TYPE_NORMAL
- en: While this is not a major problem for common cases, it can cause issues when
    a lot of data is read, up to the point where the system might kill your Python
    script because it's consuming too much memory.
  prefs: []
  type: TYPE_NORMAL
- en: By default, reading rows from a cursor returns tuples, with values in the same
    order the columns were declared. By using `db.row_factory = sqlite3.Row`, we ensure
    that the cursor returns rows as `sqlite3.Row` objects.
  prefs: []
  type: TYPE_NORMAL
- en: They are far more convenient than tuples, because while they can be indexed
    like tuples (you can still write `row[0]`), they also support accessing through
    column names (`row['name']`). Our snippet relies on the fact that `sqlite3.Row`
    objects can be converted to dictionaries to print all the row values with their
    column names.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `sqlite3` module supports many additional features, such as transactions,
    custom types, and in-memory databases.
  prefs: []
  type: TYPE_NORMAL
- en: Custom types allow us to read structured data as Python objects, but my favorite
    feature is support for in-memory databases.
  prefs: []
  type: TYPE_NORMAL
- en: Using an in-memory database is very convenient when writing test suites for
    your software. If you write software that relies on the `sqlite3` module, make
    sure you write tests connecting to a `":memory:"` database. That will make your
    tests faster and will avoid piling up test database files on your disk every time
    you run tests.
  prefs: []
  type: TYPE_NORMAL
