- en: Chapter 6. Migrating Instances
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will cover the task of migrating instances using the native
    OpenStack capability built into the Compute service (Nova). As mentioned earlier
    the existence of this functionality is unknown by many. In this chapter, we will
    prove out this capability by demonstrating how to manually migrate instances.
    As well as, review the steps required to automate this task and finally create
    a playbook with roles to fully automate instance migration to a specified compute
    node.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Instance migration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automation considerations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Coding the playbook and roles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Playbook and role review
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instance migration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Whenever the topic of instance migration comes up, it normally ends in a spirited
    conversation among my OpenStack peers for various reasons. So as a responsible
    adult, I will go on recording and say that instance migration is not perfect.
  prefs: []
  type: TYPE_NORMAL
- en: It has its flaws and can be quirky at best. Migration, whether live or not,
    does have a practical use case to your OpenStack cloud. Within OpenStack, you
    have the capability of migrating instances from one compute node to another. Some
    of the reasons you may do this is for maintenance purposes and/or to rebalance
    resource utilization across the cloud. Also, keep in mind that there are multiple
    ways to clear out a compute node for maintenance and we will cover that in more
    detail in [Chapter 8](ch08.html "Chapter 8. Setting Up Active-Active Regions"),
    *Setup Active-Active Regions*.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As mentioned earlier, the OpenStack Compute service (Nova) has the functionality
    to migrate instances in a traditional method and the ability to live-migrate an
    instance as well.
  prefs: []
  type: TYPE_NORMAL
- en: We will first examine the traditional migration method and its properties.
  prefs: []
  type: TYPE_NORMAL
- en: 'The traditional migration method will move an instance by shutting down that
    instance, coping the instance image/file to the next available compute node, starting
    the instance on the new node, and finally removing the instance from the original
    node. The areas to focus on in this method are:'
  prefs: []
  type: TYPE_NORMAL
- en: The instance is shut down
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The instance image/file will take time to copy to a new compute node
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: New compute node's selection is done by Nova Scheduler; you cannot assign one
    without additional steps required
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The instance is then brought back online once the copying is complete
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you will note, this method can be considered by some as intrusive. The idea
    of shutting down an instance to move it is generally not a desirable scenario
    back in the virtualization days. Remember that we are in a new era, *the era of
    cloud and disposable resources*.
  prefs: []
  type: TYPE_NORMAL
- en: Since resources are readily available and you have the control to determine
    how to consume those resources, there should be no issues taking an instance offline.
    Right? Yes, I know that it will take a while to shake that *pet* mentality, you
    will get there. In the event the circumstances allow this, which normally means
    you did a good job distributing across your hypervisors the instances running
    your application(s), you can very easily use this method to migration instances.
  prefs: []
  type: TYPE_NORMAL
- en: 'A working example of the traditional instance migration command via the OpenStackClient
    CLI would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The other migration method would be to perform live instance migrations. This
    method would remove the requirement to shut down the instance as was highlighted
    in the traditional migration process described earlier. Instead of shutting down
    the instance, it is suspended (still in a running state) while the instance is
    reassigned to the new compute node. Much advancement has been made since the **Mitaka**
    release to improve this functionality. Such additions include the ability to track
    the migration progress, pause, or cancel a migration in flight and the possibility
    to exclude certain attached volumes.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are additional system requirements needed in order to leverage the live
    migration functionality. Those requirements are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Some sort of shared or external storage capability must exist between your compute
    nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With live migration, you can select the new compute node, but you must assure
    that the new node has the resources required for the new instance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The old and new compute nodes must have the same CPU; OpenStack releases before
    Kilo may encounter an issue if this is not the case
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The first requirement is the most important one on the list, and it deserves
    some further explanation. The additional storage requirement can be covered in
    the following three different ways:'
  prefs: []
  type: TYPE_NORMAL
- en: The first way to satisfy the demand is to configure your hypervisors to store
    and have access to share storage for instance placement. This means that the instances
    are stored on the shared storage device and not on ephemeral storage. This could
    involve mounting NFS share on the compute node to be used to store instances or
    through fiber channel sharing LUN across the compute nodes, for example.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second approach to satisfying the shared/external storage requirement could
    be to leverage direct block storage where your instances are backed by image-based
    root disks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The third and final approach could be the boot from volume storage capability.
    This is where you are booting instances off of Cinder-based volumes. Of course,
    you would need the Block Storage service (Cinder) enabled and configured within
    your OpenStack cloud.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A key message in relation to using the live migration capability within Nova
    is that your instances must exist on some sort of shared/external storage and
    cannot use ephemeral storage local to the compute node. More details on the required
    configuration can be found at [http://docs.openstack.org/admin-guide/compute-configuring-migrations.html](http://docs.openstack.org/admin-guide/compute-configuring-migrations.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'A working example of an instance `server migrate` command via the Nova CLI
    would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As mentioned earlier, the whole concept of instance migration can range from
    being very simple all the way to being extremely complex. The hope here was you
    can now clearly understand what is required and the process followed during an
    instance migration. Let's now examine the process to manually migrating an instance
    using the CLI.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For simplicity purposes, we will demonstrate the manual commands using the OpenStack
    CLI only.
  prefs: []
  type: TYPE_NORMAL
- en: Manually migrating instances
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Compute service (Nova) is responsible for managing the instance migration
    process. Nova behind the scenes will execute all the steps needed to reassign
    the instance(s) to the new node and the movement of the instance image/file. Just
    like with every OpenStack service, you must authenticate first either by sourcing
    the OpenRC file discussed in [Chapter 1](ch01.html "Chapter 1. Introduction to
    OpenStack"), *Introduction to OpenStack*, or by passing authentication parameters
    in-line with the command. The two tasks individually require different parameter
    values to be provided in order to successfully execute the command. The examples
    are mentioned here.
  prefs: []
  type: TYPE_NORMAL
- en: 'An instance migration using an OpenRC file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Instance migration passing authentication parameters in-line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: After issuing the `openstack server migrate` command, I normally follow that
    up with the `openstack server show` command to report on the instance migration
    process. It is something that I normally would not use regularly when automating
    OpenStack tasks for obvious reasons. Since the migration process can take some
    time and we are executing the task manually, it helps to keep track of its progress.
  prefs: []
  type: TYPE_NORMAL
- en: Another way to check it on your migration would be to use the traditional Nova
    CLI with the `nova migration-list` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'A real life working example with an OpenRC file could look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the `nova migration-list` command would appear similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Manually migrating instances](graphics/B06086_06_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The complete output provided in the earlier command will vary based on any previous
    migrations executed. The key information to focus on is the `Status` of the migration
    for the instance you just attempted to migrate. The status will be reported as
    either `migrating` or `finished`. Once the status is updated to `finished`, you
    can then confirm the migration of the instance.
  prefs: []
  type: TYPE_NORMAL
- en: After migration, the instance will be in a `VERIFY_RESIZE` state by default,
    whether or not you actually resized it.
  prefs: []
  type: TYPE_NORMAL
- en: '![Manually migrating instances](graphics/image_06_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You would then need to execute the `openstack server resize` command to put
    the instance back to the `ACTIVE` state. The following example demonstrates this
    task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: At this point, you are good to go! Your instance would have been migrated to
    a new compute node and now running in an `ACTIVE` state. For those of us who have
    learned to accept the traditional migration process, the next statement normally
    is, why can't I migrate an instance to a specific compute node using the nova
    migrate command? We will talk about this concern in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Migrating an instance to a specific compute node
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The honest and straight answer to the earlier-mentioned question is that I have
    no clue why this capability was not included. Good thing is just like most things
    within OpenStack, there is always a way to get it to do what you want.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Please be advised that the steps outlined next are 100% a workaround (mid-grade
    dirty workaround) and should not be used within a production environment without
    first executing multiple levels of testing to ensure expected functionality.
  prefs: []
  type: TYPE_NORMAL
- en: As covered in the sections earlier, you cannot migrate an instance to a specific
    compute node using the traditional migration method. This option just does not
    exist (hope that changes soon). However, you can trick the Nova Scheduler to place
    the instance on a selected compute node by disabling the other compute nodes.
    Nova Scheduler will then have no choice and migrate the instance to the compute
    node you selected. Yes, in your mind you just called me an idiot. Do not worry
    it is not as intrusive at it sounds on paper.
  prefs: []
  type: TYPE_NORMAL
- en: The OpenStack control plane services are designed to report on the status of
    the distributed components such as compute nodes and/or Cinder nodes. The report
    received is then stored within the OpenStack database, and this is how the control
    plane services know if a particular node is up or down. Similarly, the control
    plane services can also force a report of a nodes status.
  prefs: []
  type: TYPE_NORMAL
- en: The Compute service (Nova) is an example service that can force a report on
    the status of a compute node. This will simply mark a compute node as up or down
    within the database and never actually do anything physically to the compute node.
    All instances running on those compute nodes will remain running, and the overall
    functionality of the node will go unchanged. However, for the time the node is
    disabled within the database, it will prevent new instances to be created there.
    If you have a very busy continuously changing OpenStack cloud and are not using
    a segregated set of compute nodes, this workaround is probably not a wise idea.
  prefs: []
  type: TYPE_NORMAL
- en: Due to its intrusive nature, this felt like a perfect administrative task to
    try to automate. With something like this, timing and accuracy is very critical.
    Wasting something as small as a minute could equate to the failure of being able
    to create any number of new instances by your Cloud Consumers inside of your OpenStack
    cloud. For tasks of this nature, automation is a king. In the next few sections,
    we will review the required steps to automate this task.
  prefs: []
  type: TYPE_NORMAL
- en: Automation considerations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This task also did not require any new framework decisions. All the other automation
    decisions we reviewed previously carried over.
  prefs: []
  type: TYPE_NORMAL
- en: Before we start, it is worth noting that when automating a task such as this
    one (migrating an instance and disabling compute nodes) it is best to collect
    details concerning them both before and after the migration. Having those details
    will simplify the process of reversing your changes, if required. Yes, this will
    add additional tasks to your role making it slightly more complex but still well
    worth it.
  prefs: []
  type: TYPE_NORMAL
- en: With this said, we are now ready to proceed with creating our next playbook
    and role.
  prefs: []
  type: TYPE_NORMAL
- en: Coding the playbooks and roles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will now create the playbook and role that will allow you
    to migrate an instance to a specific compute node using the traditional `openstack
    server migrate` command. Unlike the other tasks we have created thus far, there
    is really only one way to handle this task. We will take the steps outlined two
    sections earlier, automate them so that you only need to supply a few variable
    values, and then execute only one command.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter started off talking about instance migration and how there are
    two options within Nova to handle this: traditional migration and live migration.
    The traditional migration process is really a one-step process, but in order to
    properly automate this task, we will need to add a few more steps to the process.
    The brief outline of the tasks we will have to create are:'
  prefs: []
  type: TYPE_NORMAL
- en: List the compute nodes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Collect premigration instance details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Disable all compute nodes except for the one we want the instance to migrate
    to.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Migrate the instance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enable all compute nodes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Confirm instance migration.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Collect postmigration instance details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Role details
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since we are only creating a role in this example, we can start by the `main.yml`
    file within the role directory named `instance-migrate/tasks`. The beginning contents
    of this file will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The first step of retrieving the complete list of compute nodes within your
    OpenStack cloud is pretty easy using the `openstack hypervisor list` command.
    Once you get those results, it is best to strip down the output to provide just
    the information you need. Again, we will do this using the `awk` command and pipe
    (`|`) symbol. You will notice that this is similar to how we did it in the previous
    chapter. Remember that the shell module is used here because we are executing
    commands that require shell-specific operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this particular task, we have to get a bit magical with the `awk` commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Not only will it pull off the first three lines of the standard CLI output,
    it will also check the fourth column and print all the output except what matches
    what is passed in the `{{ desthype }}` variable. The consolidate output will then
    be registered into a variable named `hypelist`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next task will now collect premigration instance details that will be stored
    for later use within the role. The code to accomplish this looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: For this task, we are again using the OpenStackClient CLI to provide the instance
    details using the `openstack server list` command. You could as just as well use
    the `openstack server show` command to list the instance details. The distinct
    difference between the two commands is with the `openstack server list` command
    you can choose to display additional fields on the output. To do this, add the
    optional argument of `--long`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our particular case, we want to know the compute node that the particular
    instance is currently running on. Thus, we need to make sure that the `openstack
    server list` command looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The third task will be to disable the compute node(s) that you do not want
    the instance to migrate to. Remember that we are only disabling the compute nodes
    within Nova and not physically changing the state of the compute node(s). The
    code to do this would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: With the use of the `nova service-disable` command, you can tell Nova to disable
    any particular Nova-related service on remote hosts. In order to have Nova Scheduler,
    ignore/skip a compute node you need to disable the nova-compute service. The command
    also requires a reason to be provided, of which will be stored in the Nova database
    for later reference if required. It is in this task where we will use the list
    of compute node(s) stored in the `hypelist` variable collected earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that we will not disable the compute node that we want the instance to
    be migrated to as we have filtered it out of the list already.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moving on to the fourth task, we will now execute the instance migration. At
    this point, only the compute node you have selected to receive the migrated instance
    is enabled and nothing special needs to be done in reference to the `openstack
    server migrate`. See the supporting code here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the migration completes, we need to immediately enable back the compute
    node(s) that were disabled. One of the things I appreciate about OpenStack is
    if you are given a command to disable something, you are normally given a command
    to re-enable it. So we would simply execute the `nova service-enable` command.
    Again, we will use the `hypelist` variable to provide the list of compute node(s)
    to execute against. The code used is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that the migration is complete and the compute node(s) are all enabled,
    we can focus on completing the instance migration process. The last step in an
    instance migration is to notify Nova that you acknowledge the instance was moved.
    At first glance, I could live without this step, but in hindsight, some sort of
    confirmation does make overall sense. Code for this task can be found here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The last two final tasks will be used to provide the individual running the
    playbook with a visual confirmation of what was done. Consider this more of an
    automation fail safe and less of a requirement. With such a complex administrative
    task as this it is always a good common practice to output some details of what
    was changed on your system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'These two tasks will first collect postmigration instance details and then
    use the information collected from the `preinststat` and `postinststat` variables
    to output to the screen a synopses of the changes done. The synapsis template
    used will be:'
  prefs: []
  type: TYPE_NORMAL
- en: <instance migrated> was migrated from <compute node> to <compute node> and has
    a status of <instance current status>
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Feel free to go in and change it to fit your needs. This is just my opinioned
    approach. It felt right to keep it simple while still supplying the pertinent
    details one would care about when handling a migration. Upon review of the playbook
    recap, if something went wrong and/or was implemented incorrectly you should be
    able to quickly target steps for remediation.
  prefs: []
  type: TYPE_NORMAL
- en: Variable details
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Congratulations again, you have just completed your fourth OpenStack administration
    role. To support this role, we now need to create the variable file that will
    go along with it. The variable file named `main.yml`, which will be located in
    the `instance-migrate/vars` directory.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Keep in mind that the values defined in the variable file are intended to be
    changed before each execution for normal everyday use.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this role, we kept it pretty simple on the variables front and only needed
    to define three variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s take a moment to break down each variable. The summary would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Playbook details
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the variable file completed, we can move on to creating the master playbook
    file. The file will be named `migrate.yml` and saved to the `root` directory of
    the `playbook` directory.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The playbook and role names can be anything you choose. Specific names have
    been provided here in order to allow you to easily follow along and reference
    the completed code found in the GitHub repository. The only warning is whatever
    you decide to name the roles must remain uniform when referenced from within the
    playbook(s).
  prefs: []
  type: TYPE_NORMAL
- en: 'The contents of the `migrate.yml` file would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The summary of this file is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Adding content to our host inventory file and the global variable file was already
    done two chapters ago, so we already have that part covered. The values defined
    earlier would remain the same. Here is a quick recap of how those files are configured.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `hosts` file in the `root` directory of the playbook directory is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The global variable file inside the `group_vars/` directory is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Word of caution**'
  prefs: []
  type: TYPE_NORMAL
- en: Due to the contents of this file it should be stored as a secure file within
    whatever code repository you may use to store your Ansible playbooks/roles. Gaining
    access to this information could compromise your OpenStack cloud security.
  prefs: []
  type: TYPE_NORMAL
- en: We are moving along very smoothly now, smile, you did it! Hopefully by this
    point everything is becoming a bit clearer. Keeping with our tradition, we will
    finish up the chapter with a quick review of the playbook and role just created.
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing playbook and role
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s jump right into examining the role we created, named `instance-migrate`.
    The completed role and file, named `main.yml`, located in the `instance-migrate/tasks`
    directory, looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The corresponding variable file, named `main.yml`, located in the `instance-migrate/vars`
    directory, for this role will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, the master playbook file, named `migrate.yml`, located in the `root`
    directory of the `playbook` directory, will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Following that we created the `hosts` file, which also is located in the `root`
    directory of the `playbook` directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, creating the global variable file, named `util_container`, and saving
    it to the `group_vars/` directory of the playbook would complete the playbook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The complete set of code can again be found in the GitHub repository, [https://github.com/os-admin-with-ansible/os-admin-with-ansible-v2](https://github.com/os-admin-with-ansible/os-admin-with-ansible-v2).
  prefs: []
  type: TYPE_NORMAL
- en: 'We have finally landed on my most favorite part of creating Ansible playbooks
    and roles, which is to test out our great work. Fortunately for you, I have knocked
    out all the bugs already (wink wink). Assuming you have cloned the preceding GitHub
    repository, the command to test out the playbook from the Deployment node would
    be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'A sample of the playbook execution output can be viewed here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Reviewing playbook and role](graphics/B06086_06_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Nice to have completed yet another chapter covering real-life OpenStack administrative
    duties. The more you create playbooks and roles, the faster you will be able to
    create new code just by simply reusing the code created earlier for other purposes.
    Before this book is over, you will have a nice collection of playbooks/roles to
    reference for future Ansible automation.
  prefs: []
  type: TYPE_NORMAL
- en: Taking a moment to recap this chapter, you will recall that we covered what
    an instance migration is and why you would want to use this functionality. We
    reviewed the two possible migration methods traditional and live migration. You
    learned how to manually migrate an instance, as well as a workaround on how to
    use traditional migration to migrate an instance to a specific compute node. Finally,
    we created the Ansible playbook and role to automate that workaround approach. Overall
    instance maintenance and movement between compute nodes are continually improving.
    At some point you will not need to use some of the workaround mentioned in this
    chapter.  Stay tuned for some great improvements!
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter is a hot topic, as many of us have been exploring container
    technology. Particularly, we focused on how to consume and use containers while
    leveraging an OpenStack cloud. There are a few approaches now available, but the
    key is automating the process so that it is a reuseable function. In the next
    chapter, we will cover each approach and show the building blocks of how to accomplish
    this successfully. Grab another cup of coffee, do a quick stretch, and let's start
    [Chapter 7](ch07.html "Chapter 7. Managing Containers on Your Cloud"), *Managing
    Containers on Your Cloud*!
  prefs: []
  type: TYPE_NORMAL
