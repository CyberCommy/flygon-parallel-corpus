- en: Introduction to WebGL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After Apple created the Canvas element, the Mozilla Foundation began working
    on a Canvas 3D prototype in 2006, and by 2007, there were implementations of this
    early version, which would eventually become WebGL. In 2009, a consortium called
    the Kronos Group began a WebGL Working Group. By 2011, this group had produced
    the 1.0 version of WebGL, which is based on the OpenGL ES 2.0 API.
  prefs: []
  type: TYPE_NORMAL
- en: As I stated earlier, WebGL was seen as a 3D rendering API that would be used
    with the HTML5 Canvas element. Its implementation eliminates some of the rendering
    bottlenecks of the traditional 2D canvas API and gives near-direct access to the
    computer's GPU. Because of this, it is typically faster to use WebGL to render
    2D images to the HTML5 canvas than it is to use the original 2D canvas implementation.
    However, WebGL is significantly more complicated to use due to the added complexity
    of three-dimensional rendering. Because of this, several libraries are built on
    top of WebGL. This allows users to work with WebGL but use a simplified 2D API.
    If we were writing our game in traditional JavaScript, we might use a library
    such as Pixi.js or Cocos2d-x for 2D rendering on top of WebGL in order to simplify
    our code. Right now, WebAssembly uses an implementation of **Simple DirectMedia
    Layer** (**SDL**), and is the library that's used by most developers to write
    games. This WebAssembly version of SDL is built on top of WebGL and provides high-end
    performance, but is much easier to use.
  prefs: []
  type: TYPE_NORMAL
- en: Using SDL does not prevent you from also using WebGL directly from within the
    C++ code compiled into WebAssembly. There are times where we may be interested
    in directly interacting with WebGL because the features we are interested in are
    not directly available from within SDL. One example of these use cases is creating
    custom shaders that allow for special 2D lighting effects.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will need an image file from the GitHub project to run
    the examples. The app requires the `/Chapter03/spaceship.png` image file from
    the project directory. Please download the project from the following URL: [https://github.com/PacktPublishing/Hands-On-Game-Development-with-WebAssembly](https://github.com/PacktPublishing/Hands-On-Game-Development-with-WebAssembly).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will be covering the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: WebGL and canvas contexts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An introduction to WebGL shaders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: WebGL and JavaScript
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: WebGL and canvas contexts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: WebGL is a rendering context for drawing to the HTML5 element, and is an alternative
    to the 2D rendering context. Often, when someone mentions the canvas, they are
    referring to the 2D rendering context, which is accessed by calling `getContext`
    and passing in the string `2d`. Both contexts are methods of rendering to the
    HTML5 canvas element. A context is a type of API for immediate mode rendering.
    Two different WebGL contexts can be requested, both of which provide access to
    different versions of the WebGL API. These contexts are *webgl* and *webgl2*.
    In the following examples, I will be using the *webgl* context and will be using
    the WebGL 1.0 API. There is also a rarely used context for rendering a bitmap
    to the canvas that we can access by passing in `bitmaprenderer` as a string value.
  prefs: []
  type: TYPE_NORMAL
- en: I want to point out that the term canvas is sometimes used to refer to the 2D
    canvas context and sometimes used to refer to the immediate mode rendering HTML5
    canvas element. When I refer to canvas in this book without mentioning the 2D
    context, I am referring to the HTML5 canvas element.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, I will introduce you to shaders and the GLSL shader language.
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to WebGL shaders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When OpenGL or WebGL interact with a GPU, they pass in data to tell the GPU
    the geometry and textures it needs to render. At this point, the GPU needs to
    know how it must render those textures and the geometry associated with them into
    a single 2D image that will be displayed on your computer monitor. **OpenGL Shader
    Language** (**GLSL**) is a language that is used with both OpenGL and WebGL to
    instruct the GPU on how to render a 2D image.
  prefs: []
  type: TYPE_NORMAL
- en: Technically, WebGL uses the GLSL ES shader language (sometimes referred to as
    ELSL), which is a subset of the GLSL language. GLSL ES is the shader language
    that's used with OpenGL ES, a mobile-friendly subset of OpenGL (the ES is for
    Embedded Systems). Because WebGL is based on OpenGL ES, it inherited the GLSL
    ES shader language. Note that whenever I refer to GLSL within the context of WebGL
    or WebAssembly, I am referring to GLSL ES.
  prefs: []
  type: TYPE_NORMAL
- en: The WebGL rendering pipeline requires us to write two types of shaders to render
    an image to the screen. These are the vertex shader, which renders the geometry
    on a per-vertex basis, and the fragment shader, which renders pixel candidates
    known as fragments. The GLSL looks a lot like the C language, so the code will
    look somewhat familiar if you work in C or C++.
  prefs: []
  type: TYPE_NORMAL
- en: 'This introduction to GLSL shaders will not go into a lot of detail. In a later
    chapter, I will discuss WebGL shaders more extensively. Right now, I only want
    to introduce the concept and show you a very simple 2D WebGL shader. I will go
    into a lot more detail in the chapter on 2D lighting. Here is an example of a
    simple vertex shader that is used to render quads for a 2D WebGL rendering engine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This very simple shader takes in the position of a vertex and moves it based
    on a positional uniform value that's passed into the shader through WebGL. This
    shader will run on every single vertex in our geometry. In a 2D game, all geometry
    would be rendered as a quad (that is, a rectangle). Using WebGL in this way allows
    us to make better use of the computer's GPU. Let me briefly discuss what is going
    on in the code of this vertex shader.
  prefs: []
  type: TYPE_NORMAL
- en: If you are new to game development, the concept of vertex and pixel shaders
    may feel a little foreign. They are not as mysterious as they may first seem.
    You may want to quickly read over the Wikipedia *Shader* article if you want a
    better understanding of what shaders are ([https://en.wikipedia.org/wiki/Shader](https://en.wikipedia.org/wiki/Shader)).
    If you are still feeling lost, feel free to ask me questions on Twitter (`@battagline`).
  prefs: []
  type: TYPE_NORMAL
- en: 'The first line of this shader sets the floating-point precision:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'All floating-point operations on a computer are approximations for real fractions.
    We can approximate 1/3 with a low precision using 0.333 and with higher precision
    with 0.33333333\. The precision line of the code indicates the precision of the
    floating-point values on the GPU. We can use one of three possible precisions:
    `highp`, `mediump`, or `lowp`. The higher the floating-point precision, the slower
    the GPU will execute the code, but the higher the accuracy of all the values of
    the computations. In general, I have kept this value at `mediump`, and that has
    worked well for me. If you have an application that demands performance over precision,
    you can change this to `lowp`. If you require high precision, be sure that you
    know the capabilities of the target GPUs. Not all GPUs support `highp`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The attribute variables are values that are passed in with the vertex arrays
    into the pipeline. In our code, these values include the texture coordinates associated
    with the vertex, as well as the 2D translation matrix associated with the vertex:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The uniform variable type is a type of variable that remains constant across
    all vertices and fragments. In this vertex shader, we are passing in one uniform
    vector, `u_translate`. Typically, you would not want to translate all your vertices
    by the same amount unless it is for a camera, but because we are only writing
    a WebGL program to draw a single sprite, using a `uniform` variable for `translate`
    will work fine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `varying` variables (sometimes known as interpolators) are values that
    are passed from the vertex shader into the fragment shader, with each fragment
    in the fragment shader getting an interpolated version of that value. In this
    code, the only `varying` variable is the texture coordinate for the vertex:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In mathematics, an interpolated value is a calculated intermediate value. For
    example, if we interpolate the halfway point between 0.2 and 1.2, we would get
    a value of 0.7\. That is, the starting value of 0.2, plus the average of (1.2
    - 0.2) / 2 = 0.5\. So, 0.2 + 0.5 = 0.7\. Values passed from the vertex shader
    to the fragment shader using the `varying` keyword will be interpolated based
    on the position of the fragments relative to the vertex.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the code executed in the vertex shader is inside of the `main` function.
    This code takes the position of the vertex and multiplies it by the translation
    matrix to get the world coordinates of the vertex so that it can place them into
    `gl_Position`. It then sets the texture coordinate that''s passed into the vertex
    shader directly into the varying variable so that it can pass it into the fragment
    shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: After the vertex shader has been run, all the fragments that vertex shader generated
    are run through the fragment shader, which interpolates all of the varying variables
    for each fragment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a simple example of a fragment shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Just like in our vertex shader, we start by setting our floating-point precision
    to `mediump`. The fragments have a `uniform sample2D` texture that defines the
    texture map that''s used to generate the 2D sprites in our game:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '`uniform` is a little like a global variable that is passed into the pipeline
    and applies to either every vertex or every fragment in the shader that uses it.
    The code that''s executed in the `main` function is also straightforward. It takes
    the interpolated texture coordinate from the `v_texcoord` varying variable and
    retrieves the color value from our sampled texture, and then uses that value to
    set the color of the `gl_FragColor` fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Drawing a simple 2D image to the screen using WebGL directly inside of JavaScript
    requires a lot more code. In the next section, we will write out the simplest
    version of a 2D sprite rendering WebGL app I can think of, which happens to be
    a new version of the 2D canvas app we wrote in the previous chapter. I think it
    is worthwhile to see the differences between the two methods of rendering 2D images
    to the HTML canvas. Knowing more about WebGL will also help us understand what
    is going on behind the scenes when we eventually use the SDL API in WebAssembly.
    I am going to try and keep the demonstration and code as simple as I possibly
    can while creating the WebGL JavaScript app.
  prefs: []
  type: TYPE_NORMAL
- en: As I mentioned previously, the point of this chapter is for you to get some
    hands-on experience with WebGL. For most of this book, we will not directly deal
    with WebGL, but rather use the simpler SDL API. If you are not interested in writing
    your own shaders, you can consider this chapter optional but beneficial information.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will learn how to draw to the canvas with WebGL.
  prefs: []
  type: TYPE_NORMAL
- en: WebGL and JavaScript
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we learned in the previous chapter, working with the 2D canvas was pretty
    straightforward. To draw an image, you just need to translate the context to the
    pixel coordinates where you want to draw the image, and call the `drawImage` context
    function by passing in the image, its width, and its height. You could make this
    even simpler and forget about the translation passing the x and y coordinates
    directly into the `drawImage` function if you prefer. With the 2D canvas, you
    are working with images, but with WebGL, you are always working with 3D geometry,
    even when you are coding a 2D game. With WebGL, you will need to render textures
    onto geometry. You need to work with vertex buffers and texture coordinates. The
    vertex shader we wrote earlier takes 3D coordinate data and texture coordinates
    and passes those values onto a fragment shader that will interpolate between the
    geometry, and use a texture sampling function to retrieve the proper texture data
    to render pixels to the canvas.
  prefs: []
  type: TYPE_NORMAL
- en: WebGL coordinate system versus 2D canvas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With WebGL, the center of the canvas element is the origin point (0,0). **Positive
    Y** is up, whereas **Positive X** is to the right. This is a bit more intuitive
    for someone who has never worked with 2D graphics, as it is similar to quadrants
    in coordinate geometry, which we learned about in grade school. With the 2D canvas,
    you are always working with pixels, and there are no negative numbers that appear
    on the canvas:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4eec22e0-cd90-4ea2-9e50-e58c4ba7f9b3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'When you called `drawImage`, the X and Y coordinates were where the top left
    corner of the image would draw. WebGL is a bit different. Everything is using
    geometry, and both a vertex and a pixel shader are required. We convert the image
    into a texture and then stretch it over the geometry so that it''s displayed.
    Here is what the WebGL coordinate system looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9e188d87-56e7-4899-baff-52a2cd299f30.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If you want to place an image at a specific pixel location on the canvas, you
    have to know the width and height of your canvas. The **center point** of your
    canvas is **(0,0)**, the **Top left corner** is **(-1, 1)**, and the **Bottom
    right corner** is **(1, -1)**. So, if you want to place an image at x=150, y=160
    you need to use the following equation to find the WebGL x coordinate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'So, for a `pixel_x` position of 150, we have to subtract 400 from 150 to get
    -250\. Then, we have to divide -250 by 400, and we would get -0.625\. We have
    to do something similar to get the y coordinate for WebGL, but the sign of the
    axes are flipped, so instead of what we did for the `pixel_x` value, we need to
    do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: By plugging in the values, we get ((600 / 2) - 160) / (600 / 2) or (300 - 160)
    / 300 = 0.47.
  prefs: []
  type: TYPE_NORMAL
- en: 'I am skipping a lot of information about WebGL to simplify this explanation.
    WebGL is not a 2D space, even though I am treating it as a 2D space in this example.
    Because it is a 3D space, the size of the canvas in units is based on a view area
    known as clip space. Mozilla has an excellent article on clip space if you would
    like to learn more: [https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API/WebGL_model_view_projection](https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API/WebGL_model_view_projection).'
  prefs: []
  type: TYPE_NORMAL
- en: Vertex and UV data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we look at a large chunk of scary WebGL JavaScript code, I want to briefly
    discuss data buffers and how we are going to pass the geometry and texture coordinate
    data into the shaders. We will be passing in 32-bit floating point data in a large
    buffer that will contain a combination of the X and Y coordinates for the vertex
    and UV texture coordinates for that same vertex. UV mapping is the method by which
    your GPU maps 2D texture coordinates onto 3D geometry:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8f2d81e2-1594-408e-85bc-6a01b00b9973.png)'
  prefs: []
  type: TYPE_IMG
- en: WebGL and OpenGL accomplish this by assigning a U and V coordinate to every
    vertex. A UV coordinate of (0,0) assigned to a vertex means that the vertex will
    be colored based on the color in the texture in the top left corner. A UV coordinate
    of (1,1) would imply that it would be painted based on what color is in the texture
    on the bottom right. As we interpolate between the points in our 3D object, we
    also interpolate between the different UV coordinates inside of the texture. Those
    UV coordinates can be sampled in our fragment shader using the `texture2D` built-in
    function by passing in the texture and the current UV coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the vertex and texture data array that we are using inside
    of this WebGL app:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This data has been typed out in rows and columns. Even though this is a linear
    array of data, the formatting allows you to see that we have four floating-point
    values that will be passed in for each vertex. There is a comment above the data
    showing what each column represents. The first two data values are the X and Y
    coordinates of the geometry. The second two values are the U and V coordinates
    that map the texture to the X and Y coordinates in the geometry. There are six
    rows here, even though we are rendering a rectangle. The reason we need six points
    instead of just four is that the geometry used by WebGL typically consists of
    triangles. Because of this, we will need to repeat two of the vertices.
  prefs: []
  type: TYPE_NORMAL
- en: You may be wondering, *why triangles?* Well, there was a time when computer
    graphics used geometry that was not decomposed into triangles. But a problem arises
    when you have a quad, and not all the points are coplanar (in the same plane).
    This is the same problem I have whenever I go to a bar that uses four-legged stools.
    I am pretty sure the existence of the four-legged stool is some sort of Illuminati
    plot to keep me off balance, but I digress. Because three points define a plane,
    a triangle is, by definition, always coplanar, just like a three-legged stool
    will never wobble.
  prefs: []
  type: TYPE_NORMAL
- en: 2D canvas to WebGL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's begin by copying out canvas code from the `Chapter02` directory into the
    `Chapter03` directory. Next, we are going to rename the `canvas_shell.html` file
    to `webgl_shell.html`. We will rename `canvas.css` to `webgl.css`. Lastly, we
    will rename the `canvas.c` file `webgl.c`. We will also need to make sure that
    we copy over the `spaceship.png` file. We are not going to be changing the `webgl.css`
    file at all. We will make the most significant changes to the `webgl_shell.html`
    file. There is a lot of code that must be added to make the switch from 2D canvas
    to WebGL; almost all of it is additional JavaScript code. We will need to make
    some minor tweaks to `webgl.c` so that the ship's position in the `MoveShip` function
    reflects the WebGL coordinate system with its origin in the center of the canvas.
  prefs: []
  type: TYPE_NORMAL
- en: Before we begin, I would like to mention that this WebGL code is not meant to
    be production ready. The game we will be creating will not use WebGL in the way
    that I am demonstrating here. That is not the most efficient or scalable code.
    What we are writing will not be able to render more than one sprite at a time
    without significant changes. The reason I am walking you through what it takes
    to render 2D images using WebGL is to give you an idea of what is going on behind
    the scenes when you are using a library like SDL. If you do not care how things
    work behind the scenes, no one will fault you for skipping ahead. Personally,
    I always prefer knowing a little more.
  prefs: []
  type: TYPE_NORMAL
- en: Minor tweaks to the head tag
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Inside of our `head` tag, we will want to change `title`, and because we renamed
    `canvas.css` to `webgl.css`, we will need to point our `link` tag to the new stylesheet
    name. Here are the only two tags that must change at the beginning of the HTML:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Later in the HTML, we will remove the `img` tag where the `src` is set to `"spaceship.png"`.
    It is not strictly necessary to do this. In the canvas version, we were using
    this tag to render an image to the canvas. In this WebGL version, we will load
    the image dynamically, so it is not necessary to keep it around, but if you forget
    to remove it, having it there will not harm the app in any way.
  prefs: []
  type: TYPE_NORMAL
- en: Major JavaScript changes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `Module` code inside of the JavaScript portion of the `webgl_shell.html`
    file will remain the same, so you do not have to worry about modifying anything
    after the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: However, the top half of the code in the `script` tag is going to require some
    significant modifications. You may want to start fresh and delete the entire module.
  prefs: []
  type: TYPE_NORMAL
- en: WebGL global variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first thing we are going to do is create a lot of JavaScript global variables.
    If this code were meant for more than demonstration, using this many global variables
    is generally frowned upon and considered bad practice. But for what we are doing
    right now, it helps simplify things:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The first variable, `gl`, is the new version of the rendering context. Typically,
    if you are using a 2D rendering context, you call it `ctx`, and if you are using
    a WebGL rendering context, you name it `gl`. The second line defines the program
    variable. When we compile the vertex and fragment shaders, we get a compiled version
    in the form of a `WebGLProgram` object stored inside of this `program` variable.
    The `texture` variable will hold a `WebGLTexture` that we will be loading from
    the `spaceship.png` image file. That is the image that we used in the previous
    chapter for the 2D canvas tutorial. The `img` variable will be used to load the
    `spaceship.png` image file that will be used to load the texture. The canvas variable
    will once again be a reference to our HTML canvas element and `image_width`, and
    `image_height` will hold the height and width of the `spaceship.png` image once
    it is loaded.
  prefs: []
  type: TYPE_NORMAL
- en: The `vertex_texture_buffer` attribute is a buffer that will be used to transfer
    vertex geometry and texture data to the GPU so that the shader we wrote in the
    previous section can use it. The `a_texcoord_location` and `a_position_location`
    variables will be used to hold references to the `a_texcoord` and `a_position`
    attribute variables in the vertex shader, and finally, `u_translate_location`
    and `u_texture_location` are used to reference the `u_translate` and `u_texture`
    uniform variables in the shader.
  prefs: []
  type: TYPE_NORMAL
- en: The return of vertex and texture data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Would you be upset if I told you we had some more variables to discuss? Well,
    the next one is a variable we discussed earlier, but I will mention it again because
    it is important. The `vertex_texture_data` array is an array that stores all of
    the vertex geometry and UV texture coordinate data that are used for rendering:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: One thing I did not mention earlier is why the `x` and `y` values range from
    `-0.16` to `0.16` on the x-axis and `-0.213` to `0.213` on the y-axis. Because
    we are rendering a single image, we do not need to scale the geometry to fit the
    image dynamically. The spaceship image we are using is 128 x 128 pixels. The canvas
    size we are using is 800 x 600 pixels. As we discussed earlier, no matter what
    size we use for the canvas, WebGL fits both axes into a range from -1 to +1\.
    This makes the coordinate (0, 0) the center of the canvas element. It also means
    that the canvas width is always 2 and the canvas height is always 2, no matter
    how many pixels wide or high the canvas element is. So, if we want to figure out
    how wide we want our geometry to be to have it match the width of the image, we
    have to do some calculations. First, we need to figure out how many units of WebGL
    clip space width corresponds to one pixel. The WebGL clip space has a width of
    2.0, and the actual canvas has a width of 800 pixels, so the width of a single
    pixel in WebGL space is 2.0 / 800 = 0.0025\. We need to know how wide our image
    is in WebGL clip space, so we will multiply the 128 pixels by 0.0025 and get a
    WebGL clip space width of 0.32\. Because we would like to have the x value at
    the center of our geometry to be 0, we have our x geometry range from -0.16 to
    +0.16.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have done the width, let's tackle the height. The height of the
    canvas is 600 pixels, but in WebGL clip space, the height of the canvas is always
    2.0 (-1.0 Y to +1.0 Y). So, how many WebGL units are in a single pixel? 2.0 /
    600 = 0.00333333…repeating. Obviously, this is an instance where floating-point
    precision is unable to match a real-world value. We are going to lop off some
    of those trailing 3s and hope that the precision is enough. Going back to figuring
    out the height of the image in WebGL clip space, it is 128-pixels high, so we
    need to multiply 128 by 0.0033333…repeating. The result is 0.4266666…repeating,
    which we will truncate to 0.426\. So, our y geometry must go from `-0.213` to
    `+0.213`.
  prefs: []
  type: TYPE_NORMAL
- en: 'I am doing my best to ignore the complexity of the WebGL clip space. This is
    a 3D volume and not a simple 2D drawing area like the 2D canvas context. For more
    information on this topic, please consult the Mozilla developer docs for clip
    space: [https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API/WebGL_model_view_projection#Clip_space](https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API/WebGL_model_view_projection#Clip_space).'
  prefs: []
  type: TYPE_NORMAL
- en: As I said earlier, a lot of this will be managed for us by SDL when we work
    on our game, but in the future, you may wish to work with OpenGL in WebAssembly.
    The OpenGL ES 2.0 and OpenGL ES 3.0 libraries have been ported to WebAssembly,
    and those libraries more or less have direct analogs with WebGL. WebGL 1.0 is
    a modified version of OpenGL ES 2.0, which was a version of OpenGL that was designed
    to run on mobile hardware. WebGL 2.0 is a modified version of OpenGL ES 3.0\.
    Understanding what WebGL is doing through calls to SDL can make us better game
    developers, even if SDL is doing a lot of the heavy lifting for us.
  prefs: []
  type: TYPE_NORMAL
- en: Buffer constants
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I have chosen to use a single `Float32Array` to hold all of the vertex data
    for this application. That includes the X and Y coordinate data, as well as U
    and V texture coordinate data. Because of this, we are going to need to tell WebGL
    how to separate this data into different attributes when we load this data into
    the GPU''s buffer. We will use the following constants to tell WebGL how the data
    in `Float32Array` is broken out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The `FLOAT32_BYTE_SIZE` constant is the size of each variable in `Float32Array`.
    The `STRIDE` constant will be used to tell WebGL how many bytes are used for the
    data of a single vertex. The four columns we defined in the previous code represent
    *x*, *y*, *u*, and *v*. Since each one of those variables uses four bytes of data,
    we will multiply the number of variables by the number of bytes that are used
    by each variable to get the *stride*, or how many bytes are used by a single vertex.
    The `XY_OFFSET` constant is the starting location inside of each stride where
    we will find the *x* and *y* coordinate data. For consistency, I multiplied the
    floating-point byte size by the position, but since it is `0`, we could have just
    used `const XY_OFFSET = 0`. Now, `UV_OFFSET` is the offset in bytes from the beginning
    of each stride where we will find the UV texture coordinate data. Since those
    are in positions 2 and 3, the offset is the number of bytes that's used for each
    variable, multiplied by `2`.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the shaders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I walked through everything that''s being done by the shaders in the previous
    section. You may want to go through that section again as a refresher. The next
    part of the code defines the vertex shader code and the fragment shader code in
    multiline JavaScript strings. Here is the vertex shader code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The fragment shader code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s take a look at the attribute in the vertex shader code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Those two attributes will be passed in from the data in `Float32Array`. One
    of the neat tricks in WebGL is that if you are not using all four position variables
    (*x*,*y*,*z*,*w*), you can pass in the two you are using (*x*,*y*) and the GPU
    will know how to use appropriate values in the other two positions. These shaders
    will require passing in two attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Once again, we will be doing this using buffers and `Float32Array`. We will
    also need to pass in two `uniform` variables. The `u_translate` variable will
    be used by the vertex shader to translate the position of the sprite, and `u_texture`
    is a texture buffer that will be used by the fragment shader. These shaders are
    almost as simple as they get. Many tutorials start you out without a texture and
    just hardcode the color output of the fragment shader, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Making this change would cause the fragment shader to always output a red color,
    so please don't make this change. The only things I can think of that could have
    made this tutorial simpler are not loading the texture and rendering a solid color,
    and not allowing the geometry to be moved.
  prefs: []
  type: TYPE_NORMAL
- en: The ModuleLoaded function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the old 2D canvas code, we defined the `ShipPosition` JavaScript function
    before the `ModuleLoaded` function, but we have swapped these two functions for
    the WebGL demo. I felt it was better to explain the WebGL initialization before
    the rendering portion of the code. Here is the new version of the `ModuleLoaded`
    function in its entirety:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The first few lines get the `canvas` element and use that to get a WebGL context.
    If the JavaScript fails to get the WebGL context, we alert the user, letting them
    know they have a browser that does not support WebGL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The two lines after that turn on alpha blending:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Compiling, loading, and linking the vertex and the fragment shader is a lot
    of challenging code. I am not sure why there is no function inside of the WebGL
    library that does all of this in one step. Almost everyone writing webgl for 2D
    to do this, and they either put it into a separate `.js` file, or they copy and
    paste it into their code for every project. For now, all you need to know about
    the following batch of code is that it is taking the vertex and fragment shader
    we wrote earlier and compiling it into the program variable. From that point on,
    we will be using the program variable to interact with the shaders. Here is the
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have the `WebGLProgram` object in our `program` variable, we can
    use that object to interact with our shaders.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we are going to do is grab references to the `uniform` variables
    in our shader programs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, we will use the `program` object to get references to the attribute
    variables that are used by our vertex shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, it is time to start working with buffers. Do you remember when we created
    that `Float32Array` with all of our vertex data in it? It is time to use buffers
    to send that data to the GPU:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The first line creates a new buffer called `vertex_texture_buffer`. The line
    that starts with `gl.bindBuffer` binds `vertex_texture_buffer` to `ARRAY_BUFFER`,
    and then `bufferData` adds the data we had in `vertex_texture_data` to `ARRAY_BUFFER`.
    After that, we need to use the references to `a_position` and `a_texcoord` that
    we created earlier in the `a_position_location` and `a_texcoord_location` variables
    to tell WebGL where in this array buffer it will find the data for the `a_position`
    and `a_texcoord` attributes. The first thing it does is call `enableVertexAttribArray`
    to enable that attribute using the location variable we created. Next, `vertexAttribPointer`
    uses the `STRIDE` and `XY_OFFSET` or `UV_OFFSET` to tell WebGL where the attribute
    data is inside of the buffer data.
  prefs: []
  type: TYPE_NORMAL
- en: 'After that, we will create and bind a texture buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have a bound texture buffer, we can configure that buffer for mirror
    wrapping and nearest neighbor interpolation when scaling:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: We are using `gl.NEAREST` instead of `gl.LINEAR` because I would like the game
    to have an old-school pixelated look. In your game, you may prefer a different
    algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'After configuring the texture buffer, we are going to download the `spaceship.png`
    image and load that image data into the texture buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The final thing we will do is set the viewport to go from (0,0) to the canvas
    width and height. The viewport tells WebGL how the space in the canvas element
    will relate to our WebGL clip space:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The ShipPosition function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If this were production quality code, I would be doing a lot of the work that
    I am currently doing inside of the initialization routine in this rendering function.
    Moving sprites around independently on the canvas would require updates to our
    array buffers. I probably wouldn''t define my geometry in the way I did, that
    is, calculating the sizes by hand. I am not currently making any changes to the
    array buffer or the texture buffer; I am trying to keep this code to the bare
    minimum necessary to render a sprite onto the canvas using WebGL. Here is what
    I have:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The first few lines check to see whether the image download has completed.
    If not, we will exit out of this function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we tell WebGL to load the uniform `u_translate` uniform variable with
    our spaceship''s coordinates:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we instruct WebGL to draw triangles with the six vertices in our array
    buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: The MoveShip function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are going to need to jump back into the WebAssembly C module. The `webgl.c`
    file is a copied version of `canvas.c` where the only changes we need to make
    are inside of the `MoveShip` function. Here is the new version of `MoveShip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The changes are all conversions from pixel space into WebGL clip space. In
    the 2D canvas version, we were adding two pixels to the ship''s `x` coordinate
    and one pixel to the ship''s `y` coordinate every frame. But in WebGL, moving
    the `x` coordinate by two would be moving it by the entire width of the screen.
    So, instead, we have to modify these values into small units that would work with
    the WebGL coordinate system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Adding `0.002` to the `x` coordinate moves the ship by 1/500th of the width
    of the canvas each frame. Moving the `y` coordinate by `0.001` moves the ship
    on the y-axis by 1/1,000th of the height of the screen each frame. You may notice
    that in the 2D canvas version of this app, the ship was moving to the right and
    down. That was because increasing the `y` coordinate in the 2D canvas coordinate
    system moves an image down the screen. In the WebGL coordinate system, the ship
    moves up. The only other thing we have to do is change the coordinates at which
    the ship wrapped its `x` and `y` coordinates to WebGL clip space:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have all of our source code, go ahead and run `emcc` to compile
    our new `webgl.html` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you have `webgl.html` compiled, load it into a web browser. It should
    look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bb758221-c27c-49c3-9aef-70052e0c0fff.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.1: Screenshot of our WebGL app'
  prefs: []
  type: TYPE_NORMAL
- en: It is important to remember that the app must be run from a web server, or using
    `emrun`. If you do not run the app from a web server, or use `emrun`, you will
    receive a variety of errors when the JavaScript glue code attempts to download
    the WASM and data files. You should also know that IIS requires additional configuration
    in order to set the proper MIME types for the `.wasm` and `.data` file extensions.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have all of this working in WebGL, in the next chapter, I will talk
    about how much easier all of this would have been if we just did it using SDL
    in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have discussed WebGL and how it can improve performance
    in web games. I have introduced you to the concept of GLSL shaders and talked
    about vertex shaders and fragment shaders, what the differences between the two
    types of shaders are, and how they are used to render a combination of geometry
    and images to the HTML5 canvas.
  prefs: []
  type: TYPE_NORMAL
- en: We also recreated the moving spaceship that we created with the 2D canvas using
    WebGL. We have discussed how to use vertex geometry to render 2D images to a 3D
    canvas. We also talked about the differences between the pixel-based 2D canvas
    coordinate system and the 3D WebGL coordinate system.
  prefs: []
  type: TYPE_NORMAL
- en: WebGL is a broad topic to cover, so a single chapter can only give a very cursory
    introduction at best. WebGL is a 3D rendering space, and in this chapter, I went
    out of my way to ignore that and treat it like a 2D space. You could take what
    we have done here and build on it, but to improve the performance of our application,
    we will be using the WebAssembly SDL API for all of our interactions with WebGL
    in the future. If you would like to learn more about WebGL, Packt has a large
    selection of books devoted entirely to WebGL at [https://search.packtpub.com/?query=webgl](https://search.packtpub.com/?query=webgl).
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, I will teach you the basics of SDL, what it is, and how
    it works with WebAssembly. We will also learn how to render a sprite to the HTML5
    canvas using SDL, animate it, and move it around the canvas.
  prefs: []
  type: TYPE_NORMAL
