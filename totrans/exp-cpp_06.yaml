- en: Memory Management and Smart Pointers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Memory management comes at a price in C++. Concerned programmers often complain
    about C++ because of its manual memory management requirements. While languages
    like C# and Java use automatic memory management, it makes the programs run slower
    than their C++ counterparts. Manual memory management is often error-prone and
    unsafe. As we have already seen in the previous chapters, a program represents
    data and instructions. Almost every program uses computer memory to some extent.
    It's hard to imagine a useful program that doesn't require memory allocation.
  prefs: []
  type: TYPE_NORMAL
- en: Memory allocation and deallocation starts with the simplest call of a function.
    Calling a function usually implies passing arguments to it. The function needs
    space to store those arguments. To make life easier, it's handled automatically.
    The same automatic allocation happens when we declare objects in the code. Their
    lifetime depends on the scope they have declared. Whenever they go out of scope,
    they will be deallocated automatically. Most programming languages provide similar
    automatic deallocation functionality for dynamic memory. The dynamically allocated
    memory – as opposed to automatic allocation – is a term used by programmers to
    identify code portions that request new memory upon requirements. For example,
    this would be used in a program storing the list of customers' requests for new
    memory space upon the increase of the number of customers. To somehow differentiate
    between *types* of memory management, whether it's automatic or manual, programmers
    use memory segmentation. A program operates with several segments of memory, the
    stack, the heap, the read-only segment, and so on, although all of them have the
    same structure and are part of the same virtual memory.
  prefs: []
  type: TYPE_NORMAL
- en: Most languages provide simplified methods for accessing dynamic memory without
    being concerned with its deallocation strategies, leaving the hard work up to
    the runtime support environment. C++ programmers have to deal with the low-level
    details of memory management. Whether it's due to the philosophy, structure, or
    age of the language, C++ doesn't provide high-level memory management functionality.
    Therefore, a deep understanding of memory structure and its management is a must
    for every C++ programmer. Let's now illuminate the mystery behind memory and proper
    memory management techniques in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is memory and how do we access it in C++?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory allocation in detail
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory management techniques and idioms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Garbage collection basics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `g++` compiler with the option `-std=c++2a` is used to compile the examples
    throughout the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the source files used in this chapter at [https://github.com/PacktPublishing/Expert-CPP](https://github.com/PacktPublishing/Expert-CPP)
    .
  prefs: []
  type: TYPE_NORMAL
- en: Understanding computer memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At the lowest level of representation, the memory is a device that stores the
    state of a bit. Let''s say we are inventing a device that can store a single bit
    of information. Nowadays, it seems both meaningless and magical at the same time.
    It''s meaningless to invent something that has already been invented, a long time
    ago. It''s magical because programmers nowadays have the luxury of stable multifunctional
    environments providing tons of libraries, frameworks, and tools to create programs
    without even understanding them under the hood. It has become ridiculously easy
    to declare a variable or allocate a dynamic memory, as shown in the following
    code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: It's hard to describe how the device stores these variables. To somehow shed
    some light on that magical process, let's try to design a device that stores a
    bit of information.
  prefs: []
  type: TYPE_NORMAL
- en: Designing a memory storage device
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will use electrical circuits, relays, and logic gates to design a simple
    device able to store a bit. The purpose of this section is to understand the structure
    of the memory at its lowest level.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a simple illustration of an electric circuit that would be familiar
    to you from physics classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e049c87e-55a0-431d-96bf-28b605e4c07e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It consists of a **wire** connecting the battery to the **light bulb**. The
    **wire** has a **switch** that controls the state of the light bulb. The **light
    bulb** is on when the switch is closed, otherwise, it''s off. We will add to this
    circuit two NOR logical elements. The NOR is short for Not OR. It''s usually represented
    the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4072ad42-c9a2-495f-aee5-06d736ddb9c9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It has two inputs (the wires leading into the element), each of which represents
    an electrical signal. We say that the output (the wire coming out from the element)
    is 1 if both inputs are 0\. That''s why we call it *Not OR* because the OR element
    outputs 1 if any of its inputs are 1\. The preceding NOR element is simply constructed
    using two relays. A relay is a switch that uses an electromagnet to close and
    open the contacts. Look at the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/99bb5ce8-b8cc-4b27-b767-ec65c76b7ddc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'When both **switches** of **relays** are closed (meaning the **relays** are
    working and pulling down the **switches** of the circuit), the light bulb is *off*.
    When we move the **switch** to the open position of both **relays**, the light
    bulb turns *on*. The preceding diagram is one of the ways to depict a NOR gate.
    At this point, we can create a logic element using electric wires, light bulbs,
    batteries, and relays. Now let''s see a strange combination of two NOR elements
    leading to an interesting discovery:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/767e57ea-e066-4eef-b2eb-afc2868604c2.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding diagram is the typical representation of an **R-S flip-flop**.
    **R** is for *reset*, **S** is for *set*. The device built by the preceding scheme
    can store one bit. The output **Q** is the wire from which we can read the contents
    of the device. If we set the flip-flop to store the bit, the output will be 1\.
    You should carefully examine the diagram and imagine passing signals to its inputs
    one by one or both at the same time and see the output at **Q**. When the input
    **S** is 1, **Q** becomes 1\. When **R** is 1, **Q** becomes 0\. This way we *set*
    or *reset* the bit. It will store the bit as long as we supply current to the
    device.
  prefs: []
  type: TYPE_NORMAL
- en: Now imagine having a lot of devices as designed earlier interconnected together
    so that we will store more than one bit of information. This way, we can construct
    complex memory devices storing bytes or even **kilobytes** (**KB**), of data.
  prefs: []
  type: TYPE_NORMAL
- en: The preceding device is similar to those used in computers before the invention
    of transistors. A transistor is a much smaller device capable of storing bits.
    Transistors differ in types. Modern devices don't use relays; instead, they incorporate
    millions of transistors to store and manipulate data. A **Central Processing Unit**
    (**CPU**) register is an example of a device that leverages transistors to store
    a specified amount of bits. Usually, a general-purpose register stores up to 64
    bits of data. However, you can't store all your programs and data using only registers.
    The organization of computer memory is much more sophisticated. Let's now move
    on to examining the hierarchy of computer memory from a higher-level perspective.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding computer memory from a higher-level perspective
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Knowing the details of computer memory and data storage is crucial in writing
    professional programs. When programmers refer to the term *memory*, most of the
    time they mean the virtual memory. Virtual memory is an abstraction supported
    by the **Operating System** (**OS**) that controls and provides memory space for
    processes. Each process has its address space represented as a collection of several
    segments. We discussed what memory segments there are and how a given program
    uses each in [Chapter 2](06590f85-3b2c-4909-8bf0-a6a6f5d07c22.xhtml), *Low-Level
    Programming with C++*. From the programmer's perspective, accessing a memory space
    is mostly limited to an object declaration and use. Whether we declare an object
    on the stack, heap, or static memory, we access the same memory abstraction –
    the virtual memory. Although complicated, virtual memory makes life a lot easier.
    Working directly with physical memory is harder, although it is a great advancement
    in a programmer's skills. You should at least know what memory storage units there
    are and how you can leverage that knowledge to write better code.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have discussed the physical memory hierarchy. We call it
    a *hierarchy* because each memory unit at a lower level provides faster access
    but a smaller space. Each consecutively higher level of memory provides more space
    in exchange for slower access.
  prefs: []
  type: TYPE_NORMAL
- en: 'We discuss the physical memory hierarchy because it will help us design better
    code. Knowing how memory works at each level improves us as programmers and allows
    us to organize data manipulation better. The following diagram illustrates the
    memory hierarchy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3485e166-6d8d-4a59-8fe8-da8e249cd123.png)'
  prefs: []
  type: TYPE_IMG
- en: Registers are the fastest accessible memory units placed in the CPU. The number
    of registers is limited so we can't keep all the program data in them. On the
    other hand, **Dynamic RAM** (**DRAM**) is able to store a wide range of data for
    the program. It takes much longer to access data from the DRAM because of its
    physical structure and distance from the CPU. The CPU accesses DRAM via the data
    bus, which is a set of wires transferring data between the CPU and DRAM. To signal
    to the DRAM controller whether it will read or write data, the CPU uses the control
    bus. We will refer to DRAM as the *main memory*. Let's look at the memory hierarchy in
    detail.
  prefs: []
  type: TYPE_NORMAL
- en: Registers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Registers hold a fixed amount of data. The CPU word size is usually defined
    by the maximum length of a register, for example, eight bytes or four bytes. We
    can't directly access a register from a C++ program.
  prefs: []
  type: TYPE_NORMAL
- en: C++ supports embedding assembly code using the `asm` declaration, for example,
    `asm("mov edx, 4")`. It's a platform-specific and artificial augmentation to the
    code, so we don't suggest using it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In older versions of the language, we could use the `register` keyword when
    declaring a variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The modifier specified the compiler to store the variable in the register. This
    way, it gave programmers a fake sense of code optimization.
  prefs: []
  type: TYPE_NORMAL
- en: Compilers are sophisticated tools translating higher-level C++ code into machine
    code. In the translation process, the code takes several transformations, including
    code optimizations. When programmers apply *tricks* to force the compiler to optimize
    a portion of the code, the compiler takes them as suggestions rather than commands.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, accessing a variable in a loop will be faster if that variable
    is placed in a register rather than in the DRAM. For example, the following loop
    accesses objects one million times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'As we know, the `number` has an automatic storage duration (it has nothing
    to do with the `auto` keyword) and is placed on the stack. The stack is a segment
    in the virtual memory, and the virtual memory is an abstraction over the physical
    DRAM. It''s way faster to access the object in a register than in DRAM. Let''s
    suppose reading the value of `number` from the DRAM is five times slower than
    from a `register`. It might seem obvious to optimize the preceding loop using
    the `register` keyword, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: However, compilers make better optimizations nowadays, so the need for the modifier
    has faded over time and it is now a deprecated language feature. A better optimization
    would be getting rid of the `number` object altogether.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the following code represents the compile-optimized version that
    uses the actual value rather than accessing it via the variable that resides in
    the DRAM:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Although the preceding example is arguably simple, we should consider compiler
    optimizations that take place during compilation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Discovering the registers improves our understanding of program execution details.
    The point is that everything the CPU performs happens via the registers, including
    the instructions that the CPU should decode and execute are accessed using a specific
    register, commonly referred to as the **instruction pointer**. When we run the
    program, the CPU accesses its instructions and decodes and executes them. Reading
    data from the main memory and writing data to the memory is performed by copying
    it from and to the registers. Usually, general-purpose registers are used to temporarily
    hold data while the CPU performs operations on it. The following diagram depicts
    an abstract view of the **CPU** and its interaction with the main memory via buses:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b98cbe03-4c6c-4b6c-acb8-5079eee59237.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the communication between the CPU and DRAM happens via various
    buses. In [Chapter 2](06590f85-3b2c-4909-8bf0-a6a6f5d07c22.xhtml), *Low-Level
    Programming with C++*, we discussed the low-level representation of C++ programs
    – you should take a quick look at that to better understand the following example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s see registers in action. The following C++ code declares two variables
    and stores their sum in the third variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'To execute the sum instruction, the CPU moves values of variables `a` and `b`
    into its registers. After calculating the sum, it then moves the result into another
    register. An assembler pseudo-code representation of the program looks similar
    to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: It's not mandatory for the compiler to generate code that maps each variable
    to one register – the number of registers is limited. You just need to remember
    that you should keep regularly accessed variables small enough to fit into one
    of the registers. For larger objects, the cache memory comes to the rescue. Let's
    see how.
  prefs: []
  type: TYPE_NORMAL
- en: Cache memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The idea of caching is common in programming and computer systems. Images loaded
    in the browser are cached to avoid further requests to the web server to download
    it in case the user visits the website again in the future. Caching makes programs
    run faster. The concept can be leveraged in many forms, including in single functions.
    For example, the following recursive function calculates the factorial of a number:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The function doesn''t remember its previously calculated values, so the following
    calls lead to five and six recursive calls, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We can cache already calculated values at each step by storing them in a globally
    accessible variable, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The modifications optimize further calls to the function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The same way the concept of caching makes the factorial function run faster,
    an actual memory device named the **cache** is placed inside the CPU. This device
    stores recently accessed data in order to make further access to that data faster.
    The following diagram depicts **registers** and **cache memory** inside the CPU:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3ab977f8-8e12-4e36-b903-b72c9da9b7ff.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The cache size usually ranges from 2 KB to 64 KB (and, rarely, 128 KB). While
    it doesn''t seem big enough for applications such as Photoshop, where the image
    data size can be way bigger than the cache size itself, it really does help in
    many scenarios. For example, suppose we store more than 1,000 numbers in a vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code prints the vector items:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Suppose that to print the item, the **CPU** copies it from memory to the rax
    register, then calls the operator `<<`, which prints the value of the rax to the
    screen. On each iteration of the loop, the **CPU** copies the next item of the
    vector into the rax register and calls the function to print its value. Each copy
    operation requires the **CPU** to place the address of the item on the **address
    bus** and set the **control bus** to a read mode. The **DRAM** microcontroller
    accesses the data by the address received by the address bus and copies its value
    to the data bus, thereby sending the data to the **CPU**. The **CPU** directs
    the value to the rax register and then executes instructions to print its value.
    The following diagram shows this interaction between the **CPU** and **DRAM**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/38e99ee6-c6b8-4007-8a8b-3705975066fd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To optimize the loop, the CPU maintains an idea of data locality, that is, it
    copies the whole vector into the cache and accesses vector items from the cache,
    omitting the unnecessary requests to DRAM. In the following diagram, you can see
    that the data received from the DRAM via the data bus is then stored in the **cache
    memory**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a638de34-c3d8-4c57-9edc-078fb8563b94.png)'
  prefs: []
  type: TYPE_IMG
- en: The cache residing in the CPU is known as **level 1** (**L1**) **cache**. This
    is the smallest in capacity and resides inside the CPU. Many architectures have
    **level 2** (**L2**) **cache**, which resides outside the CPU (though closer than
    the main memory) and is accessed the same way as the DRAM. The difference between
    the L2 Cache and DRAM is the physical structure and data access patterns. The
    L2 Cache represents **Static RAM** (**SRAM**), which is faster than DRAM but also
    is much more expensive.
  prefs: []
  type: TYPE_NORMAL
- en: Some runtime environments leverage the idea of caching when implementing garbage
    collection. They separate the objects into categories based on their lifetime
    with objects that have the smallest lifetime, such as the ones allocated in the
    local scope of the code, being placed in the cache both to be accessed and deallocated
    faster.
  prefs: []
  type: TYPE_NORMAL
- en: New levels of cache memories serve as caches for the lower level. For example,
    the L2 Cache serves as a cache memory for the L1 Cache. When the CPU encounters
    a cache miss, it requests the L2 Cache, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Main memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The physical structure of the DRAM forces it to refresh its charge to keep the
    data stable, while the SRAM doesn't need to be refreshed like DRAM. We call DRAM
    the main memory mostly because programs are loaded into it; the OS maintains virtual
    memory and maps it to DRAM. All the actual work happens through the main memory
    first.
  prefs: []
  type: TYPE_NORMAL
- en: As we already discussed, the main memory represents a sequence of addressable
    bytes of data. Each byte has its own unique address and is accessed using that
    address. We mentioned earlier how the CPU places the address of the data on the
    address bus, thereby letting the DRAM microcontroller fetch the requested data
    and send it via the data bus.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we know, the OS introduces virtual memory as an abstraction over the physical
    memory. It maps the contents of the virtual memory to the physical memory, which
    involves the CPU''s **Translation Lookaside Buffer** (**TLB**). The TLB is another
    form of cache memory: it stores the recent translations of **virtual memory**
    to **physical memory**, thereby caching it for future requests. As shown in the
    following diagram, the **CPU** coordinates with the **TLB** in order to properly
    translate virtual addresses to physical addresses:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/38b916ec-a8a1-40f4-aa32-f99bc44eaebf.png)'
  prefs: []
  type: TYPE_IMG
- en: Though memory management is sophisticated, the OS provides us a simple enough
    abstraction to manage memory required for our programs. We have the ability to
    allocate it either automatically using the stack, or dynamically on the heap.
    The automatic memory allocation actually doesn't involve many concerns and difficulties;
    we just declare objects and they are placed on the stack and then automatically
    removed whenever the execution leaves the scope. In the case of dynamic memory
    (not to be confused with the hardware DRAM mentioned earlier), both the allocation
    and deallocation should be done manually, which creates possibilities for making
    errors leading to memory leaks.
  prefs: []
  type: TYPE_NORMAL
- en: Permanent storage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we turn off the computer, the contents of the main memory are erased (because
    the charge is not refreshed anymore). To store the data permanently even when
    the power is off, computers are equipped with a **Hard Disk Drive** (**HDD**)
    or a **Solid-State Drive** (**SSD**). From the perspective of programmers, permanent
    storage is used to store programs with their necessary data. We already know that
    in order to run a program, it should be loaded into the main memory, that is, copied
    from the HDD to the DRAM. The OS handles it using the loader and creates a program
    image in memory, commonly referred to as a process. When the program is done or
    the user closes it, the OS marks the address range of the process as free to use.
  prefs: []
  type: TYPE_NORMAL
- en: Let's suppose we use a text editor to write notes while learning C++. The text
    typed into the editor resides in the main memory unless we save it on the HDD.
    This is important to note because most programs keep track of recent user activity
    and also allow the user to modify program settings. To keep these settings the
    way the user modified them even after the program is relaunched, the program stores
    them as a separate *settings* file on the HDD. The next time the program runs,
    it first reads the corresponding settings file or files from the HDD and updates
    itself to apply the recent modifications of settings.
  prefs: []
  type: TYPE_NORMAL
- en: Usually, permanent storage has a much bigger capacity compared to the main memory,
    which makes it possible to use the HDD as a backup for virtual memory. The OS
    can maintain the virtual memory and fake its size, making it bigger than the physical
    DRAM. For example, the DRAM's two GB maximum capacity could be quickly exhausted
    by launching several heavyweight applications. However, the OS still can maintain
    a larger virtual memory by backing up its additional space with the HDD. When
    the user switches between applications, the OS copies the exceeding bytes of virtual
    memory to the HDD and maps the currently running application to the physical memory.
  prefs: []
  type: TYPE_NORMAL
- en: This makes programs and the OS run slower but allows us to keep them open without
    caring about the limited size of the main memory. Let's now dive a little deeper
    into memory management in C++.
  prefs: []
  type: TYPE_NORMAL
- en: The basics of memory management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Most of the time, issues arising during memory management happen when programmers
    forget about deallocating memory space. This results in memory leaks. A memory
    leak is a widespread issue in almost every program. When the program requests
    a new memory space for its data, the OS marks the provided space as **busy**.
    That is, no other instruction of the program or any other program can request
    that busy memory space. When the portion of the program is done with the memory
    space, ideally, it must notify the OS to remove the busy label to make the space
    available for others. Some languages provide automatic control over dynamically
    allocated memory, leaving the programmer to worry about the logic of the application
    rather than constantly being concerned with deallocating memory resources. However,
    C++ assumes that the programmer is responsible and smart (which is not always
    the case). Dynamically allocated memory management is the programmer''s responsibility.
    That''s why the language provides both "new" and "delete" operators to deal with
    memory space, where the new operator allocates memory space and the delete operator
    deallocates it. In other words, the ideal code dealing with dynamically allocated
    memory looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Forgetting to call the delete operator makes the allocated memory space *busy
    forever*. By *forever*, we mean as long as the program is running. Now imagine
    a web browser that is always open on the user computer. Memory leaks here and
    there might lead to memory starvation over time, and sooner or later the user
    has to restart the program or, even worse, the OS.
  prefs: []
  type: TYPE_NORMAL
- en: This issue is applicable to any resource that we work with, whether it's a file
    or a socket we forget to close (more about sockets in [Chapter 12](e28727f2-afc0-4e0c-9375-4031720a5d48.xhtml),
    *Networking and Security*). To solve this issue, C++ programmers use the **Resource
    Acquisition Is Initialization** (**RAII**) idiom, stating that a resource should
    be acquired on its initialization, which allows it to be properly released later.
    Let's see it in action.
  prefs: []
  type: TYPE_NORMAL
- en: An example of memory management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Consider the following function that dynamically allocates an array of 420
    `shorts`, reads their values from the user input, prints them in ascending order,
    and deallocates the array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We already made a mistake in the preceding code by using the wrong `delete`
    operator to deallocate the memory. To deallocate an array, we must use the `delete[]`
    operator, otherwise, the code leads to memory leaks. Here''s how we illustrate
    the allocation of the array:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/073fb3c2-f36b-4002-bfc3-fecbeb34ecdf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s say we release the space using `delete` instead of `delete[]`. It will
    treat the `arr` as a short pointer, and therefore will remove the first two bytes
    starting at the address contained in the `arr` pointer, as shown in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/50d84dee-769a-47cc-b579-5967570ec8ed.png)'
  prefs: []
  type: TYPE_IMG
- en: So now we removed the first item out of 420 items and left the 419 `shorts`
    untouched on the heap. Whenever we need new space on the heap, that small section
    containing the 419 **untouchables** won't be ever reused again. Though the family
    of new and delete operators is implementation-defined, we shouldn't really hope
    for the best implementation that avoids memory leaks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s modify the preceding code to properly release the allocated memory for
    the array and let''s make sure we eliminate the possibility of inputting negative
    numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding modifications are another example of a possible memory leak,
    though we clearly wrote ugly code for the sake of simplicity. The point is, whenever
    the user inputs a negative number, the function returns. This leaves us with 420
    orphan `shorts` that should be released somehow. However, the only access to the
    allocated memory was the `arr` pointer, which is declared on the stack, therefore
    it will be automatically deleted (the pointer variable, not the memory space pointed
    to it) when the function returns. To eliminate the possibility of a memory leak,
    we should simply call the `delete[]` operator before the function exits:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The code gets somewhat ugly but it fixes the memory leak. What if we modify
    the function further and use a third-party library function to sort the array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Turns out that the `strange_sort::sort` throws an exception when the value
    of the array item exceeds 420 (that''s why it''s a strange sort, after all). If
    the exception is left uncaught, it will bubble up to the caller function unless
    it is caught somewhere or the program crashes. The uncaught exception leads to
    stack unwinding, which leads to automatic destruction of the `arr` variable (the
    pointer), so we face another possibility of a memory leak. To fix it, we could
    wrap the `strange_sort::sort` in a try-catch block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: C++ programmers constantly seek ways to deal with memory leaks, such as the
    RAII idiom and smart pointers, which we will discuss in the next sections.
  prefs: []
  type: TYPE_NORMAL
- en: Using smart pointers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are many languages supporting automated garbage collection. For example,
    memory acquired for an object is tracked by the runtime environment. It will deallocate
    the memory space after the object with a reference to it goes out of the scope.
    Consider the following, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code block, the `p` reference (usually, references in garbage-collected
    languages are similar to pointers in C++) refers to the memory location returned
    by the `new` operator. The automatic garbage collector manages the lifetime of
    the object created by the `new` operator. It also tracks references to that object.
    Whenever the object has no references on it, the garbage collector deallocates
    its space. Something similar to that might be achieved by using the RAII idiom
    in C++. Let's see it in action.
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging the RAII idiom
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As already mentioned, the RAII idiom suggests acquiring the resource on its
    initialization. Look at the following class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The `print_sorted` function can now use the `ArrayManager` to properly release
    the allocated array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We suggest using standard containers such as `std::vector` rather than `ArrayManager`,
    though it''s a good example of the RAII application: acquiring the resource on
    initialization. We created an instance of `ArrayManager` and initialized it with
    the memory resource. From that point, we can forget about its release because
    the actual release happens in the destructor of `ArrayManager`. And as we declared
    the `ArrayManager` instance on the stack, it will be automatically destroyed when
    the function returns or an uncaught exception occurs, and the destructor will
    be called.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using a standard container is preferred in this scenario, so let''s implement
    the RAII idiom for single pointers. The following code dynamically allocates memory
    for a `Product` instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'If we apply the RAII idiom to the preceding code, it will release the resource
    at the proper point of code execution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The `ResourceManager` class should also overload operators `*` and `->` because
    it has to behave like a pointer in order to properly acquire and manage a pointer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The `ResourceManager` class cares about the idea of the smart pointer in C++.
    C++11 introduced several types of smart pointers. We name them *smart* because
    they wrap around the resource and manage its automatic deallocation. It happens
    solely because of the fact that the destructor of an object will be called when
    the object is set to destroy. That said, we operate with the dynamically allocated
    space through the object with an automatic storage duration. When the handler
    object goes out of scope, its destructor executes the necessary actions to deallocate
    the underlying resource.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, smart pointers might bring additional issues. The simple smart pointer
    discussed in the preceding paragraph has several issues that would arise eventually.
    For example, we didn''t take care of the `ResourceManager` copying:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code leads to undefined behavior. The following diagram shows
    the disguised problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8a9ce9cc-43a7-4a58-a6f1-53b386cae052.png)'
  prefs: []
  type: TYPE_IMG
- en: Both **res** and **apple** acquire the same resource. Whenever one of them goes
    out of scope (**apple**), the underlying resource is released, which leaves the
    other `ResourceManager` instance with a dangling pointer. When the other `ResourceManager` instance goes
    out of scope, it will try to delete the pointer twice. Usually, programmers are
    aware of the *kind* of smart pointer they need in a specific case. That's why
    C++ provides several types of smart pointers that, which we will discuss further.
    To use them in your programs, you should import the `<memory>` header.
  prefs: []
  type: TYPE_NORMAL
- en: std::unique_ptr
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Similar to the `ResourceManager` instance we implemented earlier, `std::unique_ptr`
    represents a basic smart pointer. For example, to manage the `Product` object
    using this smart pointer, we do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Note how we access the `Product` member function `set_name`. We treat the `res`
    object as something that has the type `Pointer*`.
  prefs: []
  type: TYPE_NORMAL
- en: '`unique_ptr` is named unique because it provides a semantics of strict ownership—
    it is obligated to destroy the acquired object. More interestingly, `unique_ptr`
    can''t be copied. It doesn''t have a copy constructor or assignment operator.
    That''s why its **ownership** is *strict*. Of course, that doesn''t mean that
    we can''t move a `unique_ptr` class. In that case, we completely pass the ownership
    to the other instance of the unique pointer.'
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the main requirements for smart pointers is keeping them lightweight.
    We can surely agree on that. While `unique_ptr` is a full class with several member
    functions, it doesn''t *pollute* with additional data members. It''s just a wrapper
    around the raw pointer to the allocated object. We can access that raw pointer
    by calling the `release()` member function of `unique_ptr`, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the `release()` function doesn''t call the delete operator. It only
    gives back ownership. After calling the `release()` function, the `unique_ptr` no
    longer owns the resource. To reuse a `unique_ptr` that already owns a resource,
    you should use the `reset()` member function. It calls the delete operator for
    the underlying pointer and *resets* the unique pointer for further use. On the
    other hand, if you want to get the underlying object without releasing the ownership,
    you should call the `get()` member function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We can''t use a `unique_ptr` class in the following scenario because it can''t
    be copied:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: However, it's not what we look for in the preceding code. You can consider the
    preceding code a bad design, because it confuses the ownership details. Let's
    move on to the next smart pointer in C++ that, which solves the issue of passing
    `unique_ptr` to functions.
  prefs: []
  type: TYPE_NORMAL
- en: std::shared_ptr and std::weak_ptr
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We need a smart pointer providing *shared ownership*. What we need was introduced
    back in C++11 as `std::shared_ptr`. It''s harder to implement a smart pointer
    with shared ownership, because you should take care of the correct deallocation
    of the resource. For example, when the `print_name()` function in the preceding
    code block finishes its work, its arguments and local objects will be destroyed.
    Destroying a smart pointer leads to the proper deallocation of the resource it
    owns. How would the smart pointer know if that resource is still owned by another
    smart pointer? One of the popular solutions is keeping the count of references
    to the resource. The `shared_ptr` class does the same: it keeps the number of
    pointers pointing to the underlying object and deletes it when the use count becomes
    0\. Therefore, several shared pointers can own the same object.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, the example we just discussed should be rewritten like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'After calling the `print_name()` function, the use count of the shared pointer
    increases by 1\. It will decrease by 1 when the function finishes its work but
    the managed object won''t be deallocated. It''s because the `res` object is not
    yet out of the scope. Let''s slightly modify the example to print the count of
    references to the shared object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will print the following to the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'When the last `shared_ptr` goes out of scope, it also destroys the underlying
    object. However, you should be careful when sharing an object between shared pointers.
    The following code shows an obvious issue with shared ownership:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Both `ptr1` and `ptr2` point to the same object, but they are not aware of each
    other. So when we modify the `Product` object via `ptr2`, it will affect `ptr1`.
    When `ptr2` goes out of scope (after the `if` statement), it will destroy the
    underlying object, which is still owned by `ptr1`. It happens because we make
    `ptr2` own the object by passing the raw `temp` pointer to it. `ptr1` can't track
    that.
  prefs: []
  type: TYPE_NORMAL
- en: The ownership can be shared only using the copy constructor or the assignment
    operator of `std::shared_ptr`. This way, we avoid deleting the object if it's
    in use by another `shared_ptr` instance. Shared pointers implement shared ownership
    using control blocks. Each shared pointer holds two pointers, one to the object
    it manages, and a pointer to the control block. The control block represents a
    dynamically allocated space containing the use count of the resource. It also
    contains several other things crucial for `shared_ptr`, for example, the `allocator`
    and the `deleter` of the resource. We will introduce allocators in the next section.
    The `deleter` usually is the regular `delete` operator.
  prefs: []
  type: TYPE_NORMAL
- en: The control block also contains the number of weak references. It's done because
    the owned resource might be pointed to a weak pointer, too. `std::weak_ptr` is
    the smaller brother of `std::shared_ptr`. It refers to an object managed by a `shared_ptr` instance,
    but doesn't own it. `weak_ptr` is a way to access and use the resource owned by
    `shared_ptr` without owning it. However, there is a way to convert a `weak_ptr` instance
    to `shared_ptr` using the `lock()` member function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Both `unique_ptr` and `shared_ptr` can be used for managing dynamically allocated
    arrays. The template parameter must be specified correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'To access an element of the underlying array, we use the `[]` operator of the
    shared pointer. Also, note that using a smart pointer won''t have drawbacks when
    used in dynamic polymorphism. For example, let''s suppose we have the following
    class hierarchy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code works as expected and outputs `Derived::test()` to the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Although the use of smart pointers might seem to spoil the beauty of pointers,
    it is suggested to intensively use smart pointers to avoid memory leaks. However,
    it's worth noting that replacing all pointers with smart pointers, whether it's
    a `unique_ptr` or a `shared_ptr` pointer, will not solve all the memory leak problems.
    They have their disadvantages, too. Consider a balanced approach, or better, thoroughly
    understand both the problem and the smart pointers themselves in detail before
    applying them to the problem.
  prefs: []
  type: TYPE_NORMAL
- en: Managing memory in C++ programs comes at a price. The most important thing that
    we've discussed is the proper deallocation of memory space. The language doesn't
    support automatic memory deallocation, but it's worth mentioning garbage collectors.
    However, to have a complete garbage collector, we need language-level support.
    C++ doesn't provide any of that. Let's try to imitate a garbage collector in C++.
  prefs: []
  type: TYPE_NORMAL
- en: Garbage collection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A garbage collector is a separate module usually incorporated in the runtime
    environments of interpretable languages. For example, C# and Java both have garbage
    collectors, which makes the life of programmers a lot easier. The garbage collector
    tracks all the object allocations in the code and deallocates once they are not
    in use anymore. It''s called a **garbage collector** because it deletes the memory
    resource after it''s been used: it collects the garbage left by programmers.'
  prefs: []
  type: TYPE_NORMAL
- en: It's said that C++ programmers don't leave garbage after them, that's why the
    language doesn't have support for a garbage collector. Though programmers tend
    to defend the language stating that it doesn't have a garbage collector because
    it's a fast language, the truth is that it can survive without one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Languages like C# compile the program into intermediate byte-code representation,
    which is then  interpreted and executed by the runtime environment. The garbage
    collector is a part of the environment and is actively tracking all object allocations.
    It is a sophisticated beast that tries its best to manage the memory in a reasonable
    time. The following diagram depicts a typical runtime environment that allocates
    memory supervised by the garbage collector:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2421ee02-8ebd-4784-8109-1c53318b8124.png)'
  prefs: []
  type: TYPE_IMG
- en: We manually call the `delete` operator to release the memory space in C++ even
    when using smart pointers. Smart pointers just acquire the object and delete the
    object when it goes out of scope. The key point is that even though smart pointers
    introduce some semi-automatic behavior, they still act as if the programmer didn't
    forget to release the resource at a specified point of the code. The garbage collector
    does that automatically and usually uses separate execution threads. It tries
    its best not to slow down the actual program execution speed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the garbage collection implementation techniques include classifying
    objects by their lifetime duration. Classification makes the garbage collector
    visit the objects and release the memory space if objects aren''t in use anymore.
    To make this process faster, objects with short lifetime duration should be visited
    more often than objects with longer duration. Take, for example, the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: If C++ had a garbage collector, then the objects `g1`, `g2`, and `g3` would
    be deleted in different time slots of the program execution. If the garbage collector
    classifies them by their lifetime duration, then `g2` would have the shortest
    lifetime and should be visited first in order to release it.
  prefs: []
  type: TYPE_NORMAL
- en: 'To really implement a garbage collector in C++, we should make it a part of
    the program. The garbage collector should first take care of allocating memory
    to track and remove it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding class keeps track of objects allocated through the static `allocate()` function. If
    the object is in use, it deletes it through the `deallocate()` function. Here''s
    how `GarbageCollector` can be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Actually, this class makes memory management a little bit harder than smart
    pointers. Basically, there is no need to implement a garbage collector in C++
    because smart pointers provide handling almost any scenario regarding *automatic*
    memory deallocation.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, let''s see one of the tricks that will allow the garbage collector
    to properly deallocate the space pointed to by some pointer. In our simplest possible
    preceding implementation, we kept track of all the pointers that we provided to
    users. Each pointer points to some space on the heap that should be freed at some
    point in the program execution. In `GarbageCollector`, we would use the standard
    `delete` operator. The question is, how does it know how many bytes should be
    freed? Take a look at the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Let's suppose that a `Student` instance takes 40 bytes of memory and an integer
    takes four bytes. We should somehow pass that information to the delete operator.
    In the preceding code, we delete both `ptr` and `ip`, each of which points to
    memory space of different sizes. So how does it know that 40 bytes should be marked
    as free in the case of `ptr` and four bytes should be marked as free in the case
    of `ip`? There is more than one solution to this problem, so let's look at one
    of them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Whenever we allocate memory, the new operator puts the size of the allocated
    space just before the actual memory space, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/10cfb979-45e6-41f9-9d2f-7fcb0fff9408.png)'
  prefs: []
  type: TYPE_IMG
- en: This information is then used by the `delete` operator, which reads the size
    of the memory space by reading the corresponding bytes placed before the memory
    space. One of the top concerns of C++ is managing memory for collections of data.
    STL containers, such as `std::vector` and `std::list`, described in [Chapter 6](92a352fd-cfe4-4d57-8005-ef618534ff74.xhtml),
    *Digging into Data Structures and Algorithms in STL*, have different models for
    working with memory. By default, a container has a specified memory allocator
    that handles the memory allocation and deallocation for container elements. Let's
    tackle an allocator in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Using allocators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The idea behind an allocator is to provide control to container memory management.
    In simpler words, an allocator is an advanced garbage collector for C++ containers.
    Although we discuss allocators in the scope of container memory management, you
    can surely expand the idea to a generic garbage collector. At the beginning of
    this section, we implemented a badly designed garbage collector. When examining
    allocators, you will find a lot of similarities between the poorly designed `GarbageCollector`
    class and the default allocator in C++. Defined in the `<memory>`, the default
    allocator has two basic functions – `allocate()` and `deallocate()`. The `allocate()`
    function is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: The `allocate()` function acquires space for `num` objects of type `T`. Pay
    attention to the `[[nodiscard]]` attribute – it means that the return value should
    not be discarded by the caller. The compiler will print a warning message otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use the allocator to acquire space for five integers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Note how we used `std::allocator_traits` to construct objects in the allocated
    space. The following illustration shows
  prefs: []
  type: TYPE_NORMAL
- en: 'The `deallocate()` function is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: In the previous code snippet, we used the `deallocate()` function by passing
    the pointer returned by the `allocate()` function.
  prefs: []
  type: TYPE_NORMAL
- en: You might not use allocators in your project directly, however, whenever you
    need a custom behavior for memory management, using existing or introducing new
    allocators can be helpful. STL containers use allocators mostly because they are
    different in structure and behavior, which leads to the need to have specialized
    behavior for memory allocation and deallocation. We will discuss STL containers
    in more detail in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Garbage collectors in languages like C# are provided by the environment. They
    work in parallel with the user program and try to clean up after the program whenever
    it seems efficient. We cannot do the same in C++; all we can achieve is the implementation
    of a garbage collector directly in the program, providing a semi-automatic way
    of freeing the used memory resource. This mechanism is properly covered by the
    smart pointers introduced in the language since C++11.
  prefs: []
  type: TYPE_NORMAL
- en: Memory management is one of the key components of every computer program. A
    program should be able to request memory dynamically during its execution. Good
    programmers understand the inner details of memory management. That helps them
    to design and implement more performant applications. While manual memory management
    is considered an advantage, it tends to become painful in larger applications.
    We have learned in this chapter how we can avoid errors and handle memory deallocation
    using smart pointers. Having this basic understanding, you should grow your confidence
    in designing programs that avoid memory leaks.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will learn about STL, focusing on data structures and
    algorithms, and will dive into their STL implementation. Besides comparing data
    structures and algorithms, we will introduce one of the notable new features in
    C++20: concepts.'
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Explain computer memory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is virtual memory?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which are the operators used for memory allocation and deallocation?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between `delete` and `delete[]`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a garbage collector and why doesn't C++ support one?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information, refer to the following links:'
  prefs: []
  type: TYPE_NORMAL
- en: What every programmer should know about memory, by Ulrich Drepper, at [https://people.freebsd.org/~lstewart/articles/cpumemory.pdf](https://people.freebsd.org/~lstewart/articles/cpumemory.pdf)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Code: The hidden language of computer hardware and software, by Charles Petzold,
    at [https://www.amazon.com/Code-Language-Computer-Hardware-Software/dp/0735611319/](https://www.amazon.com/Code-Language-Computer-Hardware-Software/dp/0735611319/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
