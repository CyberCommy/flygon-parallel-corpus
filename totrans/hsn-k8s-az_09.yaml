- en: 7\. Monitoring the AKS cluster and the application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you know how to deploy applications on an AKS cluster, let's focus
    on how you can ensure your cluster and applications remain available. In this
    chapter, you will learn how to monitor your cluster and the applications running
    on it. You'll explore how Kubernetes makes sure that your applications are running
    reliably using readiness and liveness probes.
  prefs: []
  type: TYPE_NORMAL
- en: You will also learn how **Azure Monitor** is used, and how it is integrated
    within the Azure portal, as well as how to set up alerts for critical events on
    your AKS cluster. You will see how you can use Azure Monitor to monitor the status
    of the cluster itself, the Pods on the cluster and get access to the logs of the
    Pods at scale.
  prefs: []
  type: TYPE_NORMAL
- en: 'In brief, the following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring and debugging applications using `kubectl`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reviewing metrics reported by Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reviewing metrics from Azure Monitor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's start the chapter by reviewing some of the commands in `kubectl` that
    you can use to monitor your applications.
  prefs: []
  type: TYPE_NORMAL
- en: Commands for monitoring applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Monitoring the health of applications deployed on Kubernetes as well as the
    Kubernetes infrastructure itself is essential to provide a reliable service to
    your customers. There are two primary use cases for monitoring:'
  prefs: []
  type: TYPE_NORMAL
- en: Ongoing monitoring to get alerts if something is not behaving as expected
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Troubleshooting and debugging applications errors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When monitoring an application running on top of a Kubernetes cluster, you''ll
    need to examine multiple things in parallel, including containers, Pods, Services,
    and the nodes in the cluster. For ongoing monitoring, you''ll need a monitoring
    system such as Azure Monitor or Prometheus. For troubleshooting, you''ll need
    to interact with the live cluster. The most common commands used for troubleshooting
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We'll describe each of these commands in detail in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we begin, we are going to have a clean start with our guestbook example.
    Recreate the guestbook example again using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: While the `create` command is running, we will watch its progress in the following
    sections.
  prefs: []
  type: TYPE_NORMAL
- en: The kubectl get command
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To see the overall picture of deployed applications, `kubectl` provides the
    `get` command. The `get` command lists the resources that you specify. Resources
    can be Pods, ReplicaSets, Ingresses, nodes, Deployments, Secrets, and so on. We
    have already run this command in the previous chapters to verify that our application
    was ready to be used. Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following `get` command, which will get us the resources and their
    statuses:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This will show you all the Deployments, ReplicaSets, Pods, and Services in
    your namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Output of the kubectl get all command showing the resources and their statuses,
    along with the Deployments, ReplicaSets, Pods, and Services in the namespace.](image/Figure_7.1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.1: All the resources running in the default namespace'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let''s focus our attention on the Pods in our Deployment. We can get the status
    of the Pods with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see that, now, only the Pods are shown, as seen in *Figure 7.2*. Let''s
    investigate this in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Retrieving the status of the pods in our deployment using the kubectl get
    pods command.](image/Figure_7.2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.2: All the Pods in your namespace'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The first column indicates the Pod name, for example, `frontend-57d8c9fb45-c6qtm`.
    The second column indicates how many containers in the Pod are ready against the
    total number of containers in the Pod. Readiness is defined via a readiness probe
    in Kubernetes. We have a dedicated section called *Readiness and liveness probes*
    later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The third column indicates the status, for example, `Pending`, or `ContainerCreating`,
    or `Running`, and so on. The fourth column indicates the number of restarts, while
    the fifth column indicates the age when the Pod was asked to be created.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you need more information about your Pod, you can add extra columns to the
    output of a `get` command by adding `-o wide` to the command like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This will show you additional information as shown in *Figure 7.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting additional information about the Pod with the kubectl get pods -o
    wide command.](image/Figure_7.3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.3: Adding -o wide shows more details on the Pods'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The extra columns include the IP address of the Pod, the node it is running
    on, the nominated node, and readiness gates. A nominated node is only set when
    a higher-priority Pod preempts a lower-priority Pod. The nominated node is the
    node where that higher-priority Pod will start once the lower-priority Pods gracefully
    terminate. A readiness gate is a way to introduce external system components as
    the readiness for a Pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'Executing a `get pods` command only shows the state of the current Pod. To
    see the events for all resources in the system, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Kubernetes maintains events for only 1 hour by default. All the commands work
    only if the event was fired within the past hour.
  prefs: []
  type: TYPE_NORMAL
- en: 'If everything goes well, you should have an output similar to *Figure 7.4*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Output of the kubectl get events command displaying a truncated list of the
    events from the past hour.](image/Figure_7.4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.4: Getting the events shows all events from the past hour'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see in the output, the general states for a Pod are `Scheduled` |
    `Pulling` | `Pulled` | `Created` | `Started`. As we will see next, things can
    fail at any of the states, and we need to use the `kubectl describe` command to
    dig deeper.
  prefs: []
  type: TYPE_NORMAL
- en: The kubectl describe command
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `kubectl get events` command lists all the events for the entire namespace.
    If you are interested in just Pods, you can use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The preceding command lists all the information pertaining to all Pods. This
    is typically too much information to contain in a typical shell.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want information on a particular Pod, you can type the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'You can either use a *slash* or a *space* in between `pod` and `podname`. The
    following two commands will have the same output:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kubectl describe pod/<pod-name>`'
  prefs: []
  type: TYPE_NORMAL
- en: '`kubectl describe pod <pod-name>`'
  prefs: []
  type: TYPE_NORMAL
- en: 'You will get an output similar to *Figure 7.5*, which will be explained in
    detail later:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Output of the kubectl describe pod/<pod-name> command displaying all the
    details of the specified pod.](image/Figure_7.5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.5: Describing an object shows the detailed output of that object'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: From the description, you can get the node on which the Pod is running, how
    long it has been running, its internal IP address, the Docker image name, the
    ports exposed, the `env` variables, and the events (from within the past hour).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding example, the Pod name is `frontend-57d8c9fb45-c6qtm`. As mentioned
    in *Chapter 1, Introduction to Docker and Kubernetes*, it has the `<ReplicaSet
    name>-<random 5 chars>` format. The `replicaset` name itself is randomly generated
    from the Deployment name front end: `<deployment name>-<random 5 chars>`.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7.6* shows the relationship between a Deployment, a ReplicaSet, and
    Pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical representation of the relationship between a Deployment, a ReplicaSet,
    and Pods.](image/Figure_7.6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.6: Relationship between a Deployment, a ReplicaSet, and Pods'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The namespace under which the Pod runs is `default`. So far, we have just been
    using the `default` namespace, appropriately named `default`. In the next chapters,
    we will see how namespaces help us to isolate Pods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another section that is important from the preceding output is the node section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The node section lets us know which physical node/VM the Pod is running on.
    If the Pod is repeatedly restarting or having issues running and everything else
    seems OK, there might be an issue with the node. Having this information is essential
    to perform advanced debugging.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the time the Pod was initially scheduled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This doesn't mean that the Pod has been running since that time, so the time
    can be misleading in that sense. If a health event occurs (for example, a container
    crashes), a Pod will be restarted.
  prefs: []
  type: TYPE_NORMAL
- en: 'Connections between resources are made using `Labels`, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This is how connections such as `Service` | `Deployment` | `ReplicaSet` | `Pod`
    are made. If you see that traffic is not being routed to a Pod from a Service,
    this is the first thing you should check. If the labels don't match, the resources
    won't attach.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following shows the internal IP of the Pod and its status:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: As mentioned in previous chapters, when building out your application, the Pods
    can be moved to different nodes and get a different IP. However, when debugging
    application issues, having a direct IP for a Pod can help in troubleshooting.
    Instead of connecting to your application through a Service object, you can connect
    directly from one Pod to another to test connectivity.
  prefs: []
  type: TYPE_NORMAL
- en: 'The containers running in the Pod and the ports that are exposed are listed
    in the following block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In this case, we are getting the `gb-frontend` container with the `v4` tag from
    the `gcr.io` container registry, and the repository name is `google-samples`.
  prefs: []
  type: TYPE_NORMAL
- en: Port `80` is exposed to outside traffic. Since each Pod has its own IP, the
    same port can be exposed for multiple instances of the same Pod even when running
    on the same host. For instance, if you were to have two Pods running a web server
    on the same node, those could both use port `80`, since each Pod has its own IP
    address. This is a huge management advantage as you don't have to worry about
    port collisions. The port that needs to be configured is also fixed so that scripts
    can be written simply without the logic of figuring out which port actually got
    allocated for the Pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'Any events that occurred in the previous hour show up here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Using `kubectl describe` is very useful to get more context about the resources
    you are running. In the next section, we'll focus on debugging applications.
  prefs: []
  type: TYPE_NORMAL
- en: Debugging applications
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that we have a basic understanding of how to monitor Deployments, we can
    start seeing how we can debug issues with Deployments.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will introduce common errors and determine how to debug
    and fix them.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have not implemented the guestbook application already, run the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: After a period of time, the Services should be up and running.
  prefs: []
  type: TYPE_NORMAL
- en: '**Image pull errors**'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we are going to introduce image pull errors by setting the
    image tag value to a non-existent one. An image pull error occurs when Kubernetes
    cannot download the image for the container it needs to run.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command on Azure Cloud Shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, change the image tag from `v4` to `v_non_existent` by executing the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Type `/gb-frontend` and hit the *Enter* button to have your cursor brought to
    the image definition.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hit the *I* key to go into insert mode. Delete `v4` and type `v_non_existent`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, close the editor by first hitting the *Esc* key, then type `:wq!` and hit
    *Enter*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Running the following command lists all the Pods in the current namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command should indicate errors, as shown in *Figure 7.7*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The output of the kubectl get pods command showing that three pods are running,
    while one.Pod throws an Image pull back off error.](image/Figure_7.7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.7: One of the Pods has the status of ImagePullBackOff'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Run the following command to get the full error details:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'A sample error output is shown in *Figure7.8*. The key error line is highlighted
    in red:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using the kubectl describe pods/<failed pod name> command to showing the
    error details for the pod that failed to pull the image. The image has two highlights,
    "Failed to pull image" and "v_non_existent not found".ils on the error'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Figure_7.8.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.8: Using describe shows more details on the error'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: So, the events clearly show that the image does not exist. Errors such as passing
    invalid credentials to private Docker repositories will also show up here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s fix the error by setting the image tag back to `v4`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, type the following command in Cloud Shell to edit the Deployment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Type `/gb-frontend` and hit `<enter>` to have your cursor brought to the image
    definition.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hit the *I* button to go into insert mode. Delete `v_non_existent`, and type
    `v4`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, close the editor by first hitting the *Esc* key, then type `:wq!` and hit
    *Enter*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Deployment should get automatically fixed. You can verify it by getting
    the events for the Pods again.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Because Kubernetes did a rolling update, the frontend was continuously available
    with zero downtime. Kubernetes recognized a problem with the new specification
    and stopped rolling out additional changes automatically.
  prefs: []
  type: TYPE_NORMAL
- en: Image pull errors can occur when images aren't available. In the next section,
    we'll explore an error within the application itself.
  prefs: []
  type: TYPE_NORMAL
- en: '**Application errors**'
  prefs: []
  type: TYPE_NORMAL
- en: We will now see how to debug an application error. The errors in this section
    will be self- induced, similar to in the last section. The method for debugging
    the issue is the same as the one we used to debug errors on running applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to test our failure, we''ll have to make the `frontend` Service publicly
    accessible:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To start, we''ll edit the `frontend` Service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Type `/ClusterIP` and hit *Enter* to bring your cursor to the type field (line
    27).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hit the *I* button to go into insert mode. Delete the `ClusterIP` and type `LoadBalancer`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, close the editor by first hitting the *Esc* key, then type `:wq!` and hit
    *Enter*. This will create a public IP for our frontend Service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can get this IP using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Let's connect to the Service, by pasting its public IP in a browser. Create
    a couple of entries:![The guestbook application with a couple of entries added.](image/Figure_7.9.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 7.9: Make a couple of entries in the guestbook application'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Most errors come from misconfiguration, where they can be fixed by editing the
    specification. Errors in the application code itself require a new image to be
    built and used.
  prefs: []
  type: TYPE_NORMAL
- en: You now have an instance of the guestbook application running. To improve the
    experience with the example, we will scale down the frontend so there is only
    a single replica running.
  prefs: []
  type: TYPE_NORMAL
- en: '**Scaling down the frontend**'
  prefs: []
  type: TYPE_NORMAL
- en: In *Chapter 3*, *Application deployment on AKS*, you learned how the deployment
    of the frontend has a configuration of `replicas=3`. This means that the requests
    the application receives can be handled by any of the Pods. To introduce the application
    error and note the errors, we would need to make changes in all three of them.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make this example easier, scale the `replicas` to `1` so that you have to
    make changes to only one Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Having only one replica running will make introducing the error easier. Let's
    now introduce this error.
  prefs: []
  type: TYPE_NORMAL
- en: '**Introducing an app error**'
  prefs: []
  type: TYPE_NORMAL
- en: In this case, we are going to make the **Submit** button fail to work. We need
    to modify the application code for this.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: It is not advised to make production changes to your application by using `kubectl
    exec` to execute commands in your Pods. If you need to make changes to your application,
    the preferable way is to create a new container image and update your Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the `kubectl exec` command. This command lets you run commands
    on the command line of that Pod. With the `-it` option, it attaches an interactive
    terminal to the Pod and gives us a shell that we can run our commands on. The
    following command launches a Bash terminal on the Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you are in the container shell, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code installs the vim editor so that we can edit the file to
    introduce an error. Now, use `vim` to open the `guestbook.php` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following line after line 18\. Remember, to insert a line in vim, you
    hit the *I* key. After you are done editing, you can exit by hitting *Esc*, and
    then type `:wq!` and then press *Enter*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The file will look like *Figure 7.10*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The guestbook.php file in the vim editor with the updated code.](image/Figure_7.10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.10: The updated code that introduced an error and additional logging'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We are introducing an error where reading messages would work, but not writing
    them. We do this by asking the frontend to connect to the Redis master at the
    non-existent localhost server. The writes should fail. At the same time, to make
    this demo more visual, we added some additional logging to this section of the
    code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open your guestbook application by browsing to its public IP, and you should
    see the entries from earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The guest book application re-opened that displays that the entries from
    earlier are still present.](image/Figure_7.11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.11: The entries from earlier are still present'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, create a new message by typing a message and hitting the **Submit** button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Add a "New message" entry to the guestbook application.](image/Figure_7.12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.12: A new message was created'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Submitting a new message makes it appear in our application. If we did not know
    any better, we would have thought the entry was written safely. However, if you
    refresh your browser, you will see that the message is no longer there.
  prefs: []
  type: TYPE_NORMAL
- en: If you have network debugging tools turned on in your browser, you can catch
    the error response from the server.
  prefs: []
  type: TYPE_NORMAL
- en: 'To verify that the message has not been written to the database, hit the **Refresh**
    button in your browser; you will see just the initial entries, and the new entry
    has disappeared:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The guestbook application showing just the initial entries after the refresh
    button is hit. The new message waslost.](image/Figure_7.13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.13: The new message has disappeared'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'As an app developer or operator, you''ll probably get a ticket like this: *After
    the new deployment, new entries are not persisted. Fix it.*'
  prefs: []
  type: TYPE_NORMAL
- en: Logs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The first step is to get the logs. Let''s exit out of our front-end Pod for
    now and get the logs for this Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see entries such as those seen in *Figure 7.14*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Output of the kubectl logs <frontend-pod-name> command displaying the logs
    for the pod. The image contains three highlighted areas: "hostname at the beginning
    of ''set'' command localhost," "cmd=set," and "new%20message".](image/Figure_7.14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.14: The new message shows up as part of the application logs'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Hence, you know that the error is somewhere when writing to the database in
    the `set` section of the code.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will see this entry:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: So we know that the error is between this line and the start of the client,
    so the setting of `$host = 'localhost'` must be the offending error. This error
    is not as uncommon as you would think and, as we just saw, could have easily gone
    through QA unless there had been a specific instruction to refresh the browser.
    It could have worked perfectly well for the developer, as they could have a running
    Redis server on the local machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two options to fix this bug we introduced now: we can either navigate
    into the Pod and make the code changes, or we can ask Kubernetes to give us a
    healthy new Pod. It is not recommended to make manual changes to Pods, so we will
    use the second approach. Let''s fix this bug by deleting our faulty Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: As we have a ReplicaSet that controls our Pods, we should immediately get a
    new Pod that has started from the correct image. Try to connect to the guestbook
    again and verify that messages are persisted across browser refreshes again.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following points summarize some of the common errors and methods to fix
    these errors:'
  prefs: []
  type: TYPE_NORMAL
- en: Errors can come in many shapes and forms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most of the errors encountered by the deployment team are configuration issues.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logs are your friends.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using `kubectl exec` on a container is a useful debugging tool.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that broadly allowing `kubectl exec` is a serious security risk, as it
    pretty much lets the Kubernetes operator do what they want in the Pods they have
    access to.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anything printed to `stdout` and `stderr` shows up in the logs (independent
    of the application/language/logging framework).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We introduced an application error to the guestbook application and were able
    to leverage Kubernetes logs to pinpoint the issue in the code. In the next section,
    we will look into a powerful mechanism in Kubernetes called *Readiness and liveness
    probes*.
  prefs: []
  type: TYPE_NORMAL
- en: Readiness and liveness probes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We touched upon readiness probes briefly in the previous section. In this section,
    we'll explore them in more depth.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes uses liveness and readiness probes to monitor the availability of
    your applications. Each probe serves a different purpose:'
  prefs: []
  type: TYPE_NORMAL
- en: A **liveness probe** monitors the availability of an application while it is
    running. If a liveness probe fails, Kubernetes will restart your Pod. This could
    be useful to catch deadlocks, infinite loops, or just a "stuck" application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **readiness probe** monitors when your application becomes available. If a
    readiness probe fails, Kubernetes will not send any traffic to unready Pods. This
    is useful if your application has to go through some configuration before it becomes
    available, or if your application could become overloaded but recover from the
    additional load.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liveness and readiness probes don't need to be served from the same endpoint
    in your application. If you have a smart application, that application could take
    itself out of rotation (meaning no more traffic is sent to the application) while
    still being healthy. To achieve this, it would have the readiness probe fail,
    but have the liveness probe remain active.
  prefs: []
  type: TYPE_NORMAL
- en: Let's build this out in an example. We will create two nginx Deployments, each
    with an index page and a health page. The index page will serve as the liveness
    probe.
  prefs: []
  type: TYPE_NORMAL
- en: Building two web containers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For this example, we''ll use a couple of web pages that we''ll use to connect
    to our readiness and liveness probes. Let''s first create `index1.html`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, create `index2.html`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s also create a health page, `healthy.html`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'In the next step, we''ll mount these files to our Kubernetes Deployments. We''ll
    turn each of these into a `configmap` that we connect to our Pods. Use the following
    commands to create the configmap:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'With that out of the way, we can go ahead and create our two web Deployments.
    Both will be very similar, with just the `configmap` changing. The first Deployment
    file (`webdeploy1.yaml`) looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'There are a few things to highlight in this Deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Lines 23-28**:This is the liveness probe. The liveness probe points to the
    health page. Remember, if the health page fails, the container will be restarted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines 29-32**: This is the readiness probe. The readiness probe in our case
    points to the index page. If this page fails, the Pod will temporarily not be
    sent any traffic but will remain running.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines 44-45**: These two lines contain a couple of commands that get executed
    when our container starts. Instead of simply running the nginx server, we copy
    the index and ready files in the right location, then start nginx, and then use
    a sleep command (so our container keeps running).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can create this Deployment using the following command. You can also deploy
    the second version for server 2, which is similar to server 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will also create a Service that routes traffic to both Deployments
    (`webservice.yaml`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'We can create that Service using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: We now have our application up and running. In the next section, we'll introduce
    some failures to verify the behavior of liveness and readiness probes.
  prefs: []
  type: TYPE_NORMAL
- en: Experimenting with liveness and readiness probes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the previous section, we explained the functionality of the liveness and
    readiness probes and created a sample application. In this section, we will introduce
    errors in our application and verify the behavior of the liveness and readiness
    probes. We will see how a failure of the readiness probe will cause the Pod to
    remain running but no longer accept traffic. After that, we will see how a failure
    of the liveness probe will cause the Pod to be restarted.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start by failing the readiness probe.
  prefs: []
  type: TYPE_NORMAL
- en: '**Failing the readiness probe causes traffic to temporarily stop**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have a simple application up and running, we can experiment with
    the behavior of the liveness and readiness probes. To start, let''s get our Service''s
    external IP to connect to our web server using the browser:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'If you hit the external IP in the browser, you should see a single line that
    either says **Server 1** or **Server 2**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The browser showing the external IP and that the application is returning
    traffic from server 2.](image/Figure_7.15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.15: Our application is returning traffic from server 2'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'During our tests, we''ll use a small script called `testWeb.sh` to connect
    to our web page 50 times, so we can monitor a good distribution of results between
    server 1 and 2\. We''ll first need to make that script executable, and then we
    can run that script while our Deployment is fully healthy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'During healthy operations, we can see that server 1 and server 2 are hit almost
    equally, with `24` hits for server 1, and `26` for server 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The output showing the hit instances for server 1 and server 2 as 24, 48,
    216 and 26, 52, 234 respectively.](image/Figure_7.16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.16: While the application is healthy, traffic is load-balanced between
    server 1 and server 2'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let''s now move ahead and fail the readiness probe in server 1\. To do this,
    we will `exec` into the container and move the index file to a different location:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Once this is executed, we can view the change in the Pod status with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the readiness state of the server 1 Pod change to `0/1`, as
    shown in *Figure 7.17*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Output of the kubectl get pods -w command showing the readiness state of
    the server 1 Pod changing to 0/1.](image/Figure_7.17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.17: The failing readiness probes causes server 1 to not have any READY
    containers'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This should direct no more traffic to the server 1 Pod. Let''s verify:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'In our case, traffic is indeed redirected to server 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Output showing that all the traffic is directed to server 2 and the traffic
    for server 1 is zero.](image/Figure_7.18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.18: All traffic is now served by server 2'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We can now restore the state of server 1 by moving the file back to its rightful
    place:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'This will return our Pod to a healthy state, and should again split traffic
    equally:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'This will show an output similar to *Figure 7.19*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Output showing the readiness probe causing traffic to be load-balanced again
    between server 1 and server 2.](image/Figure_7.19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.19: Restoring the readiness probe causes traffic to be load-balanced
    again'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: A failing readiness probe will cause Kubernetes to no longer send traffic to
    the failing Pod. We have verified this by causing a readiness probe in our example
    application to fail. In the next section, we'll explore the impact of a failing
    liveness probe.
  prefs: []
  type: TYPE_NORMAL
- en: '**A failing liveness probe causes container restart**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can repeat the previous process as well with the liveness probe. When the
    liveness probe fails, we are expecting Kubernetes to go ahead and restart our
    Pod. Let''s try this  by deleting the health file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see what this does with our Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'We should see that the Pod restarts within a couple of seconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using kubectl get pods -w to track the status of the pods. The image shows
    that server1 is restarted by incrementing the restarts counter from 0 to 1.](image/Figure_7.20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.20: A failing liveness probe will cause the Pod to be restarted'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'As you can see in *Figure 7.20*, the Pod was successfully restarted, with limited
    impact. We can inspect what was going on in the Pod by running a `describe` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command will give you an output similar to *Figure 7.21*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Output of the kubectl describe pod command provides additional details on
    the Pod and showing how the liveness probe failed.](image/Figure_7.21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.21: More details on the Pod showing how the liveness probe failed'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the `describe` command, we can clearly see that the Pod failed the liveness
    probe. After four failures, the container was killed and restarted.
  prefs: []
  type: TYPE_NORMAL
- en: 'This concludes our experiment with liveness and readiness probes. Remember
    that both are useful for your application: a readiness probe can be used to temporarily
    stop traffic to your Pod, so it has to suffer less load. A liveness probe is used
    to restart your Pod if there is an actual failure in your Pod.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s also make sure to clean up the Deployments we just created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Liveness and readiness probes are useful to ensure only healthy Pods will receive
    traffic in your cluster. In the next section, we will explore different metrics
    reported by Kubernetes that you can use to verify the state of your application.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics reported by Kubernetes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes reports multiple metrics. In this section, we'll first use a number
    of kubectl commands to get these metrics. Afterward, we'll look into Azure Monitor
    for containers to see how Azure helps with container monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: Node status and consumption
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The nodes in your Kubernetes are the servers running your application. Kubernetes
    will schedule Pods to different nodes in the cluster. You need to monitor the
    status of your nodes to ensure that the nodes themselves are healthy and that
    the nodes have enough resources to run new applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to get information about the nodes on the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command lists their name, status, and age:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Output for the kubectl get nodes command listing the name, status, and age
    of the nodes.](image/Figure_7.22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.22: There are two nodes in this cluster'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'You can get more information by passing the `-o` wide option:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The output lists the underlying `OS-IMAGE` and `INTERNAL-IP`, and other useful
    information, which can be viewed in *Figure 7.23*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Output of the kubectl get -o wide nodes command displaying additional information
    about the nodes such asinternal IP, external IP, Kernel version, and container
    runtime.](image/Figure_7.23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.23: Using -o wide adds more details about our nodes'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'You can find out which nodes are consuming the most resources by using the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'It shows the CPU and memory usage of the nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Output of the kubectl top nodes command displaying the CPU and memory utilization
    of the nodes.](image/Figure_7.24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.24: CPU and memory utilization of the nodes'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Note that this is the actual consumption at that point in time, not the number
    of requests a certain node has. To get the requests, you can execute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'This will show you the requests and limits per Pod, as well as the cumulative
    amount for the whole node:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Output showing the number of requests and limits a specific node has assigned
    to it.](image/Figure_7.25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.25: Describing the nodes shows details on requests and limits'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You now know where you can find information about the utilization of your nodes.
    In the next section, we will look into how you can get the same metrics for individual
    Pods.
  prefs: []
  type: TYPE_NORMAL
- en: Pod consumption
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Pods consume CPU and memory resources from an AKS cluster. Requests and limits
    are used to configure how much CPU and memory a Pod can consume. Requests are
    used to reserve a minimum amount of CPU and memory, while limits are used to set
    a maximum amount of CPU and memory per Pod.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will explore how we can use `kubectl` to get information
    about the CPU and memory utilization of Pods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by exploring how we can see the requests and limits for a Pod
    that we currently have running:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For this example, we will use the Pods running in the `kube-system` namespace.
    Get all the Pods in this namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'This should show something similar to *Figure 7.26*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using kubectl get pods -n kube-system to list of all the pods in the in the
    kube-system namespace with their name, status, number of restarts, and age.](image/Figure_7.26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.26: The Pods running in the kube-system namespace'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let''s get the requests and limits for one of the `coredns` Pods. This can
    be done using the `describe` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `describe` command, there should be a section similar to *Figure 7.27*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The describe command showing the limits and requests for the CoreDNS Pod.](image/Figure_7.27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.27: Limits and requests for the CoreDNS Pod'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This shows us that this Pod has a memory limit of `170Mi`, no CPU limit, and
    has a request for 100m CPU (which means 0.1 CPU) and `70Mi` of memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Requests and limits are used to perform capacity management in a cluster. We
    can also get the actual CPU and memory consumption of a Pod by running the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'This should show you the output similar to *Figure 7.28*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Output of the kubectl top pods -n kube-system command showing the CPU and
    memory consumption of Pods.](image/Figure_7.28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.28: Seeing the CPU and memory consumption of Pods'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Using the `kubectl top` command shows the CPU and memory consumption at the
    point in time when the command was run. In this case, we can see that the `coredns`
    Pods are using `2m` and `3m` CPU and are using `21Mi` and `17Mi` of memory.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have been using the `kubectl` command to get an insight
    into the resource utilization of the nodes and Pods in our cluster. This is useful
    information, but it is limited to that specific point in time. In the next section,
    we'll use Azure Monitor to get more detailed information on the cluster and the
    applications on top of the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics reported from Azure Monitor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Azure portal shows many of the metrics that you would like to see combined
    with authorization, as only personnel with access to the portal can see these
    metrics.
  prefs: []
  type: TYPE_NORMAL
- en: AKS Insights
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **Insights** section of the AKS blade provides most of the metrics you need
    to know about your cluster. It also has the ability to drill down to the container
    level. You can also see the logs of the container.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes makes metrics available but doesn't store them. Azure Monitor can
    be used to store these metrics and make them available to query over time. To
    collect the relevant metrics and logs into Insights, Azure connects to the Kubernetes
    API to collect the metrics and then stores them in Azure Monitor.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Logs of a container could contain sensitive information. Therefore, the rights
    to review logs should be controlled and audited.
  prefs: []
  type: TYPE_NORMAL
- en: Let's explore the **Insights** tab of the AKS blade. We'll start with the cluster
    metrics.
  prefs: []
  type: TYPE_NORMAL
- en: '**Cluster metrics**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Insights** shows the cluster metrics. *Figure 7.29* shows the CPU utilization
    and the memory utilization of all the nodes in the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Cluster tab in the Insights blade shows the cluster metrics. It displays
    two graphs: the CPU utilization and the memory utilization of all the nodes in
    the cluster.](image/Figure_7.29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.29: The Cluster tab shows CPU and memory utilization for the cluster'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The cluster metrics also show the node count and the number of active Pods.
    The node count is very important, as you can track whether you have any nodes
    that are in a **Not Ready** state:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Cluster tab displaying two additional graphs: the node count and the
    number of active Pods.](image/Figure_7.30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.30: The Cluster tab shows the node count and the number of active
    Pods'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The **Cluster** tab can be used to monitor the status of the nodes in the cluster.
    Next, we'll explore the **Health** tab.
  prefs: []
  type: TYPE_NORMAL
- en: '**Using the Health tab**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Health** tab was in preview at the time of writing this book. This tab
    shows you a view of your cluster health. To show you this status, Azure monitors
    and checks the required infrastructure components as well as node health:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A view of the Health tab showing the overall health of the cluster. All the
    health metrics are marked green for this cluster.](image/Figure_7.31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.31: The Health tab shows the overall health of the cluster'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The **Health** tab is useful for tracking the overall health of your cluster.
    The next tab we'll explore is the **Nodes** tab..
  prefs: []
  type: TYPE_NORMAL
- en: '**Nodes**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Nodes** view shows you detailed metrics for your nodes. It also shows
    you which Pods are running on each node, as we can see in *Figure 7.32*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Nodes view pane showing the detailed metrics for the pods running on
    each of the nodes.](image/Figure_7.32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.32: Detailed metrics of the nodes in the Nodes view pane'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'If you want even more details, you can click through and get Kubernetes event
    logs from your nodes as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The View Kubernetes event logs option in the right-hand pane allowing to
    get the logs from a cluster.](image/Figure_7.33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.33: Click on View Kubernetes event logs to get the logs from a cluster'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This will open Azure Log Analytics and will have pre-created a query for you
    that shows the logs for your node. In our case, we can see that our nodes have
    been rebooted a couple of times:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Log Analytics showing the logs for the nodes.](image/Figure_7.34.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.34: Log Analytics showing the logs for the nodes'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Controllers**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Controllers** view shows you details on all the controllers (that is,
    ReplicaSet, DaemonSet, and so on) on your cluster and the Pods running in them.
    This shows you a controller-centric view of running containers. For instance,
    you can find the frontend ReplicaSet and see all the Pods and containers running
    in it, as shown in *Figure 7.35*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![All the containers running in a ReplicaSet with their name and status, displayed
    in the Controller tab.](image/Figure_7.35.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.35: The Controller tab shows us all the containers running in a ReplicaSet'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The next tab is the **Containers** tab, which will show us the metrics, logs,
    and environment variables for a container.
  prefs: []
  type: TYPE_NORMAL
- en: '**Container metrics, logs, and environment variables**'
  prefs: []
  type: TYPE_NORMAL
- en: Clicking on the **Containers** tab lists the container metrics, environment
    variables, and access to its logs, as shown in *Figure 7.36:*
  prefs: []
  type: TYPE_NORMAL
- en: '![The Containers tab showing all the individual containers.](image/Figure_7.36.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.36: The Containers tab shows us all the individual containers'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You might notice a couple of containers with an `Unknown` state. This is to
    be expected in our situation. Our time range in Azure Monitor is set to the last
    6 hours, and in the past 6 hours, we have created and deleted a number of Pods.
    They no longer exist, but Azure Monitor knows of their existence and even kept
    logs for them.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can get access to our container''s logs from this view:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Option in the containers tab to access the container''s logs.](image/Figure_7.37.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.37: Access the container''s logs'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This shows us all the logs that Kubernetes logged from our application. We
    accessed these logs manually earlier in this chapter. Using this approach can
    be a lot more productive, as we can edit the log queries and correlate logs from
    different Pods and applications in a single view:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Editing the log queries and correlating logs from different Pods and applications
    in a single view through the Logs window.](image/Figure_7.38.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.38: Logs are collected and can be queried'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Apart from the logs, this view also shows the environment variables that are
    set for the container. To see the environment variables, scroll down in the right
    cell of this view:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Displaying the environment variables set for the container by scrolling down
    in the right cell of the Logs view.](image/Figure_7.39.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.39: The environment variables set for the container'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'And that concludes this section. Let''s make sure to clean up our Deployments
    so we can continue with a clean guestbook in the next chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: In this section, we explored monitoring applications running on top of Kubernetes.
    We used the AKS **Insights** tab in the Azure portal to get a detailed view of
    our cluster and the containers running on our cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We started the chapter by showing how to use different `kubectl` commands to
    monitor an application. Then, we showed how the logs Kubernetes creates can be
    used to debug that application. The logs contain all the information that is written
    to `stdout` and `stderr`. Lastly, we explained the use of Azure Monitor to show
    the AKS metrics and environment variables, as well as logs with log filtering.
    We also showed how to debug application and cluster issues by using `kubectl`
    and Azure Monitor monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn how to connect an AKS cluster to Azure PaaS
    services. We will specifically focus on how you can connect an AKS cluster to
    a MySQL database managed by Azure.
  prefs: []
  type: TYPE_NORMAL
