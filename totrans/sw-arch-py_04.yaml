- en: Chapter 4. Good Performance is Rewarding!
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章。良好的性能是有回报的！
- en: Performance is one of the cornerstones of modern-day software applications.
    Every day we interact with high performing computing systems in many different
    ways, as part of our work and our leisure.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 性能是现代软件应用的基石之一。每天我们以多种不同的方式与高性能计算系统进行交互，作为我们工作和休闲的一部分。
- en: When you book an airline ticket from one of the travel sites on the web, you
    are interacting with a high performance system that carries out hundreds s of
    such transactions at a given time. When you transfer money to someone or pay your
    credit card bill online via an Internet banking transaction, you are interacting
    with a high performance and high throughput transactional system. Similarly when
    you play online games on your mobile phone and interact with other players, again
    there is a network of servers built for high concurrency and low latency that
    is receiving input from you and thousands of other players, performing computations
    at the back and sending data to you – all with reasonable and quiet efficiency.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在网上的旅行网站之一预订航班时，你正在与一个高性能系统交互，该系统在特定时间内执行数百个此类交易。当你向某人转账或通过互联网银行交易支付信用卡账单时，你正在与一个高性能和高吞吐量的交易系统交互。同样，当你在手机上玩在线游戏并与其他玩家互动时，又有一个网络服务器系统专为高并发和低延迟而建，它接收你和成千上万其他玩家的输入，进行后台计算并向你发送数据
    - 所有这些都以合理而安静的效率进行。
- en: Modern day web applications that serve millions of users concurrently became
    possible with the advent of high-speed Internet and huge drops in the price/performance
    ratio of hardware. Performance is still a key quality attribute of modern day
    software architecture and writing high performing and scalable software still
    continues to be something of a difficult art. You may write an application which
    ticks all the boxes of functionality and other quality attributes, but if it fails
    its performance tests, then it cannot be moved to production.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 现代网络应用程序可以同时为数百万用户提供服务，这是因为高速互联网的出现以及硬件价格/性能比的大幅下降。性能仍然是现代软件架构的关键质量属性，编写高性能和可扩展软件仍然是一门艰难的艺术。你可能编写了一个功能和其他质量属性都符合要求的应用程序，但如果它未通过性能测试，那么它就不能投入生产。
- en: In this chapter and the next, we focus on two aspects of writing software with
    high throughput – namely performance and scalability. In this chapter, the focus
    is on performance, the various aspects of it, how to measure it, the performance
    of various data structures, and when to choose what – with the focus on Python.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章和下一章中，我们将重点关注写高吞吐量软件的两个方面 - 即性能和可扩展性。在本章中，重点是性能，以及它的各个方面，如何衡量它，各种数据结构的性能，以及在何时选择什么
    - 重点放在Python上。
- en: 'The topics we will be discussing in this chapter roughly fall under the following
    sections:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将讨论的主题大致包括以下几个部分：
- en: Defining performance
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义性能
- en: Software performance engineering
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 软件性能工程
- en: Types of performance testing tool
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能测试工具的类型
- en: 'Performance complexity and the Big-O notation:'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能复杂性和大O符号：
- en: Measuring performance
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能测量
- en: Finding performance complexity using graphs
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用图表找到性能复杂性
- en: Improving performance
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高性能
- en: 'Profiling:'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能分析：
- en: Deterministic profiling
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定性分析
- en: '`cProfile` and `profile`'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cProfile` 和 `profile`'
- en: Third-party profilers
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三方性能分析工具
- en: 'Other tools:'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他工具：
- en: Objgraph
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Objgraph
- en: Pympler
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pympler
- en: 'Programming for performance – data structures:'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为性能编程 - 数据结构：
- en: Lists
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列表
- en: Dictionaries
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字典
- en: Sets
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集合
- en: Tuples
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元组
- en: 'High performance containers – the collections module:'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高性能容器 - collections模块：
- en: '`deque`'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deque`'
- en: '`defaultdict`'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`defaultdict`'
- en: '`OrderedDict`'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OrderedDict`'
- en: '`Counter`'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Counter`'
- en: '`ChainMap`'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChainMap`'
- en: '`namedtuple`'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`namedtuple`'
- en: Probabilistic data structure – bloom filters
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概率数据结构 - 布隆过滤器
- en: What is performance?
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是性能？
- en: 'The performance of a software system can be broadly defined as:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 软件系统的性能可以广义地定义为：
- en: '*"The degree to which the system is able to meet its throughput and/or latency
    requirements in terms of the number of transactions per second or time taken for
    a single transaction."*'
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “系统能够满足其吞吐量和/或延迟要求的程度，以每秒事务数或单个事务所需时间来衡量。”
- en: We've already taken an overview of measuring performance in the introductory
    chapter. Performance can be measured either in terms of response time/latency
    or in terms of throughput. The former is the time it takes for the application
    to complete a request/response loop on average. The latter is the rate at which
    the system processes its input in terms of the number of requests or transactions
    successfully completed per minute.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在介绍章节中概述了性能测量。性能可以用响应时间/延迟或吞吐量来衡量。前者是应用程序完成请求/响应循环的平均时间。后者是系统以每分钟成功完成的请求或交易数量来处理其输入的速率。
- en: The performance of a system is a function of its software and of its hardware
    capabilities. A badly written piece of software could still be made to perform
    better by scaling the hardware – for example, the amount of RAM.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 系统的性能是其软件和硬件能力的函数。一个糟糕编写的软件仍然可以通过扩展硬件（例如RAM的数量）来提高性能。
- en: Similarly a piece of software can be made to work better on existing hardware
    by increasing its performance – for example, by rewriting routines or functions
    to be more efficient in terms of time or memory or by modifying the architecture.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，通过增加性能（例如，通过重写例程或函数以在时间或内存方面更有效，或通过修改架构），可以使现有硬件上的软件更好地运行。
- en: However, the right type of performance engineering is the one where the software
    is tuned for the hardware in an optimal fashion so that software scales linearly
    or better with respect to the available hardware.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，正确的性能工程是软件以最佳方式针对硬件进行调整，使得软件相对于可用硬件的线性扩展或更好。
- en: Software performance engineering
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 软件性能工程
- en: Software performance engineering includes all the activities of software engineering
    and analysis applied during the **Software** **Development Life Cycle** (**SDLC**)
    and directed towards meeting performance requirements.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: In conventional software engineering, performance testing and feedback are done
    usually towards the end of the SDLC. This approach is purely measurement-based
    and waits for the system to be developed before applying tests and diagnostics
    and tuning the system based on the results.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Another more formal model named **Software Performance Engineering** (**SPE**)
    itself, develops performance models early in the SDLC and uses results from the
    models to modify the software design and architecture to meet performance requirements
    in multiple iterations.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 'In this approach, both performance as a non-functional requirement and software
    development meeting its functional requirement go hand in hand. There is a specific
    **Performance** **Engineering Life Cycle** (**PELC**) that parallels the steps
    in the SDLC. At every step, starting from the design and architecture all the
    way to deployment, feedback between both the life cycles is used to iteratively
    improve the software quality:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '![Software performance engineering](../Images/image00410.jpeg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: SPE - Performance Engineering Life Cycle mirroring Software Development Life
    Cycle
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: In both approaches, performance testing and diagnostics are important, followed
    by tuning the design/architecture or the code based on the results obtained. Hence
    performance testing and measurement tools play an important role in this step.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: Performance testing and measurement tools
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: These tools fall under two broad categories – namely, the ones used for performance
    testing and diagnostics, and the ones used for performance metrics gathering and
    instrumentation.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: 'Performance testing and diagnostic tools can be classified further as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '**Stress testing tools**: These tools are used to supply workload to the system
    under test, simulating peak workloads in production. These tools can be configured
    to send a continuous stream of input to the application to simulate high stress
    or to periodically send a burst of very high traffic – much exceeding even peak
    stress – to test the robustness of the system. These tools are also called **load
    generators**. Examples of common stress testing tools used for web application
    testing include **httpperf**, **ApacheBench**, **LoadRunner**, **Apache JMeter**,
    and **Locust**. Another class of tools involves those that actually record real
    user traffic and then replay it via the network to simulate real user load. For
    example, the popular network packet capturing and monitoring tool, **Wireshark**
    and its console cousin program, `tcpdump`, can be used to do this. We won''t be
    discussing these tools in this chapter as they are general-purpose and examples
    of usage for them can be found in abundance on the Web.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring tools**: These tools work with the application code to generate
    performance metrics such as the time and memory taken for functions to execute,
    the number of function calls made per request-response loop, the average and peak
    times spent on each function, and so on.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Instrumentation tools**: Instrumentation tools trace metrics, such as the
    time and memory required for each computing step, and also track events, such
    as exceptions in code, covering such details as the module/function/line number
    where the exception occurred, the timestamp of the event, and the environment
    of the application (environment variables, application configuration parameters,
    user information, system information, and so on). Often external instrumentation
    tools are used in modern web application programming systems to capture and analyze
    such data in detail.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Code or application profiling tools**: These tools generates statistics about
    functions, their frequency of duration of calls, and the time spent on each function
    call. This is a kind of dynamic program analysis. It allows the programmer to
    find critical sections of code where the most time is spent, allowing him/her
    to optimize those sections. Optimization without profiling is not advised as the
    programmer may end up optimizing the wrong code, thereby not surfacing the intended
    benefits up to the application.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most programming languages come with their own set of instrumentation and profiling
    tools. In Python, a set of tools in the standard library (such as the `profile`
    and `cProfile` modules) do this – this is supplemented by a rich ecosystem of
    third-party tools. We will discuss these tools in the coming sections.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: Performance complexity
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It would be helpful to spend some time discussing what we mean by the performance
    complexity of code before we jump into code examples in Python and discuss tools
    to measure and optimize performance.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: The performance complexity of a routine or function is defined in terms of how
    they respond to changes in the input size typically in terms of the time spent
    in executing the code.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: This is usually represented by the so-called Big-O notation which belongs to
    a family of notations called the **Bachmann–Landau notation or asymptotic** notation.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: The letter O is used as the rate of growth of a function with respect to input
    size - also called the **order** of the function.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: 'Commonly used Big-O notations or function orders are shown in the following
    table in order of increasing complexity:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '| # | Order | Complexity | Example |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
- en: '| 1 | *O(1)* | Constant | Looking for a key in a constant look-up table such
    as a HashMap or dictionary in Python |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
- en: '| 2 | *O(log (n))* | Logarithmic | Searching for an item in a sorted array
    with a binary search. All operations on a heapq in Python |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
- en: '| 3 | *O(n)* | Linear | Searching an item in an array (list in Python) by traversing
    it |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
- en: '| 4 | *O(n*k)* | Linear | Worst-case complexity of Radix sort |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
- en: '| 5 | *O(n * log (n))* | n log-star n | Worst-case complexity in a mergesort
    or heapsort algorithm |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
- en: '| 6 | *O(n²)* | Quadratic | Simple sorting algorithms such as bubblesort, insertion
    sort, and selection sort. Worst-case complexity on some sorting algorithms such
    as quicksort, shellsort, and so on |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
- en: '| 7 | *O(2^n)* | Exponential | Trying to break a password of size n using brute
    force, solving the travelling salesman problem using dynamic programming |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
- en: '| 8 | *O(n!)* | Factorial | Generating all partitions of a set |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
- en: 'Table 1: Common Big-O notations for function orders with respect to input size
    "n"'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: When implementing a routine or algorithm accepting an input of a certain size
    *n*, the programmer ideally should aim for implementing it in an order that falls
    in the first five. Anything which is of the order of *O(n) or O(n* log(n))* or
    lesser indicates reasonable to good performance.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Algorithms with an order of *O(n²)* can usually be optimized to work at a lower
    order. We will see some examples of this in the sections in the following diagram.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows how each of these orders grow with respect to *n*:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '![Performance complexity](../Images/image00411.jpeg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
- en: Graph of growth rate of each order of complexity (y-axis) w.r.t input size (x-axis)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Measuring performance
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we've had an overview of what performance complexity is and also of
    performance testing and measurement tools, let us take an actual look at the various
    ways of measuring performance complexity with Python.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: One of the simplest time measurements can be done by using the `time` command
    of a POSIX/Linux system.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'This is done by using the following command line:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For example, here is a screenshot of the time it takes to fetch a very popular
    page from the Web:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '![Measuring performance](../Images/image00412.jpeg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
- en: Output of the time command on fetching a web page from the Internet via wget
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: 'See that it shows three classes of time output, namely `real`, `user`, and
    `sys`. It is important to know the distinction between these three so let us look
    at them briefly:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，它显示了三种时间输出，即`real`、`user`和`sys`。重要的是要知道这三者之间的区别，让我们简要地看一下它们：
- en: '`real`: Real time is the actual wall clock time that elapsed for the operation.
    This is the time of the operation from start to finish. It will include any time
    the process sleeps or spends blocked – such as time taken for I/O to complete.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`real`：实际时间是操作所经历的实际挂钟时间。这是操作从开始到结束的时间。它将包括进程休眠或阻塞的任何时间，例如I/O完成所花费的时间。'
- en: '`User`: User time is the amount of actual CPU time spent within the process
    in user mode (outside the kernel). Any sleep time or time spent in waiting such
    as I/O doesn''t add to the user time.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`User`：用户时间是进程在用户模式（在内核之外）内实际花费的CPU时间。任何休眠时间或在等待中花费的时间，如I/O，不会增加用户时间。'
- en: '`Sys`: System time is the amount of CPU time spent on executing system calls
    within the kernel for the program. This counts only those functions that execute
    in kernel space such as privileged system calls. It doesn''t count any system
    calls that execute in user space (which is counted in `User`).'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Sys`：系统时间是程序内核中执行系统调用所花费的CPU时间。这仅计算在内核空间中执行的函数，如特权系统调用。它不计算在用户空间中执行的任何系统调用（这在`User`中计算）。'
- en: The total CPU time spent by a process is `user` + `sys` time. The real or wall
    clock time is the time mostly measured by simple time counters.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 一个进程所花费的总CPU时间是`user` + `sys`时间。真实或挂钟时间是由简单的时间计数器大多数测量的时间。
- en: Measuring time using a context manager
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用上下文管理器测量时间
- en: In Python, it is not very difficult to write a simple function that serves as
    a context manager for blocks of code whose execution time you want to measure.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，编写一个简单的函数作为代码块的上下文管理器，用于测量其执行时间并不是很困难。
- en: But first we need a program whose performance we can measure.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 但首先我们需要一个可以测量性能的程序。
- en: 'Take a look at the following steps to learn how to use a context manager for
    measuring time:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 请看以下步骤，了解如何使用上下文管理器来测量时间：
- en: 'Let us write a program that calculates the common elements between two sequences
    as a test program. Here is the code:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们编写一个计算两个序列之间共同元素的程序作为测试程序。以下是代码：
- en: '[PRE1]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let us write a simple context-manager timer to time this code. For timing we
    will use `perf_counter` of the `time` module, which gives the time to the most
    precise resolution for short durations:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们编写一个简单的上下文管理器计时器来计时这段代码。为了计时，我们将使用`time`模块的`perf_counter`，它可以给出最精确的时间分辨率：
- en: '[PRE2]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let us time the function for some simple input data. For this a `test` function
    is useful that generates random data, given an input size:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们为一些简单的输入数据计时函数。为此，一个`test`函数很有用，它可以生成随机数据，给定一个输入大小：
- en: '[PRE3]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here is the output of the `timer` method on the `test` function on the Python
    interactive interpreter:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在Python交互解释器上对`test`函数的`timer`方法的输出：
- en: '[PRE4]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In fact both test data generation and testing can be combined in the same function
    to make it easy to test and generate data for a range of input sizes:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实际上，测试数据生成和测试可以结合在同一个函数中，以便轻松地测试和生成一系列输入大小的数据：
- en: '[PRE5]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now let us measure the time taken for different ranges of input sizes in the
    Python interactive console:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们在Python交互控制台中测量不同范围的输入大小所花费的时间：
- en: '[PRE6]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Oops, the time spent for `1000` items is less than that for `800`! How''s that
    possible? Let''s try again:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 哎呀，`1000`个项目所花费的时间比`800`的时间少！这怎么可能？让我们再试一次：
- en: '[PRE7]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now the time spent for `800` items seems to be lesser than that for `400` and
    `500`. And time spent for `1000` items has increased to more than twice what it
    was before.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，`800`个项目所花费的时间似乎比`400`和`500`的时间少。而`1000`个项目所花费的时间增加到了之前的两倍以上。
- en: The reason is that our input data is random, which means it will sometimes have
    a lot of common items – which takes more time – and sometimes have much less.
    Hence on subsequent calls the time taken can show a range of values.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 原因是我们的输入数据是随机的，这意味着它有时会有很多共同的项目-这需要更多的时间-有时会少得多。因此，在后续调用中，所花费的时间可能会显示一系列值。
- en: In other words, our timing function is useful to get a rough picture, but not
    very useful when it comes to getting the true statistical measure of time taken
    for program execution, which is more important.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们的计时函数对于获得一个大致的图片是有用的，但是当涉及到获取程序执行所花费的真实统计度量时，它并不是非常有用，这更为重要。
- en: For this we need to run the timer many times and take an average. This is somewhat
    similar to the **amortized** analysis of algorithms, which takes into account
    both the lower end and upper end of the time taken for executing algorithms and
    gives the programmer a realistic estimate of the average time spent.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为此，我们需要多次运行计时器并取平均值。这与算法的**摊销**分析有些类似，它考虑了执行算法所花费的时间的下限和上限，并给程序员一个实际的平均时间估计。
- en: Python comes with such a module, which helps to perform such timing analysis,
    in its standard library, namely the `timeit` module. Let us look at this module
    in the next section.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: Python自带了这样一个模块，它可以帮助在其标准库中执行这样的计时分析，即`timeit`模块。让我们在下一节中看看这个模块。
- en: Timing code using the timeit module
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用`timeit`模块计时代码
- en: The `timeit` module in the Python standard library allows the programmer to
    measure the time taken to execute small code snippets. The code snippets can be
    a Python statement, an expression, or a function.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Python标准库中的`timeit`模块允许程序员测量执行小代码片段所花费的时间。代码片段可以是Python语句、表达式或函数。
- en: The simplest way to use the `timeit` module is to execute it as a module in
    the Python command line.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`timeit`模块的最简单方法是在Python命令行中将其作为模块执行。
- en: 'For example, here is timing data for some simple Python inline code measuring
    the performance of a list comprehension calculating squares of numbers in a range:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下是一些简单的Python内联代码的计时数据，用于测量在范围内计算数字平方的列表推导的性能：
- en: '[PRE8]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The result shows the time taken for execution of the code snippet. When run
    on the command line, the `timeit` module automatically determines the number of
    cycles to run the code and also calculates the average time spent in a single
    execution.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The results show that the statement we are executing is linear or O(n) as a
    range of size 100 takes 5.5 usec and that of 1,000 takes 56.5 usec or about 10
    times its time. A usec – or microsecond - is 1 millionth of a second or 1*10-6
    seconds.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how to use the `timeit` module on the Python interpreter in a similar
    manner:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Observe that when used in this way, the programmer has to pass the correct number
    of iterations as the `number` argument and, to average, has to divide by the same
    number. The multiplication by `1000000` is to convert the time to microseconds
    (usec).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: The `timeit` module uses a `Timer` class behind the scenes. The class can be
    made use of directly as well as for finer control.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: When using this class, `timeit` becomes a method of the instance of the class
    to which the number of cycles is passed as an argument.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: The `Timer` class constructor also accepts an optional `setup` argument, which
    sets up the code for the `Timer` class. This can contain statements for importing
    the module that contains the function, setting up globals, and so on. It accepts
    multiple statements separated by semi-colons.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: Measuring the performance of our code using timeit
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let us rewrite our `test` function to test the common items between two sequences.
    Now that we are going to use the `timeit` module, we can remove the context manager
    timer from the code. We will also hard-code the call to `common_items` in the
    function.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We also need to create the random input outside the test function since otherwise
    the time taken for it will add to the test function's time and corrupt our results.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Hence we need to move the variables out as globals in the module and write a
    `setup` function, which will generate the data for us as a first step.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'Our rewritten `test` function looks like this:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The `setup` function with the global variables looks like this:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Let's assume the module containing both the `test` and `common_items` functions
    is named `common_items.py`.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: 'The timer test can now be run as follows:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: So the time taken for a range of `100` numbers is around 117 usec (0.12 microseconds)
    on average.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: 'Executing it now for a few other ranges of input sizes gives the following
    output:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: So the maximum time taken for this test run is 12.4 microseconds for an input
    size of `1000` items.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Finding out time complexity – graphs
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Is it possible to find out from these results what the time performance complexity
    of our function is? Let us try plotting it in a graph and see the results.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: 'The `matplotlib` library is very useful in plotting graphs in Python for any
    type of input data. We just need the following simple piece of code for this to
    work:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The preceding code gives you the following output:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Take a look at the following graph:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '![Finding out time complexity – graphs](../Images/image00413.jpeg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
- en: Plot of the input range versus time taken for the common_items function
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: This is clearly not linear, yet of course not quadratic (in comparison with
    the figure on Big-O notations). Let us try and plot a graph of O(n*log(n)) superimposed
    on the current plot to see if there's a match.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we now need two series of `ydata`, we need another slightly modified
    function:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The preceding code gives you the following output:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'You get the following graph:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '![Finding out time complexity – graphs](../Images/image00414.jpeg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
- en: Plot of time complexity of common_items superimposed on the plot of y = x*log(x)
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: The superimposed plot shows that the function is a close match for the n*log(n)
    order, if not exactly the same. So our current implementation's complexity seems
    to be roughly O(n*log(n)).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've done the performance analysis, let us see if we can rewrite our
    routine to perform better.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the current code:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The routine first does a pass over an outer `for` loop (of size `n`) and does
    a check in a sequence (also of size `n`) for the item. Now the second search is
    also of time complexity `n` on average.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 例程首先对外部的`for`循环（大小为`n`）进行一次遍历，并在一个序列（同样大小为`n`）中检查该项。现在第二次搜索的平均时间复杂度也是`n`。
- en: However, some items would be found immediately and some items would take linear
    time (k) where 1 <k < n. On average, the distribution would be somewhere in between,
    which is why the code has an average complexity approximating O(n*log(n)).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有些项会立即被找到，有些项会花费线性时间(k)，其中1 < k < n。平均而言，分布会在两者之间，这就是为什么代码的平均复杂度接近O(n*log(n))。
- en: A quick analysis will tell you that the inner search can be avoided by converting
    the outer sequence to a dictionary, setting values to 1\. The inner search will
    be replaced with a loop on the second sequence that increments values by 1.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 快速分析会告诉你，通过将外部序列转换为字典并将值设置为1，可以避免内部搜索。内部搜索将被在第二个序列上的循环替代，该循环将值递增1。
- en: In the end, all common items will have a value greater than 1 in the new dictionary.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，所有共同项在新字典中的值都将大于1。
- en: 'The new code is as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 新代码如下：
- en: '[PRE19]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'With this change, the timer gives the following updated results:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个改变，计时器给出了以下更新后的结果：
- en: '[PRE20]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let us plot this and superimpose it on an O(n) graph:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制这个图并叠加在O(n)图上：
- en: '[PRE21]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let''s take a look at the following graph:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下下面的图表：
- en: '![Finding out time complexity – graphs](../Images/image00415.jpeg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![找出时间复杂度-图表](../Images/image00415.jpeg)'
- en: Plot of time taken by common_items function (v2) against y = x graph
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: common_items函数（v2）所花费的时间的图与y = x图
- en: The upper green line is the reference **y** = **x** graph and the lower blue
    line is the plot of the time taken by our new function. It is pretty obvious that
    the time complexity is now linear or O(n).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的绿线是参考**y** = **x**图，下面的蓝线是我们新函数所花费的时间的图。很明显，时间复杂度现在是线性的或者O(n)。
- en: However, there seems to be a constant factor here as the slopes of two lines
    are different. From a quick calculation one can compute this factor as roughly
    `0.35`.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这里似乎有一个常数因子，因为两条线的斜率不同。通过快速计算，可以大致计算出这个因子约为`0.35`。
- en: 'After applying this change, you will get the following output:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 应用这个改变后，你会得到以下输出：
- en: '[PRE22]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![Finding out time complexity – graphs](../Images/image00416.jpeg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![找出时间复杂度-图表](../Images/image00416.jpeg)'
- en: Plot of time taken by common_items function (v2) against y = 0.35*x graph
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: common_items函数（v2）所花费的时间的图与y = 0.35*x图
- en: You can see that the plots pretty much superimpose on each other. So our function
    is now performing at O(c*n) where c ~= 0.35.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到这些图几乎完全叠加在一起。因此我们的函数现在的性能是O(c*n)，其中c约等于0.35。
- en: Note
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Another implementation of the `common_items` function is to convert both sequences
    to sets and return their intersection. It would be an interesting exercise for
    the reader to make this change, time it, and plot the graphs to determine the
    time complexity.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '`common_items`函数的另一个实现是将两个序列都转换为集合并返回它们的交集。读者可以尝试进行这种改变，计时并绘制图表以确定时间复杂度。'
- en: Measuring CPU time with timeit
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用timeit测量CPU时间
- en: The `Timer` module by default uses the `perf_counter` function of the `time`
    module as the default `timer` function. As mentioned earlier, this function returns
    the wall clock time spent to the maximum precision for small time durations, hence
    it will include any sleep time, time spent for I/O, and so on.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '`Timer`模块默认使用时间模块的`perf_counter`函数作为默认的`timer`函数。正如前面提到的，这个函数返回小时间段的最大精度的墙钟时间，因此它将包括任何睡眠时间、I/O时间等。'
- en: 'This can be made clear by adding a little sleep time to our test function as
    follows:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 通过向我们的测试函数添加一点睡眠时间，可以澄清这一点：
- en: '[PRE23]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The preceding code will give you the following output:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将给出以下输出：
- en: '[PRE24]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The time jumped by as much as 300 times since we are sleeping `0.01` seconds
    (10 milliseconds) upon every invocation, so the actual time spent on the code
    is now determined almost completely by the sleep time as the result shows `10545.260819926625`
    microseconds (or about 10 milliseconds).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在每次调用时睡眠了`0.01`秒（10毫秒），所以时间增加了300倍，因此代码实际消耗的时间现在几乎完全由睡眠时间决定，因为结果显示为`10545.260819926625`微秒（大约10毫秒）。
- en: Sometimes you may have such sleep times and other blocking/wait times but you
    want to measure only the actual CPU time taken by the function. To use this, the
    `Timer` object can be created using the `process_time` function of the time module
    as the `timer` function.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候你可能会有这样的睡眠时间和其他阻塞/等待时间，但你只想测量函数实际消耗的CPU时间。为了使用这个功能，可以使用时间模块的`process_time`函数作为`timer`函数来创建`Timer`对象。
- en: 'This can be done by passing in a `timer` argument when you create the `Timer`
    object:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 当你创建`Timer`对象时，可以通过传入一个`timer`参数来实现：
- en: '[PRE25]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: If you now increase the sleep time by a factor of, say, 10, the testing time
    increases by that factor, but the return value of the timer remains the same.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你现在将睡眠时间增加10倍，测试时间也会增加相应的倍数，但计时器的返回值仍然保持不变。
- en: 'For example, here is the result when sleeping for 1 second. The output comes
    after about 100 seconds (since we are iterating `100` times), but notice that
    the return value (time spent per invocation) doesn''t change:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当睡眠1秒时，结果如下。输出大约在100秒后出现（因为我们迭代了`100`次），但请注意返回值（每次调用所花费的时间）并没有改变：
- en: '[PRE26]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Let us move on to profiling next.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们接下来进行分析。
- en: Profiling
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析
- en: In this section, we will discuss profilers and take a deep look at the modules
    in the Python standard library, which provides support for deterministic profiling.
    We will also look at third-party libraries that provide support for profiling
    such as `line_profiler` and `memory_profiler`.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论分析器，并深入研究Python标准库中提供的支持确定性分析的模块。我们还将研究提供分析支持的第三方库，如`line_profiler`和`memory_profiler`。
- en: Deterministic profiling
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确定性分析
- en: Deterministic profiling means that all function calls, function returns, and
    exception events are monitored, and precise timings are made for the intervals
    between these events. Another type of profiling, namely **statistical profiling**,
    randomly samples the instruction pointer and deduces where time is being spent
    – but this may not be very accurate.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 确定性性能分析意味着监视所有函数调用、函数返回和异常事件，并对这些事件之间的时间间隔进行精确计时。另一种类型的性能分析，即**统计性能分析**，会随机抽样指令指针，并推断时间花费在哪里-但这可能不是非常准确。
- en: Python, being an interpreted language, already has a certain overhead in terms
    of metadata kept by the interpreter. Most deterministic profiling tools makes
    use of this information and hence only add very little extra processing overhead
    for most applications. Hence deterministic profiling in Python is not a very expensive
    operation.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种解释性语言，Python在元数据方面已经有一定的开销。大多数确定性性能分析工具利用了这些信息，因此对于大多数应用程序来说，只会增加很少的额外处理开销。因此，在Python中进行确定性性能分析并不是一项非常昂贵的操作。
- en: Profiling with cProfile and profile
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用cProfile和profile
- en: The `profile` and `cProfile` modules provide support for deterministic profiling
    in the Python standard library. The `profile` module is purely written in Python.
    The `cProfile` module is a C extension that mimics the interface of the `profile`
    module but adds lesser overhead to it when compared to profile.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '`profile`和`cProfile`模块在Python标准库中提供了确定性性能分析的支持。`profile`模块纯粹由Python编写。`cProfile`模块是一个C扩展，模仿了`profile`模块的接口，但与`profile`相比，它的开销更小。'
- en: Both modules report statistics that are converted into reportable results using
    the `pstats` module.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个模块都报告统计数据，使用`pstats`模块将其转换为可报告的结果。
- en: 'We will use the following code, which is a prime number iterator, in order
    to show our examples using the `profile` modules:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下代码，这是一个质数迭代器，以展示我们使用`profile`模块的示例：
- en: '[PRE27]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The prime number iterator generates the first `n` prime numbers given the value
    of `n`:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 给定值`n`，质数迭代器生成前`n`个质数：
- en: '[PRE28]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'To profile this code, we just need to pass the code to be executed as a string
    to the `run` method of the profile or cProfile module. In the following examples,
    we will be using the `cProfile` module:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 要对此代码进行性能分析，我们只需要将要执行的代码作为字符串传递给`profile`或`cProfile`模块的`run`方法。在以下示例中，我们将使用`cProfile`模块：
- en: '![Profiling with cProfile and profile](../Images/image00417.jpeg)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![使用cProfile和profile进行性能分析](../Images/image00417.jpeg)'
- en: Profiling output of the prime iterator function for the first 100 primes
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 对前100个质数的质数迭代器函数的性能分析输出
- en: 'See how the profiler reports its output. The output is ordered into six columns
    as follows:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 看看性能分析器如何报告其输出。输出按以下六列排序：
- en: '`ncalls`: The number of calls per function'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ncalls`：每个函数的调用次数'
- en: '`tottime`: The total time spent in the call'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tottime`：调用中花费的总时间'
- en: '`percall`: The `percall` time (quotient of `tottime`/`ncalls`)'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`percall`：`percall`时间（`tottime`/`ncalls`的商）'
- en: '`cumtime`: The cumulative time in this function plus any child function'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cumtime`：此函数及任何子函数中的累积时间'
- en: '`percall`: Another `percall` column (the quotient of `cumtime`/number of primitive
    calls)'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`percall`：另一个`percall`列（`cumtime`/原始调用次数的商）'
- en: '`filename: lineno(function)`: The filename and line number of the function
    call'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`filename: lineno(function)`：函数调用的文件名和行号'
- en: In this case, our function took `4` microseconds to complete with most of that
    time (`3` microseconds) being spent inside the `is_prime` method, which also dominates
    the number of calls at 271.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们的函数完成需要`4`微秒，其中大部分时间（`3`微秒）花在`is_prime`方法内部，这也占据了271次调用中的大部分。
- en: 'Here are the outputs of the profiler at `n = 1000` and `10000` respectively:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`n = 1000`和`10000`的性能分析输出：
- en: '![Profiling with cProfile and profile](../Images/image00418.jpeg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![使用cProfile和profile进行性能分析](../Images/image00418.jpeg)'
- en: Profiling output of the prime iterator function for the first 1,000 primes
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 对前1,000个质数的质数迭代器函数的性能分析输出
- en: 'Take a look at the following additional output:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下额外输出：
- en: '![Profiling with cProfile and profile](../Images/image00419.jpeg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![使用cProfile和profile进行性能分析](../Images/image00419.jpeg)'
- en: Profiling output of the Prime iterator function for first 10,000 primes
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 对前10,000个质数的质数迭代器函数的性能分析输出
- en: As you can see, at `n`=`1000` it took about `0.043` seconds (43 microseconds)
    and at `n`=`10000` it took `0.458` seconds (458 microseconds). Our `Prime` iterator
    seems to be performing at an order close to O(n).
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，在`n`=`1000`时，大约需要`0.043`秒（43微秒），而在`n`=`10000`时，需要`0.458`秒（458微秒）。我们的`Prime`迭代器似乎以接近O(n)的顺序执行。
- en: As usual, most of that time is spent in `is_primes`. Is there a way to reduce
    that time?
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，大部分时间都花在`is_primes`上。有没有办法减少这段时间？
- en: At this point, let us analyze the code.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，让我们分析一下代码。
- en: Prime number iterator class – performance tweaks
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 质数迭代器类-性能调整
- en: A quick analysis of the code tells us that inside `is_prime` we are dividing
    the value by every number in the range from `3` to the successor of the square
    root of the value.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 对代码的快速分析告诉我们，在`is_prime`内部，我们将值除以从`3`到值的平方根的后继数的范围内的每个数。
- en: This contains many even numbers as well – we are doing unnecessary computation,
    which we can avoid by dividing only by the odd numbers.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这包含许多偶数-我们正在进行不必要的计算，我们可以通过仅除以奇数来避免这种情况。
- en: 'The modified `is_prime` method is as follows:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 修改后的`is_prime`方法如下：
- en: '[PRE29]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: With this, the profile for `n`=`1000` and `n`=`10000` looks as follows.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，`n`=`1000`和`n`=`10000`的性能分析如下。
- en: The following is the output of the profiler for `n = 1000`.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`n = 1000`的性能分析输出。
- en: '![Prime number iterator class – performance tweaks](../Images/image00420.jpeg)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![质数迭代器类-性能调整](../Images/image00420.jpeg)'
- en: Profiling output of the Prime iterator function for the first 1,000 primes with
    tweaked code
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 对前1,000个质数的质数迭代器函数的性能分析输出，使用了调整后的代码
- en: 'The following is the output of the profiler for `n` = `10000`:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`n`=`10000`时的性能分析输出：
- en: '![Prime number iterator class – performance tweaks](../Images/image00421.jpeg)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![质数迭代器类-性能调整](../Images/image00421.jpeg)'
- en: Profiling output of the Prime iterator function for first 10,000 primes with
    tweaked code
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: You can see that, at `1000`, the time has dropped a bit (43 microseconds to
    38 microseconds) but at `10000`, there is nearly a 50% drop from 458 microseconds
    to 232 microseconds. At this point, the function is performing better than O(n).
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Profiling – collecting and reporting statistics
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The way we used cProfile in the example earlier, it ran and reported the statistics
    directly. Another way to use the module is to pass a `filename` argument to which
    it writes the statistics, which can later be loaded and interpreted by the `pstats`
    module.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: 'We modify the code as follows:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: By doing this, the stats, instead of getting printed out, are saved to the file
    named `prime.stats`.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how to parse the statistics using the `pstats` module and print the
    results ordered by the number of calls:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '![Profiling – collecting and reporting statistics](../Images/image00422.jpeg)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
- en: Parsing and printing saved profile results using the pstats module
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: The `pstats` module allows sorting the profile results by a number of headers
    such as total time (`tottime`), number of primitive calls (`pcalls`), cumulative
    time (`cumtime`), and so on. You can see from the output of pstats again that
    most of the processing in terms of number of calls are being spent in the is_prime
    method, as we are sorting the output by 'ncalls' or the number of function calls.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: The `Stats` class of the `pstats` module returns a reference to itself after
    every operation. This is a very useful aspect of some Python classes and allows
    us to write compact one line code by chaining method calls.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: 'Another useful method of the `Stats` object is to find out the callee/caller
    relationship. This can be done by using the `print_callers` method instead of
    `print_stats`. Here is the output from our current statistics:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '![Profiling – collecting and reporting statistics](../Images/image00423.jpeg)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
- en: Printing callee/caller relationships ordered by primitive calls using pstats
    module
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: Third-party profilers
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Python ecosystem comes with a plethora of third-party modules for solving
    most problems. This is true in the case of profilers as well. In this section,
    we will take a quick look at a few popular third-party profiler applications contributed
    by developers in the Python community.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: Line profiler
  id: totrans-262
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Line profiler is a profiler application developed by Robert Kern for performing
    line by line profiling of Python applications. It is written in Cython, an optimizing
    static compiler for Python that reduces the overhead of profiling.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: 'Line profiler can be installed via `pip` as follows:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: As opposed to the profiling modules in Python, which profile functions, line
    profiler is able to profile code line by line, thus providing more granular statistics.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: Line profiler comes with a script called `kernprof.py` that makes it easy to
    profile code using line profiler. One needs only to decorate the functions that
    need to be profiled with the `@profile` decorator when using `kernprof`.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: For example, we realized that most of the time in our prime number iterator
    was being spent in the `is_prime` method. However, line profiler allows us to
    go into more detail and find which lines of those functions take the most time.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, just decorate the method with the `@profile` decorator:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Since `kernprof` accepts a script as an argument, we need to add some code
    to invoke the prime number iterator. To do that, we can append the following at
    the end of the `primes.py` module:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Now, run it with line profiler as follows:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: By passing `-v` to the `kernprof` script, we tell it to display the profile
    results in addition to saving them.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the output:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '![Line profiler](../Images/image00424.jpeg)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
- en: Line profiler results from profiling the is_prime method using n = 1000
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: 'Line profiler tells us that the majority of the time – close to 90% of the
    total time spent in the method – is spent in the first two lines: the for loop
    and the reminder check.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: This tells us that, if ever we want to optimize this method, we need to concentrate
    on these two aspects.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们，如果我们想要优化这种方法，我们需要集中在这两个方面。
- en: Memory profiler
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内存分析器
- en: Memory profiler is a profiler similar to line profiler in that it profiles Python
    code line by line. However, instead of profiling the time taken in each line of
    code, it profiles lines by memory consumption.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 内存分析器类似于行分析器，它逐行分析Python代码。但是，它不是分析代码每行所花费的时间，而是通过内存消耗逐行分析代码。
- en: 'Memory profiler can be installed the same way as line profiler:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 内存分析器可以像行分析器一样安装：
- en: '[PRE35]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Once installed, memory for lines can be printed by decorating the function with
    the `@profile` decorator in a similar way to line profiler.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 安装后，可以通过将函数装饰为`@profile`装饰器来打印行的内存，类似于行分析器。
- en: 'Here is a simple example:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的例子：
- en: '[PRE36]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Here''s how to run this:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何运行的：
- en: '![Memory profiler](../Images/image00425.jpeg)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![内存分析器](../Images/image00425.jpeg)'
- en: Memory profiler profiling a list comprehension of squares of the first 1,000
    numbers
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 内存分析器对前1000个数字的平方的列表推导式进行分析
- en: 'Memory profiler shows memory increments line by line. In this case, there is
    almost no increment for the line containing the number of squares (the list comprehension)
    as the numbers are rather small. The total memory usage remains what it was at
    the beginning: about 32 MB.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 内存分析器逐行显示内存增量。在这种情况下，包含平方数（列表推导式）的行几乎没有增量，因为数字相当小。总内存使用量保持在开始时的水平：约32 MB。
- en: 'What happens if we change the value of `n` to a million? This can be done by
    rewriting the last line of the code as follows:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将`n`的值更改为一百万会发生什么？可以通过将代码的最后一行改写为以下内容来实现：
- en: '[PRE37]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '![Memory profiler](../Images/image00426.jpeg)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![内存分析器](../Images/image00426.jpeg)'
- en: Memory profiler profiling a list comprehension of squares of the first 1 million
    numbers
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 内存分析器对前100万个数字的平方的列表推导式进行分析
- en: Now you can see that there is a clear memory increment of about 39 MB for the
    list comprehension calculating the squares, with a total final memory usage of
    about 70 MB.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以看到，计算平方的列表推导式的内存增加约为39 MB，最终总内存使用量约为70 MB。
- en: To demonstrating the real usefulness of memory profiler, let us look at another
    example.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示内存分析器的真正用处，让我们看另一个例子。
- en: This involves finding the strings from a sequence that are subsequences of any
    of the strings present in another sequence, generally containing larger strings.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 这涉及查找序列中作为另一个序列中任何字符串的子序列的字符串，通常包含较大的字符串。
- en: Substring (subsequence) problem
  id: totrans-299
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 子字符串（子序列）问题
- en: 'Let us say you have a sequence containing the following strings:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您有一个包含以下字符串的序列：
- en: '[PRE38]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'And say there is another sequence as follows:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 假设还有另一个序列如下：
- en: '[PRE39]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The problem is to find the strings in `seq2` that are substrings – as is found
    anywhere contiguously in any of the strings in `seq1`:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是要找到`seq2`中作为`seq1`中任何字符串中连续出现的子字符串：
- en: 'In this case, the answer is as follows:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，答案如下：
- en: '[PRE40]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'This can be solved using a brute-force search – checking for each string one
    by one in each of the parent strings as follows:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过蛮力搜索来解决-逐个检查每个字符串是否在父字符串中，如下所示：
- en: '[PRE41]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: However, a quick analysis will tell you that the time complexity of this function
    scales rather badly as the size of the sequences increase. Since every step needs
    iteration through two sequences and then a search in each string in the first
    sequence, the average performance would be O(n1*n2), where n1, n2 are the sizes
    of the sequences respectively.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，快速分析会告诉您，该函数的时间复杂度随着序列大小的增加而变得非常糟糕。由于每个步骤都需要迭代两个序列，然后在第一个序列的每个字符串中进行搜索，平均性能将是O(n1*n2)，其中n1，n2分别是序列的大小。
- en: 'Here are the results of some tests of this function with input sizes (both
    sequences of the same size) of random strings varying from length 2 to 10:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对此函数进行一些测试的结果，输入大小为随机字符串的长度2到10的两个序列的大小相同：
- en: '| Input size | Time taken |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| 输入大小 | 花费时间 |'
- en: '| --- | --- |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 100 | 450 usec |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| 100 | 450 微秒 |'
- en: '| 1000 | 52 microseconds |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| 1000 | 52 微秒 |'
- en: '| 10000 | 5.4 seconds |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| 10000 | 5.4 秒 |'
- en: The results indicate the performance is almost exactly O(n²).
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明性能几乎完全是O(n²)。
- en: 'Is there a way to rewrite the function to be more performance-efficient? This
    approach is captured in the following `sub_string` function:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 有没有办法重写函数以提高性能？这种方法体现在以下`sub_string`函数中：
- en: '[PRE42]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: In this approach, we pre-compute all the substrings of a size range from the
    strings in `seq1` and store it in a dictionary. Then it is a matter of going through
    the strings in `seq2` and checking if they are in this dictionary and if so adding
    them to a list.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种方法中，我们预先计算`seq1`中字符串的大小范围的所有子字符串，并将其存储在字典中。然后只需遍历`seq2`中的字符串，并检查它们是否在此字典中，如果是，则将它们添加到列表中。
- en: To optimize the calculation, we only compute strings whose size is in the range
    of the minimum and maximum length of the strings in `seq2`.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 为了优化计算，我们只计算大小在`seq2`字符串的最小和最大长度范围内的字符串。
- en: As with almost all solutions to performance issues, this one trades space for
    time. By pre-computing all the substrings, we are expending more space in memory
    but this eases the computation time.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 与几乎所有解决性能问题的解决方案一样，这种方法以时间换空间。通过预先计算所有子字符串，我们在内存中消耗了更多的空间，但这简化了计算时间。
- en: 'The test code looks like this:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 测试代码如下：
- en: '[PRE43]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Here are the timing results of this function using the `timeit` module:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用`timeit`模块运行此函数的时间结果：
- en: '[PRE44]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Here are the summarized results for this test:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是此测试的总结结果：
- en: '| Input size | Time taken |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| 输入大小 | 花费时间 |'
- en: '| --- | --- |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 100 | 1.08 microseconds |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| 100 | 1.08 微秒 |'
- en: '| 1000 | 11.97 microseconds |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| 1000 | 11.97 微秒 |'
- en: '| 10000 | 0.12 microseconds |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '| 10000 | 0.12 微秒 |'
- en: '| 100000 | 1.26 seconds |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| 100000 | 1.26 秒 |'
- en: 'Table 2: Input size versus time taken for sub-sequence solution via brute force'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：通过蛮力解决方案的输入大小与花费时间
- en: A quick calculation tells us that the algorithm is now performing at O(n). Pretty
    good!
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 快速计算告诉我们，该算法现在的性能为O(n)。非常好！
- en: But this is at the expense of memory in terms of the pre-computed strings. We
    can get an estimate of this by invoking memory profiler.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 但这是以预先计算的字符串的内存为代价。我们可以通过调用内存分析器来估计这一点。
- en: 'Here is the decorated function for doing this:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于执行此操作的装饰函数：
- en: '[PRE45]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The test function would now be as follows:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 现在测试函数如下：
- en: '[PRE46]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Let's test this for the sequence of sizes 1,000 and 10,000 respectively.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分别测试大小为1,000和10,000的序列。
- en: 'Here is the result for an input size of 1,000:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输入大小为1,000时的结果：
- en: '![Substring (subsequence) problem](../Images/image00427.jpeg)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
  zh: '![子串（子序列）问题](../Images/image00427.jpeg)'
- en: Memory profiler results for testing sub-strings of sequences of size 1,000
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 测试大小为1,000的序列的内存分析器结果
- en: 'And here is the result for an input size of 10,000:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输入大小为10,000时的结果：
- en: '![Substring (subsequence) problem](../Images/image00428.jpeg)'
  id: totrans-345
  prefs: []
  type: TYPE_IMG
  zh: '![子串（子序列）问题](../Images/image00428.jpeg)'
- en: Memory profiler results for testing sub-strings of sequences of size 10,000
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 测试大小为10,000的序列的内存分析器结果
- en: For the sequence of size of 1,000, the memory usage increased by a paltry 1.4
    MB. For the sequence of size 10,000 it increased by 6.2 MB. Clearly these are
    not very significant numbers.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大小为1,000的序列，内存使用量增加了微不足道的1.4 MB。对于大小为10,000的序列，它增加了6.2 MB。显然，这些数字并不是非常显著的。
- en: So the test with memory profiler makes it clear that our algorithm, while being
    efficient on time performance, is also memory-efficient.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，使用内存分析器进行测试清楚地表明，尽管我们的算法在时间性能上效率高，但也具有高效的内存利用率。
- en: Other tools
  id: totrans-349
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他工具
- en: In this section, we will discuss a few more tools that will aid the programmer
    in debugging memory leaks and also enable him to visualize his objects and their
    relations.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论一些其他工具，这些工具将帮助程序员调试内存泄漏，并使其能够可视化其对象及其关系。
- en: Objgraph
  id: totrans-351
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Objgraph
- en: Objgraph (**object graph**) is a Python object visualization tool that makes
    use of the `graphviz` package to draw object reference graphs.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: Objgraph（**对象图**）是一个Python对象可视化工具，它利用`graphviz`包绘制对象引用图。
- en: It is not a profiling or instrumentation tool but can be used along with such
    tools to visualize object trees and references in complex programs while hunting
    for elusive memory leaks. It allows you to find out references to objects to figure
    out what references are keeping an object alive.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 它不是一个分析或检测工具，但可以与此类工具一起使用，以可视化复杂程序中的对象树和引用，同时寻找难以捉摸的内存泄漏。它允许您查找对象的引用，以找出是什么引用使对象保持活动状态。
- en: 'As with almost everything in the Python world, it is installable via `pip`:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 与Python世界中的几乎所有内容一样，它可以通过`pip`安装：
- en: '[PRE47]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: However objgraph is really useful only if it can generate graphs. Hence we need
    to install the `graphviz` package and the `xdot` tool.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，objgraph只有在能够生成图形时才真正有用。因此，我们需要安装`graphviz`包和`xdot`工具。
- en: 'In a Debian/Ubuntu system, you will install this as follows:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 在Debian/Ubuntu系统中，您可以按照以下步骤安装：
- en: '[PRE48]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Let''s look at a simple example of using `objgraph` to find out hidden references:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个使用`objgraph`查找隐藏引用的简单示例：
- en: '[PRE49]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: We have a class named `MyRefClass` with a single instances `ref` that is referred
    to by 100 instances of the class `C` created in a `for` loop. These are references
    that may cause memory leaks. Let us see how `objgraph` allows us to identify them.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个名为`MyRefClass`的类，其中有一个单一实例`ref`，由`for`循环中创建的100个`C`类的实例引用。这些是可能导致内存泄漏的引用。让我们看看`objgraph`如何帮助我们识别它们。
- en: 'When this piece of code is executed, it stops at the debugger (`pdb`):'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 当执行这段代码时，它会停在调试器（`pdb`）处：
- en: '[PRE50]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Note
  id: totrans-364
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The left side of the image has been cropped to show only the relevant part.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 图像的左侧已被裁剪，只显示相关部分。
- en: 'Next is the diagram generated by objgraph:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是objgraph生成的图表：
- en: '![Objgraph](../Images/image00429.jpeg)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
  zh: '![Objgraph](../Images/image00429.jpeg)'
- en: Objgraph back references visualization for the object ref'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: Objgraph对象引用的可视化
- en: The red box in the preceding diagram says **99 more references**, which means
    that it is showing one instance of class **C** and informing us there are 99 more
    like it – totaling to 100 instances of C, refer to the single object **ref**.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 前面图表中的红色框显示**99个更多的引用**，这意味着它显示了一个**C**类的实例，并告诉我们还有99个类似的实例 - 总共有100个C类的实例，引用了单个对象**ref**。
- en: In a complex program where we are unable to track object references that cause
    memory leaks, such reference graphs can be put to good use by the programmer.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个复杂的程序中，我们无法跟踪导致内存泄漏的对象引用，程序员可以利用这样的引用图。
- en: Pympler
  id: totrans-371
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pympler
- en: 'Pympler is a tool that can be used to monitor and measure the memory usage
    of objects in a Python application. It works on both Python 2.x and 3.x. It can
    be installed using `pip` as follows:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: Pympler是一个用于监视和测量Python应用程序中对象内存使用情况的工具。它适用于Python 2.x和3.x。可以使用`pip`安装如下：
- en: '[PRE51]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The documentation of pympler is rather lacking. However, it's well-known use
    is to track objects and print their actual memory usage via its `asizeof` module.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: Pympler的文档相当缺乏。但是，它的众所周知的用途是通过其`asizeof`模块跟踪对象并打印其实际内存使用情况。
- en: 'The following is our `sub_string` function modified to print the memory usage
    of the sequences dictionary (where it stores all the generated substrings):'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们修改后用于打印序列字典（其中存储了所有生成的子串）的内存使用情况的`sub_string`函数：
- en: '[PRE52]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'When running this for a sequence size of 10,000:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 当对大小为10,000的序列运行时：
- en: '[PRE53]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: The memory size of `5870408` bytes (or around 5.6 MB) is in line with what memory
    profiler reported (around 6 MB)
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '`5870408`字节（约5.6 MB）的内存大小与内存分析器报告的一致（约6 MB）'
- en: Pympler also comes with a package called `muppy` which allows to keep track
    of all objects in a program. This can be summarized with the `summary` package
    to print out the summary of memory usage of all objects (classified according
    to their types) in an application.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: Pympler还带有一个名为`muppy`的包，允许跟踪程序中的所有对象。这可以通过`summary`包总结应用程序中所有对象（根据其类型分类）的内存使用情况。
- en: 'Here is a report of our `sub_string` module run with n =10,000\. To do this,
    the execution part has to be modified as follows:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们使用n =10,000运行的`sub_string`模块的报告。为此，执行部分必须修改如下：
- en: '[PRE54]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The following shows the output that `pympler` summarizes at the end of the
    program:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: '![Pympler](../Images/image00430.jpeg)'
  id: totrans-384
  prefs: []
  type: TYPE_IMG
- en: Summary of memory usage classified by object type by pympler
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: Programming for performance – data structures
  id: totrans-386
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've looked at the definition of performance, measuring performance complexity,
    and the different tools for measuring program performance. We've also gained insights
    by profiling code for statistics, memory usage, and the like.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: We also saw a couple of examples of program optimization to improve the time
    performance of the code.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will take a look at common Python data structures and discuss
    what their best and worst performance scenarios are and also discuss some situations
    of where they are an ideal fit and where they may not be the best choice.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: Mutable containers – lists, dictionaries, and sets
  id: totrans-390
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Lists, dictionaries, and sets are the most popular and useful mutable containers
    in Python.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: Lists are appropriate for object access via a known index. Dictionaries provide
    a near constant time look-up for objects with known keys. Sets are useful to keep
    groups of items while dropping duplicates and finding their difference, intersection,
    union, and so on in near linear time.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: Let us look at each of these in turn.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: Lists
  id: totrans-394
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Lists provide a near constant time O(1) order for the following operations:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: '`get(index)` via the `[]` operator'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `append(item)` via the `.append` method
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, lists perform badly `(O(n))` in the following cases:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: Seeking an item via the `in` operator
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inserting at an index via the `.insert` method
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A list is ideal in the following cases:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: If you need a mutable store to keep different types or classes of items (heterogeneous).
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your search of objects involves getting the item by a known index.
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you don't have a lot of lookups via searching the list (**item in list**).
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If any of your elements are non-hashable. Dictionaries and sets require their
    entries to be hashable. So in this case, you almost default to using a list.
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you have a huge list – of, say, more than 100,000 items – and you keep finding
    that you search it for elements via the `in` operator, you should replace it with
    a dictionary.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, if you find that you keep inserting to a list instead of appending
    to it most of the time, you can think of replacing the list with `deque` from
    the `collections` module.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: Dictionaries
  id: totrans-408
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Dictionaries provide a constant time order for:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: Setting an item via a key
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting an item via a key
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deleting an item via a key
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, dictionaries take slightly more memory than lists for the same data.
    A dictionary is useful in the following situations:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: You don't care about the insertion order of the elements
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You don't have duplicate elements in terms of keys
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A dictionary is also ideal where you load a lot of data uniquely indexed by
    keys from a source (database or disk) in the beginning of the application and
    need quick access to them – in other words, a lot of random reads as against fewer
    writes or updates.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: Sets
  id: totrans-417
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The usage scenario of sets lies somewhere between lists and dictionaries. Sets
    are in implementation closer to dictionaries in Python – since they are unordered,
    don't support duplicate elements, and provide near O(1) time access to items via
    keys. They are kind of similar to lists in that they support the pop operation
    (even if they don't allow index access!).
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: Sets are usually used in Python as intermediate data structures for processing
    other containers – for operations such as dropping duplicates, finding common
    items across two containers, and so on.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: Since the order of set operations is exactly same as that of a dictionary, you
    can use them for most cases where a dictionary needs to be used, except that no
    value is associated to the key.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples include:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: Keeping heterogeneous, unordered data from another collection while dropping
    duplicates
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processing intermediate data in an application for a specific purpose – such
    as finding common elements, combining unique elements across multiple containers,
    dropping duplicates, and so on
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Immutable containers – tuples
  id: totrans-424
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Tuples are an immutable version of lists in Python. Since they are unchangeable
    after creation, they don't support any of the methods of list modification such
    as insert, append, and so on.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: Tuples have the same time complexity as when using the index and search (via
    **item in tuple**) as lists. However, they take much less memory overhead when
    compared to lists; the interpreter optimizes them more as they are immutable.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: 'Hence tuples can be used whenever there are use cases for reading, returning,
    or creating a container of data that is not going to be changed but requires iteration.
    Some examples are as follows:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: Row-wise data loaded from a data store that is going to have only read access.
    For example, results from a DB query, processed rows from reading a CSV file,
    and so on.
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Constant set of values that needs iteration over and over again. For example,
    a list of configuration parameters loaded from a configuration file.
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When returning more than one value from a function. In this case, unless one
    explicitly returns a list, Python always returns a tuple by default.
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When a mutable container needs to be a dictionary key. For example, when a list
    or set needs to be associated to a value as a dictionary key, the quick way is
    to convert it to a tuple.
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High performance containers – the collections module
  id: totrans-432
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The collection module supplies high performance alternatives to the built-in
    default container types in Python, namely `list`, `set`, `dict`, and `tuple`.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: 'We will briefly look at the following container types in the collections module:'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
- en: '`deque`: Alternative to a list container supporting fast insertions and pops
    at either ends'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`defaultdict`: Sub-class of `dict` that provides factory functions for types
    to provide missing values'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OrderedDict`: Sub-class of `dict` that remembers the order of insertion of
    keys'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Counter`: Dict sub-class for keeping count and statistics of hashable types'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Chainmap`: Class with a dictionary-like interface for keeping track of multiple
    mappings'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`namedtuple`: Type for creating tuple-like classes with named fields'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: deque
  id: totrans-441
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A deque or *double ended queue* is like a list but supports nearly constant
    (O(1)) time appends and pops from either side as opposed to a list, which has
    an O(n) cost for pops and inserts at the left.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: 'Deques also support operations such as rotation for moving `k` elements from
    back to front and reverse with an average performance of O(k). This is often slightly
    faster than the similar operation in lists, which involves slicing and appending:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: By a simple `timeit` measurement, you should find that deques have a slight
    performance edge over lists (about 10-15%), in the above example.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
- en: defaultdict
  id: totrans-446
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Default dicts are dict sub-classes that use type factories to provide default
    values to dictionary keys.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
- en: A common problem one encounters in Python when looping over a list of items
    and trying to increment a dictionary count is that there may not be any existing
    entry for the item.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if one is trying to count the number of occurrences of a word
    in a piece of text:'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-450
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: We are forced to write code like the preceding or a variation of it.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
- en: 'Another example is when grouping objects according to a key using a specific
    condition, for example, trying to group all strings with the same length to a
    dictionary:'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: A `defaultdict` container solves these problems elegantly by defining a type
    factory to supply the default argument for any key that is not yet present in
    the dictionary. The default factory type supports any of the default types and
    defaults to `None`.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
- en: 'For each type, its empty value is the default value. This means:'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-456
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The word-count code can then be rewritten as follows:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-458
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Similarly, for the code which groups strings by their length we can write this:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-460
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: OrderedDict
  id: totrans-461
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: OrderedDict is a sub-class of dict that remembers the order of the insertion
    of entries. It kind of behaves as a dictionary and list hybrid. It behaves like
    a mapping type but also has list-like behavior in remembering the insertion order
    plus supporting methods such as `popitem` to remove the last or first entry.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example:'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-464
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: You can compare and contrast how the dictionary changes the order around and
    how the `OrdredDict` container keeps the original order.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
- en: This allows a few recipes using the `OrderedDict` container.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
- en: Dropping duplicates from a container without losing the order
  id: totrans-467
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let us modify the cities list to include duplicates:'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-469
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: See how the duplicates are dropped but the order is preserved.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a Least Recently Used (LRU) cache dictionary
  id: totrans-471
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: An LRU cache gives preference to entries that are recently used (accessed) and
    drops those entries that are least used. This is a common caching algorithm used
    in HTTP caching servers such as Squid and in places where one needs to keep a
    limited size container that keeps recently accessed items preferentially over
    others.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we make use of the behavior of `OrderedDict`: when an existing key is
    removed and re-added, it is added at the end (the right side):'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  id: totrans-474
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Here is a demonstration.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  id: totrans-476
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Since a key `mumbai` was set first and never set again, it became the leftmost
    one and got dropped off.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-478
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Notice how the next candidate to drop off is `bangalore`, followed by `chennai`.
    This is because `chennai` was set once more after `bangalore` was set.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
- en: Counter
  id: totrans-480
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A counter is a subclass of a dictionary to keep a count of hashable objects.
    Elements are stored as dictionary keys and their counts get stored as the values.
    The `Counter` class is a parallel for multisets in languages such as C++ or Bag
    in languages like Smalltalk.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
- en: A counter is a natural choice for keeping the frequency of items encountered
    when processing any container. For example, a counter can be used to keep the
    frequency of words when parsing text or the frequency of characters when parsing
    words.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
- en: For example, both of the following code snippets perform the same operation
    but the counter one is less verbose and compact.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
- en: They both return the most common 10 words from the text of the famous Sherlock
    Holmes Novel, namely the "The Hound of Baskerville" from its gutenberg version
    online.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `defaultdict` container in the following code:'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE65]'
  id: totrans-486
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Using the `Counter` class in the following code:'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE66]'
  id: totrans-488
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: ChainMap
  id: totrans-489
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A `ChainMap` is a dictionary-like class that groups multiple dictionaries or
    similar mapping data structures together to create a single view that is updateable.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
- en: All of the usual dictionary methods are supported. Lookups search successive
    maps until a key is found.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
- en: The `ChainMap` class is a more recent addition to Python, having been added
    in Python 3.3.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
- en: When you have a scenario where you keep updating keys from a source dictionary
    to a target dictionary over and over again, a `ChainMap` class can work in your
    favor in terms of performance, especially if the number of updates is large.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some practical uses of a `ChainMap`:'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: A programmer can keep the `GET` and `POST` arguments of a web framework in separate
    dictionaries and keep the configuration updated via a single `ChainMap`.
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keeping multilayered configuration overrides in applications.
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Iterating over multiple dictionaries as a view when there are no overlapping
    keys.
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A `ChainMap` class keeps the previous mappings in its maps attribute. However,
    when you update a dictionary with mappings from another dictionary, the original
    dictionary state is lost. Here is a simple demonstration:'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE67]'
  id: totrans-499
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: namedtuple
  id: totrans-500
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A namedtuple is like a class with fixed fields. Fields are accessible via attribute
    lookups like a normal class but are also indexable. The entire namedtuple is also
    iterable like a container. In other words, a namedtuple behaves like a class and
    a tuple combined in one:'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  id: totrans-502
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Let''s create an instance of Employee:'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  id: totrans-504
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'We can iterate over the fields of the instance, as if it is an iterator:'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  id: totrans-506
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Once created, the `namedtuple` instance, like a tuple, is read-only:'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  id: totrans-508
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'To update values, the `_replace` method can be used. It returns a new instance
    with the specified keyword arguments replaced with new values:'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  id: totrans-510
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'A namedtuple is much more memory-efficient when compared to a class which has
    the same fields. Hence a namedtuple is very useful in the following scenarios:'
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
- en: A large amount of data needs to be loaded as read-only with keys and values
    from a store. Examples are loading columns and values via a DB query or loading
    data from a large CSV file.
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When a lot of instances of a class need to be created but not many write or
    set operations need to be done on the attributes. Instead of creating class instances,
    `namedtuple` instances can be created to save on memory.
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `_make` method can be used to load an existing iterable that supplies fields
    in the same order to return a `namedtuple` instance. For example, if there is
    an `employees.csv` file with the columns name, age, gender, title, and department
    in that order, we can load them all into a container of `namedtuples` using the
    following command line:'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE73]'
  id: totrans-515
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Probabilistic data structures – bloom filters
  id: totrans-516
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we conclude our discussion on the container data types in Python, let
    us take a look at an important probabilistic data structure named **Bloom Filter**.
    Bloom filter implementations in Python behave like containers, but they are probabilistic
    in nature.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
- en: A bloom filter is a sparse data structure that allows us to test for the presence
    of an element in the set. However, we can only positively be sure of whether an
    element is not there in the set – that is, we can assert only for true negatives.
    When a bloom filter tells us an element is there in the set, it might be there
    – in other words, there is a non-zero probability that the element may actually
    be missing.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
- en: Bloom filters are usually implemented as bit vectors. They work in a similar
    way to a Python dictionary in that they use hash functions. However, unlike dictionaries,
    bloom filters don't store the actual elements themselves. Also elements, once
    added, cannot be removed from a bloom filter.
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
- en: Bloom filters are used when the amount of source data implies an unconventionally
    large amount of memory if we store all of it without hash collisions.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python, the `pybloom` package provides a simple bloom filter implementation
    (however, at the time of writing, it doesn''t support Python 3.x, so the examples
    here are shown in Python 2.7.x):'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  id: totrans-522
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Let us write a program to read and index words from the text of `The Hound
    of Baskervilles`, which was the example we used in the discussion of the Counter
    data structure, but this time using a bloom filter:'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  id: totrans-524
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Executing this, we get the following output:'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  id: totrans-526
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Note
  id: totrans-527
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The words `holmes`, `watson`, `hound`, and `moor` are some of the most common
    in the story of *The Hound of Basekervilles*, so it is reassuring that the bloom
    filter finds these words. On the other hand, the word `queen` never appears in
    the text so the bloom filter is correct on that fact (true negative). The length
    of the words in the text is 62,154, out of which only 9,403 got indexed in the
    filter.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
- en: Let us try and measure the memory usage of the bloom filter as opposed to the
    Counter. For that we will rely on memory profiler.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
- en: 'For this test, we will rewrite the code using the `Counter` class as follows:'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  id: totrans-531
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'And the one using the bloom filter as follows:'
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  id: totrans-533
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Here is the output from running the memory profiler for the first one:'
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
- en: '![Probabilistic data structures – bloom filters](../Images/image00431.jpeg)'
  id: totrans-535
  prefs: []
  type: TYPE_IMG
- en: Memory usage by the Counter object when parsing the text of The Hound of the
    Basekervilles
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
- en: 'The following result is for the second one:'
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
- en: '![Probabilistic data structures – bloom filters](../Images/image00432.jpeg)'
  id: totrans-538
  prefs: []
  type: TYPE_IMG
- en: Memory usage by the Bloom filter for parsing text of The Hound of the Basekervilles
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
- en: The final memory usage is roughly the same at about 50 MB each. In the case
    of the Counter, nearly no memory is used when the Counter class is created but
    close to 0.7 MB is used when words are added to the counter.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
- en: However, there is a distinct difference in the memory growth pattern between
    both these data structures.
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
- en: In the case of the bloom filter, an initial memory of 0.16 MB is allotted to
    it upon creation. The addition of the words seems to add nearly no memory to the
    filter and hence to the program.
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
- en: 'So when should we use a bloom filter as opposed to, say, a dictionary or set
    in Python? Here are some general principles and real-world usage scenarios:'
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
- en: When you are fine with not storing the actual element itself but only interested
    in the presence (or absence) of the element. In other words, where your application
    use case relies more on checking the absence of data than its presence.
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the size of your input data is so large that storing each and every item
    in a deterministic data structure (as a dictionary or hashtable) in memory is
    not feasible. A bloom filter takes much less data in memory as opposed to a deterministic
    data structure.
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you are fine with a certain well-defined error rate of *false positives*
    with your dataset – let us say this is 5% out of 1 million pieces of data – you
    can configure a bloom filter for this specific error rate and get a data hit rate
    that will satisfy your requirements.
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Some real-world examples of using bloom filters are as follows:'
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
- en: '**Security testing**: Storing data for malicious URLs in browsers, for example'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bio-informatics**: Testing the presence of a certain pattern (a k-mer) in
    a genome'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To avoid storing URLs with just one hit in a distributed web caching infrastructure
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  id: totrans-551
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter was all about performance. At the start of the chapter, we discussed
    performance and SPE. We looked at the two categories of performance testing and
    diagnostic tools – namely, stress testing tools and profiling/instrumentation
    tools.
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
- en: We then discussed what performance complexity really means in terms of the Big-O
    notation and discussed briefly the common time orders of functions. We looked
    at the time taken by functions to execute and learned the three classes of time
    usage – namely `real`, `user`, and `sys` in POSIX systems.
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
- en: We moved on to measuring performance and time in the next section – starting
    with a simple context manager timer and moving on to more accurate measurements
    using the `timeit` module. We measured the time taken for certain algorithms for
    a range of input sizes. By plotting the time taken against the input size and
    superimposing it on the standard time complexity graphs, we were able to get a
    visual understanding of the performance complexity of functions. We optimized
    the common item problem from its O(n*log(n)) performance to O(n) and the plotted
    graphs of time usage confirmed this.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
- en: We then started our discussion on profiling code and saw some examples of profiling
    using the `cProfile` module. The example we chose was a prime number iterator
    returning the first `n` primes performing at O(n). Using the profiled data, we
    optimized the code a bit, making it perform better than O(n). We briefly discussed
    the `pstats` module and used its `Stats` class to read profile data and produce
    custom reports ordered by a number of available data fields. We discussed two
    other third-party profilers – the `liner_profiler` and the `memory_profiler`,
    which profile code line by line – and discussed the problem of finding sub-sequences
    among two sequences of strings, writing an optimized version of them, and measuring
    its time and memory usage using these profilers.
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
- en: Among other tools, we discussed objgraph and pympler – the former as a visualization
    tool to find relations and references between objects, helping to explore memory
    leaks, and the latter as a tool to monitor and report the memory usage of objects
    in the code and provide summaries.
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
- en: In the last section on Python containers, we looked at the best and worst use
    case scenarios of standard Python containers – such as list, dict, set, and tuple.
    We then studied high performance container classes in the collections module –
    `deque`, `defaultdict`, `OrderedDict`, `Counter`, `Chainmap`, and `namedtuple`,
    with examples and recipes for each. Specifically, we saw how to create an LRU
    cache very naturally using `OrderedDict`.
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
- en: Towards the end of the chapter, we discussed a special data structure called
    the bloom filter, which is very useful as a probabilistic data structure to report
    true negatives with certainty and true positives within a pre-defined error rate.
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss a close cousin of performance, scalability,
    where we will look at the techniques of writing scalable applications and the
    details of writing scalable and concurrent programs in Python.
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
