- en: Testing Your Serverless Microservice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we created a fully functional serverless data API using
    API Gateway, Lambda, and DynamoDB, and we deployed it to the AWS CLI. The testing
    we showed was performed in the AWS Management Console and browser, which is fine
    for small amounts of simple code development as a proof of concept, but is not
    recommended for development or production systems.
  prefs: []
  type: TYPE_NORMAL
- en: It is much more efficient for a developer to first develop and test locally,
    and it is essential for continuous delivery to have automated tests. This chapter
    is all about testing.
  prefs: []
  type: TYPE_NORMAL
- en: Testing could easily cover a whole book, but we will keep things very practical
    and focused on testing your serverless code and the data API we deployed in [Chapter
    3](559653f9-3f81-4443-badd-77796dceb0c0.xhtml), *Deploying Your Serverless Stack*.
    This will include unit testing, mocking, local debugging, integration testing,
    running the Lambda or serverless APIs with an HTTP server locally in a Docker
    container, and load testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Unit testing your Python Lambda code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running and debugging your AWS Lambda code locally
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integration testing using real test data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The AWS **Serverless Application Model** (**SAM**) CLI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading and end-to-end testing at scale
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strategies to reduce the API's latency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cleaning up
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unit testing your Python Lambda code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to look at why testing is important, as well as
    the sample data we can use for testing, unit testing, and mocking.
  prefs: []
  type: TYPE_NORMAL
- en: Why is testing important?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Think about the **collaboration and teamwork** taking place in large, distributed
    teams of developers in different countries, and imagine they want to collaborate
    on the same source code repository and check code changes at different times.
    It's very important for these teams to understand the code and be able to test
    it locally to see how it works, whether their changes will impact existing services,
    and whether the code is still working as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Testing is important to ensure we have **quality** in the delivery or user experience.
    By having lots of tests, you can identify defects early and fix them. For example,
    if there are major bugs detected, you could decide not to release the recent update
    and fix the issues before doing the release.
  prefs: []
  type: TYPE_NORMAL
- en: Another major point is **usability**. For example, your client might have performance
    or non-functional requirements. Imagine an e-commerce website, for example, where
    you could add items and would have to wait a whole minute for them to be added
    to the basket. In most cases, that would be unacceptable and the user would lose
    trust in the platform. Ideally, you would have a testing process to make sure
    that the latency is still low and the website is responsive. Other examples that
    require testing would be features that are not working as expected or user interface
    defects that prevent the users from completing the tasks they want to do.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to have **shorter release cycles**. Using automation, you can
    run a thousand tests automatically and consistently, without needing a human to
    test different parts of the site manually, test the APIs manually, or rigorously
    inspect the code before any release. Before every release into production, you
    run those thousand tests, making you much more confident that everything is working
    as expected, and if you do spot an issue those thousand tests missed in production,
    you can fix it and add a new test for that scenario too.
  prefs: []
  type: TYPE_NORMAL
- en: Types of testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing can be done manually, as we have done with the AWS Management Console,
    which is prone to error and not scalable. Generally, tests are automated using
    test suites, which are written in advance and are essential for continuous integration
    and continuous delivery.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many definitions and types of software testing available; it could
    take a whole book to cover them all. Here, we will focus on the three main ones
    that are relevant for our serverless stacks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Unit testing:** The low-level testing of individual software modules in isolation,
    typically done by the developers and used in **test-driven development** (**TDD**).
    These types of tests are usually quick to execute.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integration testing**: Verifies that all combined services after integration
    are working correctly. These are generally more expensive to run as many services
    need to be running.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Load testing**: This is non-functional testing used to check how the system
    performs under a heavy load. It is sometimes also called performance or stress
    testing as it helps to understand the availability and reliability of a platform.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unit testing Lambda Python code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is not easy to debug in AWS Management Console; it's much more constructive
    to debug code locally and later automate the process.
  prefs: []
  type: TYPE_NORMAL
- en: We know from previous chapters that the Lambda event source is an API Gateway
    `GET` request. As we are only looking at a subset of the data, this full JSON
    payload can be simulated with a few lines of Python code too.
  prefs: []
  type: TYPE_NORMAL
- en: The sample test data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here, we have a test case with a `setUp()` method that is run once at the start
    of the test suite and a `tearDown()` method that is run at the end.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a subset of the contents linked to the test setup and teardown at the
    top of `serverless-microservice-data-api/test/test_dynamo_get.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'I created four different JSON Python dictionaries:'
  prefs: []
  type: TYPE_NORMAL
- en: '`self.validJsonDataNoStartDate`: A valid `GET` request with no `StartDate`
    filter'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`self.validJsonDataStartDate`: A valid `GET` request with a `StartDate` filter'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`self.invalidJsonUserIdData`: An invalid `UserId` that is not a number'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`self.invalidJsonData`: Invalid JSON that cannot be parsed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The unit test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are the units tests that can be found in the middle of `serverless-microservice-data-api/test/test_dynamo_get.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'I''m using a prefix of `test` so Python test suites can automatically detect
    them as unit tests, and I''m using the triplet unit test naming convention for
    the test methods: the method name, the state under test, and the expected behavior.
    The test methods are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`test_validparameters_parseparameters_pass()`: Checks that the parameters are
    parsed correctly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`test_emptybody_parsebody_nonebody()`: We are not using a body in the `GET`
    method, so we want to make sure that it still works if none is provided.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`test_invalidjson_getrecord_notfound404()`: Check how the Lambda will react
    with an invalid JSON payload.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`test_invaliduserid_getrecord_invalididerror()`: Check how the Lambda will
    react to an invalid non-number `userId`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The preceding does not query DynamoDB for the records. If we want to do so,
    we should have DynamoDB running, use the new DynamoDB Local ([https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.html](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.html)),
    or we can mock the DynamoDB calls, which is what we will look at next.
  prefs: []
  type: TYPE_NORMAL
- en: Mocking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is a Python AWS mocking framework called Moto ([http://docs.getmoto.org/en/latest/](http://docs.getmoto.org/en/latest/)),
    but I prefer to use a generic one called `mock`, which is much more widely supported
    in the Python community and from Python 3.3 is included in the Python standard
    library.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following mocking code can be found at the bottom of `serverless-microservice-data-api/test/test_dynamo_get.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The key observations from this code are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`@mock.patch.object()` is a decorator for the `query_by_partition_key()` or
    `query_by_partition_and_sort_key()` method we are mocking from the `DynamoRepository()`
    class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`test_validid_checkstatus_status200()`: We mock the calls to `query_by_partition_key()`.
    If the query is valid, we get a `''200''` status code back.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`test_validid_getrecords_validparamcall()`: We mock the calls to `query_by_partition_key()`
    and check the method is called with the correct parameters. Note that don''t need
    to check that the lower-level `boto3` `self.db_table.query()` method works.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`test_validid_getrecordsdate_validparamcall()`: We mock the calls to `query_by_partition_and_sort_key()`
    and check that the method is called with the correct parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You are not here to test existing third-party libraries or Boto3, but your code
    and integration with them. Mocking allows you to replace parts of the code under
    test with mock objects and make an assertion about the method or attributes.
  prefs: []
  type: TYPE_NORMAL
- en: Running the unit test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have all the test suites, rather than run them in your IDE, such
    as PyCharm, you can run the tests from the root folder using the following bash
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '`unittest` automatically detects that all of the test files must be modules
    or packages importable from the top-level directory of the project. Here, we just
    want to run the tests from the test folder that begin with the `test_` prefix.'
  prefs: []
  type: TYPE_NORMAL
- en: 'I have created a shell script under `serverless-microservice-data-api/bash/apigateway-lambda-dynamodb/unit-test-lambda.sh`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Code coverage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We won't discuss it in depth, but code coverage is another important measure
    used in software engineering. Code coverage measures the degree of code that your
    test suites cover. The main idea is that the higher the coverage percentage, the
    more code is covered by tests, so the less likely you are to create undetected
    bugs and the service should behave as intended. These reports can help developers
    come up with additional tests or scenarios to increase the coverage percentage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Test-coverage-related Python packages include `coverage`, `nose`, and the more
    recent `nose2`, which can provide coverage reports. For example, you can run the
    following to get a test-coverage analysis report of your Lambda code with `nose`
    or `nose2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: When we commence with writing our own tests, we have an option to use an additional
    set of tools to do so. Such tools are known as code coverage tools. Codecov and
    Coveralls are examples of such tools. When we want to analyze the code that is
    written via hosting services such as GitHub, these tools are very helpful as they
    provided a complete breakdown of whether the lines are tested.
  prefs: []
  type: TYPE_NORMAL
- en: Running and debugging your AWS Lambda code locally
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes you want to simulate an API Gateway payload with a local Lambda against
    a real instance of remote DynamoDB hosted in AWS. This allows you to debug and
    build up unit tests with real data. In addition, we will see how these can later
    be used in the integration test.
  prefs: []
  type: TYPE_NORMAL
- en: Batch-loading data into DynamoDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will first discuss how to batch-load data into DynamoDB from a **comma-separated
    values** (**CSV**) file called `sample_data/dynamodb-sample-data.txt`. Rather
    than insert an individual statement for each item, this is a much more efficient
    process, as the data file is decoupled from the Python code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Add another method, called `update_dynamo_event_counter()`, that updates DynamoDB
    records using the `DynamoRepository` class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the contents of the `serverless-microservice-data-api/aws_dynamo/dynamo_insert_items_from_file.py` Python
    script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Here, we have a `DynamoRepository` class that instantiates a connection to DynamoDB
    in `__init__()` and an `update_dynamo_event_counter()` method that updates the
    DynamoDB records if they exist, or adds a new one if they don't using the passed-in
    parameters. This is done in one atomic action.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the second half of the `serverless-microservice-data-api/aws_dynamo/dynamo_insert_items_from_file.py` Python
    script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This Python code opens the CSV, extracts the header row, and parses each row
    while writing it to the DynamoDB table called `user-visits-sam`.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have loaded some data rows into the DynamoDB table, we will query
    the table by debugging a local Lambda function.
  prefs: []
  type: TYPE_NORMAL
- en: Running the Lambda locally
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here is a full example API Gateway request, `serverless-microservice-data-api/sample_data/request-api-gateway-valid-date.json`,
    that a proxy Lambda function would receive as an event. These can be generated
    by printing the real API Gateway JSON event, which the Lambda gets as an event
    source into CloudWatch logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Rather than relying on another third-party framework for local debugging (such
    as the SAM CLI), you can debug a Lambda function directly by calling it with the
    JSON `Dict` event. This means that you don't need any additional libraries to
    run and it's native Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'The contents of `serverless-microservice-data-api/test/run_local_api_gateway_lambda_dynamo.py`
    are an example of debugging a Lambda function locally with services such as DynamoDB
    in AWS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We open the sample `GET` file, parse the JSON into `Dict`, and then pass it
    as an argument to `lambda_query_dynamo.lambda_handler()`. As we have not mocked
    DynamoDB, it will query the table specified in the `table_name = ''user-visits-sam''` Lambda
    function. It will then capture the output response, which could look like the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The body is the same as we saw in the browser in [Chapter 3](559653f9-3f81-4443-badd-77796dceb0c0.xhtml),
    *Deploying Your Serverless Stack*. As such, you can debug different integration
    scenarios directly with real data and build more complete test suites as you step
    though the Lambda code with real data.
  prefs: []
  type: TYPE_NORMAL
- en: Integration testing using real test data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we understand the real test data, we will look at how we can test
    a deployed Lambda function. First, you will need to install and set up the AWS
    CLI and configure the AWS Credentials as shown at the end of [Chapter 1](669eac03-68f5-4097-83fb-0f0ecce5ef42.xhtml),
    *Serverless Microservices Architectures and Patterns*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We will redeploy the serverless microservice stack we deployed in [Chapter
    3](559653f9-3f81-4443-badd-77796dceb0c0.xhtml), *Deploying Your Serverless Stack*,
    so that we can test it. Use the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This will rebuild the Lambda ZIP package as the code if there have been any
    changes. Then it will package and deploy the code and SAM configuration. Finally,
    it will create the API Gateway, Lambda function, and DynamoDB table.
  prefs: []
  type: TYPE_NORMAL
- en: For testing, we will be using the AWS CLI, which can invoke all of the AWS-managed
    services. Here we are interested in the `<code>lambda</code>` ([https://docs.aws.amazon.com/cli/latest/reference/lambda/index.html](https://docs.aws.amazon.com/cli/latest/reference/lambda/index.html))
    and `<code>apigateway</code>` ([https://docs.aws.amazon.com/cli/latest/reference/apigateway/index.html](https://docs.aws.amazon.com/cli/latest/reference/apigateway/index.html))
    services.
  prefs: []
  type: TYPE_NORMAL
- en: Testing that a Lambda has been deployed correctly
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To test a deployed Lambda, you can run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'To automate it, we can put the following code into a shell script, `serverless-microservice-data-api/bash/apigateway-lambda-dynamodb/invoke-lambda.sh`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: We invoke the Lambda, but also check the response given in the `outputfile.tmp`
    file using the `grep` command. We return an exit code of `1` if an error is detected,
    and `0` otherwise. This allows you to chain logic when involved by other tools
    or by CI/CD steps.
  prefs: []
  type: TYPE_NORMAL
- en: Testing that API Gateway has been deployed correctly
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We also want to be able to test that the serverless microservice API is working
    correctly after it is deployed. I use a mix of Python and bash to make it easier.
  prefs: []
  type: TYPE_NORMAL
- en: 'A Python script called `serverless-microservice-data-api/bash/apigateway-lambda-dynamodb/get_apigateway_endpoint.py`
    is first used to query AWS API Gateway to get the full endpoint and return a code
    `0` if it succeeds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Then we use a shell script to call the Python script. The Python script returns
    the API endpoint, which is used in the curl with the sample `GET` request. We
    then look to see whether we get a valid status code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the full script for `serverless-microservice-data-api/bash/apigateway-lambda-dynamodb/curl-api-gateway.sh`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Having these scripts set up in this way allows us to easily automate these integrations
    tests.
  prefs: []
  type: TYPE_NORMAL
- en: '**Functions as a Service** (**FaaS**) is still a relatively new area. There
    are still many discussions on the types of integration tests that should be used.
    One view is that we should do the full suite of testing in a different AWS account,
    especially the ones that would write or update a data store, such as `POST` or
    `PUT` requests.'
  prefs: []
  type: TYPE_NORMAL
- en: I've included `--profile` and `aws_account_id` if you want to do this. In addition,
    with API Gateway, you can use a wide range of test suites that already exist around
    the HTTP endpoints, but testing other AWS services integration with Lambdas, such
    as objects being created in S3 that trigger a Lambda, needs a little bit more
    work and thought. In my view, serverless integration tests are still less mature,
    but I have already shown how they can be achieved by invoking the Lambda function
    directly with AWS CLI and Lambda with a JSON event source payload or invoking
    the API Gateway endpoint directly with a `curl` command.
  prefs: []
  type: TYPE_NORMAL
- en: Next we will look at how the SAM CLI can also be used for local testing.
  prefs: []
  type: TYPE_NORMAL
- en: The AWS Serverless Application Model CLI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will walk through different features of SAM Local with
    fully-working examples. For local testing, you can use Python and bash like I
    have shown or you can also use the SAM CLI ([https://github.com/awslabs/aws-sam-cli](https://github.com/awslabs/aws-sam-cli)),
    which at the time of writing is still in beta. It uses Docker and is based on
    open source `docker-lambda` ([https://github.com/lambci/docker-lambda](https://github.com/lambci/docker-lambda))
    Docker images. If you are using Windows 10 Home, I recommend you upgrade to Pro
    or Enterprise as it''s harder to get Docker working on the Home edition. There
    are also some hardware requirements, such as virtualization, to be aware of. We
    need to perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Install the AWS CLI ([https://docs.aws.amazon.com/cli/latest/userguide/installing.html](https://docs.aws.amazon.com/cli/latest/userguide/installing.html)).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install Docker CE ([https://docs.docker.com/install/](https://docs.docker.com/install/)).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install the AWS SAM CLI ([https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-install.html](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-install.html)).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For Linux, you can run the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: For Windows, you can install AWS SAM CLI using an MSI.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a new SAM Python 3.6 project, `sam-app`, and `docker pull` the images
    (this should happen automatically but I needed to do `pull` to get it to work):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Invoke the following function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'You will get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This can be used to add automated testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Start the local Lambda endpoint:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: This starts a Docker container that emulates AWS Lambda with an HTTP server
    locally, which you can use to automate the testing of your Lambda functions from
    the AWS CLI or Boto3.
  prefs: []
  type: TYPE_NORMAL
- en: 'Start an API and test it using the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: This starts a Docker container with an HTTP server locally, which you can use
    to automate the testing of the API you can use with `curl`, Postman, or your web
    browser.
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to generate sample events is to print out the event from a Lambda,
    and copy it from CloudWatch logs (my preference). Another way is to use `sam local`,
    which can generate some examples events. For example, you can run the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Personally, I haven't used the SAM CLI extensively as it is very new, needs
    Docker installed, and is still in beta. But it does look promising, and as another
    tool to test your serverless stack, it's useful that it can simulate a Lambda
    in Docker container that exposes an endpoint, and I expect more features to be
    added in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps less usefully, it also wraps some of the existing command's serverless
    package and deployment commands as an alias for the CloudFormation ones. I think
    this is done to keep them all in one place.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of the SAM CLI `package` and `deploy` commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'CloudFormation with SAM to `package` and `deploy` commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Loading and end-to-end testing at scale
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, we are going to take a look at Locust, which is a Python tool for performance
    and load testing. Then we are going to talk about strategies to reduce the API's
    latency and improve the response time of the API, and using Locust will show us
    the performance improvements.
  prefs: []
  type: TYPE_NORMAL
- en: Load testing your serverless microservice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, you need to have a serverless microservice stack running with `./build-package-deploy-lambda-dynamo-data-api.sh`,
    and have loaded data into the DynamoDB table using the `python3 dynamo_insert_items_from_file.py` Python
    script.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then install Locust, if it hasn''t already been installed with the other packages
    in `requirements.txt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Locust ([https://docs.locust.io](https://docs.locust.io)) is an easy-to-use
    load-testing tool with a web metrics and monitoring interface. It allows you to
    define user behavior using Python code and can be used to simulate millions of
    users over multiple machines.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use Locust, you first need to create a Locust Python file where you define
    the Locust tasks. The `HttpLocust` class adds a client attribute that is used
    to make the HTTP request. A `TaskSet` class defines a set of tasks that a Locust
    user will execute. The `@task` decorator declares the tasks for `TaskSet`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: To test the `GET` method with different resources and parameters, we are selecting
    three different paths randomly from a paths list, where one of the IDs does not
    exist in DynamoDB. The main idea is that we could easily scale this out to simulate
    millions of different queries if we had loaded their corresponding rows from a
    file into DynamoDB. Locust supports much more complex behaviors, including processing
    responses, simulating user logins, sequencing, and event hooks, but this script
    is a good start.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run Locust, we need to get the API Gateway ID, which looks like `abcdefgh12`,
    to create the full hostname used for load testing. Here, I wrote a Python script
    called `serverless-microservice-data-api/bash/apigateway-lambda-dynamodbget_apigateway_id.py`
    that can do so based on the API name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following commands to launch Locust:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, I also have this `locust` run commands as a shell script you
    can run under the `test` folder `serverless-microservice-data-api/bash/apigateway-lambda-dynamodb/run_locus.sh`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'You should now see Locust start in the Terminal and perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to `http://localhost:8089/` in your web browser to access the Locust
    web-monitoring and -testing interface.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the Start New Locust swarm, enter the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`10` for **Number of users** to simulate'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`5` for Hatch rate (users spawned/second)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leave the tool running on the Statistics tab for a few minutes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will get something like this in the Statistics tab:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4c3715e8-f782-4920-bab7-04b091154bb0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And on the Charts tab, you should get something similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/43fbaf5b-6abd-45ec-bd3f-4e1f816cdc5d.png)'
  prefs: []
  type: TYPE_IMG
- en: In the Response Times (ms) chart, the orange line represents the 95^(th) percentile,
    and green is for the median response times.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some observations about the preceding charts:'
  prefs: []
  type: TYPE_NORMAL
- en: The maximum request time is 2,172 milliseconds or about 2.1 seconds, which is
    really slow—this is linked to what is known as a cold start, which is the slower
    way to first launch a Lambda.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The number of fails also goes up after about a minute—this is because DynamoDB
    permits some burst reads before it starts to throttle the read requests. If you
    log onto the AWS Management Console and look at the DynamoDB table metrics, you
    will see that this is happening:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/4704d163-b694-4510-ba67-6a57890ee1a7.png)'
  prefs: []
  type: TYPE_IMG
- en: Strategies to reduce the API's latency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are many strategies to reduce latency. We will look at two, both of which
    are set in the SAM template:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Increasing the Lambda RAM size**: Currently, it is set to the minimum of
    128 MB'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Increasing the DynamoDB Read Capacity**: Currently, it is set to the smallest
    value of 1 unit'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What I really like about DynamoDB is that you can change the capacity per table,
    and change the write capacity independently of the read capacity. This is very
    interesting and cost-effective for me in read-heavy use cases, where I can set
    the read capacity higher than the write capacity. There are even options to have
    the table autoscale based on the read/write utilization, or have the capacity
    purely based **on demand**, where you pay per read/write request.
  prefs: []
  type: TYPE_NORMAL
- en: We will start by increasing the DynamoDB read capacity for the table from 1
    to 500 read units (keep the write capacity at 1 units). The cost was $0.66/month,
    but it will now increase to $55.24/month.
  prefs: []
  type: TYPE_NORMAL
- en: 'Edit the `lambda-dynamo-data-api.yaml` SAM YAML template file and increase `ReadCapacityUnits`
    from `1` to `500`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Run `./build-package-deploy-lambda-dynamo-data-api.sh` to deploy the serverless
    stack with the DynamoDB table changes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now run Locust again with 10 users with a hatch rate of 5:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c7010d83-294f-4e89-b8c5-a71631f1822e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And on the Charts tab, you should get something similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5820f3fb-b465-4722-8e28-596a7a4c6559.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here are some observations about the preceding charts:'
  prefs: []
  type: TYPE_NORMAL
- en: There are zero faults
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The average response time is 64 milliseconds, which is excellent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We get these results because the DynamoDB table read capacity was increased,
    that is, the requests are no longer getting throttled.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now increase the RAM available in the Lambda function:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Modify the `lambda-dynamo-data-api.yaml` SAM YAML file by changing MemorySize:
    128 to MemorySize: 1536.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run `./build-package-deploy-lambda-dynamo-data-api.sh` to deploy the serverless
    stack with the Lambda RAM changes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here are some observations that we''ve made the preceding changes:'
  prefs: []
  type: TYPE_NORMAL
- en: There are zero faults
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The average response time is 60 milliseconds, which is slightly better, especially
    considering this is a round trip of API Gateway to Lambda to DynamoDB and back
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With 100 users with a hatch rate of 10, we get the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: There are zero faults
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The average response time is 66 milliseconds, with a max of 1,057 milliseconds
    at the start of the load test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With 250 users with a hatch rate of 50, we get the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: There are zero faults
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The average response time is 81 ms, with a max of 1,153 milliseconds at the
    start of the load test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can test with a higher number of concurrent users as well, such as 1,000,
    and it will still work without faults even if the response time will be much higher
    to due to other bottlenecks. If you want to scale out further, I recommend you
    consider a different architecture. It is still impressive to have a serverless
    microservice scale up so easily, with just a couple of parameter changes in a
    config file!
  prefs: []
  type: TYPE_NORMAL
- en: This gives you a very good idea of how you can reduce the latency of your API.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Run the following shell script with `./delete-stack.sh` to delete the serverless
    stack:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored many types of testing, including unit tests with
    mocks, integration testing with Lambda and API Gateway, debugging a Lambda locally,
    making a local endpoint available, and load testing. This is something that we
    will build upon in the rest of this book.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at serverless, distributed data management
    patterns and architectures that you can apply within your organization.
  prefs: []
  type: TYPE_NORMAL
