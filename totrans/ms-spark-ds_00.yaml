- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The purpose of data science is to transform the world using data, and this goal
    is mainly achieved through disrupting and changing real processes in real industries.
    To operate at that level we need to be able to build data science solutions of
    substance; ones that solve real problems, and which can run reliably enough for
    people to trust and act upon.
  prefs: []
  type: TYPE_NORMAL
- en: 'This book explains how to use Spark to deliver production grade data science
    solutions that are innovative, disruptive, and reliable enough to be trusted.
    Whilst writing this book it was the authors’ intention to deliver a work that
    transcends the traditional cookbook style: providing not just examples of code,
    but developing the techniques and mind-set that are needed to explore content
    like a master; as they say, *Content is King*! Readers will notice that the book
    has a heavy emphasis on news analytics, and occasionally pulls in other datasets
    such as Tweets and financial data. This emphasis on news is not an accident; much
    effort has been spent on trying to focus on datasets that offer context at a global
    scale.'
  prefs: []
  type: TYPE_NORMAL
- en: The implicit problem that this book is dedicated to is the lack of data offering
    proper context around how and why people make decisions. Often, directly accessible
    data sources are very focused on problem specifics and, as a consequence, can
    be very light on broader datasets offering the behavioral context needed to really
    understand what’s driving the decisions that people make.
  prefs: []
  type: TYPE_NORMAL
- en: Considering a simple example where website users’ key information such as age,
    gender, location, shopping behavior, purchases and so on are known, we might use
    this data to recommend products based on what others “like them” have been buying.
  prefs: []
  type: TYPE_NORMAL
- en: But to be exceptional, more context is required as to why people behave as they
    do. When news reports suggest a massive Atlantic hurricane is approaching the
    Florida coastline, and could reach the coast in say 36 hours, perhaps we should
    be recommending products people might need. Items such as USB enabled battery
    packs for keeping phones charged, candles, flashlights, water purifiers, and the
    like. By understanding the context in which decisions are being made, we can conduct
    better science.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, whilst this book certainly contains useful code and, in many cases,
    unique implementations, it further dives deep into the techniques and skills required
    to truly master data science; some of which are often overlooked or not considered
    at all. Drawing on many years of commercial experience, the authors have leveraged
    their extensive knowledge to bring the real, and exciting world of data science
    to life.
  prefs: []
  type: TYPE_NORMAL
- en: What this book covers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Chapter 1](ch01.xhtml "Chapter 1.  The Big Data Science Ecosystem"), *The
    Big Data Science Ecosystem*, this chapter is an introduction to an approach and
    accompanying ecosystem for achieving success with data at scale. It focuses on
    the data science tools and technologies that will be used in later chapters as
    well as introducing the environment and how to configure it appropriately. Additionally
    it explains some of the non-functional considerations relevant to the overall
    data architecture and long-term success.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 2](ch02.xhtml "Chapter 2. Data Acquisition"), *Data Acquisition*,
    as a data scientist, one of the most important tasks is to accurately load data
    into a data science platform. Rather than having uncontrolled, ad hoc processes,
    this chapter explains how a general data ingestion pipeline in Spark can be constructed
    that serves as a reusable component across many feeds of input data.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 3](ch03.xhtml "Chapter 3. Input Formats and Schema"), *Input Formats
    and Schema*, this chapter demonstrates how to load data from its raw format onto
    different schemas, therefore enabling a variety of different kinds of downstream
    analytics to be run over the same data. With this in mind, we will look at the
    traditionally well-understood area of data schemas. We will cover key areas of
    traditional database modeling and explain how some of these cornerstone principles
    are still applicable to Spark today. In addition, whilst honing our Spark skills
    we will analyze the GDELT data model and show how to store this large dataset
    in an efficient and scalable manner.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 4](ch04.xhtml "Chapter 4. Exploratory Data Analysis"), *Exploratory
    Data Analysis*, a common misconception is that an EDA is only for discovering
    the statistical properties of a dataset and providing insights about how it can
    be exploited. In practice, this isn’t the full story. A full EDA will extend that
    idea, and include a detailed assessment of the “feasibility of using this Data
    Feed in production.” It requires us to also understand how we would specify a
    production grade data loading routine for this dataset, one that might potentially
    run in a “lights out mode” for many years. This chapter offers a rapid method
    for doing Data Quality assessment using a “data profiling” technique to accelerate
    the process.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 5](ch05.xhtml "Chapter 5. Spark for Geographic Analysis"), *Spark
    for Geographic Analysis*, geographic processing is a powerful new use case for
    Spark, and this chapter demonstrates how to get started. The aim of this chapter
    is to explain how Data Scientists can process geographic data, using Spark, to
    produce powerful map based views of very large datasets. We demonstrate how to
    process spatio-temporal datasets easily via Spark integrations with Geomesa, which
    helps turn Spark into a sophisticated geographic processing engine. The chapter
    later leverages this spatio-temporal data to apply machine learning with a view
    to predicting oil prices.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 6](ch06.xhtml "Chapter 6. Scraping Link-Based External Data"), *Scraping
    Link-Based External Data*, this chapter aims to explain a common pattern for enhancing
    local data with external content found at URLs or over APIs, such as GDELT and
    Twitter. We offer a tutorial using the GDELT news index service as a source of
    news URLS, demonstrating how to build a web scale News Scanner that scrapes global
    breaking news of interest from the internet. We further explain how to use the
    specialist web-scraping component in a way that overcomes the challenges of scale,
    followed by the summary of this chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 7](ch07.xhtml "Chapter 7. Building Communities"), *Building Communities*,
    this chapter aims to address a common use case in data science and big data. With
    more and more people interacting together, communicating, exchanging information,
    or simply sharing a common interest in different topics, the entire world can
    be represented as a Graph. A data scientist must be able to detect communities,
    find influencers / top contributors, and detect possible anomalies.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 8](ch08.xhtml "Chapter 8. Building a Recommendation System"), *Building
    a Recommendation System*, if one were to choose an algorithm to showcase data
    science to the public, a recommendation system would certainly be in the frame.
    Today, recommendation systems are everywhere; the reason for their popularity
    is down to their versatility, usefulness and broad applicability. In this chapter,
    we will demonstrate how to recommend music content using raw audio signals.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 9](ch09.xhtml "Chapter 9.  News Dictionary and Real-Time Tagging System"),
    *News Dictionary and Real-Time Tagging System*, while a hierarchical data warehouse
    stores data in files of folders, a typical Hadoop based system relies on a flat
    architecture to store your data. Without a proper data governance or a clear understanding
    of what your data is all about, there is an undeniable chance of turning data
    lakes into swamps, where an interesting dataset such as GDELT would be nothing
    more than a folder containing a vast amount of unstructured text files. In this
    chapter, we will be describing an innovative way of labeling incoming GDELT data
    in a non-supervised way and in near real time.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 10](ch10.xhtml "Chapter 10. Story De-duplication and Mutation"), *Story
    De-duplication and Mutation*, in this chapter, we de-duplicate and index the GDELT
    database into stories, before tracking stories over time and understanding the
    links between them, how they may mutate and if they could lead to any subsequent
    events in the near future. Core to this chapter is the concept of Simhash to detect
    near duplicates and building vectors to reduce dimensionality using Random Indexing.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 11](ch11.xhtml "Chapter 11. Anomaly Detection on Sentiment Analysis"),
    *Anomaly Detection and Sentiment Analysis*, perhaps the most notable occurrence
    of the year 2016 was the tense US presidential election and its eventual outcome:
    the election of President Donald Trump, a campaign that will long be remembered;
    not least for its unprecedented use of social media and the stirring up of passion
    among its users, most of whom made their feelings known through the use of hashtags.
    In this chapter, instead of trying to predict the outcome itself, we will aim
    to detect abnormal tweets during the US election using a real-time Twitter feed.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 12](ch12.xhtml "Chapter 12. TrendCalculus"), *TrendCalculus*, long
    before the concept of “what’s trending” became a popular topic of study by data
    scientists, there was an older one that is still not well served by data science;
    it is that of Trends. Presently, the analysis of trends, if it can be called that,
    is primarily carried out by people “eyeballing” time series charts and offering
    interpretations. But what is it that people’s eyes are doing? This chapter describes
    an implementation in Apache Spark of a new algorithm for studying trends numerically:
    TrendCalculus.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 13](ch13.xhtml "Chapter 13. Secure Data"), *Secure Data*, throughout
    this book we visit many areas of data science, often straying into those that
    are not traditionally associated with a data scientist’s core working knowledge.
    In this chapter we will visit another of those often overlooked fields, Secure
    Data; more specifically, how to protect your data and analytic results at all
    stages of the data life cycle. Core to this chapter is the construction of a commercial
    grade encryption codec for Spark.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 14](ch14.xhtml "Chapter 14. Scalable Algorithms"), *Scalable Algorithms*,
    in this chapter we learn about why sometimes even basic algorithms, despite working
    at small scale, will often fail in “big data”. We’ll see how to avoid issues when
    writing Spark jobs that run over massive Datasets and will learn about the structure
    of algorithms and how to write custom data science analytics that scale over petabytes
    of data. The chapter features areas such as: parallelization strategies, caching,
    shuffle strategies, garbage collection optimization and probabilistic models;
    explaining how these can help you to get the most out of the Spark paradigm.'
  prefs: []
  type: TYPE_NORMAL
- en: What you need for this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Spark 2.0 is used throughout the book along with Scala 2.11, Maven and Hadoop.
    This is the basic environment required, there are many other technologies used
    which are introduced in the relevant chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We presume that the data scientists reading this book are knowledgeable about
    data science, common machine learning methods, and popular data science tools,
    and have in the course of their work run proof of concept studies, and built prototypes.
    We offer a book that introduces advanced techniques and methods for building data
    science solutions to this audience, showing them how to construct commercial grade
    data products.
  prefs: []
  type: TYPE_NORMAL
- en: Conventions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this book, you will find a number of text styles that distinguish between
    different kinds of information. Here are some examples of these styles and an
    explanation of their meaning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Code words in text, database table names, folder names, filenames, file extensions,
    pathnames, dummy URLs, user input, and Twitter handles are shown as follows: "The
    next lines of code read the link and assign it to the to the `BeautifulSoup` function."'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Any command-line input or output is written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**New terms** and **important words** are shown in bold. Words that you see
    on the screen, for example, in menus or dialog boxes, appear in the text like
    this: "In order to download new modules, we will go to **Files** | **Settings**
    | **Project Name** | **Project Interpreter**."'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Warnings or important notes appear in a box like this.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Tips and tricks appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Reader feedback
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome. Let us know what you think about
    this book-what you liked or disliked. Reader feedback is important for us as it
    helps us develop titles that you will really get the most out of. To send us general
    feedback, simply e-mail feedback@packtpub.com, and mention the book's title in
    the subject of your message. If there is a topic that you have expertise in and
    you are interested in either writing or contributing to a book, see our author
    guide at [www.packtpub.com/authors](http://www.packtpub.com/authors).
  prefs: []
  type: TYPE_NORMAL
- en: Customer support
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you are the proud owner of a Packt book, we have a number of things
    to help you to get the most from your purchase.
  prefs: []
  type: TYPE_NORMAL
- en: Downloading the example code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can download the example code files for this book from your account at [http://www.packtpub.com](http://www.packtpub.com).
    If you purchased this book elsewhere, you can visit  [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files e-mailed directly to you.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can download the code files by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Log in or register to our website using your e-mail address and password.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hover the mouse pointer on the **SUPPORT** tab at the top.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on **Code Downloads & Errata**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the name of the book in the **Search** box.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the book for which you're looking to download the code files.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose from the drop-down menu where you purchased this book from.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on **Code Download**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  prefs: []
  type: TYPE_NORMAL
- en: WinRAR / 7-Zip for Windows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zipeg / iZip / UnRarX for Mac
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 7-Zip / PeaZip for Linux
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/Mastering-Spark-for-Data-Science](https://github.com/PacktPublishing/Mastering-Spark-for-Data-Science).
    We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  prefs: []
  type: TYPE_NORMAL
- en: Downloading the color images of this book
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We also provide you with a PDF file that has color images of the screenshots/diagrams
    used in this book. The color images will help you better understand the changes
    in the output. You can download this file from [https://www.packtpub.com/sites/default/files/downloads/MasteringSparkforDataScience_ColorImages.pdf](https://www.packtpub.com/sites/default/files/downloads/MasteringSparkforDataScience_ColorImages.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: Errata
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although we have taken every care to ensure the accuracy of our content, mistakes
    do happen. If you find a mistake in one of our books-maybe a mistake in the text
    or the code-we would be grateful if you could report this to us. By doing so,
    you can save other readers from frustration and help us improve subsequent versions
    of this book. If you find any errata, please report them by visiting [http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    selecting your book, clicking on the **Errata Submission Form** link, and entering
    the details of your errata. Once your errata are verified, your submission will
    be accepted and the errata will be uploaded to our website or added to any list
    of existing errata under the Errata section of that title.
  prefs: []
  type: TYPE_NORMAL
- en: To view the previously submitted errata, go to [https://www.packtpub.com/books/content/support](https://www.packtpub.com/books/content/support)
    and enter the name of the book in the search field. The required information will
    appear under the **Errata** section.
  prefs: []
  type: TYPE_NORMAL
- en: Piracy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Piracy of copyrighted material on the Internet is an ongoing problem across
    all media. At Packt, we take the protection of our copyright and licenses very
    seriously. If you come across any illegal copies of our works in any form on the
    Internet, please provide us with the location address or website name immediately
    so that we can pursue a remedy.
  prefs: []
  type: TYPE_NORMAL
- en: Please contact us at copyright@packtpub.com with a link to the suspected pirated
    material.
  prefs: []
  type: TYPE_NORMAL
- en: We appreciate your help in protecting our authors and our ability to bring you
    valuable content.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you have a problem with any aspect of this book, you can contact us at questions@packtpub.com,
    and we will do our best to address the problem.
  prefs: []
  type: TYPE_NORMAL
