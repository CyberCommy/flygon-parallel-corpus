- en: Unit Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will take a look at a process that has really grown in
    popularity in the recent years—unit testing. We’ll briefly talk about what it
    is and why we would want to do it before covering how to integrate it into our
    solution using Qt’s very own unit testing tool, Qt Test. We will cover the following
    topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Unit Testing principles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The default Qt approach
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An alternative approach
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DataDecorator tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Entity tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mocking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unit testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The essence of unit testing is to break an application down into its smallest
    functional blocks (units) and then test each unit with real-world scenarios within
    the scope of the initiative. For example, take a simple method that takes two
    signed integers and adds them together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Some example scenarios can be as listed:'
  prefs: []
  type: TYPE_NORMAL
- en: Adding two positive numbers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding two negative numbers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding two zeroes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding one positive and one negative number
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding zero and a positive number
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding zero and a negative number
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can write a test for each of these scenarios and then every time our code
    base changes (any code, not just our `add()` method), these tests can be executed
    to ensure that the code still behaves as expected. It is a really valuable tool
    to give you confidence that any code changes you make aren’t having a detrimental
    effect on the existing functionality.
  prefs: []
  type: TYPE_NORMAL
- en: Historically, these tests would have been performed manually, but tooling exists
    that can enable us to write code to test code automatically, which sounds like
    a bit of a paradox, but it really works. Qt provides a tailored framework for
    unit testing Qt-based applications, called Qt Test, and that is what we will use.
  prefs: []
  type: TYPE_NORMAL
- en: You can use other C++ testing frameworks such as Google test, which arguably
    offer more power and flexibility, particularly when used with Google mock, but
    can be a bit more fiddly to set up.
  prefs: []
  type: TYPE_NORMAL
- en: '**Test-driven development** (**TDD**) takes unit testing to the next level
    and actually changes the way you write code in the first place. In essence, you
    write a test first. The test will initially fail (indeed, probably it won’t even
    build) because you have no implementation. You then write the bare minimum of
    code it takes to make the test pass and then move on to writing the next test.
    You iteratively build out your implementation in this way until you have delivered
    the block of functionality required. Finally, you refactor the code to the required
    standard, using the completed unit tests to validate that the refactored code
    still behaves as expected. This is sometimes referred to as *Red-Green-Refactor*.'
  prefs: []
  type: TYPE_NORMAL
- en: This isn’t a book about unit testing, and it is certainly not about TDD, so
    we will be very loose with our approach, but it is a key part of modern application
    development, and it is important to know how it fits into your Qt projects.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve demonstrated the mechanism for passing a simple piece of data (the welcome
    message) from our business logic project to our UI, so as always, starting as
    simply as possible, our first goal for this chapter is to write a rudimentary
    unit test for that behavior. Once done, we’ll move on to test the data classes
    we implemented in the previous chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The default Qt approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we created our `cm-tests` project, Qt Creator helpfully created a `ClientTests`
    class for us to use a starting point, containing a single test named `testCase1`. Let's
    dive straight in and execute this default test and see what happens. We'll then
    take a look at the code and discuss what's going on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Switch the Run output to `cm-tests`, and compile and run:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/41069538-8323-4ea5-8784-a20ae5b91672.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You won’t see any fancy applications spring to life this time, but you will
    see some text in the Application Output pane in Qt Creator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We can see that three methods have been called, the second of which is our default
    unit test.  The other two functions—`initTestCase()` and `cleanupTestCase()`—are
    special methods that execute before and after the suite of tests in the class,
    allowing you to set up any preconditions required to execute the tests and then
    perform any clean up afterward. All the three steps pass.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, in `client-tests.cpp`, add another method—`testCase2()`—which is the same
    as `testCase1()` but substitute the `true` condition for `false`. Note that the
    class declaration and method definitions are all in the same `.cpp` file, so you
    need to add the method in both places. Run the tests again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This time, you can see that `testCase2()` tried to verify that false was true,
    which of course it isn’t, and our test fails, outputting our failure message in
    the process. `initTestCase()` and `cleanupTestCase()` are still executed at the
    beginning and end of the suite of tests.
  prefs: []
  type: TYPE_NORMAL
- en: Now we've seen what passing and failing tests look like, but what is actually
    going on?
  prefs: []
  type: TYPE_NORMAL
- en: We have a `QObject` derived class `ClientTests`, which implements an empty default
    constructor. We then have some methods declared as private `Q_SLOTS`. Much like `Q_OBJECT`,
    this is a macro that injects a bunch of clever boilerplate code for us, and much
    like `Q_OBJECT`, you don’t need to worry about understanding its inner workings
    in order to use it. Each method in the class defined as one of these private slots
    is executed as a unit test.
  prefs: []
  type: TYPE_NORMAL
- en: The unit test methods then use the `QVERIFY2` macro to verify a given boolean
    condition, namely that true is, well, true. If this fails, which we have engineered
    in `testCase2`, the helpful message failure will be output to the console.
  prefs: []
  type: TYPE_NORMAL
- en: If there is a `QVERIFY2`, then presumably there must be a `QVERIFY1`, right?
    Well, nearly, there is `QVERIFY`, which performs the same test but does not have
    the failure message parameter. Other commonly used macros are `QCOMPARE`, which
    verifies that two parameters of the same type are equivalent, and `QVERIFY_EXCEPTION_THROWN`, which
    verifies that an exception is thrown when a given expression is executed. This
    may sound odd, as we don’t ideally want our code to throw exceptions. However,
    things aren’t always ideal, and we should always write negative tests that verify
    how the code behaves when something does go wrong. A common example of this is
    where we have a method that accepts a pointer to an object as a parameter. We
    should write a negative test that verifies what happens if we pass in a `nullptr` (which
    is always a possibility, regardless of how careful you are). We may expect the
    code to happily ignore it and take no further action or we may want some sort
    of null argument exception to throw, which is where `QVERIFY_EXCEPTION_THROWN` comes
    in.
  prefs: []
  type: TYPE_NORMAL
- en: After the test case definitions, another macro `QTEST_APPLESS_MAIN` stubs out
    a `main()` hook to execute the tests and the final `#include` statement pulls
    in the .moc file produced by the build process. Every class that inherits from
    QObject will have a `companion .moc` file generated, containing all the magic metadata
    code created by `Q_OBJECT` and other associated macros.
  prefs: []
  type: TYPE_NORMAL
- en: Now, if you’re thinking “why would you test if true is true and false is true?”,
    then you absolutely wouldn’t, this is a totally pointless pair of tests. The purpose
    of this exercise is just to look at how the default approach that Qt Creator has
    pulled together for us works, and it does work, but it has a few key failings
    that we will need to work to fix before we write a real test.
  prefs: []
  type: TYPE_NORMAL
- en: The first issue is that `QTEST_APPLESS_MAIN` creates a `main()` method in order
    to run our test cases in `ClientTests`. What happens when we write another test
    class? We’ll have two `main()` methods and things won’t go well. Another issue
    is that our test output is just piped to the Application Output pane. In a business
    environment, it is common to have build servers that pull application code, perform
    a build, run the unit test suite, and flag any test failures for investigation.
    In order for this to work, the build tool needs to be able to access the test
    output and can’t read the Application Output pane in the IDE like a human can.
    Let’s look at an alternative approach that solves these issues.
  prefs: []
  type: TYPE_NORMAL
- en: Custom approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The custom approach we will take still applies the same basic concepts we've
    just discussed.  At the heart of it, we will still have a test class that contains
    a suite of unit test methods to be executed. All we will do is supplement this
    with some additional boilerplate code to allow us to easily accommodate multiple
    test classes and pipe the output to files rather than the console.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s begin by adding a new class `TestSuite` to `cm-tests` in the source folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6e6569fd-21b3-449b-9355-31fd0727841a.png)'
  prefs: []
  type: TYPE_IMG
- en: '`test-suite.h`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '`test-suite.cpp`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Here, we are creating a base class that will be used for each of our test classes.
    There is generally a one-to-one relationship between a regular class and a test
    suite class, for example, the `Client` and `ClientTests` classes. Each derived
    instance of `TestSuite` adds itself to a shared vector. This can be a little confusing
    at first glance, so we are also writing some information out to the console using
    `qDebug()` so that you can follow what’s going on. It will make more sense when
    we create our first class deriving from `TestSuite`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, add a new C++ Source File `main.cpp`, again to the source folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '`main.cpp`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This looks more complicated than it actually is because of the `qDebug()` statements
    added for information. We iterate through each of the registered test classes
    and use the static `QTest::qExec()` method to detect and run all tests discovered
    within them. A key addition, however, is that we create an XML file for each class
    and pipe out the results to it.
  prefs: []
  type: TYPE_NORMAL
- en: This mechanism solves our two problems. We now have a single `main()` method
    that will detect and run all of our tests, and we get a separate XML file containing
    output for each of our test suites. However, before you can build the project,
    you will need to revisit `client-tests.cpp` and either comment out or remove the
    `QTEST_APPLESS_MAIN` line, or we'll be back to the problem of multiple `main()`
    methods. Don’t worry about the rest of `client-tests.cpp` for now; we’ll revisit
    it later when we start testing our data classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Build and run now, and you’ll get a different set of text in `Application Output`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s go ahead and implement our first `TestSuite`. We have a `MasterController`
    class that presents a message string to the UI, so let''s write a simple test
    that verifies that the message is correct. We will need to reference code from
    `cm-lib` in the `cm-tests` project, so ensure that the relevant `INCLUDE` directives
    are added to `cm-tests.pro`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Create a new companion test class called `MasterControllerTests` in `cm-tests/source/controllers`.
  prefs: []
  type: TYPE_NORMAL
- en: '`master-controller-tests.h`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: We’ve explicitly added the `initTestCase()` and `cleanupTestCase()` scaffolding
    methods so that there is no mystery as to where they come from. We've also added
    another couple of special scaffolding methods for completeness: `init()` and `cleanup()`. The
    difference is that these methods are executed before and after each individual
    test, as opposed to before and after the entire suite of tests.
  prefs: []
  type: TYPE_NORMAL
- en: None of these methods are doing anything for us and are there just for future
    reference. They can safely be removed if you want to streamline things.
  prefs: []
  type: TYPE_NORMAL
- en: '`master-controller-tests.cpp`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: We again have a single test, but this time, it actually serves some meaningful
    purpose. We want to test that when we instantiate a `MasterController` object
    and access its `welcomeMessage` method, it returns the message that we want, which
    will be Welcome to the Client Management system!.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlike the scaffolding methods, the naming of your tests is entirely down to
    preference. I tend to loosely follow the `methodIAmTesting_givenSomeScenario_doesTheCorrectThing` 
    format, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We construct an instance of `MasterController` as a private member variable
    that we will use to test against. In the implementation, we specify the name of
    the test suite via the constructor, and we also create a static instance of the
    test class. This is the trigger that adds `MasterControllerTests` to the static
    vector we saw in the `TestSuite` class.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, for the implementation of our test, we test the value of the `welcomeMessage`
    of our `masterController` instance with the message we want using the `QCOMPARE`
    macro. Note that because `QCOMPARE` is a macro, you won’t get implicit typecasting,
    so you need to ensure that the types of the expected and actual results are the
    same. Here, we’ve achieved that by constructing a `QString` object from the literal
    text.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run `qmake`, and build and run to see the results of our test in the Application
    Output pane:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This begins with the registration of the `MasterControllerTests` class via the
    static instance. The `main()` method iterates the collection of registered test
    suites and finds one, then executes all the unit tests within that suite. The
    test suite contains one unit test that runs and promptly fails. This may seem
    to be less helpful than earlier as there is no indication as to which test failed
    or why. However, remember that this output is simply from the `qDebug()` statements
    we added for extra information; it is not the true output from the test execution. 
    In `master-controller-tests.cpp` we instantiated the `TestSuite` with a `testName` parameter
    of `MasterControllerTests`, so the output will have been piped to a file named
    `MasterControllerTests.xml`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to the `cm/binaries` folder and drill down through the folders to
    where we direct our project output for the selected configuration and in there,
    you will see `MasterControllerTests.xml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Here, we have the full output from the tests, and you can see that the failure
    was because the welcome message we got from `masterController` was This is MasterController
    to Major Tom, and we expected Welcome to the Client Management system!.
  prefs: []
  type: TYPE_NORMAL
- en: '`MasterController` is not behaving as expected, and we’ve found a bug, so head
    over to `master-controller.cpp` and fix the problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Rebuild both projects, execute the tests again, and bask in the glory of a
    100% pass rate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have the testing framework set up, let’s test something a little
    more complex than a simple string message and validate the work we did in the
    last chapter.
  prefs: []
  type: TYPE_NORMAL
- en: DataDecorator tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [Chapter 5](d1169ccb-4e46-49f4-b41b-2aaf896337ad.xhtml), *Data*, we created
    various classes deriving from `DataDecorator`. Let''s create companion test classes
    for each of those and test the following functionalities:'
  prefs: []
  type: TYPE_NORMAL
- en: Object construction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting the value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting the value as JSON
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Updating the value from JSON
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In `cm-tests/source/data`, create the `DateTimeDecoratorTests`, `EnumeratorDecoratorTests`,
    `IntDecoratorTests`, and `StringDecoratorTests` classes.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s begin with the simplest suite, `IntDecoratorTests`. The tests will be
    broadly similar across the suites, so once we’ve written one suite, we will be
    able to copy most of it across to the other suites and then supplement as necessary.
  prefs: []
  type: TYPE_NORMAL
- en: '`int-decorator-tests.h`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: A common approach is to follow a “method as a unit” approach, where each method
    is the smallest testable unit in a class and then that unit is tested in multiple
    ways. So we begin by testing the constructor, both with and without parameters.
    The `setValue()` method should only do anything when we actually change the value,
    so we test both setting a different value and the same value. Next, we test that
    we can convert the decorator to a JSON value, both with a default value (`0` in
    the case of an `int`) and with a set value. Finally, we perform a couple of tests
    against the `update()` method. If we pass in a JSON that contains the property,
    then we expect the value to be updated as per the JSON value. However, if the
    property is missing from the JSON, we expect the class to handle it gracefully
    and reset to a default value instead.
  prefs: []
  type: TYPE_NORMAL
- en: Note that we aren’t explicitly testing the `value()` method. This is just a
    simple accessor method with no side effects, and we will be calling it in the
    other unit tests, so we will be indirectly testing it there. Feel free to create
    additional tests for it if you wish.
  prefs: []
  type: TYPE_NORMAL
- en: '`int-decorator-tests.cpp`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Unit tests tend to follow an *Arrange > Act > Assert* pattern. Preconditions
    for the test are fulfilled first: variables are initialized, classes are configured,
    and so on. Then, an action is performed, generally calling the function being
    tested.  Finally, the results of the action are checked. Sometimes one or more
    of these steps will not be necessary or may be merged with another, but that is
    the general pattern.'
  prefs: []
  type: TYPE_NORMAL
- en: We begin testing the constructor by initializing a new `IntDecorator` without
    passing in any parameters and then test that the various properties of the object
    have been initialized to expected default values using `QCOMPARE` to match actual
    against expected values. We then repeat the test, but this time, we pass in values
    for each of the parameters and verify that they have been updated in the instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'When testing the `setValue()` method, we need to check whether or not the `valueChanged()`
    signal is emitted. We can do this by connecting a lambda to the signal that sets
    a flag when called, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: However, a much simpler solution we’ve used here is to use Qt’s `QSignalSpy`
    class that keeps track of calls to a specified signal. We can then check how many
    times a signal has been called using the `count()` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first `setValue()` test ensures that when we provide a new value that is
    different to the existing one, the value is updated and the `valueChanged()` signal
    is emitted once. The second test ensures that when we set the same value, no action
    is taken and the signal is not emitted. Note that we use an additional `QCOMPARE`
    call in both cases to assert that the value is what we expect it to be before
    the action is taken. Consider the following pseudo test:'
  prefs: []
  type: TYPE_NORMAL
- en: Set up your class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform an action.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test that the value is `99`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If everything works as expected, step 1 sets the value to `0`, step 2 takes
    the correct action and updates the value to `99`, and step 3 passes because the
    value is `99`. However, step 1 could be faulty and wrongly sets the value to `99`,
    step 2 is not even implemented and takes no action, and yet step 3 (and the test)
    passes because the value is `99`. With a `QCOMPARE` precondition after step 1,
    this is avoided.
  prefs: []
  type: TYPE_NORMAL
- en: The `jsonValue()` tests are simple equality checks, both with a default value
    and a set value.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, with the `update()` tests, we construct a couple of JSON objects. In
    one object, we add an item that has the same key as our decorator object (“Test
    Key”), which we expect to be matched and the associated value (`123`) passed through
    to `setValue()`. In the second object, the key is not present. In both cases,
    we also add other extraneous items to ensure that the class can correctly ignore
    them. The post action checks are the same as for the `setValue()` tests.
  prefs: []
  type: TYPE_NORMAL
- en: The `StringDecoratorTests` class is essentially the same as `IntDecoratorTests`,
    just with a different value data type and default values of empty string `""`
    rather than `0`.
  prefs: []
  type: TYPE_NORMAL
- en: '`DateTimeDecorator` also follows the same pattern, but with additional tests
    for the string formatting helper methods `toIso8601String()` and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: '`EnumeratorDecoratorTests` performs the same tests but requires a little more
    setup because of the need for an enumerator and associated mapper. In the body
    of the tests, whenever we test `value()`, we also need to test `valueDescription()`
    to ensure that the two remain aligned. For example, whenever the value is `eTestEnum::Value2`,
    the `valueDescription()` must be `Value 2`. Note that we always use the enumerated
    values in conjunction with the `value()` checks and `static_cast` them to an `int`.
    Consider the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'It may be tempting to make this much shorter by just using the raw `int` value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The problem with this approach, other than the number 2 having much less meaning
    to readers of the code than the enumerated `Value2`, is that the values of `eTestEnum`
    can change and render the test invalid. Consider this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Due to the insertion of `MyAmazingNewTestValue`, the numeric equivalent of `Value2`
    is actually now 3\. Any tests that used the number 2 to represent `Value2` are
    now wrong, whereas those that use the more long-winded `static_cast<int>(eTestEnum::Value2)`
    are still correct.
  prefs: []
  type: TYPE_NORMAL
- en: Rebuild and run the new test suites, and they should all happily pass and give
    us renewed confidence in the code we wrote earlier. With the data decorators tested,
    let's move on to our data models next.
  prefs: []
  type: TYPE_NORMAL
- en: Entity Tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have some confidence that our data decorators are working as expected,
    let’s move up a level and test our data entities. The Client class is the root
    of our model hierarchy and by testing that, we can test our other models in the
    process.
  prefs: []
  type: TYPE_NORMAL
- en: We already have `client-tests.cpp` in `cm-tests/source/models` that Qt Creator
    added for us when we created the project, so go ahead and add a companion header
    file `client-tests.h`.
  prefs: []
  type: TYPE_NORMAL
- en: '`client-tests.h`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'There are three main areas we want to test here:'
  prefs: []
  type: TYPE_NORMAL
- en: Object construction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serialization to JSON
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deserialization from JSON
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As with previous suites, we have a couple of different flavors of test for
    each area—one with default data and one with specified data. In the private section,
    you will see numerous verify methods. They are to encapsulate the functionality
    required to test a particular subset of our data. The advantages of doing this
    are the same as with regular code: they make the unit tests much more concise
    and readable, and they allow easy reuse of the validation rules. Also, in the
    private section, we define a blob of JSON we can use to construct our Client instances.
    A `QByteArray`, as its name suggests, is simply an array of bytes that comes with
    numerous associated helpful functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Starting with the constructor tests, we instantiate a new Client, both with
    and without a JSON object. Note that in order to convert our JSON byte array to
    a `QJsonObject`, we need to pass it through a `QJsonDocument`. Once we have our
    initialized client, we check the name property and utilize the verify methods
    to test the state of the child objects for us. Regardless of whether or not we
    supply any initial data via a JSON object, we expect the `supplyAddress` and `billingAddress` objects
    to be created for us automatically as well as the appointments and contacts collections.
    By default, the collections should be empty:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The `toJson()` tests follow much the same pattern. We construct an object without
    a JSON object so that we get default values for all the properties and child objects.
    We then immediately construct a `QJsonDocument` using a call to `toJson()` in
    the constructor to get the serialized JSON object for us. The `name` property
    is tested, and then we utilize the verify methods once more. When constructing
    a **Client** using JSON, we add precondition checks to ensure that our properties
    have been set correctly before we again call `toJson()` and test the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The `update()` tests are the same as `toJson()`, but the other way around. This
    time, we construct a JSON object using our byte array and pass it in to `update()`,
    checking the state of the model afterward.
  prefs: []
  type: TYPE_NORMAL
- en: 'The various private verification methods are all simply sets of checks that
    save us having to repeat the same code over and over. Consider the given example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Build and run the unit tests again and the new **Client** tests should all happily
    pass.
  prefs: []
  type: TYPE_NORMAL
- en: Mocking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The unit tests we’ve written so far have all been pretty straightforward. While
    our **Client** class isn’t totally independent, its dependencies are all other
    data models and decorators that it can own and change at will. However, looking
    forward, we will want to persist client data in a database. Let's look at a few
    examples of how this can work and discuss how the design decisions we make impact
    the testability of the Client class.
  prefs: []
  type: TYPE_NORMAL
- en: Open up the `scratchpad` project and create a new header `mocking.h` file, where
    we’ll implement a dummy Client class to play around with.
  prefs: []
  type: TYPE_NORMAL
- en: '`mocking.h`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'In `main.cpp`, `#include <mocking.h>`, update the `engine.load()` line to load
    the default `main.qml` if it doesn’t already and add a few lines to spin up and
    save a dummy Client object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Build and run the app, ignore the window, and take a look at the Application
    Output console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We have a way to ask a client to save itself, but it needs a database to save
    itself too. Let’s encapsulate our database management functionality into a `DatabaseController`
    class. In mocking.h, add the following implementation before the Client class.
    Note that you need to forward declare Client:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, edit the Client class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Back in `main.cpp`, replace the Client lines with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we create and save two clients rather than just one. Build, run, and check
    the console again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Okay, now we’re saving our clients to the production database, but we’re creating
    a new database connection for every client, which seems a bit wasteful. The Client
    class needs an instance of a `DatabaseController` to function, and this is known
    as a dependency.  However, we do not need the Client to be responsible for creating
    that instance; we can instead pass—or *inject—*the instance in via the constructor
    and manage the lifetime of the `DatabaseController` elsewhere. This technique
    of Dependency Injection is a form of a broader design pattern known as **Inversion
    of Control**. Let''s pass a reference to a shared `DatabaseController` into our
    Client class instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Over in `main.cpp`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Build and run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Great, we’ve got a highly-efficient decoupled system architecture in place;
    let’s test it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In `mocking.h`, add a pretend test suite after the Client class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'In `main.cpp`, after saving `client2`, add the following to run our tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Build and run this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Our test passed, fantastic! What’s not to love about that? Well, the fact that
    we’ve just saved some test data to our production database.
  prefs: []
  type: TYPE_NORMAL
- en: If you don’t already implement interfaces for the majority of your classes,
    you soon will after you start unit testing for this precise reason. It’s not used
    solely to avoid nasty side effects like writing test data to a production database;
    it allows you to simulate all kinds of behaviors that make unit testing so much
    easier.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let’s move our `DatabaseController` behind an interface. Replace the plain
    `DatabaseController` in `mocking.h` with a supercharged interface-driven version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'With the interface in place, we can now create a fake or mock implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, tweak our Client to hold a reference to the interface rather than the
    concrete implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, change our test suite to create a mock controller to pass into the
    clients:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Build and run this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Perfect. By programming to interfaces and injecting dependencies, we can safely
    test in isolation. We can create as many mock implementations as we need and use
    them to simulate whatever behavior we want, enabling us to test multiple different
    scenarios. Once you get more involved in mocking, it really pays to use a dedicated
    framework like **google mock**, as they save you the hassle of having to write
    a bunch of boilerplate mock classes. You can easily mock the interface once using
    helper macros and then specify behaviors for individual methods on the fly.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we’ve taken our first proper look at the unit testing project,
    and you’ve seen how to implement unit testing using the Qt Test framework. We’ve
    also discussed the importance of programming to interfaces to enable mocking.
    Now we have unit tests in place for our main data classes, so if we ever accidentally
    change the behavior, the unit tests will fail and highlight a potential problem
    for us.
  prefs: []
  type: TYPE_NORMAL
- en: As we discussed, this is not a book about test driven development, and we will
    sometimes cut corners and go against the advice in this chapter to keep the explanation
    of other concepts as simple as possible, but I do urge you to implement unit testing
    of some kind in your projects if you can, as it is a very valuable practice that
    is always worth the additional time investment. Some developers like the rigor
    of full-blown TDD, whereas others prefer to write unit test after the fact to
    verify the work they have done. Find an approach that works for you and your coding
    style.
  prefs: []
  type: TYPE_NORMAL
- en: We will return to the test project occasionally to demonstrate certain behaviors.
    but we’ll certainly not be achieving 100% code coverage. Now that you have the
    test project and scaffolding in place, it’s just a case of adding further test
    classes for each class you want to test. As long as you inherit from `TestSuite`
    in the same way as we have in this chapter, they will be automatically detected
    and executed when you run the test project.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 7](0563666d-47ad-4c30-abb0-731ed70a5349.xhtml), *Persistence*, we’ll
    go ahead and implement the functionality we just discussed—persisting our data
    to a database.
  prefs: []
  type: TYPE_NORMAL
