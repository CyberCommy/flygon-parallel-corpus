- en: Highly Available Cloud Deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Continuing with our AWS deployment, we will start to deploy services into the
    network we created in the previous chapter, and by the end of the chapter, we
    will be left with a highly available WordPress installation, which we will test
    by removing the instances while sending traffic to the site.
  prefs: []
  type: TYPE_NORMAL
- en: 'Building on top of the roles we created in the previous chapter, we will be
    doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Launching and configuring Amazon RDS (database)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Launching and configuring Amazon EFS (shared storage)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Launching and creating an **Amazon Machine Image** (**AMI**) (deploying the
    WordPress code)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Launching and configuring a launch configuration and autoscaling group (high
    availability)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As in the previous chapter, we are going to be using AWS; you will need the
    access key and secret key we created in the previous chapter to launch the resources
    needed for our highly available WordPress installation. Please note that we will
    be launching resources that incur charges. Again, you can find the complete playbook
    in the `Chapter10` folder of the accompanying GitHub repository at [https://github.com/PacktPublishing/Learn-Ansible/tree/master/Chapter10/aws-wordpress](https://github.com/PacktPublishing/Learn-Ansible/tree/master/Chapter10/aws-wordpress).
  prefs: []
  type: TYPE_NORMAL
- en: Planning the deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we dive into the playbooks, we should get an idea of what it is we are
    trying to achieve. As already mentioned, we are going to be building on our AWS
    VPC role by adding instances and storage. Our updated diagram looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/fb26f773-d780-41c2-aebe-87647cc26984.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the diagram, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 3 x EC2 instances (t2.micro), one in each availability zone
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2 x RDS instances (t2.micro), in a master/standby multi-AZ configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 5 GB of EFS storage across three availability zones
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before we talk about the deployment itself, based on the diagram and specifications
    here, how much is this deployment going to cost us to run?
  prefs: []
  type: TYPE_NORMAL
- en: Costing the deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The cost of running this deployment in the EU-West-1 region is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Instance type** | **# Instances** | **Total cost** **per hour** | **Total
    cost** **per day** | **Total cost** **per month** |'
  prefs: []
  type: TYPE_TB
- en: '| EC2 instances (t2.micro) | 3 | $0.038 | $0.091 | $27.22 |'
  prefs: []
  type: TYPE_TB
- en: '| RDS instance (t2.micro)—Master and Standby | 2 | $0.036 | $0.086 | $25.92
    |'
  prefs: []
  type: TYPE_TB
- en: '| Application Load Balancer | 1 | $0.033 | $0.80 | $23.90 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 GB EFS | 1 | $0.002 | £0.06 | $1.65 |'
  prefs: []
  type: TYPE_TB
- en: '| Total: | $0.109 | $2.62 | $78.69 |'
  prefs: []
  type: TYPE_TB
- en: There will be a few other small costs, such as bandwidth and the cost of storing
    the AMI that contains our software stack. We could look at reducing these costs
    significantly by removing some of the redundancy, by disabling the multi-AZ RDS
    instance and also reducing the number of EC2 instances down to just one; however,
    this starts to introduce single points of failure into our deployment, which we
    do not want to do.
  prefs: []
  type: TYPE_NORMAL
- en: WordPress considerations and high availability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have been launching WordPress on a single server, which is fine,
    but as we are trying to remove as many of the single points of failure within
    our deployment as possible, this means that we have to put a little thought into
    how we initially configure and launch our deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, let''s discuss the order that we will need to launch our deployment
    in. The basic order we will need to launch the elements in is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**VPC, subnets, internet gateway, routing and security groups**: These are
    all needed to launch our deployment'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The Application Elastic Load Balancer**: We will be using the public hostname
    of the Elastic Load Balancer for our installation, so this needs to be launched
    before we start our installation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The RDS database instance**: It is important that our database instance is
    available before we launch our installation as we need to create the WordPress
    database and bootstrap the installation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The EFS storage**: We need some storage to share between the EC2 instances
    we will be launching next'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So far, so good; however, this is where we have to start taking WordPress into
    account.
  prefs: []
  type: TYPE_NORMAL
- en: As some of you may know from experience, the current version of WordPress is
    not really designed to be spread across multiple servers. There are plenty of
    hacks and workarounds we can apply to make WordPress play nicely in this sort
    of deployment; however, this chapter is not about the finer points of deploying
    WordPress. Instead, it is about how you can use Ansible to deploy a multi-tiered
    web application.
  prefs: []
  type: TYPE_NORMAL
- en: Because of this, we will be going for the most basic of the multi-instance WordPress
    options by deploying our code and content on the EFS volume. This means that all
    we have to do is install our LEMP stack. It should be noted that this option is
    not the most performant, but it will serve our needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now back to the list of tasks. When it comes to launching our instances, we
    need to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Launch a temporary EC2 instance running CentOS 7 so that we can reuse parts
    of existing playbooks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Update the operating system and install the software stack, supporting tools,
    and configuration needed for us to install and run our WordPress installation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mount the EFS volume and set the correct permissions, and configure it to mount
    on boot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attach the temporary instance to our load balancer, and install and configure
    WordPress
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create an AMI from our temporary instance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a launch configuration that uses the AMI we just created
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create an autoscaling group and attach the launch configuration; it should also
    register our WordPress instances with the Elastic Load Balancer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: During the initial playbook execution, there will be a short period of downtime
    as we create the AMI; further playbook runs should repeat the process with the
    existing instances up and running, and then, once the AMI is built, it should
    be deployed alongside the current instances, which will then be terminated once
    the new instances are registered with the Elastic Load Balancer and receiving
    traffic. This will allow us to update our operating system packages and configuration
    without any downtime—this will also simulate us deploying AMIs that have our code
    base baked in; more on that later in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Now we have an idea of what we are trying to achieve, let's make a start on
    our playbook.
  prefs: []
  type: TYPE_NORMAL
- en: The playbook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The playbook is going to be split up into several sections. Before we make
    a start on the first one, let''s create the folder structure. As per previous
    chapters, we simply need to run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have our basic structure in place, we can make a start on creating
    the roles, starting with the network.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon VPC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the work for creating the underlying network was completed in the previous
    chapter, meaning that we simply need to copy the `elb`, `gateway`, `securitygroups`,
    `subnets`, and `vpc` folders from your previous playbook across to your current
    `roles` folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once copied, update the `site.yml` file so it reads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, add the following to the `group_vars/common.yml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we need to update the subnets that are being created; to do this,
    update `the_subnets` variable in `roles/subnets/defaults/main.yml` to read:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we are adding an additional subnet for our EFS volume, making
    it available in all three availability zones. More on why later. However, it does
    demonstrate the flexibility of our playbook, when all we have to do is add an
    additional line to our variables to create the additional subnet.
  prefs: []
  type: TYPE_NORMAL
- en: That completes the first part of the playbook; we can now move on to some new
    territory and launch our Amazon RDS instance.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon RDS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s start by creating the file structure for the role by running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that''s in place, let''s discuss what we need to do to launch the RDS instance.
    To start with, we need to define some default values; add the following to the
    `roles/rds/defaults/main.yml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Some of the variables are self-explanatory, such as `db_username`, `db_password`,
    and `db_name`, although, as you can see, we are doing something interesting with
    the content of `db_password`. Rather than hardcoding a password, we are using
    a lookup plugin; these allow Ansible to read external data, for example, the contents
    of a file, Redis, MongoDB, or various APIs.
  prefs: []
  type: TYPE_NORMAL
- en: In our case, we are using the Ansible password lookup plugin to populate a file
    on our Ansible controller with a randomly generated password; this file is left
    alone on subsequent lookups, meaning that the password can be reused. Ansible
    will be generating a password that contains letters and numbers and is 30 characters
    long, and it is placing it in a file at `group_vars/rds_passwordfile`. This file
    is then added to the `.gitignore` file, so we don't end up shipping our passwords
    to version control.
  prefs: []
  type: TYPE_NORMAL
- en: Other things to note are that we are launching a db.t2.micro (`app_instance_type`)
    MariaDB (`engine`) instance, with 5 GB (`hdd_size`) of storage in a multi-AZ configuration
    (`multi_az`). We will be keeping 7 days of backups (`no_of_backups`), and when
    the instance first launches, we will wait (`wait`) for 20 minutes (`wait_time`)
    for the instance to become available before moving on to the next part of the
    playbook.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is one thing we need to do before we launch our RDS instance, and that
    is to create an RDS subnet group; this is how we associate our RDS instance with
    the subnets we created when launched the VPC. In `roles/rds/tasks/main.yml`, enter
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This task uses the list of two subnets we registered in the `subnets` role
    to, in our case, create a group called `wordpress_rds_group`. When it comes to
    associating the subnet group with our RDS instance, we will be using its name
    rather than its unique ID, so there is no need for us to register the output of
    the task for later use. The next, and final, task in the role launches the RDS
    instance. Enter the following `rds_subnet_group` task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Apart from the `command` option, everything else is populated using a variable—this
    means that if there is any part of the instance we want to change when reusing
    the role, we can simply override the default variables by copying them to our
    `group_vars/common.yml` file. There are several options for the `command` option
    you can choose when interacting with the RDS module, which are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`create`: This creates an RDS instance. If one already exists, the module will
    gather facts on it'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`replicate`: This creates a read-only replica of the RDS instance you pass
    to it'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`delete`: This deletes the RDS instance; you have the option to take a snapshot
    before the instance is deleted'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`facts`: Gathers information on the RDS instance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modify`: If you have changed any part of your configuration, then this will
    update your instance, either immediately or during the next scheduled maintenance
    window'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`promote`: This will promote one of your read-replicas to be the new master'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`snapshot`: This creates a manual snapshot of your RDS instance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reboot`: This reboots the named RDS instance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`restore`: This creates a new RDS instance from a named snapshot'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are a few niggles with the current RDS module you might want to take into
    account. The biggest of which is that it currently only allows you to launch RDS
    instances backed with magnetic storage. It is possible to add a task that uses
    the AWS command-line tools to migrate the storage to general purpose SSD once
    the instance has launched; however, we will not be covering that here.
  prefs: []
  type: TYPE_NORMAL
- en: Also, Ansible does not yet support Amazon Aurora, even though it is listed as
    an option. Again, it is possible to create tasks that use the AWS command-line
    tools to create and configure an Aurora cluster, but if you want native Ansible
    support, you are currently out of luck.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Aurora is Amazon's own database engine, which allows you to run either
    your MySQL or PostgreSQL databases on top of Amazon's custom-built, SSD-based,
    fault-tolerant, and self-healing database storage clusters. This custom storage
    architecture allows you to scale your database to over 60 TB without disruption
    or the need to reorganize your datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Work within the Ansible community is ongoing to refactor the RDS module to support
    custom storage options and also introduce native support for Aurora. However,
    this is very much a work in progress, which has not made its way into the current
    Ansible release (2.5 at the time of writing).
  prefs: []
  type: TYPE_NORMAL
- en: That is all we need for our RDS instance; we can move on to the next role.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon EFS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are only three tasks needed to create the EFS volumes; as with previous
    roles, we can use the `ansible-galaxy` command to create the folder and file structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Before we add the tasks, we need to add some default variables and a template,
    so add the following to `roles/efs/defaults/main.yml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, create a file in `roles/efs/templates` called `targets.j2`, which should
    contain:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, this template is looping over the `subnet_efs_ids` variable
    to create a list of subnet IDs and security groups under the variable name `efs_targets`;
    we will find out why this is needed shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first task in `roles/efs/tasks/main.yml` uses the `template` module to
    read the previous file to create a file and store it in the `group_vars` folder,
    and the second task loads the contents of the file using the `include_vars` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the `efs_targets` variable populated and loaded, we can add
    the third and final task; this task uses the `efs` module to create the volume:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '"So, why go to the effort of creating a template, generating a file, and then
    loading the contents in when you could use `with_items`?" you may be asking yourself.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we were to use `with_items`, then our task would look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This, at first glance, looks like it should work; however, if we take a look
    at an example of what `group_vars/generated_efs_targets.yml` looks like once it
    is has been generated, you may notice one important difference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from the example, we have three sections, each with the `subnet_id`
    unique to an availability zone. If we were to use `with_items`, we would only
    have one section and the task would be executed three times, each time overwriting
    the previous targets. Sure, we could have hardcoded three targets, but then what
    if we decided to reuse the role in a region that only has two availability zones,
    or one that has four? Hardcoding would mean we would lose the flexibility to have
    Ansible dynamically adapt to situations where there is a range of dynamic results
    depending on what is being targeted.
  prefs: []
  type: TYPE_NORMAL
- en: Now we have our EFS role complete and the basics finished. Before we start to
    launch EC2 instances, we can look at testing our playbook.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the playbook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As mentioned, now would be a good time to test the roles we have completed
    to make sure they are working as expected. To do this, open the `site.yml` file
    and add the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Before we run our playbook, we will need to set the `AWS_ACCESS_KEY` and `AWS_SECRET_KEY`
    environment variables; to do this, run the following, replacing the value of each
    variable with the details that we generated in the previous chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We will want to time our playbook run. To do this, we can prefix our `ansible-playbook`
    command with `time`, which means the command we need to run looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Don't forget that we have told Ansible to wait for a maximum of 20 minutes before
    launching the RDS instance and creating the EFS volume, so the initial playbook
    run may take a little time.
  prefs: []
  type: TYPE_NORMAL
- en: 'The reason for this is that when the RDS instance is launched, it is first
    created, then cloned to a standby server, and then, finally, an initial backup
    is made. Only once these steps have been completed is the RDS instance marked
    as ready and our playbook run progresses. Also, for the EFS volumes, we are creating
    a cluster of three volumes across three availability zones, so it takes a little
    while to configure them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from the output, the playbook run executed as expected. We can
    check the AWS console to make sure everything has been created, starting with
    the VPC:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/a7a633ee-a083-4535-9583-b7cad69f009f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, check the Elastic Load Balancer, which can be found in the EC2 section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/da9b6cfd-03b9-4d38-8dee-1a8f5c9f8813.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can also check that our RDS instance is up and running:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/f0f85c79-4387-40c8-925e-5e11081485e0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, the final part of our playbook is the EFS volume:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/743d2712-73d1-495a-b457-35b7f1e40347.png)'
  prefs: []
  type: TYPE_IMG
- en: 'When I ran the playbook, it took just over 18 minutes, as you can see from
    the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/d910bf0a-002d-4f9d-8111-6fbc69cb8d13.png)'
  prefs: []
  type: TYPE_IMG
- en: As expected, the majority of that time was Ansible waiting for the RDS instance
    and the EFS volume to be ready.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know that the playbook can launch our basic infrastructure without
    error, we can proceed with the rest of playbook. Or can we?
  prefs: []
  type: TYPE_NORMAL
- en: Terminating resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As already mentioned at the start of this chapter, we are launching resources
    that are going to incur costs when they are up and running. As we are still writing
    our playbook, we don't want the resource to sit idle and rack up costs while we
    work, so let's create a supporting playbook that undoes everything we have just
    ran.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, let''s create a single role called `remove`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This role will use Ansible to, well, remove everything we have just launched,
    thus keeping costs down while we are developing our playbook. First of all, we
    need to add some default variables to `roles/remove/defaults/main.yml`; these
    are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The `vpc_cidr_block` variable should match your VPC CIDR. Now, we can make
    a start on adding the tasks to `roles/remove/tasks/main.yml`, which removes everything
    we have launched. We will be working our way backwards as each of the resources
    were launched in a certain order, meaning that we need to remove them in reverse
    order. So let''s start with the EFS volume:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We only have to provide a few details this time as the volume is already present;
    we need to give it the name of the volume and also a `state` of `absent`. You
    will notice that we wait for the volume to be removed completely before continuing.
    We are going to have quite a few pauses in this playbook to allow for the resources
    to be fully unregistered with the AWS API before we move on to the next task.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next few tasks deal with the removal of the RDS instance and the RDS subnet
    group:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we have a pause, using the `pause` module, of 2 minutes between
    the RDS instance being terminated and the removal of the RDS subnet group. If
    we remove this pause, then we run the risk of the RDS instance not being fully
    unregistered, meaning that we would not be able to remove the subnet group, which
    would result in an error in the playbook.
  prefs: []
  type: TYPE_NORMAL
- en: If, at any stage, the playbook throws an error, we should be able to run it
    a second time and it should pick up where it left off. Although, there is a point
    of no return when we will not be able to run the playbook at all; I will let you
    know when this is.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that the RDS instance and subnet group have been removed, we can remove
    the Elastic Load Balancer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: You will notice that, this time, although the `pause` module is being used again,
    we are not providing a period of time. Instead, we are instructing the user to
    check the AWS console, then to press a key once the Elastic Load Balancer has
    been removed. This is because the `elb_application_lb` module doesn't support
    waiting around for the resource to be removed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next task will immediately fail if you just hit *Enter* when the resource
    is in the process of being removed, hence the need for the manual check. The task
    removes the ELB target group:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The tasks that follow remove the security groups; as we have groups that reference
    other groups, there is a 30-second `pause` before we remove the next group in
    line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, as you can see, we only have to provide the group name and the `state`
    of `absent`. The next task, the removal of the route table, requires a little
    more than just the name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: To remove the route table, we need to know the VPC ID and also the route table's
    ID. To find out this information, we are using the `ec2_vpc_route_table_facts`
    module to gather the data based on the `Name` and `Environment` tags, so we only
    remove what we intend to. This is information that is then passed to the `ec2_vpc_route_table`
    module, which we are instructing to use the ID of the route table to do the `lookup`.
  prefs: []
  type: TYPE_NORMAL
- en: We are also telling Ansible to ignore any errors generated here. The reason
    being that if a subsequent task throws an error and we need to rerun the playbook,
    we will need it to progress past this point in the playbook run, and if this task
    has successfully run, it won't be able to as there will be nothing to remove,
    which itself will generate an error.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next two tasks gather information on the VPC and remove the internet gateway:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, we are ignoring any errors generated so that we can progress with the
    playbook run should it need to be executed more than once. The task gathers information
    on the subnets that are active in the environment using the `ec2_vpc_subnet_facts`
    module; we then register this information as `the_subnets`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have information on the subnets, we can remove them using their CIDR
    block and by setting the `state` to `absent`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: It is at this point that the playbook would generate an error if you were to
    run it more than once and make it this far. If it does, you can remove the VPC
    manually.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, now that we have removed all of the contents from our VPC and it is
    empty which means we can remove the VPC itself without error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have our role completed, we can create a playbook called `remove.yml`,
    which contains the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have all the pieces in place to remove our AWS environment; to do this,
    run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Don't forget to check that the Elastic Load Balancer has been removed and press
    any key to continue during the playbook run. Otherwise, you will be waiting around
    for a while.
  prefs: []
  type: TYPE_NORMAL
- en: 'When I ran the playbook, it took just under 12 minutes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/10471d7f-0fa6-4bc8-808c-eaf619c3c01b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If you are not following along with the output of the playbook, you can see
    all of the pauses and the information on the subnets collected by the `ec2_vpc_subnet_facts`
    module here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: I would recommend double-checking that the resources have gone from your AWS
    console, as no one likes a surprise bill. Now that we have completed and executed
    our `remove` playbook, so that we don't incur any unnecessary costs, we can continue
    to build out our highly available WordPress installation.
  prefs: []
  type: TYPE_NORMAL
- en: EC2 instances
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have all the basic services required for our WordPress installation
    to consume, we can make a start on deploying the compute resource to install WordPress
    on. This is where things get interesting, as we have to build logic into our playbook
    so that if our site is up and running, we can deploy updates to the operating
    system and roll out new images without any downtime.
  prefs: []
  type: TYPE_NORMAL
- en: But if it is a new deployment, we need to launch an instance, attach it to the
    Elastic Load Balancer, install the software stack, configure WordPress, and create
    an image we can then use in a launch configuration, which we will need to attach
    to an autoscaling group.
  prefs: []
  type: TYPE_NORMAL
- en: While this may seem complicated, building this logic into the playbook will
    make it a lot easier to maintain and hand over to someone else to manage/run,
    as they will not need to worry about the existing deployment, they will just need
    to run the playbook.
  prefs: []
  type: TYPE_NORMAL
- en: Instance discovery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are going to simply call this role EC2, so we need to run the following
    command to create the role structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: The primary goal of this role is to ensure that by the end of its execution,
    we have an instance, either a new or an existing one, that we can then use in
    the forthcoming roles to base an AMI on.
  prefs: []
  type: TYPE_NORMAL
- en: 'The defaults in `roles/ec2/defaults/main.yml` define which image we want to
    use if our role discovers that this is a new deployment. For our installation,
    we are going to be using the AMI provided by CentOS in the AWS Marketplace; this
    means we can reuse large chunks of our WordPress installation playbook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: We will go into a little more detail about why we need this information when
    we come to use images. Now we have the defaults in place, we can move on to the
    tasks in `roles/ec2/tasks/main.yml`.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we launch our instances using the autoscaling group, they will all be
    named `wordpress_ec2`, so the first thing our EC2 role has to do is figure out
    whether we have any running instances. To do this, we will use the `ec2_instance_facts`
    module to gather information on any instances that are running and are tagged
    with the name `wordpress_ec2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Although we now have information on any instances that are already running,
    it is not really in a format we can use, so let''s add the results to a host group
    called `already_running`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we are left with a host group called `already_running`, which may contain
    from zero to three hosts; we now need to count the number of hosts in the group
    and set a fact that contains the number of hosts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Here, we are using the inbuilt Ansible variable `groups` along with our group
    name; now we have a list of hosts, we can count the number of items in the list
    by using the `length` filter. Finally, we are saying that if the list is empty,
    then the default value should be `0`.
  prefs: []
  type: TYPE_NORMAL
- en: Now we have a variable that contains `number_of_running_hosts`, we can now make
    some decisions on what we need to do next.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, if `number_of_running_hosts` is `0`, then we are working on a new deployment,
    and we should run the tasks that launch a fresh EC2 instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Or, if `number_of_running_hosts` is more than `1`, then we need to choose an
    already running instance to work with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Let's take a look at these tasks, starting with what happens during a new deployment.
  prefs: []
  type: TYPE_NORMAL
- en: New deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If we are working on a new deployment, then we need to perform the following
    tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Find the latest CentOS 7 AMI in the region we are using
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Upload a copy of our public key so that we can use it to SSH into the instance
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Launch an instance using the previous information
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the new instance to a host group
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Wait until SSH is available
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add our instance to the Elastic Load Balancer
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All of these tasks are defined in `roles/ec2/tasks/new_deployment.yml`, so let's
    start working on these tasks by looking at how we can find the correct AMI to
    use.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can''t simply supply an AMI ID here as each region has a different ID, and
    also each AMI is regularly updated to make sure it is patched. To get around this,
    we can run the following tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we are first looking for all `x86_64` AMIs created by CentOS
    that have `CentOS Linux 7 x86_64*` in the name and also use **Elastic Block Store**
    (**EBS**)-backed storage. This will give us details about several AMIs, which
    we have registered as `amiFind`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we need to filter the list of AMIs down to just the latest one, so we
    set a fact called `amiSortFilter`. Here, it is taking the list of images, `amiFind`,
    and sorting them by the date they were created. We then take just the information
    for the last AMI in the list to register as `amiSortFilter`. Finally, we reduce
    the information down more by setting a fact called `our_ami_id`, which is the
    `image_id` in the `amiSortFilter` variable, leaving us with just the information
    we need.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we know the AMI ID, we need to ensure that there is an SSH key we can use
    so that we can access the instance when launched. First of all, let''s check that
    your user on the Ansible controller has an SSH key; if we can''t find one, then
    one will be created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have confirmed the presence of a key, we need to upload the public
    portion to AWS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have everything in place to launch an EC2 instance; to do this, we will
    be using the `ec2_instance` module, which was introduced in Ansible 2.5:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: With this, we are launching our EC2 instance into one of the EC2 subnets, attaching
    a public IP address and also our EC2 security group. The instance will be a t2.micro
    CentOS 7 instance called `wordpress-tmp`. We are assigning tags to it, and we
    are also using filters so that if anything happens during the playbook run and
    we need to rerun it, it will use our instance that is already running rather than
    launching another.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the instance has launched, we need to find out its information and add
    it to a host group called `ec2_instance`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to wait for SSH to be accessible before moving on; here, we will use
    the `wait_for` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, once SSH is available, we need to register the instance with our Elastic
    Load Balancer target group:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: This will leave us with a single instance called `wordpress-tmp`, which is accessible
    over SSH and active behind our Elastic Load Balancer in a host group named `ec2_instance`.
  prefs: []
  type: TYPE_NORMAL
- en: Existing deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If we already have instances running, the previous tasks are skipped and the
    single task in `roles/ec2/existing_deployment.yml` is run. This task simply takes
    one of the running hosts and adds it to the host group named `ec2_instance`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: This leaves us in the same position as we were in at the end of the new deployment
    tasks, with a host called `ec2_instance` with a single instance that is accessible
    over SSH.
  prefs: []
  type: TYPE_NORMAL
- en: Stack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next role that we are going to create is the one that is only executed
    on the host— the `ec2_instance` group called `stack`. As with the previous roles,
    we can run the following command from within our `aws-wordpress` folder to create
    the files needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: This role is three roles in one. As with the EC2 role, we are building in logic
    to execute tasks based on the state of the instance our playbook finds when it
    first connects. Let's look at the contents of `roles/stack/tasks/main.yml` first.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first task in there is executed on both new and existing deployments; it
    runs a `yum update`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to know whether WordPress is installed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The next two tasks include two additional roles; one installs and configures
    the software stack and the other performs the initial WordPress installation,
    but only if no existing installation is found:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: These two roles are condensed versions of the roles we created when we installed
    WordPress locally.
  prefs: []
  type: TYPE_NORMAL
- en: Default variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we look at the roles, let''s take a look at the code of `roles/stack/defaults/main.yml`
    as there are a few differences:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The main differences are:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `wordpress.domain` URL: This time, rather than hardcoding the domain, we
    have the Elastic Load Balancer URL, which we get from using the `elb_application_lb_facts`
    module. More on that later.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `efs_mount_dir` variable: This is a new variable, which we will use to
    define where in the instance we want our EFS share mounted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `wordpress_system.home` option: This now uses `efs_mount_dir` so our WordPress
    installation can be shared across all instances.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lack of a MariaDB server: You will notice that references to installing and
    configuring a MariaDB server have been removed; as we have an RDS instance, we
    no longer need these.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are using the `include_role` module to execute the tasks as a role to ensure
    that the variables are loaded correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Deploy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first additional role, called `roles/stack/tasks/deploy.yml`, does as you
    would expect and deploys the software stack and configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'It starts by mounting the EFS share; first, we need to gather some information
    about the EFS share using the `efs_facts` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: You may have already noticed that we are calling the `efs_facts` module differently;
    we are actually using the `local_action` module, which runs the `efs_facts` module
    on our Ansible controller rather than the EC2 instance. This is because we are
    not actually giving our EC2 instance access to the API, as we are not installing
    Boto or passing our access key and secret access key as a variable.
  prefs: []
  type: TYPE_NORMAL
- en: Using the `local_action` module allows us to flip back to our Ansible controller
    to gather information on our EFS and then apply the results on our EC2 instance;
    we will be using this module again later in the installation.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are using `become: no` as part of this task; otherwise, it will try to execute
    using `sudo`. This is because we are telling all tasks to use `become: yes` with
    `become_method: sudo` in this part of the `site.yml` file, which we will update
    later in this chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The next task mounts the EFS share and also adds it to the `fstab` file, which
    means that it will automatically mount when the instance we will be launching
    from the AMI we are creating first boots:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '`efs_mount_dir` is automatically created so we don''t need to worry about creating
    it beforehand. The next part of the role installs and configures the stack:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: For this to work, you will need to copy the files from `files`, `handlers`,
    and `templates` from the `stack-config` role of the LEMP playbook we created in
    [Chapter 5](159d7be3-6d13-4a66-8766-e4cf3b982b0f.xhtml), *Deploying WordPress*.
  prefs: []
  type: TYPE_NORMAL
- en: WordPress
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you may have already guessed, this role, which can be found in the `roles/stack/tasks/wordpress.yml`
    file alongside `roles/stack/tasks/main.yml` and `roles/stack/tasks/deploy.yml`,
    installs and configures WordPress.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we progress with the tasks, we need to find out information about our
    RDS instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'This is so that we can use the tasks when defining the database connection;
    likewise, we also need to find out about the Elastic Load Balancer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'The remaining tasks do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Install WP-CLI.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Download WordPress.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the correct permissions on the WordPress folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure WordPress to connect to our RDS using the endpoint we found when gathering
    facts; we are reusing the password file we generated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Install WordPress using the Elastic Load Balancer URL and details from the
    default variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: To keep things simple, we are not managing the theme or plugins using Ansible.
  prefs: []
  type: TYPE_NORMAL
- en: This is where we stop running tasks on the instance we discovered/launched in
    the previous role; it is now time for us to switch back to our Ansible controller
    and make an AMI using our instance.
  prefs: []
  type: TYPE_NORMAL
- en: AMI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This role does not need to make any choices, it simply takes our host from
    the `ec2_instances` group and creates an image of it. To start, let''s create
    the role:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'The role is made up of three tasks, one of which is a pause. First of all,
    in `roles/ami/tasks/main.yml`, we need to find out some information about the
    instance. We are using the `ec2_instance_facts` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we know about the instance, we can create the AMI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we are using the `instance_id` we discovered when running the
    `ec2_instance_facts` module; we are also using the `ansible_date_time` variable,
    which was defined when the `gather_facts` module was called to give our AMI a
    unique name.
  prefs: []
  type: TYPE_NORMAL
- en: 'As already mentioned, the final task is a pause:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: This is required as it can take a short while for our newly created AMI to fully
    register and be available in the AWS API.
  prefs: []
  type: TYPE_NORMAL
- en: Autoscaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The final role in our playbook creates a launch configuration and then creates/updates
    an autoscaling group to finally launch our instances. It then does a tiny bit
    of housekeeping. To create the role, run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'First of all, there are a few default variables we need to set in `roles/autoscaling/default/main.yml`;
    these details show how many instances we want running at any one time, and also
    how many instances we replace at a time when doing a deployment of a new AMI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: What those variables are saying is that we want three instances running at all
    times, so if there are two, then launch more and never launch more than nine at
    any one time. When deploying a new image, replace instances two at a time.
  prefs: []
  type: TYPE_NORMAL
- en: We are also defining the health check, where, using the Elastic Load Balancer
    check, we are telling the instances to launch using a public IP address, meaning
    that we can access them over SSH, and finally, we are defining the type of instance
    to use.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first task we need to define in `roles/autoscaling/tasks/main.yml` needs
    to find the right AMI to use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, we need to know the details of the last AMI we built:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we need to get the AMI ID and also the AMI name; we will be using
    this to name the launch configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Next up, we have the task, which uses the previous information to create the
    launch configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have the launch configuration created, we can create/update the autoscaling
    group to reference it. Before we do, we need to find out the **Amazon Resource
    Name** (**ARN**) of the target group:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have that information, we can move on to the next task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: An autoscaling group ensures that we have our desired number of EC2 instances
    running at all times. If there are none running, it launches them and registers
    them with the target group for the Elastic Load Balancer.
  prefs: []
  type: TYPE_NORMAL
- en: If there are instances already running and we have updated the launch configuration,
    then it will do a rolling deploy of our new configuration, making sure that we
    never have any downtime as new instances are launched and registered before old
    ones are removed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final task removes any `tmp` instances we may have running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: This should leave us with our desired state running and nothing more.
  prefs: []
  type: TYPE_NORMAL
- en: Running the playbook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first thing we need to do is update our `production` inventory file; this
    should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we are defining the host groups and also configuring Ansible
    to use the `centos` user, which is the default for the original AMI we are using.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `site.yml` file needs to be updated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we now have three sections; the first section prepares the environment,
    as we have already seen—there is also the addition of the `ec2` role. This section
    is all executed on the Ansible controller.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next section, we move over to running the roles against the host in
    the `ec2_instance` group; as already mentioned, we are using `become: yes` and
    `become_method: sudo` on this host because the user we are connecting with, `centos`,
    does not have the correct privileges we need to install our software stack. This
    is why we need to disable `become` when using the `local_action` module. The third
    section takes us back to our Ansible controller, where we use the AWS API to create
    our AMI and launch it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Don''t forget to set your access key and secret access key environment variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'Before we run the playbook you need to make sure that you are subscribed to
    the CentOS 7 Amazon Machine Image in the AWS Marketplace, to do this go to the
    following link and hit the subscribe button, if you are not subscribed to the
    AMI you will receive an error when you run the playbook instructing you that you
    do not have access to the image: [https://aws.amazon.com/marketplace/pp/B00O7WM7QW](https://aws.amazon.com/marketplace/pp/B00O7WM7QW).'
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to be timing our playbook to run again, so, to execute the playbook,
    use the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'As we have already seen the output of half of the playbook running, I am going
    to skip the output of the `vpc`, `subnets`, `gateway`, `securitygroups`, `elb`,
    `rds`, and `efs` roles, meaning that we will start with the `ec2` one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'The playbook ran for me in the following time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'So, from a single command and in 32 minutes, we have a highly available vanilla
    WordPress installation. If you find out the public URL of your Elastic Load Balancer
    from the AWS console, you should be able to see your site:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/5881a9c1-2284-48e3-a975-9cdfaa51b5e4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Checking the EC2 instances in the AWS console, we can see that there are three
    instances, all called `wordpress-ec2`, running and the `wordpress-tmp` instance
    has been terminated:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/abb0b8b8-edcb-48ea-ba19-4d6f8c9ce447.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, let''s see what happens when we run the playbook again. We should not
    only see it execute more quickly, but it should skip a few roles:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, I have truncated the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, I got the following timings returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'Once complete, I checked that I could still log in to WordPress using the username
    (`ansible`) and password (`password`) we set in the playbook by going to my Elastic
    Load Balancer URL and adding `/wp-admin` to the end:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/4e2a20d2-626e-4bd8-a44a-f444ded054e7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can see what happened in the autoscaling activity logs in the AWS console:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/5560c9c1-21d8-4b43-a1e1-b7fa840ca59d.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, three new instances were launched and three terminated.
  prefs: []
  type: TYPE_NORMAL
- en: Terminating all the resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we complete this chapter, we need to look at terminating the resources;
    the only additions we need to make are to remove the autoscaling group and AMIs.
    To do this, we are going to add four tasks to `roles/remove/tasks/main.yml`; starting
    at the top of the file, add the following two tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: The first task removes the autoscaling group. This, in turn, will terminate
    any instances that have been launched by it. We have also built in a pause to
    ensure that everything has been removed properly from the AWS API.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the end of the role, add the following two tasks to remove all of the AMIs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'You can then run the playbook with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: As before, don't forget to check that the Elastic Load Balancer has been removed
    before progressing. Once the playbook has run, I would recommend you log in to
    the AWS console and double-check that everything has been correctly removed. The
    playbook does not remove the launch configurations, which should not be a problem
    as there are no costs associated with them. However, I would recommend checking
    on unattached EBS volumes and snapshots as these will incur costs.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have taken our AWS to the next level by creating and launching
    a highly available WordPress installation. By leveraging the various services
    offered by AWS, we engineered out any single points of failure with regards to
    the availability of instances and availability zones.
  prefs: []
  type: TYPE_NORMAL
- en: We also built logic into our playbook so that we can use the same command to
    launch a new deployment or update the operating system on an existing one with
    a rolling deploy of new instance AMIs that contain our updated packages—allowing
    for zero downtime during deployment.
  prefs: []
  type: TYPE_NORMAL
- en: While the WordPress deployment is probably as simple as we could make it, the
    process of deploying the production-ready images would remain similar when using
    a more complicated application.
  prefs: []
  type: TYPE_NORMAL
- en: In our next chapter, we are going to look at moving from public cloud to private
    cloud, and how Ansible interacts with VMware.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is the name of the variable that is registered using the `gather_facts`
    option, which contains the date and time our playbook was executed?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True or false: Ansible automatically figures out which task it needs to execute,
    meaning we don''t have to define any logic ourselves.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explain why we have to use the `local_action` module.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which command do we prepend to our `ansible-playbook` command to record how
    long our command took to execute?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True or false: When using autoscaling, you have to manually launch EC2 instances.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the playbook so that it gives you the public URL of the Elastic Load
    Balancer at the end of the playbook run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can find more details about CentOS AMIs on the AWS Marketplace at [https://aws.amazon.com/mp/centos/](https://aws.amazon.com/mp/centos/).
  prefs: []
  type: TYPE_NORMAL
