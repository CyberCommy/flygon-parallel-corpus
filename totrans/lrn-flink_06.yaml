- en: Chapter 6. Machine Learning Using FlinkML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we talked about how to solve complex event-processing
    problems using the Flink CEP library. In this chapter, we are going to see how
    to do machine learning using Flink's machine learning library, called FlinkML.
    FlinkML consists of a set of supported algorithms, which can be used to solve
    real-life use cases. Throughout this chapter, we will look at what algorithms
    are available in FlinkML and how to apply them.
  prefs: []
  type: TYPE_NORMAL
- en: Before diving deep into FlinkML, let us first try to understand basic machine
    learning principles.
  prefs: []
  type: TYPE_NORMAL
- en: What is machine learning?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Machine learning is a stream of engineering which uses mathematics to allow
    machines to make classifications, predictions, recommendations, and so on, based
    on the data provided to them. This area is vast, and we could spend years discussing
    it. But in order to keep our discussion focused, we will discuss only what is
    required for the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Very broadly, machine learning can be divided into three big categories:'
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semi supervised learning![What is machine learning?](img/image_06_001.jpg)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The preceding diagram shows a broad classification of machine learning algorithms.
    Now let's discuss these in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In supervised learning, we are generally given an input dataset, which is a
    historical record of actual events. We are also given what the expected output
    should look like. Using the historical data, we choose which factors contributed
    to the results. Such attributes are called features. Using the historical data,
    we understand how the previous results were calculated and apply that same understanding
    to the data on which we want to make predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Supervised learning can be again subdivided into:'
  prefs: []
  type: TYPE_NORMAL
- en: Regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In regression problems, we try to predict results using inputs from a continuous
    function. Regression means predicting the score of one variable based on the scores
    of another variable. The variable we will be predicting is called the criterion
    variable, and the variable from which we will be doing our predictions is called
    the predictor variable. There can be more than one predictor variable; in this
    case, we need to find the best fitting line, called the regression line.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can read more about regression at [https://en.wikipedia.org/wiki/Regression_analysis](https://en.wikipedia.org/wiki/Regression_analysis).
  prefs: []
  type: TYPE_NORMAL
- en: 'Some very common algorithms used for solving regression problem are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support Vector Machine (SVM)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Naive Bayes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random forest
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linear regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Polynomial regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In classification, we predict the output in discrete results. Classification,
    being a part of supervised learning, also needs the input data and sample output
    to be given. Here, based on the features, we try to classify the results into
    sets of defined categories. For instance, based on the features given, classify
    records of people into male or female. Or, based on customer behavior, predict
    if he/she would buy a product or not. Or based on the e-mail content and sender,
    predict if the e-mail is spam or not. Refer to [https://en.wikipedia.org/wiki/Statistical_classification](https://en.wikipedia.org/wiki/Statistical_classification).
  prefs: []
  type: TYPE_NORMAL
- en: In order to understand the difference between regression and classification,
    consider the example of stock data. Regression algorithms can help to predict
    the value of stock in upcoming days, while classification algorithms can help
    decide whether to buy the stock or not.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unsupervised learning does not give us any idea about how our results should
    look. Instead, it allows us to group data based on the features of the attributes.
    We derive the clustering based on the relationships among the records.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike supervised learning, there is no validation we can do to verify our results,
    which means there is no feedback method to teach us whether we did right or wrong.
    Unsupervised learning is primarily based on clustering algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Clustering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to understand clustering more easily, let's consider an example; let's
    say we have 20,000 news articles on various topics and we have to group them based
    on their content . In this case, we can use clustering algorithms, which would
    group set of articles into small groups.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also consider the basic example of fruits. Let''s say we have apples,
    bananas, lemons, and cherries in a fruit basket and we need to classify them into
    groups. If we look at their colors, we can classify them into two groups:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Red color group**: Apples and cherries'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Yellow color group**: Bananas and lemons'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now we can do more grouping based on another feature, its size:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Red color and large size**: Apples'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Red color and small size**: Cherries'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Yellow color and large size**: Banana'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Yellow color and small size**: Lemons'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram shows a representation of clustering:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Clustering](img/image_06_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This way, by looking at more features, we can also do more clustering. Here,
    we don't have any training data and a variable to be predicted, unlike in supervised
    learning. Our only task is to learn more about the features and cluster the records
    based on inputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some of the algorithms commonly used for clustering:'
  prefs: []
  type: TYPE_NORMAL
- en: K-means clustering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hierarchical clustering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden Markov models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Association
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Association problems are more about learning, and making recommendations by
    defining association rules. Association rules could, for example, refer to the
    assumption that people who bought an iPhone are more likely to buy an iPhone case.
  prefs: []
  type: TYPE_NORMAL
- en: These days, many retail companies use these algorithms to make personalized
    recommendations. For instance, on [www.amazon.com](http://www.amazon.com), if
    I tend to purchase product *X* and then Amazon recommends me product *Y* as well,
    there must be some association between the two.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the algorithms based on these principles are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Apriori algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eclat algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FDP growth algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semi-supervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Semi-supervised learning is a sub-class of supervised learning that considers
    unlabeled data for training. Generally, while training, it has a good amount of
    unlabeled data and only a very small amount of labeled data. Many researchers
    and machine learning practitioners have found that, when labeled data is used
    in conjunction with unlabeled data, the results are likely to be more accurate.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: More details on semi-supervised learning can be found at [https://en.wikipedia.org/wiki/Semi-supervised_learning](https://en.wikipedia.org/wiki/Semi-supervised_learning).
  prefs: []
  type: TYPE_NORMAL
- en: FlinkML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: FlinkML is a library of sets of algorithms supported by Flink that can be used
    to solve real-life use cases. The algorithms are built so that they can use the
    distributed computing power of Flink and make predictions or do clustering and
    so on with ease. Right now, there are only a few sets of algorithms supported,
    but the list is growing.
  prefs: []
  type: TYPE_NORMAL
- en: FlinkML is being built with the focus on ML developers needing to write minimal
    glue code. Glue code is code that helps bind various components together. Another
    goal of FlinkML is to keep the use of algorithms simple.
  prefs: []
  type: TYPE_NORMAL
- en: Flink exploits in-memory data streaming and executes iterative data processing
    natively. FlinkML allows data scientists to test their models locally, with a
    subset of data, and then execute them in cluster mode on bigger data.
  prefs: []
  type: TYPE_NORMAL
- en: FlinkML is inspired by scikit-learn and Spark's MLlib, which allows you to define
    data pipelines cleanly and solve machine learning problems in a distributed manner.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the road map Flink''s development team is aiming to build:'
  prefs: []
  type: TYPE_NORMAL
- en: Pipelines of transformers and learners
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data pre-processing:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature scaling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Polynomial feature base mapper
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature hashing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature extraction for text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dimensionality reduction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Model selection and performance evaluation:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model evaluation using a variety of scoring functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cross-validation for model selection and evaluation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyper-parameter optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Supervised learning:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimization framework
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stochastic Gradient Descent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: L-BFGS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generalized Linear Models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple linear regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LASSO, Ridge regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-class Logistic regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random forests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support Vector Machines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Unsupervised learning:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clustering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: K-means clustering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Principal Components Analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Recommendation:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ALS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Text analytics:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LDA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Statistical estimation tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Distributed linear algebra
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Streaming ML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The algorithms highlighted are already part of the existing Flink source code.
    In the following section, we will look at how we can use those in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Supported algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To get started with FlinkML, we first need to add the following Maven dependency:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now let's try to understand the supported algorithms and how to use those.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Flink supports three algorithms in the supervised-learning category. They are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Support Vector Machine (SVM)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple linear regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimization framework
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's get started learning about them one at a time.
  prefs: []
  type: TYPE_NORMAL
- en: Support Vector Machine
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Support Vector Machines** (**SVMs**) are supervised learning models, which
    analyze the data solving classification and regression problems. It helps classify
    objects into one category or another. It is non-probabilistic linear classification.
    There are various examples in which SVM can be used, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Regular data classification problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text and hypertext classification problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image classification problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Biological and other science problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flink supports SVM based on a soft-margin using a communication-efficient distributed
    dual-coordinate ascent algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Details on this algorithm are available at [https://ci.apache.org/projects/flink/flink-docs-release-1.2/dev/libs/ml/svm.html#description](https://ci.apache.org/projects/flink/flink-docs-release-1.2/dev/libs/ml/svm.html#description).
  prefs: []
  type: TYPE_NORMAL
- en: Flink uses **Stochastic Dual Coordinate Ascent** (**SDCA**) to solve the minimization
    problem. To make this algorithm efficient in a distributed environment, Flink
    uses the CoCoA algorithm, which calculates the SDCA on a local data block and
    then merges it into global state.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The implementation of this algorithm is based on the following paper: [https://arxiv.org/pdf/1409.1458v2.pdf](https://arxiv.org/pdf/1409.1458v2.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s look at how we can solve a real-life problem using this algorithm.
    We will take the example of the Iris dataset ([https://en.wikipedia.org/wiki/Iris_flower_data_set](https://en.wikipedia.org/wiki/Iris_flower_data_set)),
    consisting of four attributes which decide the species of Iris. The following
    is some sample data:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Sepal length** | **Sepal width** | **Petal length** | **Petal width** |
    **Species** |'
  prefs: []
  type: TYPE_TB
- en: '| 5.1 | 3.5 | 1.4 | 0.2 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 5.6 | 2.9 | 3.6 | 1.3 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| 5.8 | 2.7 | 5.1 | 1.9 | 3 |'
  prefs: []
  type: TYPE_TB
- en: 'Here, it is important to use categories in number format to be used as input
    to SVM:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Species code** | **Species name** |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Iris Setosa |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Iris Versicolor |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Iris Virginica |'
  prefs: []
  type: TYPE_TB
- en: One more thing we need to do before using data for Flink's SVM algorithm is
    to convert this CSV data into LibSVM data.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: LibSVM data is a special format used for specifying SVM datasets. More information
    on LibSVM is available at [https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/).
  prefs: []
  type: TYPE_NORMAL
- en: To convert CSV data to LibSVM data, we will use some open-source Python code
    available at [https://github.com/zygmuntz/phraug/blob/master/csv2libsvm.py](https://github.com/zygmuntz/phraug/blob/master/csv2libsvm.py).
  prefs: []
  type: TYPE_NORMAL
- en: 'To convert CSV to LibSVM, we need to execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s get started with writing the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: So, now we are all set to run the program, and you will the see the predicted
    output in the output folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also fine-tune the results by setting various parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Parameter** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `Blocks` | Sets the number of blocks into which the input data will be split.
    It is ideal to set this number equal to the parallelism you want to achieve. On
    each block, local stochastic dual-coordinate ascent is performed. The default
    value is `None`. |'
  prefs: []
  type: TYPE_TB
- en: '| `Iterations` | Sets the number of iterations of the outer loop method, for
    example, the amount of time the SDCA method should applied on blocked data. The
    default value is `10`. |'
  prefs: []
  type: TYPE_TB
- en: '| `LocalIterations` | Defines the maximum number of SDCA iterations that need
    to be executed locally. The default value is `10`. |'
  prefs: []
  type: TYPE_TB
- en: '| `Regularization` | Sets the regularization constant of the algorithm. The
    higher you set the value, the smaller the 2 norm of the weighted vector be. The
    default value is `1`. |'
  prefs: []
  type: TYPE_TB
- en: '| `StepSize` | Defines the initial step size for the updates of weight vector.
    This value needs to be set up in case the algorithm becomes unstable. The default
    value is `1.0`. |'
  prefs: []
  type: TYPE_TB
- en: '| `ThresholdValue` | Defines the limiting value for the decision function.
    The default value is `0.0`. |'
  prefs: []
  type: TYPE_TB
- en: '| `OutputDecisionFunction` | Setting this to true will return the hyperplane
    distance for each example. Setting it to false will return the binary label. |'
  prefs: []
  type: TYPE_TB
- en: '| `Seed` | Sets the random long integer. This will be used to initialize the
    random number generator. |'
  prefs: []
  type: TYPE_TB
- en: Multiple Linear Regression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Multiple Linear Regression** (**MLR**) is an extension of simple linear regression
    where more than one independent variable (*X*) is used to determine the single
    independent variable (*Y*). The predicted value is a linear transformation of
    input variables such that the sum of squared deviations of the observed and predicted
    is minimum.'
  prefs: []
  type: TYPE_NORMAL
- en: MLR tries to model the relationship between multiple explanatory variables and
    response variables by fitting a linear equation.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A more detailed explanation of MLR can be found on this link [http://www.stat.yale.edu/Courses/1997-98/101/linmult.htm](http://www.stat.yale.edu/Courses/1997-98/101/linmult.htm).
  prefs: []
  type: TYPE_NORMAL
- en: Let's try solving the same classification problem of Iris dataset using MLR
    now. First we need the training dataset on which we can train our mode.
  prefs: []
  type: TYPE_NORMAL
- en: Here we will be using the same data files we used in previous section on SVM.
    So now we have `iris-train.txt` and `iris-test.txt` which are converted into LibSVM
    format.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet shows how MLR can be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The complete code and the data files are available for download on [https://github.com/deshpandetanmay/mastering-flink/tree/master/chapter06](https://github.com/deshpandetanmay/mastering-flink/tree/master/chapter06). We
    can also fine-tune the results by setting various parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Parameter** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `Iterations` | Sets the maximum number of iterations. The default value is
    `10`. |'
  prefs: []
  type: TYPE_TB
- en: '| `Stepsize` | The step size of the gradient descent method. This value controls
    how far the gradient descent method can move in the opposite direction. Tuning
    this parameter is very important to get better results. The default value is `0.1`.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `Convergencethreshold` | The threshold for the relative change of the sum
    of squared residuals until the iteration is stopped. The default value is `None`.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `Learningratemethod` |  `Learningratemethod` is used to calculate the learning
    rate of each iteration. |'
  prefs: []
  type: TYPE_TB
- en: Optimization framework
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Optimization framework in Flink is a developer-friendly package which can be
    used to solve optimization problems. This is not a specific algorithm to solve
    exact problems, but it is the basis of every machine learning problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally, it is about finding the model, with a set of parameters, with a
    minimization function. FlinkML supports **Stochastic Gradient Descent** (**SGD**),
    with the following types of regularizations:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Regularization function** | **Class name** |'
  prefs: []
  type: TYPE_TB
- en: '| L1 regularization | `GradientDescentL1` |'
  prefs: []
  type: TYPE_TB
- en: '| L2 regularization | `GradientDescentL2` |'
  prefs: []
  type: TYPE_TB
- en: '| No regularization | `SimpleGradient` |'
  prefs: []
  type: TYPE_TB
- en: 'The following code snippet shows how to use SGD using FlinkML:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also use parameters to fine-tune the algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Parameter** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `LossFunction` | Flink supports the following loss functions:'
  prefs: []
  type: TYPE_NORMAL
- en: Squared Loss
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hinged Loss
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logistic Loss
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The default is `None`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| `RegularizationConstant` | The weight of regularization to be applied. The
    default value is `0.1`. |'
  prefs: []
  type: TYPE_TB
- en: '| `Iterations` | The maximum number of iterations to be performed. The default
    is `10`. |'
  prefs: []
  type: TYPE_TB
- en: '| `ConvergenceThreshold` | The threshold for relative change of the sum of
    squared residuals until the iteration is stopped. The default value is `None`.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `LearningRateMethod` | This method is used to calculate the learning rate
    of each iteration. |'
  prefs: []
  type: TYPE_TB
- en: '| `LearningRate` | This is the initial learning rate for the gradient descent
    method. |'
  prefs: []
  type: TYPE_TB
- en: '| `Decay` | The default value is `0.0`. |'
  prefs: []
  type: TYPE_TB
- en: Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Recommendation engines are one of the most interesting and heavily used machine
    learning techniques to provide user-based and item-based recommendations. E-commerce
    companies such as Amazon use recommendation engines to personalize recommendations
    based on the purchasing patterns and review ratings of its customers.
  prefs: []
  type: TYPE_NORMAL
- en: Flink also supports ALS-based recommendations. Let's look at ALS in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Alternating Least Squares
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **Alternating Least Squares** (**ALS**) algorithm factorizes a given matrix,
    *R*, into two factors, *U* and *V*, such that  ![Alternating Least Squares](img/image_06_003.jpg)
  prefs: []
  type: TYPE_NORMAL
- en: In order to better understand the application of this algorithm, let's assume
    that we have a dataset which contains the rating, *r*, provided by user *u* for
    book *b*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a sample data format (`user_id`, `book_id`, `rating)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can feed this information to the ALS algorithm and start getting recommendations
    from it. The following is a code snippet for using ALS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you execute the application, you''ll get the results as recommendations.
    Like with other algorithms, you can fine-tune the parameters to get better results:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Parameter** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `NumFactors` | The number of latent factors to use for the underlying model.
    The default value is `10`. |'
  prefs: []
  type: TYPE_TB
- en: '| `Lambda` | This is a regularization factor; we can tune this parameter for
    better results. The default is `1`. |'
  prefs: []
  type: TYPE_TB
- en: '| `Iterations` | The maximum number of iterations to be performed. The default
    is `10`. |'
  prefs: []
  type: TYPE_TB
- en: '| `Blocks` | The number of blocks in which user and item matrix are grouped.
    The fewer the blocks, the less data is sent redundantly. The default value is
    `None`. |'
  prefs: []
  type: TYPE_TB
- en: '| `Seed` | The seed value to initiate the item matrix generator. The default
    is `0`. |'
  prefs: []
  type: TYPE_TB
- en: '| `TemporaryPath` | This is a path to be used for storing intermediate results.
    |'
  prefs: []
  type: TYPE_TB
- en: Unsupervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now let's try to understand what FinkML offers for unsupervised learning. For
    now, it supports only one algorithm, called the k Nearest Neighbor join algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: k Nearest Neighbour join
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **k Nearest Neighbor** (**kNN**) algorithm is designed to find the k Nearest
    Neighbour from a dataset for every object in another dataset. It is one of the
    most widely used solutions in many data-mining algorithms. The kNN is an expensive
    operation, as it is a combination of finding the k nearest neighbor and performing
    a join. Considering the volume of the data, it is very difficult to perform this
    operation on a centralized single machine, hence it is always good to have solutions
    that can work on distributed architecture. The FlinkML algorithm provides kNN
    on a distributed environment.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A research paper describing the implementation of kNN on a distributed environment
    can be found here: [https://arxiv.org/pdf/1207.0141v1.pdf](https://arxiv.org/pdf/1207.0141v1.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: Here, the idea is to compute the distance between every training and testing
    point and then find the nearest points for a given point. Computing the distance
    between each point is a time-consuming activity, which is eased out in Flink by
    implementing quad trees.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using quad trees reduces the computation by partitioning the dataset. This
    reduces the computation to the subset of data only. The following diagram shows
    computation with and without quad trees:'
  prefs: []
  type: TYPE_NORMAL
- en: '![k Nearest Neighbour join](img/image_06_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You can find a detailed discussion on using quad trees to calculate the nearest
    neighbors here: [http://danielblazevski.github.io/assets/player/KeynoteDHTMLPlayer.html](http://danielblazevski.github.io/assets/player/KeynoteDHTMLPlayer.html).'
  prefs: []
  type: TYPE_NORMAL
- en: It's not always the case that quad trees will perform better. If the data is
    spatial, the quad trees might be the worst choice. But as a developer, we don't
    need to worry about it as FlinkML takes care of deciding whether to use quad tree
    or not based on the data available.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet shows how to use kNN join in FlinkML:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The following are some parameters we can use to fine-tune the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Parameter** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `K` | The number of nearest neighbours to search for. The default is `5`.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `DistanceMetric` | Sets the distance metric to be used to calculate the distance
    between two points. By default, Euclidian Distance Metric is used. |'
  prefs: []
  type: TYPE_TB
- en: '| `Blocks` | The number of blocks into which the input data should be split.
    It is ideal to set this number equal to the degree of parallelism. |'
  prefs: []
  type: TYPE_TB
- en: '| `UseQuadTree` | Sets whether to use quad tree for processing or not. The
    default value is `None`. If nothing is specified, the algorithm decides on its
    own. |'
  prefs: []
  type: TYPE_TB
- en: Utilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'FlinkML supports various extensible utilities, which can be handy while doing
    data analysis and predictions. One such utility is distance metrics. Flink supports
    a set of distance metrics which can be used. The following link shows Flink-supported
    distance metrics: [https://ci.apache.org/projects/flink/flink-docs-release-1.2/dev/libs/ml/distance_metrics.html](https://ci.apache.org/projects/flink/flink-docs-release-1.2/dev/libs/ml/distance_metrics.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 'If any of the previously mentioned algorithms do not satisfy your needs, you
    can think about writing your own custom distance algorithm. The following code
    snippet shows how to do so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: A good application of using distance metrics is the kNN join algorithm, where
    you can set the distance metric to use.
  prefs: []
  type: TYPE_NORMAL
- en: Another important utility is `Splitter`, which can be used for cross validation.
    In some cases, we may not have a test dataset to validate our results. In such
    cases, we can split the training dataset using `Splitter`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we are splitting the training dataset into portions
    of 60% and 40% of the actual data.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is another method to fetch better results, called `TrainTestHoldout`
    split. Here, we use some portion of the data for training, some for testing, and
    another set for final result validations. The following snippet shows how to do
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use another strategy, called K fold splits. In this method, the training
    set is split into *k* equal size folds. Here, an algorithm is created for each
    fold and then validated against its testing set. The following code shows how
    to do k-fold splits:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also use **Multi Random Splits**; here we can specify how many datasets
    to create and of what portion of the original:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Data pre processing and pipelines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Flink supports Python scikit-learn style pipeline. A pipeline in FlinkML is
    feature to chain multiple transformers and predictors in one go. In general, many
    data scientists would like to see and build the flow of machine learning application
    with ease. Flink allows them to do so using the concept of pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, there are three building blocks of ML pipelines:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Estimator:** Estimator performs the actual training of a model using a `fit`
    method. For example, finding correct weights in a linear regression model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transformer:** Transformer as the name suggests have a `transform` method
    which can help in scaling the input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Predictor:** Predictors have the `predict` method which applies the algorithm
    for generating predictions, for example, SVM or MLR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A pipeline is a chain of estimator, transformers and predictor. The predictor
    is the end of a pipeline and nothing can be chained after that.
  prefs: []
  type: TYPE_NORMAL
- en: Flink supports various data pre-processing tools which would help us advance
    the results. Let's start understanding the details.
  prefs: []
  type: TYPE_NORMAL
- en: Polynomial features
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The polynomial feature is a transformer which maps a vector into the polynomial
    feature space of degree *d*. Polynomial feature helps in solving classification
    problems by changing the graph of the function. Let''s try to understand this
    by an example:'
  prefs: []
  type: TYPE_NORMAL
- en: Consider a linear formula: *F(x,y) = 1*x + 2*y;*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Imagine we have two observations:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*x=12* and *y=2*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*x=5* and *y =5.5*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In both cases, we get *f() = 16*. If these observations belong to two different
    classes then we cannot differentiate between the two. Now if we add one more feature
    called *z* which is combination of previous two features *z = x+y*.
  prefs: []
  type: TYPE_NORMAL
- en: So now *f(x,y,z) = 1*x + 2*y + 3*z*
  prefs: []
  type: TYPE_NORMAL
- en: Now the same observations would be
  prefs: []
  type: TYPE_NORMAL
- en: '*(1*12)+ (2*2) + (3*24) = 88*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*(1*5)+ (2*5.5) + (3*27.5) = 98.5*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This way adding a new feature using existing features can help us get better
    results. Flink polynomial features allows us to do the same with pre-build functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to use polynomial features in Flink, we have the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Standard scaler
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Standard scaler helps scale the input data using the user-specified mean and
    variance. If the user does not specify any values then default mean is `0` and
    standard deviation would be `1`. Standard scaler is a transformer which has `fit`
    and `transform` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'First we need to define the values for mean and standard deviation as shown
    in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Next we need to let it learn about mean and standard deviation of training
    dataset as shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'And finally we scale the provided data using the user-defined mean and standard
    deviation as shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Now we can use this scaled input data to do further transformation and analysis.
  prefs: []
  type: TYPE_NORMAL
- en: MinMax scaler
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: MinMax scaler is like standard scaler but the only difference is it makes sure
    that scaling of each feature lies between user-defined `min` and `max` values.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet shows how to use this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Thus, we can use these data pre-processing operations to enhance the results.
    These can also be combined in pipelines to create the workflow.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet shows how to use these data pre-processing operations
    in pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The complete code is available on GitHub at [https://github.com/deshpandetanmay/mastering-flink/tree/master/chapter06](https://github.com/deshpandetanmay/mastering-flink/tree/master/chapter06).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about the different types of machine learning algorithm.
    We looked at various supervised and unsupervised algorithms, and their respective
    examples. We also looked at various utilities provided by FlinkML, which can be
    very handy during data analysis. Later we looked at data pre-processing operations
    and how to use them in pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapter, we will look at the graph-processing capabilities
    of Flink.
  prefs: []
  type: TYPE_NORMAL
