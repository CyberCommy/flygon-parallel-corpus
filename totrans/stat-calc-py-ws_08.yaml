- en: 8\. Foundational Probability Concepts and Their Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Overview
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be familiar with basic and foundational
    concepts in probability theory. You'll learn how to use NumPy and SciPy modules
    to perform simulations and solve problems by calculating probabilities using simulations.
    This chapter also covers how to calculate the probabilities of events using simulations
    and theoretical probability distributions. Along with this, we'll conceptually
    define and use random variables included in the scipy.stats module. We will also
    understand the main characteristics of the normal distribution and calculate probabilities
    by computing the area under the curve of the probability distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous chapter, we learned how to perform the first steps in any statistical
    analysis. Given a business or scientific problem and a related dataset, we learned
    how to load the dataset and prepare it for analysis. Then, we learned how to calculate
    and use descriptive statistics to make sense of the variables. Finally, we performed
    EDA to complement the information we gathered from the descriptive statistics
    and gained a better understanding of the variables and their possible relationships.
    After getting a basic understanding of an analytical problem, you may need to
    go one step further and use more sophisticated quantitative tools, some of which
    are used in the following fields:'
  prefs: []
  type: TYPE_NORMAL
- en: Inferential statistics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prescriptive analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'What do all of these domains have in common? Many things: for example, they
    have a mathematical nature, they make heavy use of computational tools, and in
    one way or another they use **probability theory**, which is one of the most useful
    branches of applied mathematics and provides the foundation and tools for other
    disciplines, such as the ones mentioned previously.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll give a very brief introduction to probability theory.
    Unlike traditional statistical books, in this chapter, we'll make heavy use of
    simulations to put the theoretical concepts into practice and make them more concrete.
    For this, we will make extensive use of NumPy's and SciPy's random number generation
    capabilities and we will learn how to use simulations to solve problems. After
    introducing the mandatory foundational concepts, we'll show you how to produce
    random numbers using NumPy and use these capabilities to calculate probabilities.
    After doing that, we'll define the concept of random variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Later in this chapter, we''ll delve deeper into the two types of random variables:
    discrete and continuous, and for each type, we will learn how to create random
    variables with SciPy, as well as how to calculate exact probabilities with these distributions.'
  prefs: []
  type: TYPE_NORMAL
- en: Randomness, Probability, and Random Variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is a dense section, with many theoretical concepts to learn. Although it
    is heavy, you will finish this section with a very good grasp of some of the most
    basic and foundational concepts in probability theory. We will also introduce
    very useful methods you can use to perform simulations using NumPy so that you
    get to play around with some code. By using simulations, we hope to show you how
    the theoretical concepts translate into actual numbers and problems that can be
    solved with these tools. Finally, we will define **random variables** and **probability
    distribution**, two of the most important concepts to know about when using statistics
    to solve problems in the real world.
  prefs: []
  type: TYPE_NORMAL
- en: Randomness and Probability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We all have an intuitive idea of the concept of randomness and use the term
    in everyday life. Randomness means that certain events happen unpredictably or
    without a pattern.
  prefs: []
  type: TYPE_NORMAL
- en: One paradoxical fact about random events is that although individual random
    events are, by definition, unpredictable, when considering many such events, it
    is possible to predict certain results with very high confidence. For instance,
    when flipping a coin *once*, we cannot know which of the two possible outcomes
    we will see (heads or tails). On the other hand, when flipping a coin *1,000*
    times, we can be almost sure that we will get between 450 and 550 heads.
  prefs: []
  type: TYPE_NORMAL
- en: 'How do we go from individually unpredictable events to being able to predict
    something meaningful about a collection of them? The key is probability theory,
    the branch of mathematics that formalizes the study of randomness and the calculation
    of the likelihood of certain outcomes. Probability can be understood as a measure
    of uncertainty, and probability theory gives us the mathematical tools to understand
    and analyze uncertain events. That''s why probability theory is so useful as a
    decision-making tool: by rigorously and logically analyzing uncertain events,
    we can reach better decisions, despite the uncertainty.'
  prefs: []
  type: TYPE_NORMAL
- en: Uncertainty can come from either ignorance or pure randomness, in such a way
    that flipping a coin is not a truly random process if you know the mass of the
    coin, the exact position of your fingers, the exact force applied when throwing
    it, the exact gravitational pull, and so on. With this information, you could,
    in principle, predict the outcome, but in practice, we don't know all these variables
    or the equations to actually make an exact prediction. Another example could be
    the outcome of a football (soccer) game, the results of a presidential election,
    or if it's going to rain one week from now.
  prefs: []
  type: TYPE_NORMAL
- en: Given our ignorance about what will happen in the future, assigning a probability
    is what we can do to come up with a *best guess*.
  prefs: []
  type: TYPE_NORMAL
- en: Probability theory is also a big business. Entire industries, such as lotteries,
    gambling, and insurance, have been built around the laws of probability and how
    to monetize the predictions we can make from them. The casino does not know if
    the person playing roulette will win in the next game, but because of probability
    laws, the casino owner is completely sure that roulette is a profitable game.
    The insurance company does not know if a customer will have a car crash tomorrow,
    but they're sure that having enough car insurance costumers paying their premiums
    is a profitable business.
  prefs: []
  type: TYPE_NORMAL
- en: Although the following section will feel a bit theoretical, it is necessary
    to get to know the most important concepts before we can use them to solve analytical
    problems.
  prefs: []
  type: TYPE_NORMAL
- en: Foundational Probability Concepts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will start with the basic terminology that you will find on most treatments
    of this subject. We must learn these concepts in order to be able to solve problems
    rigorously and to communicate our results in a technically correct fashion.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start with the notion of an **experiment**: a situation that happens
    under controlled conditions and from which we get an observation. The result we
    observe is called the **outcome** of the experiment. The following table presents
    some examples of experiments, along with some possible outcomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1: Example experiments and outcomes'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.1: Example experiments and outcomes'
  prefs: []
  type: TYPE_NORMAL
- en: 'The **sample space** of the experiment consists of the *mathematical set* of
    all possible outcomes. Finally, an **event** is any subset of the sample space.
    Each element of the sample space is called a **simple event** because it consists
    of a single element. We now have four terms that are related to each other and
    that are essential to probability theory: experiment, sample space, event, and
    outcome. To continue with our examples from the previous table, the following
    table presents the sample space and examples of events for the experiments:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2: Example experiments, sample spaces, and events'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.2: Example experiments, sample spaces, and events'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Please note that the details in the preceding table are assuming a maximum of
    1 transaction per minute is happening.
  prefs: []
  type: TYPE_NORMAL
- en: It is worth noting that we defined the sample space as a *set* in the mathematical
    sense. Therefore, we can use all the mathematical operations we know from set
    theory, including getting subsets (which are events). As events are subsets of
    a larger set, they are sets themselves, and we can use unions, intersections,
    and so on. The conventional notation for events is to use uppercase letters such
    as A, B, and C.
  prefs: []
  type: TYPE_NORMAL
- en: We say that an event has happened when the outcome of the experiment belongs
    to the event. For example, in the experiment *tossing a die*, if we are interested
    in the event *getting an odd number* and we observe any of the outcomes, that
    is, 1, 3, or 5, then we can say that the event has happened.
  prefs: []
  type: TYPE_NORMAL
- en: When performing a random experiment, we don't know which outcome we are going
    to get. What we do in probability theory is assign a number to all the possible
    events related to an experiment. This number is what we know as the *probability*
    of an event.
  prefs: []
  type: TYPE_NORMAL
- en: 'How do we assign probabilities to events? There are a couple of alternatives.
    However, regardless of the method we use to assign probabilities to events, the
    theory of probability and its results hold if our way of assigning probabilities
    to events fulfills the following four conditions. Given events *A* and *B* and
    their probabilities, denoted as *P(A)* and *P(B)*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![a](image/B15968_08_InlineEquation1.png): The probability of an event is always
    a number between 0 and 1\. The closer to 1, the more likely the event will occur.
    The extremes are 0 for an event that can''t occur and 1 for an event that will
    certainly occur.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![b](image/B15968_08_InlineEquation2.png): If A is the empty set, then the
    probability must be 0\. For instance, for the experiment *tossing a die*, the
    event *getting a number greater than 10* does not exist, hence this is the empty
    set and its probability is 0.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![c](image/B15968_08_InlineEquation3.png): This basically says that when performing
    an experiment, some outcome must occur for sure.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![d](image/B15968_08_InlineEquation4.png) for disjoint events A and B: If we
    have a collection of non-overlapping events, A and B, then the probability the
    event (A U B), also known as *A or B*, can be obtained by adding the individual
    probabilities. These rules also apply for more than two events.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This subsection has been heavy in terms of concepts and theory, but it is important
    to understand these now, in order to avoid mistakes later. Fortunately, we have
    Python and NumPy with their great numerical capabilities that will help us put
    this theory into practice.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'A quick note on all the exercises and related test scripts: If you are using
    a CLI (such as Windows'' Command Prompt or Mac''s Terminal) to run the test scripts,
    it will throw an error, such as `Implement enable_gui in a subclass`. This is
    something to do with some of the commands being used in the notebooks (such as
    `%matplotlib` inline). So, if you want to run the test scripts, please use the
    IPython shell. The code for the exercises in this book is best run on Jupyter
    Notebooks.'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Simulations with NumPy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To start putting all this theory into practice, let''s begin by loading the
    libraries we will use in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We will make extensive use of NumPy's random number generation capabilities.
    We will use the random module (`np.random`), which is able to generate random
    numbers that follow many of the most important probability distributions (more
    on probability distributions later).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s begin by simulating a random experiment: *tossing a regular die*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s learn how to perform this experiment using NumPy. There are different
    ways to do this. We''ll use the function `randint` from the `random` module, which
    generates random integers between `low` (inclusive) and `high` (exclusive) arguments.
    Since we want to generate numbers between 1 and 6, our function will look like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s use our function ten times in a row to observe how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is an example output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Since these numbers are randomly generated, you will most likely get different values.
  prefs: []
  type: TYPE_NORMAL
- en: For this function and almost every other function that produces random numbers
    (or some other random result), it is sometimes necessary to generate random numbers
    in such a way that anyone running the code at any moment obtains the same results.
    For that, we need to use a `seed`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s add a line that creates the seed and then use our function ten times
    in a row to observe how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: As long as you run the first line containing the number 123 inside the seed
    function, anyone running this code (with the same NumPy version) will get the
    same output numbers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another useful function from the `numpy.random` module is `np.random.choice`,
    which can sample elements from a vector. Say we have a class of 30 students, and
    we would like to randomly chose four of them. First, we generate the fictional
    student list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, can use `np.random.choice` to randomly select four of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The `replace=False` argument ensures that once an element has been chosen, it
    can't be selected again. This is called **sampling without replacement**.
  prefs: []
  type: TYPE_NORMAL
- en: 'In contrast, **sampling with replacement** means that all the elements of the
    vector are considered when producing each sample. Imagine that all the elements
    of the vector are in a bag. We randomly pick one element for each sample and then
    put the element we got in the bag before drawing the next sample. An application
    of this could be as follows: say that we will give a surprise quiz to one student
    of the group, every week for 12 weeks. All the students are subjects who may be
    given the quiz, even if that student was selected in a previous week. For this,
    we could use `replace=True`, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, poor student 6 was chosen on weeks 1 and 10, and student 30
    on 6 and 8.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know how to use NumPy to generate dice outcomes and get samples
    (with or without replacement), we can use it to practice probability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 8.01: Sampling with and without Replacement'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will use `random.choice` to produce random samples with
    and without replacement. Follow these steps to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the NumPy library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Create two lists containing four different suits and 13 different ranks in
    the set of standard cards:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a list, named `cards`, containing the 52 cards of the standard deck:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `np.random.choice` function to draw a hand (five cards) from the deck.
    Use `replace=False` so that each card gets selected only once:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The result should look something like this (you might get different cards):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, create a function named `deal_hands` that returns two lists, each with
    five cards drawn from the same deck. Use `replace=False` in the `np.random.choice`
    function. This function will perform sampling *without* replacement:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'To print the output, run the function like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a second function called `deal_hands2` that''s identical to the last
    one, but with the `replace=True` argument in the `np.random.choice` function.
    This function will perform sampling *with* replacement:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, run the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, by allowing sampling *with replacement*, the `Jack-hearts` card
    was drawn in both hands, meaning that when each card was sampled, all 52 were considered.
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, we practiced the concept of sampling with and without replacement
    and learned how to apply it using the `np.random.choice` function.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2Zs7RuY](https://packt.live/2Zs7RuY).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2Bm7A4Y](https://packt.live/2Bm7A4Y).
  prefs: []
  type: TYPE_NORMAL
- en: Probability as a Relative Frequency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s return to the question of the conceptual section: how do we assign probabilities
    to events? Under the *relative frequency* approach, what we do is repeat an experiment
    a large number of times and then define the probability of an event as the *relative
    frequency it has occurred*, that is, how many times we observed the event happening,
    divided by the number of times we performed the experiment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3: Formula to calculate the probability'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.3: Formula to calculate the probability'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look into this concept with a practical example. First, we will perform
    the experiment of tossing a die 1 million times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We can get the first 10 values from the array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'This look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Remember that the sample space of this experiment is S = {1, 2, 3, 4, 5, 6}.
    Let''s define some events and assign them probabilities using the relative frequency
    method. First, let''s use a couple of simple events:'
  prefs: []
  type: TYPE_NORMAL
- en: '`A`: Observing the number 2'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`B`: Observing the number 6'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can use the vectorization capabilities of NumPy and count the number of
    *simple events* happening by summing the Boolean vector we get from performing
    the comparison operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Following the exact same procedure, we can calculate the probability for event
    `B`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will try with a couple of compounded events (they have more than one
    possible outcome):'
  prefs: []
  type: TYPE_NORMAL
- en: '`C`: Observing an odd number (or {1, 3, 5})'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`D`: Observing a number less than 5 (or {1, 2, 3, 4})'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Because the event *observing an odd number* will occur if we get a 1 *or* 3
    *or* 5, we can translate the *or* that we use in our spoken language into the
    mathematical `OR` operator. In Python, this is the `|` operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let''s calculate the probability of `D`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we have used the relative frequency approach to calculate the probability
    of the following events:'
  prefs: []
  type: TYPE_NORMAL
- en: '`A`: Observing the number 2: 0.16595'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`B`: Observing the number 6: 0.166809'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`C`: Observing an odd number: 0.501162'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`D`: Observing a number less than 5: 0.666004'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In summary, under the relative frequency approach, when we have a set of outcomes
    from repeated experiments, what we do to calculate the probability of an event
    is count how many times the event has happened and divide that count by the total
    number of experiments. As simple as that.
  prefs: []
  type: TYPE_NORMAL
- en: In other cases, the assignments of probabilities can arise based on a definition.
    This is what we may call **theoretical probability**. For instance, a *fair* coin,
    *by definition*, has an equal probability of showing either of the two outcomes,
    say, heads or tails. Since there are only two outcomes for this experiment {heads,
    tails} and the probabilities must add up to 1, each simple event must have a 0.5
    probability of occurring.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another example is as follows: a *fair* die is one where the six numbers have
    the same probability of occurring, so the probability of tossing any number must
    be equal to *1/6 = 0.1666666*. In fact, the default behavior of the `numpy.randint`
    function is to simulate the chosen integer numbers, each with the same probability
    of coming out.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the theoretical definition, and knowing that we have simulated a *fair*
    die with NumPy, we can arrive at the probabilities for the events we presented
    previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '`A`: Observing the number 2, P(A) = 1/6 = 0.1666666'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`B`: Observing the number 6, P(B) = 1/6 = 0.1666666'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`C`: Observing an odd number: P(observing 1 *or* observing 3 *or* observing
    5) = P(observing 1) + or P(observing 3) + P(observing 5) = 1/6 + 1/6 + 1/6 = 3/6
    = 0.5'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`D`: Observing a number less than 5: P(observing 1 *or* observing 2 *or* observing
    3 *or* observing 4) = P(observing 1) + or P(observing 2) + P(observing 3) + P(observing
    4) = 1/6 + 1/6 + 1/6 + 1/6 = 4/6 = 0.666666'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Notice two things here:'
  prefs: []
  type: TYPE_NORMAL
- en: These numbers are surprisingly (or unsurprisingly, if you already knew this)
    close to the results we obtained by using the relative frequency approach.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We could decompose the sum of `C` and `D` because of rule 4 of the *Foundational
    Probability Concepts* section.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining Random Variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Often, you will find quantities whose values are (or seem to be) the result
    of a random process. Here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: The sum of the outcome of two dice
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of heads when throwing ten coins
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The price of the stock of IBM one week from now
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of visitors to a website
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of calories ingested in a day by a person
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'All of these are examples of quantities that can vary, which means they are
    *variables*. In addition, since the value they take depends partially or entirely
    on randomness, we call them *random variables*: quantities whose values are determined
    by a random process. The typical notation for random variables is uppercase letters
    at the end of the alphabet, such as *X*, *Y*, and *Z*. The corresponding lowercase
    letter is used to refer to the values they take. For instance, if *X* is *the
    sum of the outcomes of two dice*, here are some examples of how to read the notation:'
  prefs: []
  type: TYPE_NORMAL
- en: '*P(X = 10)*: Probability of *X* taking the number 10'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P(X > 5)*: Probability of *X* taking a value greater than 5'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P(X = x)*: Probability of *X* taking the value *x* (when we are making a general statement)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Since *X* is the sum of two numbers from two dice, *X* can take the following
    values: {2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}. Using what we learned in the previous
    section, we can simulate a large number of values for our random variable, *X*,
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'We have simulated 100,000 die tosses for two dice and got the respective values
    for *X*. These are the first values for our vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: So, in the first simulated roll, we got `6` on the first die and `1` on the
    second, so the first value of *X* is `7`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Just as with experiments, we can define events over random variables and calculate
    the respective probabilities of those events. For instance, we can use the relative
    frequency definition to calculate the probability of the following events:'
  prefs: []
  type: TYPE_NORMAL
- en: '*X = 10*: Probability of *X* taking the number 10'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*X > 5*: Probability of *X* taking a value greater than 5'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The calculations to get the probabilities of those events are essentially the
    same as the ones we did previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'And for the second event, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use a bar plot to visualize the number of times each of the possible
    values has appeared in our simulation. This will allow us to get to know our random
    variable better:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot that''s generated is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.4: Frequencies of the values of X'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.4: Frequencies of the values of X'
  prefs: []
  type: TYPE_NORMAL
- en: We can see out of the 100,000 of *X*, it took the value 3 around 5,800 times
    and the value 6 a little less than 14,000 times, which is also very close to the
    number of times the value 8 appeared. We can also observe that the most common
    outcome was the number 7\.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following the relative frequency definition of probability, if we divide the
    frequencies by the number of values of *X*, we can get the probability of observing
    each of the values of *X*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5: Probability distribution of the values of X'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.5: Probability distribution of the values of X'
  prefs: []
  type: TYPE_NORMAL
- en: 'The plot looks almost exactly like the last one, but in this case, we can see
    the probabilities of observing all the possible values of *X*. This is what we
    call the *probability distribution* (or simply the distribution) of a random variable:
    the probabilities of observing each of the values the random variable can take.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s illustrate both concepts, random variables and probability distribution,
    with another example. First, we''ll define the random variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Y: Number of heads when tossing 10 fair coins.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, our task is to estimate the probability distribution. We know that this
    random variable can take 11 possible values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}.
    For each of these values, there is a corresponding probability that the *Y* variable
    will take that value. Intuitively, we know that it is very unlikely to observe
    extreme values of the variable: getting 10 heads (*Y=10*) or 10 tails (*Y=0*)
    is very unlikely. We also expect the *Y* variable to take values such as 4, 5,
    and 6 most of the time. We can calculate the probability distribution to validate
    our intuition.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once again, let''s simulate the experiment of tossing 10 coins. From there,
    we can observe the values of this random variable. Let''s begin by simulating
    tossing 10 fair coins 1 million times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will produce a matrix of 1,000,000 x 10, with each row representing
    the experiment of tossing 10 coins. We can consider 0s as tails and 1s as heads.
    Here, we have the first 12 rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'To produce the different values of *Y*, we need to add every row, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can use the former calculated object (`Y`) to calculate probabilities
    of certain events, for instance, the probability of obtaining zero heads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a very small number and is consistent with our intuition: it is very
    unlikely to get 10 tails. In fact, that only happened 986 times in 1 million experiments.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Just as we did previously, we can plot the probability distribution of *Y*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6: Probability distribution of Y'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.6: Probability distribution of Y'
  prefs: []
  type: TYPE_NORMAL
- en: 'The probability of getting 5 heads is around 0.25, so around 25% of the time,
    we could expect to get 5 heads. The chance of getting 4 or 6 heads is also relatively
    high. What is the probability of getting 4, 5, or 6 heads? We can easily calculate
    this using `Prob_of_Y_values` by adding the respective probabilities of getting
    4, 5, or 6 heads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: So, around 2/3 (~66%) of the time, we will observe 4, 5, or 6 heads when tossing
    10 fair coins. Going back to the definition of probability as a measure of uncertainty,
    we could say that we are 66% confident that, when tossing 10 fair coins, we will
    see between 4 and 6 heads.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 8.02: Calculating the Average Wins in Roulette'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, we will learn how to use `np.random.choice` to simulate a
    real-world random process. Then, we will take this simulation and calculate how
    much money we will gain/lose on average if we play a large number of times.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will simulate going to a casino to play roulette. European roulette consists
    of a ball falling on any of the integer numbers from 0 to 36 randomly with an
    equal chance of falling on any number. Many modalities of betting are allowed,
    but we will play it in just one way (which is equivalent to the famous way of
    betting on red or black colors). The rules are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Bet *m* units (of your favorite currency) on the numbers from 19 to 36.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the outcome of the roulette is any of the selected numbers, then you win
    *m* units.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the outcome of the roulette is any number between 0 and 18 (inclusive), then
    you lose *m* units.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To simplify this, let''s say the bets are of 1 unit. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the NumPy library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `np.random.choice` function to write a function named `roulette` that
    simulates any number of games from European roulette:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Write a function named `payoff` that encodes the preceding payoff logic. It
    receives two arguments: `outcome`, a number from the roulette wheel (an integer
    from 0 to 36); and `units` to bet with a default value of 1:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Use `np.vectorize` to vectorize the function so it can also accept a vector
    of roulette outcomes. This will allow you to pass a vector of outcomes and get
    the respective payoffs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, simulate playing roulette 20 times (betting one unit). Use the `payoff`
    function to get the vector of outcomes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Simulate 1 million roulette games and use the outcomes to get the respective
    payoffs. Save the payoffs in a vector named `payoffs`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `np.mean` function to calculate the mean of the payoffs vector. The
    value you will get should be close to -0.027027:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: The negative means that, on average, you lose -0.027027 for every unit you bet.
    Remember that your loss is the casino's profit. That is their business.
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, we learned how to simulate a real-world process using the
    capabilities of NumPy for random number generation. We also simulated a large
    number of events to get a long-term average.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2AoiyGp](https://packt.live/2AoiyGp).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3irX6Si](https://packt.live/3irX6Si).
  prefs: []
  type: TYPE_NORMAL
- en: With that, we learned how we can make sense of random events by assigning probabilities
    to quantify uncertainty. Then, we defined some of the most important concepts
    in probability theory. We also learned how to assign probabilities to events using
    the relative frequency definition. In addition, we introduced the important concept
    of random variables. Computationally, we learned how to simulate values and samples
    with NumPy and how to use simulations to answer questions about the probabilities
    of certain events.
  prefs: []
  type: TYPE_NORMAL
- en: 'Depending on the types of values random variables can take, we can have two
    types:'
  prefs: []
  type: TYPE_NORMAL
- en: Discrete random variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous random variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will provide some examples of both in the following two sections.
  prefs: []
  type: TYPE_NORMAL
- en: Discrete Random Variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we''ll continue learning about and working with random variables.
    We will study a particular type of random variable: **discrete random variables**.
    These types of variables arise in every kind of applied domain, such as medicine,
    education, manufacturing, and so on, and therefore it is extremely useful to know
    how to work with them. We will learn about perhaps the most important, and certainly
    one of the most commonly occurring, discrete distributions: the binomial distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: Defining Discrete Random Variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Discrete random variables are those that can take only a specific number of
    values (technically, a *countable* number of values). Often, the values they can
    take are specific integer values, although this is not necessary. For instance,
    if a random variable can take the set of values {1.25, 3.75, 9.15}, it would also
    be considered a discrete random variable. The two random variables we introduced
    in the previous section are examples of discrete random variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider an example in which you are the manager of a factory that produces
    auto parts. The machine producing the parts will produce, on average, defective
    parts 4% of the time. We can interpret this 4% as the probability of producing
    defective parts. These auto parts are packaged in boxes containing 12 units, so,
    in principle, every box can contain anywhere from 0 to 12 defective pieces. Suppose
    we don''t know which piece is defective (until it is used), nor do we know when
    a defective piece will be produced. Hence, we have a random variable. First, let''s
    formally define it:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Z: number of defective auto parts in a 12-box pack.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'As the manager of the plant, one of your largest clients asks you the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: What percentage of boxes have 12 non-defective pieces (zero defective pieces)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What percentage of boxes have 3 or more defective pieces?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can answer both questions if you know the probability distribution for
    your variable, so you ask yourself the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*What does the probability distribution of Z look like?*'
  prefs: []
  type: TYPE_NORMAL
- en: 'To answer this question, we can again use simulations. To simulate a single
    box, we can use `np.random.choice` and provide the probabilities via the `p` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that this particular box contains one defective piece. Notice that
    the probability vector that was used in the function must add up to one: since
    the probability of observing a defective piece is 4% (0.04), the probability of
    observing a good piece is *100% – 4% = 96%* (0.96), which are the values that
    are passed to the p argument.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we know how to simulate a single box, to estimate the distribution
    of our random variable, let''s simulate a large number of boxes; 1 million is
    more than enough. To make our calculations easier and faster, let''s use 1s and
    0s to denote defective and good parts, respectively. To simulate 1 million boxes,
    it is enough to change the size parameter to a tuple that will be of size *12
    x 1,000,000*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'The first five boxes can be found using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Each of the zeros in the output represents a non-defective piece, and one represents
    a defective piece. Now, we count how many defective pieces we have per box, and
    then we can count how many times we observed 0, 1, 2, ..., 12 defective pieces,
    and with that, we can plot the probability distribution of Z:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let''s visualize this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s what the probability distribution will look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.7: Probability distribution of Z'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.7: Probability distribution of Z'
  prefs: []
  type: TYPE_NORMAL
- en: 'From this simulation, we can conclude that around 61% of boxes will be shipped
    with zero defective parts, and around 30% of the boxes will contain one defective
    part. We can also see that it is very, very unlikely to observe three or more
    defective parts in a box. Now, you can answer the questions your client had:'
  prefs: []
  type: TYPE_NORMAL
- en: 'What percentage of boxes have 12 non-defective parts? *Answer: 61% of the boxes
    will contain 12 non-defective parts.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'What percentage of boxes have 3 or more defective pieces? *Answer: Only about
    1% of the boxes will contain 3 or more defective parts.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Binomial Distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It turns out that, under certain conditions, we can find out the exact probability
    distribution of certain discrete random variables. The *binomial distribution*
    is a theoretical distribution that applies to random variables and fulfills the
    following three characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Condition 1**: For an individual observation, there are *only two possible
    outcomes*, usually denoted as *success* and *failure*. If the probability of success
    is *p*, then the probability of failure must be *1 – p*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Condition 2**: The experiment is performed a *fixed number of times*, usually
    denoted by *n*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Condition 3**: All the experiments are *independent*, meaning that knowing
    the outcome of an experiment does not change the probability of the next. Therefore,
    the probability of success (and failure) remains the same.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If these conditions are met, then we say that the random variable follows a
    binomial distribution, or that the random variable is a *binomial random variable*.
    We can get the exact probability distribution of a binomial random variable, *X*,
    using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.8: Formula to calculate the probability distribution of X'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.8: Formula to calculate the probability distribution of X'
  prefs: []
  type: TYPE_NORMAL
- en: Technically, the *mathematical function* that takes a possible value of a discrete
    random variable (*x*) and returns the respective probability is called the **probability
    mass function**. Notice that once we know the values of *n* and *p* from the previous
    equation, the probability depends only on the *x* value, so the former equation
    defines the probability mass function for a binomial random variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'OK, this sounds and looks very theoretical and abstract (because it is). However,
    we have already introduced two random variables that follow the binomial distribution.
    Let''s verify the conditions for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Y: Number of heads when tossing 10 fair coins.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Condition 1**: For each individual coin, there are only two possible outcomes,
    *head* or *tails*, each with a fixed probability of 0.5\. Since we were interested
    in the *number of heads*, *heads* can be considered our *success* and *tails*
    our *failure*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Condition 2**: The number of coins was fixed at 10 coins.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Condition 3**: Each coin toss is independent: we implicitly (and logically)
    assumed that the outcome of one coin does not influence the outcome of any other
    coin.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, we have the numbers we need to use in the preceding formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '*p = 0.5*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*n = 10*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If we want to get the probability of getting five heads, then we only need
    to replace *x = 5* in the formula with the known *p* and *n*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.9: Substituting the values of x, p and n in the probability distribution
    formula'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.9: Substituting the values of x, p and n in the probability distribution
    formula'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s do these theoretical calculations with Python. It is time to introduce
    another Python module that we will be using heavily in this and the following
    chapter. The `scipy.stats` module contains many statistical functions. Among those,
    there are many that can be used to create random variables that follow many of
    the most commonly used probability distributions. Let''s use this module to create
    a random variable that follows the theoretical binomial distribution. First, we
    instantiate the random variable with the appropriate parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Once created, we can use the `pmf` method of this object to calculate the exact
    theoretical probabilities for each of the possible values *Y* can take. First,
    let''s create a vector containing all the values *Y* can take (integers from 0
    to 10):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can simply use the `pmf` (which stands for **probability mass function**)
    method to get the respective probabilities for each of the former values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'We can visualize the `pmf` we got like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'The output we get is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.10: pmf of Y'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.10: pmf of Y'
  prefs: []
  type: TYPE_NORMAL
- en: 'This looks very similar to what we got using the simulations. Now, let''s compare
    both plots. We will create a DataFrame to make the plotting process easier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.11: pmf of Y versus simulated results'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.11: pmf of Y versus simulated results'
  prefs: []
  type: TYPE_NORMAL
- en: The two sets of bars are practically identical; the probabilities we got from
    our simulation are very close to the theoretical values. This shows the power
    of simulations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 8.03: Checking If a Random Variable Follows a Binomial Distribution'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, we will practice how to verify if a random variable follows
    a binomial distribution. We will also create a random variable using `scipy.stats`
    and plot the distribution. This will be a mostly conceptual exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we will check if the random variable, *Z: number of defective auto parts
    in a 12-box pack*, follows a binomial distribution (remember that we consider
    4% of the auto parts are defective). Follow these steps to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import NumPy, Matplotlib, and `scipy.stats` following the usual conventions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Just as we did in the *Defining Discrete Random Variables* section, try to
    conceptually check if *Z* fulfills the three characteristics given for a binomial
    random variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'a. **Condition 1**: For each individual auto part, there are only two possible
    outcomes, *defective* or *good*. Since we were interested in the *defective* parts,
    then that outcome can be considered the *success*, with a fixed probability of
    0.04 (4%).'
  prefs: []
  type: TYPE_NORMAL
- en: 'b. **Condition 2**: The number of parts per box was fixed at 12, so the experiment
    was performed a fixed number of times per box.'
  prefs: []
  type: TYPE_NORMAL
- en: 'c. **Condition 3**: We assumed that the defective parts had no relationship
    between one another because the machine randomly produces an average of 4% defective
    parts.'
  prefs: []
  type: TYPE_NORMAL
- en: Determine the *p* and *n* parameters for the distributions of this variable,
    that is, *p = 0.04* and *n = 12*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the theoretical formula with the former parameters to get the exact theoretical
    probability of getting exactly one defective piece per box (using *x = 1*):![Figure
    8.12: Substituting the values of x, p and n in the probability distribution formula'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](image/B15968_08_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.12: Substituting the values of x, p and n in the probability distribution
    formula'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `scipy.stats` module to produce an instance of the *Z* random variable.
    Name it `Z_rv`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'Plot the probability mass function of *Z*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'The result looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.13: pmf of Z'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.13: pmf of Z'
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, we learned how to check for the three conditions that are
    needed for a discrete random variable to have a binomial distribution. We concluded
    that the variable we analyzed indeed has a binomial distribution. We were also
    able to calculate its parameters and use them to create a binomial random variable
    using `scipy.stats` and plotted the distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3gbTm5k](https://packt.live/3gbTm5k).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2Anhx1k](https://packt.live/2Anhx1k).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we focused on discrete random variables. Now, we know they
    are the kind of random variables that can take on a specific number of values.
    Typically, these are integer values. Often, these types of variables are related
    to counts: the number of students that will pass a test, the number of cars crossing
    a bridge, and so on. We also learned about the most important distribution of
    discrete random variables, known as the binomial distribution, and how we can
    get the exact theoretical probabilities of a binomial random variable using Python.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we'll focus on continuous random variables.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous Random Variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we''ll continue working with random variables. Here, we''ll
    discuss continuous random variables. We will learn the key distinction between
    continuous and discrete probability distributions. In addition, we will introduce
    the mother of all distributions: the famous **normal distribution**. We will learn
    how to work with this distribution using `scipy.stats` and review its most important
    characteristics.'
  prefs: []
  type: TYPE_NORMAL
- en: Defining Continuous Random Variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are certain random quantities that, in principle, can take any real value
    in an interval. Some examples are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The price of the IBM stocks one week from now
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of calories ingested by a person in a day
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The closing exchange rate between the British pound and the Euro
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The height of a randomly chosen male from a specific group
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because of their nature, these variables are known as *continuous* random variables.
    As with discrete random variables, there are many theoretical distributions that
    can be used to model real-world phenomena.
  prefs: []
  type: TYPE_NORMAL
- en: 'To introduce this type of random variable, let''s look at an example we are
    already familiar with. Once again, let''s load the games dataset we introduced
    in *Chapter 7*, *Doing Basic Statistics with Python*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'One of the variables we have in the dataset is *size of the game* in bytes.
    Before visualizing the distribution of this variable, we will transform it into
    megabytes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.14: Distribution of the size of the game'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_14.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.14: Distribution of the size of the game'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s define our random variable, *X*, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*X: Size of a randomly chosen strategy game from the app store.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Having defined this random variable, we can start asking questions about the
    probabilities of certain events:'
  prefs: []
  type: TYPE_NORMAL
- en: '*P(X > 100)*: Probability that *X* is strictly greater than 100 MB'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P(100 ≤ X ≤ 400)*: Probability that *X* is between 100 and 400 MB'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P(X = 152.53)*: Probability of *X* being exactly 152.53 MB'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'By now, you know how you can estimate these probabilities by using the relative
    frequency definition of probability: count the number of times an event happens
    and divide this by the total number of events (games, in this case):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: Notice the last probability we calculated, *P(X = 152.53)*. The estimated probability
    that a random variable takes a *specific* value (such as 152.53) is zero. This
    is always the case for any continuous random variable. Since these types of variables
    can, in principle, take an infinite number of values, then the probability of
    taking *exactly* a specific value must be zero.
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding example shows that when we have enough data points about a continuous
    random variable, we can use the data to estimate the probability of the random
    variable taking values within certain intervals. However, having lots of observations
    about one variable might not always be the case. Given this fact, let''s consider
    the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: What if we have no data at all?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What if we don't have enough data?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can we perform simulations to get an estimation of the probabilities of certain
    events (as we did with discrete random variables)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These are sensible questions, and we can answer them by knowing more about
    **theoretical continuous probability distributions**:'
  prefs: []
  type: TYPE_NORMAL
- en: What if we have no data at all? *We can make some reasonable assumptions about
    the variable, and then model it using one of the many theoretical continuous probability
    distributions.*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What if we don't have enough data? *We can make some reasonable assumptions
    about the variable, support these assumptions with the data, and use estimation
    techniques (the subject of the next chapter) to estimate the parameters of the
    chosen theoretical continuous probability distribution.*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can we perform simulations to get an estimation of the probabilities of certain
    events (as we did with discrete random variables)? *Yes. Once we have chosen the
    probability distribution, along with its parameters, we can use simulations to
    answer complicated questions.*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To make the previous answers clear, in the following subsections, we''ll introduce
    the most important continuous probability distribution: the normal distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: It is worth noting that for continuous random variables, the probability distribution
    is also known as the **probability density function** or **pdf**.
  prefs: []
  type: TYPE_NORMAL
- en: The Normal Distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s introduce the most famous and important distribution in probability
    theory: the normal distribution. The pdf of the normal distribution is defined
    by the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.15: The pdf of the normal distribution'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.15: The pdf of the normal distribution'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, *π* and *e* are the well-known mathematical constants. Don''t try to
    understand the equation; all you need to know is two things: first, that the distribution
    is completely determined when we have two parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '*µ*: The mean of the distribution'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*σ*: The standard deviation of the distribution'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Second, if *X* is a random variable that follows a normal distribution, then
    for a possible value *x*, the preceding formula will give you a value that is
    *directly related* to the probability of the variable *taking values near x*.
    Unlike the formula of the binomial distribution, where we got the probability
    by directly plugging the value, *x*, into the formula, in the case of continuous
    random variables, it is different: there is no direct interpretation of the values
    given by the formula. The following example will clarify this.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will create a random variable that follows a normal distribution using the
    `scipy.stats` module. Let''s suppose that the heights of a certain population
    of males is described by a normal distribution with a mean of 170 cm and a standard
    deviation of 10 cm. To create this random variable using `scipy.stats`, we need
    to use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code creates the normally distributed random variable, whose
    pdf looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.16: The pdf of a normally distributed random variable'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_16.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.16: The pdf of a normally distributed random variable'
  prefs: []
  type: TYPE_NORMAL
- en: 'For every value, *x*, say, `175`, we can get the value of the pdf by using
    the `pdf` method, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'This number is what you would get if you replaced *x* with `175` in the preceding formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.17 Substituting the vale of x=175'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_17.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.17 Substituting the vale of x=175
  prefs: []
  type: TYPE_NORMAL
- en: 'To be clear, this *is not* the probability of observing a male whose height
    is 175 cm (remember that the probability of this variable taking a specific value
    should be zero) as this number does not have a simple direct interpretation. However,
    if we plot the whole density curve, then we can start understanding the distribution
    of our random variable. To plot the whole probability density function, we must
    create a vector that contains a collection of possible values that this variable
    can take. According to the context of male heights, let''s say that we want to
    plot the pdf for values between 130 cm and 210 cm, which are the likely values
    for healthy male adults. First, we create the vector of values using `np.linspace`,
    which in this case will create 200 equally spaced numbers between 120 and 210
    (inclusive):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can produce the pdf and plot against the created values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'The curve looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.18: Example of a normal distribution with mean=170 and sd=10'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_18.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.18: Example of a normal distribution with mean=170 and sd=10'
  prefs: []
  type: TYPE_NORMAL
- en: The higher the curve, the more likely it is to observe those values around the
    corresponding *x* axis value. For instance, we can see that we are more likely
    to observe male heights between 160 cm and 170 cm than those between 140 cm and
    150 cm.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have defined this normally distributed random variable, can we
    use simulations to answer certain questions about it? Absolutely. In fact, now,
    we will learn how to use the already defined random variable to simulate sample
    values. We can use the `rvs` method for this, which generates random samples from
    the probability distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are simulating taking five random males from the population and measuring
    their heights. Notice that we used the `random_state` parameter, which plays a
    similar role to the `numpy.seed`: it ensures anyone running the same code will
    get the same random values.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As we did previously, we can use the simulations to answer questions about
    the probability of events related to this random variable. For instance, what
    is the probability of finding a male taller than 190 cm? The following code calculates
    this simulation using our previously defined random variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: As we will see in the following section, there is a way to get the exact probabilities
    from the `density` function without the need to simulate values, which can sometimes
    be computationally expensive and unnecessary.
  prefs: []
  type: TYPE_NORMAL
- en: Some Properties of the Normal Distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One impressive fact about the universe and mathematics is that many variables
    in the real world follow a normal distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: Human heights
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weights of members of most species of mammals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scores of standardized tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deviations from product specifications in manufacturing processes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Medical measurements such as diastolic pressure, cholesterol, and sleep times
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Financial variables such as the returns of some securities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The normal distribution describes so many phenomena and is so extensively used
    in probability and statistics that it is worth knowing two key properties:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The normal distribution is completely determined by its two parameters: mean
    and standard deviation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *empirical rule* of a normally distributed random variable tells us what
    proportion of observations that we will find, depending on the number of standard
    deviations away from the mean.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s understand these two key properties. First, we will illustrate how the
    parameters of the distribution determine its shape:'
  prefs: []
  type: TYPE_NORMAL
- en: The mean determines the center of the distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The standard deviation determines how wide (or spread out) the distribution
    is.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To illustrate this property, let''s say that we have the following three populations
    of male heights. Each population correspond to a different country:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Country A**: Mean = 170 cm, standard deviation = 10 cm'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Country B**: Mean = 170 cm, standard deviation = 5 cm'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Country C**: Mean = 175 cm, standard deviation = 10 cm'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With these parameters, we can visualize and contrast the distributions of the
    three different countries. Before visualizing, let''s create the random variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'With these objects created, we can proceed with the visualizations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.19: Comparison of normal distributions with different parameters'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_19.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.19: Comparison of normal distributions with different parameters'
  prefs: []
  type: TYPE_NORMAL
- en: Although the populations for **Country A** and **Country B** have the same mean
    (170 cm), the difference in standard deviations implies that the distribution
    for **Country B** is much more concentrated around 170 cm. We could say that the
    males in this country tend to have more homogenous heights. The curves for **Country
    A** and **Country C** are basically the same; the only difference is that the
    curve for **Country C** is *shifted* to the right by 5 cm, which implies that
    it would be more likely to find males around 190 cm in height and above in **Country
    C** than in **Country A** or **Country B** (the green curve has a greater *y*
    axis value than the other two at *x=190* and above).
  prefs: []
  type: TYPE_NORMAL
- en: 'The second important characteristic of the normal distribution is known as
    the **empirical rule**. Let''s take our example of the population of male heights
    that are normally distributed with a mean of 170 cm and a standard deviation of
    10 cm:'
  prefs: []
  type: TYPE_NORMAL
- en: '*~68% of observations will lie in the interval: mean ± 1 sd*. For the height
    of males, we will find that around 68% of males are between 160 cm and 180 cm
    (170 ± 10) in height.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*~95% of observations will lie in the interval: mean ± 2 sd*. For the height
    of males, we will find that around 95% of males are between 150 cm and 190 cm
    (170 ± 20) in height.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*More than 99% of observations will lie in the interval: mean ± 3 sd*. Virtually
    all observations will be at a distance that is less than three standard deviations
    from the mean. For the height of males, we will find that around 99.7% of males
    will be between 150 cm and 200 cm (170 ± 30) in height.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The empirical rule can be used to quickly give us a sense of the proportion
    of observations we expect to see when we consider some number of standard deviations
    from the mean.
  prefs: []
  type: TYPE_NORMAL
- en: 'To finish this section and this chapter, one very important fact you should
    know about any continuous random variable is that the **area under the probability
    distribution** will give the probability of the variable being in a certain range.
    Let''s illustrate this with the normal distribution, and also connect this with
    the empirical rule. Say we have a normally distributed random variable with *mean
    = 170* and *standard deviation = 10*. What is the area under the probability distribution
    between *x = 160* and *x = 180* (one standard deviation away from the mean)? The
    empirical rule tells us that 68% of the observations will lie in this interval,
    so we would expect that ![a](image/B15968_08_InlineEquation5.png), which will
    correspond with the area below the curve in the interval [160, 180]. We can visualize
    this plot with matplotlib. The code to produce the plot is somewhat long, so we
    will split it into two parts. First, we will create the function to plot, establish
    the limits of the plots in the *x* axis, and define the vectors to plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will create the figure with a shaded region:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.20: Area under the pdf as the probability of an event'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_20.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.20: Area under the pdf as the probability of an event'
  prefs: []
  type: TYPE_NORMAL
- en: 'How do we calculate the integral that will give us the area under the curve?
    The `scipy.stats` module will make this very easy. Using the `cdf` (**cumulative
    distribution function**) method of the random variable, which is essentially the
    integral of the pdf, we can easily evaluate the integral by subtracting the lower
    and upper limits (remember the fundamental theorem of calculus):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'And this is how we get probabilities from the `pdf` without the need to perform
    simulations. Let''s look at one last example to make this clear by connecting
    it with an earlier result. A few pages earlier, for the same population, we asked,
    *What is the probability of finding a male taller than 190 cm?* We got the answer
    by performing simulations. Now, we can get the exact probability like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: If you compare this with the result we got earlier, you will see it is virtually
    the same. However, this approach is better since it's exact and does not require
    us to perform any computationally heavy or memory-consuming simulations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 8.04: Using the Normal Distribution in Education'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, we'll use a normal distribution object from `scipy.stats`
    and the `cdf` and its inverse, `ppf`, to answer questions about education.
  prefs: []
  type: TYPE_NORMAL
- en: 'In psychometrics and education, it is a well-known fact that many variables
    relevant to education policy are normally distributed. For instance, scores in
    standardized mathematics tests follow a normal distribution. In this exercise,
    we''ll explore this phenomenon: in a certain country, high school students take
    a standardized mathematics test whose scores follow a normal distribution with
    the following parameters: *mean = 100*, *standard deviation = 15*. Follow these
    steps to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import NumPy, Matplotlib, and `scipy.stats` following the usual conventions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `scipy.stats` module to produce an instance of a normally distributed
    random variable, named `X_rv`, with *mean = 100* and *standard deviation = 15*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'Plot the probability distribution of *X*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.21: Probability distribution of tests scores'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_21.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.21: Probability distribution of tests scores'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Ministry of Education has decided that the minimum score for someone to
    be considered *competent* in mathematics is 80\. Use the `cdf` method to calculate
    the proportion of students that will get a score above that score:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: Around 91% of the students are considered *competent* in mathematics.
  prefs: []
  type: TYPE_NORMAL
- en: 'A very selective university wants to set very high standards for high school
    students that are admitted to their programs. The policy of the university is
    to only admit students with mathematics scores in the top 2% of the population.
    Use the `ppf` method (which is essentially the inverse function of the `cdf` method)
    with an argument of *1 - 0.02 = 0.98* to get the cut-off score for admission:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'The result should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: In this exercise, we used a normal distribution and the `cdf` and `ppf` methods
    to answer real-world questions about education policy.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3eUizB4](https://packt.live/3eUizB4).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2VFyF9X](https://packt.live/2VFyF9X).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we learned about continuous random variables, as well as the
    most important distribution of these types of variables: the normal distribution.
    The key takeaway from this section is that a continuous random variable is determined
    by its probability density function, which is, in turn, determined by its parameters.
    In the case of the normal distribution, its two parameters are the mean and the
    standard deviation. We used an example to demonstrate how these parameters influence
    the shape of the distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: Another important takeaway is that you can use the area below the pdf to calculate
    the probability of certain events. This is true for any continuous random variable,
    including, of course, those that follow a normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we also learned about the empirical rule for the normal distribution,
    which is a good-to-know *rule of thumb* if you want to quickly get a sense of
    the proportion of values that will lie *k* standard deviations away from the mean
    of the distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you are familiar with this important distribution, we will continue
    using it in the next chapter when we encounter it again in the context of the
    **central limit theorem**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 8.01: Using the Normal Distribution in Finance'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this activity, we'll explore the possibility of using the normal distribution
    to understand the daily returns of the stock price. By the end of this activity,
    you should have an opinion regarding whether the normal distribution is an appropriate
    model for the daily returns of stocks.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we will use daily information about Microsoft stock provided
    by Yahoo! Finance. Follow these steps to complete this activity:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The dataset that's required to complete this activity can be found at [https://packt.live/3imSZqr](https://packt.live/3imSZqr).
  prefs: []
  type: TYPE_NORMAL
- en: Using pandas, read the CSV file named `MSFT.csv` from the `data` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Optionally, rename the columns so they are easy to work with.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Transform the `date` column into a proper `datetime` column.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the `date` column as the index of the DataFrame.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In finance, the daily returns of a stock are defined as the percentage change
    of the daily closing price. Create the `returns` column in the MSFT DataFrame
    by calculating the percent change of the `adj close` column. Use the `pct_change`
    series pandas method to do so.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Restrict the analysis period to the dates between `2014-01-01` and `2018-12-31`
    (inclusive).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use a histogram to visualize the distribution of the returns column, using 40
    bins. Does it look like a normal distribution?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The output should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.22: Histogram of returns of the MSFT stock'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/B15968_08_22.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.22: Histogram of returns of the MSFT stock'
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculate the descriptive statistics of the `returns` column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: Create a random variable named `R_rv` that will represent *The daily returns
    of the MSFT stock*. Use the mean and standard deviation of the return column as
    the parameters for this distribution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Plot the distribution of `R_rv` and the histogram of the actual data. Then,
    use the `plt.hist()` function with the `density=True` parameter so that both the
    real data and the theoretical distribution appear in the same scale:![Figure 8.23:
    Histogram of returns of the MSFT stock'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](image/B15968_08_23.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.23: Histogram of returns of the MSFT stock'
  prefs: []
  type: TYPE_NORMAL
- en: After looking at the preceding plot, *would you say that the normal distribution
    provides an accurate model for the daily returns of Microsoft stock?*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Additional activity: Repeat the preceding steps with the `PG.csv` file, which
    contains information about the Procter and Gamble stock.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This activity was about observing real-world data and trying to use a theoretical
    distribution to describe it. This is important because by having a theoretical
    model, we can use its known properties to arrive at real-world conclusions and
    implications. For instance, you could use the *empirical rule* to say something
    about the daily returns of a company, or you could calculate the probability of
    losing a determined amount of money in a day.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The solution for this activity can be found on page 684.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter gave you a brief introduction to the branch of mathematics regarding
    probability theory.
  prefs: []
  type: TYPE_NORMAL
- en: 'We defined the concept of probability, as well as some of its most important
    rules and associated concepts such as experiment, sample space, and events. We
    also defined the very important concept of random variables and provided examples
    of the two main discrete and continuous random variables. Later in this chapter,
    we learned how to create random variables using the `scipy.stats` module, which
    we also used to generate the probability mass function and the probability density
    function. We also talked about two of the most important random variables in the
    (literal) universe: the normal distribution and the binomial distribution. These
    are used in many applied fields to solve real-world problems.'
  prefs: []
  type: TYPE_NORMAL
- en: This was, of course, a brief introduction to the topic, and the goal was to
    present and make you familiar with some of the basic and foundational concepts
    in probability theory, especially those that are crucial and necessary to understand
    and use inferential statistics, which is the topic of the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: WUE84
  prefs: []
  type: TYPE_NORMAL
- en: JNP97
  prefs: []
  type: TYPE_NORMAL
