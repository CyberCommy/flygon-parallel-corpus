- en: IIS and Kestrel in ASP.NET Core
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous chapter, we discussed writing unit test cases for parallel
    and asynchronous code. We also discussed three unit testing frameworks that are
    available in Visual Studio: MSUnit, NUnit, and xUnit.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will introduce how the threading model works with **Internet
    Information Services** (**IIS**) and Kestrel. We will also look at various tweaks
    we can make to take maximum advantage of resources on a server. We will introduce
    the working model of Kestrel and how we can take advantage of parallel programming
    techniques while creating microservices.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The IIS threading model and internals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Kestrel threading model and internals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to best practices of threading in microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to async in ASP.NET MVC Core
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Async streams (new in .NET Core 3.0)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's get started.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A good understanding of how servers work is required so that you can understand
    this chapter. You should also learn about threading models before you start this
    chapter. The source code for this chapter is available on GitHub at [https://github.com/PacktPublishing/-Hands-On-Parallel-Programming-with-C-8-and-.NET-Core-3/tree/master/Chapter12](https://github.com/PacktPublishing/-Hands-On-Parallel-Programming-with-C-8-and-.NET-Core-3/tree/master/Chapter12).
  prefs: []
  type: TYPE_NORMAL
- en: IIS threading model and internals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As the name suggests, these are services that are utilized on the Windows system
    to connect your web applications from other systems via the internet over a set
    of protocols such as HTTP, TCP, web sockets, and more.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will discuss how the **IIS threading model** works. At the
    core of IIS lies the **CLR thread pool**. It's very important to understand how
    the CLR thread pool adds and removes threads in order to understand how IIS works
    to serve user requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Every application that gets deployed to IIS is assigned a unique worker process.
    Each worker process has two thread pools: the **worker thread pool** and the **IOCP**
    (short for **I/O completion port**) thread pool:'
  prefs: []
  type: TYPE_NORMAL
- en: Whenever we create a new thread pool thread using either legacy `ThreadPool.QueueUserWorkItem`
    or **TPL**, the ASP.NET runtime makes use of worker threads for processing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whenever we perform any I/O operations, that is, database calls, file read/write,
    or network calls to another web service, the ASP.NET runtime makes use of IOCP
    threads.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By default, there is one worker thread and one IOCP thread per processor. So,
    a dual-core CPU will have two workers and two IOCP threads by default. `ThreadPool`
    keeps adding and removing threads, depending on load and demand. IIS assigns a
    thread to each request that it receives. This allows every request to have a different
    context from other requests hitting the server at the same time. It's the responsibility
    of the thread to cater to requests, as well as generating and sending a response
    back to a client.
  prefs: []
  type: TYPE_NORMAL
- en: If the number of available thread pool threads is less than the number of requests
    that are received by a server at any time, the requests will start to be queued.
    Later, the thread pool generates threads using one of two important algorithms,
    known as *Hill Climbing* and *Starvation Avoidance*. The creation of threads is
    not instant and it usually takes up to 500 ms from the time `ThreadPool` comes
    to know that there is a shortage of threads. Let's try to understand both algorithms
    that are used by `ThreadPool` to generate threads.
  prefs: []
  type: TYPE_NORMAL
- en: Starvation Avoidance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this algorithm, `ThreadPool` keeps monitoring the queue, and if it doesn't
    progress, then it keeps pumping new threads into the queue.
  prefs: []
  type: TYPE_NORMAL
- en: Hill Climbing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this algorithm, `ThreadPool` tries to maximize the throughput using as few
    threads as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running IIS with the default settings will have a significant impact on performance
    since, by default, only one worker thread is available per processor. We can increase
    this setting by modifying the configuration element in the `machine.config` file,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we increased the minimum worker threads and IOCP threads to
    25\. As more requests come in, additional threads will be created. An important
    thing to note here is that since every request is assigned one unique thread,
    we should avoid writing blocking code. With blocking code, there will not be free
    threads. Once a thread pool is exhausted, the requests will start to queue. IIS
    can only queue up to 1,000 requests per application pool. We can modify this by
    changing the `requestQueueLimit` application settings in the `machine.config`
    file.
  prefs: []
  type: TYPE_NORMAL
- en: 'To modify the settings for all the application pools, we need to add the `applicationPool`
    element with the required values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To modify the settings for a single application pool, we need to navigate to
    the Advanced Settings of a specific application pool in IIS. As shown in the following
    screenshot, we can change the Queue Length property to modify a number of requests
    that can be queued per application pool:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/804457ce-c889-4d44-a876-1cfc35f55cc6.png)'
  prefs: []
  type: TYPE_IMG
- en: As a good coding practice for developers to reduce contention issues and thus
    avoid queues on the server, we should try to use the `async`/`await` keywords
    for any blocking I/O code. This will reduce contention issues on a server as threads
    will not be blocked and return to the thread pool to serve other requests.
  prefs: []
  type: TYPE_NORMAL
- en: Kestrel threading model and internals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: IIS has been the most popular server for hosting .NET applications, but it's
    tied to the Windows OS. With more and more cloud providers coming and non-Windows
    cloud hosting options becoming a lot cheaper, there was a need for a cross-platform
    hosting server. Microsoft introduced Kestrel as a cross-platform web server for
    hosting ASP.NET Core applications. If we create and run ASP.NET Core applications,
    Kestrel is the default web server that runs them. Kestrel is open source and uses
    an event-driven, asynchronous I/O-based server. Kestrel is not a full-fledged
    web server and is recommended to be used behind full-featured web servers such
    as IIS and Nginx.
  prefs: []
  type: TYPE_NORMAL
- en: When it was initially launched, Kestrel was based on the `libuv` library, which
    is also open source. The use of `libuv` in .NET is not new and dates back to ASP.NET
    5\. `libuv` has been specifically built for asynchronous I/O operations and uses
    a single-threaded event looping model. The library also supports cross-platform
    asynchronous sockets on Windows, macOS, and Linux. You can check its progress
    and download the source code for `libuv` for custom implementation from GitHub
    at [https://github.com/libuv/libuv](https://github.com/libuv/libuv).
  prefs: []
  type: TYPE_NORMAL
- en: '`libuv` has been used in Kestrel to only support async I/O. Apart from I/O
    operations, all the other work that''s done in Kestrel is still done by .NET worker
    threads using managed code. The core idea behind creating Kestrel is improving
    the performance of servers. The stack is very robust and extensible. `libuv` in
    Kestrel is used as a transport layer only and, due to excellent abstraction, it
    can be replaced by other network implementations as well. Kestrel also supports
    running multiple event loops, thereby making it a more robust choice than Node.js.
    The number of event loops that are used depends on the number of logical processors
    on the machine and on there being one thread running one event loop. We can configure
    this number via code as well while creating the host.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an excerpt from the `Program.cs` file, which is present in
    all ASP.NET Core projects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: As you will see, the Kestrel server is based on the builder pattern, and functionality
    can be added using the appropriate packages and extension methods. In the following
    sections, we will learn how to modify the settings of Kestrel for different versions
    of .NET Core.
  prefs: []
  type: TYPE_NORMAL
- en: ASP.NET Core 1.x
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can use an extension method called `UseLibuv` to set the thread count. We
    can do this by setting the `ThreadCount` property, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '`WebHost` has been replaced by a generic host in .NET Core 3.0\. The following
    is a code snippet for ASP.NET Core 3.0:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: ASP.NET Core 2.x
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Starting from ASP.NET 2.1, Kestrel has replaced the default transport from `libuv` for
    managed sockets. So, if you are upgrading your project from ASP.NET Core to ASP.NET
    2.x or 3.x and still want to use `libuv`, you need to add the `Microsoft.AspNetCore.Server.Kestrel.Transport.Libuv`
    NuGet package to make the code work.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kestrel currently supports the following scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: HTTPS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Opaque upgrades, which are used to enable web sockets ([https://github.com/aspnet/websockets](https://github.com/aspnet/websockets))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unix sockets behind Nginx for high performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HTTP/2 (not currently supported on macOS)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Since Kestrel is built on sockets, you can configure the connection limits
    of them by using the `ConfigureLimits` method on `Host`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The default connection limit is unlimited if we set `MaxConcurrentConnections`
    to null.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the best practices of threading in microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices are the most popular software design patterns for making very
    performant and scalable backend services. Rather than building one service for
    an entire application, multiple loosely coupled services are created, with each
    being responsible for a single feature. Depending on the load on features, each
    service can be scaled up or down individually. Consequently, while designing microservices,
    the choice of the threading model you use becomes very important.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices can be stateless or stateful. The choice between stateless and
    stateful does have an impact on performance. With stateless services, the requests
    can be served in any order without regard to what happened before or after the
    current request, whereas with stateful services, all the requests should be processed
    in a particular order, like a queue. This can have an impact on performance. Since
    microservices are asynchronous, we need to write some logic to make sure the request
    is processed in the correct order and state after each request is communicated
    to the next message. Microservices can be single-threaded or multithreaded as
    well, and this choice coupled with the state can really improve or degrade performance
    and should be well thought out while planning services.
  prefs: []
  type: TYPE_NORMAL
- en: 'The microservice design approaches can be categorized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Single thread-single process microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Single thread-multiple processes microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple threads-single process microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We'll look at these design approaches in more detail in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Single thread-single process microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is the most basic design for microservices. The microservice runs on a
    single thread in a single CPU core. With every new request from a client, a new
    thread is created, which spawns a new process. This takes away the connection
    pooling caching benefits. While working with a database, every new process will
    create a new connection pool. Also, since only one process can be created at a
    time, only one client can be served.
  prefs: []
  type: TYPE_NORMAL
- en: The cons of single thread-single process microservices include the fact that
    it is a waste of resources and that the throughput of the service doesn't increase
    when the load is increased**. **
  prefs: []
  type: TYPE_NORMAL
- en: Single thread-multiple process microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The microservice runs on a single thread but can spawn multiple processes, thereby
    improving their throughput. Since a new process is created for each client, we
    cannot take advantage of connection pooling while connecting to databases. There
    are some third-party environments, such as Zend, OpCache, and APC, that provide
    cross-process opcode caches.
  prefs: []
  type: TYPE_NORMAL
- en: The pros of the single thread-multiple processes microservices approach is that
    it improves throughput on load, but note that we cannot take advantage of connection
    pooling.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple threads-single process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservice runs on multiple threads and there is a single long-lived process.
    With the same database, we can take advantage of connection pooling and also limit
    the number of connections as and when needed. The problem with the single process
    is that all the threads will use a shared resource and can have resource contention
    issues.
  prefs: []
  type: TYPE_NORMAL
- en: The pro of the multiple threads-single process approach is that it improves
    the performance of stateless services, whereas its con is that there can be synchronization
    issues when sharing a resource.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can avoid performance issues during integration with various application
    components by decoupling communication between microservices. Microservices must
    be created asynchronously by design to achieve this decoupling.
  prefs: []
  type: TYPE_NORMAL
- en: Dedicated thread pools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If the application flow requires us to connect to various microservices, then
    it makes more sense to create a dedicated thread pool for such tasks. With a single
    thread pool, if a service starts having issues, then all the threads from the
    pool can become exhausted. This can impact the performance of a microservice.
    This pattern is also known as the **Bulkheads** pattern. The following diagram
    shows two microservices with a shared pool. As you can see, both microservices
    use a shared connection pool:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7775bc70-bd55-45fd-adc5-a2549b9067b5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following diagram shows two microservices with dedicated thread pools:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e7cde3f-7af7-493f-97a4-4f1028f7eb21.png)'
  prefs: []
  type: TYPE_IMG
- en: In the next section, we will introduce how async can be used in ASP.NET MVC
    core.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing async in ASP.NET MVC core
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`async` and `await` are code markers that help us write asynchronous code using
    TPL. They help maintain the structure of code and make it look synchronous while
    processing code asynchronously in the background.'
  prefs: []
  type: TYPE_NORMAL
- en: We introduced `async` and `await` in [Chapter 9](1b0d3653-dd80-486b-96fc-b17000f9439d.xhtml),
    *Async, Await, and Task-Based Asynchronous Programming Basics*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s create an asynchronous web API with ASP.NET Core 3.0 and VS 2019
    preview. The API will read a file from the server:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open Visual Studio 2019 to be presented with the following screen. Create a
    new ASP.NET Core Web Application project in VS 2019, as shown in the following
    screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/6af4da68-75e4-42f2-b4cb-2ed6c9f106dc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Give the project a name and the location where you want it to be created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2b29b76f-9f1c-42ad-836c-cb80ee916aee.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Select the project''s type, which in our case is API, and click Create:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/5bbfee2e-3a88-4f7a-9a0c-9a02bd5c088d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, create a new folder in our project called `Files` and add a file named
    `data.txt` that contains the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3baa8323-ae99-45b4-9e78-c32b367b58aa.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, we will modify the `Get` method in `ValuesController.cs`, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a simple method that reads a file from the server and returns the content
    as a string to the user. The problem with this code is that, when `File.ReadAllText`
    is called, the calling thread will be blocked until the file is read completely.
    As we now know, our server''s response will be to make the call asynchronous,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The ASP.NET Core web API supports all the new features of parallel programming,
    including async, as we have seen from the preceding code example.
  prefs: []
  type: TYPE_NORMAL
- en: Async streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: .NET Core 3.0 also introduced asynchronous streams support. `IAsyncEnumerable<T>`
    is the asynchronous version of `IEnumerable<T>`. This new feature allows developers
    to await `foreach` loops over `IAsyncEnumerable<T>` to consume elements from the
    stream and use `yield` to return a stream to produce elements.
  prefs: []
  type: TYPE_NORMAL
- en: This is very important in scenarios where we want to iterate over elements asynchronously
    and perform some compute operations on iterated elements. With more emphasis being
    on big data nowadays (which is available as streamed output), it makes more sense
    to go for *async* streams, which support high volumes of data while making servers
    responsive by efficiently utilizing threads at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: Two new interfaces have been added to support async streams**:**
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from the definition of `IAsyncEnumerator`, `MoveNext` has been
    made asynchronous. This has two benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: It's easy to cache `Task<bool>` over `Task<T>` so that there will be fewer memory
    allocations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Existing collections just need to add one extra method to support asynchronous
    behaviors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's try to understand this using some sample code that enumerates numbers
    at odd indexes asynchronously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a custom enumerator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from the `MoveNextAsync()` method we defined in the preceding
    code, this method starts with an odd index (that is, index 1) and keeps reading
    items at odd indexes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is our collection, which makes use of the custom enumeration
    logic we created previously and implements the `GetAsyncEnumerator()` method of
    the `IAsyncEnumerable<T>` interface to return the `OddIndexEnumerator` enumerator
    we created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is our magic extension method, which will convert our custom collection into
    an `AsyncEnumerable`. As you can see, it works on any collection that implements `IEnumerable<int>`
    and wraps the underlying collection with `CustomAsyncIntegerCollection`, which,
    in turn, implements `IAsyncEnumerable<T>`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Once all the pieces are in place, we can create a method that returns an asynchronous
    stream. We can see how items are generated by using the `yield` keyword:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code calls the stream. Here, we call the `GetBigResultsAsync()`
    method, which returns `IAsyncEnumerable<int>` inside a `foreach` loop and then
    iterates over it asynchronously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The following is the output of the preceding code. As you can see, it generated
    numbers at the odd indexes in the collection**:**
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a4c7c02d-65c0-4032-95d3-5e245be1555f.png)'
  prefs: []
  type: TYPE_IMG
- en: In this section, we introduced async streams, which make it very efficient for
    us to iterate over a collection in parallel without blocking the caller thread,
    which is something that's been missing since TPL was introduced.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's take a look at what we covered in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed IIS threading models and making changes to .NET
    Core implementations of a server by going from using `libuv` to .NET Core 2.0
    in order to manage sockets from .NET Core 2.1 onward. We also discussed ways to
    improve the performance of IIS, Kestrel, and some thread pool algorithms such
    as Starvation Avoidance and Hill Climbing. We introduced the concepts of microservices
    and various threading patterns that are used in microservices, such as single
    thread-single process microservices, single thread-multiple process microservices,
    and multiple threads-single process microservices.
  prefs: []
  type: TYPE_NORMAL
- en: We also discussed the process of using async in ASP.NET MVC Core 3.0 and introduced
    the new concept of async streams in .NET Core 3.0, as well as its usage. Async
    streams can be very handy in big data scenarios in which the load on servers can
    be huge due to a rapid influx of data.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about some patterns that are commonly used
    in parallel and asynchronous programming. These patterns will enhance our understanding
    of parallel programming.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Which of these is used to host web applications?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`IWebHostBuilder`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`IHostBuilder`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following `ThreadPool` algorithms tries to maximize the throughput
    using as few threads as possible?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hill Climbing
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Starvation Avoidance
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which is not a valid microservice design approach?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Single thread-single process
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Single thread-multiple processes
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Multiple threads-single process
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Multiple threads-multiple processes
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can await `foreach` loops in new versions of .NET Core.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'False'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
