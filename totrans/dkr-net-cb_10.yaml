- en: Chapter 10. Leveraging IPv6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: IPv6 command-line basics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enabling IPv6 capabilities in Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with IPv6-enabled containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring NDP proxying
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User-defined networks and IPv6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up until this point in the book, we've focused solely on IPv4 networking. However,
    IPv4 is not the only IP protocol available to us. Although IPv4 is still the most
    widely understood protocol, IPv6 has started to gain significant attraction. Public
    IPv4 space is exhausted and many are starting to foresee issues with running out
    of private IPv4 allocations as well. IPv6 looks to overcome this problem by defining
    a much larger set of usable IP space. However, IPv6 does some things differently
    from IPv4 making some believe that implementing IPv6 would be cumbersome. I would
    argue that as you look to deploy container technology, you should also be looking
    at how to effectively leverage IPv6\. Although IPv6 is a different animal, it
    will soon become a requirement in many networks. With containers representing
    the possibility of introducing many more IP endpoints on your network making the
    transition sooner rather than later is a good idea. In this chapter, we'll look
    at what IPv6 features Docker currently supports.
  prefs: []
  type: TYPE_NORMAL
- en: IPv6 command-line basics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even if you understand the basics of the IPv6 protocol, working with IPv6 on
    a Linux host for the first time can be a bit daunting. Much like IPv4, IPv6 has
    its own unique set of command-line tools that can be leveraged to configure and
    troubleshoot IPv6 connectivity. Some of these tools are the same that we used
    with IPv4 and just use a slightly different syntax. Other tools are completely
    unique to IPv6\. In this recipe, we'll walk through configuring and verifying
    basic IPv6 connectivity.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we''ll be using a small lab consisting of two Linux hosts:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](graphics/5453_10_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Each host has both an IPv4 address as well as an IPv6 address assigned to its
    physical interface. You'll need root-level access to each host to make network
    configuration changes.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The intent of this recipe is not to teach the basics of IPv6 or IPv6 network
    design. The examples in this recipe are for example purposes only. Although we
    may cover some of the basics during the examples, it is assumed that the reader
    has a base understanding of how the IPv6 protocol works.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As shown in the preceding figure, each Linux host has been assigned both an
    IPv4 and an IPv6 IP address. These were both configured as part of the host''s
    network configuration script. The following are sample configurations from each
    of the two lab hosts:'
  prefs: []
  type: TYPE_NORMAL
- en: '`net1.lab.lab`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '`net2.lab.lab`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that in each case, we''re adding the IPv6 address to the existing physical
    network interface. In this type of configuration, both the IPv4 and IPv6 addresses
    coexist on the same NIC. This is commonly referred to as running **dual stack**
    since both protocols share the same physical adapter. Once configured, you''ll
    need to reload the interfaces for the configuration to take effect. You should
    then be able to confirm that each host has the correct configuration by either
    using the `ifconfig` tool or the `ip` (`iproute2`) toolset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The advantage of using the older `ifconfig` tool is that you can see the IPv4
    and IPv6 interface information at the same time. When using the `ip` tool, you
    need to specify that you wish to see IPv6 information by passing the `-6` flag.
    We'll see this is the same case later on when we use the `ip` tool for configuration
    of IPv6 interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: In either case, both hosts now appear to be configured for IPv6 on their `eth0`
    interfaces. However, note that we actually have two IPv6 addresses defined. You'll
    notice that one address has a scope of local and the other has a scope of global.
    In IPv6, each IP interface gets assigned both a global and a local IPv6 address.
    The locally scoped interface is only valid for communication on the link it is
    assigned on and is commonly used to reach neighboring devices on the same segment.
    In most cases, the link local address is dynamically determined by the host itself.
    This means that an IPv6-enabled interface almost always has a link local IPv6
    address defined even if you haven't specifically configured a global IPv6 address
    on the interface. Packets using link local IP addresses are never forwarded by
    a router which restricts them to the segment they are defined on. For the majority
    of our discussion, we'll be focusing on the global address.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Any further reference to an IPv6 address is referring to a globally scoped IPv6
    address unless otherwise noted.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since both of our hosts are on the same subnet, we should be able to reach
    one server from the other using IPv6:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Note that instead of using the standard ping tool, we're using the `ping6` tool
    to verify IPv6 reachability.
  prefs: []
  type: TYPE_NORMAL
- en: The last thing we want to check is the neighbor discovery table. Another major
    change with IPv6 is that it doesn't use ARP to find the hardware or MAC address
    of an IP endpoint. The major reason for this is that IPv6 does not support broadcast
    traffic. ARP relies on broadcasts to work, so it couldn't be used in IPv6\. Instead,
    IPv6 uses neighbor discovery, which leverages multicast.
  prefs: []
  type: TYPE_NORMAL
- en: 'That being said, you need to look at the neighbor discovery table rather than
    the ARP table when troubleshooting local network. To do this, we can use the familiar
    `iproute2` toolset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Much like the ARP table, the neighbor table shows us the hardware or MAC address
    of the IPv6 address we wish to reach. Note that as before we passed the `-6` flag
    to the `ip` command to tell it we wanted IPv6 information.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have basic connectivity, let''s add a new IPv6 interface to each
    host. To do that, we follow almost the same steps we did when we added an IPv4
    interface. For instance, adding a dummy interface is almost identical:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the only difference is that we need to tell `iproute2` that we''re
    specifying a IPv6 address by once again passing the `-6` flag. In all other regards,
    the configuration is identical to how we did this in IPv4\. Let''s configure another
    dummy interface on the second host as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, our topology now looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](graphics/5453_10_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s now check the IPv6 routing table on each host. As before we can also
    use the `iproute2` tool to check the IPv6 routing table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, each host knows about its directly connected interfaces but
    does not know about the other hosts dummy interface. In order for either host
    to reach the other hosts dummy interface, we''re going to need to route to get
    to it. Since these hosts are directly connected, this could be solved by adding
    a default IPv6 route. Each default route would reference the other host as the
    next hop. Although that''s doable, let''s instead add specific routes to each
    host that reference the network that the dummy interface is in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'After adding these routes, either host should be able to reach the other hosts
    `ipv6_dummy` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You'll likely notice that just adding one route on a single host will allow
    that host to reach the dummy interface on the other host. This is because we only
    need the route to get the traffic off the initiating host. The traffic will be
    sourced by the hosts `eth0` interface (`2003:ab11::/64`), which the other host
    knows how to get to inherently. If the ping was sourced from the dummy interface,
    you'd need both routes for this to work.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we''ve configured and verified basic connectivity, let''s take one
    final step and rebuild these interfaces using network namespaces. To do that,
    let''s first clean up the dummy interfaces since we''ll be reusing those IPv6
    subnets inside the namespaces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The configuration we''re after will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](graphics/5453_10_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Although very similar to the last configuration, there are two major differences.
    You'll notice that we are now using network namespaces to encapsulate the new
    interfaces. In doing so, we've configured the IPv6 address for the new interface
    on one side of a VETH pair. The other end of the VETH pair lives on the host in
    the default network namespace.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you aren't comfortable with some of these Linux networking constructs, please
    review [Chapter 1](ch01.html "Chapter 1. Linux Networking Constructs"), *Linux
    Networking Constructs*, where we discuss namespaces and VETH interfaces in much
    greater detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'To configure this, we''ll apply the following configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a new network namespace named `net1_ns`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a VETH pair naming one end `host_veth1` and the other end `ns_veth1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Move the namespace side of the VETH pair into the namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Within the namespace, give the VETH interface an IP address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Within the namespace, bring the interface up:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Within the namespace, add a route to reach the namespace on the other host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Give the host side of the VETH pair an IP address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Bring the host side of VETH interface up:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that we only added a route within the namespace to reach the other namespace.
    We did not add the same route on the Linux host. This is because we already did
    this earlier in the recipe in order to reach the dummy interface. If you removed
    that route, you'll need to add it back for this to work.
  prefs: []
  type: TYPE_NORMAL
- en: 'We must now perform a similar configuration on the second host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Once this is added, you should be able to verify that each namespace has the
    routing information required to reach the other hosts namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'But when we try to reach from namespace to namespace, the connection fails:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This is because we''re now trying to use the Linux host as a router. If you
    recall from earlier chapters when we want the Linux kernel to forward or route
    packets we have to enable that functionality. This is done by changing these two
    kernel parameters on each host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Keep in mind that these settings won't persist through a reboot when defined
    in this manner.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once these settings are made on both hosts, your ping should now begin to work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'As an interesting side note, check your neighbor table on the host once you''ve
    enabled IPv6 forwarding in the kernel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Can you notice anything different about the neighbor entry for the other Linux
    host? It now has the `router` flag as part of the neighbor definition. The Linux
    host advertises itself as a router on the segment when IPv6 forwarding is enabled
    in the kernel.
  prefs: []
  type: TYPE_NORMAL
- en: Enabling IPv6 capabilities in Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: IPv6 functionality is disabled by default in Docker. Much like other features
    we reviewed earlier, enabling it requires doing so at the service level. Once
    enabled, Docker will provision the host interfaces associated with Docker, as
    well as the containers themselves, with IPv6 addressing.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we''ll be using a small lab consisting of two Docker hosts:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](graphics/5453_10_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Each host has both an IPv4 address as well as an IPv6 address assigned to its
    physical interface. You'll need root-level access to each host to make network
    configuration changes. It is assumed that Docker is installed, and it's a default
    configuration.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned, Docker will not provision containers with an IPv6 address unless
    told to do so. To enable IPv6 in Docker, we need to pass a service-level flag
    to the Docker service.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you need a refresher on defining Docker service-level parameters, see the
    last recipe in [Chapter 2](ch02.html "Chapter 2. Configuring and Monitoring Docker
    Networks"), *Configuring and Monitoring Docker Networks*, where we discuss configuring
    these on a system running `systemd`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to enabling IPv6 functionality, you also need to define a subnet
    for the `docker0` bridge. To do this, we''ll modify our `systemd` drop-in file
    for Docker and make sure that it has the following options:'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the host `docker1`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'On the host `docker2`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'If we apply this configuration, reload the `systemd` configuration and restart
    the Docker service on each host, we should see that the `docker0` bridge has taken
    the first available IP address from the defined IPv6 CIDR range:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, our topology looks a lot like it did in the first recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](graphics/5453_10_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Docker will issue an IPv6 address along with an IPv4 address to each container
    it creates. Let''s spin up a container on the first host to see what I mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that we did not pass the `-P` flag to the containers to publish the containers
    exposed ports. If we test locally, we can validate that the host can reach the
    service within the container from both the containers IPv4 and IPv6 address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When using `curl` with IPv6 addresses, you need to put the IPv6 address inside
    of brackets and then tell `curl` not to glob by passing the `-g` flag.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can see, the behavior with the IPv6 address is the same as it is with
    the IPv4 address. Following suit, containers on the same host can talk directly
    to each other across the `docker0` bridge using their assigned IPv6 address. Let''s
    start a second container on the same host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'A quick validation will prove to us that these two containers are allowed to
    talk directly to one another with their IPv6 addresses just as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Working with IPv6-enabled containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous recipe, we saw how Docker handles the basic allocation of IPv6-enabled
    containers. The behavior we've seen up to this point has closely mimicked what
    we saw in earlier chapters when only dealing with IPv4 addressed containers. However,
    this is not the case for all of the network functionality. Docker does not currently
    have complete feature parity between IPv4 and IPv6\. Namely, as we'll see in this
    recipe, Docker does not have `iptables` (ip6tables) integration for IPv6 enabled
    containers. In this chapter, we'll review some of the network features that we
    previously visited with IPv4 only enabled containers and see how they act when
    using IPv6 addressing.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we'll be building off of the lab we built in the previous recipe.
    You'll need root-level access to each host to make network configuration changes.
    It is assumed that Docker is installed, and it's a default configuration.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned, Docker does not currently have host firewall, specifically netfilter
    or `iptables`, integration for IPv6\. This means that several of the features
    we relied on previously with IPv4 behave differently when dealing with a containers
    IPv6 address. Let's start with some of the basic functionality. In the previous
    recipe, we saw that two containers on the same host, connected to the `docker0`
    bridge, could talk directly with one another.
  prefs: []
  type: TYPE_NORMAL
- en: 'This behavior was expected and works in much the same manner when using IPv4
    addresses. If we wanted to prevent this communication, we might look to disable
    **Inter-Container Communication** (**ICC**) in the Docker service. Let''s update
    our Docker options on the host `docker1` to set ICC to `false`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can reload the `systemd` configuration, restart the Docker service,
    and restart the containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the attempt on IPv4 fails and the subsequent IPv6 attempt works.
    Since Docker is not managing any firewall rules related to the containers IPv6
    address, there is nothing to prevent direct connectivity between IPv6 addresses.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since Docker isn''t managing IPv6-related firewall rules, you might also assume
    that features like outbound masquerade and port publishing no longer work as well.
    And while this is true in the sense that Docker is not creating IPv6 associated
    NAT rules and firewall policy, it does not mean that a containers IPv6 address
    is not reachable from the outside network. Let''s walk through an example to show
    you what I mean. Let''s start a container on the second Docker host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that when we ran the container on the host `docker2` that we passed the
    `-P` flag to tell Docker to publish the exposed ports of the container. If we
    check the port mapping, we can see that the host has chosen port `32768`. Note
    that the port mapping indicates an IP address of `0.0.0.0`, which typically indicates
    any IPv4 address. Let''s perform some quick tests from the other Docker host to
    validate what is and isn''t working:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'As expected, the IPv4 port mapping works. We''re able to access the containers
    service through the Docker hosts IPv4 address by leveraging the `iptables` NAT
    rule to map port `32769` to the actual service port of `80`. Let''s now try the
    same example but using the hosts IPv6 address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Surprisingly, this also works. You might be wondering how this is working considering
    that Docker doesn''t manage or integrate with any of the hosts IPv6 firewall policy.
    The answer is actually quite simple. If we look at the second Docker hosts open
    ports, we''ll see that there is a `docker-proxy` service bound to port `32769`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: As we saw in earlier chapters, the `docker-proxy` service facilitates inter
    container and published port connectivity. In order for this to work, the `docker-proxy`
    service has to bind to the port in which the container publishes. Recall that
    services listening on all IPv4 interfaces use the syntax of `0.0.0.0` to represent
    all IPv4 interfaces. In a similar fashion, IPv6 interfaces use the syntax of `:::`
    to indicate the same thing. You'll note that the `docker-proxy` port references
    all IPv6 interfaces. Although this may differ based on your operating system,
    binding to all IPv6 interfaces also implies binding to all IPv4 interfaces. That
    is, the preceding `docker-proxy` service is actually listening on all of the hosts
    IPv4 and IPv6 interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Keep in mind that `docker-proxy` is not typically used for inbound services.
    Those rely on the `iptables` NAT rules to map the published port to the container.
    However, in the case that those rules don't exist, the host is still listening
    on all of its interfaces for traffic to port `32769`.
  prefs: []
  type: TYPE_NORMAL
- en: The net result of this is that despite not having an IPv6 NAT rule, I'm still
    able to access the containers service through the Docker hosts interfaces. In
    this manner, published ports with IPv6 still work. However, this only works when
    using the `docker-proxy`. That mode of operation, while still the default, is
    intended to be removed in favor of hairpin NAT. We can enable hairpin NAT on the
    Docker host by passing the `--userland-proxy=false` parameter to Docker as a service-level
    option. Doing so would prevent this means of IPv6 port publishing from working.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the lack of firewall integration also means that we no longer have
    support for the outbound masquerade feature. In IPv4, this feature allowed containers
    to talk to the outside network without having to worry about routing or IP address
    overlapping. Container traffic leaving the host was always hidden behind one of
    the hosts IP interfaces. However, this was not a mandated configuration. As we
    saw in earlier chapters, you could very easily disable the outbound masquerade
    feature and provision the `docker0` bridge with a routable IP address and subnet.
    So long as the outside, or external, network knew how to reach that subnet, a
    container could very easily have a unique routable IP address.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the reasons IPv6 came to be was because of the rapid depletion of IPv4
    addresses. NAT in IPv4 served as a largely successful, although equally troublesome,
    temporary stop gap to the address depletion problem. This means that many believe
    that we shouldn''t be implementing any sort of NAT in regard to IPv6 whatsoever.
    Rather, all IPv6 prefixes should be natively routable and reachable without the
    obfuscation of an IP translation. Lacking IPv6 firewall integration, natively
    routing IPv6 traffic to each host is the current means in which Docker can facilitate
    reachability across multiple Docker hosts and the outside network. This requires
    that each Docker host uses a unique IPv6 CIDR range and that the Docker hosts
    know how to reach all of the other Docker hosts defined CIDR range. While this
    typically requires the physical network to have network reachability information,
    in our simple lab example each host just requires a static route to the other
    hosts CIDR. Much like we did in the first recipe, we''ll add an IPv6 route on
    each host so both know how to reach the IPv6 subnet of the other `docker0` bridge:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'After adding the routes, each Docker host knows how to get to the other host''s
    IPv6 `docker0` bridge subnet:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](graphics/5453_10_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If we now check, we should have reachability between containers on each host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the container on the host `docker1` was able to successfully
    route directly to the container running on the host `docker2`. So as long as each
    Docker host has the appropriate routing information, containers will be able to
    route directly to one another.
  prefs: []
  type: TYPE_NORMAL
- en: The downside of this approach is that the container is now a fully exposed network
    endpoint. We no longer get the advantage of exposing only certain ports to the
    outside network through Docker published ports. If you want to ensure that only
    certain ports are exposed on your IPv6 interfaces the userland proxy may be your
    best option at this point. Keep these options in mind when designing services
    around IPv6 connectivity.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring NDP proxying
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we saw in the last recipe, one of the major differences with IPv6 support
    in Docker is the lack of the firewall integration. Without that integration, we
    lose things like outbound masquerade and full port publishing capabilities. And
    while this may not be necessary in all cases, there is a certain convenience factor
    that is lost when not using this. For instance, when running in IPv4 only mode,
    an administrator could install Docker and immediately connect your containers
    to the outside network. This is because the container was only ever seen through
    the Docker host's IP addresses for both inbound (published port) and outbound
    (masquerade) connectivity. This meant that there was no need to inform the outside
    network about additional subnets because the outside network only ever saw the
    Docker host's IP addresses. In the IPv6 model, the outside network has to know
    about the container subnets in order to route to them. In this chapter, we'll
    review how to configure NDP proxying as a workaround to this problem.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we''ll be using this lab topology:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](graphics/5453_10_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: You'll need root-level access to each host to make network configuration changes.
    It is assumed that Docker is installed, and it's a default configuration.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The preceding topology shows that our hosts are dual stack connected to the
    network, but Docker has not yet been configured to use IPv6\. Like we saw in the
    previous recipe, configuring Docker for IPv6 would also typically mean configuring
    routing on the outside network, so it knows how to reach the IPv6 CIDR you define
    for the `docker0` bridge to use. However, assume for a moment that this isn't
    possible. Assume that you have no control over the outside network, which means
    you can't advertise or notify other network endpoints about any newly defined
    IPv6 subnet on your Docker host.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s also assume that while you can''t advertise any newly defined IPv6 networks,
    you are however able to reserve additional IPv6 space within the existing networks.
    For instance, the hosts currently have interfaces defined within the `2003:ab11::/64`
    network. If we carve up this space, we can split it into four `/66` networks:'
  prefs: []
  type: TYPE_NORMAL
- en: '`2003:ab11::/66`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`2003:ab11:0:0:4000::/66`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`2003:ab11:0:0:8000::/66`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`2003:ab11:0:0:c000::/66`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s assume for a second that we are allowed to reserve the last two subnets
    for our use. We can now enable IPv6 within Docker and allocate these two networks
    as the IPv6 CIDR ranges. Here are the configuration options for each Docker host:'
  prefs: []
  type: TYPE_NORMAL
- en: '`docker1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '`docker2`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'After loading the new configuration into `systemd` and restarting the Docker
    service, our lab topology would now look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](graphics/5453_10_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s launch a container on both hosts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Now determine the allocated IPv6 address of the `web1` container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s try and reach that container from the `web2` container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'This fails because the Docker hosts believe that the destination address is
    directly connected to their `eth0` interface. When the `web2` container attempts
    the connection, the following actions occur:'
  prefs: []
  type: TYPE_NORMAL
- en: The container does a route lookup and determines that the address `2003:ab11::8000:242:ac11:2`
    does not fall within its local subnet of `2003:ab11:0:0:c000::1/66`, so it forwards
    the traffic to its default gateway (the `docker0` bridge interface)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The host receives the traffic and does a route lookup and determines that the
    destination address of `2003:ab11::8000:242:ac11:2` falls within its local subnet
    of `2003:ab11::/64` (`eth0`) and uses NDP to try and find the host with that destination
    IP address
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The host receives no response to this query and the flow fails
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can verify that this is what''s happening by checking the `docker2` host''s
    IPv6 neighbor table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Following the normal routing logic, everything is working the way it should.
    However IPv6 has a feature called NDP proxy, which can help solve this problem.
    Those of you familiar with proxy ARP in IPv4 will find NDP proxy to provide similar
    functionality. Essentially, NDP proxy allows a host to answer neighbor requests
    on behalf of another endpoint. In our case, we can tell both Docker hosts to answer
    on behalf of the containers. To do this, we need to first enable NDP proxy on
    the host itself. This is done by enabling the kernel parameter `net.ipv6.conf.eth0.proxy_ndp`,
    as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Keep in mind that these settings won't persist through a reboot when defined
    in this manner.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once that is enabled, we need to manually tell each host what IPv6 address
    to answer for. We do that by adding proxy entries to each host''s neighbor table.
    In the preceding example, we need to do that for both the source and the destination
    container in order to allow for bidirectional traffic flow. First, add the entry
    on the host `docker1` for the destination:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, determine the IPv6 address of the `web2` container, which will act as
    the source of the traffic and add a proxy entry for that on the host `docker2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'This will tell each Docker host to reply to the neighbor solicitation requests
    on behalf of the containers. Ping tests should now work as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'And we should see the relevant neighbor entry on each host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Much like proxy ARP, NDP proxy works by the host providing its own MAC address
    in response to the neighbor discovery request. We can see that in both cases,
    the MAC address in the neighbor table is actually each host''s `eth0` MAC address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: This approach works fairly well in cases where you can't advertise your Docker
    IPv6 subnet to the outside network. However, it relies on individual proxy entries
    for each IPv6 address you wish to proxy. For each container spawned you would
    need to generate an additional IPv6 proxy address.
  prefs: []
  type: TYPE_NORMAL
- en: User-defined networks and IPv6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Much like we saw with IPv4, user-defined networks can leverage IPv6 addressing.
    That is, all of the network-related parameters relate to both IPv4 and IPv6\.
    In this chapter, we'll walk through defining a user-defined IPv6 network and demonstrate
    some of the related configuration options.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we'll be using a single Docker host. It is assumed that Docker
    is installed and is its default configuration. It is not required that the Docker
    service be enabled with the `--ipv6` service-level parameter in order to use IPv6
    addressing on user-defined networks.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When working with user-defined networks, we can define configuration for both
    IPv4 and IPv6\. In addition, when we run containers we can specify both their
    IPv4 and IPv6 addresses. To demonstrate this, let''s first define a user-defined
    network that has both IPv4 and IPv6 addressing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: The syntax of this command should be familiar to you from [Chapter 3](ch03.html
    "Chapter 3. User-Defined Networks"), *User-Defined Networks*, where we discussed
    user-defined networks. However, there are a couple of things to point out.
  prefs: []
  type: TYPE_NORMAL
- en: First, you'll notice that we've defined the `--subnet` parameter twice. In doing
    so, we defined both an IPv4 subnet as well as an IPv6 subnet. The `--gateway`
    and `--aux-address` fields can be used in a similar fashion when defining IPv4
    and IPv6 addresses. Second, we defined an option to enable IPv6 on this network.
    If you do not define this option to enable IPv6 the gateway interface of the host
    will not be defined.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once defined, let''s start a container on the network to see what our configuration
    looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: This syntax should also look familiar to you. Note that we specified that this
    container should be a member of the user-defined network `ipv6_bridge`. In doing
    so, we can also define both an IPv4 and IPv6 address for the container using the
    `--ip` and `--ip6` parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we inspect the network, we should see the container attached as well as
    all of the relevant information related to both the network definition as well
    as the containers network interfaces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'By checking the host''s network configuration, we should see that a new bridge
    has been created that matches up with these networks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'If we check the container itself, we''ll note that these interfaces are what
    the containers on this network will use for both their IPv4 and IPv6 default gateway:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Just like the default network modes, user-defined networks do not support host
    firewall integration to support outbound masquerade or inbound port publishing.
    IPv6 connectivity on and off of the host is the same as the `docker0` bridge in
    regard to having to route the IPv6 traffic natively.
  prefs: []
  type: TYPE_NORMAL
- en: 'You''ll also note that if you start a second container on the host that embedded
    DNS works for both IPv4 and IPv6 addressing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
