- en: Chapter 9. Maintaining Redis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To maintain data, it's important to understand the data that we are going to
    store in our Redis datastore. Data comes with various properties, which we covered
    in [Chapter 1](ch01.html "Chapter 1. Introduction to NoSQL"), *Introduction to
    NoSQL*, and we are again going to focus on one of these facets in deciding the
    strategies that we will undertake for data maintenance in this chapter. The facet
    that we will be focusing on is the ephemeral nature of data.
  prefs: []
  type: TYPE_NORMAL
- en: Maintaining ephemeral data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Data that has its importance for a certain duration of time, which is transient
    in nature, can be termed as **ephemeral data**. Such data needs to be flushed
    out of the system after the intended duration and computer resources have to be
    freed in order to be made available for newer datasets. In some datastores where
    there is no in-built capability to do this, scripts and programs have to be written
    to clean them, or in other words, the onus is on the user to cleanse the system.
    Before we get into details of the mechanisms Redis has to offer, let''s look at
    the types of data that can be termed as ephemeral. Data types that fall in this
    category are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Event data**: Stock tickers have importance over a small period of time and
    then lose their value in the context form in which they are viewed. Suppose the
    value of the tech stock of a dummy corporation is $100 at 1300 hours, and for
    all the algorithms interested in calculating the *whatever* index of the tech
    stock at 1300 hours this data is important. After, let''s say, 1310 hours, this
    value of data is not important as it''s old data or log data and can thus be viewed
    as ephemeral data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transient business data**: Transient business data, for example, promotion
    coupon discounts is an important feature of e-commerce businesses. They carry
    importance for a certain period of time and after the time period is over these
    promotional offers cease to exist. Again, this type of data can be categorized
    as ephemeral data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Session data**: Every e-business has a component for session handling; it''s
    basically the data that is maintained to record the data generated when the registered
    user is interacting with the portal.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The strategy to handle ephemeral data is easy in Redis. Redis has a built-in
    capability called **Time to Live** (**TTL**), or the other option is P-TTL, which
    is more precise as it returns data with millisecond resolution. This capability
    keeps the data in the memory for a specified time, and after the time is over,
    the data is flushed out. Redis has an in-built process that keeps on monitoring
    the data that has a specified TTL and moves in a loop, cleaning data once the
    duration is over.
  prefs: []
  type: TYPE_NORMAL
- en: '![Maintaining ephemeral data](img/1794_09_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A diagrammatic representation of the TTL process in Redis
  prefs: []
  type: TYPE_NORMAL
- en: Another mechanism to cleanse data if TTL/PTTL is not specified is to use the
    `EXPIRE` or `PEXPIRE` commands. These commands set a time-out on the key as the
    data is volatile. An interesting thing that occurs in `PEXPIRE` is that if a key
    has been assigned with a value and an `EXPIRE` time, and if the value is set again
    before this time lapses, then the `EXPIRE` time attribute is removed.
  prefs: []
  type: TYPE_NORMAL
- en: For the `PEXPIRE` command in a clustered environment, the DEL command for the
    key is sent to all the slaves and to the **append-only file** (**AOF**) of the
    node. Redis makes sure that it is deleted from all the locations, either in memory
    (such as, in slaves) or in the filesystem (such as, in the AOF).
  prefs: []
  type: TYPE_NORMAL
- en: '![Maintaining ephemeral data](img/1794_09_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A diagrammatic representation of the EXPIRE command in a clustered environment
  prefs: []
  type: TYPE_NORMAL
- en: The behavior of TTL is similar to that of the `EXPIRE` command in a clustered
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: Maintaining nonephemeral data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Nonephemeral type of data is not dependent on time and has usefulness throughout
    its existence in the system. Since this kind of data is time-independent, it is
    possible that the data can increase in due course of time. This can be problematic
    in Redis since data is stored in memory in Redis. Handling and maintaining this
    nonephemeral data is crucial for the maintenance of Redis since at the back of
    our minds, we have to keep the available memory and availability of data in mind.
  prefs: []
  type: TYPE_NORMAL
- en: Redis comes with some capabilities to handle the previously discussed scenarios,
    which is if the datastore grows at an alarming rate, as it can outgrow the memory
    available. In such scenarios, adding more RAM can solve the issue, or we can distribute
    the datasets using a programmatic technique called Sharding. However, in this
    chapter, we will discuss a mechanism to maintain data that is not required in
    an active application but needs to be stored.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see a few in-built techniques or mechanisms to manage data in Redis and
    its evolution roadmap over the versions that have been released.
  prefs: []
  type: TYPE_NORMAL
- en: Redis 2.4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Redis has an in-built capability (deprecated since 2.4) of swapping datasets
    between the RAM and filesystem (disk or SSD). This capability of Redis is called
    **virtual memory** (**VM**). This capability can be configured by enabling it,
    `vm-enabled yes`, in the configuration file.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand this feature, let''s imagine the entire dataset in Redis as a
    bucket sorted on the basis of the last accessed data. Here, last accessed refers
    to the instance it was last modified or accessed. The dataset that is least accessed
    is pushed to disk. This way the space is maintained for frequently accessed datasets.
    In case the dataset that has been pushed is accessed again, then this dataset
    is brought back to the main memory and the second to last least-accessed data
    is pushed to disk. The following figure is a representation of the behind-the-scenes
    activity when VM is enabled:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Redis 2.4](img/1794_09_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A simplistic representation of the handling of datasets of a VM-enabled system
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that it's the values that are pushed to disk and not the keys. The keys
    are always in memory.
  prefs: []
  type: TYPE_NORMAL
- en: This VM option is suitable for business data that contains large datasets against
    a key. This option is also useful when there is a usage pattern wherein with time,
    some data is less frequently accessed.
  prefs: []
  type: TYPE_NORMAL
- en: 'This VM option is also suitable in scenarios where we have a large number of
    key-value pairs that can outgrow the memory. In this case, we can club these key-values
    in Hashes. For example, let''s assume that we are maintaining customer records
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Customer 1 as (KEY) and some customer data "ABC" as (VALUE)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Customer 2 as (KEY) and some customer data "XYZ" as (VALUE)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Customer 3 as (KEY) and some customer data "123" as (VALUE)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Customer 4 as (KEY) and some customer data "AQ@" as (VALUE)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we continue to store data in this fashion, then we have the danger of running
    out of space (memory) if the customer data grows (although it's good for business,
    it's not so good for the technical team supporting it). A better way of storing
    this customer data would be in a Hash.
  prefs: []
  type: TYPE_NORMAL
- en: 'A customer store will be `(KEY)` and the corresponding customer values will
    be of the type `(HASHES)` and contain the following data:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Customer 3 as (KEY) and some customer data "123" as (VALUE)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Customer 4 as (KEY) and some customer data "AQ@" as (VALUE)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Customer 1 as (KEY) and some customer data "ABC" as (VALUE)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Customer 2 as (KEY) and Some Customer data "XYZ" as (VALUE)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we store values in this way, in a worst-case scenario, the entire value dataset
    will be pushed to disk and can be brought back to memory again, if need be.
  prefs: []
  type: TYPE_NORMAL
- en: 'To configure a VM capability apart from `vm-enabled yes`, the following configurations
    need to be looked into:'
  prefs: []
  type: TYPE_NORMAL
- en: '`vm-max-threads`: This provides the maximum number of threads to perform I/O
    activity between memory and disk. Setting the value to `0` will burden the single
    thread, which is managing the client request, stall the entire process and load
    the dataset back into the main memory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vm-max-memory`: This option tells the Redis server the amount of memory it
    should reserve to store datasets. The moment this threshold is reached it starts
    to swap datasets from memory to disk.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vm-swap-file`: This setting provides the location in the filesystem where
    the datasets can be dumped.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vm-pages`: This setting will hint the Redis server about the number of pages
    that need to be created to swap the file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vm-page-size`: This setting will hint the Redis server about the amount of
    disk storage to be allocated to store a value dataset. The combination of `vm-pages`
    and `vm-page-size` is important for the storage and faster retrieval of the datasets
    from the disk.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In business case scenarios where performance is paramount and there's a constraint
    of using the VM option, performance can be improved by using **solid-state devices**
    (**SSD**). These devices have faster reads and writes as compared to disk, which
    is limited by the read/write speed of the disk.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that the VM option will be getting deprecated as of Redis 2.4.
  prefs: []
  type: TYPE_NORMAL
- en: Redis 2.6 to 2.8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unlike Version 2.4—where the VM option was the way out to handle data bigger
    than memory—in newer versions, it's better to clear the data and store it in a
    separate location (here, location can be a different instance or a filesystem).
    The problems faced in the VM option were taken care of in the newer version.
  prefs: []
  type: TYPE_NORMAL
- en: Dump and restore
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For Redis Version 2.6, one of the mechanisms is to issue the `Dump` key command,
    which will return the serialized version of the data for the key. This data can
    be used along with the `Restore` command in the target instance of Redis from
    where it can be converted to readable data. As discussed earlier, the best pattern
    to handle large data is to collect the key-values in a collection, such as Hashes,
    and then to operate on it to manage the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram is a simple representation of the actions that can be
    taken to handle data (which is no longer accessed but need to be kept in the system):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Dump and restore](img/1794_09_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A diagrammatic representation of the DUMP and RESTORE commands
  prefs: []
  type: TYPE_NORMAL
- en: The benefit of storing keys and values in a collection, such as Hashes, is that
    you can fire one command that will act on the entire collection and then use one
    command to restore it back. This technique is useful when you already have a pocket
    of data that needs to be purged. However, when you want to store the entire dataset,
    you have to look into *snapshotting*, which is discussed later.
  prefs: []
  type: TYPE_NORMAL
- en: This mechanism has a caveat; that is, it records data in a serialized RDB version,
    so this serialized data cannot be used for any other Redis version.
  prefs: []
  type: TYPE_NORMAL
- en: Snapshotting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An in-built technique to handle large datasets is called *snapshotting*. This
    technique, as discussed in the previous chapters, is used to persist data in AOF.
    This process will dump data into an AOF, as specified in the configuration file.
    The means and mechanism to do this is to execute commands in order to dump data
    into the file either in the background (`BGSAVE`) or foreground (`SAVE`). In a
    highly concurrent environment, if these activities cause a strain on the system
    performance, one clever way to solve this issue is to have a bigger machine.
  prefs: []
  type: TYPE_NORMAL
- en: The idea to bring in a bigger machine and make it a slave to the node (master)
    under stress and at a suitable time promotes this bigger machine to master node.
    So, now the entire datasets are in the bigger machine with more resources. The
    following diagram is a simple representation of the entire activity. In many production
    environments, since the data layer is usually behind a router, it's general practice
    to use a router to make a switch of traffic rather than depend on Sentinel to
    make the switch. In an environment where the router is not present, Sentinel can
    be used to make the switch, and the process to do so has been dealt with in previous
    chapters.
  prefs: []
  type: TYPE_NORMAL
- en: '![Snapshotting](img/1794_09_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A simplistic representation of migrating data from a small to a large machine
  prefs: []
  type: TYPE_NORMAL
- en: Redis 3.0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another mechanism to keep the Redis dataset limited to the available memory
    is to purge old data. Redis doesn't have an in-built mechanism to purge data;
    instead, it has a combination of `MIGRATE` and `RESTORE` data. Let's look at this
    process in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Let's assume that we have a collection of Hashes, which maintain the purchase
    history of all the customers for the year 2012; so, typically the key will look
    like **PURCHASE_HISTORY_2012**, and the value will be a Hash of datasets, containing
    the customer's ID as the key and the customer purchase details as values.
  prefs: []
  type: TYPE_NORMAL
- en: '![Redis 3.0](img/1794_09_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A representation of the key-value datasets to be migrated
  prefs: []
  type: TYPE_NORMAL
- en: Likewise, **PURCHASE_HISTORY_2013**, **PURCHASE_HISTORY_2014**, and **PURCHASE_HISTORY_2015**
    will be maintained for subsequent years. Any business requirement to show the
    purchase data for the last 4 years for a user, let's say **Customer-A**, will
    pick data from the key for 2012, 2013, 2014, and 2015\. The business requirement
    will append the data from these years, thereby forming a composite response. Now,
    in 2016, another key will be created, but the same function to get the purchase
    history for **Customer-A** will pick data from the key for 2013, 2014, 2015, and
    2016\. In this case, **PURCHASE_HISTORY_2012** will be left out, but for legal
    reasons, we cannot delete it. Yet, it occupies memory space in the online system.
    In this scenario, we can issue the `MIGRATE` command, which is a combination of
    `DUMP` and `DEL`. When we issue the `MIGRATE` command internally, Redis will issue
    a `DUMP` key to serialize the data and I/O into the target instance. Once the
    target instance is restored, the serialized key then sends an `OK` command back
    to the source machine, which can then delete the **PURCHASE_HISTORY_2012** key.
    We can now issue a `SAVE` command in the target instance and make an AOF file,
    which can be stored in the filesystem for later reference, if need be.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure is a representation of the migration of data for a given
    key:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Redis 3.0](img/1794_09_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A representation of the migration process in Redis
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that the `MIGRATE` command will work in Redis 3.0 Version.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you saw various mechanisms to maintain data in Redis, either
    using the in-built capability in Redis or by employing clever mechanisms to achieve
    it.
  prefs: []
  type: TYPE_NORMAL
