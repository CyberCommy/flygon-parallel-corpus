- en: Chapter 9. Maintaining Redis
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To maintain data, it's important to understand the data that we are going to
    store in our Redis datastore. Data comes with various properties, which we covered
    in [Chapter 1](ch01.html "Chapter 1. Introduction to NoSQL"), *Introduction to
    NoSQL*, and we are again going to focus on one of these facets in deciding the
    strategies that we will undertake for data maintenance in this chapter. The facet
    that we will be focusing on is the ephemeral nature of data.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: Maintaining ephemeral data
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Data that has its importance for a certain duration of time, which is transient
    in nature, can be termed as **ephemeral data**. Such data needs to be flushed
    out of the system after the intended duration and computer resources have to be
    freed in order to be made available for newer datasets. In some datastores where
    there is no in-built capability to do this, scripts and programs have to be written
    to clean them, or in other words, the onus is on the user to cleanse the system.
    Before we get into details of the mechanisms Redis has to offer, let''s look at
    the types of data that can be termed as ephemeral. Data types that fall in this
    category are the following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: '**Event data**: Stock tickers have importance over a small period of time and
    then lose their value in the context form in which they are viewed. Suppose the
    value of the tech stock of a dummy corporation is $100 at 1300 hours, and for
    all the algorithms interested in calculating the *whatever* index of the tech
    stock at 1300 hours this data is important. After, let''s say, 1310 hours, this
    value of data is not important as it''s old data or log data and can thus be viewed
    as ephemeral data.'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transient business data**: Transient business data, for example, promotion
    coupon discounts is an important feature of e-commerce businesses. They carry
    importance for a certain period of time and after the time period is over these
    promotional offers cease to exist. Again, this type of data can be categorized
    as ephemeral data.'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Session data**: Every e-business has a component for session handling; it''s
    basically the data that is maintained to record the data generated when the registered
    user is interacting with the portal.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The strategy to handle ephemeral data is easy in Redis. Redis has a built-in
    capability called **Time to Live** (**TTL**), or the other option is P-TTL, which
    is more precise as it returns data with millisecond resolution. This capability
    keeps the data in the memory for a specified time, and after the time is over,
    the data is flushed out. Redis has an in-built process that keeps on monitoring
    the data that has a specified TTL and moves in a loop, cleaning data once the
    duration is over.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '![Maintaining ephemeral data](img/1794_09_01.jpg)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
- en: A diagrammatic representation of the TTL process in Redis
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Another mechanism to cleanse data if TTL/PTTL is not specified is to use the
    `EXPIRE` or `PEXPIRE` commands. These commands set a time-out on the key as the
    data is volatile. An interesting thing that occurs in `PEXPIRE` is that if a key
    has been assigned with a value and an `EXPIRE` time, and if the value is set again
    before this time lapses, then the `EXPIRE` time attribute is removed.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: For the `PEXPIRE` command in a clustered environment, the DEL command for the
    key is sent to all the slaves and to the **append-only file** (**AOF**) of the
    node. Redis makes sure that it is deleted from all the locations, either in memory
    (such as, in slaves) or in the filesystem (such as, in the AOF).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '![Maintaining ephemeral data](img/1794_09_02.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
- en: A diagrammatic representation of the EXPIRE command in a clustered environment
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: The behavior of TTL is similar to that of the `EXPIRE` command in a clustered
    environment.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Maintaining nonephemeral data
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Nonephemeral type of data is not dependent on time and has usefulness throughout
    its existence in the system. Since this kind of data is time-independent, it is
    possible that the data can increase in due course of time. This can be problematic
    in Redis since data is stored in memory in Redis. Handling and maintaining this
    nonephemeral data is crucial for the maintenance of Redis since at the back of
    our minds, we have to keep the available memory and availability of data in mind.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 非短暂类型的数据不依赖于时间，在系统中存在期间具有用处。由于这种数据是与时间无关的，可能会随着时间的推移而增加。这在Redis中可能会有问题，因为Redis中的数据存储在内存中。处理和维护这种非短暂数据对于Redis的维护至关重要，因为我们必须牢记可用内存和数据的可用性。
- en: Redis comes with some capabilities to handle the previously discussed scenarios,
    which is if the datastore grows at an alarming rate, as it can outgrow the memory
    available. In such scenarios, adding more RAM can solve the issue, or we can distribute
    the datasets using a programmatic technique called Sharding. However, in this
    chapter, we will discuss a mechanism to maintain data that is not required in
    an active application but needs to be stored.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Redis具有一些功能来处理先前讨论的情况，即如果数据存储在惊人的速度增长，可能会超出可用内存。在这种情况下，增加更多的RAM可以解决问题，或者我们可以使用一个称为Sharding的编程技术来分发数据集。然而，在本章中，我们将讨论一种维护不需要在活动应用程序中的数据但需要存储的机制。
- en: Let's see a few in-built techniques or mechanisms to manage data in Redis and
    its evolution roadmap over the versions that have been released.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看Redis中管理数据的一些内置技术或机制，以及它在已发布的版本中的演进路线图。
- en: Redis 2.4
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Redis 2.4
- en: Redis has an in-built capability (deprecated since 2.4) of swapping datasets
    between the RAM and filesystem (disk or SSD). This capability of Redis is called
    **virtual memory** (**VM**). This capability can be configured by enabling it,
    `vm-enabled yes`, in the configuration file.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Redis具有一个内置功能（自2.4版起已弃用），可以在RAM和文件系统（磁盘或SSD）之间交换数据集。这个Redis的功能称为虚拟内存（VM）。可以通过在配置文件中启用它`vm-enabled
    yes`来配置这个Redis的功能。
- en: 'To understand this feature, let''s imagine the entire dataset in Redis as a
    bucket sorted on the basis of the last accessed data. Here, last accessed refers
    to the instance it was last modified or accessed. The dataset that is least accessed
    is pushed to disk. This way the space is maintained for frequently accessed datasets.
    In case the dataset that has been pushed is accessed again, then this dataset
    is brought back to the main memory and the second to last least-accessed data
    is pushed to disk. The following figure is a representation of the behind-the-scenes
    activity when VM is enabled:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这个特性，让我们想象一下Redis中整个数据集是一个按最后访问数据排序的桶。这里，最后访问是指上次修改或访问的实例。最少访问的数据集被推送到磁盘。这样就为频繁访问的数据集保留了空间。如果再次访问被推送的数据集，那么这个数据集将被带回主内存，而倒数第二个最少访问的数据将被推送到磁盘。当VM启用时，下图是幕后活动的表示：
- en: '![Redis 2.4](img/1794_09_03.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![Redis 2.4](img/1794_09_03.jpg)'
- en: A simplistic representation of the handling of datasets of a VM-enabled system
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一个虚拟机启用系统数据集处理的简单表示
- en: Note
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Note that it's the values that are pushed to disk and not the keys. The keys
    are always in memory.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，推送到磁盘的是值，而不是键。键始终在内存中。
- en: This VM option is suitable for business data that contains large datasets against
    a key. This option is also useful when there is a usage pattern wherein with time,
    some data is less frequently accessed.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这个VM选项适用于包含大型数据集的业务数据。当存在一种使用模式，随着时间推移，一些数据被较少访问时，这个选项也是有用的。
- en: 'This VM option is also suitable in scenarios where we have a large number of
    key-value pairs that can outgrow the memory. In this case, we can club these key-values
    in Hashes. For example, let''s assume that we are maintaining customer records
    as shown here:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可以将这些键值对合并在Hashes中。例如，假设我们正在维护客户记录如下所示：
- en: '*Customer 1 as (KEY) and some customer data "ABC" as (VALUE)*'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*客户1作为（KEY），一些客户数据“ABC”作为（VALUE）*'
- en: '*Customer 2 as (KEY) and some customer data "XYZ" as (VALUE)*'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*客户2作为（KEY），一些客户数据“XYZ”作为（VALUE）*'
- en: '*Customer 3 as (KEY) and some customer data "123" as (VALUE)*'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*客户3作为（KEY），一些客户数据“123”作为（VALUE）*'
- en: '*Customer 4 as (KEY) and some customer data "AQ@" as (VALUE)*'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*客户4作为（KEY），一些客户数据“AQ@”作为（VALUE）*'
- en: If we continue to store data in this fashion, then we have the danger of running
    out of space (memory) if the customer data grows (although it's good for business,
    it's not so good for the technical team supporting it). A better way of storing
    this customer data would be in a Hash.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们继续以这种方式存储数据，那么如果客户数据增长，我们有可能会耗尽空间（内存）（尽管这对业务来说是好事，但对支持它的技术团队来说并不是好事）。更好的存储客户数据的方法是使用Hash。
- en: 'A customer store will be `(KEY)` and the corresponding customer values will
    be of the type `(HASHES)` and contain the following data:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 客户存储将是（KEY），相应的客户值将是（HASHES），并包含以下数据：
- en: '*Customer 3 as (KEY) and some customer data "123" as (VALUE)*'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*客户3作为（KEY），一些客户数据“123”作为（VALUE）*'
- en: '*Customer 4 as (KEY) and some customer data "AQ@" as (VALUE)*'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*客户4作为（KEY），一些客户数据“AQ@”作为（VALUE）*'
- en: '*Customer 1 as (KEY) and some customer data "ABC" as (VALUE)*'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*客户1作为（KEY），一些客户数据“ABC”作为（VALUE）*'
- en: '*Customer 2 as (KEY) and Some Customer data "XYZ" as (VALUE)*'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*客户2作为（KEY），一些客户数据“XYZ”作为（VALUE）*'
- en: If we store values in this way, in a worst-case scenario, the entire value dataset
    will be pushed to disk and can be brought back to memory again, if need be.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果以这种方式存储值，在最坏的情况下，整个值数据集将被推送到磁盘，并且如果需要，可以再次带回内存。
- en: 'To configure a VM capability apart from `vm-enabled yes`, the following configurations
    need to be looked into:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 除了`vm-enabled yes`之外，要配置VM功能，需要查看以下配置：
- en: '`vm-max-threads`: This provides the maximum number of threads to perform I/O
    activity between memory and disk. Setting the value to `0` will burden the single
    thread, which is managing the client request, stall the entire process and load
    the dataset back into the main memory.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vm-max-threads`：此设置提供了在内存和磁盘之间执行I/O活动的最大线程数。将值设置为`0`将使管理客户端请求的单个线程负担过重，导致整个过程停滞，并将数据集重新加载到主内存中。'
- en: '`vm-max-memory`: This option tells the Redis server the amount of memory it
    should reserve to store datasets. The moment this threshold is reached it starts
    to swap datasets from memory to disk.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vm-max-memory`：此选项告诉Redis服务器应保留多少内存来存储数据集。一旦达到此阈值，它就开始将数据集从内存交换到磁盘。'
- en: '`vm-swap-file`: This setting provides the location in the filesystem where
    the datasets can be dumped.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vm-swap-file`：此设置提供了可以转储数据集的文件系统中的位置。'
- en: '`vm-pages`: This setting will hint the Redis server about the number of pages
    that need to be created to swap the file.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vm-pages`：此设置将提示Redis服务器需要创建多少页面来交换文件。'
- en: '`vm-page-size`: This setting will hint the Redis server about the amount of
    disk storage to be allocated to store a value dataset. The combination of `vm-pages`
    and `vm-page-size` is important for the storage and faster retrieval of the datasets
    from the disk.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vm-page-size`：此设置将提示Redis服务器分配多少磁盘存储空间来存储值数据集。`vm-pages`和`vm-page-size`的组合对于从磁盘快速检索数据集的存储非常重要。'
- en: In business case scenarios where performance is paramount and there's a constraint
    of using the VM option, performance can be improved by using **solid-state devices**
    (**SSD**). These devices have faster reads and writes as compared to disk, which
    is limited by the read/write speed of the disk.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在业务案例场景中，性能至关重要，并且有使用VM选项的限制时，可以通过使用**固态设备**（**SSD**）来提高性能。与磁盘相比，这些设备具有更快的读写速度，磁盘受读/写速度的限制。
- en: Note
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Note that the VM option will be getting deprecated as of Redis 2.4.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，从Redis 2.4开始，VM选项将被弃用。
- en: Redis 2.6 to 2.8
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Redis 2.6到2.8
- en: Unlike Version 2.4—where the VM option was the way out to handle data bigger
    than memory—in newer versions, it's better to clear the data and store it in a
    separate location (here, location can be a different instance or a filesystem).
    The problems faced in the VM option were taken care of in the newer version.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 与2.4版本不同——在该版本中，VM选项是处理大于内存的数据的方法——在更新的版本中，最好清除数据并将其存储在一个单独的位置（这里，位置可以是不同的实例或文件系统）。在新版本中解决了VM选项面临的问题。
- en: Dump and restore
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 转储和恢复
- en: For Redis Version 2.6, one of the mechanisms is to issue the `Dump` key command,
    which will return the serialized version of the data for the key. This data can
    be used along with the `Restore` command in the target instance of Redis from
    where it can be converted to readable data. As discussed earlier, the best pattern
    to handle large data is to collect the key-values in a collection, such as Hashes,
    and then to operate on it to manage the data.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Redis版本2.6，其中一种机制是发出`Dump`键命令，它将返回该键的数据的序列化版本。此数据可以与目标Redis实例中的`Restore`命令一起使用，从而将其转换为可读数据。如前所述，处理大数据的最佳模式是将键值收集到集合中（例如Hashes），然后对其进行操作以管理数据。
- en: 'The following diagram is a simple representation of the actions that can be
    taken to handle data (which is no longer accessed but need to be kept in the system):'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表是处理数据（不再访问但需要保留在系统中）的简单表示：
- en: '![Dump and restore](img/1794_09_04.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![转储和恢复](img/1794_09_04.jpg)'
- en: A diagrammatic representation of the DUMP and RESTORE commands
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: DUMP和RESTORE命令的示意图表示
- en: The benefit of storing keys and values in a collection, such as Hashes, is that
    you can fire one command that will act on the entire collection and then use one
    command to restore it back. This technique is useful when you already have a pocket
    of data that needs to be purged. However, when you want to store the entire dataset,
    you have to look into *snapshotting*, which is discussed later.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 将键和值存储在集合中（例如Hashes）的好处是，您可以发出一个命令来操作整个集合，然后使用一个命令将其恢复。当您已经有一小部分需要清除的数据时，这种技术非常有用。然而，当您想要存储整个数据集时，您必须研究*快照*，这将在后面讨论。
- en: This mechanism has a caveat; that is, it records data in a serialized RDB version,
    so this serialized data cannot be used for any other Redis version.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这种机制有一个警告；即它记录数据的序列化RDB版本，因此这些序列化数据不能用于任何其他Redis版本。
- en: Snapshotting
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 快照
- en: An in-built technique to handle large datasets is called *snapshotting*. This
    technique, as discussed in the previous chapters, is used to persist data in AOF.
    This process will dump data into an AOF, as specified in the configuration file.
    The means and mechanism to do this is to execute commands in order to dump data
    into the file either in the background (`BGSAVE`) or foreground (`SAVE`). In a
    highly concurrent environment, if these activities cause a strain on the system
    performance, one clever way to solve this issue is to have a bigger machine.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 处理大型数据集的内置技术称为*快照*。如前几章所讨论的，这种技术用于在AOF中持久化数据。此过程将数据转储到AOF中，如配置文件中指定的那样。执行命令将数据转储到文件中的方式和机制可以是在后台（`BGSAVE`）或前台（`SAVE`）执行。在高度并发的环境中，如果这些活动对系统性能造成压力，解决此问题的一个聪明方法是使用更大的机器。
- en: The idea to bring in a bigger machine and make it a slave to the node (master)
    under stress and at a suitable time promotes this bigger machine to master node.
    So, now the entire datasets are in the bigger machine with more resources. The
    following diagram is a simple representation of the entire activity. In many production
    environments, since the data layer is usually behind a router, it's general practice
    to use a router to make a switch of traffic rather than depend on Sentinel to
    make the switch. In an environment where the router is not present, Sentinel can
    be used to make the switch, and the process to do so has been dealt with in previous
    chapters.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '![Snapshotting](img/1794_09_05.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
- en: A simplistic representation of migrating data from a small to a large machine
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Redis 3.0
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another mechanism to keep the Redis dataset limited to the available memory
    is to purge old data. Redis doesn't have an in-built mechanism to purge data;
    instead, it has a combination of `MIGRATE` and `RESTORE` data. Let's look at this
    process in detail.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Let's assume that we have a collection of Hashes, which maintain the purchase
    history of all the customers for the year 2012; so, typically the key will look
    like **PURCHASE_HISTORY_2012**, and the value will be a Hash of datasets, containing
    the customer's ID as the key and the customer purchase details as values.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '![Redis 3.0](img/1794_09_06.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
- en: A representation of the key-value datasets to be migrated
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: Likewise, **PURCHASE_HISTORY_2013**, **PURCHASE_HISTORY_2014**, and **PURCHASE_HISTORY_2015**
    will be maintained for subsequent years. Any business requirement to show the
    purchase data for the last 4 years for a user, let's say **Customer-A**, will
    pick data from the key for 2012, 2013, 2014, and 2015\. The business requirement
    will append the data from these years, thereby forming a composite response. Now,
    in 2016, another key will be created, but the same function to get the purchase
    history for **Customer-A** will pick data from the key for 2013, 2014, 2015, and
    2016\. In this case, **PURCHASE_HISTORY_2012** will be left out, but for legal
    reasons, we cannot delete it. Yet, it occupies memory space in the online system.
    In this scenario, we can issue the `MIGRATE` command, which is a combination of
    `DUMP` and `DEL`. When we issue the `MIGRATE` command internally, Redis will issue
    a `DUMP` key to serialize the data and I/O into the target instance. Once the
    target instance is restored, the serialized key then sends an `OK` command back
    to the source machine, which can then delete the **PURCHASE_HISTORY_2012** key.
    We can now issue a `SAVE` command in the target instance and make an AOF file,
    which can be stored in the filesystem for later reference, if need be.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure is a representation of the migration of data for a given
    key:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '![Redis 3.0](img/1794_09_07.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
- en: A representation of the migration process in Redis
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that the `MIGRATE` command will work in Redis 3.0 Version.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you saw various mechanisms to maintain data in Redis, either
    using the in-built capability in Redis or by employing clever mechanisms to achieve
    it.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
