- en: Debugging and Instrumenting Application Containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker can remove a lot of the friction in the typical developer workflow process
    and significantly reduce the time spent on overhead tasks, such as dependency
    management and environment configuration. When developers run the changes they're
    working on using the exact same application platform where the final product will
    run, there are far fewer opportunities for deployment mistakes, and the upgrade
    path is straightforward and well-understood.
  prefs: []
  type: TYPE_NORMAL
- en: Running your application in a container during development adds another layer
    to your development environment. You'll be working with different types of assets
    such as Dockerfiles and Docker Compose files, and that experience is improved
    if your IDE supports these types. Also, there's a new runtime between the IDE
    and your app, so the debugging experience will be different. You may need to change
    your workflow to make the most of the platform benefits.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, I''ll look at the development process with Docker, covering
    IDE integration and debugging, and how to add instrumentation to your Dockerized
    applications. You''ll learn about:'
  prefs: []
  type: TYPE_NORMAL
- en: Working with Docker in integrated development environments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instrumentation in Dockerized applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bug fixing workflow in Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will need Docker running on Windows 10 update 18.09, or Windows Server 2019
    to follow along with the examples. The code for this chapter is available at [https://github.com/sixeyed/docker-on-windows/tree/second-edition/ch11](https://github.com/sixeyed/docker-on-windows/tree/second-edition/ch11).
  prefs: []
  type: TYPE_NORMAL
- en: Working with Docker in integrated development environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, I demonstrated a containerized *outer loop*, the compilation
    and packaging CI process that is triggered from central source control when developers
    push changes. The **integrated development environments** (**IDEs**) are beginning
    to support containerized workflows for the *inner loop*, which is the developer
    process of writing, running, and debugging applications in containers before pushing
    changes to central source control.
  prefs: []
  type: TYPE_NORMAL
- en: Visual Studio 2017 has native support for Docker artifacts, including IntelliSense
    and code completion for Dockerfiles. There is also runtime support for ASP.NET
    projects running in containers, both .NET Framework and .NET Core. In Visual Studio
    2017, you can hit the *F5* key and your web app will launch inside a container,
    running in Docker Desktop on Windows. The application uses the same base image
    and Docker runtime that you will use in all other environments.
  prefs: []
  type: TYPE_NORMAL
- en: Visual Studio 2015 has a plugin that provides support for Docker artifacts,
    and Visual Studio Code has a very useful Docker extension. Visual Studio 2015
    and Visual Studio Code don't provide an integrated *F5* debugging experience for
    .NET apps running in Windows containers, but you can configure this manually,
    and I will demonstrate that in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: There's a compromise when you debug inside a container—this means creating a
    disconnect between the inner loop and the outer loop. Your development process
    uses a different set of Docker artifacts from your **continuous integration**
    (**CI**) process to make the debugger available to the container and to map the
    application assemblies to the source code. The benefit is that you can run in
    a container in development with the same developer build and debug experience
    that you're used to. The downside is that your development Docker image is not
    the exact same image you'll be promoting to test.
  prefs: []
  type: TYPE_NORMAL
- en: A good way to mitigate this is to use the local Docker artifacts for development
    when you're iterating rapidly over a feature. Then, you use the CI Docker artifacts,
    still running locally, for the final build and end-to-end tests before pushing
    your changes.
  prefs: []
  type: TYPE_NORMAL
- en: Docker in Visual Studio 2017
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Visual Studio 2017 has the most complete Docker support of all the .NET IDEs.
    You can open an ASP.NET Framework Web API project in Visual Studio 2017, right-click
    on the project, and select Add | Container Orchestrator Support:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/b3921071-0b2f-487b-9b25-193543b06c6b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There''s only one orchestrator option to choose from, which is Docker Compose.
    Visual Studio then generates a set of Docker artifacts. In the `Web` project,
    it creates a Dockerfile that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: There's full IntelliSense support for the Dockerfile syntax, so you can hover
    over instructions and see information about them and use *Ctrl* + Spacebar to
    open a prompt for all Dockerfile instructions.
  prefs: []
  type: TYPE_NORMAL
- en: The generated Dockerfile uses the `microsoft/aspnet` base image, which comes
    with ASP.NET 4.7.2, fully installed and configured. At the time of writing, the
    Dockerfile uses an old version of the Windows base image, so you need to manually
    update it to use the latest Windows Server 2019 base image, that is, `mcr.microsoft.com/dotnet/framework/aspnet:4.7.2-windowsservercore-ltsc2019`.
  prefs: []
  type: TYPE_NORMAL
- en: The Dockerfile looks odd because it uses a build argument to specify the location
    of the source folder, and then it copies the content of that folder to the web
    root directory, `C:\inetpub\wwwroot`, inside the container image.
  prefs: []
  type: TYPE_NORMAL
- en: In the solution root, Visual Studio creates a set of Docker Compose files. There
    are multiple files, and Visual Studio uses them with the Docker Compose `build`
    and `up` commands to package and run the application. This works behind the scenes
    when you run the app with the *F5* key , but it's worth looking at how Visual
    Studio uses them; it shows you how you can add this level of support to different
    IDEs.
  prefs: []
  type: TYPE_NORMAL
- en: Debugging with Docker Compose in Visual Studio 2017
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The generated Docker Compose files are shown under the top-level solution object:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/0b2f32c1-dfa2-431e-8f3b-4ae277474b2a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There''s a basic `docker-compose.yml` file with the web application defined
    as a service, complete with build details for the Dockerfile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'There''s also a `docker-compose.override.yml` file, which adds the port and
    network configuration so that it can run locally:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'There''s nothing here about building the application because the compilation
    is done in Visual Studio rather than in Docker. The built application binaries
    live on your development machine and are copied into the container. When you hit
    *F5*, the container is started and Visual Studio launches a browser at the container''s
    IP address. You can add breakpoints to code in Visual Studio, and when you navigate
    to that code from the browser, you''ll be taken to the debugger in Visual Studio:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/8a0d0f97-90fe-43fb-b674-05d152804d08.png)'
  prefs: []
  type: TYPE_IMG
- en: It's a seamless experience, but it's not clear what's happening—how does the
    Visual Studio debugger on your machine connect to the binaries inside the container?
    Fortunately, Visual Studio logs all the Docker commands it issues to the output
    windows, so you can track down how this works.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the build output window, you''ll see something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see that the build happens first, and then the container is launched
    with `docker-compose up`. The `docker-compose.yml` and `docker-compose.override.yml`
    files we''ve already seen are used, along with a file called `docker-compose.vs.debug.g.yml`.
    Visual Studio generates that file on the build, and you need to show all the files
    in the solution to see it. It contains additional Docker Compose settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'There''s a lot going on here:'
  prefs: []
  type: TYPE_NORMAL
- en: The Docker image uses the `dev` tag to distinguish it from the release build
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The build argument for the source location specifies an empty directory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A volume is used to mount the web root in the container from the project folder
    on the host
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A second volume is used to mount the Visual Studio remote debugger in the container
    from the host
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The entrypoint launches `ServiceMonitor` to run IIS, and then launches `msvsmon`,
    which is the remote debugger
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In debug mode, the argument for the source code environment variable is an empty
    directory. Visual Studio builds a Docker image with an empty `wwwroot` directory
    and then mounts the source code folder from the host into the web root in the
    container to populate that folder at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the container is running, Visual Studio runs some commands inside the
    container to set permissions, which allows the remote debugger tool to work. In
    the output window for Docker, you''ll see something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: That's Visual Studio fetching the ID of the container it launched with Docker
    Compose, then running `appcmd` to set the IIS application pool to use an administrative
    account and to set the web server to allow anonymous authentication.
  prefs: []
  type: TYPE_NORMAL
- en: Visual Studio 2017 keeps the container running in the background when you stop
    debugging. If you make a change to the program and rebuild, the same container
    is used so that there's no startup lag. By mounting the project location into
    the container, any changes in content or binaries are reflected when you rebuild.
    By mounting the remote debugger from the host, your image doesn't have any development
    tools baked into it; they stay on the host.
  prefs: []
  type: TYPE_NORMAL
- en: This is the inner loop process, where you get fast feedback. Whenever you change
    and rebuild your app, you see these changes in the container. However, the Docker
    image from debug mode is not usable for the outer loop CI process; the app is
    not copied into the image; it works only if you mount the app from your local
    source into a container.
  prefs: []
  type: TYPE_NORMAL
- en: 'To support the outer loop, there''s also a Docker compose override file for
    release mode in a second hidden override file, `docker-compose.vs.release.g.yml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The difference here is that there's no volume mapping the local source location
    to the web root in the container. When you compile in release mode, the value
    of the source argument is a published location that contains the web app. Visual
    Studio builds the release image by packaging the published application into the
    container.
  prefs: []
  type: TYPE_NORMAL
- en: In release mode, you can still run the application in a Docker container and
    you can still debug the application. But you lose the fast feedback loop because
    to change the app, Visual Studio needs to rebuild the Docker image and start a
    new container.
  prefs: []
  type: TYPE_NORMAL
- en: This is a fair compromise, and the Docker tooling in Visual Studio 2017 gives
    you a seamless development experience, along with the basis for your CI build.
    One thing Visual Studio 2017 doesn't do is use multi-stage builds, so the project
    compilation still happens on the host rather than inside a container. This makes
    the generated Docker artifacts less portable, so you need more than just Docker
    to build this app on a server.
  prefs: []
  type: TYPE_NORMAL
- en: Docker in Visual Studio 2015
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Visual Studio 2015 has a plugin available from the marketplace called **Visual
    Studio Tools for Docker**. This gives you syntax highlighting for Dockerfiles,
    but it doesn't integrate Visual Studio with Docker for .NET Framework apps. With
    Visual Studio 2015, you can add Docker support to a .NET Core project, but you
    need to manually write your own Dockerfile and Docker Compose files for full .NET.
  prefs: []
  type: TYPE_NORMAL
- en: Also, there's no integrated debugging for applications running in Windows containers.
    You can still debug code running in a container, but you need to manually configure
    the setup. I'll demonstrate how to do this now using the same approach as Visual
    Studio 2017, and with some of the same compromises.
  prefs: []
  type: TYPE_NORMAL
- en: In Visual Studio 2017, you can mount the folder containing the remote debugger
    from the host into your container. When you run the project, Visual Studio starts
    a container and executes the `msvsmon.exe` from the host that is the remote debugger
    agent. You don't need to install anything in your image to provide the debugging
    experience.
  prefs: []
  type: TYPE_NORMAL
- en: The remote debugger in Visual Studio 2015 is not so portable. You can mount
    the debugger from the host in the container, but when you try to start the agent,
    you'll see errors about missing files. Instead, you need to install the remote
    debugger into your image.
  prefs: []
  type: TYPE_NORMAL
- en: 'I have this set up in a folder called `ch11-webapi-vs2015`. In the Dockerfile
    for this image, I use a build-time argument to conditionally install the debugger
    if the `configuration` value is set to `debug.` This means that I can build locally
    with the debugger installed, but when I build for deployment, the image doesn''t
    have the debugger:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'I use the same approach as Visual Studio 2017 to mount the source directory
    on the host into the container when running in debug mode, but I create a custom
    website rather than using the default one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The `:-` syntax in the `COPY` instruction specifies a default value if the
    `source` argument is not provided. The default is to copy from the published web
    application unless it is specified in the `build` command. I have a core `docker-compose.yml`
    file with the basic service definition and a `docker-compose.debug.yml` file that
    mounts the host source location, maps the debugger ports, and specifies the `configuration`
    variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The label specified in the compose file attaches a key-value pair to the container.
    The value isn't visible inside the container, unlike an environment variable,
    but it is visible to external processes on the host. In this case, it is used
    by Visual Studio to identify the operating system of the container.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start the app in debug mode, I use both Compose files to start the application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the container is running my web app using **Internet Information Services**
    (**IIS**) inside the container, and the Visual Studio remote debugger agent is
    running as well. I can connect to a remote process in Visual Studio 2015 and use
    the IP address of the container:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/3909f411-ca1a-4d71-a1c8-f10ecdc8607e.png)'
  prefs: []
  type: TYPE_IMG
- en: The debugger in Visual Studio attaches to the agent running in the container,
    and I can add breakpoints and view variables, just like debugging to a local process.
    In this approach, the container is using the host mount for the content of the
    web app. I can stop the debugger, make changes, rebuild the app, and see the changes
    in the same container without having to start a new container.
  prefs: []
  type: TYPE_NORMAL
- en: This approach has the same benefits and drawbacks as the integrated Docker support
    in Visual Studio 2017\. I'm running my app in a container for local debugging,
    so I get all the features of the Visual Studio debugger and my app is running
    in the same platform I'll use in other environments. But I won't be using the
    same image because the Dockerfile has conditional branches, so it produces different
    outputs for the debug and release modes.
  prefs: []
  type: TYPE_NORMAL
- en: There is an advantage to manually building debugger support in your Docker artifacts.
    You can construct your Dockerfile with conditioning so that the default `docker
    image build` command produces the production-ready image without requiring any
    additional artifacts. This example still does not use a multi-stage build, though,
    so the Dockerfile is not portable and the application needs to be compiled before
    it can be packaged.
  prefs: []
  type: TYPE_NORMAL
- en: In development, you build the image once in debug mode, run the container, and
    then attach the debugger whenever you need to. Your integration tests build and
    run the production image, so only the inner loop has the additional debugger components.
  prefs: []
  type: TYPE_NORMAL
- en: Docker in Visual Studio Code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Visual Studio Code is a new cross-platform IDE for cross-platform development.
    The C# extension installs a debugger that can attach to .NET Core applications,
    but there's no support for debugging full .NET Framework apps.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Docker extension adds some very useful features, including the ability
    to add Dockerfiles and Docker Compose files to existing projects for known platforms,
    such as Go and .NET Core. You can add a Dockerfile to a .NET Core project and
    choose between using Windows or Linux containers as the base—hit *F1*, type `docker`,
    and select Add Docker Files to Workspace:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/d6ee79a9-f1d5-4c77-81bf-dbee789ba6b1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here''s the generated Dockerfile for a .NET Core Web API project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This is using an old version of the .NET Core base images, so the first step
    is to replace the `nanoserver-1803` tags in the `FROM` lines with `nanoserver-1809`.
    The extension generates a multi-stage Dockerfile, using the SDK image for the
    build and publish stages, and the ASP.NET Core runtime for the final image. VS
    Code generates more stages in the Dockerfile than you really need, but that's
    a design choice.
  prefs: []
  type: TYPE_NORMAL
- en: VS Code also generates a `.dockerignore` file. This is a useful feature that
    speeds up your Docker image builds. In the ignore file, you list any file or directory
    paths that aren't used in your Dockerfile, and these are excluded from the build
    context. Excluding all the `bin`, `obj`, and `packages` folders means that the
    Docker CLI sends a much smaller payload to the Docker Engine when you build the
    image, and that can make the build much faster.
  prefs: []
  type: TYPE_NORMAL
- en: You can use F1 | docker tasks to build the image and run a container, but there's
    no functionality to generate Docker Compose files in the way that Visual Studio
    2017 does.
  prefs: []
  type: TYPE_NORMAL
- en: Visual Studio Code has a very flexible system for running and debugging your
    projects, so you can add your own configuration to provide debugging support for
    apps running in Windows containers. You can edit the `launch.json` file to add
    a new configuration for debugging in Docker.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `ch11-webapi-vscode` folder, I have a sample .NET Core project set up
    to run the application in Docker and attach a debugger. It uses the same approach
    as Visual Studio 2017\. The debugger for .NET Core is called `vsdbg` and is installed
    with the C# extension in Visual Studio Code, so I mount the `vsdbg` folder from
    the host into the container, along with the source location using the `docker-compose.debug.yml`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This setup uses a specific version of the C# extension. That's 1.17.1 in my
    case, but you may have a different version. Check for the location of `vsdbg.exe`
    in the `.vscode` folder in your user directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you run the app through Docker Compose using the debug override file,
    it starts the .NET Core application and makes the debugger from the host available
    to run in the container. This is configured for a debugging experience in Visual
    Studio Code in the `launch.json` file. The `Debug Docker container` configuration
    specifies what type of application to debug and the name of the process to attach:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This configuration also maps the application root in the container to the source
    code location on the host, so the debugger can associate the correct source files
    with the debug files. In addition, the debugger configuration specifies how to
    launch the debugger by running a `docker container exec` command on the named
    container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'To debug my app, I need to build and run it in the debug configuration, using
    Docker Compose with the override file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, I can activate the debugger using the Debug action and selecting Debug
    Docker container:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/64e9ad65-f404-4292-a022-36536a415a3a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Visual Studio Code starts the .NET Core debugger `vsdbg` inside the container
    and attaches it to the running `dotnet` process. You''ll see the output from the
    .NET Core application being redirected into the DEBUG CONSOLE window in Visual
    Studio Code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/c219df7a-a5ca-44a1-956d-acc2d5e697fe.png)'
  prefs: []
  type: TYPE_IMG
- en: At the time of writing, Visual Studio Code doesn't fully integrate with the
    debugger running inside a Windows Docker container. You can place breakpoints
    in the code and the debugger will pause the process, but control does not pass
    to Visual Studio Code. This is a known issue with running the Omnisharp debugger
    inside a Nano Server container – it's being tracked on GitHub at: [https://github.com/OmniSharp/omnisharp-vscode/issues/1001](https://github.com/OmniSharp/omnisharp-vscode/issues/1001).
  prefs: []
  type: TYPE_NORMAL
- en: Running your application in a container and being able to debug from your normal
    IDE is a huge benefit. It means your app is running on the same platform and with
    the same deployment configuration it will use in all other environments, but you
    can step into code just as if it were running locally.
  prefs: []
  type: TYPE_NORMAL
- en: Docker support in IDEs is improving rapidly so all the manual steps I've detailed
    in this chapter will be built into products and extensions soon. JetBrains Rider
    is a good example of a third-party .NET IDE that works well with Docker. It integrates
    with the Docker API and can attach its own debugger to running containers.
  prefs: []
  type: TYPE_NORMAL
- en: Instrumentation in Dockerized applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Debugging your app is what you do when the logic doesn't work as expected and
    you're trying to track down what's going wrong. You don't debug in production,
    so you need your app to record its behavior to help you trace any problems that
    occur.
  prefs: []
  type: TYPE_NORMAL
- en: Instrumentation is often neglected, but it should be a crucial component of
    your development. It's the best way to understand the health and activity of your
    app in production. Running your app in Docker provides new opportunities for centralized
    logging and instrumentation so that you can get a consistent view across the different
    parts of your application, even if they use different languages and platforms.
  prefs: []
  type: TYPE_NORMAL
- en: Adding instrumentation to your containers can be a straightforward process.
    Windows Server Core containers are already collecting lots of metrics in Windows
    performance counters. Docker images built with .NET or IIS will also have all
    the additional performance counters from those stacks. You can instrument containers
    just by exposing the performance counter values to a metrics server.
  prefs: []
  type: TYPE_NORMAL
- en: Instrumentation with Prometheus
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The ecosystem around Docker is very large and active, taking advantage of the
    open standards and extensibility of the platform. As the ecosystem has matured,
    a few technologies have emerged as strong candidates for inclusion in almost all
    Dockerized applications.
  prefs: []
  type: TYPE_NORMAL
- en: Prometheus is an open source monitoring solution. It's a flexible component
    that you can use in different ways, but the typical implementation is to run a
    Prometheus server in a Docker container, configured to read instrumentation endpoints
    that you make available in your other Docker containers.
  prefs: []
  type: TYPE_NORMAL
- en: You configure Prometheus to poll all the container endpoints and it stores the
    results in a time-series database. You can add a Prometheus endpoint to your application
    by simply adding a REST API, which responds to `GET` requests from the Prometheus
    server with a list of the metrics you're interested in collecting.
  prefs: []
  type: TYPE_NORMAL
- en: For .NET Framework and .NET Core projects, there is a NuGet package that does
    this for you, that is, adding a Prometheus endpoint to your application. It exposes
    a useful set of metrics by default, including the values of key .NET statistics
    and Windows performance counters. You can add Prometheus support directly to your
    application or you can run a Prometheus exporter alongside your app.
  prefs: []
  type: TYPE_NORMAL
- en: The approach you take will depend on the type of application you want to instrument.
    If it's a legacy .NET Framework app that you're moving to Docker, you can add
    basic instrumentation by packaging a Prometheus exporter in the Docker image,
    and that will give you metrics about your application without you needing to change
    code. For new applications, you can write code to expose specific application
    metrics to Prometheus.
  prefs: []
  type: TYPE_NORMAL
- en: Exposing .NET application metrics to Prometheus
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `prometheus-net` NuGet package provides a set of default metric collectors
    and a `MetricServer` class that provides the instrumentation endpoint that Prometheus
    hooks into. This package is great for adding Prometheus support to any app. The
    metrics are provided by a self-hosted HTTP endpoint, and you can provide custom
    metrics for your application.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `dockeronwindows/ch11-api-with-metrics` image, I''ve added Prometheus
    support into a Web API project. The code to configure and start the metrics endpoint
    is in the `PrometheusServer` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This starts a new `MetricServer` instance listening on port `50505` and running
    the default set of .NET statistics and performance counter collectors that the
    `NuGet` package provides. These are on-demand collectors, which means they provide
    metrics when the Prometheus server calls into the endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `MetricServer` class will also return any custom metrics you set up in
    your application. Prometheus supports different types of metrics. The simplest
    is the counter, which is just an incrementing counter—Prometheus queries your
    app for the metrics values, and the app returns a single number for each counter.
    In the `ValuesController` class, I have set up some counters to record requests
    and responses to the API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'When requests come into the controller, the controller action method increments
    the request count for the URL and increments the status count for the response
    code by calling the `Inc()` method on the counter objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Prometheus has various other types of metrics that you can use to record key
    information about your app—counters only increase, but gauges can increase and
    decrease, so they're useful for recording snapshots. Prometheus records each metric
    value with a timestamp and a set of arbitrary labels that you provide. In this
    case, I will add the `URL` and the `HTTP` method to the request count and the
    URL and status code to the response count. I can use these to aggregate or filter
    metrics in Prometheus.
  prefs: []
  type: TYPE_NORMAL
- en: 'The counters I set up in the Web API controller give me a set of custom metrics
    showing which endpoints are being used and the status of the responses. These
    are exposed by the server component in the `NuGet` package, along with the default
    metrics to record the system''s performance. In the Dockerfile for this app, there
    are two additional lines for the Prometheus endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The first line just exposes the custom port I'm using for the metrics endpoint.
    The second line sets up the permissions that are needed for that endpoint. In
    this case, the metrics endpoint is hosted inside the ASP.NET app, so the IIS user
    account needs permissions to listen on the custom port and to access the system
    performance counters.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can build the Dockerfile and run a container from the image in the usual
    way, that is, by publishing all the ports with `-P`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'To check whether the metrics are being recorded and exposed, I can run some
    PowerShell commands to grab the port of the container, then make some calls to
    the API endpoint and check the metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'You''ll see a plain text list of metrics, grouped by name and label. Each metric
    also contains the metadata for Prometheus, including the metric name, the type,
    and a friendly description:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The complete output is much larger. In this snippet, I've shown the total number
    of threads, the allocated memory and the CPU usage, which all comes from standard
    Windows and .NET performance counters inside the container. I've also shown the
    custom HTTP request and response counters.
  prefs: []
  type: TYPE_NORMAL
- en: My custom counters in this application show the URL and the response code. In
    this case, I can see 10 requests to the root URL of the value controller, and
    ten responses with the OK status code `200`. Later in this chapter, I'll show
    you how to visualize these statistics using Grafana.
  prefs: []
  type: TYPE_NORMAL
- en: Adding the `NuGet` package to the project and running the `MetricServer` is
    a simple extension of the source code. It lets me record any kind of metric that
    is useful, but it does mean changing the app, so it's only suitable for applications
    that are under active development.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, you may want to add monitoring without altering the application
    you want to instrument. In that case, you can run an **exporter** alongside your
    app. An exporter pulls metrics from your application process and exposes them
    to Prometheus. In Windows containers, you can get a lot of useful information
    from the standard performance counters.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a Prometheus exporter alongside existing apps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a Dockerized solution, Prometheus will make scheduled calls to the metrics
    endpoint that are exposed from a container and will store the results. For an
    existing app, you don't need to add a metrics endpoint—you can run a console app
    alongside the current application, and host the metrics endpoint in that console
    app.
  prefs: []
  type: TYPE_NORMAL
- en: 'I''ve added a Prometheus endpoint to the NerdDinner web application from [Chapter
    10](e0946741-5df7-4a13-b220-ffc963f1e3d3.xhtml), *Powering a Continuous Deployment
    Pipeline with Docker*, without changing any code. In the `dockeronwindows/ch11-nerd-dinner-web-with-metrics`
    image, I''ve added a console app that exports ASP.NET performance counters and
    provides the metrics endpoint. The ASP.NET exporter app comes from a public image
    on Docker Hub. The full Dockerfile for NerdDinner copies in the binaries for the
    exporter and sets the startup command for containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The `aspnet-exporter.exe` console application implements a custom metrics collector,
    which reads the performance counter values for a named process running on the
    system. It uses the same set of counters as the default collector in the NuGet
    package, but it targets a different process. The exporter reads performance counters
    for the IIS `w3wp.exe` process, and it's configured to export key IIS metrics.
  prefs: []
  type: TYPE_NORMAL
- en: The source code for the exporter is all on GitHub in the `dockersamples/aspnet-monitoring`
    repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'The console exporter is a lightweight component. It starts when the container
    starts and keeps running as long as the container is running. It only uses compute
    resources when the metrics endpoint is called, so it has minimal impact when running
    on a Prometheus schedule. I run NerdDinner in the usual way (here, I''m just running
    the ASP.NET component, not the full solution):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'I can fetch the container port and browse to NerdDinner in the usual way. Then,
    I can also browse to the metrics endpoint on the exporter application''s port,
    which publishes the IIS performance counters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/45dac49c-d499-475b-b061-7b0d59893237.png)'
  prefs: []
  type: TYPE_IMG
- en: In this case, there are no custom counters from the application, and all the
    metrics come from standard Windows and .NET performance counters. The exporter
    application can read these performance counter values for the running `w3wp` process,
    so the application doesn't need to change to provide basic information to Prometheus.
  prefs: []
  type: TYPE_NORMAL
- en: These are runtime metrics telling you how hard IIS is working inside the container.
    You can see the number of active threads, memory usage, and the size of the IIS
    file cache. There are also metrics for the percentage of HTTP status codes IIS
    has responded with, so you can see if there are large numbers of 404 or 500 errors.
  prefs: []
  type: TYPE_NORMAL
- en: To record custom application metrics, you need to instrument your code and explicitly
    record the data points you're interested in. You need to invest effort for that,
    but the result is an instrumented application where you can see key performance
    metrics in addition to the .NET runtime metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Adding instrumentation to your Dockerized application means providing the metrics
    endpoint for Prometheus to query. The Prometheus server itself runs in a Docker
    container, and you configure it with the services you want to monitor.
  prefs: []
  type: TYPE_NORMAL
- en: Running a Prometheus server in a Windows Docker container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Prometheus is a cross-platform application written in Go, so it can run in a
    Windows container or a Linux container. Like other open source projects, the team
    publishes a Linux image on Docker Hub, but you need to build your own Windows
    image. I'm using an existing image that packages Prometheus into a Windows Server
    2019 container from the same `dockersamples/aspnet-monitoring` example on GitHub
    that I used for the ASP.NET exporter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Dockerfile for Prometheus doesn''t do anything you haven''t already seen
    plenty of times in this book—it downloads the release file, extracts it, and sets
    up the runtime environment. The Prometheus server has multiple functions: it runs
    scheduled jobs to poll metrics endpoints, it stores the data in a time-series
    database, and it provides a REST API to query the database and a simple Web UI
    to navigate the data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'I need to add my own configuration for the scheduler, which I could do by running
    a container and mounting a volume for the config file, or using Docker config
    objects in swarm mode. The configuration for my metrics endpoints is fairly static,
    so it would be nice to bundle a default set of configurations into my own Prometheus
    image. I''ve done that with `dockeronwindows/ch11-prometheus:2e`, which has a
    very simple Dockerfile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'I already have containers running from my instrumented API and NerdDinner web
    images, which expose metrics endpoints for Prometheus to consume. To monitor them
    in Prometheus, I need to specify the metric locations in the `prometheus.yml`
    configuration file. Prometheus will poll these endpoints on a configurable schedule.
    It calls this **scraping**, and I''ve added my container names and ports in the
    `scrape_configs` section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Each application to monitor is specified as a job, and each endpoint is listed
    as a target. Prometheus will be running in a container on the same Docker network,
    so I can refer to the targets by the container name.
  prefs: []
  type: TYPE_NORMAL
- en: This setup is for a single Docker Engine, but you can use the same approach
    with Prometheus to monitor services running across multiple replicas, just using
    different configuration settings. I cover that in detail for Windows and Linux
    containers in my Pluralsight course, *Monitoring Containerized Application Health
    with Docker.*
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, I can start the Prometheus server in a container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Prometheus polls all the configured metrics endpoints and stores the data. You
    can use Prometheus as the backend for a rich UI component such as Grafana, building
    all your runtime KPIs into a single dashboard. For basic monitoring, the Prometheus
    server has a simple Web UI listening on port `9090`.
  prefs: []
  type: TYPE_NORMAL
- en: 'I can go to the published port of the Prometheus container to run some queries
    over the data it''s scraping from my application containers. The Prometheus UI
    can present the raw data, or aggregated graphs over time. Here''s the HTTP response
    that''s sent by the REST API application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/51c842d2-ccef-4050-804c-944af2e34719.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see that there are separate lines for each different label value, so
    I can see the different response codes from different URLs. These are counters
    that increase with the life of the container, so the graphs will always go up.
    Prometheus has a rich set of functions so that you can also graph the rate of
    change over time, aggregate metrics, and select projections over the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Other counters from the Prometheus `NuGet` package are snapshots, such as performance
    counter statistics. I can see the number of requests per second that IIS is handling
    from the NerdDinner container:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/9cc9e9fb-a94b-4fb5-a7ea-a988d49eb640.png)'
  prefs: []
  type: TYPE_IMG
- en: Metric names are important in Prometheus. If I wanted to compare the memory
    usage of a .NET Console and an ASP.NET app, then I can query both sets of values
    if they have the same metric name, something like `process_working_set`. The labels
    for each metric identify which service is providing the data, so you can aggregate
    across all your services or filter to specific services. You should also include
    an identifier for each container as a metric label. The exporter app adds the
    server hostname as a label. That's actually the container ID, so when you're running
    at scale, you can aggregate for the whole service or look at individual containers.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 8](98e12163-b4ad-4b5d-aecc-827f5e204caa.xhtml), *Administering and
    Monitoring Dockerized Solutions*, I demonstrated **Universal Control Plane** (**UCP**),
    the **Containers-as-a-Service** (**CaaS**) platform in Docker Enterprise. The
    standard APIs to start and manage Docker containers lets this tool present a consolidated
    management and administration experience. The openness of the Docker platform
    lets open source tools take the same approach to rich, consolidated monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: Prometheus is a good example of that. It runs as a lightweight server, which
    is well-suited to running in a container. You add support for Prometheus to your
    application either by adding a metrics endpoint to your app, or by running a metrics
    exporter alongside your existing app. The Docker Engine itself can be configured
    to export Prometheus metrics, so you can collect low-level metrics about container
    and node health.
  prefs: []
  type: TYPE_NORMAL
- en: Those metrics are all you need to power a rich dashboard that tells you about
    the health of your application at a glance.
  prefs: []
  type: TYPE_NORMAL
- en: Building application dashboards in Grafana
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Grafana is a web UI for visualizing data. It can read from many data sources, including
    time-series databases, such as Prometheus, and relational databases, such as SQL
    Server. You can build dashboards in Grafana that display the health of your whole
    application estate, including business KPIs, application and runtime metrics,
    and infrastructure health.
  prefs: []
  type: TYPE_NORMAL
- en: 'You typically add Grafana in a containerized application to present the data
    from Prometheus. You run Grafana in a container too, and you can package your
    Docker image so that the dashboards, user accounts, and database connections are
    built-in. I''ve done that for the final part of this chapter, in the `dockeronwindows/ch11-grafana:2e` image.
    The Grafana team don''t publish a Windows image on Docker Hub, so my Dockerfile
    starts from a sample image and adds in all the configuration for my setup:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Grafana has two approaches to automating deployment. The first just uses files
    in known locations, which I use to set up the Prometheus data source, the dashboard,
    and the dashboard provider, which just points Grafana to a directory for dashboards.
    The second uses a REST API for authentication and authorization, and my `init.ps1`
    script uses that to create a read-only user with access to the dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: It's simple to create your own dashboards with Grafana. You create a panel for
    a particular type of visualization—numbers, graphs, heatmaps, traffic lights,
    and tables are all supported. Then, you connect the panel to a data source and
    specify the query. Typically, you'd use the Prometheus UI to fine-tune the query
    and then add it to Grafana. To save time, my image comes with a ready-made dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: 'I''ll start the monitoring solution with the Docker Compose file in the `ch11`
    folder, then browse to the API and the website to generate some traffic. Now,
    I can browse to Grafana and log in with the username `viewer` and password `readonly`,
    and I''ll see the dashboard:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/a8ac5193-aa9c-433f-811e-5e25f9899cfa.png)'
  prefs: []
  type: TYPE_IMG
- en: This is just a sample dashboard, but it gives you an idea about how much information
    you can present. I have a row for the REST API, showing a breakdown of HTTP requests
    and responses, and an overall view of the CPU usage. I also have a row for NerdDinner,
    showing performance metrics from IIS and headline statistics for cache usage.
  prefs: []
  type: TYPE_NORMAL
- en: You can add instrumentation to all your applications with very little effort
    and build a detailed dashboard to give you insight into what's happening in your
    solution. What's more, you can have the exact same monitoring facility in every
    environment, so in development and test you can see the same metrics that you
    use in production. This is very useful in tracking down performance issues. Developers
    can add a new metric and visualization for a performance problem, fix the problem,
    and when the change goes live, it will include the new metric that can be tracked
    in production.
  prefs: []
  type: TYPE_NORMAL
- en: The last thing I'll cover in this chapter is how to approach fixing bugs in
    Docker, and how containerization makes it so much easier.
  prefs: []
  type: TYPE_NORMAL
- en: The bug fixing workflow in Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the biggest difficulties in fixing production defects is replicating
    them in your development environment. This is the first step in confirming that
    you have a bug and the starting point for drilling down to find the problem. It
    can also be the most time-consuming part of the problem.
  prefs: []
  type: TYPE_NORMAL
- en: Large .NET projects tend to have infrequent releases because the release process
    is complex, and a lot of manual testing is needed to verify the new features and
    check for any regressions. It's not unusual to have just three or four releases
    a year and for developers to find themselves having to support multiple versions
    of an application in different parts of the release process.
  prefs: []
  type: TYPE_NORMAL
- en: In this scenario, you may have version 1.0 in production, version 1.1 in **user
    acceptance testing** (**UAT**), and version 1.2 in system testing. Bugs could
    be raised in any of these versions that the development team needs to track down
    and fix while they're currently working on version 1.3, or even a major upgrade
    for 2.0.
  prefs: []
  type: TYPE_NORMAL
- en: Bug fixing before Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I've been in this position lots of times, having to context switch from the
    refactored 2.0 code base I'm working on back to the 1.1 code base that is due
    to be released. The context switch is expensive, but the process of setting up
    my development environment to recreate the 1.1 UAT environment is even more costly.
  prefs: []
  type: TYPE_NORMAL
- en: The release process may create a versioned MSI, but typically you can't just
    run that in your development environment. The installer may be packaged with the
    configuration for a specific environment. It may have been compiled in release
    mode and packaged without PDB files, so there's no option to attach a debugger,
    and it may have prerequisites that I don't have available in development, such
    as certificates or encryption keys or additional software components.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, I need to recompile the 1.1 version from source. Hopefully, the release
    process has enough information for me to find the exact source code that was used
    to build the release, take a branch, and clone it locally (maybe the Git commit
    ID or the TFS change set is recorded in the built assemblies). Then, the real
    problems start when I try to recreate another environment on my local development
    box.
  prefs: []
  type: TYPE_NORMAL
- en: 'The workflow looks a little like this, where there are lots of differences
    between my setup and the 1.1 environment:'
  prefs: []
  type: TYPE_NORMAL
- en: Compile the source locally. I'll build the app in Visual Studio, but the released
    version uses MSBuild scripts, which do a lot of extra things.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run the app locally. I'll be using IIS Express on Windows 10, but the release
    uses an MSI that deploys to IIS 8 on Windows Server 2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: My local SQL Server database is set up for the 2.0 schema I'm working on. The
    release has upgrade scripts from 1.0 to 1.1, but there are no downgrade scripts
    from 2.0 to 1.1, so I need to manually fix the local schema.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I have stubs for any dependencies I can't run locally, such as third-party APIs.
    The release uses real application components.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even if I can get the exact source code for version 1.1, my development environment
    is hugely divergent from the UAT environment. This is the best I can do, and it
    may take several hours of effort. To reduce this time, I could take shortcuts,
    such as using my knowledge of the app to run version 1.1 against the 2.0 database
    schema, but taking shortcuts means my local environment is even less like the
    target environment.
  prefs: []
  type: TYPE_NORMAL
- en: I can run the app in debug mode at this point and try to replicate the issue.
    If the bug is caused by a data problem or an environmental problem in UAT, then
    I won't be able to replicate it and it could have taken a whole day of effort
    to find that out. If I suspect that the issue is to do with the setup of UAT,
    I can't verify that in my environment; I need to work with the Ops team to look
    at the UAT configuration.
  prefs: []
  type: TYPE_NORMAL
- en: But hopefully I can reproduce the issue by following the steps in the bug report.
    When I have the manual steps worked out, I can write a failing test that replicates
    the issue and be confident that I've fixed the problem when I change the code
    and the test runs green. There are differences between my environment and UAT,
    so it could be that my analysis is not correct and the fix won't fix UAT, but
    I won't find that out until the next release.
  prefs: []
  type: TYPE_NORMAL
- en: How that fix gets released into the UAT environment is another problem. Ideally,
    the full CI and packaging process is already set up for the 1.1 branch, so I just
    push my changes and a new MSI comes out that is ready to be deployed. In the worst
    case, the CI runs only from the master branch, so I need to set up a new job on
    the fix branch and try to configure that job to be the same as it was for the
    last 1.1 release.
  prefs: []
  type: TYPE_NORMAL
- en: If any part of the toolchain has moved on between 1.1 and 2.0, then it makes
    every step of the process more difficult, from configuring the local environment,
    running the app, analyzing the problem, and pushing the fix.
  prefs: []
  type: TYPE_NORMAL
- en: Bug fixing with Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The process is much simpler with Docker. To replicate the UAT environment locally,
    I just need to run containers from the same images that are running in UAT. There
    will be a Docker Compose or stack file describing the whole solution which is
    versioned, so by deploying version 1.1, I get the exact same environment as UAT
    without having to build from source.
  prefs: []
  type: TYPE_NORMAL
- en: I should be able to replicate the issue at this point and confirm whether it's
    a coding issue or something to do with data or the environment. If it's a configuration
    issue, then I should see the same problem as UAT, and I could test the fix with
    an updated Compose file. If it's a coding issue, then I need to dig into the code.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, I can clone the source from the version 1.1 tag and build the
    Docker images in debug mode, but I don't spend time doing that until I'm pretty
    sure this is a problem in the app. If I'm using multi-stage builds with all versions
    pinned in the Dockerfile, the local build will produce an identical image to the
    one running in UAT, but with the extra artifacts for debugging.
  prefs: []
  type: TYPE_NORMAL
- en: Now, I can find the problem, write a test, and fix the bug. When the new integration
    test passes, it's executing against the same Dockerized solution I'll be deploying
    in UAT, so I can be very confident that the bug is fixed.
  prefs: []
  type: TYPE_NORMAL
- en: If there's no CI configured for the 1.1 branch, then setting it up should be
    straightforward because the build task will just need to run the `docker image
    build` or `docker-compose build` commands. If I want fast feedback, I can even
    push the locally built image to the registry and deploy a new UAT environment
    to verify the fix while the CI setup is being configured. That new environment
    will just be a different stack on the test cluster, so I don't need to commission
    any more infrastructure for the deployment.
  prefs: []
  type: TYPE_NORMAL
- en: The workflow with Docker is much cleaner and faster, but more importantly, there
    is far less risk. When you replicate the issue locally, you are using the exact
    same application components running on the exact same platform as the UAT environment.
    When you test your fix, you know it will work in UAT because you'll be deploying
    the same new artifacts.
  prefs: []
  type: TYPE_NORMAL
- en: The time you invest in Dockerizing your application will be repaid many times
    over by the time saved in supporting multiple versions of the app.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter looked at troubleshooting applications running in containers, along
    with debugging and instrumentation. Docker is a new application platform, but
    applications in containers run as processes on the host, so they're still suitable
    targets for remote debugging and centralized monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: Support for Docker is available in all the current versions of Visual Studio.
    Visual Studio 2017 has the most complete support, covering Linux and Windows containers.
    Visual Studio 2015 and Visual Studio Code currently have extensions that provide
    debugging for Linux containers. You can easily add your own support for Windows
    containers, but the full debugging experience is still evolving.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, I also introduced Prometheus, a lightweight instrumentation
    and monitoring component that you can run in a Windows Docker container. Prometheus
    stores the metrics it extracts from applications running on other containers.
    The standardized nature of containers makes monitoring solutions such as these
    very simple to configure. I used Prometheus data to drive a dashboards in Grafana,
    running in a container, which is a simple and powerful way of presenting a consolidated
    view of the health of your application.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter is the final chapter of this book. I'll end by sharing some
    approaches to get started with Docker in your own domain, including case studies
    where I have used Docker on Windows for existing projects.
  prefs: []
  type: TYPE_NORMAL
