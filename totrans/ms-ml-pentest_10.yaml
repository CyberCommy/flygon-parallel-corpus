- en: Best Practices for Machine Learning and Feature Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we learned about the fundamentals of machine learning,
    and we learned how to build many different Python projects by using a suite of
    amazing open source Python libraries. Also, we dove into how to break machine
    learning models.
  prefs: []
  type: TYPE_NORMAL
- en: This last chapter will help you to build better models by illustrating many
    tips and best practices for different aspects of your projects.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following:'
  prefs: []
  type: TYPE_NORMAL
- en: An in-depth overview of feature engineering in machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The best practices for machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can find the code files for this chapter at [https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/tree/master/Chapter10](https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/tree/master/Chapter10).
  prefs: []
  type: TYPE_NORMAL
- en: Feature engineering in machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Through building and developing all of the projects and prototypes in this book,
    you have certainly noticed that feature engineering and feature selection are
    essential to every modern data science product, especially machine learning based
    projects. According to research, over 50% of the time spent building the model
    is occupied by cleaning, processing, and selecting the data required to train
    the model. It is your responsibility to design, represent, and select the features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most machine learning algorithms cannot work on raw data. They are not smart
    enough to do so. Thus, feature engineering is needed, to transform data in its
    raw status into data that can be understood and consumed by algorithms. Professor
    Andrew Ng once said:'
  prefs: []
  type: TYPE_NORMAL
- en: '"Coming up with features is difficult, time-consuming, requires expert knowledge.
    ''Applied machine learning'' is basically feature engineering."'
  prefs: []
  type: TYPE_NORMAL
- en: 'Feature engineering is a process in the data preparation phase, according to
    the cross-industry standard process for data mining:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00220.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The term **Feature Engineering** itself is not a formally defined term. It
    groups together all of the tasks for designing features to build intelligent systems.
    It plays an important role in the system. If you check data science competitions,
    I bet you have noticed that the competitors all use the same algorithms, but the
    winners perform the best feature engineering. If you want to enhance your data
    science and machine learning skills, I highly recommend that you visit and compete
    at [www.kaggle.com](http://www.kaggle.com):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00221.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: When searching for machine learning resources, you will face many different
    terminologies. To avoid any confusion, we need to distinguish between feature
    selection and feature engineering. Feature engineering transforms raw data into
    suitable features, while feature selection extracts necessary features from the
    engineered data. Featuring engineering is selecting the subset of all features,
    without including redundant or irrelevant features.
  prefs: []
  type: TYPE_NORMAL
- en: Feature selection algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To enable the algorithms to train faster, and to reduce the complexity and
    overfitting of the model, in addition to improving its accuracy, you can use many
    feature selection algorithms and techniques. We are going to look at three different
    feature selection methods: filter methods, wrapper methods, and embedded methods.
    Let''s discuss the various methodologies and techniques.'
  prefs: []
  type: TYPE_NORMAL
- en: Filter methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In filter methods, each feature will be assigned a score, computed by different
    statistical measures. In other words, these methods rank features by considering
    the relationships between the features and the targets. Filter methods are usually
    used in the pre-processing phase:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00222.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Pearson's correlation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Pearson''s correlation is a statistical method used to measure the linear correlation
    between two variables, `x` and `y`. It is ranged between `+1` and `-1` ; `+1`
    means that there is a positive association. You need to know that `x` and `y`
    should be continuous variables. The formula for Pearson''s correlation coefficient
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00223.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '*Cov* is the **covariance,** and `dx` and `dy` are the standard deviations
    of `x` and `y`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00224.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: To calculate this using Python, you can use `scipy.stats.pearsonr(x, y)`, from
    the `scipy` library.
  prefs: []
  type: TYPE_NORMAL
- en: Linear discriminant analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In previous chapters, especially in [Chapter 1](part0021.html#K0RQ0-49a67f1d6e7843d3b2296f38e3fe05f5),
    *Introduction to Machine Learning in Pen Testing*, we saw the statistical procedure
    of **principal component analysis** (**PCA**). **Linear discriminant analysis**
    (**LDA**) is a dimensionality reduction technique, as well. It is used to find
    a linear combination of features that separate classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00225.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'To use LDA with scikit-learn, import it with this line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Use it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Analysis of variance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Analysis of variance** (**ANOVA**) is like LDA, but it operates using categorical
    features to check whether the means of several classes are equal, by analyzing
    the differences between them.'
  prefs: []
  type: TYPE_NORMAL
- en: Chi-square
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Chi-square** is used to determine if a subset data matches a population.
    The values should be in categories. In other words, the chi-square test is used
    to check the correlations and associations between the different categories or
    classes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The formula for the chi-square test is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00226.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following is an example of chi-square using scikit-learn, delivered by
    Jason Brownlee, PhD:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The following diagram illustrates the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00227.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Wrapper methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Wrapper methods are performed by taking subsets and training learning algorithms.
    Based on the results of the training, we can select the best features for our
    model. And, as you may have guessed, these methods are computationally very expensive:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00228.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: There are many wrapper techniques, including those listed in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Forward selection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Forward selection uses searching as a technique for selecting the best features.
    It is an iterative method. In every iteration, we add more features to improve
    the model, until we no longer have any further improvements to make:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00229.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Backward elimination
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Backward elimination is like the previous method but, this time, we start with
    all of the features, and we eliminate some in every iteration until the model
    stops improving:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00230.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Recursive feature elimination
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can see that recursive feature elimination as a greedy optimization algorithm.
    This technique is performed by creating models with different subsets and computing
    the best performing feature, scoring them according to an elimination ranking.
  prefs: []
  type: TYPE_NORMAL
- en: 'This script is like the previous one, but it uses recursive feature elimination
    as a feature selection method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The following diagram illustrates the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00231.gif)'
  prefs: []
  type: TYPE_IMG
- en: Embedded methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The main goal of feature selection''s embedded method is learning which features
    are the best in contributing to the accuracy of the machine learning model. They
    have built-in penalization functions to reduce overfitting:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00232.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Some of the embedded techniques are listed in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Lasso linear regression L1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In statistics, Lasso is a regression analysis method. Lasso linear regression
    L1 simply adds a penalty equivalent to the absolute value of the magnitude of
    coefficients. The following is an implementation of the method in Python and sckit-learn:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00233.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Ridge regression L2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The ridge regression L2 method adds a penalty equivalent to the square of the
    magnitude of coefficients. In other words, it performs an L2 regularization.
  prefs: []
  type: TYPE_NORMAL
- en: Tree-based feature selection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The tree-based feature selection method is used to check and compute feature
    importance. The following is an example of how we can use the tree-based feature
    selection technique delivered by the official scikit-learn documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00234.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'As I said previously, feature selection is used in the pre-processing phase,
    so you can use scikit-learn to build a pipeline, as in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: A great book called *An Introduction to Variable and Feature Selection,* written
    by Isabelle Guyon and Andre Elisseeff, includes a checklist for better feature
    selection.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more about the full checklist, you can browse to [https://machinelearningmastery.com/an-introduction-to-feature-selection/](https://machinelearningmastery.com/an-introduction-to-feature-selection/).
  prefs: []
  type: TYPE_NORMAL
- en: Best practices for machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous sections, we saw how to perform feature engineering to enhance
    the performance of our machine learning system. Now, we are going to discuss some
    tips and best practices to build robust intelligent systems. Let's explore some
    of the best practices in the different aspects of machine learning projects.
  prefs: []
  type: TYPE_NORMAL
- en: Information security datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Data is a vital part of every machine learning model. To train models, we need
    to feed them datasets. While reading the earlier chapters, you will have noticed
    that to build an accurate and efficient machine learning model, you need a huge
    volume of data, even after cleaning data. Big companies with great amounts of
    available data use their internal datasets to build models, but small organizations,
    like startups, often struggle to acquire such a volume of data. International
    rules and regulations are making the mission harder because data privacy is an
    important aspect in information security. Every modern business must protect its
    users'' data. To solve this problem, many institutions and organizations are delivering
    publicly available datasets, so that others can download them and build their
    models for educational or commercial use. Some information security datasets are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Controller Area Network** (**CAN**) dataset for intrusion detection (OTIDS):
    [http://ocslab.hksecurity.net/Dataset/CAN-intrusion-dataset](http://ocslab.hksecurity.net/Dataset/CAN-intrusion-dataset)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The car-hacking dataset for intrusion detection: [http://ocslab.hksecurity.net/Datasets/CAN-intrusion-dataset](http://ocslab.hksecurity.net/Datasets/CAN-intrusion-dataset)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The web-hacking dataset for cyber criminal profiling: [http://ocslab.hksecurity.net/Datasets/web-hacking-profiling](http://ocslab.hksecurity.net/Datasets/web-hacking-profiling)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The **API-based malware detection system** (**APIMDS**) dataset: [http://ocslab.hksecurity.net/apimds-dataset](http://ocslab.hksecurity.net/apimds-dataset)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The intrusion detection evaluation dataset (CICIDS2017): [http://www.unb.ca/cic/datasets/ids-2017.html](http://www.unb.ca/cic/datasets/ids-2017.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Tor-nonTor dataset: [http://www.unb.ca/cic/datasets/tor.html](http://www.unb.ca/cic/datasets/tor.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Android adware and general malware dataset: [http://www.unb.ca/cic/datasets/android-adware.html](http://www.unb.ca/cic/datasets/android-adware.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Project Jupyter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Jupyter Notebook is an open source web application used to create and share
    coding documents. I highly recommend it, especially for novice data scientists,
    for many reasons. It will give you the ability to code and visualize output directly.
    It is great for discovering and playing with data; exploring data is an important
    step to building machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Jupyter''s official website is [http://jupyter.org/](http://jupyter.org/):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00235.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'To install it using `pip`, simply type the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Speed up training with GPUs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you know, even with good feature engineering, training in machine learning
    is computationally expensive. The quickest way to train learning algorithms is
    to use **graphics processing units** (**GPUs**). Generally, though not in all
    cases, using GPUs is a wise decision for training models. In order to overcome
    CPU performance bottlenecks, the gather/scatter GPU architecture is best, performing
    parallel operations to speed up computing.
  prefs: []
  type: TYPE_NORMAL
- en: 'TensorFlow supports the use of GPUs to train machine learning models. Hence,
    the devices are represented as strings; following is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'To use a GPU device in TensorFlow, you can add the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'You can use a single GPU or multiple GPUs. Don''t forget to install the CUDA
    toolkit, by using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Install cuDNN as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Selecting models and learning curves
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To improve the performance of machine learning models, there are many hyper
    parameters to adjust. The more data that is used, the more errors that can happen.
    To work on these parameters, there is a method called `GridSearchCV`. It performs
    searches on predefined parameter values, through iterations. `GridSearchCV` uses
    the `score()` function, by default. To use it in scikit-learn, import it by using
    this line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Learning curves are used to understand the performance of a machine learning
    model. To use a learning curve in scikit-learn, import it to your Python project,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Machine learning architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the real world, data scientists do not find data to be as clean as the publicly
    available datasets. Real world data is stored by different means, and the data
    itself is shaped in different categories. Thus, machine learning practitioners
    need to build their own systems and pipelines to achieve their goals and train
    the models. A typical machine learning project respects the following architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00236.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Coding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Good coding skills are very important to data science and machine learning.
    In addition to using effective linear algebra, statistics, and mathematics, data
    scientists should learn how to code properly. As a data scientist, you can choose
    from many programming languages, like Python, R, Java, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Respecting coding''s best practices is very helpful and highly recommended.
    Writing elegant, clean, and understandable code can be done through these tips:'
  prefs: []
  type: TYPE_NORMAL
- en: Comments are very important to understandable code. So, don't forget to comment
    your code, all of the time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choose the right names for variables, functions, methods, packages, and modules.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use four spaces per indentation level.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Structure your repository properly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Follow common style guidelines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you use Python, you can follow this great aphorism, called the *The Zen
    of Python,* written by the legend, Tim Peters:'
  prefs: []
  type: TYPE_NORMAL
- en: '"Beautiful is better than ugly.'
  prefs: []
  type: TYPE_NORMAL
- en: Explicit is better than implicit.
  prefs: []
  type: TYPE_NORMAL
- en: Simple is better than complex.
  prefs: []
  type: TYPE_NORMAL
- en: Complex is better than complicated.
  prefs: []
  type: TYPE_NORMAL
- en: Flat is better than nested.
  prefs: []
  type: TYPE_NORMAL
- en: Sparse is better than dense.
  prefs: []
  type: TYPE_NORMAL
- en: Readability counts.
  prefs: []
  type: TYPE_NORMAL
- en: Special cases aren't special enough to break the rules.
  prefs: []
  type: TYPE_NORMAL
- en: Although practicality beats purity.
  prefs: []
  type: TYPE_NORMAL
- en: Errors should never pass silently.
  prefs: []
  type: TYPE_NORMAL
- en: Unless explicitly silenced.
  prefs: []
  type: TYPE_NORMAL
- en: In the face of ambiguity, refuse the temptation to guess.
  prefs: []
  type: TYPE_NORMAL
- en: There should be one-- and preferably only one --obvious way to do it.
  prefs: []
  type: TYPE_NORMAL
- en: Although that way may not be obvious at first unless you're Dutch.
  prefs: []
  type: TYPE_NORMAL
- en: Now is better than never.
  prefs: []
  type: TYPE_NORMAL
- en: Although never is often better than *right* now.
  prefs: []
  type: TYPE_NORMAL
- en: If the implementation is hard to explain, it's a bad idea.
  prefs: []
  type: TYPE_NORMAL
- en: If the implementation is easy to explain, it may be a good idea.
  prefs: []
  type: TYPE_NORMAL
- en: Namespaces are one honking great idea -- let's do more of those!"
  prefs: []
  type: TYPE_NORMAL
- en: Data handling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Good data handling leads to successfully building machine learning projects.
    After loading a dataset, please make sure that all of the data has loaded properly,
    and that the reading process is performing correctly. After performing any operation
    on the dataset, check over the resulting dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Business contexts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An intelligent system is highly connected to business aspects because, after
    all, you are using data science and machine learning to solve a business issue
    or to build a commercial product, or for getting useful insights from the data
    that is acquired, to make good decisions. Identifying the right problems and asking
    the right questions are important when building your machine learning model, in
    order to solve business issues.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book was a practical guide for learning how to build machine learning projects
    to defend against cyber threats and malicious activities, using open source libraries,
    Python, and a set of open source projects. We didn't stop there; we also showed
    you how to attack those models using adversarial machine learning. Through that,
    you acquired a set of skills to analyze data, build defensive systems, and break
    next-generation safeguards. We finished the book by discussing many points to
    help you build better models.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is the difference between feature engineering and feature selection?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between principal component analysis (PCA) and feature
    selection?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can we encode features like dates and hours?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why it is useful to print out training and testing accuracy?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can we deploy a machine learning model and use it in a product?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why does feature engineering take much more time than other steps?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the role of a dummy variable?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Papers and slides**:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Feature Engineering* - *Knowledge Discovery and Data Mining 1*, by Roman Kern:
    [http://kti.tugraz.at/staff/denis/courses/kddm1/featureengineering.pdf](http://kti.tugraz.at/staff/denis/courses/kddm1/featureengineering.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Feature Engineering and Selection* ([https://people.eecs.berkeley.edu/~jordan/courses/294-fall09/lectures/feature/slides.pdf](https://people.eecs.berkeley.edu/~jordan/courses/294-fall09/lectures/feature/slides.pdf))
    - *CS 294: Practical Machine Learning,* Berkeley: [https://people.eecs.berkeley.edu/~jordan/courses/294-fall09/lectures/feature/](https://people.eecs.berkeley.edu/~jordan/courses/294-fall09/lectures/feature/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Feature Engineering* by Leon Bottou, Princeton: [http://www.cs.princeton.edu/courses/archive/spring10/cos424/slides/18-feat.pdf](http://www.cs.princeton.edu/courses/archive/spring10/cos424/slides/18-feat.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Blog posts**:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Discover Feature Engineering - How to Engineer Features and How to Get Good
    at It:* [https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/](https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Machine Learning Mastery*: [https://machinelearningmastery.com/start-here/](https://machinelearningmastery.com/start-here/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Books**:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Feature Extraction, Construction, and Selection: A Data Mining Perspective*:
    [https://www.amazon.com/dp/0792381963?tag=inspiredalgor-20](https://www.amazon.com/dp/0792381963?tag=inspiredalgor-20)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Feature Extraction: Foundations and Applications*: [https://www.amazon.com/dp/3540354875?tag=inspiredalgor-20](https://www.amazon.com/dp/3540354875?tag=inspiredalgor-20)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Feature Extraction and Image Processing for Computer Vision, Third Edition:*
    [https://www.amazon.com/dp/0123965497?tag=inspiredalgor-20](https://www.amazon.com/dp/0123965497?tag=inspiredalgor-20)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
