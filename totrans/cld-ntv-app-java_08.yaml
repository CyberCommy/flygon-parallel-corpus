- en: Cloud-Native Application Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most unique things about cloud-native applications is their deployment.
    In traditional application deployment, teams deploy their applications by logging
    on to a server and installing the application. But in the cloud there are usually
    many servers, and logging into each one and installing the application manually
    is not feasible and can be very error prone. To combat these problems, we use
    cloud provisioning tools to automate the deployment of cloud-native applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will dive into the deployment model for the microservice—including
    how to package your application as a Docker container, how to set up the CI/CD
    pipeline, and how to protect your service from security attacks such as a **distributed
    denial of service** (**DDoS**). We will cover the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Deployment models, packaging, and containerization (using Docker)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment patterns (blue-green, canary release, and dark release)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DDoS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CI/CD
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will cover the deployment models that will be used to deploy our application
    in the cloud environment.
  prefs: []
  type: TYPE_NORMAL
- en: Virtualization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The fundamental building block of the cloud is a virtual machine (referred
    to as VM from now on), which is equivalent to a physical server (or host) on which
    users can log in and install or maintain applications. The difference being that
    there can be several VMs hosted on a single host thereby increasing the resource
    utilization. This is achieved by using virtualization, where a hypervisor is installed
    on the host that can then apportion the resources available on the physical server,
    such as compute, memory, storage, and networking to the different VMs hosted on
    it. Cloud-native applications can be deployed on such VMs using the following
    strategies:'
  prefs: []
  type: TYPE_NORMAL
- en: Several applications per VM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One application per VM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When running several applications per VM there is the possibility of one application
    hogging all the resources available on the VM and starving out the other applications.
    On the other hand, running a single application per VM ensures that the applications
    are isolated so that they are not affecting each other, but the down side of such
    a deployment is the waste of resources, as each application might not always be
    consuming all the resources that are available to it.
  prefs: []
  type: TYPE_NORMAL
- en: PaaS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PaaS or Platform as a Service is another popular option for deploying cloud-native
    applications. PaaS offers additional services that complement the development,
    scaling, and maintenance of cloud-native applications. Services such as automated
    builds and deployments through buildpacks greatly minimize the time spent in setting
    up additional infrastructure to support these activities. PaaS also provides some
    basic infrastructure services such as monitoring, log aggregation, secrets management,
    and load balancing out-of-the-box. Cloud Foundry, Google App Engine, Heroku, and
    OpenShift are some examples of  PaaS.
  prefs: []
  type: TYPE_NORMAL
- en: Containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The efforts made to provide the level of isolation required for independent
    operation, while also conserving resource utilization, has resulted in the development
    of container technology. By leveraging features of the Linux kernel, containers
    provide CPU, memory, storage, and network isolation at a process level. The following
    figure demonstrates the difference between virtualizations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8c53dec6-cf46-4c95-be5b-36c11e62e444.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Containers eliminate the need for the guest operating system, thereby greatly
    increasing the number of containers that can be run versus the number of VMs on
    the same host. Containers also have a smaller footprint, in the order of MBs,
    whereas VMs can easily exceed several GBs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Containers are also very resource efficient in terms of the amount of CPU and
    memory required, as they do not have to support the many peripheral systems that
    have to be supported when running a fully fledged operating system:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/48a52590-2ddf-490d-b0fd-2d9b256d9448.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The previous diagram shows the evolution of cloud-native application deployment
    strategies with the aim of increasing the resource utilization and isolation of
    the applications. At the top of the stack are running containers within VMs running
    on a host. This allows the applications to scale by two degrees:'
  prefs: []
  type: TYPE_NORMAL
- en: Increasing the number of containers within a VM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increasing the number of VMs running containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker is a container runtime that has gained popularity, and has proved itself
    to be a robust platform for deploying cloud-native applications. Docker is available
    on all major platforms, such as Windows, Mac, and Linux. Since containers require
    the Linux kernel, it is easier to run the Docker engine in a Linux environment.
    But, there are several resources available to run Docker containers comfortably
    in both Windows and Mac environments. We will be demonstrating how to deploy the
    services that we have been developing so far as Docker containers, including connecting
    to an external database running in its own container.
  prefs: []
  type: TYPE_NORMAL
- en: In our examples, we will be using Docker Toolbox and using Docker Machine to
    create a VM, within which the Docker engine will be running. We will connect to
    this engine using the Docker command-line client and use the various commands
    provided.
  prefs: []
  type: TYPE_NORMAL
- en: Building Docker images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will begin to containerize our current projects as a set of Docker containers.
    We will go through the steps for each of the projects.
  prefs: []
  type: TYPE_NORMAL
- en: Eureka server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Add a `.dockerignore` file with the following contents in `$WORKSPACE/eureka-server/.dockerignore`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Add a Dockerfile with the following contents in `$WORKSPACE/eureka-server/Dockerfile`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Build the runnable JAR, which will be available in the target folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Build the Docker container:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding command is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/42200017-a61d-439d-b4dc-428fa2f4682a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Before running the container, we need to create a network on which the different
    containers can communicate freely with each other. This can be created by running
    the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding command is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9e39ed0d-67a3-4a5e-9b93-9b5d9bbe7c21.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Run the container with the name `eureka` and attach it to the network created
    earlier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding command is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/82772713-3df6-42a4-974e-5bd487f590b5.png)'
  prefs: []
  type: TYPE_IMG
- en: Product API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next we work on the product API project:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a new Spring profile, `docker` in the `application.yml` by appending the
    following contents to the existing file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Build the Spring Boot JAR to reflect changes to `application.yml`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Add a `.dockerignore` file with the following contents:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Add a Dockerfile with the following contents:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Build the Docker container:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding command is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1936e083-c0fd-458d-bf95-2182c3abbe95.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Start several Docker containers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding commands is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a3cc2622-9d4b-405e-98cb-d34ef758054c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The product API will be available at the following URLs:'
  prefs: []
  type: TYPE_NORMAL
- en: '`http://<docker-host>:8011/product/1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`http://<docker-host>:8012/product/1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connecting to an external Postgres container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To connect the `product` API to an external database instead of an in-memory
    database, first create a container image with the data already populated in it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a file, `import-postgres.sql`, with the following contents:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `Dockerfile.postgres` with the following contents:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now build the Postgres container image which will have the database initialized
    with the contents of `import-postgres.sql`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding command is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0f5dd173-6cab-407f-b09f-fe8ea3dcd8c3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Add a new Spring profile, `postgres` to the `application.yml` by appending
    the following contents to the existing file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Ensure that you replace `<docker-host>` with the value appropriate for your
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Build the Spring Boot JAR to reflect changes to `application.yml`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Build the Docker container:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding command is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1089a595-eaec-4cd2-a7e2-f88448bee18d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If you already have containers running off the old image you can stop and remove
    them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Start the database container:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding command is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c281d1ed-3aae-4f73-ae03-1ffdc9694a6e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Start several Docker containers for the product API:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding command is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c1ba1fe6-d65b-48e3-a52d-493e594b36bf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The product API will be available at the following URLs:'
  prefs: []
  type: TYPE_NORMAL
- en: '`http://<docker-host>:8011/product/1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`http://<docker-host>:8012/product/1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having covered the packaging and deployment models of cloud-native applications,
    we will now cover the patterns used for deploying cloud-native applications. Traditionally,
    applications get deployed in several environments such as development, testing,
    staging, pre-production, and so on, and each of these environments might be a
    scaled-down version of the final production environment. Applications move through
    a series of pre-production environments and get deployed finally to the production
    environment. However, one significant difference is that while downtime is tolerated
    in all other environments, downtime in a production deployment could lead to serious
    business consequences.
  prefs: []
  type: TYPE_NORMAL
- en: With cloud-native applications, it is possible to release software with zero
    downtime. This is achieved by the rigorous application of automation to every
    aspect of the development, testing, and deployment of the application. We will
    cover **continuous integration** (**CI**) / **continuous deployment** (**CD**)
    in a later section, but here we will cover some patterns that enable rapid deployment
    of applications. All of these patterns rely on the presence of a router component,
    which not unlike a load balancer can route requests to a certain set of application
    instances. In some cases, the application itself is built with features that are
    hidden behind feature flags, which can be enabled through changes to the application
    configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Blue-green deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Blue-green deployment is a pattern that happens over three stages. The initial
    state of the deployment is depicted in the following figure. All the traffic to
    the application is routed to the existing instances, which are treated as the
    blue instances. A representation of blue-green deployment is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f7c9ea7f-4822-4601-b318-9d079e137d2f.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the first stage of blue-green deployment, a new set of instances with the
    new release of the application are provisioned and become available. At this stage,
    the new green application instance is not available to the end users and the deployment
    is verified internally. This is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3337e8ca-4e65-4196-b35b-125c16a298c0.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the next stage of the deployment, a figurative switch is thrown on the router,
    which now starts routing all the requests to the green instances instead of the
    old blue instances. The old blue instances are kept around for a period of observation
    and if any critical issues are detected we can quickly rollback the deployment
    to the older instance of the application if required:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/180fc891-da2a-4ec2-8bb1-ca2ac06e6c4f.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the last stage of the deployment, the older blue instances of the application
    are decommissioned and the green instance becomes the next stable production release:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/21619477-0763-44a9-83d3-f945bb33dd27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Blue-green deployments are effective when switching between two stable releases
    of an application and quick recovery is ensured by the availability of a fallback
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: Canary deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Canary deployment is also a variation of the blue-green deployment. Canary
    deployment addresses the wasted resources that are provisioned when running two
    production instances simultaneously, albeit for a short duration. In canary deployments,
    the green environment is a scaled-down version of the blue environment and is
    relying on the capability of the router to consistently route a small percentage
    of the requests to the new green environment, while the bulk of the requests are
    routed to the blue environment. The following figure depicts this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/76b22168-fae1-4ec4-a902-9b3f0cc10699.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'This is particularly useful when releasing new features of an application that
    need to be tested with a few beta test users, and then based on the feedback of
    this user group rolled out to all users. Once it is ascertained that the green
    environment is ready for full rollout, instances in the green environment are
    ramped up while simultaneously, instances from the blue environment are ramped
    down. It is best illustrated by the following sequence of diagrams:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b668e3dc-825b-46c1-b9ed-85e2d32535f6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This way the problem of having to run two production level environments is avoided,
    and there is a smooth transition from one version to the other while also providing
    an easy fallback to the old version.
  prefs: []
  type: TYPE_NORMAL
- en: Dark release
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another popular deployment pattern that is utilized for deploying cloud-native
    applications is the dark release pattern. Here, new features are hidden behind
    feature flags and are enabled for a select group of users, or in some cases the
    users are totally unaware of the feature while the application mimics the users'
    behavior and exercises the hidden features of the application. Once the feature
    is deemed ready and stable for rollout to all users then it is enabled by toggling
    the feature flags.
  prefs: []
  type: TYPE_NORMAL
- en: Applying CI/CD to automate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the central aspects of cloud-native application deployment relies on
    the ability to effectively automate and build a software delivery pipeline. This
    is primarily accomplished by using CI/CD tools that can take the source code from
    the source repositories, run tests, build a deployable artifact, and deploy them
    to the target environments. Most modern CI/CD tools, such as Jenkins, provide
    support for configuring build pipelines that can be used to build several artifacts
    based on a configuration file in the form of a script.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will take the example of a Jenkins pipeline script to demonstrate how a
    simple build pipeline can be configured. In our example, we will simply build
    two artifacts, namely the `eureka-server` and the `product-api` runnable JARs.
    Add a new file named `Jenkinsfile` with the following contents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The pipeline script does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Checks out the source code from GitHub
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configures the Maven tool
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Builds two artifacts by running the Maven build within two directories of the
    checked-out source repository
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Stores the test results and the resultant JARs from the build
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a new pipeline job in Jenkins:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/56901c5c-41af-48b3-b314-6315c6e06ff0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the pipeline configuration, specify the GitHub repository and the path to
    the `Jenkinsfile` in that Git repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f9c530a7-f018-4e4e-ac6a-8a4f1e0d0f25.png)'
  prefs: []
  type: TYPE_IMG
- en: 'On running the build, it should result in the building of two artifacts:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ecbf5ebc-5677-4959-9b5f-6d59d4cfedc0.png)'
  prefs: []
  type: TYPE_IMG
- en: The pipeline script can be extended to build the Docker containers that we built
    by hand earlier in the chapter using the Docker plugin for Jenkins.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about the various deployment patterns that can be
    used for deploying cloud-native applications, and how continuous integration tools
    such as Jenkins can be used to automate the build and deployment. We also learned
    how to build and run a sample cloud-native application using Docker containers.
  prefs: []
  type: TYPE_NORMAL
