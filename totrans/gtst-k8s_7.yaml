- en: Chapter 7. OCI, CNCF, CoreOS, and Tectonic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first half of this chapter will cover how open standards encourage a diverse
    ecosystem of container implementations. We'll look at the Open Container Initiative
    and its mission to provide an open container specification as well. The second
    half of this chapter will cover CoreOS and its advantages as a host OS, including
    performance and support for various container implementations. Also, we'll take
    a brief look at the Tectonic enterprise offering from CoreOS.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will discuss the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Why standards matter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Open Container Initiative and Cloud Native Computing Foundation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container specifications versus implementations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CoreOS and its advantages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tectonic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The importance of standards
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the past two years, containerization technology has had a tremendous growth
    in popularity. While Docker has been at the center of this ecosystem, there is
    an increased number of players in the container space. There is already a number
    of alternatives to the containerization and Docker implementation itself (**rkt**,
    **Garden**, **LXD**, and so on). In addition, there is a rich ecosystem of third-party
    tools that enhance and compliment your container infrastructure. Kubernetes lands
    squarely on the orchestration side of this ecosystem, but the bottom line is that
    all these tools form the basis to build cloud native applications.
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned in the very beginning of the book, one of the most attractive
    things about containers is their ability to package our application for deployment
    across various environments (that is, development, testing, production) and various
    infrastructure providers (GCP, AWS, On-Premise, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: To truly support this type of deployment agility, we need not only the container
    themselves to have a common platform, but also the underlying specifications to
    follow a common set of ground rules. This will allow for implementations that
    are both flexible and highly specialized. For example, some workloads may need
    to be run on a highly secure implementation. To provide this, the implementation
    will have to make more intentional decisions about some aspects of implementation.
    In either case, we will have more agility and freedom if our containers are built
    on some common structures that all implementations agree on and support.
  prefs: []
  type: TYPE_NORMAL
- en: Open Container Initiative
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the first initiatives to gain widespread industry engagement is the **Open
    Container Initiative** (**OCI**). Among the industry collaborators are Docker,
    Red Hat, VMware, IBM, Google, AWS, and many more listed on the OCI website, that
    is, [https://www.opencontainers.org/](https://www.opencontainers.org/).
  prefs: []
  type: TYPE_NORMAL
- en: 'The purpose of the OCI is to split implementations, such as Docker and Rocket,
    from a standard specification for the format and runtime of containerized workloads.
    By their own terms, the goal of the OCI specification has three tenets¹:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Creating a formal specification for container image formats and runtime, which
    will allow a compliant container to be portable across all major, compliant operating
    systems and platforms without artificial technical barriers.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '>'
  prefs: []
  type: TYPE_NORMAL
- en: '*Accepting, maintaining and advancing the projects associated with these standards
    (the "Projects"). It will look to agree on a standard set of container actions
    (start, exec, pause,….) as well as runtime environment associated with container
    runtime.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '>'
  prefs: []
  type: TYPE_NORMAL
- en: '*Harmonizing the above-referenced standard with other proposed standards, including
    the appc specification*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Cloud Native Computing Foundation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A second initiative that also has a widespread industry acceptance is the **Cloud
    Native Computing Foundation** (**CNCF**). While still focused on containerized
    workloads, the CNCF operates a bit higher up the stack at an application design
    level. The purpose is to provide a standard set of tools and technologies to build,
    operate, and orchestrate cloud native application stacks. Cloud has given us access
    to a variety of new technologies and practices that can improve and evolve our
    classic software designs. This is also particularly focused at the new paradigm
    of microservice-oriented development.
  prefs: []
  type: TYPE_NORMAL
- en: As a founding participant in CNCF, Google has donated the Kubernetes open source
    project as the first step. The goal will be to increase interoperability in the
    ecosystem and support better integration with projects, starting off with Mesos.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For more information on CNCF refer: [https://cncf.io/](https://cncf.io/)'
  prefs: []
  type: TYPE_NORMAL
- en: Standard container specification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A core result of the OCI effort is the creation and development of the overarching
    container specification. The specification has five core principles for all containers
    to follow, which I will briefly paraphrase²:'
  prefs: []
  type: TYPE_NORMAL
- en: It must have **standard operations** to create, start, and stop containers across
    all implementations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It must be **content-agnostic**, which means that type of application inside
    the container does not alter the standard operation or publishing of the container
    itself.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The container must be **infrastructure-agnostic** as well. Portability is paramount;
    therefore, the containers must be able to operate just as easily in GCE as in
    your company data center or on a developer's laptop.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A container must also be **designed for automation**, which allows us to automate
    across the build, updating, and deployment pipelines. While this rule is a bit
    vague, the container implementation should not require onerous manual steps for
    creation and release.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, the implementation must support **industrial-grade delivery**. Once
    again, speaking to the build and deployment pipelines and requiring a streamlined
    efficiency to the portability and transit of the containers between infrastructure
    and deployment tiers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The specification also defines core principles for container formats and runtimes.
    You can read more about the specifications on the GitHub project at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/opencontainers/specs](https://github.com/opencontainers/specs)'
  prefs: []
  type: TYPE_NORMAL
- en: While the core specification can be a bit abstract, the **runC** implementation
    is a concrete example of the OCI specs in the form of a container runtime and
    image format. Also, you can read more of the technical details on GitHub at [https://github.com/opencontainers/runc](https://github.com/opencontainers/runc).
  prefs: []
  type: TYPE_NORMAL
- en: runC is the backing format and runtime for a variety of popular container tools.
    It was donated to OCI by Docker and was created from the same plumbing work used
    in the Docker platform. Since its release, it has had a welcome uptake by numerous
    projects.
  prefs: []
  type: TYPE_NORMAL
- en: Even the popular Open Source PaaS, **Cloud Founrdy** announced that it will
    use runC in Garden. Garden provides the containerization plumbing for Deigo, which
    acts as an orchestration layer similar to Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: rkt was originally based on the **appc** specification. appc was actually an
    earlier attempt by the folks at CoreOS to form a common specification around containerization.
    Now that CoreOS is participating in OCI, they are working to help merge the appc
    specification into OCI; it should result in a higher level of compatibility across
    the container ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: CoreOS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While the specifications provide us a common ground, there are also some trends
    evolving around the choice of OS for our containers. There are several tailor-fit
    OSes that are being developed specifically to run container workloads. Although
    implementations vary, they all have similar characteristics. Focus on a slim installation
    base, atomic OS updating, and signed applications for efficient and secure operations.
  prefs: []
  type: TYPE_NORMAL
- en: One OS that is gaining popularity is CoreOS. **CoreOS** offers major benefits
    for both security and resource utilization. It provides the later by removing
    package dependencies completely from picture. Instead, CoreOS runs all applications
    and services in containers. By providing only a small set of services required
    to support running containers and bypassing the need for hypervisor usage, CoreOS
    lets us use a larger portion of the resource pool to run our containerized applications.
    This allows users to gain higher performance from their infrastructure and better
    container to node (server) usage ratios.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**More container OSes**'
  prefs: []
  type: TYPE_NORMAL
- en: There are several other container-optimized OSes that have emerged recently.
  prefs: []
  type: TYPE_NORMAL
- en: '**Red Hat Enterprise Linux Atomic Host** focuses on security with **SELinux**
    enabled by default and "Atomic" updates to the OS similar to what we saw with
    CoreOS. Refer to the following link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://access.redhat.com/articles/rhel-atomic-getting-started](https://access.redhat.com/articles/rhel-atomic-getting-started)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ubuntu Snappy** also capitalizes on the efficiency and security gains of
    separating the OS components from the frameworks and applications. Using application
    images and verification signatures, we get an efficient Ubuntu-based OS for our
    container workloads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://www.ubuntu.com/cloud/tools/snappy](http://www.ubuntu.com/cloud/tools/snappy)'
  prefs: []
  type: TYPE_NORMAL
- en: '**VMware Photon** is another lightweight container OS that is optimized specifically
    for **vSphere** and the VMware platform. It runs Docker, rkt, and Garden and also
    has some experimental versions you can run on the popular public cloud offerings.
    Refer to the following link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://vmware.github.io/photon/](https://vmware.github.io/photon/)'
  prefs: []
  type: TYPE_NORMAL
- en: Using the isolated nature of containers, we increase reliability and decrease
    the complexity of updates for each application. Now applications can be updated
    along with supporting libraries whenever a new container release is ready.
  prefs: []
  type: TYPE_NORMAL
- en: '![CoreOS](../images/00075.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1\. CoreOS updates
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, CoreOS has some added advantages in the realm of security. For starters,
    the OS can be updated as one whole unit instead of by individual packages (refer
    to Figure 7.1). This avoids many issues that arise from partial updates. To achieve
    this, CoreOS uses two partitions: one as the active OS partition and a secondary
    to receive a full update. Once updates are completed successfully, a reboot promotes
    the secondary partition. If anything goes wrong, the original partition is available
    for fail back.'
  prefs: []
  type: TYPE_NORMAL
- en: The system owners can also control when those updates are applied. This gives
    us the flexibility to prioritize critical updates while working with real-world
    scheduling for the more common updates. In addition, the entire update is signed
    and transmitted via SSL for added security across the entire process.
  prefs: []
  type: TYPE_NORMAL
- en: rkt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A central piece of the CoreOS ecosystem is its own container runtime, named
    rkt. As we mentioned earlier, rkt is another implementation with a specific focus
    on security. rkt's main advantage is in running the engine without a daemon as
    root the way Docker does today. Initially, rkt also had an advantage in establishing
    trust for container images. However, recent updates to Docker have made great
    strides with the new **Content Trust** feature.
  prefs: []
  type: TYPE_NORMAL
- en: The bottom line is that rkt is still an implementation focused on security to
    run containers in production. rkt does use an image format named **ACI**, but
    it also supports running Docker-based images. At the time of writing this book,
    it is only at version 0.11.0, but it's already gaining momentum as a way to run
    Docker images securely in production.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, CoreOS recently announced integration with the **Intel® Virtualization
    Technology**, which allows containers to run in higher levels of isolation. This
    hardware-enhanced security allows the containers to be run inside a **Kernel-based
    Virtual Machine** (**KVM**) process providing isolation from the kernel similar
    to what we see with hypervisors today.
  prefs: []
  type: TYPE_NORMAL
- en: etcd
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another central piece in the CoreOS ecosystem worth mentioning is their open
    source etcd project. etcd is a distributed and consistent key-value store. A RESTful
    API is used to interface with etcd, so it's easy to integrate with your project.
  prefs: []
  type: TYPE_NORMAL
- en: If it sounds familiar, it's because we saw this process running in [Chapter
    1](part0015_split_000.html#E9OE1-22fbdd9ef660435ca6bcc0309f05b1b7 "Chapter 1. Kubernetes
    and Container Operations"), *Kubernetes and Container Operations*, under the *Services
    running on the master* section. Kubernetes actually utilizes etcd to keep track
    of cluster configuration and current state. K8s uses it for the service discovery
    capabilities as well.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes with CoreOS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we understand the benefits, let's take a look at a Kubernetes cluster
    using CoreOS. The documentation supports a number of platforms, but one of the
    easiest to spin up is AWS with the CoreOS **CloudFormation** and CLI scripts.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you are interested in running Kubernetes with CoreOS on other platforms,
    you can find more details in the CoreOS documentation here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://coreos.com/kubernetes/docs/latest/](https://coreos.com/kubernetes/docs/latest/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can find the latest scripts for AWS here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/coreos/coreos-kubernetes/releases/latest](https://github.com/coreos/coreos-kubernetes/releases/latest)'
  prefs: []
  type: TYPE_NORMAL
- en: For this walk-through, we will use v0.1.0 (latest at the time of writing) of
    the scripts. We'll need a Linux machine with the AWS CLI installed and configured.
    See the *Working with other providers* section of [Chapter 1](part0015_split_000.html#E9OE1-22fbdd9ef660435ca6bcc0309f05b1b7
    "Chapter 1. Kubernetes and Container Operations"), *Kubernetes and Container Operations*,
    for details on installing and configuring the AWS CLI. I recommend that you use
    a box with the Kubernetes control scripts already installed to avoid having to
    download `kubectl` separately.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s first download and extract the **tarball** from GitHub as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This will extract a single executable named `kube-aws`. This file will launch
    the AWS infrastructure in the same way that `kube-up.sh` did for us earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Before we proceed, we need to create a key-pair to use on AWS. For this example,
    I create one key-pair named `kube-aws-key`. We can create a key in the console
    under the EC2 service on the left-hand menu and then select **Key Pairs**. Keys
    can also be created using the CLI.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will need to create a cluster definition file. In the same folder,
    we downloaded `kube-aws`; create a new file from the listing 7-1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-1*: `coreos-cluster.yaml`'
  prefs: []
  type: TYPE_NORMAL
- en: We have a few things to note. We have `keyName` set to the key we just created,
    `kube-aws-key`. The region is set to `us-east-1` (Northern Virginia), so edit
    this if you prefer a different region. In addition, `clustername` and `workerCount`
    are commented out, but their defaults are as listed, `kubernetes` and `1`, respectively.
    `workerCount` defines the number of slaves, so you can increase this value if
    you need more.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, we have a placeholder DNS entry. The value for `externalDNSName`
    is set to `kube-aws`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For simplicity's sake, we can simply add an entry for `kube-aws` in the `/etc/hosts`
    file. For a production system, we would want a real entry that we could expose
    through Route 53, another DNS registrar, or a local DNS entry.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can spin up the CoreOS cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We should get the master IP in the console output under controller IP. We will
    need to update the IP address for `kube-aws` in our `/etc/hosts` file or DNS provider.
    We can also get the master IP by checking our running instances in AWS. It should
    be labeled `kube-aws-controller`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: There you have it! We now have a cluster running CoreOS. The script creates
    all the necessary AWS resources, such as **Virtual Private Clouds** (**VPCs**),
    security groups, and IAM role.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Note that if this is a fresh box, you will need to download `kubectl` separately
    as it is not bundled with `kube-aws`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now use `kubectl` to see our new cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We should see a single node listed with the EC2 internal DNS as the name. Note
    `kubeconfig`, this tells Kubernetes to use the configuration file for the cluster
    we just created instead of the previous GCE cluster we have been working thus
    far. This is useful if we want to manage multiple clusters from the same machine.
  prefs: []
  type: TYPE_NORMAL
- en: Tectonic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Running Kubernetes on CoreOS is a great start, but you may find that you want
    a higher level of support. Enter **Tectonic**, the CoreOS enterprise offering
    for running Kubernetes with CoreOS. Tectonic uses many of the components we've
    already discussed. CoreOS is the OS and both Docker and rkt runtimes are supported.
    In addition, Kubernetes, etcd, and flannel are packaged together to give a full
    stack of cluster orchestration. We discussed flannel briefly in [Chapter 3](part0028_split_000.html#QMFO2-22fbdd9ef660435ca6bcc0309f05b1b7
    "Chapter 3. Core Concepts – Networking, Storage, and Advanced Services"), *Core
    Concepts – Networking, Storage, and Advanced Services*. It is an overlay network
    that uses a model similar to the native Kubernetes model, and it uses etcd as
    a backend.
  prefs: []
  type: TYPE_NORMAL
- en: Offering a support package similar to Red Hat, CoreOS are also providing 24x7
    support for the open source software that Tectonic is built on. Tectonic also
    provides regular cluster updates and a nice dashboard with views for all the components
    of Kubernetes. **CoreUpdate** allows users to have more control of the automatic
    updates. In addition, it ships with **Tectonic Identity** for SSO across the cluster
    and the **Quay Enterprise**, which provides a secure container registry behind
    your own firewall.
  prefs: []
  type: TYPE_NORMAL
- en: Dashboard highlights
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are some highlights of the Tectonic dashboard:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Dashboard highlights](../images/00076.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2\. The Tectonic main dashboard
  prefs: []
  type: TYPE_NORMAL
- en: 'Tectonic is now generally available and the dashboard already has some nice
    features. As you can see in Figure 7.3, we can see a lot of detail about our replication
    controller and can even use the GUI to scale up and down with the click of a button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Dashboard highlights](../images/00077.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.3\. Tectonic replication controller detail
  prefs: []
  type: TYPE_NORMAL
- en: Another nice feature is the **Streaming events** page. Here, we can watch the
    events live, pause, and filter based on event severity and resource type.
  prefs: []
  type: TYPE_NORMAL
- en: '![Dashboard highlights](../images/00078.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.4\. Events stream
  prefs: []
  type: TYPE_NORMAL
- en: A useful feature to browse anywhere in the dashboard system is the namespace
    filtering option. Simply click on the gear in the top-right corner of the page,
    and we can filter our views by namespace. This can be helpful if we want to filter
    out the Kubernetes system pods or just look at a particular collection of resources.
  prefs: []
  type: TYPE_NORMAL
- en: '![Dashboard highlights](../images/00079.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.5\. Namespace filtering
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at the emerging standards bodies in the container
    community and how they are shaping the technology for the better with open specifications.
    We also took a closer look at CoreOS, a key player in both the container and Kubernetes
    community. We explored the technology they are developing to enhance and compliment
    container orchestration and saw first-hand how to use some of it with Kubernetes.
    Finally, we looked at the supported enterprise offering of Tectonic and some of
    the features that will be available soon.
  prefs: []
  type: TYPE_NORMAL
- en: Footnotes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ¹[https://www.opencontainers.org/faq/](https://www.opencontainers.org/faq/)
    (#11 on the page)
  prefs: []
  type: TYPE_NORMAL
- en: ²[https://github.com/opencontainers/specs/blob/master/principles.md](https://github.com/opencontainers/specs/blob/master/principles.md)
  prefs: []
  type: TYPE_NORMAL
