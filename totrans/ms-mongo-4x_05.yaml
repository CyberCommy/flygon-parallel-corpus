- en: MongoDB CRUD Operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will learn how to use the mongo shell for database administration
    operations. Starting with simple **create,** **read,** **update, and delete**
    (**CRUD**) operations, we will master scripting from the shell. We will also learn
    how to write MapReduce scripts from the shell and contrast them to the aggregation
    framework, into which we will dive deeper in [Chapter 6](e74806c0-d233-4157-a354-31ab937b85b5.xhtml),
    *Aggregation*. Finally, we will explore authentication and authorization using
    the MongoDB community and its paid counterpart, the Enterprise Edition.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: CRUD using the shell
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: Administration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aggregation framework
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Securing the shell
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Authentication with MongoDB
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CRUD using the shell
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The mongo shell is equivalent to the administration console used by relational
    databases. Connecting to the mongo shell is as easy as typing the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Type this on the command line for standalone servers or replica sets. Inside
    the shell, you can view available databases simply by typing the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, you can connect to a database by typing the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The mongo shell can be used to query and update data into our databases. Inserting
    this document in the `books` collection can be done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then find documents from a collection named `books` by typing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The result we get back from MongoDB informs us that the write succeeded and
    inserted one new document in the database.
  prefs: []
  type: TYPE_NORMAL
- en: 'Deleting this document has a similar syntax and results in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'You can try to update this same document as shown in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we notice a couple of things:'
  prefs: []
  type: TYPE_NORMAL
- en: The JSON-like formatted field in the `update` command is our query for searching
    for documents to update
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `WriteResult` object notifies us that the query matched one document and
    modified one document
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most importantly, the contents of this document were entirely replaced by the
    contents of the second JSON-like formatted field but we have lost information
    on `title` and `isbn`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'By default, the `update` command in MongoDB will replace the contents of our
    document with the document we specify in the second argument. If we want to update
    the document and add new fields to it, we need to use the `$set` operator, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, our document matches what we would expect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'However, deleting a document can be done in several ways, the most simple way
    is through its unique `ObjectId`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: You can see here that when there are no results, the mongo shell will not return
    anything other than the shell prompt itself: `>`.
  prefs: []
  type: TYPE_NORMAL
- en: Scripting for the mongo shell
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Administering the database using built-in commands is helpful, but it's not
    the main reason for using the shell. The true power of the mongo shell comes from
    the fact that it is a JavaScript shell.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can declare and assign variables in the shell as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In the previous example, we declared a new `title` variable as `MongoDB in a
    nutshell` and used the variable to insert a new document into our `books` collection,
    as shown in the following code.
  prefs: []
  type: TYPE_NORMAL
- en: 'As it''s a JavaScript shell, we can use it for functions and scripts that generate
    complex results from our database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'With this one-liner, we are creating a new function named `queryBooksByIsbn` that
    takes a single argument, which is the `isbn` value. With the data that we have
    in our collection, we can use our new function and fetch books by `isbn`, as shown
    in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the shell, we can write and test these scripts. Once we are satisfied,
    we can store them in the `.js` file and invoke them directly from the command
    line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are some useful notes about the default behavior of these scripts:'
  prefs: []
  type: TYPE_NORMAL
- en: Write operations will use a default write concern of `1`, which is global for
    MongoDB as of the current version. As write concern of `1` will request an acknowledgement
    that the write operation has propagated to the standalone `mongod` server or the
    primary server in a replica set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To get results from operations from a script back to standard output, we must
    use either JavaScript's built-in `print()` function or the mongo-specific `printjson()`
    function, which prints out results formatted in JSON.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The differences between scripting for the mongo shell and using it directly
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When writing scripts for the mongo shell, we cannot use the shell helpers.
    MongoDB''s commands, such as `use <database_name>`, `show collections`, and other
    helpers are built into the shell and so are not available from the JavaScript
    context where our scripts will get executed. Fortunately, there are equivalents
    to them that are available from the JavaScript execution context, as shown in
    the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Shell helpers** | **JavaScript equivalents** |'
  prefs: []
  type: TYPE_TB
- en: '| `show dbs, show databases` | `db.adminCommand(''listDatabases'')` |'
  prefs: []
  type: TYPE_TB
- en: '| `use <database_name>` | `db = db.getSiblingDB(''<database_name>'')` |'
  prefs: []
  type: TYPE_TB
- en: '| `show collections` | `db.getCollectionNames()` |'
  prefs: []
  type: TYPE_TB
- en: '| `show users` | `db.getUsers()` |'
  prefs: []
  type: TYPE_TB
- en: '| `show roles` | `db.getRoles({showBuiltinRoles: true})` |'
  prefs: []
  type: TYPE_TB
- en: '| `show log <logname>` | `db.adminCommand({ ''getLog'' : ''<logname>'' })`
    |'
  prefs: []
  type: TYPE_TB
- en: '| `show logs` | `db.adminCommand({ ''getLog'' : ''*'' })` |'
  prefs: []
  type: TYPE_TB
- en: '| `it` | `cursor = db.collection.find()` `if ( cursor.hasNext() ){`'
  prefs: []
  type: TYPE_NORMAL
- en: '` cursor.next();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}` |'
  prefs: []
  type: TYPE_NORMAL
- en: In the previous table, `it` is the iteration cursor that the mongo shell returns
    when we query and get back too many results to show in one batch.
  prefs: []
  type: TYPE_NORMAL
- en: Using the mongo shell, we can script almost anything that we would from a client,
    meaning that we have a really powerful tool for prototyping and getting quick
    insights into our data.
  prefs: []
  type: TYPE_NORMAL
- en: Batch inserts using the shell
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When using the shell, there will be many times we want to insert a large number
    of documents programmatically. The most straightforward implementation since we
    have a JavaScript shell, is to iterate through a loop, generating each document
    along the way, and performing a write operation in every iteration in the loop,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'In this simple example, we create an `authorMongoFactory()` method for an author
    who writes `1000` books on MongoDB with a slightly different name for each one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This will result in `1000` writes being issued to the database. While it is
    simple from a development point of view, this method will put a strain on the
    database.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, using a `bulk` write, we can issue a single database `insert` command
    with the `1000` documents that we have prepared beforehand, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The end result is the same as before, with the `1000` documents being inserted
    with the following structure in our `books` collection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The difference from the user's perspective lies in the speed of execution and
    reduced strain on the database.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding example, we used `initializeUnorderedBulkOp()` for the `bulk`
    operation builder setup. The reason we did this is because we don't care about
    the order of insertions being the same as the order in which we add them to our
    `bulk` variable with the `bulk.insert()` command.
  prefs: []
  type: TYPE_NORMAL
- en: This makes sense when we can make sure that all operations are unrelated to
    each other or idempotent.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we care about having the same order of insertions, we can use `initializeOrderedBulkOp()`;
    by changing the second line of our function, we get the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Batch operations using the mongo shell
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the case of inserts, we can generally expect that the order of operations
    doesn't matter.
  prefs: []
  type: TYPE_NORMAL
- en: '`bulk`, however, can be used with many more operations than just inserts. In
    the following example, we have a single book with `isbn : 101` and the `name` of `Mastering
    MongoDB` in a `bookOrders` collection with the number of available copies to purchase
    in the `available` field, with the `99` books available for purchase:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'With the following series of operations in a single `bulk` operation, we are
    adding one book to the inventory and then ordering `100` books, for a final total
    of zero copies available:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'With the code, we will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/be7ce6c2-d39a-4090-953c-aa8830588774.png)'
  prefs: []
  type: TYPE_IMG
- en: Using `initializeOrderedBulkOp()`, we can make sure that we are adding one book
    before ordering `100` so that we are never out of stock. On the contrary, if we
    were using `initializeUnorderedBulkOp()`, we won't have such a guarantee and we
    might end up with the 100-book order coming in before the addition of the new
    book, resulting in an application error as we don't have that many books to fulfill
    the order.
  prefs: []
  type: TYPE_NORMAL
- en: 'When executing through an ordered list of operations, MongoDB will split the
    operations into batches of `1000` and group these by operation. For example, if
    we have `1002` inserts, `998` updates, `1004` deletes, and finally, `5` inserts,
    we will end up with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The previous code can be explained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9bce1eca-424e-447a-a0df-5c866a63024f.png)'
  prefs: []
  type: TYPE_IMG
- en: This doesn't affect the series of operations, but it implicitly means that our
    operations will leave the database in batches of `1000`. This behavior is not
    guaranteed to stay in future versions.
  prefs: []
  type: TYPE_NORMAL
- en: If we want to inspect the execution of a `bulk.execute()` command, we can issue
    `bulk.getOperations()` right after we type `execute()`.
  prefs: []
  type: TYPE_NORMAL
- en: Since version 3.2, MongoDB has offered an alternative command for bulk writes,
    `bulkWrite()`.
  prefs: []
  type: TYPE_NORMAL
- en: '`bulkWrite` arguments are the series of operations we want to execute. `WriteConcern` (the
    default is again `1`), and if the series of write operations should get applied
    in the order that they appear in the array (they will be ordered by default):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The following operations are the same ones supported by `bulk`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`insertOne`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`updateOne`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`updateMany`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`deleteOne`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`deleteMany`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`replaceOne`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`updateOne`, `deleteOne`, and `replaceOne` have matching filters; if they match
    more than one document, they will only operate on the first one. It''s important
    to design these queries so that they don''t match more than one document, otherwise,
    the behavior will be undefined.'
  prefs: []
  type: TYPE_NORMAL
- en: Administration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using MongoDB should, for the most part, be as transparent as possible to the
    developer. Since there are no schemas, there is no need for migrations, and generally,
    developers find themselves spending less time on administrative tasks in the database
    world.
  prefs: []
  type: TYPE_NORMAL
- en: That said, there are several tasks that an experienced MongoDB developer or
    architect can perform to keep up the speed and performance of MongoDB.
  prefs: []
  type: TYPE_NORMAL
- en: 'Administration is generally performed in three different levels, ranging from
    more generic to more specific: **process**, **collection**, and **index**.'
  prefs: []
  type: TYPE_NORMAL
- en: At the process level, there is the `shutDown` command to shut down the MongoDB
    server.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the database level, we have the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '`dropDatabase`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`listCollections`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`copyDB` or `clone` to clone a remote database locally'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`repairDatabase` for when our database is not in a consistent state due to
    an unclean shutdown'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In comparison, at the collection level, the following commands are used:'
  prefs: []
  type: TYPE_NORMAL
- en: '`drop`: To drop a collection'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`create`: To create a collection'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`renameCollection`: To rename a collection'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cloneCollection`: To clone a remote collection to our local DB'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cloneCollectionAsCapped`: To clone a collection into a new capped collection'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`convertToCapped`: To convert a collection to a capped one'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'At the index level, we can use the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '`createIndexes`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`listIndexes`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dropIndexes`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reIndex`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will also go through a few other commands that are more important from an
    administration standpoint.
  prefs: []
  type: TYPE_NORMAL
- en: fsync
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MongoDB normally writes all operations to the disk every 60 seconds. fsync will
    force data to persist to the disk immediately and synchronously.
  prefs: []
  type: TYPE_NORMAL
- en: If we want to take a backup of our databases, we need to apply a lock as well.
    Locking will block all writes and some reads while fsync is operating.
  prefs: []
  type: TYPE_NORMAL
- en: In almost all cases, it's better to use journaling and refer to our techniques
    for backup and restore, which will be covered in [Chapter 8](687220c0-264a-4edb-9e04-c10b0c180766.xhtml)*,*
    *Monitoring, Backup, and Security*, for maximum availability and performance.
  prefs: []
  type: TYPE_NORMAL
- en: compact
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MongoDB documents take up a specified amount of space on a disk. If we perform
    an update that increases the size of a document, this may end up being moved out
    of sequence to the end of the storage block, creating a hole in storage, resulting
    in increased execution times for this update, and possibly missing it from running
    queries. The compact operation will defragment space and result in less space
    being used.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can update a document by adding an extra 10 bytes, showing how it will be
    moved to the end of the storage block, and creating an empty space in the physical
    storage:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8e60c62b-f925-4231-9ff6-6e43f60683df.png)'
  prefs: []
  type: TYPE_IMG
- en: '`compact` can also take a `paddingFactor` argument as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '`paddingFactor` is the preallocated space in each document that ranges from
    `1.0` (that is, no padding, which is the default value) to `4.0` for calculating
    the padding of `300` bytes for each `100` bytes of document space that is needed
    when we initially insert it.'
  prefs: []
  type: TYPE_NORMAL
- en: Adding padding can help alleviate the problem of updates moving documents around,
    at the expense of more disk space being needed for each document when created.
    By padding each document, we are allocating more space for it that will prevent
    it from being moved to the end of the storage block if our updated document can
    still fit in the preallocated storage space.
  prefs: []
  type: TYPE_NORMAL
- en: currentOp and killOp
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`db.currentOp()` will show us the currently-running operation in the database
    and will attempt to kill it. We need to run the `use admin` command before running
    `killOp()`. Needless to say, using `killOp()` against internal MongoDB operations
    is not recommended or advised, as the database may end up in an undefined state.
    The `killOp()` command can be used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: collMod
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`collMod` is used to pass flags to a collection by modifying the underlying
    database''s behavior.'
  prefs: []
  type: TYPE_NORMAL
- en: Since version 3.2, the most interesting set of flags that we can pass to a collection
    is document validation.
  prefs: []
  type: TYPE_NORMAL
- en: Document validation can specify a set of rules to be applied to new updates
    and inserts into a collection. This means that current documents will be checked
    if they get modified.
  prefs: []
  type: TYPE_NORMAL
- en: We can only apply validations to documents that are already valid if we set
    `validationLevel` to `moderate`. By specifying `validationAction`, we can log
    documents that are invalid by setting it to `warn` or prevent updates from happening
    altogether by setting it to `error`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, with the previous example of `bookOrders` we can set `validator`
    on the `isbn` and `name` fields being present for every insert or update, as demonstrated
    in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we get back the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, if we try to insert a new document with only the `isbn` field being present,
    we get an error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: We get an error because our validation has failed. Managing validation from
    the shell is really useful as we can write scripts to manage it, and also make
    sure that everything is in place.
  prefs: []
  type: TYPE_NORMAL
- en: touch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `touch` command will load data and/or index data from storage to memory.
    This is typically useful if our script will subsequently use this data, speeding
    up the execution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: This command should be used with caution in production systems, as loading data
    and indexes into memory will displace existing data from it.
  prefs: []
  type: TYPE_NORMAL
- en: MapReduce in the mongo shell
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most interesting features that has been underappreciated and not
    widely supported throughout MongoDB history, is the ability to write MapReduce
    natively using the shell.
  prefs: []
  type: TYPE_NORMAL
- en: MapReduce is a data processing method for getting aggregation results from large
    sets of data. The main advantage of this is that it is inherently parallelizable
    as evidence by frameworks such as Hadoop.
  prefs: []
  type: TYPE_NORMAL
- en: MapReduce is really useful when used to implement a data pipeline. Multiple
    MapReduce commands can be chained to produce different results. An example of
    this is aggregating data by using different reporting periods (such as hour, day,
    week, month, and year) where we use the output of each more granular reporting
    period to produce a less granular report.
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple example of MapReduce in our examples given that our input books collection
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Our map and reduce functions are defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'In this `mapper`, we simply output a key of `id` of each document with a value
    of `1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'In `reducer`, we sum across all values (where each one has a value of `1`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Our final output will be a document with no ID, since we didn't output any value
    for ID, and a value of six, since there are six documents in the input dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Using MapReduce, MongoDB will apply a map to each input document, emitting key-value
    pairs at the end of the map phase. Then each reducer will get key-value pairs
    with the same key as input, processing all multiple values. The reducer's output
    will be a single key-value pair for each key.
  prefs: []
  type: TYPE_NORMAL
- en: Optionally, we can use a `finalize` function to further process the results
    of `mapper` and `reducer`. MapReduce functions use JavaScript and run within the
    `mongod` process. MapReduce can output inline as a single document, subject to
    the 16 MB document size limit, or as multiple documents in an output collection.
    Input and output collections can be sharded.
  prefs: []
  type: TYPE_NORMAL
- en: MapReduce concurrency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'MapReduce operations will place several short-lived locks that should not affect
    operations. However, at the end of the `reduce` phase, if we output the data to
    an existing collection, then output actions such as `merge`, `reduce`, and `replace`
    will take an exclusive global write lock for the whole server, blocking all other
    writes to the `db` instance. If we want to avoid this, then we should invoke `mapReduce`
    in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: We can apply `nonAtomic` only to `merge` or `reduce` actions. `replace` will
    just replace the contents of documents in `bookOrders`, which will not take much
    time anyway.
  prefs: []
  type: TYPE_NORMAL
- en: With the `merge` action, the new result is merged with the existing result if
    the output collection already exists. If an existing document has the same key
    as the new result, then it will overwrite the existing document.
  prefs: []
  type: TYPE_NORMAL
- en: With the `reduce` action, the new result is processed together with the existing
    result if the output collection already exists. If an existing document has the
    same key as the new result, it will apply the `reduce` function to both the new
    and the existing documents, and will overwrite the existing document with the
    result.
  prefs: []
  type: TYPE_NORMAL
- en: Although MapReduce has been present since the early versions of MongoDB, it
    hasn't evolved as much as the rest of the database, resulting in its usage being
    less than that of specialized MapReduce frameworks such as Hadoop, which we will
    learn more about in [Chapter 11](da971527-0a0e-43cd-933e-5979379e75b4.xhtml),
    *Harnessing Big Data with MongoDB*.
  prefs: []
  type: TYPE_NORMAL
- en: Incremental MapReduce
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Incremental MapReduce is a pattern where we use MapReduce to aggregate to previously
    calculated values. An example of this could be counting non-distinct users in
    a collection for different reporting periods (that is, by hour, day, or month)
    without the need to recalculate the result every hour.
  prefs: []
  type: TYPE_NORMAL
- en: 'To set up our data for incremental MapReduce, we need to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Output our reduce data to a different collection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the end of every hour, query only for the data that got into the collection
    in the last hour
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the output of our reduce data, merge our results with the calculated results
    from the previous hour
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Continuing with the previous example, let''s assume that we have a `published`
    field in each of the documents with our input dataset, as shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Using our previous example of counting books, we will get the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we get a third book in our `mongo_book` collection with a document, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: What happened in the preceding code is that by querying for documents in July,
    2017, we only got the new document out of the query and then used its value to
    reduce the value with the already-calculated value of `2` in our `books_count`
    document, adding `1` to the final sum of `3` documents.
  prefs: []
  type: TYPE_NORMAL
- en: 'This example, as contrived as it is, shows a powerful attribute of MapReduce:
    the ability to re-reduce results to incrementally calculate aggregations over
    time.'
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting MapReduce
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the years, one of the major shortcomings of MapReduce frameworks has been
    the inherent difficulty in troubleshooting, as opposed to simpler non-distributed
    patterns. Most of the time, the most effective tool is debugging using `log` statements
    to verify that output values match our expected values. In the mongo shell, which
    is a JavaScript shell, it is as simple as providing the output using the `console.log()`
    function.
  prefs: []
  type: TYPE_NORMAL
- en: Diving deeper into MapReduce in MongoDB, we can debug both in the map and the
    reduce phase by overloading the output values.
  prefs: []
  type: TYPE_NORMAL
- en: 'By debugging the `mapper` phase, we can overload the `emit()` function to test
    what the output key values will be, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then call it manually on a single document to verify that we get back
    the key-value pair that we expect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The `reducer` function is somewhat more complicated. A MapReduce `reducer`
    function must meet the following criteria:'
  prefs: []
  type: TYPE_NORMAL
- en: It must be idempotent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It must be commutative
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The order of values coming from the `mapper` function should not matter for
    the reducer's result
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `reducer` function must return the same type of result as the `mapper` function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will dissect each of these following requirements to understand what they
    really mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '**It must be idempotent**: MapReduce, by design, may call the `reducer` function
    multiple times for the same key with multiple values from the `mapper` phase.
    It also doesn''t need to reduce single instances of a key as it''s just added
    to the set. The final value should be the same no matter the order of execution.
    This can be verified by writing our own `verifier` function and forcing `reducer`
    to re-reduce, or by executing `reducer` many times as shown in the following code
    snippet:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '**It must be commutative**: As multiple invocations of the `reducer` function
    may happen for the same `key`, if it has multiple values, the following code should
    hold:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '**The order of values coming from the mapper function should not matter for
    the reducer''s result**: We can test that the order of values from `mapper` doesn''t
    change the output for `reducer`, by passing in documents to `mapper` in a different
    order and verifying that we get the same results out:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '**The reduce function must return the same type of result as the mapper function**:
    Hand-in-hand with the first requirement, the type of object that the `reduce`
    function returns should be the same as the output of the `mapper` function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aggregation framework
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since version 2.2, MongoDB has provided a better way to work with aggregation,
    one that has been supported, adopted, and enhanced regularly ever since. The aggregation
    framework is modeled after data processing pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: 'In data processing pipelines, there are three main operations: filters that
    operate like queries, filtering documents, and document transformations that transform
    documents to get them ready for the next stage.'
  prefs: []
  type: TYPE_NORMAL
- en: SQL to aggregation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An aggregation pipeline can replace and augment querying operations in the
    shell. A common pattern for development is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: To verify that we have the correct data structures and get quick results using
    a series of queries in the shell
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To prototype pipeline results using the aggregation framework
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To refine and refactor if/when needed, either by ETL processes to get data into
    a dedicated data warehouse, or by more extensive usage of the application layer
    to get the insights that we need
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the following table, we can see how SQL commands map to the aggregation
    framework operators:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **SQL** | **Aggregation framework** |'
  prefs: []
  type: TYPE_TB
- en: '| `WHERE`/`HAVING` | `$match` |'
  prefs: []
  type: TYPE_TB
- en: '| `GROUP BY` | `$group` |'
  prefs: []
  type: TYPE_TB
- en: '| `SELECT` | `$project` |'
  prefs: []
  type: TYPE_TB
- en: '| `ORDER BY` | `$sort` |'
  prefs: []
  type: TYPE_TB
- en: '| `LIMIT` | `$limit` |'
  prefs: []
  type: TYPE_TB
- en: '| `sum()`/`count()` | `$sum` |'
  prefs: []
  type: TYPE_TB
- en: '| `join` | `$lookup` |'
  prefs: []
  type: TYPE_TB
- en: Aggregation versus MapReduce
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In MongoDB, we can essentially get data out of our database by using three
    methods: querying, the aggregation framework, and MapReduce. All three of them
    can be chained to each other and many times it is useful to do so; however, it''s
    important to understand when we should use aggregation and when MapReduce may
    be a better alternative.'
  prefs: []
  type: TYPE_NORMAL
- en: We can use both aggregation and MapReduce with sharded databases.
  prefs: []
  type: TYPE_NORMAL
- en: Aggregation is based on the concept of a pipeline. As such, it's important to
    be able to model our data from the input to the final output, in a series of transformations
    and processing that can get us there. It's also mostly useful when our intermediate
    results can be used on their own, or feed parallel pipelines. Our operations are
    limited by the operators that we have available from MongoDB, so it's important
    to make sure that we can calculate all the results we need by using the available
    commands.
  prefs: []
  type: TYPE_NORMAL
- en: MapReduce, on the other hand, can be used to construct pipelines by chaining
    the output of one MapReduce job to the input of the next one via an intermediate
    collection, but this is not its primary purpose.
  prefs: []
  type: TYPE_NORMAL
- en: MapReduce's most common use case is to periodically calculate aggregations for
    large datasets. Having MongoDB's querying in place, we can incrementally calculate
    these aggregations without the need to scan through the whole input table every
    time. In addition, its power comes from its flexibility as we can define mappers
    and reducers in JavaScript with the full flexibility of the language when calculating
    intermediate results. Not having the operators that the aggregation framework
    provides us with, we have to implement them on our own.
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, the answer is not either/or. We can (and should) use the aggregation
    framework to construct our ETL pipeline and resort to MapReduce for the parts
    that are not yet supported sufficiently by it.
  prefs: []
  type: TYPE_NORMAL
- en: A complete use case with aggregation and MapReduce is provided in [Chapter 6](e74806c0-d233-4157-a354-31ab937b85b5.xhtml),
    *Aggregation*.
  prefs: []
  type: TYPE_NORMAL
- en: Securing the shell
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MongoDB is a database developed with the ease of development in mind. As such,
    security at the database level was not baked in from the beginning and it was
    up to the developers and administrators to secure the MongoDB host from accessing outside
    the application server.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, this means that as far as back as 2015, there were 39,890 databases
    found open to the internet, with no security access configured. Many of them were
    production databases, one belonging to a French telecom operator and containing
    more than eight million records from its customers.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, there is no excuse for leaving any MongoDB server with the default
    authentication off settings at any stage of development, from local server deployment
    to production.
  prefs: []
  type: TYPE_NORMAL
- en: Authentication and authorization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Authentication and authorization are closely connected and sometimes confused.
    Authentication is about verifying the identity of a user to the database. An example
    of authentication is **Secure Sockets Layer** (**SSL**), where the web server
    verifies its identity—that it is who it claims to be—to the user.
  prefs: []
  type: TYPE_NORMAL
- en: Authorization is about determining what actions a user can take on a resource.
    In the next sections, we will discuss authentication and authorization with these
    definitions in mind.
  prefs: []
  type: TYPE_NORMAL
- en: Authorization with MongoDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'MongoDB''s most basic authorization relies on the username/password method.
    By default, MongoDB will not start with authorization enabled. To enable it, we
    need to start our server with the `--auth` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'To set up authorization, we need to start our server without authorization
    to set up a user. Setting up an admin user is simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, `<adminUser>` is the name of the user we want to create, `<password>`
    is the password, and `<adminRole>` can be any of the following values ordered
    from the most powerful to the least powerful, as shown in the following list:'
  prefs: []
  type: TYPE_NORMAL
- en: '`root`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dbAdminAnyDatabase`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`userAdminAnyDatabase`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '``readWriteAnyDatabase``'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`readAnyDatabase`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dbOwner`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dbAdmin`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`userAdmin`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`readWrite`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`read`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of these roles, `root` is the superuser that allows access to everything. This
    is not recommended to be used, except for special circumstances.
  prefs: []
  type: TYPE_NORMAL
- en: All the `AnyDatabase` roles provide access to all databases, of which `dbAdminAnyDatabase`
    combines the `userAdminAnyDatabase` and `readWriteAnyDatabase` scopes being an
    admin again in all databases.
  prefs: []
  type: TYPE_NORMAL
- en: 'The rest of the roles are defined in the database that we want them to apply,
    by changing the roles subdocument of the preceding `db.createUser()`; for example,
    to create a `dbAdmin` for our `mongo_book` database, we would use the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Cluster administration has even more roles, which we will cover in more depth
    in [Chapter 12](59874e20-5c76-4e7c-9d21-934fe637f3c1.xhtml), *Replication*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, when we restart our database with the `--auth` flag set, we can use
    either the command line or the connection string (from any driver) to connect
    as `admin` and create new users with predefined or custom-defined roles:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Security tips for MongoDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Common software system security precautions apply with MongoDB. We will outline
    some of them here and learn how to enable them.
  prefs: []
  type: TYPE_NORMAL
- en: Encrypting communication using TLS/SSL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Communication between the `mongod` or `mongos` server and the client mongo shell
    or applications should be encrypted. This is supported in most MongoDB distributions
    from version 3.0 onward; however, we need to take care that we download the proper
    version with SSL support.
  prefs: []
  type: TYPE_NORMAL
- en: After this, we need to get a signed certificate from a trusted certificate authority
    or sign our own. Using self-signed certificates is fine for preproduction systems,
    but in production it will mean that MongoDB servers won't be able to verify our
    identity, leaving us susceptible to man-in-the-middle attacks; thus using a proper
    certificate is highly recommended.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start our MongoDB server with SSL, we need the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Here, `<pem>` is our `.pem` signed certificate file and `<ca>` is the `.pem`
    root certificate from the certificate authority that contains the root certificate
    chain.
  prefs: []
  type: TYPE_NORMAL
- en: 'These options can also be defined in our configuration file, `mongod.conf`
    or `mongos.conf`, in YAML file format, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Here, we specified a `PEMKeyFile`, a `CAFile`, and also that we won't allow
    the server to start with certificates that follow the `TLS1_0`, `TLS1_1` or `TLS1_2`
    versions. These are the available versions for `disabledProtocols` at this time.
  prefs: []
  type: TYPE_NORMAL
- en: Encrypting data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using WiredTiger is highly recommended for encrypting data at rest, as it supports
    it natively from version 3.2.
  prefs: []
  type: TYPE_NORMAL
- en: For users of the Community Edition version, this can be achieved in the storage
    selection of their choice; for example, in **Amazon Web Services** (**AWS**) using **Elastic
    Block Store** (**EBS**) encrypted storage volumes.
  prefs: []
  type: TYPE_NORMAL
- en: This feature is available only for MongoDB Enterprise Edition.
  prefs: []
  type: TYPE_NORMAL
- en: Limiting network exposure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The oldest security method to secure any server is to disallow it from accepting
    connections from unknown sources. In MongoDB, this is done in a configuration
    file with a simple line as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Here, `<string>` is a comma-separated list of IPs that the MongoDB server will
    accept connections from.
  prefs: []
  type: TYPE_NORMAL
- en: Firewalls and VPNs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Together with limiting network exposure on the server side, we can use firewalls
    to prevent access to our network from the outside internet. VPNs can also provide
    tunneled traffic between our servers, but regardless, they shouldn't be used as
    our sole security mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: Auditing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: No matter how secure any system is, we need to keep a close eye on the system from
    an auditing perspective to make sure that we detect possible breaches and stop
    them as soon as possible.
  prefs: []
  type: TYPE_NORMAL
- en: This feature is available only for MongoDB Enterprise Edition.
  prefs: []
  type: TYPE_NORMAL
- en: For users of the Community Edition version, we have to set up auditing manually
    by logging changes to documents and collections in the application layer, possibly
    in a different database altogether. This will be addressed in the next chapter,
    which covers advanced querying using client drivers.
  prefs: []
  type: TYPE_NORMAL
- en: Using secure configuration options
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It goes without saying that the same configuration options should be used.
    We must use one of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: MapReduce
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The mongo shell group operation or a group operation from our client driver
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`$where` JavaScript server evaluation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we don't, we should disable server-side scripting by using the `--noscripting`
    option on the command line when we start our server.
  prefs: []
  type: TYPE_NORMAL
- en: The mongo shell group operation, as mentioned in the previous list, can be a
    tricky one as many drivers may use MongoDB's `group()` command when we issue group
    commands in the driver. However, given the limitations that `group()` has in terms
    of performance and output documents, we should rethink our design to use the aggregation
    framework or application-side aggregations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The web interface also has to be disabled by not using any of the following
    commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '`net.http.enabled`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`net.http.JSONPEnabled`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`net.http.RESTInterfaceEnabled`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On the contrary, `wireObjectCheck` needs to remain enabled as it is by default,
    and ensures that all documents stored by the `mongod` instance are valid BSON.
  prefs: []
  type: TYPE_NORMAL
- en: Authentication with MongoDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By default, MongoDB uses SCRAM-SHA-1 as the default challenge and response authentication
    mechanism. This is an SHA-1 username/password-based mechanism for authentication.
    All drivers and the mongo shell itself have built-in methods to support it.
  prefs: []
  type: TYPE_NORMAL
- en: The authentication protocol in MongoDB has changed since version 3.0\. In older
    versions, the less secure MONGODB-CR was used.
  prefs: []
  type: TYPE_NORMAL
- en: Enterprise Edition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MongoDB's Enterprise Edition is a paid subscription product offering more features
    around security and administration.
  prefs: []
  type: TYPE_NORMAL
- en: Kerberos authentication
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MongoDB Enterprise Edition also offers Kerberos authentication. Kerberos, named
    after the character Kerberos (or Cerberus) from Greek mythology—which is the ferocious
    three-headed guard-dog of the god of the underworld, Hades—focuses on mutual authentication
    between client and server, protecting against eavesdropping and replay attacks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kerberos is widely used in Windows systems through integration with Microsoft''s
    Active Directory. To install Kerberos, we need to start `mongod` without Kerberos
    set up, then connect to the `$external` database (not the admin that we normally
    use for admin authorization), and create a user with a Kerberos role and permissions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we authorize the `mongo_book_user@packt.net` user
    to read our `mongo_book` database, just like we would do with a user using our
    admin system.
  prefs: []
  type: TYPE_NORMAL
- en: 'After that, we need to start our server with Kerberos support by passing in
    the `authenticationMechanisms` parameter, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can connect from our server or command line, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: LDAP authentication
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Similar to Kerberos authentication, we can also use **Lightweight Directory
    Access Protocol** (**LDAP**) in MongoDB Enterprise Edition only. The user setup
    needs to be done in the `$external` database and must match the name of the authentication
    LDAP name. The name may need to pass through a transformation and this may cause
    a mismatch between the LDAP name and the user entry in the `$external` database.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up LDAP authentication is beyond the scope of this book, but the important
    thing to consider is that any changes in the LDAP server may need changes in the
    MongoDB server, which won't happen automatically.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we scratched the tip of the iceberg of CRUD operations. Starting
    from the mongo shell, we learned how to insert, delete, read, and modify documents.
    We also discussed the differences between one-off inserts and inserting in batches
    for performance.
  prefs: []
  type: TYPE_NORMAL
- en: Following that, we discussed administration tasks and how to perform them in
    the mongo shell. MapReduce and its successor, aggregation framework, were also
    discussed in this chapter, including how they compare, how to use them, and how
    we can translate SQL queries to aggregation framework pipeline commands.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we discussed security and authentication with MongoDB. Securing our
    database is of paramount importance; we will learn more about this in [Chapter
    8](687220c0-264a-4edb-9e04-c10b0c180766.xhtml), *Monitoring, Backup, and Security*.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will dive deeper into CRUD using three of the most
    popular languages for web development: Ruby, Python, and **PHP: Hypertext Preprocessor**
    (**PHP**).'
  prefs: []
  type: TYPE_NORMAL
