- en: Building an App Using the Google Faces API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The ability of computers to perform tasks such as identifying objects has always
    been a humongous task for both the software and the required architecture. This
    isn't the case anymore since the likes of Google, Amazon, and a few other companies
    have done all the hard work, providing the infrastructure and making it available
    as a cloud service. It should be noted that they are as easy to access as making
    REST API calls.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will learn how to use the face detection API from Google's
    Mobile Vision API to detect faces and add fun functionalities such as adding rabbit
    ears to a user's picture.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, the following topics are going to be covered:'
  prefs: []
  type: TYPE_NORMAL
- en: Identifying human faces in an image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracking human faces from a camera feed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying specific parts of the face (for example, eyes, ears, nose, and mouth)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drawing graphics on specific parts of a detected face in an image (for example,
    rabbit ears over the user's ears)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to Mobile Vision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Mobile Vision API provides a framework for finding objects in photos and
    videos. The framework can locate and describe visual objects in **images** or
    **video frames**, and it has an event-driven API that tracks the position of those
    objects.
  prefs: []
  type: TYPE_NORMAL
- en: Currently, the Mobile Vision API includes **face**, **barcode**, and **text**
    detectors.
  prefs: []
  type: TYPE_NORMAL
- en: Faces API concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before diving into coding the features, it is necessary that you understand
    the underlying concepts of the face detection capabilities of the face detection
    API.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the official documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: <q>Face detection is the process of automatically locating human faces in visual
    media (digital images or video). A face that is detected is reported at a position
    with an associated size and orientation. Once a face is detected, it can be searched
    for landmarks such as the eyes and nose.</q>
  prefs: []
  type: TYPE_NORMAL
- en: A key point to note is that only after a face is detected will landmarks such
    as eyes and a nose be searched for. As part of the API, you could opt out of detecting
    these landmarks.
  prefs: []
  type: TYPE_NORMAL
- en: Note the difference between face detection and face recognition. While the former
    is able to recognize a face from an image or video, the latter does the same and
    is also able to tell that a face has been seen before. The former has no memory
    of a face it has detected before.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will be using a couple of terms in this section, so let me give you an overview
    of each of these before we go any further:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Face tracking** extends face detection to video sequences. When a face appears
    in a video for any length of time, it can be identified as the same person and
    can be tracked.'
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that the face that you are tracking must appear in the
    same video. Also, this is not a form of face recognition; this mechanism just
    makes inferences based on the position and motion of the face(s) in a video sequence.
  prefs: []
  type: TYPE_NORMAL
- en: A **landmark** is a point of interest within a face. The left eye, right eye,
    and nose base are all examples of landmarks. The Face API provides the ability
    to find landmarks on a detected face.
  prefs: []
  type: TYPE_NORMAL
- en: '**Classification** is determining whether a certain facial characteristic is
    present. For example, a face can be classified with regards to whether its eyes
    are open or closed or smiling or not.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting started – detecting faces
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will first learn how to detect a face in a photo and its associated landmarks.
  prefs: []
  type: TYPE_NORMAL
- en: We will need some requirements in order to pursue this.
  prefs: []
  type: TYPE_NORMAL
- en: With a minimum of Google Play Services 7.8, you can use the Mobile Vision APIs,
    which provide the face detection APIs. Make sure you update your Google Play Services
    from the SDK manager so that you meet this requirement.
  prefs: []
  type: TYPE_NORMAL
- en: Get an Android device that runs Android 4.2.2 or later or a configured Android
    Emulator. The latest version of the Android SDK includes the SDK tools component.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the FunyFace project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create a new project called FunyFace. Open up the app module''s `build.gradle`
    file and update the dependencies to include the Mobile Vision APIs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, update your `AndroidManifest.xml` to include meta data for the faces API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Now, your app is ready to use the face detection APIs.
  prefs: []
  type: TYPE_NORMAL
- en: 'To keep things simple, for this lab, you''re just going to process an image
    that is already present in your app. Add the following image to your `res/drawable`
    folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2112ecc1-219a-482e-8a9d-c2cc06eeedfb.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Now, this is how you will go about performing face detection.
  prefs: []
  type: TYPE_NORMAL
- en: You will first load the image into memory, get a `Paint` instance, and create
    a temporary bitmap based on the original, from which you will create a canvas. Create
    a frame using the bitmap and then call the detect method on `FaceDetector`, using
    this frame to get back `SparseArray` of face objects.
  prefs: []
  type: TYPE_NORMAL
- en: Well, let's get down to business—this is where you will see how all of these
    play out.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, open up your `activity_main.xml` file and update the layout so that
    it has an image view and a button. See the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'That is all you need to do here so that you have `FrameLayout` with `ImageView`
    and a button. Now, open up `MainActivity.kt` and add the following import statements. This
    is just to make sure that you import from the right packages as you move along.
    In your `onCreate()` method, attach a click listener to the button in your `MainActivity`
    layout file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Loading the image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In your `detectFace()` method, you will first load your image from the drawable
    folder into memory and create a bitmap image from it. Since you will be updating
    this bitmap to paint over it when the face is detected, you need to make it mutable.
    This is what makes your bitmap mutable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'See the following implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Creating a Paint instance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Use the `Paint` API to get an instance of the `Paint` class. You will only
    draw around the face, and not paint the whole face. To do this, set a thin stroke,
    give it a color, which in our case is red, and set the style of paint to `STROKE`
    using `Paint.Style.STROKE`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The `Paint` class holds the information related to the *style* and *color* related
    to the text, bitmap, and various shapes.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a canvas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To get the canvas, first create a bitmap using the dimensions from the bitmap
    you created earlier. With this canvas, you will paint over the bitmap to draw
    the outline of the face after it has been detected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `Canvas` class is used to hold the call made to draw. A canvas is a drawing
    surface and it provides various methods for drawing onto a bitmap.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the face detector
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All you have done thus far is basically housekeeping. You will now access the
    FaceDetector API by which you will, well, detect the face in the image. You will
    disable tracking for now, as you only want to detect the face at this stage.
  prefs: []
  type: TYPE_NORMAL
- en: Note that on its first run, the Play Services SDK will take some time to initialize
    the Faces API. It may or may not have completed this process at the time you intend
    to use it. Therefore, as a safety check, you need to ensure its availability before
    using it. In this case, you will show a simple dialog to the user if the `FaceDetector`
    is not ready at the time the app is run.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also note that you may need an internet connection as the SDK initializes.
    You also need to ensure you have enough space, as the initialization may download
    some native library onto the device:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Detecting the faces
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, you will use the `detect()` method from the `faceDetector` instance to
    get the faces and their metadata. The result will be `SparseArray` of `Face` objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Drawing rectangles on the faces
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that you have the faces, you will iterate through this array to get the
    coordinates of the bounding rectangle for the face. Rectangles require `x`, `y`
    of the top left and bottom right corners, but the information available only gives
    the left and top positions, so you have to calculate the bottom right using the
    top `left`, `width`, and `height`. Then, you need to release the `faceDetector`
    to free up resources. Here''s the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'All set. Run the app, press the DETECT FACE button, and wait a while...:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/784e912e-461c-42b5-b1d6-a0ac18c096e2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The app should detect the face and a square box should appear around the face,
    voila:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/71235c88-1ca6-4ac3-b85b-9c3b4488cb53.png)'
  prefs: []
  type: TYPE_IMG
- en: Okay, let's move on and add some fun to their faces. To do this, you need to
    identify the position of the specific landmark you want, then draw over it.
  prefs: []
  type: TYPE_NORMAL
- en: To find out the landmark's representation, you label them this time around,
    then afterwards draw your filter to the desired position.
  prefs: []
  type: TYPE_NORMAL
- en: 'To label, update the for loop which drew the rectangle around the face:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the app and take note of the labels of the various landmarks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b183ac20-c006-4bcb-9066-28510bfaed67.png)'
  prefs: []
  type: TYPE_IMG
- en: There you have it! That's funny, right?
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to use the Mobile Vision APIs, in this case,
    the Faces API. There are a few things to note here. This program is not optimized
    for production. Some things you can do on your own are load the image and do the
    processing in a background thread. You can also provide a functionality to allow
    the user to pick and choose images from different sources other than the static
    one used. You can get more creative with the filters and how they are applied
    too. Also, you can enable the tracking feature on the FaceDetector instance, and
    feed in a video to try out face tracking.
  prefs: []
  type: TYPE_NORMAL
