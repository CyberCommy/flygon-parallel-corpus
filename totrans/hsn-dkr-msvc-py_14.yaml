- en: Monitoring Logs and Metrics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控日志和指标
- en: In real-life operations, the ability to quickly detect and debug a problem is
    critical. In this chapter, we will discuss the two most important tools we can
    use to discover what's happening in a production cluster processing a high number
    of requests. The first tool is logs, which help us to understand what's happening
    within a single request, while the other tool is metrics, which categorizes the
    aggregated performance of the system.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际运营中，快速检测和调试问题的能力至关重要。在本章中，我们将讨论我们可以用来发现在处理大量请求的生产集群中发生了什么的两个最重要的工具。第一个工具是日志，它帮助我们了解单个请求中发生了什么，而另一个工具是指标，它对系统的聚合性能进行分类。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Observability of a live system
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实时系统的可观测性
- en: Setting up logs
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置日志
- en: Detecting problems through logs
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过日志检测问题
- en: Setting up metrics
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置指标
- en: Being proactive
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 积极主动
- en: By the end of this chapter, you'll know how to add logs so that they are available
    to detect problems and how to add and plot metrics and understand the differences
    between both of them.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，您将了解如何添加日志以便检测问题，以及如何添加和绘制指标，并了解它们之间的区别。
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'We will be using the example system for this chapter and tweaking it to include
    centralized logging and metrics. The code for this chapter can be found in this
    book''s GitHub repository: [https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用示例系统，并对其进行调整，包括集中式日志记录和指标。本章的代码可以在本书的GitHub存储库中找到：[https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10)。
- en: 'To install the cluster, you need to build each individual microservice:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装集群，您需要构建每个单独的微服务：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The microservices in this chapter are the same ones that we introduced previously,
    but they add extra log and metrics configuration.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的微服务与之前介绍的相同，但它们增加了额外的日志和指标配置。
- en: 'Now, we need to create the example namespace and start the Kubernetes cluster
    using the `find` configuration in the `Chapter10/kubernetes` subdirectory:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要创建示例命名空间，并使用`Chapter10/kubernetes`子目录中的`find`配置启动Kubernetes集群：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To be able to access the different services, you need to update your `/etc/hosts`
    file so that it includes the following lines of code:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 要能够访问不同的服务，您需要更新您的`/etc/hosts`文件，以便包含以下代码行：
- en: '[PRE2]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: With that, you will be able to access the logs and metrics for this chapter.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，您将能够访问本章的日志和指标。
- en: Observability of a live system
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实时系统的可观测性
- en: Observability is the capability of knowing what's going on in a live system.
    We can deal with low-observability systems, where we have no way of knowing what's
    going on, or high-observability systems, where we can infer the events and internal
    state from the outside through tools.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 可观测性是了解实时系统发生情况的能力。我们可能会遇到低可观测性系统，我们无法了解其中发生了什么，或者高可观测性系统，我们可以通过工具从外部推断事件和内部状态。
- en: Observability is a property of the system itself. Typically, monitoring is the
    action of obtaining information about the current or past state of the system.
    It's all a bit of a naming debate, but you monitor the system to collect the observable
    parts of it.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 可观测性是系统本身的属性。通常，监控是获取有关系统当前或过去状态的信息的行为。这有点命名上的争议，但你要监控系统以收集其中可观测的部分。
- en: For the most part, monitoring is easy. There are great tools out there that
    can help us capture and analyze information and present it in all kinds of ways.
    However, the system needs to expose the relevant information so that it can be
    collected.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，监控是很容易的。有很多出色的工具可以帮助我们捕获和分析信息，并以各种方式呈现。但是，系统需要暴露相关信息，以便可以收集。
- en: Exposing the correct amount of information is difficult. Too much information
    will produce a lot of noise that will hide the relevant signal. Too little information
    will not be enough to detect problems. In this chapter, we will look at different
    strategies to combat this, but every system will have to explore and discover
    this on its own. Expect to experiment and make changes in your own system!
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 暴露正确数量的信息是困难的。太多信息会产生很多噪音，会掩盖相关信号。信息太少将不足以检测问题。在本章中，我们将探讨不同的策略来解决这个问题，但每个系统都必须自行探索和发现。期望在自己的系统中进行实验和更改！
- en: Distributed systems, such as the ones that follow a microservice architecture,
    also present problems as the complexity of the system can make it difficult to
    understand its internal state. Behavior can be also unpredictable in some circumstances.
    This kind of system at scale is inherently never completely healthy; there will
    always be minor problems here and there. You need to develop a priority system
    to determine what problems require immediate action and which ones can be solved
    at a later stage.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式系统，例如遵循微服务架构的系统，也会出现问题，因为系统的复杂性可能会使其内部状态难以理解。在某些情况下，行为也可能是不可预测的。这种规模的系统本质上永远不会完全健康；总会有一些小问题。您需要制定一个优先级系统，以确定哪些问题需要立即解决，哪些可以在以后解决。
- en: The main tools for the observability of microservices are **logs** and **metrics**.
    They are well-understood and used by the community, and there are plenty of tools
    that greatly simplify their usage, both as packages that can be installed locally
    and as cloud services that can help with data retention and the reduction of maintenance
    costs.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务可观测性的主要工具是**日志**和**指标**。它们为社区所熟知，并且有许多工具大大简化了它们的使用，既可以作为可以在本地安装的软件包，也可以作为云服务，有助于数据保留和降低维护成本。
- en: Using cloud services for monitoring will save you from maintenance costs. We
    will talk about this later in the *Setting up logs* and *Setting up metrics* sections.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用云服务进行监控将节省您的维护成本。我们将在*设置日志*和*设置指标*部分稍后讨论这一点。
- en: Another alternative when it comes to observability is services such as Data
    Dog ([https://www.datadoghq.com/](https://www.datadoghq.com/)) and New Relic ([https://newrelic.com/](https://newrelic.com/)).
    They receive events – normally logs – and are able to derive metrics from there.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在可观察性方面的另一种选择是诸如Data Dog（[https://www.datadoghq.com/](https://www.datadoghq.com/)）和New
    Relic（[https://newrelic.com/](https://newrelic.com/)）等服务。它们接收事件——通常是日志——并能够从中推导出指标。
- en: The most important details of the state of the cluster can be checked through
    `kubectl`, as we saw in previous chapters. This will include details such as the
    versions that have been deployed, restarts, pulling images, and so on.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 集群状态的最重要细节可以通过`kubectl`进行检查，就像我们在之前的章节中看到的那样。这将包括已部署的版本、重启、拉取镜像等详细信息。
- en: 'For production environments, it may be good to deploy a web-based tool to display
    this kind of information. Check out Weave Scope, an open source tool that shows
    data in a web page similar to the one that can be obtained with `kubectl`, but
    in a nicer and more graphical way. You can find out more about this tool here:
    [https://www.weave.works/oss/scope/](https://www.weave.works/oss/scope/).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于生产环境，部署一个基于Web的工具来显示这种信息可能是一个好主意。查看Weave Scope，这是一个开源工具，可以在网页上显示数据，类似于可以使用`kubectl`获得的数据，但以更美观和更图形化的方式。您可以在这里了解更多关于这个工具的信息：[https://www.weave.works/oss/scope/](https://www.weave.works/oss/scope/)。
- en: Logs and metrics have different objectives, and both can be intricate. We will
    look at some common usages of them in this book.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 日志和指标有不同的目标，两者都可能很复杂。我们将在本书中看一些它们的常见用法。
- en: Understanding logs
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解日志
- en: Logs track unique events that occur in the system. Each log stores a message,
    which is produced when a specific part of the code is executed. Logs can be totally
    generic (*function X is called*) or include specific details (*function X is called
    with parameter A*).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 日志跟踪系统中发生的唯一事件。每个日志都存储一个消息，当代码的特定部分被执行时产生。日志可以是完全通用的（*调用函数X*）或包含特定细节（*使用参数A调用函数X*）。
- en: The most common format for logs is to generate them as plain strings. This is
    very flexible, and normally log-related tools work with text searches.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 日志的最常见格式是将它们生成为纯文本。这非常灵活，通常与与日志相关的工具一起使用文本搜索。
- en: Each log includes some metadata about who produced the log, what time it was
    created, and more. This is also normally encoded as text, at the beginning of
    the log. A standard format helps with sorting and filtering.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 每个日志都包含一些关于谁产生了日志、创建时间等元数据。这通常也被编码为文本，出现在日志的开头。标准格式有助于排序和过滤。
- en: Logs also include a severity level. This allows for categorization so that we
    can capture the importance of the messages. The severity level can be, in order
    of importance, `DEBUG`, `INFO`, `WARNING`, or `ERROR`. This severity allows us
    to filter out unimportant logs and determine actions that we should take. The
    logging facility can be configured to set a threshold; less severe logs are ignored.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 日志还包括严重级别。这允许对消息的重要性进行分类。严重级别可以按重要性顺序为`DEBUG`、`INFO`、`WARNING`或`ERROR`。这种严重性允许我们过滤掉不重要的日志，并确定我们应该采取的行动。日志记录设施可以配置为设置阈值；较不严重的日志将被忽略。
- en: There are many severity levels, and you can define custom intermediate levels
    if you wish. However, this isn't very useful except in very specific situations.
    Later in this chapter, in the *Detecting problems through logs* section, we will
    describe how to set a strategy per level; too many levels can add confusion.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多严重级别，如果您愿意，可以定义自定义中间级别。然而，除非在非常特定的情况下，否则这并不是非常有用。在本章后面的*通过日志检测问题*部分，我们将描述如何针对每个级别设置策略；太多级别会增加混乱。
- en: 'In a web service environment, most of the logs will be generated as part of
    the response for a web request. This means that a request will arrive at the system,
    be processed, and return a value. Several logs will be generated along the way.
    Keep in mind that, in a system under load, multiple requests will be happening
    simultaneously, so the logs from multiple requests will also be generated simultaneously.
    For example, note how the second log comes from a different IP:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在Web服务环境中，大多数日志将作为对Web请求的响应的一部分生成。这意味着请求将到达系统，被处理，并返回一个值。沿途将生成多个日志。请记住，在负载下的系统中，多个请求将同时发生，因此多个请求的日志也将同时生成。例如，注意第二个日志来自不同的IP：
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: A common request ID can be added to group all the related logs that have been
    produced for a single request. We will see how to do this later in this chapter.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的请求ID可以添加到所有与单个请求相关的日志中。我们将在本章后面看到如何做到这一点。
- en: Each individual log can be relatively big and, in aggregate, use significant
    disk space. Logs can quickly grow out of proportion in a system under load. The
    different log systems allow us to tweak their retention time, which means that
    we only keep them for a certain amount of time. Finding the balance between keeping
    logs to see what happened in the past and using a sane amount of space is important.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 每个单独的日志可能相对较大，并且在聚合时会占用大量磁盘空间。在负载下的系统中，日志可能会迅速膨胀。不同的日志系统允许我们调整其保留时间，这意味着我们只保留它们一段时间。在保留日志以查看过去发生的事情和使用合理的空间之间找到平衡是很重要的。
- en: Be sure to check the retention policies when enabling any new log service, whether
    it be local or cloud-based. You won't be able to analyze what happened before
    the time window. Double-check that the progress rate is as expected – you don't
    want to find out that you went unexpectedly over quota while you were tracking
    a bug.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在启用任何新的日志服务时，请务必检查保留策略，无论是本地还是基于云的。您将无法分析发生在时间窗口之前的情况。仔细检查进度是否符合预期——您不希望在跟踪错误时意外超出配额。
- en: Some tools allow us to use raw logs to generate aggregated results. They can
    count the number of times a particular log appears and generate the average times
    per minute or other statistics. This is expensive, though, as each log takes space.
    To observe this aggregated behavior, it is better to use a specific metrics system.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Understanding metrics
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Metrics deal with aggregated information. They show information related not
    to a single event, but a group of them. This allows us to check the general status
    of the cluster in a better way than using logs.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: We will use typical examples related to web services, mainly dealing with requests
    metrics, but don't feel restricted by them. You can generate your own metrics
    that are specific to your service!
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Where a log keeps information about each individual event, metrics reduce the
    information to the number of times the event happens or reduce them to a value
    that can then be averaged or aggregated in a certain way.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: This makes metrics much more lightweight than logs and allows us to plot them
    against time. Metrics present information such as the number of requests per minute,
    the average time for a request during a minute, the number of queued requests,
    the number of errors per minute, and so on.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: The resolution of the metrics may depend on the tool that was used to aggregate
    them. Keep in mind that a higher resolution will require more resources. A typical
    resolution is 1 minute, which is small enough to present detailed information
    unless you have a very active system that receives 10 or more requests per second.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Capturing and analyzing information related to performance, such as the average
    request time, allows us to detect possible bottlenecks and act quickly in order
    to improve the performance of the system. This is much easier to deal with on
    average since a single request may not capture enough information for us to see
    the big picture. It also helps us predict future bottlenecks.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many different kinds of metrics, depending on the tool that''s used.
    The most commonly supported ones are as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '**Counter**: A trigger is generated each time something happens. This will
    be counted and aggregated. An example of this is the number of requests and the
    number of errors.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gauge**: A single number that is unique. It can go up or down, but the last
    value overwrites the previous. An example of this is the number of requests in
    the queue and the number of available workers.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Measure**: Events that have a number associated with them. These numbers
    can be averaged, summed, or aggregated in some way. Compared with gauges, the
    difference is that previous measures are still independent; for example, when
    we request time in milliseconds and request size in bytes. Measures can also work
    as counters since their number can be important; for example, tracking the request
    time also counts the number of requests.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are two main ways in which metrics work:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Each time something happens, an event gets *pushed* toward the metrics collector.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each system maintains their own metrics, which are then *pulled* from the metrics
    system periodically.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each way has its own pros and cons. Pushing events produces higher traffic as
    every event needs to be sent; this can cause bottlenecks and delays. Pulling events
    will only sample the information and miss exactly what happened between the samples,
    but it's inherently more scalable.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: While both approaches are used, the trend is moving toward pulling systems for
    metrics. They reduce the maintenance that's required for pushing systems and are
    much more easier to scale.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: We will set up Prometheus, which uses the second approach. The most used exponent
    of the first approach is Graphite.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: Metrics can also be combined to generate other metrics; for example, we can
    divide the number of requests that return errors by the total number of requests
    that generate error requests. Such derived metrics can help us present information
    in a meaningful way.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: 'Multiple metrics can be displayed in dashboards so that we can understand the
    status of a service or cluster. At a glance, these graphical tools allow us to
    detect the general state of the system. We will set Grafana so that it displays
    graphical information:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 多个指标可以显示在仪表板上，这样我们就可以了解服务或集群的状态。通过这些图形工具，我们可以一目了然地检测系统的一般状态。我们将设置Grafana，以显示图形信息：
- en: '![](img/1d334374-d1df-4f9f-a7ac-07ccd296c87a.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1d334374-d1df-4f9f-a7ac-07ccd296c87a.png)'
- en: Compared to logs, metrics take up much less space and they can capture a bigger
    window of time. It's even possible to keep metrics for the system's life. This
    differs compared to logs, which can never be stored for that long.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 与日志相比，指标占用的空间要少得多，可以捕获更长的时间窗口。甚至可以保留系统的生命周期内的指标。这与日志不同，日志永远无法存储那么长时间。
- en: Setting up logs
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置日志
- en: We will centralize all the logs that are generated by the system into a single
    pod. In local development, this pod will expose all the received logs through
    a web interface.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把系统生成的所有日志集中到一个单独的pod中。在本地开发中，这个pod将通过Web界面公开所有接收到的日志。
- en: The logs will be sent over the `syslog` protocol, which is the most standard
    way of transmitting them. There's native support for `syslog` in Python, as well
    as in virtually any system that deals with logging and has Unix support.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 日志将通过`syslog`协议发送，这是传输日志的最标准方式。Python中有`syslog`的原生支持，几乎任何处理日志并具有Unix支持的系统都有。
- en: Using a single container makes it easy to aggregate logs. In production, this
    system should be replaced with a container that relays the received logs to a
    cloud service such as Loggly or Splunk.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用单个容器可以轻松聚合日志。在生产环境中，应该用一个容器来替换这个系统，将接收到的日志传送到Loggly或Splunk等云服务。
- en: There are multiple `syslog` servers that are capable of receiving logs and aggregating
    them; `syslog-ng` ([https://www.syslog-ng.com/](https://www.syslog-ng.com/)) and
    `rsyslog` ([https://www.rsyslog.com/](https://www.rsyslog.com/)) are the most
    common ones. The simplest method is to receive the logs and to store them in a
    file. Let's start a container with an `rsyslog` server, which will store the received
    logs.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 有多个`syslog`服务器可以接收日志并进行聚合；`syslog-ng` ([https://www.syslog-ng.com/](https://www.syslog-ng.com/))和`rsyslog`
    ([https://www.rsyslog.com/](https://www.rsyslog.com/))是最常见的。最简单的方法是接收日志并将其存储在文件中。让我们启动一个带有`rsyslog`服务器的容器，它将存储接收到的日志。
- en: Setting up an rsyslog container
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置rsyslog容器
- en: In this section, we will create our own `rsyslog` server. This is a very simple
    container, and you can check `docker-compose` and `Dockerfile` on GitHub for more
    information regarding logs ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/kubernetes/logs](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/kubernetes/logs)).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将创建自己的`rsyslog`服务器。这是一个非常简单的容器，您可以在GitHub上查看有关日志的`docker-compose`和`Dockerfile`的更多信息([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/kubernetes/logs](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/kubernetes/logs))。
- en: We will set up logs using the UDP protocol. This is the standard protocol for
    `syslog`, but it's less common than the usual HTTP over TCP that's used for web
    development.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用UDP协议设置日志。这是`syslog`的标准协议，但比用于Web开发的通常的TCP上的HTTP要少见。
- en: The main difference is that UDP is connectionless, so the log is sent and no
    confirmation that it has been delivered is received. This makes UDP lighter and
    faster, but also less reliable. If there's a problem in the network, some logs
    may disappear without warning.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 主要区别在于UDP是无连接的，因此日志被发送后不会收到已传递的确认。这使得UDP更轻更快，但也更不可靠。如果网络出现问题，一些日志可能会无预警地消失。
- en: This is normally an adequate trade-off since the number of logs is high and
    the implications of losing a few isn't big. `syslog` can also work over TCP, thus
    increasing reliability but also reducing the performance of the system.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常是一个合理的权衡，因为日志数量很大，丢失一些日志的影响并不大。`syslog`也可以通过TCP工作，从而增加可靠性，但也降低了系统的性能。
- en: 'The Dockerfile installs `rsyslog` and copies its configuration file:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Dockerfile安装了`rsyslog`并复制了其配置文件：
- en: '[PRE4]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The configuration file mainly starts the server at port `5140` and stores the
    received files in `/var/log/syslog`:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 配置文件主要是在端口`5140`启动服务器，并将接收到的文件存储在`/var/log/syslog`中：
- en: '[PRE5]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: With log rotation, we set a limit on the side of the `/var/log/syslog` file
    so that it doesn't grow without limits.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 通过日志轮换，我们设置了`/var/log/syslog`文件的大小限制，以防止其无限增长。
- en: 'We can build the container with the usual `docker-compose` command:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用通常的`docker-compose`命令构建容器：
- en: '[PRE6]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This will create a combination of a pod, a service, and an Ingress, as we did
    with the other microservices, to collect logs and allow external access from a
    browser.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个pod、一个服务和一个Ingress的组合，就像我们对其他微服务所做的那样，以收集日志并允许从浏览器进行外部访问。
- en: Defining the syslog pod
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义syslog pod
- en: The `syslog` pod will contain the `rsyslog` container and another container
    to display the logs.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`syslog` pod将包含`rsyslog`容器和另一个用于显示日志的容器。'
- en: To display the logs, we will use front rail, an application that streams log
    files to a web server. We need to share the file across both containers in the
    same pod, and the simplest way to do this is through a volume.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了显示日志，我们将使用front rail，这是一个将日志文件流式传输到Web服务器的应用程序。我们需要在同一个pod中的两个容器之间共享文件，最简单的方法是通过卷。
- en: We control the pod using a deployment. You can check the deployment configuration
    file at [https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/kubernetes/logs/deployment.yaml](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/kubernetes/logs/deployment.yaml).
    Let's take a look at its most interesting parts in the following subsections.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用部署来控制pod。您可以在[https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/kubernetes/logs/deployment.yaml](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/kubernetes/logs/deployment.yaml)中检查部署配置文件。让我们在以下小节中看一下它最有趣的部分。
- en: log-volume
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: log-volume
- en: '`log-volume` creates an empty directory that is shared across both containers:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '`log-volume`创建了一个空目录，该目录在两个容器之间共享：'
- en: '[PRE7]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This allows the containers to communicate while storing information in a file.
    The `syslog` container will write to it while the front rail one will read from
    it.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这允许容器在存储信息的同时进行通信。`syslog`容器将向其中写入，而前端容器将从其中读取。
- en: syslog container
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: syslog容器
- en: 'The `syslog` container starts an `rsyslogd` process:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '`syslog`容器启动了一个`rsyslogd`进程：'
- en: '[PRE8]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `rsyslogd -n -f /etc/rsyslog.d/rsyslog.conf` command starts the server with
    the configured file we described previously. The `-n` parameter keeps the process
    in the foreground, thereby keeping the container running.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`rsyslogd -n -f /etc/rsyslog.d/rsyslog.conf`命令使用我们之前描述的配置文件启动服务器。`-n`参数将进程保持在前台，从而保持容器运行。'
- en: The UDP port `5140`, which is the defined port to receive logs, is specified,
    and `log-volume` is mounted to `/var/log`. Later in the file, `log-volume` will
    be defined.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 指定了UDP端口`5140`，这是接收日志的定义端口，并且将`log-volume`挂载到`/var/log`。文件的后面将定义`log-volume`。
- en: The front rail container
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前端容器
- en: 'The front rail container is started from the official container image:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 前端容器是从官方容器镜像启动的：
- en: '[PRE9]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We start it with the `frontrail /var/log/syslog` command, specify port `9001`
    (which is the one we use to access `frontrail`), and mount `/var/log`, just like
    we did with the `syslog` container, to share the log file.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`frontrail /var/log/syslog`命令启动它，指定端口`9001`（这是我们用来访问`frontrail`的端口），并挂载`/var/log`，就像我们用`syslog`容器一样，以共享日志文件。
- en: Allowing external access
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 允许外部访问
- en: As we did with the other microservices, we will create a service and an Ingress.
    The service will be used by other microservices so they can send their logs. The
    Ingress will be used to access the web interface so that we can see the logs as
    they arrive.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他微服务一样，我们将创建一个服务和一个Ingress。服务将被其他微服务使用，以便它们可以发送它们的日志。Ingress将用于访问Web界面，以便我们可以在日志到达时查看日志。
- en: The YAML files are on GitHub ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/kubernetes/logs](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/kubernetes/logs))
    in the `service.yaml` and `ingress.yaml` files, respectively.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: YAML文件位于GitHub上（[https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/kubernetes/logs](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/kubernetes/logs)），分别是`service.yaml`和`ingress.yaml`文件。
- en: 'The service is very straightforward; the only peculiarity is that it has two
    ports – one TCP port and one UDP port – and each one connects to a different container:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 服务非常简单；唯一的特殊之处在于它有两个端口 - 一个TCP端口和一个UDP端口 - 每个端口连接到不同的容器：
- en: '[PRE10]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The Ingress only exposes the front rail port, which means we can access it
    through the browser. Remember that the DNS needs to be added to your `/etc/host`
    file, as described at the start of this chapter:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Ingress只暴露了前端端口，这意味着我们可以通过浏览器访问它。请记住，DNS需要添加到您的`/etc/host`文件中，就像本章开头所描述的那样：
- en: '[PRE11]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Going to `http://syslog.example.local` in your browser will allow you to access
    the front rail interface:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在浏览器中输入`http://syslog.example.local`将允许您访问前端界面：
- en: '![](img/f6ccd237-8812-48f4-90a1-b5c971772d3a.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f6ccd237-8812-48f4-90a1-b5c971772d3a.png)'
- en: You can filter the logs using the box in the top-right corner.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用右上角的框来过滤日志。
- en: Remember that, most of the time, logs reflect the readiness and liveness probes,
    as shown in the preceding screenshot. The more health checks you have in your
    system, the more noise you'll get.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，大多数时候，日志反映了就绪和存活探针，如前面的屏幕截图所示。您的系统中有更多的健康检查，您将会得到更多的噪音。
- en: You can filter them out at the `syslog` level by configuring the `rsyslog.conf`
    file, but be careful not to leave out any relevant information.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过配置`rsyslog.conf`文件在`syslog`级别上将其过滤掉，但要小心不要遗漏任何相关信息。
- en: Now, we need to see how the other microservices configure and send their logs
    here.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要看看其他微服务如何配置并将它们的日志发送到这里。
- en: Sending logs
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发送日志
- en: We need to configure the microservices in uWSGI so that we can forward the logs
    to the logging service. We will use the Thoughts Backend as an example, even though
    the Frontend and Users Backend, which can be found under the `Chapter10/microservices`
    directory, also have this configuration enabled.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要在uWSGI中配置微服务，以便我们可以将日志转发到日志服务。我们将使用Thoughts Backend作为示例，即使Frontend和Users
    Backend也有这个配置，可以在`Chapter10/microservices`目录下找到。
- en: 'Open the `uwsgi.ini` configuration file ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/docker/app/uwsgi.ini](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/docker/app/uwsgi.ini)).
    You''ll see the following line:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 打开`uwsgi.ini`配置文件（[https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/docker/app/uwsgi.ini](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/docker/app/uwsgi.ini)）。您将看到以下行：
- en: '[PRE12]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This sends the logs, in `rsyslog` format, toward the `syslog` service at port
    `5140`. We also add the *facility*, which is where the logs come from. This adds
    the string to all the logs coming from this service, which helps with sorting
    and filtering. Each `uwsgi.ini` file should have its own facility to help with
    filtering.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这将以`rsyslog`格式发送日志到端口`5140`的`syslog`服务。我们还添加了*facility*，这是日志来源的地方。这将为来自此服务的所有日志添加字符串，有助于排序和过滤。每个`uwsgi.ini`文件应该有自己的facility以帮助过滤。
- en: In old systems that support the `syslog` protocol, the facility needs to fit
    predetermined values such as `KERN`, `LOCAL_7`, and more. But in most modern systems,
    this is an arbitrary string that can take any value.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在支持`syslog`协议的旧系统中，facility需要符合预定值，例如`KERN`，`LOCAL_7`等。但在大多数现代系统中，这是一个任意的字符串，可以取任何值。
- en: Automatic logs by uWSGI are interesting, but we also need to set up our own
    logs for custom tracking. Let's see how.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: uWSGI自动记录很有趣，但我们还需要为自定义跟踪设置自己的日志。让我们看看如何做。
- en: Generating application logs
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成应用程序日志
- en: 'Flask automatically configures a logger for the app. We need to add a log in
    the following way, as shown in the `api_namespace.py` file ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/api_namespace.py#L102](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/api_namespace.py#L102)):'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Flask自动为应用程序配置了一个记录器。我们需要以以下方式添加日志，如`api_namespace.py`文件中所示（[https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/api_namespace.py#L102](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/api_namespace.py#L102)）：
- en: '[PRE13]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '`app.logger` can call `.debug`, `.info`, `.warning`, or `.error` to generate
    a log. Note that `app` can be retrieved by importing `current_app`.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`app.logger`可以调用`.debug`、`.info`、`.warning`或`.error`来生成日志。请注意，可以通过导入`current_app`来检索`app`。'
- en: The logger follows the standard `logging` module in Python. It can be configured
    in different ways. Take a look at the `app.py` file ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py))
    to view the different configuration we'll be going through in the following subsections.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 记录器遵循Python中的标准`logging`模块。它可以以不同的方式进行配置。查看`app.py`文件（[https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py)）以查看我们将在以下子部分中进行的不同配置。
- en: Dictionary configuration
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 字典配置
- en: 'The first level of logging goes through the default `dictConfig` variable.
    This variable is automatically defined by Flask and allows us to configure the
    logs in the way that''s defined in the Python documentation ([https://docs.python.org/3.7/library/logging.config.html](https://docs.python.org/3.7/library/logging.config.html)).
    You can check the definition of logging in the `app.py` file:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 第一级别的日志记录通过默认的`dictConfig`变量。这个变量由Flask自动定义，并允许我们按照Python文档中定义的方式配置日志（[https://docs.python.org/3.7/library/logging.config.html](https://docs.python.org/3.7/library/logging.config.html)）。您可以在`app.py`文件中查看日志的定义：
- en: '[PRE14]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The `dictConfig` dictionary has three main levels:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '`dictConfig`字典有三个主要级别：'
- en: '`formatters`: This checks how the log is formatted. To define the format, you
    can use the automatic values that are available in the Python documentation ([https://docs.python.org/3/library/logging.html#logrecord-attributes](https://docs.python.org/3/library/logging.html#logrecord-attributes)).
    This gathers information for every log.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`formatters`：这检查日志的格式。要定义格式，可以使用Python文档中提供的自动值（[https://docs.python.org/3/library/logging.html#logrecord-attributes](https://docs.python.org/3/library/logging.html#logrecord-attributes)）。这收集每个日志的信息。'
- en: '`handlers`: This checks where the log goes to. You can assign one or more to
    the loggers. We defined a handler called `wsgi` and configured it so that it goes
    up, toward uWSGI.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`handlers`：这检查日志的去向。您可以将一个或多个分配给记录器。我们定义了一个名为`wsgi`的处理程序，并对其进行了配置，以便将其发送到uWSGI。'
- en: '`root`: This is the top level for logs, so anything that wasn''t previously
    logged will refer to this level. We configure the `INFO` logging level here.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`root`：这是日志的顶层，因此以前未记录的任何内容都将参考此级别。我们在这里配置`INFO`日志级别。'
- en: This sets up default configuration so that we don't miss any logs. However,
    we can create even more complex logging handlers.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这将设置默认配置，以便我们不会错过任何日志。但是，我们可以创建更复杂的日志处理程序。
- en: Logging a request ID
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 记录请求ID
- en: One of the problems when analyzing a large number of logs is correlating them.
    We need to see which ones are related to each other. One possibility is to filter
    logs by the pod that's generating them, which is stored at the start of the log
    (for example, `10-1-0-27.frontend-service.example.svc.cluster.local`). This is
    analogous to the host generating the logs. This process, however, is cumbersome
    and, in some cases, a single container can process two requests simultaneously.
    We need a unique identifier per request that gets added to all the logs for a
    single request.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析大量日志时的一个问题是对其进行关联。我们需要看到哪些日志彼此相关。一种可能性是通过生成它们的pod来过滤日志，该pod存储在日志的开头（例如，`10-1-0-27.frontend-service.example.svc.cluster.local`）。这类似于生成日志的主机。然而，这个过程很繁琐，并且在某些情况下，单个容器可以同时处理两个请求。我们需要为每个请求添加一个唯一标识符，该标识符将添加到单个请求的所有日志中。
- en: To do so, we will use the `flask-request-id-header` package ([https://pypi.org/project/flask-request-id-header/](https://pypi.org/project/flask-request-id-header/)).
    This adds an `X-Request-ID` header (if not present) that we can use to log each
    individual request.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Why do we set up a header instead of storing a randomly generated value in memory
    for the request? This is a common pattern that allows us to inject the request
    ID into the backend. The request ID allows us to carry over the same request identifier
    through the life cycle of a request for different microservices. For example,
    we can generate it on the Frontend and pass it over to the Thoughts Backend so
    that we can trace several internal requests that have the same origin.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Although we won't be including this in our example for simplicity, as a microservices
    system grows, this becomes crucial for determining flows and origins. Generating
    a module so that we can automatically pass it over internal calls is a good investment.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows the flow between a **frontend** and two services.
    Note that the `X-Request-ID` header is not set up for the **frontend** service
    upon arrival and that it needs to be forwarded to any call:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/158370df-bab7-416c-ab69-63d258408159.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
- en: We need to also send the logs straight toward the `syslog` service so that we
    can create a handler that does this for us.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: When executing code from a script, compared to running the code in a web server,
    we don't use this handler. When running a script directly, we want our logs to
    go to the default logger we defined previously. In `create_app`, we will set up
    a parameter to differentiate between them.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: The Python logging module has a lot of interesting features. Check out the Python
    documentation for more information ([https://docs.python.org/3/library/logging.html](https://docs.python.org/3/library/logging.html)).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Setting logs properly is trickier than it looks. Don't be discouraged and keep
    tweaking them until they work.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: 'We will set up all the logging configuration in the `app.py` file. Let''s break
    up each part of the configuration:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will generate a formatter that appends the `request_id` so that it''s
    available when generating logs:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As you can see, the `HTTP_X_REQUEST_ID` header is available in the `request.environ`
    variable.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: 'Later, in `create_app`, we will set up the handler that we append to the `application`
    logger:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We only set up the handler if the run happens out of a script. `SysLogHandler`
    is included in Python. After this, we set up the format, which includes `request_id`.
    The formatter uses the `RequestFormatter` that we defined previously.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Here, we are hardcoding the values of the logger level to `INFO` and the `syslog`
    host to `syslog`, which corresponds to the service. Kubernetes will resolve this
    DNS correctly. Both values can be passed through environment variables, but we
    didn't do this here for the sake of simplicity.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: The logger hasn't been propagated, so avoid sending it to the `root` logger,
    which will duplicate the log.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Logging each request
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are common elements in every request that we need to capture. Flask allows
    us to execute code before and after a request, so we can use that to log the common
    elements of each request. Let's learn how to do this.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: 'From the `app.py` file, we will define the `logging_before` function:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This creates a log with the word `REQUEST` and two essential parts of each request
    – the method and the URI – which come from `request.environ`. Then, they're added
    to an `INFO` log with the app logger.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: We also use the `g` object to store the time when the request is started.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: The `g` object allows us to store values through a request. We will use it to
    calculate the time the request is going to take.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: 'There''s the corresponding `logging_after` function as well. It gathers the
    time at the end of the request and calculates the difference in milliseconds:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This will allow us to detect requests that are taking longer and will be stored
    in metrics, as we will see in the following section.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, the functions are enabled in the `create_app` function:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This creates a set of logs each time we generate a request.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: With the logs generated, we can search for them in the `frontrail` interface.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Searching through all the logs
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the different logs from different applications will be centralized and available
    to search for at `http://syslog.example.local`.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: 'If you make a call to `http://frontend.example.local/search?search=speak` to
    search for thoughts, you will see the corresponding Thoughts Backend in the logs,
    as shown in the following screenshot:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1254a0cc-90d6-4340-b901-95536a0a34e0.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
- en: We can filter by the request ID, that is, `63517c17-5a40-4856-9f3b-904b180688f6`,
    to get the Thoughts Backend request logs. Just after this are the `thoughts_backend_uwsgi`
    and `frontend_uwsgi` request logs, which show the flow of the request.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, you can see all the elements we talked about previously:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: The `REQUEST` log before the request
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `api_namespace` request, which contains app data
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The after `RESPONSE` logs, which contain the result and time
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Within the code for the Thoughts Backend, we left an error on purpose. It will
    be triggered if a user tries to share a new thought. We will use this to learn
    how to debug issues through logs.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: Detecting problems through logs
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For any problem in your running system, there are two kinds of errors that
    can occur: expected errors and unexpected errors.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: Detecting expected errors
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Expected errors are errors that are raised by explicitly creating an `ERROR`
    log in the code. If an error log is being generated, this means that it reflects
    a situation that has been planned in advance; for example, you can't connect to
    the database, or there is some data stored in an old, deprecated format. We don't
    want this to happen, but we saw the possibility of it happening and prepared the
    code to deal with it. They normally describe the situation well enough that the
    issue is obvious, even if the solution isn't.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: They are relatively easy to deal with since they describe foreseen problems.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Capturing unexpected errors
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unexpected errors are the other types of errors that can occur. Things break
    in unforeseen ways. Unexpected errors are normally produced by Python exceptions
    being raised at some point in the code and not being captured.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: If logging has been properly configured, any exceptions or errors that haven't
    been caught will trigger an `ERROR` log, which will include the stack trace. These
    errors may not be immediately obvious and will require further investigation.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: To help explain these errors, we introduced an exception in the code for the
    Thoughts Backend in the `Chapter10` code. You can check the code on GitHub ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend)).
    This simulates an unexpected exception.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: 'While trying to post a new thought for a logged user, we get a weird behavior
    and see the following error in the logs. As shown in the top-right corner of the
    following screenshot, we are filtering by `ERROR` to filter for problems:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3bad0ee5-9505-4648-8158-cf878d1969ad.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
- en: As you can see, the stack trace is displayed in a single line. This may depend
    on how you capture and display the logs. Flask will automatically generate an
    HTTP response with a status code of 500\. This may trigger more errors along the
    path if the caller isn't ready to receive a 500 response.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: Then, the stack trace will let you know what broke. In this case, we can see
    that there's a `raise Exception` command in the `api_namespace.py` file at line
    80\. This allows us to locate the exception.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: Since this is a synthetic error that's been generated specifically as an example,
    it is actually easy to find out the root cause. In the example code, we are explicitly
    raising an exception, which produces an error. This may not be the case in a real
    use case, where the exception could be generated in a different place than the
    actual error. Exceptions can be also originated in a different microservice within
    the same cluster.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: After detecting the error, the objective should be to replicate it with a unit
    test in the microservice in order to generate the exception. This will allow us
    to replicate the conditions in a controlled environment.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: 'If we run the tests for the Thoughts Backend code that''s available in `Chapter10`,
    we will see errors because of this. Note that the logs are being displayed in
    failing tests:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Once the error has been reproduced in unit tests, fixing it will often be trivial.
    Add a unit test to capture the set of conditions that trigger the error and then
    fix it. The new unit test will detect whether the error has been reintroduced
    on each automated build.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: To fix the example code, remove the `raise` line of code. Then, things will
    work again.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, the problem cannot be solved as it may be external. Maybe there's
    a problem in some of the rows in our database or maybe another service is returning
    incorrectly formatted data. In those cases, we can't completely avoid the root
    cause of the error. However, it's possible to capture the problem, do some remediation,
    and move from an unexpected error to an expected error.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Note that not every detected unexpected error is worth spending time on. Sometimes,
    uncaptured errors provide enough information on what the problem is, which is
    out of the realm of what the web service should handle; for example, there may
    be a network problem and the web service can't connect to the database. Use your
    judgment when you want to spend time on development.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: Logging strategy
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There's a problem when we're dealing with logs. What is the adequate level for
    a particular message? Is this a `WARNING` or an `ERROR`? Should this be an `INFO`
    statement?
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Most of the log level descriptions use definitions such as *the program shows
    a potentially harmful situation* or *the program highlights the progress of the
    request*. These are vague and not very useful in a real-life environment. Instead,
    try to define each log level by relating them to the expected follow-up action.
    This helps provide clarity on what to do when a log of a particular level is found.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table shows some examples of the different levels and what action
    should be taken:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '| **Log level** | **Action to take** | **Comments** |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
- en: '| `DEBUG` | Nothing. | Not tracked. |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
- en: '| `INFO` | Nothing. | The `INFO` logs show generic information about the flow
    of the request to help track problems. |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
- en: '| `WARNING` | Track number. Alert on raising levels. | The `WARNING` logs track
    errors that have been automatically fixed, such as retries to connect (but finally
    connecting) or fixable formatting errors in the database''s data. A sudden increase
    may require investigation. |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
- en: '| `ERROR` | Track number. Alert on raising levels. Review all. | The `ERROR`
    logs track errors that can''t be fixed. A sudden increase may require immediate
    action so that this can be remediated. |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
- en: '| `CRITICAL` | Immediate response. | A `CRITICAL` log indicates a catastrophic
    failure in the system. Even one will indicate that the system is not working and
    can''t recover. |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
- en: This is just a recommendation, but it sets clear expectations on how to respond.
    Depending on how your teams and your expected level of service work, you can adapt
    them to your use case.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: Here, the hierarchy is very clear, and there's an acceptance that a certain
    number of `ERROR` logs will be generated. Not everything needs to be fixed immediately,
    but they should be noted and reviewed.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: In real life, `ERROR` logs will be typically categorized as "we're doomed" or
    "meh." Development teams should actively either fix or remove "mehs" to reduce
    them as much as possible. That may include lowering the level of logs if they
    aren't covering actual errors. You want as few `ERROR` logs as possible, but all
    of them need to be meaningful.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Be pragmatic, though. Sometimes, errors can't be fixed straight away and time
    is best utilized in other tasks. However, teams should reserve time to reduce
    the number of errors that occur. Failing to do so will compromise the reliability
    of the system in the medium term.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '`WARNING` logs are indications that something may not be working as smoothly
    as we expected, but there''s no need to panic unless the numbers grow. `INFO`
    is just there to give us context if there''s a problem, but otherwise should be
    ignored.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: Avoid the temptation to produce an `ERROR` log when there's a request returning
    a 400 BAD REQUEST status code. Some developers will argue that if the customer
    sent a malformed request, it is actually an error. But this isn't something that
    you should care about if the request has been properly detected and returned.
    This is business as usual. If this behavior can lead to indicate something else,
    such as repeated attempts to send incorrect passwords, you can set a `WARNING`
    log. There's no point in generating `ERROR` logs when your system is behaving
    as expected.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: As a rule of thumb, if a request is not returning some sort of 500 error (500,
    502, 504, and so on), it should not generate an `ERROR` log. Remember the categorization
    of 400 errors as *you (customer) have a problem* versus 500 errors, which are
    categorized as *I have a problem*.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: This is not absolute, though. For example, a spike in authentication errors
    that are normally 4XX errors may indicate that users cannot create logs due to
    a real internal problem.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: With these definitions in mind, your development and operations teams will have
    a shared understanding that will help them take meaningful actions.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Expect to tweak the system and change some of the levels of the logs as your
    system matures.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Adding logs while developing
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we've already seen, properly configuring `pytest` will make any errors in
    tests display the captured logs.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: This is an opportunity to check that the expected logs are being generated while
    a feature is in development. Any test that checks error conditions should also
    add its corresponding logs and check that they are being generated during the
    development of the feature.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: You can check the logs as part of testing with a tool such as `pytest-catchlog`
    ([https://pypi.org/project/pytest-catchlog/](https://pypi.org/project/pytest-catchlog/))
    to enforce that the proper logs are being produced.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: Typically, though, just taking a bit of care and checking during development
    that logs are produced is enough for most cases. However, be sure that developers
    understand why it's useful to have logs while they're developing.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: During development, `DEBUG` logs can be used to show extra information about
    the flow that will be too much for production. This may fill in the gaps between
    `INFO` logs and help us develop the habit of adding logs. A `DEBUG` log may be
    promoted to `INFO` if, during tests, it's discovered that it will be useful for
    tracking problems in production.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: Potentially, `DEBUG` logs can be enabled in production in controlled cases to
    track some difficult problems, but be aware of the implications of having a large
    number of logs.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Be sensible with the information that's presented in `INFO` logs. In terms of
    the information that's displayed, avoid sensible data such as passwords, secret
    keys, credit card numbers, or personal information. This is the same for the number
    of logs.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: Keep an eye on any size limitations and how quickly logs are being generated.
    Growing systems may have a log explosion while new features are being added, more
    requests are flowing through the system, and new workers are being added.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: Also, double-check that the logs are being generated and captured correctly
    and that they work at all the different levels and environments. All of this configuration
    may take a bit of time, but you need to be very sure that you can capture unexpected
    errors in production and that all the plumbing is set correctly.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the other key element when it comes to observability:
    metrics.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: Setting up metrics
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To set up metrics with Prometheus, we need to understand how the process works.
    Its key component is that each service that's measured has its own Prometheus
    client that keeps track of the metrics. The data in the Prometheus server will
    be available for a Grafana service that will plot the metrics.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows the general architecture:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5b14900d-d4cd-4768-a10b-7a918425d553.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
- en: The Prometheus server pulls information at regular intervals. This method of
    operation is very lightweight since registering metrics just updates the local
    memory of the service and scales well. On the other hand, it shows sampled data
    at certain times and doesn't register each individual event. This has certain
    implications in terms of storing and representing data and imposes limitations
    on the resolution of the data, especially for very low rates.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: 'There are lots of available metrics exporters that will expose standard metrics
    in different systems, such as databases, hardware, HTTP servers, or storage. Check
    out the Prometheus documentation for more information: [https://prometheus.io/docs/instrumenting/exporters/](https://prometheus.io/docs/instrumenting/exporters/).'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: This means that each of our services needs to install a Prometheus client and
    expose its collected metrics in some way. We will use standard clients for Flask
    and Django.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: Defining metrics for the Thoughts Backend
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For Flask applications, we will use the `prometheus-flask-exporter` package
    ([https://github.com/rycus86/prometheus_flask_exporter](https://github.com/rycus86/prometheus_flask_exporter)),
    which has been added to `requirements.txt`.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: It gets activated in the `app.py` file ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py#L95](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py#L95))
    when the application is created.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: 'The `metrics` object is set up with no app, and is then instantiated in the
    `created_app` function:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This generates an endpoint in the `/metrics` service endpoint, that is, `http://thoughts.example.local/metrics`,
    which returns the data in Prometheus format. The Prometheus format is plain text,
    as shown in the following screenshot:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/81ba132d-890c-4b57-96db-46bbfca38f44.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
- en: The default metrics that are captured by `prometheus-flask-exporter` are request
    calls based on the endpoint and the method (`flask_http_request_total`), as well
    as the time they took (`flask_http_request_duration_seconds`).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: Adding custom metrics
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We may want to add more specific metrics when it comes to application details.
    We also added some extra code at the end of the request so that we can store similar
    information to the metric that `prometheus-flask-exporter` allows us to.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: In particular, we added this code to the `logging_after` function ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py#L72](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py#L72))
    using the lower-level `prometheus_client`.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: 'This code creates `Counter` and `Histogram`:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here, we''ve created two metrics: a counter called `requests` and a histogram
    called `req_time`. A histogram is a Prometheus implementation of measures and
    events that have a specific value, such as the request time (in our case).'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: The histogram stores the values in buckets, thereby making it possible for us
    to calculate quantiles. Quantiles are very useful to determine metrics such as
    the 95% value for times, such as the aggregate time, where 95% comes lower than
    it. This is much more useful than averages since outliers won't pull from the
    average.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: There's another similar metric called summary. The differences are subtle, but
    generally, the metric we should use is a histogram. Check out the Prometheus documentation
    for more details ([https://prometheus.io/docs/practices/histograms/](https://prometheus.io/docs/practices/histograms/)).
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: The metrics are defined in `METRIC_REQUESTS` and `METRIC_REQ_TIME` by their
    name, their measurement, and the labels they define. Each label is an extra dimension
    of the metric, so you will be able to filter and aggregate by them. Here, we define
    the endpoint, the HTTP method, and the resulting HTTP status code.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: For each request, the metric is updated. We need to set up the labels, the counter
    calls, that is, `.inc()`, and the histogram calls, that is, `.observe(time)`.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: You can find the documentation for the Prometheus client at [https://github.com/prometheus/client_python](https://github.com/prometheus/client_python).
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: We can see the `request` and `req_time` metrics on the metrics page.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '**Setting up metrics for the Users Backend follows a similar pattern.** The
    Users Backend is a similar Flask application, so we install `prometheus-flask-exporter`
    as well, but no custom metrics. You can access these metrics at `http://users.example.local/metrics`.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: The next stage is to set up a Prometheus server so that we can collect the metrics
    and aggregate them properly.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: Collecting the metrics
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this, we need to deploy the metrics using Kubernetes. We prepared a YAML
    file with everything set up already in the `Chapter10/kubernetes/prometheus.yaml`
    file.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: This YAML file contains a deployment, a `ConfigMap`, which contains the configuration
    file, a service, and an Ingress. The service and Ingress are pretty standard,
    so we won't comment on them here.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ConfigMap` allows us to define a file:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Note how the `prometheus.yaml` file is generated after the `|` symbol. This
    is a minimal Prometheus configuration scraping from the `thoughts-service`, `users-service`,
    and `frontend-service` servers. As we know from the previous chapters, these names
    access the services and will connect to the pods that are serving the applications.
    They will automatically search for the `/metrics` path.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: There is a small caveat here. From the point of view of Prometheus, everything
    behind the service is the same server. If you have more than one pod being served,
    the metrics that are being accessed by Prometheus will be load balanced and the
    metrics won't be correct.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: This is fixable with a more complicated Prometheus setup whereby we install
    the Prometheus operator, but this is out of the scope of this book. However, this
    is highly recommended for a production system. In essence, it allows us to annotate
    each of the different deployments so that the Prometheus configuration is dynamically
    changed. This means we can access all the metrics endpoints exposed by the pods
    automatically once this has been set up. Prometheus Operator annotations make
    it very easy for us to add new elements to the metrics system.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following article if you want to learn how to do this: [https://sysdig.com/blog/kubernetes-monitoring-prometheus-operator-part3](https://sysdig.com/blog/kubernetes-monitoring-prometheus-operator-part3).'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: 'The deployment creates a container from the public Prometheus image in `prom/prometheus`,
    as shown in the following code:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: It also mounts `ConfigMap` as a volume, and then as a file in `/etc/prometheus/prometheus.yml`.
    This starts the Prometheus server with that configuration. The container opens
    port `9090`, which is the default for Prometheus.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, note how we delegated for the Prometheus container. This is
    one of the advantages of using Kubernetes: we can use standard available containers
    to add features to our cluster with minimal configuration. We don''t even have
    to worry about the operating system or the packaging of the Prometheus container.
    This simplifies operations and allows us to standardize the tools we use.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: The deployed Prometheus server can be accessed at `http://prometheus.example.local/`,
    as described in the Ingress and service.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: 'This displays a graphic interface that can be used to plot the graphs, as shown
    in the following screenshot:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/98c116d8-05e9-461b-b13b-d8a24a240609.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
- en: The Expression search box will also autocomplete metrics, helping with the discovery
    process.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: 'The interface also displays other elements from Prometheus that are interesting,
    such as the configuration or the statuses of the targets:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4a164941-5d6b-4364-903e-5123751f6476.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
- en: The graphs in this interface are usable, but we can set up more complicated
    and useful dashboards through Grafana. Let's see how this setup works.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: Plotting graphs and dashboards
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The required Kubernetes configuration, `grafana.yaml`, is available in this
    book's GitHub repository in the `Chapter10/kubernetes/metrics` directory. Just
    like we did with Prometheus, we used a single file to configure Grafana.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: 'We won''t show the Ingress and service for the same reason we explained previously.
    The deployment is simple, but we mount two volumes instead of one, as shown in
    the following code:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The `volume-config` volume shares a single file that configures Grafana. The
    `volume-dashboard` volume adds a dashboard. The latter mounts a directory that
    contains two files. Both mounts are in the default location that Grafana expects
    for configuration files.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: 'The `volume-config` volume sets up the data source in the place where Grafana
    will receive the data to plot:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The data comes from `http://prometheus-service` and points to the Prometheus
    service we configured previously.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '`volume-dashboard` defines two files, `dashboard.yaml` and `dashboard.json`:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '`dashboard.yaml` is a simple file that points to the directory where we can
    find JSON files describing the available dashboards for the system. We point to
    the same directory to mount everything with a single volume.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: '`dashboard.json` is redacted here to save space; check out this book''s GitHub
    repository for the data.'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '`dashboard.json` describes a dashboard in JSON format. This file can be automatically
    generated through the Grafana UI. Adding more `.json` files will create new dashboards.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: Grafana UI
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'By accessing `http://grafana.example.local` and using your login/password details,
    that is, `admin/admin` (the default values), you can access the Grafana UI:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e0ed3527-9a22-4a49-8356-5e58795741ac.png)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
- en: 'From there, you can check the dashboard, which can be found in the left central
    column:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/15311ba9-bf88-4c0c-8b8b-15a29b88edf3.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
- en: 'This captures the calls to Flask, both in terms of numbers and in *95^(th)*
    percentile time. Each individual graph can be edited so that we can see the recipe
    that produces it:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bfba98e1-1532-46a9-8bbd-126745e3ee24.png)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
- en: The icons on the left allow us to change the queries that are running in the
    system, change the visualization (units, colors, bars or lines, kind of scale
    to plot, and so on), add general information such as name, and create alerts.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: The Grafana UI allows us to experiment and so is highly interactive. Take some
    time to try out the different options and learn how to present the data.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: The Query section allows us to add and display metrics from Prometheus. Note
    the Prometheus logo near default, which is the data source.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: Each of the queries has a Metrics section that extracts data from Prometheus.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: Querying Prometheus
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Prometheus has its own query language called PromQL. The language is very powerful,
    but it presents some peculiarities.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: The Grafana UI helps by autocompleting the query, which makes it easy for us
    to search for metric names. You can experiment directly in the dashboard, but
    there's a page on Grafana called Explore that allows you to make queries out of
    any dashboard and has some nice tips, including basic elements. This is denoted
    by a compass icon in the left sidebar.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: The first thing to keep in mind is understanding the Prometheus metrics. Given
    its sampling approach, most of them are monotonically increasing. This means that
    plotting the metrics will show a line going up and up.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: 'To get the rate at which the value changes over a period of time, you need
    to use `rate`:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This generates the requests per second, on average, with a moving window of
    `5` minutes. The rate can be further aggregated using `sum` and `by`:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'To calculate the times, you can use `avg` instead. You can also group by more
    than one label:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'However, you can also set up quantiles, just like we can in graphs. We multiply
    by 100 to get the time in milliseconds instead of seconds and group by `method`
    and `path`. Now, `le` is a special tag that''s created automatically and divides
    the data into multiple buckets. The `histogram_quantile` function uses this to
    calculate the quantiles:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Metrics can be filtered so that only specific labels are displayed. They can
    also be used for different functions, such as division, multiplication, and so
    on.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: Prometheus queries can be a bit long and complicated when we're trying to display
    the result of several metrics, such as the percentage of successful requests over
    the total. Be sure to test that the result is what you expect it to be and allocate
    time to tweak the requests, later.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: 'Be sure to check out the Prometheus documentation if you want to find out more:
    [https://prometheus.io/docs/prometheus/latest/querying/basics/](https://prometheus.io/docs/prometheus/latest/querying/basics/).'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: Updating dashboards
  id: totrans-316
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Dashboards can be interactively changed and saved, but in our Kubernetes configuration,
    we set up the volumes that contain the files as non-persistent. Due to this, restarting
    Grafana will discard any changes and reapply the defined configuration in `volume-dashboard`
    in the `Chapter10/kubernetes/metrics/grafana.yaml` file.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: This is actually a good thing since we apply the same GitOps principles to store
    the full configuration in the repository under Git source control.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: However, as you can see, the full JSON description of the dashboard contained
    in the `grafana.yaml` file is very long, given the number of parameters and the
    difficulty to change them manually.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: 'The best approach is to change the dashboard interactively and then export
    it into a JSON file with the Share file button at the top of the menu. Then, the
    JSON file can be added to the configuration:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e3802571-88e1-4692-85bb-4560de9d23ea.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
- en: The Grafana pod can then be redeployed and will contain the saved changes in
    the dashboard. The Kubernetes configuration can then be updated in Git through
    the usual process.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: 'Be sure to explore all the possibilities for dashboards, including the option
    to set up variables so that you can use the same dashboard to monitor different
    applications or environments and the different kinds of visualization tools. See
    the full Grafana documentation for more information: [https://grafana.com/docs/reference/](https://grafana.com/docs/reference/).'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: Having metrics available allows us to use them to proactively understand the
    system and anticipate any problems.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: Being proactive
  id: totrans-325
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Metrics show an aggregated point of view for the status of the whole cluster.
    They allow us to detect trending problems, but it's difficult to find a single
    spurious error.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: Don't underestimate them, though. They are critical for successful monitoring
    because they tell us whether the system is healthy. In some companies, the most
    critical metrics are prominently displayed in screens on the wall so that the
    operations team can see them at all times and quickly react.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: 'Finding the proper balance for metrics in a system is not a straightforward
    task and will require time and trial and error. There are four metrics for online
    services that are always important, though. These are as follows:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: '**Latency**: How many milliseconds the system takes to respond to a request.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Depending on the times, a different time unit, such as seconds or microseconds,
    can be used. From my experience, milliseconds is adequate since most of the requests
    in a web application system should take between 50 ms and 1 second to respond.
    Here, a system that takes 50 ms is too slow and one that takes 1 second is a very
    performant one.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: '**Traffic**: The number of requests flowing through the system per unit of
    time, that is, requests per second or per minute.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Errors**: The percentage of requests received that return an error.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Saturation**: Whether the capacity of the cluster has enough headroom. This
    includes elements such as hard drive space, memory, and so on. For example, there
    is 20% available RAM memory.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To measure saturation, remember to install the available exporters that will
    collect most of the hardware information (memory, hard disk space, and so on)
    automatically. If you use a cloud provider, normally, they expose their own set
    of related metrics as well, for example, CloudWatch for AWS.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: These metrics can be found in the Google SRE Book as *the Four Golden Signals*
    and are recognized as the most important high-level elements for successful monitoring.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: Alerting
  id: totrans-336
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When problems arise in metrics, an automatic alert should be generated. Prometheus
    has an included alert system that will trigger when a defined metric fulfills
    the defined condition.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the Prometheus documentation on alerting for more information: [https://prometheus.io/docs/alerting/overview/](https://prometheus.io/docs/alerting/overview/).'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: Prometheus' Alertmanager can perform certain actions, such as sending emails
    to be notified based on rules. This system can be connected to an integrated incident
    solution such as OpsGenie ([https://www.opsgenie.com](https://www.opsgenie.com))
    in order to generate all kinds of alerts and notifications, such as emails, SMS,
    calls, and so on.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: Logs can also be used to create alerts. There are certain tools that allow us
    to create an entry when an `ERROR` is raised, such as **Sentry**. This allows
    us to detect problems and proactively remediate them, even if the health of the
    cluster hasn't been compromised.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: Some commercial tools that handle logs, such as Loggly, allow us to derive metrics
    from the logs themselves, plotting graphs either based on the kind of log or extracting
    values from them and using them as values. While not as complete as a system such
    as Prometheus, they can monitor some values. They also allow us to notify if thresholds
    are reached.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: The monitoring space is full of products, both free and paid, that can help
    us to handle this. While it's possible to create a completely in-house monitoring
    system, being able to analyze whether commercial cloud tools will be of help is
    crucial. The level of features and their integration with useful tools such as
    external alerting systems will be difficult to replicate and maintain.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: Alerting is also an ongoing process. Some elements will be discovered down the
    line and new alerts will have to be created. Be sure to invest time so that everything
    works as expected. Logs and metrics will be used while the system is unhealthy,
    and in those moments, time is critical. You don't want to be guessing about logs
    because the host parameter hasn't been configured correctly.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: Being prepared
  id: totrans-344
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the same way that a backup is not useful unless the recovery process has
    been tested and is working, be proactive when checking that the monitoring system
    is producing useful information.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: In particular, try to standardize the logs so that there's a good expectation
    about what information to include and how it's structured. Different systems may
    produce different logs, but it's good to make all the microservices log in the
    same format. Double-check that any parameters, such as client references or hosts,
    are being logged correctly.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: The same applies to metrics. Having a set of metrics and dashboards that everyone
    understands will save a lot of time when you're tracking a problem.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-348
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to work with logs and metrics, as well as how
    to set up logs and send them to a centralized container using the `syslog` protocol.
    We described how to add logs to different applications, how to include a request
    ID, and how to raise custom logs from the different microservices. Then, we learned
    how to define a strategy to ensure that the logs are useful in production.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: We also described how to set up standard and custom Prometheus metrics in all
    the microservices. We started a Prometheus server and configured it so that it
    collects metrics from our services. We started a Grafana service so that we can
    plot the metrics and created dashboards so that we can display the status of the
    cluster and the different services that are running.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: Then, we introduced you to the alert system in Prometheus and how it can be
    used so that it notifies us of problems. Remember that there are commercial services
    to help you with logs, metrics, and alerts. Analyze your options as they can save
    you a lot of time and money in terms of maintenance costs.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn how to manage changes and dependencies that
    affect several microservices and how to handle configurations and secrets.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-353
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is the observability of a system?
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the different severity levels that are available in logs?
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are metrics used for?
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why do you need to add a request ID to logs?
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the available kinds of metrics in Prometheus?
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the 75th percentile in a metric and how does it differ from the average?
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the four golden signals?
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-361
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can learn more about monitoring with different tools and techniques while
    using Docker by reading *Monitoring Docker* ([https://www.packtpub.com/virtualization-and-cloud/monitoring-docker](https://www.packtpub.com/virtualization-and-cloud/monitoring-docker)).
    To find out more about Prometheus and Grafana, including how to set up alerts,
    please read *Hands-On Infrastructure Monitoring with Prometheus* ([https://www.packtpub.com/virtualization-and-cloud/hands-infrastructure-monitoring-prometheus](https://www.packtpub.com/virtualization-and-cloud/hands-infrastructure-monitoring-prometheus)).
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring is only the starting point of successfully running services reliably.
    To find out how to successfully improve your operations, check out *Real-World
    SRE* ([https://www.packtpub.com/web-development/real-world-sre](https://www.packtpub.com/web-development/real-world-sre)).
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
