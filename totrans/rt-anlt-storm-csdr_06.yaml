- en: Chapter 6. Adding NoSQL Persistence to Storm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will graduate to the next step in understanding Storm—we
    will add persistence to our topology. We have chosen Cassandra for very obvious
    reasons, which will be elaborated during this chapter. The intent is to make you
    understand how the Cassandra data store can be integrated with the Storm topology.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The advantages of Cassandra
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to columnar databases and column family design fundamentals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up a Cassandra cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing the CQLSH, CLI, and Connector APIs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storm topology wired to the Cassandra store
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the mechanism of persistence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The best practices for Storm Cassandra applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The advantages of Cassandra
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is the first and most obvious question anyone would ask, "Why are we using
    NoSQL?" Well, the very quick answer for looking at NoSQL instead of traditional
    data stores is the same as why the world is moving to big data—low cost, highly
    scalable, and reliable solutions that can store endless amounts of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, the next question is why Cassandra, and why not anything else out of the
    NoSQL stack. Here the answer lies in the kind of problem and solution approach
    we are trying to implement. Well, we are handling real-time analytics, and everything
    we need should be accurate, fail-safe, and lightning fast. Therefore, Cassandra
    is the best choice because:'
  prefs: []
  type: TYPE_NORMAL
- en: It has the fastest writes amongst its peers such as HBase and so on
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is linearly scalable with peer-to-peer design
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No single point of failure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Read and write requests can be handled without impacting each other's performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handles search queries comprising millions of transactions and lightning-fast
    speeds
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fail-safe and highly available with replication factors in place
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guarantees eventual consistency with the CAP theorem on NoSQL DBs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Column family design to handle a variety of formats
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No or low licensing cost
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Less development-ops or operational cost
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It can be extended for integration on a variety of other big data components
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Columnar database fundamentals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most important aspects of getting started with NoSQL data stores
    is getting to understand the fundamentals of columnar databases; or rather, let's
    use the actual term—column families.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a concept that has a variety of implementations in different NoSQL
    databases, for instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cassandra**: This is a key-value-pair-based NoSQL DB'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mongo DB**: This is a document-based NoSQL DB'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neo4J**: This is a graph DB'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'They differ from conventional RDBMS systems that are row-oriented in terms
    of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storage extendibility
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fault tolerance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Low or no licensing cost
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: But having iterated all the differences and benefits of NoSQL DBs, you must
    clearly understand that the shift to NoSQL is a shift of the entire paradigm of
    data storage, availability, and access—they are not a replacement for RDBMS.
  prefs: []
  type: TYPE_NORMAL
- en: In the RDBMS world, we are all used to creating tables, but here in Cassandra,
    we create column families where we define the metadata of the columns, but the
    columns are actually stored as rows. Each row can have different sets of columns,
    thus making the whole column family relatively unstructured and extendible.
  prefs: []
  type: TYPE_NORMAL
- en: Types of column families
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two types of column families:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Static column family**: As the name suggests, this has a static set of columns
    and is a very close surrogate of all well-known RDBMS tables, barring a few differences
    that are a result of its NoSQL heritage. Here is an example of a static column
    family:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Rowkey | Columns |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Raman | Name | E-mail | Cell no. | Age |'
  prefs: []
  type: TYPE_TB
- en: '|   | Raman Subramanian | aa@yahoo.com | 9999999999 | 20 |'
  prefs: []
  type: TYPE_TB
- en: '| Edison | Name | E-mail | Cell no. | Age |'
  prefs: []
  type: TYPE_TB
- en: '|   | Edison Weasley | bb@yahoo.com | 88888888888 | 30 |'
  prefs: []
  type: TYPE_TB
- en: '| Amey | Name | E-mail | Cell no. | Age |'
  prefs: []
  type: TYPE_TB
- en: '|   | Amey Marriot | cc@yahoo.com | 7777777777 | 40 |'
  prefs: []
  type: TYPE_TB
- en: '| Sriman | Name | E-mail |   |   |'
  prefs: []
  type: TYPE_TB
- en: '|   | Sriman Mishra | dd@yahoo.com |   |   |'
  prefs: []
  type: TYPE_TB
- en: '**Dynamic column family**: This one gets the true essence of being unstructured
    and schema-less. Here, we don''t use predefined columns associated with the column
    family, but the same can be dynamically generated and supplied by the client application
    at the time of inserting data into the column family. During the creation or definition
    of a dynamic column family, we get to define the information about the column
    names and values by defining the comparators and validators. Here is an example
    of a dynamic column family:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Rowkey | Columns |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Raman | Name | E-mail | Cell no. | Age |'
  prefs: []
  type: TYPE_TB
- en: '|   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| Edison | Address | State | Territory |   |'
  prefs: []
  type: TYPE_TB
- en: '|   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| Amey | Country | Sex | Cell no. | Age |'
  prefs: []
  type: TYPE_TB
- en: '|   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| Sriman | Nationality |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '|   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: Types of columns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are a variety of columns that Cassandra supports:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Standard columns**: These columns contain a name; this is either static or
    dynamic and set by the writing application. A value (this is actually the attribute
    that stores the data) and timestamp are shown here:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Column_name |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| value |'
  prefs: []
  type: TYPE_TB
- en: '| timestamp |'
  prefs: []
  type: TYPE_TB
- en: Cassandra makes use of the timestamp associated with the column to find out
    the last update to the column. When data is queried from Cassandra, it orders
    by this timestamp and always returns the most recent value.
  prefs: []
  type: TYPE_NORMAL
- en: '**Composite columns**: Cassandra makes use of this storage mechanism to handle
    clustered rows. This is a unique way of handling all the logical rows together
    that share the same partition key into a single physical wide row. This enables
    Cassandra to accomplish the legendary feat of storing 2 billion columns per row.
    For example, let''s say I want to create a table where I capture live status updates
    from some social networking sites:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The live updates are being recorded under the `StatusUpdates` table that has
    the `username`, `message`, and `update_id` (which is actually a UUID) property.
  prefs: []
  type: TYPE_NORMAL
- en: While designing a Cassandra column family, you should make extensive use of
    the functionality provided by UUIDs, which can be employed for sequencing data.
  prefs: []
  type: TYPE_NORMAL
- en: The combination of the `user_id` and `update_id` properties from `timeseriesTable`
    can uniquely identify a row in chronology.
  prefs: []
  type: TYPE_NORMAL
- en: Cassandra makes use of the first column defined in the primary key as the partition
    key; this is also known as the row key.
  prefs: []
  type: TYPE_NORMAL
- en: '**Expiring columns**: These are special types of Cassandra columns that have
    a time to live (**TTL**) associated with them; the values stored in these columns
    are automatically deleted or erased after the TTL has elapsed. These columns are
    used for use cases where we don''t want to retain data older than a stated interval;
    for instance, if we don''t need data older than 24 hours. In our column family,
    I would associate a TTL of 24 hours with every column that is being inserted,
    and this data will be automatically deleted by Cassandra after 24 hours of its
    insertion.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Counter columns**: These are again specialized function columns that store
    a number incrementally. They have a special implementation and a specialized usage
    for situations where we use counters; for instance, if I need to count the number
    of occurrences of an event.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up the Cassandra cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cassandra is a very scalable key-value store. It promises eventual consistency
    and its distributed ring-based architecture eliminates any single point of failure
    in the cluster, thus making it highly available. It's designed and developed to
    support very fast reads and writes over excessively large volumes of data .This
    fast write and read ability makes it a very strong contender to be used in an
    **online transaction processing** (**OLTP**) application to support large business
    intelligence systems.
  prefs: []
  type: TYPE_NORMAL
- en: Cassandra provides a column-family-based data model that is more flexible than
    typical key-value systems.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Cassandra
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Cassandra requires the most stable version of Java 1.6 that you can deploy,
    preferably the Oracle or Sun JVM. Perform the following steps to install Cassandra:'
  prefs: []
  type: TYPE_NORMAL
- en: Download the most recent stable release (version 1.1.6 at the time of writing)
    from the Apache Cassandra site.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a Cassandra directory under `/usr/local` as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Extract the downloaded TAR file to the `/usr/local` location. Use the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Cassandra needs a directory to store its data, log files, and cache files.
    Create `/usr/local/cassandra/tmp` to store this data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Update the `Cassandra.yaml` configuration file under `/usr/local/Cassandra/apache-cassandra-1.1.6/conf`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following properties will go into it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Calculate a token for each node using the following script and update the `initial_token`
    property to each node by adding a unique token value in `Cassandra.yaml`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Update the following property in the `conf/log4j-server.properties` file. Create
    the `temp` directory under `cassandra`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Increase the `rpc_timeout` property in `Cassandra.yaml` (if this timeout is
    very small and the network latency is high, Cassandra might assume the nodes are
    dead without waiting long enough for a response to propagate).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the Cassandra server at `/usr/local/Cassandra/apache-cassandra-1.1.6 using
    bin/Cassandra –f`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the Cassandra client at `/usr/local/Cassandra/apache-cassandra-1.1.6 using
    bin/Cassandra-cli` with a host and port.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the `bin/nodetool` ring utility at `/usr/local/Cassandra/apache-cassandra-1.1.6`
    to verify a properly connected cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The preceding output displays a connected cluster. This configuration shows
    that it's correctly configured and connected.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a screenshot of the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Installing Cassandra](img/00046.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Multiple data centers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In practical scenarios, we would want to have Cassandra clusters distributed
    across different data centers so that the system is more reliable and resilient
    overall to localized network snags and physical disasters.
  prefs: []
  type: TYPE_NORMAL
- en: Prerequisites for setting up multiple data centers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following are a set of prerequisites that should be used for setting up
    multiple data centers:'
  prefs: []
  type: TYPE_NORMAL
- en: Have Cassandra installed on each node
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have the IP address of each node in the cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identify the cluster names
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identify the seed nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identify the snitch that is to be used
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing Cassandra data centers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following are a set of steps to set up Cassandra data centers:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with an assumption that we have already installed Cassandra on
    the following nodes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 10.188.66.41 (seed1)
  prefs: []
  type: TYPE_NORMAL
- en: 10.196.43.66
  prefs: []
  type: TYPE_NORMAL
- en: 10.188.247.41
  prefs: []
  type: TYPE_NORMAL
- en: 10.196.170.59 (seed2)
  prefs: []
  type: TYPE_NORMAL
- en: 10.189.61.170
  prefs: []
  type: TYPE_NORMAL
- en: 10.189.30.138
  prefs: []
  type: TYPE_NORMAL
- en: Assign tokens using the token generation Python script defined in the previous
    section to each of the preceding nodes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s say we align to the following distribution of nodes and their tokens
    across the data centers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '| Node | IP Address | Token | Data Center |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| node0 | 10.188.66.41 | 0 | Dc1 |'
  prefs: []
  type: TYPE_TB
- en: '| node1 | 10.196.43.66 | 56713727820156410577229101238628035245 | Dc1 |'
  prefs: []
  type: TYPE_TB
- en: '| node2 | 10.188.247.41 | 113427455640312821154458202477256070488 | Dc1 |'
  prefs: []
  type: TYPE_TB
- en: '| node3 | 10.196.170.59 | 10 | Dc2 |'
  prefs: []
  type: TYPE_TB
- en: '| node4 | 10.189.61.170 | 56713727820156410577229101238628035255 | Dc2 |'
  prefs: []
  type: TYPE_TB
- en: '| node5 | 10.189.30.138 | 113427455640312821154458202477256070498 | Dc2 |'
  prefs: []
  type: TYPE_TB
- en: 'Stop Cassandra on the nodes and clear the data from `data_dir` of Cassandra:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This command finds the Cassandra Java process ID (PID):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the command to kill the process with the specified PID:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The preceding command clears the data from the default directories of Cassandra.
  prefs: []
  type: TYPE_NORMAL
- en: 'Modify the following property settings in the `cassandra.yaml` file for each
    node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is what the updated configuration will look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: All the properties for these nodes are the same as those defined for the preceding
    `node0` except for the `initial_token` and `listen_address` properties.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will have to assign names to each data center and their racks; for
    example, `Dc1`, `Dc2` and `Rc1`, `Rc2`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Go to the `cassandra-topology.properties` file and add an assignment for data
    center and rack names against the IP addresses of each node. For example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The next step is to start seed nodes one by one, followed by all the rest of
    the nodes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check that your ring is up and running.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Introduction to CQLSH
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we are through with the Cassandra setup, let''s get acquainted with
    the shell and a few basic commands:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run CQL at `/usr/local/Cassandra/apache-cassandra-1.1.6` using `bin/cqlsh`
    with a host and port:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a keyspace either at the Cassandra client or at CQL, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a column family at the Cassandra client or at CQL as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'For example, create the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Insert a few records into the column family from the command line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Retrieve the data from the column family:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Introduction to CLI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section gets you acquainted with another tool that is used for interaction
    with Cassandra processes—the CLI shell.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps are used for interacting with Cassandra using the CLI shell:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the command to connect to the Cassandra CLI:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a keyspace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Verify the creation of the keyspace using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a column family:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Insert data into the column family:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this example, the code `ss` is my row key.
  prefs: []
  type: TYPE_NORMAL
- en: 'Retrieve data from the Cassandra column family:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Using different client APIs to access Cassandra
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we are acquainted with Cassandra, let's move on to the next step where
    we will access (insert or update) data into the cluster programmatically. In general,
    the APIs we are talking about are wrappers written over the core Thrift API, which
    offers various CRUD operations over the Cassandra cluster using programmer-friendly
    packages.
  prefs: []
  type: TYPE_NORMAL
- en: 'The client APIs that are used to access Cassandra are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Thrift protocol**: The most basic of all APIs to access Cassandra is the
    **Remote Procedure Call** (**RPC**) protocol, which provides a language-neutral
    interface and thus exposes flexibility to communicate using Python, Java, and
    so on. Please note that almost all other APIs we''ll discuss use **Thrift** under
    the hood. It is simple to use and it provides basic functionality out of the box
    like ring discovery and native access. Complex features such as retry, connection
    pooling, and so on are not supported out of the box. However, there are a variety
    of libraries that have extended Thrift and added these much required features,
    and we will touch upon a few widely used ones in this chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hector**: This has the privilege of being one of the most stable and extensively
    used APIs for Java-based client applications to access Cassandra. As mentioned
    earlier, it uses Thrift under the hood, so it essentially can''t offer any feature
    or functionality not supported by the Thrift protocol. The reason for its widespread
    use is that it has a number of essential features ready to use and available out
    of the box:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It has implementation for connection pooling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It has a ring discovery feature with an add-on of automatic failover support
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It has a retry option for downed hosts in the Cassandra ring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Datastax Java driver**: This is, again, a recent addition to the stack of
    client access options to Cassandra, and hence goes well with the newer version
    of Cassandra. Here are its salient features:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connection pooling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reconnection policies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load balancing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cursor support
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Astyanax**: This is a very recent addition to the bouquet of Cassandra client
    APIs and has been developed by Netflix, which definitely makes it more fabled
    than others. Let''s have a look at its credentials to see where it qualifies:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It supports all of the functions of Hector and is much easier to use
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It promises better connection pooling than Hector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is better at handling failovers than Hector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It provides some out-of-the-box, database-like features (now that''s big news).
    At the API level, it provides functionality called Recipes in its terms, which
    provides:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parallel row query execution
  prefs: []
  type: TYPE_NORMAL
- en: Messaging queue functionality
  prefs: []
  type: TYPE_NORMAL
- en: Object storage
  prefs: []
  type: TYPE_NORMAL
- en: Pagination
  prefs: []
  type: TYPE_NORMAL
- en: It has numerous frequently required utilities like JSON Writer and CSV Importer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storm topology wired to the Cassandra store
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now you have been educated and informed about why you should use Cassandra.
    You have been walked through setting up Cassandra and column family creation,
    and have even covered the various client/protocol options available to access
    the Cassandra data store programmatically. As mentioned earlier, Hector has so
    far been the most widely used API for accessing Cassandra, though the `Datastax`
    and `Astyanax` drivers are fast catching up. For our exercise, we'll use the Hector
    API.
  prefs: []
  type: TYPE_NORMAL
- en: The use case we want to implement here is to use Cassandra to support real-time,
    adhoc reporting for telecom data that is being collated, parsed, and enriched
    using a Storm topology.
  prefs: []
  type: TYPE_NORMAL
- en: '![Storm topology wired to the Cassandra store](img/00047.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As depicted in the preceding figure, the use case requires live telecom **Call
    Detail Record** (**CDR**) capture using the data collection components (for practice,
    we can use sample records and a simulator shell script to mimic the live CDR feeds).
    The collated live feed is pushed into the RabbitMQ broker and then consumed by
    the Storm topology.
  prefs: []
  type: TYPE_NORMAL
- en: For the topology, we have an AMQP spout as the consumer, which reads the data
    of the queue and pushes it downstream to the topology bolts; here, we have wired
    in bolts to parse the message and convert it to **Plain Old Java Objects** (**POJO**'s).
    Then, we have a new entry in our topology, the Cassandra bolt, which actually
    stores the data in the Cassandra cluster.
  prefs: []
  type: TYPE_NORMAL
- en: From the Cassandra cluster, a UI-based consumer retrieves the data based on
    a search query defined by the user, thus providing the adhoc, real-time reporting
    over live data.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the sake of our implementation, we will query the data from CLI/CQLSH as
    shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a keyspace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the column family:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The following changes need to be made to `pom.xml` in the project. The Hector
    dependency should be added to the `pom.xml` file so that it is fetched at the
    time of build and added to the `m2` repository, as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: If you are working with a non-Maven project, follow the usual protocol—download
    the Hector core JAR file and add it to the project build path so that all the
    required dependencies are satisfied.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we''ll need to get the components in place in our Storm topology. We
    will start by creating a `CassandraController` Java component that will hold all
    Cassandra-related functionality, and it will be called from the `CassandraBolt`
    class in the topology to persist the data into Cassandra:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Last but not least in our topology is actually the component that will write
    into Cassandra, the Storm bolt that will make use of `CassandraController` created
    earlier to write the real-time data into Cassandra:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: So here we complete the last piece of the puzzle; we can now stream data into
    Cassandra using Storm in real time. Once you execute the topology end to end,
    you can verify the data in Cassandra by using the select or list commands on CLI/CQLSH.
  prefs: []
  type: TYPE_NORMAL
- en: The best practices for Storm/Cassandra applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When working with distributed applications that have SLAs operating 24/7 with
    a very high velocity and a miniscule average processing time, certain aspects
    become extremely crucial to be taken care of:'
  prefs: []
  type: TYPE_NORMAL
- en: Network latency plays a big role in real-time applications and can make or break
    products, so make a very informed and conscious decision on the placement of various
    nodes in a data center or across data centers. In such situations, it's generally
    advisable to keep ping latency at a minimum.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The replication factor should be around three for Cassandra.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compaction should be part of routine Cassandra maintenance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quiz time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Q.1\. State whether the following statements are true or false:'
  prefs: []
  type: TYPE_NORMAL
- en: Cassandra is a document-based NoSQL.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Cassandra has a single point of failure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Cassandra uses consistent hashing for key distribution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Cassandra works on master-slave architecture.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Q.2\. Fill in the blanks:'
  prefs: []
  type: TYPE_NORMAL
- en: _______________attributes of the CAP theorem are adhered to by Cassandra.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: _______________ is the salient feature that makes Cassandra a contender to be
    used in conjunction with Storm.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The ____________ is an API to access Cassandra using a Java client, and is a
    Greek mythological character—*brother of Cassandra*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Q.3\. Complete the use case mentioned in the chapter and demonstrate end-to-end
    execution to populate data into Cassandra.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you have covered the fundamentals of NoSQL in general and specifically
    Cassandra. You got hands-on experience in setting up the Cassandra cluster as
    well as got to know about varied APIs, drivers, and protocols that provide programmatic
    access to Cassandra. We also integrated Cassandra as a data store to our Storm
    topology for data insertion.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will touch upon some integral aspects of Cassandra,
    specifically consistency and availability.
  prefs: []
  type: TYPE_NORMAL
