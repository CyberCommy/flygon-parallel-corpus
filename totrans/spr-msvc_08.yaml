- en: Chapter 8. Containerizing Microservices with Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the context of microservices, containerized deployment is the icing on the
    cake. It helps microservices be more autonomous by self-containing the underlying
    infrastructure, thereby making the microservices cloud neutral.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will introduce the concepts and relevance of virtual machine images
    and the containerized deployment of microservices. Then, this chapter will further
    familiarize readers with building Docker images for the BrownField PSS microservices
    developed with Spring Boot and Spring Cloud. Finally, this chapter will also touch
    base on how to manage, maintain, and deploy Docker images in a production-like
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will learn about:'
  prefs: []
  type: TYPE_NORMAL
- en: The concept of containerization and its relevance in the context of microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building and deploying microservices as Docker images and containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using AWS as an example of cloud-based Docker deployments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reviewing the microservice capability model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will explore the following microservice capabilities from
    the microservice capability model discussed in [Chapter 3](ch03.html "Chapter 3. Applying
    Microservices Concepts"), *Applying Microservices Concepts*:'
  prefs: []
  type: TYPE_NORMAL
- en: Containers and virtual machines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The private/public cloud
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The microservices repository
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The model is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Reviewing the microservice capability model](img/B05447_08_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Understanding the gaps in BrownField PSS microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 5](ch05.html "Chapter 5. Scaling Microservices with Spring Cloud"),
    *Scaling Microservices with Spring Cloud,* BrownField PSS microservices were developed
    using Spring Boot and Spring Cloud. These microservices are deployed as versioned
    fat JAR files on bare metals, specifically on a local development machine.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 6](ch06.html "Chapter 6. Autoscaling Microservices"), *Autoscaling
    Microservices*, the autoscaling capability was added with the help of a custom
    life cycle manager. In [Chapter 7](ch07.html "Chapter 7. Logging and Monitoring
    Microservices"), *Logging and Monitoring Microservices*, challenges around logging
    and monitoring were addressed using centralized logging and monitoring solutions.
  prefs: []
  type: TYPE_NORMAL
- en: There are still a few gaps in our BrownField PSS implementation. So far, the
    implementation has not used any cloud infrastructure. Dedicated machines, as in
    traditional monolithic application deployments, are not the best solution for
    deploying microservices. Automation such as automatic provisioning, the ability
    to scale on demand, self-service, and payment based on usage are essential capabilities
    required to manage large-scale microservice deployments efficiently. In general,
    a cloud infrastructure provides all these essential capabilities. Therefore, a
    private or public cloud with the capabilities mentioned earlier is better suited
    to deploying Internet-scale microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Also, running one microservice instance per bare metal is not cost effective.
    Therefore, in most cases, enterprises end up deploying multiple microservices
    on a single bare metal server. Running multiple microservices on a single bare
    metal could lead to a "noisy neighbor" problem. There is no isolation between
    the microservice instances running on the same machine. As a result, services
    deployed on a single machine may eat up others' space, thus impacting their performance.
  prefs: []
  type: TYPE_NORMAL
- en: An alternate approach is to run the microservices on VMs. However, VMs are heavyweight
    in nature. Therefore, running many smaller VMs on a physical machine is not resource
    efficient. This generally results in resource wastage. In the case of sharing
    a VM to deploy multiple services, we would end up facing the same issues of sharing
    the bare metal, as explained earlier.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of Java-based microservices, sharing a VM or bare metal to deploy
    multiple microservices also results in sharing JRE among microservices. This is
    because the fat JARs created in our BrownField PSS abstract only application code
    and its dependencies but not JREs. Any update on JRE installed on the machine
    will have an impact on all the microservices deployed on this machine. Similarly,
    if there are OS-level parameters, libraries, or tunings that are required for
    specific microservices, then it will be hard to manage them on a shared environment.
  prefs: []
  type: TYPE_NORMAL
- en: One microservice principle insists that it should be self-contained and autonomous
    by fully encapsulating its end-to-end runtime environment. In order to align with
    this principle, all components, such as the OS, JRE, and microservice binaries,
    have to be self-contained and isolated. The only option to achieve this is to
    follow the approach of deploying one microservice per VM. However, this will result
    in underutilized virtual machines, and in many cases, extra cost due to this can
    nullify benefits of microservices.
  prefs: []
  type: TYPE_NORMAL
- en: What are containers?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Containers are not revolutionary, ground-breaking concepts. They have been in
    action for quite a while. However, the world is witnessing the re-entry of containers,
    mainly due to the wide adoption of cloud computing. The shortcomings of traditional
    virtual machines in the cloud computing space also accelerated the use of containers.
    Container providers such as **Docker** simplified container technologies to a
    great extent, which also enabled a large adoption of container technologies in
    today's world. The recent popularity of DevOps and microservices also acted as
    a catalyst for the rebirth of container technologies.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, what are containers? Containers provide private spaces on top of the operating
    system. This technique is also called operating system virtualization. In this
    approach, the kernel of the operating system provides isolated virtual spaces.
    Each of these virtual spaces is called a container or **virtual engine** (**VE**).
    Containers allow processes to run on an isolated environment on top of the host
    operating system. A representation of multiple containers running on the same
    host is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![What are containers?](img/B05447_08_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Containers are easy mechanisms to build, ship, and run compartmentalized software
    components. Generally, containers package all the binaries and libraries that
    are essential for running an application. Containers reserve their own filesystem,
    IP address, network interfaces, internal processes, namespaces, OS libraries,
    application binaries, dependencies, and other application configurations.
  prefs: []
  type: TYPE_NORMAL
- en: There are billions of containers used by organizations. Moreover, there are
    many large organizations heavily investing in container technologies. Docker is
    far ahead of the competition, supported by many large operating system vendors
    and cloud providers. **Lmctfy**, **SystemdNspawn**, **Rocket**, **Drawbridge**,
    **LXD**, **Kurma**, and **Calico** are some of the other containerization solutions.
    Open container specification is also under development.
  prefs: []
  type: TYPE_NORMAL
- en: The difference between VMs and containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: VMs such as **Hyper-V**, **VMWare**, and **Zen** were popular choices for data
    center virtualization a few years ago. Enterprises experienced a cost saving by
    implementing virtualization over the traditional bare metal usage. It has also
    helped many enterprises utilize their existing infrastructure in a much more optimized
    manner. As VMs support automation, many enterprises experienced that they had
    to make lesser management effort with virtual machines. Virtual machines also
    helped organizations get isolated environments for applications to run in.
  prefs: []
  type: TYPE_NORMAL
- en: 'Prima facie, both virtualization and containerization exhibit exactly the same
    characteristics. However, in a nutshell, containers and virtual machines are not
    the same. Therefore, it is unfair to make an apple-to-apple comparison between
    VMs and containers. Virtual machines and containers are two different techniques
    and address different problems of virtualization. This difference is evident from
    the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The difference between VMs and containers](img/B05447_08_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Virtual machines operate at a much lower level compared to containers. VMs provide
    hardware virtualization, such as that of CPUs, motherboards, memory, and so on.
    A VM is an isolated unit with an embedded operating system, generally called a
    **Guest OS**. VMs replicate the whole operating system and run it within the VM
    with no dependency on the host operating system environment. As VMs embed the
    full operating system environment, these are heavyweight in nature. This is an
    advantage as well as a disadvantage. The advantage is that VMs offer complete
    isolation to the processes running on VMs. The disadvantage is that it limits
    the number of VMs one can spin up in a bare metal due to the resource requirements
    of VMs.
  prefs: []
  type: TYPE_NORMAL
- en: The size of a VM has a direct impact on the time to start and stop it. As starting
    a VM in turn boots the OS, the start time for VMs is generally high. VMs are more
    friendly with infrastructure teams as it requires a low level of infrastructure
    competency to manage VMs.
  prefs: []
  type: TYPE_NORMAL
- en: In the container world, containers do not emulate the entire hardware or operating
    system. Unlike VMs, containers share certain parts of the host kernel and operating
    system. There is no concept of guest OS in the case of containers. Containers
    provide an isolated execution environment directly on top of the host operating
    system. This is its advantage as well as disadvantage. The advantage is that it
    is lighter as well as faster. As containers on the same machine share the host
    operating system, the overall resource utilization of containers is fairly small.
    As a result, many smaller containers can be run on the same machine, as compared
    to heavyweight VMs. As containers on the same host share the host operating system,
    there are limitations as well. For example, it is not possible to set iptables
    firewall rules inside a container. Processes inside the container are completely
    independent from the processes on different containers running on the same host.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike VMs, container images are publically available on community portals.
    This makes developers' lives much easier as they don't have to build the images
    from scratch; instead, they can now take a base image from certified sources and
    add additional layers of software components on top of the downloaded base image.
  prefs: []
  type: TYPE_NORMAL
- en: The lightweight nature of the containers is also opening up a plethora of opportunities,
    such as automated build, publishing, downloading, copying, and so on. The ability
    to download, build, ship, and run containers with a few commands or to use REST
    APIs makes containers more developer friendly. Building a new container does not
    take more than a few seconds. Containers are now part and parcel of continuous
    delivery pipelines as well.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, containers have many advantages over VMs, but VMs have their own
    exclusive strengths. Many organizations use both containers and VMs, such as by
    running containers on top of VMs.
  prefs: []
  type: TYPE_NORMAL
- en: The benefits of containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have already considered the many benefits of containers over VMs. This section
    will explain the overall benefits of containers beyond the benefits of VMs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Self-contained**: Containers package the essential application binaries and
    their dependencies together to make sure that there is no disparity between different
    environments such as development, testing, or production. This promotes the concept
    of Twelve-Factor applications and that of immutable containers. Spring Boot microservices
    bundle all the required application dependencies. Containers stretch this boundary
    further by embedding JRE and other operating system-level libraries, configurations,
    and so on, if there are any.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lightweight**: Containers, in general, are smaller in size with a lighter
    footprint. The smallest container, Alpine, has a size of less than 5 MB. The simplest
    Spring Boot microservice packaged with an Alpine container with Java 8 would only
    come to around 170 MB in size. Though the size is still on the higher side, it
    is much less than the VM image size, which is generally in GBs. The smaller footprint
    of containers not only helps spin new containers quickly but also makes building,
    shipping, and storing easier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalable**: As container images are smaller in size and there is no OS booting
    at startup, containers are generally faster to spin up and shut down. This makes
    containers the popular choice for cloud-friendly elastic applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Portable**: Containers provide portability across machines and cloud providers.
    Once the containers are built with all the dependencies, they can be ported across
    multiple machines or across multiple cloud providers without relying on the underlying
    machines. Containers are portable from desktops to different cloud environments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lower license cost**: Many software license terms are based on the physical
    core. As containers share the operating system and are not virtualized at the
    physical resources level, there is an advantage in terms of the license cost.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DevOps**: The lightweight footprint of containers makes it easy to automate
    builds and publish and download containers from remote repositories. This makes
    it easy to use in Agile and DevOps environments by integrating with automated
    delivery pipelines. Containers also support the concept of *build once* by creating
    immutable containers at build time and moving them across multiple environments.
    As containers are not deep into the infrastructure, multidisciplinary DevOps teams
    can manage containers as part of their day-to-day life.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Version controlled**: Containers support versions by default. This helps
    build versioned artifacts, just as with versioned archive files.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reusable**: Container images are reusable artifacts. If an image is built
    by assembling a number of libraries for a purpose, it can be reused in similar
    situations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Immutable containers**: In this concept, containers are created and disposed
    of after usage. They are never updated or patched. Immutable containers are used
    in many environments to avoid complexities in patching deployment units. Patching
    results in a lack of traceability and an inability to recreate environments consistently.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservices and containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is no direct relationship between microservices and containers. Microservices
    can run without containers, and containers can run monolithic applications. However,
    there is a sweet spot between microservices and containers.
  prefs: []
  type: TYPE_NORMAL
- en: Containers are good for monolithic applications, but the complexities and the
    size of the monolith application may kill some of the benefits of the containers.
    For example, spinning new containers quickly may not be easy with monolithic applications.
    In addition to this, monolithic applications generally have local environment
    dependencies, such as the local disk, stovepipe dependencies with other systems,
    and so on. Such applications are difficult to manage with container technologies.
    This is where microservices go hand in hand with containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows three polyglot microservices running on the same
    host machine and sharing the same operating system but abstracting the runtime
    environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Microservices and containers](img/B05447_08_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The real advantage of containers can be seen when managing many polyglot microservices—for
    instance, one microservice in Java and another one in Erlang or some other language.
    Containers help developers package microservices written in any language or technology
    in a platform- and technology-agnostic fashion and uniformly distribute them across
    multiple environments. Containers eliminate the need to have different deployment
    management tools to handle polyglot microservices. Containers not only abstract
    the execution environment but also how to access the services. Irrespective of
    the technologies used, containerized microservices expose REST APIs. Once the
    container is up and running, it binds to certain ports and exposes its APIs. As
    containers are self-contained and provide full stack isolation among services,
    in a single VM or bare metal, one can run multiple heterogeneous microservices
    and handle them in a uniform way.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous sections talked about containers and their benefits. Containers
    have been in the business for years, but the popularity of Docker has given containers
    a new outlook. As a result, many container definitions and perspectives emerged
    from the Docker architecture. Docker is so popular that even containerization
    is referred to as **dockerization**.
  prefs: []
  type: TYPE_NORMAL
- en: Docker is a platform to build, ship, and run lightweight containers based on
    Linux kernels. Docker has default support for Linux platforms. It also has support
    for Mac and Windows using **Boot2Docker**, which runs on top of Virtual Box.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon **EC2 Container Service** (**ECS**) has out-of-the-box support for Docker
    on AWS EC2 instances. Docker can be installed on bare metals and also on traditional
    virtual machines such as VMWare or Hyper-V.
  prefs: []
  type: TYPE_NORMAL
- en: The key components of Docker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A Docker installation has two key components: a **Docker daemon** and a **Docker
    client**. Both the Docker daemon and Docker client are distributed as a single
    binary.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows the key components of a Docker installation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The key components of Docker](img/B05447_08_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The Docker daemon
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Docker daemon is a server-side component that runs on the host machine responsible
    for building, running, and distributing Docker containers. The Docker daemon exposes
    APIs for the Docker client to interact with the daemon. These APIs are primarily
    REST-based endpoints. One can imagine that the Docker daemon as a controller service
    running on the host machine. Developers can programmatically use these APIs to
    build custom clients as well.
  prefs: []
  type: TYPE_NORMAL
- en: The Docker client
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Docker client is a remote command-line program that interacts with the Docker
    daemon through either a socket or REST APIs. The CLI can run on the same host
    as the daemon is running on or it can run on a completely different host and connect
    to the daemon remotely. Docker users use the CLI to build, ship, and run Docker
    containers.
  prefs: []
  type: TYPE_NORMAL
- en: Docker concepts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Docker architecture is built around a few concepts: images, containers,
    the registry, and the Dockerfile.'
  prefs: []
  type: TYPE_NORMAL
- en: Docker images
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the key concepts of Docker is the image. A Docker image is the read-only
    copy of the operating system libraries, the application, and its libraries. Once
    an image is created, it is guaranteed to run on any Docker platform without alterations.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Spring Boot microservices, a Docker image packages operating systems such
    as Ubuntu, Alpine, JRE, and the Spring Boot fat application JAR file. It also
    includes instructions to run the application and expose the services:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Docker images](img/B05447_08_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As shown in the diagram, Docker images are based on a layered architecture in
    which the base image is one of the flavors of Linux. Each layer, as shown in the
    preceding diagram, gets added to the base image layer with the previous image
    as the parent layer. Docker uses the concept of a union filesystem to combine
    all these layers into a single image, forming a single filesystem.
  prefs: []
  type: TYPE_NORMAL
- en: In typical cases, developers do not build Docker images from scratch. Images
    of an operating system, or other common libraries, such as Java 8 images, are
    publicly available from trusted sources. Developers can start building on top
    of these base images. The base image in Spring microservices can be JRE 8 rather
    than starting from a Linux distribution image such as Ubuntu.
  prefs: []
  type: TYPE_NORMAL
- en: 'Every time we rebuild the application, only the changed layer gets rebuilt,
    and the remaining layers are kept intact. All the intermediate layers are cached,
    and hence, if there is no change, Docker uses the previously cached layer and
    builds it on top. Multiple containers running on the same machine with the same
    type of base images would reuse the base image, thus reducing the size of the
    deployment. For instance, in a host, if there are multiple containers running
    with Ubuntu as the base image, they all reuse the same base image. This is applicable
    when publishing or downloading images as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Docker images](img/B05447_08_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As shown in the diagram, the first layer in the image is a boot filesystem called
    `bootfs`, which is similar to the Linux kernel and the boot loader. The boot filesystem
    acts as a virtual filesystem for all images.
  prefs: []
  type: TYPE_NORMAL
- en: On top of the boot filesystem, the operating system filesystem is placed, which
    is called `rootfs`. The root filesystem adds the typical operating system directory
    structure to the container. Unlike in the Linux systems, `rootfs`, in the case
    of Docker, is on a read-only mode.
  prefs: []
  type: TYPE_NORMAL
- en: On top of `rootfs`, other required images are placed as per the requirements.
    In our case, these are JRE and the Spring Boot microservice JARs. When a container
    is initiated, a writable filesystem is placed on top of all the other filesystems
    for the processes to run. Any changes made by the process to the underlying filesystem
    are not reflected in the actual container. Instead, these are written to the writable
    filesystem. This writable filesystem is volatile. Hence, the data is lost once
    the container is stopped. Due to this reason, Docker containers are ephemeral
    in nature.
  prefs: []
  type: TYPE_NORMAL
- en: The base operating system packaged inside Docker is generally a minimal copy
    of just the OS filesystem. In reality the process running on top may not use the
    entire OS services. In a Spring Boot microservice, in many cases, the container
    just initiates a CMD and JVM and then invokes the Spring Boot fat JAR.
  prefs: []
  type: TYPE_NORMAL
- en: Docker containers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Docker containers are the running instances of a Docker image. Containers use
    the kernel of the host operating system when running. Hence, they share the host
    kernel with other containers running on the same host. The Docker runtime ensures
    that the container processes are allocated with their own isolated process space
    using kernel features such as **cgroups** and the kernel **namespace** of the
    operating system. In addition to the resource fencing, containers get their own
    filesystem and network configurations as well.
  prefs: []
  type: TYPE_NORMAL
- en: The containers, when instantiated, can have specific resource allocations, such
    as the memory and CPU. Containers, when initiated from the same image, can have
    different resource allocations. The Docker container, by default, gets an isolated
    **subnet** and **gateway** to the network. The network has three modes.
  prefs: []
  type: TYPE_NORMAL
- en: The Docker registry
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Docker registry is a central place where Docker images are published and
    downloaded from. The URL [https://hub.docker.com](https://hub.docker.com) is the
    central registry provided by Docker. The Docker registry has public images that
    one can download and use as the base registry. Docker also has private images
    that are specific to the accounts created in the Docker registry. The Docker registry
    screenshot is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Docker registry](img/B05447_08_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Docker also offers **Docker Trusted Registry**, which can be used to set up
    registries locally on premises.
  prefs: []
  type: TYPE_NORMAL
- en: Dockerfile
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A Dockerfile is a build or scripting file that contains instructions to build
    a Docker image. There can be multiple steps documented in the Dockerfile, starting
    from getting a base image. A Dockerfile is a text file that is generally named
    Dockerfile. The `docker build` command looks up Dockerfile for instructions to
    build. One can compare a Dockerfile to a `pom.xml` file used in a Maven build.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying microservices in Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will operationalize our learning by showcasing how to build containers
    for our BrownField PSS microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The full source code of this chapter is available under the `Chapter 8` project
    in the code files. Copy `chapter7.configserver`, `chapter7.eurekaserver`, `chapter7.search`,
    `chapter7.search-apigateway`, and `chapter7.website` into a new STS workspace
    and rename them `chapter8.*`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to build Docker containers for BrownField PSS microservices:'
  prefs: []
  type: TYPE_NORMAL
- en: Install Docker from the official Docker site at [https://www.docker.com](https://www.docker.com).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Follow the **Get Started** link for the download and installation instructions
    based on the operating system of choice. Once installed, use the following command
    to verify the installation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In this section, we will take a look at how to dockerize the **Search** (`chapter8.search`)
    microservice, the **Search API Gateway** (`chapter8.search-apigateway`) microservice,
    and the **Website** (`chapter8.website`) Spring Boot application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Before we make any changes, we need to edit `bootstrap.properties` to change
    the config server URL from localhost to the IP address as localhost is not resolvable
    from within the Docker containers. In the real world, this will point to a DNS
    or load balancer, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Replace the IP address with the IP address of your machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, edit `search-service.properties` on the Git repository and change
    localhost to the IP address. This is applicable for the Eureka URL as well as
    the RabbitMQ URL. Commit back to Git after updating. You can do this via the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Change the RabbitMQ configuration file `rabbitmq.config` by uncommenting the
    following line to provide access to guest. By default, guest is restricted to
    be accessed from localhost only:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The location of `rabbitmq.config` will be different for different operating
    systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a Dockerfile under the root directory of the Search microservice, as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is a quick examination of the contents of the Dockerfile:'
  prefs: []
  type: TYPE_NORMAL
- en: '`FROM frolvlad/alpine-oraclejdk8`: This tells the Docker build to use a specific
    `alpine-oraclejdk8` version as the basic image for this build. The `frolvlad`
    indicates the repository to locate the `alpine-oraclejdk8` image. In this case,
    it is an image built with Alpine Linux and Oracle JDK 8\. This will help layer
    our application on top of the base image without setting up Java libraries ourselves.
    In this case, as this image is not available on our local image store, the Docker
    build will go ahead and download this image from the remote Docker Hub registry.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`VOLUME /tmp`: This enables access from the container to the directory specified
    in the host machine. In our case, this points to the `tmp` directory in which
    the Spring Boot application creates working directories for Tomcat. The `tmp`
    directory is a logical one for the container, which indirectly points to one of
    the local directories of the host.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ADD target/search-1.0.jar search.jar`: This adds the application binary file
    to the container with the destination filename specified. In this case, the Docker
    build copies `target/search-1.0.jar` to the container as `search.jar`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`EXPOSE 8090`: This is to tell the container how to do port mapping. This associates
    `8090` with external port binding for the internal Spring Boot service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ENTRYPOINT ["java","-jar", "/search.jar"]`: This tells the container which
    default application to run when a container is started. In this case, we are pointing
    to the Java process and the Spring Boot fat JAR file to initiate the service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The next step is to run `docker build` from the folder in which the Dockerfile
    is stored. This will download the base image and run the entries in the Dockerfile
    one after the other, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this command will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying microservices in Docker](img/B05447_08_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Repeat the same steps for Search API Gateway and Website.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the images are created, they can be verified by typing the following command.
    This command will list out the images and their details, including the size of
    image files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying microservices in Docker](img/B05447_08_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The next thing to do is run the Docker container. This can be done with the
    `docker run` command. This command will load and run the container. On starting,
    the container calls the Spring Boot executable JAR to start the microservice.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Before starting the containers, ensure that the Config and the Eureka servers
    are running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The preceding command starts the Search and Search API Gateway microservices
    and Website.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we are using the host network `(--net host`) instead of the
    bridge network to avoid Eureka registering with the Docker container name. This
    can be corrected by overriding `EurekaInstanceConfigBean`. The host option is
    less isolated compared to the bridge option from the network perspective. The
    advantage and disadvantage of host versus bridge depends on the project.
  prefs: []
  type: TYPE_NORMAL
- en: Once all the services are fully started, verify with the `docker ps` command,
    as shown in the following screenshot:![Deploying microservices in Docker](img/B05447_08_10.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The next step is to point the browser to `http://192.168.99.100:8001`. This
    will open the BrownField PSS website.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Note the IP address. This is the IP address of the Docker machine if you are
    running with Boot2Docker on Mac or Windows. In Mac or Windows, if the IP address
    is not known, then type the following command to find out the Docker machine''s
    IP address for the default machine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: If Docker is running on Linux, then this is the host IP address.
  prefs: []
  type: TYPE_NORMAL
- en: Apply the same changes to **Booking**, **Fares**, **Check-in**, and their respective
    gateway microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Running RabbitMQ on Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As our example also uses RabbitMQ, let''s explore how to set up RabbitMQ as
    a Docker container. The following command pulls the RabbitMQ image from Docker
    Hub and starts RabbitMQ:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Ensure that the URL in `*-service.properties` is changed to the Docker host's
    IP address. Apply the earlier rule to find out the IP address in the case of Mac
    or Windows.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Docker registry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Docker Hub provides a central location to store all the Docker images. The
    images can be stored as public as well as private. In many cases, organizations
    deploy their own private registries on premises due to security-related concerns.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to set up and run a local registry:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following command will start a registry, which will bind the registry on
    port `5000`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Tag `search:1.0` to the registry, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, push the image to the registry via the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Pull the image back from the registry, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Setting up the Docker Hub
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous chapter, we played with a local Docker registry. This section
    will show how to set up and use the Docker Hub to publish the Docker containers.
    This is a convenient mechanism to globally access Docker images. Later in this
    chapter, Docker images will be published to the Docker Hub from the local machine
    and downloaded from the EC2 instances.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to do this, create a public Docker Hub account and a repository. For
    Mac, follow the steps as per the following URL: [https://docs.docker.com/mac/step_five/](https://docs.docker.com/mac/step_five/).'
  prefs: []
  type: TYPE_NORMAL
- en: In this example, the Docker Hub account is created using the `brownfield` username.
  prefs: []
  type: TYPE_NORMAL
- en: The registry, in this case, acts as the microservices repository in which all
    the dockerized microservices will be stored and accessed. This is one of the capabilities
    explained in the microservices capability model.
  prefs: []
  type: TYPE_NORMAL
- en: Publishing microservices to the Docker Hub
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to push dockerized services to the Docker Hub, follow these steps.
    The first command tags the Docker image, and the second one pushes the Docker
    image to the Docker Hub repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: To verify whether the container images are published, go to the Docker Hub repository
    at `https://hub.docker.com/u/brownfield`.
  prefs: []
  type: TYPE_NORMAL
- en: Repeat this step for all the other BrownField microservices as well. At the
    end of this step, all the services will be published to the Docker Hub.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices on the cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the capabilities mentioned in the microservices capability model is the
    use of the cloud infrastructure for microservices. Earlier in this chapter, we
    also explored the necessity of using the cloud for microservices deployments.
    So far, we have not deployed anything to the cloud. As we have eight microservices
    in total—`Config-server`, `Eureka-server`, Turbine, RabbitMQ, Elasticsearch, Kibana,
    and Logstash—in our overall BrownField PSS microservices ecosystem, it is hard
    to run all of them on the local machine.
  prefs: []
  type: TYPE_NORMAL
- en: In the rest of this book, we will operate using AWS as the cloud platform to
    deploy BrownField PSS microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Docker on AWS EC2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will install Docker on the EC2 instance.
  prefs: []
  type: TYPE_NORMAL
- en: This example assumes that readers are familiar with AWS and an account is already
    created on AWS.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to set up Docker on EC2:'
  prefs: []
  type: TYPE_NORMAL
- en: Launch a new EC2 instance. In this case, if we have to run all the instances
    together, we may need a large instance. The example uses **t2.large**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In this example, the following Ubuntu AMI image is used: `ubuntu-trusty-14.04-amd64-server-20160114.5
    (ami-fce3c696)`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Connect to the EC2 instance and run the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command will install Docker on an EC2 instance. Verify the installation
    with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Running BrownField services on EC2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will set up BrownField microservices on the EC2 instances
    created. In this case, the build is set up in the local desktop machine, and the
    binaries will be deployed to AWS.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to set up services on an EC2 instance:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install Git via the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Create a Git repository on any folder of your choice.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change the Config server's `bootstrap.properties` to point to the appropriate
    Git repository created for this example.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change the `bootstrap.properties` of all the microservices to point to the config-server
    using the private IP address of the EC2 instance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copy all `*.properties` from the local Git repository to the EC2 Git repository
    and perform a commit.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change the Eureka server URLs and RabbitMQ URLs in the `*.properties` file to
    match the EC2 private IP address. Commit the changes to Git once they have been
    completed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the local machine, recompile all the projects and create Docker images for
    the `search`, `search-apigateway`, and `website` microservices. Push all of them
    to the Docker Hub registry.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copy the config-server and the Eureka-server binaries from the local machine
    to the EC2 instance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set up Java 8 on the EC2 instance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, execute the following commands in sequence:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Check whether all the services are working by opening the URL of the website
    and executing a search. Note that we will use the public IP address in this case:
    `http://54.165.128.23:8001`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Updating the life cycle manager
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 6](ch06.html "Chapter 6. Autoscaling Microservices"), *Autoscaling
    Microservices*, we considered a life cycle manager to automatically start and
    stop instances. We used SSH and executed a Unix script to start the Spring Boot
    microservices on the target machine. With Docker, we no longer need SSH connections
    as the Docker daemon provides REST-based APIs to start and stop instances. This
    greatly simplifies the complexities of the deployment engine component of the
    life cycle manager.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will not rewrite the life cycle manager. By and large, we
    will replace the life cycle manager in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The future of containerization – unikernels and hardened security
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Containerization is still evolving, but the number of organizations adopting
    containerization techniques has gone up in recent times. While many organizations
    are aggressively adopting Docker and other container technologies, the downside
    of these techniques is still in the size of the containers and security concerns.
  prefs: []
  type: TYPE_NORMAL
- en: Currently, Docker images are generally heavy. In an elastic automated environment,
    where containers are created and destroyed quite frequently, size is still an
    issue. A larger size indicates more code, and more code means that it is more
    prone to security vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: The future is definitely in small footprint containers. Docker is working on
    unikernels, lightweight kernels that can run Docker even on low-powered IoT devices.
    Unikernels are not full-fledged operating systems, but they provide the basic
    necessary libraries to support the deployed applications.
  prefs: []
  type: TYPE_NORMAL
- en: The security issues of containers are much discussed and debated. The key security
    issues are around the user namespace segregation or user ID isolation. If the
    container is on root, then it can by default gain the root privilege of the host.
    Using container images from untrusted sources is another security concern. Docker
    is bridging these gaps as quickly as possible, but there are many organizations
    that use a combination of VMs and Docker to circumvent some of the security concerns.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about the need to have a cloud environment when
    dealing with Internet-scale microservices.
  prefs: []
  type: TYPE_NORMAL
- en: We explored the concept of containers and compared them with traditional virtual
    machines. You also learned the basics of Docker, and we explained the concepts
    of Docker images, containers, and registries. The importance and benefits of containers
    were explained in the context of microservices.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter then switched to a hands-on example by dockerizing the BrownField
    microservice. We demonstrated how to deploy the Spring Boot microservice developed
    earlier on Docker. You learned the concept of registries by exploring a local
    registry as well as the Docker Hub to push and pull dockerized microservices.
  prefs: []
  type: TYPE_NORMAL
- en: As the last step, we explored how to deploy a dockerized BrownField microservice
    in the AWS cloud environment.
  prefs: []
  type: TYPE_NORMAL
