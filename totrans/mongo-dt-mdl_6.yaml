- en: Chapter 6. Managing the Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Planning a database operation is one of the most important phases of data model
    maintenance. In MongoDB, depending on the nature of the data, we can segregate
    the application's operations by functionality or by geographic groups.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will review some concepts already introduced in [Chapter
    5](ch05.html "Chapter 5. Optimizing Queries"), *Optimizing Queries*, such as read
    preferences and write concerns. But this time we will focus on understanding how
    these functionalities can help us to split the operations through MongoDB deployments,
    for instance, separating read and write operations, or ensuring information consistency
    using the write propagation through replica set nodes, considering the application's
    characteristics.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: You will also see how it is possible to have collections that support a high
    read/write throughput—which is essential for some applications—by exploring special
    properties.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, in this chapter, you will learn about:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Operational segregation
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Capped collections
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data self-expiration
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operational segregation
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have seen how our application's queries can influence, in general,
    our decisions regarding document design. However, there is more to the read preferences
    and write concern concepts than we have already explored.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: MongoDB offers us a series of functionalities that allow us to segregate the
    application operations by functional or geographic groups. When using the functional
    segregation, we can direct an application responsible for report generation to
    use only a certain MongoDB deployment. The geographic segregation means that we
    can target operations considering the geographic distance from a MongoDB deployment.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Giving priority to read operations
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is not that hard to imagine that once an application is built, marketing
    or commercial people will ask for a new report of the application's data, and
    by the way, this will be the essential report. We know how dangerous it can be
    to build and plug such applications in our main database just for the purpose
    of reporting. Besides the data concurrence with other applications, we know that
    this type of application can overload our database by making complex queries and
    manipulating a huge amount of data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: This is the reason why we must target dedicated MongoDB deployments to the operations
    that handle huge volumes of data and need heavier processing from the database.
    We will make applications target the right MongoDB deployments through read preferences
    as you already saw in [Chapter 5](ch05.html "Chapter 5. Optimizing Queries"),
    *Optimizing Queries*.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: By default, an application will always read the first node from our replica
    set. This behavior guarantees that the application will always read the most recent
    data, which ensures the data's consistency. Although, if the intention is to reduce
    the throughput in the first node, and we can accept eventual consistence, it is
    possible to redirect the read operations to secondary nodes from the replica set
    by enabling the `secondary` or `secondaryPreferred` mode.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Besides the function of throughput reduction on the primary node, giving preference
    to read operations in a secondary node is crucial when we have application distributed
    in multiple datacenters and consequently, we have replica sets distributed geographically.
    This is because we make it possible to choose the nearest node or a node with
    the lowest latency to execute the read operation by setting the nearest mode.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we can substantially increase the database's availability by allowing
    the read operations to be executed in any replica set node using the `primaryPreferred`
    mode.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: But what if, in addition to the read preference specification, primary or secondary,
    we could specify in which instance we will target an operation? For instance,
    think of a replica set that is distributed in two different locations and each
    instance has a different type of physical storage. In addition to this, we want
    to ensure that the write operation will be performed in at least one instance
    of each datacenter that has an **ssd** disk. Is this possible? The answer is *yes*!
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，除了读取偏好规范，主要或次要，如果我们还可以指定将操作定位到哪个实例呢？例如，考虑一个分布在两个不同位置的副本集，每个实例都有不同类型的物理存储。除此之外，我们希望确保写操作将在至少一个具有**ssd**磁盘的每个数据中心的实例中执行。这是可能的吗？答案是*是*！
- en: This is possible due to **tag sets**. Tags sets are a configuration property
    that give you control over write concerns and read preferences for a replica set.
    They consist of a document containing zero or more tags. We will store this configuration
    in the replica set configuration document in the `members[n].tags` field.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这是由于**标签集**。标签集是一个配置属性，可以控制副本集的写关注和读偏好。它们由一个包含零个或多个标签的文档组成。我们将把这个配置存储在副本集配置文档的`members[n].tags`字段中。
- en: In the case of read preferences, the tag sets grant you target read operations
    for a specific member of a replica set. The tag sets values are applied when the
    replica set member for the read process is chosen.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在读取偏好的情况下，标签集允许您为副本集的特定成员定位读取操作。当选择读取过程的副本集成员时，标签集值将被应用。
- en: The tag sets will affect only one of the read preference modes, which are `primaryPreferred`,
    `secondary`, `secondaryPreferred`, and `nearest`. The tag sets will have no effect
    on the `primary` mode, meaning that it will only impact the choice of a replica
    set secondary member, unless used in combination with the `nearest` mode, where
    the closest node or the less latency node can be the primary node.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 标签集只会影响读取偏好模式之一，即`primaryPreferred`、`secondary`、`secondaryPreferred`和`nearest`。标签集不会影响`primary`模式，这意味着它只会影响副本集次要成员的选择，除非与`nearest`模式结合使用，在这种情况下，最接近的节点或延迟最小的节点可以成为主节点。
- en: Before we see how to do this configuration, you need to understand how the replica
    set member is chosen. The client driver that will perform the operation makes
    the choice, or in the case of a sharded cluster, the choice is done by the **mongos**
    instance.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在看如何进行此配置之前，您需要了解副本集成员是如何选择的。将执行操作的客户端驱动程序进行选择，或者在分片集群的情况下，选择是由**mongos**实例完成的。
- en: 'Therefore, the choice process is done in the following way:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，选择过程是这样进行的：
- en: A list of the members, both primary and secondary, is created.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建主要和次要成员的列表。
- en: If a tag set is specified, the members that do not match the specification are
    skipped.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果指定了标签集，则不符合规范的成员将被跳过。
- en: The client that is nearest to the application is determined.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定最接近应用程序的客户端。
- en: A list of the other replica set members is created considering the latency among
    the other members. This latency can be defined as soon as the write operation
    is performed through the `secondaryAcceptableLatencyMS` property. In the case
    of a sharded cluster, it is set through the `--localThreshold` or `localPingThresholdMs`
    options. If none of these configurations are set, the default value will be 15
    milliseconds.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建其他副本集成员的列表，考虑其他成员之间的延迟。此延迟可以在通过`secondaryAcceptableLatencyMS`属性执行写操作时定义。在分片集群的情况下，可以通过`--localThreshold`或`localPingThresholdMs`选项进行设置。如果没有设置这些配置中的任何一个，那么默认值将为15毫秒。
- en: Tip
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: You can find more about this configuration in the MongoDB manual reference at
    [http://docs.mongodb.org/manual/reference/configuration-options/#replication.localPingThresholdMs](http://docs.mongodb.org/manual/reference/configuration-options/#replication.localPingThresholdMs).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在MongoDB手册参考中找到有关此配置的更多信息[http://docs.mongodb.org/manual/reference/configuration-options/#replication.localPingThresholdMs](http://docs.mongodb.org/manual/reference/configuration-options/#replication.localPingThresholdMs)。
- en: The host that will be chosen to perform the operation is randomly selected and
    the read operation is performed.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将随机选择要执行操作的主机，并执行读操作。
- en: The tag set configuration is as easy and simple as any other MongoDB configuration.
    As always, we use documents to create a configuration, and as stated before, the
    tag sets are a field of the replica set configuration document. This configuration
    document can be retrieved by running the `conf()` method on a replica set member.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 标签集配置与任何其他MongoDB配置一样简单。与往常一样，我们使用文档来创建配置，并且如前所述，标签集是副本集配置文档的一个字段。可以通过在副本集成员上运行`conf()`方法来检索此配置文档。
- en: Tip
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: You can find out more about the `conf()` method in the MongoDB documentation
    at [http://docs.mongodb.org/manual/reference/method/rs.conf/#rs.conf](http://docs.mongodb.org/manual/reference/method/rs.conf/#rs.conf).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在MongoDB文档中找到有关`conf()`方法的更多信息[http://docs.mongodb.org/manual/reference/method/rs.conf/#rs.conf](http://docs.mongodb.org/manual/reference/method/rs.conf/#rs.conf)。
- en: 'The following document shows a tag set example for a read operation, after
    an execution of the `rs.conf()` command on the mongod shell of the `rs1`, which
    is our replica set''s primary node:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 以下文件显示了在`rs1`的mongod shell上执行`rs.conf()`命令后，读操作的标签集示例，这是我们副本集的主节点。
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To create a tag set configuration for each node of the replica set, we must
    do the following sequence of commands in the primary mongod shell:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 要为副本集的每个节点创建标签集配置，我们必须在主要的mongod shell中执行以下命令序列：
- en: 'First, we will get the replica set configuration document and store it in the
    `cfg` variable:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将获取副本集配置文档并将其存储在`cfg`变量中：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, by using the `cfg` variable, we will set a document as a new value to
    the `members[n].tags` field for each one of our three replica set members:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，通过使用`cfg`变量，我们将为我们的三个副本集成员中的每一个设置一个文档作为`members[n].tags`字段的新值：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Finally, we call the `reconfig()` method, passing in our new configuration
    document stored in the `cfg` variable to reconfigure our replica set:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们调用`reconfig()`方法，传入存储在`cfg`变量中的新配置文档以重新配置我们的副本集：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If everything is correct, then we must see this output in the mongod shell:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切正确，我们必须在mongod shell中看到这个输出：
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To check the configuration, we can re-execute the command `rs.conf()`. This
    will return the following:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查配置，我们可以重新执行命令`rs.conf()`。这将返回以下内容：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, consider the following `customer` collection:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，考虑以下`customer`集合：
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The following read operations will use the tags created in our replica set''s
    instances:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的读操作将使用我们副本集实例中创建的标签：
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The preceding configuration is an example of *segregation by application operation*.
    We created tag sets, marking the application's nature and what the media type
    that will be read will be.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的配置是*按应用操作分离*的一个例子。我们创建了标签集，标记了应用的性质以及将要读取的媒体类型。
- en: 'As we have seen before, tag sets are very useful when we need to separate our
    application geographically. Suppose that we have MongoDB applications and instances
    of our replica set in two different datacenters. Let''s create tags that will
    indicate in which datacenter our instances are present by running the following
    sequence on the replica set primary node mongod shell. First, we will get the
    replica set configuration document and store it in the `cfg` variable:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所看到的，当我们需要在地理上分离我们的应用时，标签集非常有用。假设我们在两个不同的数据中心中有MongoDB应用程序和副本集的实例。让我们通过在副本集主节点mongod
    shell上运行以下序列来创建标签，这些标签将指示我们的实例位于哪个数据中心。首先，我们将获取副本集配置文档并将其存储在`cfg`变量中：
- en: '[PRE8]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then, by using the `cfg` variable, we will set a document as a new value to
    the `members[n].tags` field, for each one of our three replica set members:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，通过使用`cfg`变量，我们将为我们的三个副本集成员中的每一个设置一个文档作为`members[n].tags`字段的新值：
- en: '[PRE9]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Finally, we call the `reconfig()` method, passing our new configuration document
    stored in the `cfg` variable to reconfigure our replica set:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们调用`reconfig()`方法，传入存储在`cfg`变量中的新配置文档以重新配置我们的副本集：
- en: '[PRE10]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'If everything is correct, then we will see this output in the mongod shell:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切正确，我们将在mongod shell中看到这个输出：
- en: '[PRE11]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The result of our configuration can be checked by executing the command `rs.conf()`:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的配置结果可以通过执行命令`rs.conf()`来检查：
- en: '[PRE12]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In order to target a read operation to a given datacenter, we must specify
    it in a new tag inside our query. The following queries will use the tags and
    each one will be executed in its own datacenter:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将读操作定位到特定的数据中心，我们必须在查询中指定一个新的标签。以下查询将使用标签，并且每个查询将在自己的数据中心中执行：
- en: '[PRE13]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In write operations, the tag sets are not used to choose the replica set member
    that will be available to write. Although, it is possible to use tag sets in write
    operations through the creation of custom write concerns.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在写操作中，标签集不用于选择可用于写入的副本集成员。尽管可以通过创建自定义写关注来在写操作中使用标签集。
- en: 'Let''s get back to the requirement raised at the beginning of this section.
    How can we ensure that a write operation will be spread over at least two instances
    of a geographic area? By running the sequence of the following commands on the
    replica set primary node mongod shell, we will configure a replica set with five
    instances:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到本节开头提出的要求。我们如何确保写操作将分布在地理区域的至少两个实例上？通过在副本集主节点mongod shell上运行以下命令序列，我们将配置一个具有五个实例的副本集：
- en: '[PRE14]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The tags `riodc` and `spdc` represent which localities our instances are physically
    present in.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 标签`riodc`和`spdc`表示我们的实例所在的地理位置。
- en: Now, let's create a custom `writeConcern` MultipleDC using the property `getLastErrorModes`.
    This will ensure that the write operation will be spread to at least one location
    member.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建一个自定义的`writeConcern` MultipleDC，使用`getLastErrorModes`属性。这将确保写操作将分布到至少一个位置成员。
- en: 'To do this, we will execute the preceding sequence, where we set a document
    representing our custom write concern on the `settings` field of our replica set
    configuration document:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们将执行前面的序列，其中我们在副本集配置文档的`settings`字段上设置了一个代表我们自定义写关注的文档：
- en: '[PRE15]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output in the mongod shell should look like this:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: mongod shell中的输出应该是这样的：
- en: '[PRE16]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Then we call the `reconfig()` method, passing the new configuration:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们调用`reconfig()`方法，传入新的配置：
- en: '[PRE17]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'If the execution was successful, the output in the mongod shell is a document
    like this:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果执行成功，在mongod shell中的输出将是这样的文档：
- en: '[PRE18]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'From this moment, we can use a `writeConcern` MultipleDC in order to ensure
    that the write operation will be performed in at least one node of each data center
    shown, as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 从这一刻起，我们可以使用`writeConcern` MultipleDC来确保写操作将在每个显示的数据中心的至少一个节点中执行，如下所示：
- en: '[PRE19]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Back to our requirement, if we want the write operation to be performed in
    at least two instances of each datacenter, we must configure it in the following
    way:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的要求，如果我们希望写操作至少在每个数据中心的两个实例中执行，我们必须按以下方式配置：
- en: '[PRE20]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'And, fulfilling our requirement, we can create a `writeConcern` MultipleDC
    called `ssd`. This will ensure that the write operation will happen in at least
    one instance that has this type of disk:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 并且，满足我们的要求，我们可以创建一个名为`ssd`的`writeConcern` MultipleDC。这将确保写操作将发生在至少一个具有这种类型磁盘的实例中：
- en: '[PRE21]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In the following query, we see how using a `writeConcern` MultipleDC requires
    the write operation to be present in at least one instance that has `ssd`:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的查询中，我们看到使用`writeConcern` MultipleDC需要写操作至少出现在具有`ssd`的一个实例中：
- en: '[PRE22]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: It is not a simple task to make an operational segregation in our database.
    However, it is very useful for the database's management and maintenance. The
    early implementation of this kind of task requires a good knowledge of our data
    model, as details about the storage our database resides in are highly important.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will see how to plan collections for applications that
    need high throughput and fast response times.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you want to learn more about how to configure replica set tag sets, you can
    visit the MongoDB reference manual at [http://docs.mongodb.org/manual/tutorial/configure-replica-set-tag-sets/#replica-set-configuration-tag-sets](http://docs.mongodb.org/manual/tutorial/configure-replica-set-tag-sets/#replica-set-configuration-tag-sets).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Capped collections
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Non-functional requirements are often related to the application's response
    time. Especially nowadays when we are connected to news feeds all the time and
    we want fresh information to be available in the shortest response time.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: MongoDB has a special type of collection that meets this non-functional requirement,
    capped collections. Capped collections are fixed size collections that support
    high read and write throughput. This is because the documents are inserted in
    their natural order, without the need for an index to perform the write operation.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: The natural insertion order is guaranteed by MongoDB, which writes the data
    like it is written on the disk. Therefore, updates that increase the document
    size are not allowed during the document's lifecycle. As soon as the collection
    reaches maximum size, MongoDB automatically cleans old documents so that new documents
    can be inserted.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: One very common use case is the persistence of application logs. MongoDB itself
    uses the replica set operation log, `oplog.rs`, as a capped collection. In [Chapter
    8](ch08.html "Chapter 8. Logging and Real-time Analytics with MongoDB"), *Logging
    and Real-time Analytics with MongoDB*, you will see another practical example
    of this.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Another very common usage of MongoDB is as a publisher/subscriber system, especially
    if we use tailable cursors. Tailable cursors are cursors that remain open even
    after the client reads all the returned records. So, when new documents are inserted
    into the collection, the cursor returns it to the client.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: 'The following command creates the `ordersQueue` collection:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We used the `util` command `createCollection` to create our capped collection,
    passing to it the name `ordersQueue` and a collection with the `capped` property
    with the value `true` and `size` with a value of `10000`. If the `size` property
    is less than 4,096, MongoDB adjusts it to 4,096 bytes. On the other hand, if it
    is greater than 4,096, MongoDB raises the size and adjusts it to be a multiple
    of 256.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: 'Optionally, we can set the maximum document number that a collection can have
    by using the `max` property:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Note
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If we need to convert a collection into a capped collection, we should use
    the `convertToCapped` method as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'As we have already seen, MongoDB keeps the documents in a natural order, in
    other words, the order in which they are inserted into MongoDB. Consider the following
    documents, inserted in the `ordersQueue` collection as shown:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The query `db.ordersQueue.find()` produces the following result:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'If we use the `$natural` operator as shown in the following query, we will
    have the same result as shown in the preceding output:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'But if we need the last insertion first, we must execute the command with a
    `-1` value on the `$natural` operator:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We must be careful when creating a capped collection as:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: We cannot shard a capped collection.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We cannot update a document in a capped collection; otherwise, the document
    grows in size. If we need to update a document in a capped collection, then we
    must make sure that the size will remain the same. And for better performance,
    we should create an index to avoid a collection scan when updating.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We cannot delete a document in a capped collection.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们无法在封顶集合中删除文档。
- en: Capped collections are a good tool when we have a high read/write throughput
    as a non-functional requirement, or we need to limit the collection size in bytes
    or by document number.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们具有高读/写吞吐量作为非功能性要求，或者需要按字节大小或文档数量限制集合大小时，封顶集合是一个很好的工具。
- en: Nonetheless, if we need to automatically expire data, based on a time frame,
    we should use the **time to live** (**TTL**) function.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，如果我们需要根据时间范围自动使数据过期，我们应该使用**生存时间**（TTL）函数。
- en: Data self-expiration
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据自动过期
- en: As you already saw in [Chapter 4](ch04.html "Chapter 4. Indexing"), *Indexing*,
    MongoDB offers us an index type that helps us to remove data from a collection
    after a certain amount of time in seconds, or by a specific date.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在[第4章](ch04.html "第4章。索引")中已经看到的，MongoDB为我们提供了一种索引类型，可以帮助我们在一定时间后或特定日期之后从集合中删除数据。
- en: Indeed, the TTL is a background thread that executes on a mongod instance that
    looks for documents with date typed fields on the index, and removes them.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，TTL是在mongod实例上执行的后台线程，它会查找索引上具有日期类型字段的文档，并将其删除。
- en: 'Consider a `customers` collection with the following document:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个名为`customers`的集合，其中包含以下文档：
- en: '[PRE30]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'To expire the documents in this collection after 360 seconds, we should create
    the following index:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在360秒后使该集合中的文档过期，我们应该创建以下索引：
- en: '[PRE31]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'To expire the documents at exactly 2015-01-11 20:27:02, we should create the
    following index:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在2015-01-11 20:27:02准确地使文档过期，我们应该创建以下索引：
- en: '[PRE32]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'When using the TTL function, we must take extra care and keep the following
    points in mind:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用TTL函数时，我们必须格外小心，并牢记以下几点：
- en: We cannot create a TTL index on a capped collection because MongoDB will not
    be able to remove documents from the collection.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们无法在封顶集合上创建TTL索引，因为MongoDB无法从集合中删除文档。
- en: A TTL index cannot have a field that is part of another index.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TTL索引不能具有作为另一个索引一部分的字段。
- en: The field of the index should be a Date or array of a Date type.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索引字段应为日期或日期类型的数组。
- en: Despite having the background thread in every replica set node, which removes
    the documents when we have a TTL index, it will only remove them from the primary
    one. The replication process will delete the documents from the secondary nodes
    of the replica set.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管在每个副本集节点中都有后台线程，可以在具有TTL索引时删除文档，但它只会从主节点中删除它们。复制过程将从副本集的辅助节点中删除文档。
- en: Summary
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you saw that besides thinking of our schema design based on
    our queries, it is also important to think about the planning of the operation
    and maintenance for the creation of our collections.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您看到了除了根据我们的查询来思考架构设计之外，还要考虑规划操作和维护来创建我们的集合。
- en: You learned how to use tag sets to deal with datacenter-aware operations and
    why we limit the amount of documents stored in our collections by doing a capped
    collection. In the same manner, you saw how TTL indexes can be useful in real-life
    use cases.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 您学会了如何使用标签集来处理数据中心感知操作，以及为什么通过创建封顶集合来限制我们集合中存储的文档数量。同样，您还了解了TTL索引在实际用例中的用处。
- en: In the next chapter, you will see how we can scale our MongoDB instance by creating
    shards.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将看到如何通过创建分片来扩展我们的MongoDB实例。
