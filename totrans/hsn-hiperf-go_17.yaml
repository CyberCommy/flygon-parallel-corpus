- en: Clusters and Job Queues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Clustering and job queues in Go are good ways to get distributed systems to
    work synchronously and deliver a consistent message. Distributed computing is
    difficult and it becomes very important to watch for potential performance optimizations
    within both clustering and job queues.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will learn about the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Clustering with hierarchical and centroid algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goroutines as queues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Buffered channels as job queues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing third-party queuing systems (Kafka and RabbitMQ)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning about different clustering systems can help you identify large groups
    of data and how to accurately classify them in your datasets. Learning about queueing
    systems will help you move large amounts of information from your data structures
    into specific queueing mechanisms in order to pass large amounts of data to different
    systems in real time.
  prefs: []
  type: TYPE_NORMAL
- en: Clustering in Go
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Clustering is a methodology that you can use in order to search for consistent
    groups of data within a given dataset. Using comparison techniques, we can look
    for groups of items within the dataset that contain similar characteristics. These
    individual datapoints are then divided into clusters. Clustering is commonly used
    in order to solve multi-objective problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two general classifications of clustering, both of which have distinct
    subclassifications:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hard clustering**: The datapoints within the dataset are either explicitly
    a part of a cluster or not explicitly part of a cluster. Hard clustering can be
    further classified as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Strict partitioning**: An object can belong to exactly one cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Strict partitioning with outliers**: Strict partitioning, which also includes
    a concept that objects can be classified as outliers (meaning they belong to no
    cluster).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Overlapping clustering**: Individual objects can be associated with one or
    more clusters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Soft clustering**: Datapoints are assigned a probability that they are associated
    with a particular cluster based on explicit criteria. They can be further classified
    as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Subspace**: Clusters use a two-dimensional subspace in order to be further
    classified into two dimensions.'
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hierarchical**: Clustering using a hierarchical model; an object that is
    associated with a child cluster is also associated with the parent clusters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are also many different algorithm types that are used for clustering.
    Some examples are shown in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Name** | **Definition** |'
  prefs: []
  type: TYPE_TB
- en: '| Hierarchical | Used to attempt to build a hierarchy of clusters. Usually
    based on a top-down or a bottom-up approach, attempting to segment datapoints
    either from one to many clusters (top-down) or many to few clusters (bottom-up).
    |'
  prefs: []
  type: TYPE_TB
- en: '| Centroid | Used to find a specific point location that acts as the center
    of a cluster. |'
  prefs: []
  type: TYPE_TB
- en: '| Density | Used to look for places in the dataset that have dense regions
    of datapoints. |'
  prefs: []
  type: TYPE_TB
- en: '| Distribution | Used to utilize distribution models to order and classify
    datapoints within a cluster. |'
  prefs: []
  type: TYPE_TB
- en: In this book, we're going to focus on hierarchical and centroid algorithms as
    they are commonly used in computer science (namely in machine learning).
  prefs: []
  type: TYPE_NORMAL
- en: K-nearest neighbors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hierarchical clustering is a clustering method in which an object that is associated
    with a child cluster is also associated with the parent clusters. The algorithm
    begins with all of the individual datapoints in the data struct being assigned
    to individual clusters. The nearest clusters to one another merge. This pattern
    continues until all the datapoints have an association with another datapoint.
    Hierarchical clustering is often displayed using a charting technique called a
    **dendrogram**. Hierarchical clustering is *O(n²)*, so it's not typically used
    for large datasets.
  prefs: []
  type: TYPE_NORMAL
- en: The **K-nearest neighbors** (**KNN**) algorithm is a hierarchical algorithm
    often used in machine learning. One of the most popular ways to find KNN data
    in Go is with the `golearn` package. A classic KNN example that gets used as a
    machine learning example is the classification of iris flowers, which can be seen
    at [https://github.com/sjwhitworth/golearn/blob/master/examples/knnclassifier/knnclassifier_iris.go](https://github.com/sjwhitworth/golearn/blob/master/examples/knnclassifier/knnclassifier_iris.go).
  prefs: []
  type: TYPE_NORMAL
- en: 'Given a dataset with sepal and petal lengths and widths, we can see calculated
    data about this dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7fb62e91-76e2-436a-9266-d4a7993c2271.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can see the calculated accuracy in this prediction model. In the preceding
    output, we have the following descriptors:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Descriptor** | **Definition** |'
  prefs: []
  type: TYPE_TB
- en: '| Reference Class | A title associated with the output. |'
  prefs: []
  type: TYPE_TB
- en: '| True Positives | The model correctly predicts a positive response. |'
  prefs: []
  type: TYPE_TB
- en: '| False Positives | The model incorrectly predicts a positive response. |'
  prefs: []
  type: TYPE_TB
- en: '| True Negatives | The model correctly predicts a negative response. |'
  prefs: []
  type: TYPE_TB
- en: '| Precision | Ability to not label an instance positive that''s actually negative.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Recall | A ratio of *True Positives / (Sum of True Positives + False Negatives)*.
    |'
  prefs: []
  type: TYPE_TB
- en: '| F1 Score | The weighted harmonic mean of precision and recall. This value
    is somewhere between 0.0 and 1.0, with 1.0 being the best possible outcome for
    this value. |'
  prefs: []
  type: TYPE_TB
- en: Last but certainly not least, we have an overall accuracy, which tells us how
    accurately our algorithm predicted our outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: K-means clustering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: K-means clustering is one of the most commonly utilized clustering algorithms
    in machine learning. K-means attempts to identify the underlying patterns of datapoints
    in a dataset. In K-means, we define *k* as the number of centroids (the center
    of an object with uniform density) that our cluster has. Then, we categorize the
    different datapoints with respect to those centroids.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the K-means library, which can be found at [https://github.com/muesli/kmeans](https://github.com/muesli/kmeans),
    in order to perform K-means clustering on a dataset. Let''s take a look:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we instantiate the `main` package and import our required packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create a random two-dimensional dataset with the `createDataset` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create a function that allows us to print our data for consumption:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In our `main` function, we define our cluster size, our dataset size, and our
    threshold size.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can create a new random 2D dataset and perform K-means clustering on
    that dataset. We plot the result and print our clusters as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'After we execute this function, we will be able to see our datapoints grouped
    together in their respective clusters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2569c1a4-10e2-4215-bc8d-1ed8556cbf77.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In our results, we can see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Our initial (randomly generated) 2D dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our three defined clusters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The associated datapoints that are assigned to each cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This program also generates `.png` images of each step of clustering. The one
    that was created last is a visualization of the clustering of the datapoints:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7319abcf-10d1-4f28-9995-4ac9319a7783.png)'
  prefs: []
  type: TYPE_IMG
- en: 'K-means clustering is a very good algorithm to use if you want to group a large
    dataset into smaller groups. It has an O notation of *O(n)*, so it is often practical
    to use for large datasets. Practical applications of K-means clustering may include
    two-dimensional datasets for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Identifying crime-prone areas on a map using GPS coordinates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying clustering of pages for on-call developers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying athlete performance characteristics based on step output compared
    to the number of rest days
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, let's explore job queues in Go.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring job queues in Go
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Job queues are frequently used to process units of work in a computer system.
    They are often used to schedule both synchronous and asynchronous functions. While
    working with larger datasets, there can be data structures and algorithms that
    take quite a bit of time to process. Either the system is processing a very large
    segment of data, the algorithm that is being applied to the dataset is very complex,
    or there's a combination of the two. Being able to add these jobs to a job queue
    and perform them in a different order or at different times can be very helpful
    to maintain the stability of a system and give an end user a better experience.
    Job queues are also frequently used for asynchronous jobs since the time when
    the job completes isn't as impactful for the end user. The job system can also
    prioritize the jobs in a priority queue if one is implemented. This allows the
    system to process the most important jobs first, followed by the jobs that don't
    have as much of an explicit deadline.
  prefs: []
  type: TYPE_NORMAL
- en: Goroutines as job queues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Perhaps you don't need a job queue for your particular task. Using a goroutine
    for a task is often sufficient. Let's say that we want to send an email asynchronously
    during some particular task. We can send this email using a goroutine within our
    function.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this example, I''m going to send an email via Gmail. To do so, you may
    need to allow less secure app access for email authentication to work ([https://myaccount.google.com/lesssecureapps?pli=1](https://myaccount.google.com/lesssecureapps?pli=1)).
    This is not recommended to do in the long term; it''s just a simple way to show
    a real-world email interaction. If you''re interested in building a more robust
    email solution, you can use the Gmail API at [https://developers.google.com/gmail/api/quickstart/go](https://developers.google.com/gmail/api/quickstart/go).
    Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we''ll instantiate our `main` package and import the necessary packages
    into our sample program:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will create our `main` function, which will do the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log a `Doing Work` line (representative of doing other things in our function).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Log a `Sending Emails` line (representative of the time where the email is added
    to the goroutine).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spawn a goroutine to send the email.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sleep to ensure the goroutine completes (we could use a `WaitGroup` here too
    if we''d like):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'In our `sendMail` function, we take in a recipient, set the proper email headers
    we need to send our email, and send it using the `gomail` dialer. You''ll need
    to change the `sender`, `recipient`, `username`, and `password` variables if you''d
    like to see this program execute successfully:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see from our resulting output that we are able to effectively do some
    work and send an email:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/052fc4f2-e76f-42bd-bb2f-a0c295ca6763.png)'
  prefs: []
  type: TYPE_IMG
- en: It's been noted as a core tenant in this book that the most performant method
    to perform a task can often be the simplest one. If you don't need to build a
    new job-queueing system to perform a simple task, you should avoid it. At larger
    companies, there are often dedicated teams to maintaining job queue systems for
    large-scale data. They are expensive from both performance and cost perspectives.
    They are often important to manage large-scale data systems, but I feel as if
    I'd be remiss if I didn't mention that you should take careful consideration before
    you add a distributed job queue to your technology stack.
  prefs: []
  type: TYPE_NORMAL
- en: Buffered channels as job queues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Go''s buffered channels are a perfect example of a worker queue. As we learned
    in [Chapter 3](61b73482-0431-4b8f-a069-d647ac1c1b87.xhtml), *Understanding Concurrency*,
    buffered channels are channels that have a bounded size. They are typically more
    performant than their unbounded counterpart. They are useful for retrieving values
    from an explicit number of goroutines you''ve launched. Because they are **first
    in first out** (**FIFO**) queuing mechanisms, they can be effectively used as
    a fixed-size queuing mechanism, and we can process requests in the order that
    they came in. We can write a simple job queue using a buffered channel. Let''s
    take a look:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by instantiating our `main` package, importing our required libraries,
    and setting our constants:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we create a `job` struct. This keeps track of the job name and the payload,
    as shown in the following code block:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Our `runJob` function just prints a success message. This is where we could
    add more intense work if we were so inclined:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Our main function creates a `jobQueue` channel of a defined `queueSize`. Then,
    it iterates through the workers and spawns goroutines for each of the workers.
    Lastly, it iterates through the job queue and runs the necessary jobs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We also have an HTTP handler function here to take requests from an external
    source (in our case, it''s going to be a simple cURL request, but you could have
    many different requests from external systems):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'After this, we start the job queue and execute a request to test the command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows a resulting set that shows the different workers
    completing the different jobs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a6a32e02-7046-4aed-be59-9e3a188beb89.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that the individual workers picked up the jobs as they were able to. This
    is helpful as we continue to grow our system, which requires these jobs.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating job queues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are times where we may not want to use built-in Go queueing systems. Perhaps
    we already have a pipeline that contains other message-queueing systems or perhaps
    we know that we are going to have to maintain a very large data ingress. Two systems
    that are commonly used for this task are Apache Kafka and RabbitMQ. Let's take
    a quick look at how to integrate with both of these systems using Go.
  prefs: []
  type: TYPE_NORMAL
- en: Kafka
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apache Kafka is referred to as a *distributed streaming system*, which is just
    another way of saying a distributed job queue. Kafka, which is written in Java,
    uses the idea of a publish/subscribe model for message queueing. It's often used
    for writing real-time streaming data pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll assume you have a Kafka instance set up already. If you don''t, you
    can use the following bash script to get a quick Kafka instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We can execute this bash script as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: After we do this, we can run the `kafka` read and write Go programs to read
    and write from Kafka. Let's investigate each of these.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the `writeToKafka.go` program to write to Kafka. Let''s take a look:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we initialize our `main` package and import the required packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'In our `main` function, we create a connection to Kafka, set a write deadline,
    and then we write messages to our Kafka topic/partition. In this case, it''s just
    a simple message count from 1 to 10:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The `readFromKafka.go` program instantiates the `main` package and imports
    all the necessary packages, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Our `main` function then sets a Kafka topic and partition, followed by creating
    a connection, setting a connection deadline, and setting a batch size.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'More information about Kafka topics and partitions can be found at: [http://kafka.apache.org/documentation/#intro_topics](http://kafka.apache.org/documentation/#intro_topics).'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see that our `topic` and `partition` have been set as variables and
    that our connection has been instantiated:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we set a deadline on our connection and read our batches. Lastly, we
    close our connections:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'After we execute our `readFromKafka.go` and `writeFromKafka.go` files, we can
    see the resulting output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/35f8e1a7-6cba-4c62-afa4-f1e751bd8cbc.png)'
  prefs: []
  type: TYPE_IMG
- en: Our Kafka instance now has the messages that we sent from our `writeToKafka.go`
    program, which can now be consumed by our `readFromKafka.go` program.
  prefs: []
  type: TYPE_NORMAL
- en: 'To stop our Kafka and zookeeper services after we are finished with them, we
    can execute the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Many enterprises use Kafka as a message brokering system, so being able to understand
    how to read and write from these systems in Go can be helpful for creating things
    at scale in an enterprise setting.
  prefs: []
  type: TYPE_NORMAL
- en: RabbitMQ
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'RabbitMQ is a popular open source message broker written in Erlang. It uses
    a protocol called the **Advanced Message Queueing Protocol** (**AMQP**) in order
    to pass messages through its queueing system. Without further ado, let''s set
    up a RabbitMQ instance and pass messages to and from it using Go:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to start up a RabbitMQ instance using Docker:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Then, we have a RabbitMQ instance, complete with the management portal, running
    on our host.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, we can use the Go AMQP library ([https://github.com/streadway/amqp](https://github.com/streadway/amqp))
    in order to pass messages to and from our RabbitMQ system with Go.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We will start by creating a listener. Let''s see this procedure step by step:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we instantiate the `main` package and import the necessary dependencies,
    as well as set the explicit variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we create a connection to the `amqp` server:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we declare the queue that we are listening on and consume messages from
    the queue:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can create the sending function. Again, we declare our package and
    import our dependencies, as well as set our variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We use the same connection methodology that we used in our listener. We might
    abstract this away in a production instance, but it was included here for ease
    of understanding:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we declare the queue we''d like to use and publish a message body to
    that queue:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'After we''ve created both of these programs, we can test them out. We''ll iterate
    over our message-sending program with a while true loop:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/480ad6b8-ec58-42d6-8666-0a3c28fe1268.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After we do this, we should see the messages coming into our receiver:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ba78ccd7-da8f-4ae6-92ea-a8a17e3cdfc2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can also see the output from this activity by looking at the RabbitMQ management
    portal, located at `http://0.0.0.0:15672`, using the username and password of
    guest by default:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6cf9a660-ad49-4116-9877-ff10d226515e.png)'
  prefs: []
  type: TYPE_IMG
- en: This portal gives us all sorts of different information about the RabbitMQ job
    queue, from the number of messages queued, the publish/subscribe model state,
    and results about individual parts of the RabbitMQ system (connections, channels,
    exchanges, and queues). Understanding how this queueing system works will help
    you, should you ever need to communicate with a RabbitMQ queue.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about clustering with hierarchical and centroid
    algorithms, goroutines as queues, buffered channels as job queues, and implementing
    third-party queuing systems (Kafka and RabbitMQ).
  prefs: []
  type: TYPE_NORMAL
- en: Learning about all of these clustering and job-queueing techniques will help
    make you better at using algorithms and distributed systems and solving computer
    science problems. In the next chapter, we are going to learn about how to measure
    and compare code quality across versions using the Prometheus exporter, APMs,
    SLIs/SLOs, and logging.
  prefs: []
  type: TYPE_NORMAL
