- en: '1\. Linux: History and future in the cloud'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '"Microsoft ♡ Linux" was written on the closing slide of a presentation given
    by Microsoft CEO Satya Nadella in 2015\. This announced a wave of changes that
    were going to happen, and Satya Nadella wanted to address Microsoft''s interest
    in Linux and **Open-Source Software** (**OSS**) technologies. Everyone felt that
    there was some contradiction here, wondering why Microsoft was working with OSS
    technologies. Wired magazine reported that Nadella is not interested in fighting
    old battles—especially, when, like it or not, Linux has become a vital part of
    today''s business technology. "If you don''t jump on the new," Nadella told Wired,
    "you don''t survive."'
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing, more than 50% of Microsoft Azure is ruled by Linux.
    There are a lot of misconceptions around migrating existing Linux workloads to
    Microsoft Azure and this book will help in understanding the complexities, simplifying
    the migration process.
  prefs: []
  type: TYPE_NORMAL
- en: We will start off with a brief history of Linux and the events that led to its
    development. Along with that, we will talk about some of the competitors of Linux
    and the use cases for both Linux and these competitors. We will cover some of
    the key roles that Linux servers play in IT infrastructure, touching on why the
    cloud is better for running these workloads compared to on-premises solutions.
    As most organizations are going with a cloud transformation strategy, the demand
    for virtual machines, containers, container orchestration solutions, big data,
    and so on is increasing, and Microsoft Azure provides a platform to run all these
    mission-critical workloads.
  prefs: []
  type: TYPE_NORMAL
- en: In order to understand the complexity of migrating Linux workloads to Azure,
    you need to understand the history of IT, operating systems, Unix, Linux, and
    Windows, before the cloud and virtualization. This chapter will provide some important
    background information about Linux to enable those who are not very familiar with
    it to learn the terminology.
  prefs: []
  type: TYPE_NORMAL
- en: The public cloud has many benefits over self-hosted environments. We will talk
    about them, particularly covering how Azure is designed to support Linux workloads.
  prefs: []
  type: TYPE_NORMAL
- en: While we will briefly mention some typically difficult aspects of Linux systems,
    you will also learn that Azure is evolving rapidly. Azure now has out-of-the-box
    features that will make Linux sysadmins' lives much easier.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following key topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Brief history and evolution of Linux
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use cases of Linux in IT infrastructure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Challenges in on-premises infrastructure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud economics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advantages of migrating to Azure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simplifying the complexity associated with migration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's get started with a brief history of Linux.
  prefs: []
  type: TYPE_NORMAL
- en: A brief history of Linux
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we talk about the history of Linux, it's a good idea to start with the
    events that led to its development. You might have seen pictures of old computers
    that were as big as a car or a house. It's hard to imagine how cumbersome it would
    be to handle a system this big now that we live in a world of handheld devices
    and thin clients. It's not just the massive size; the different operating systems
    that used to run on these devices made things more complicated. Every piece of
    software was designed to serve a single purpose and was impossible to run on another
    computer. In short, we had a compatibility issue. On top of these problems, the
    cost of buying these computers was huge. Purchasing a computer was not a dream
    that came true for normal people.
  prefs: []
  type: TYPE_NORMAL
- en: Unix
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The aforementioned shortcomings led to the development of a project called **Unix**,
    which was started in the mid-1970s by a group of developers at Bell Laboratories.
    The main intention of this project was to make a common software for all computers,
    rather than having individual pieces of software for each computer. The project
    used the C language instead of assembly language; it was indeed refined and uncomplicated.
  prefs: []
  type: TYPE_NORMAL
- en: The Unix operating system was widely adopted by government organizations, universities,
    and schools. It existed for many systems, ranging from personal computers all
    the way to supercomputers. Though the advent of Unix resolved some issues, it
    hadn't dealt with the pricing problem; these systems were still expensive.
  prefs: []
  type: TYPE_NORMAL
- en: During the early 1980s, organizations began developing their own versions of
    Unix. As a result of the multiple development branches, we ended up with lots
    of different versions, or dialects. Every developer and organization wanted to
    create a free Unix-like operating system and, in 1983 at MIT, Richard Stallman
    developed the GNU project. The goal of this project was to create a free operating
    system (in the sense of licensing, and not necessarily cost). This project didn't
    gain much popularity, as expected; nevertheless, GNU tools were adopted by Linux
    when it came into existence.
  prefs: []
  type: TYPE_NORMAL
- en: Linux
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In 1991, Linus Torvalds developed Linux as a freely distributable Unix while
    he was a student at the University of Helsinki, Finland. Linus was motivated by
    Andrew Tanenbaum''s Minix operating system, which was another free Unix for PCs.
    Linus wanted to author a freely available academic version of Unix that could
    run on Intel 386-based PCs for Minix users who wanted to get more out of their
    computers. The project was initially named "Freax," a fun project that ended up
    as one of the biggest revolutions in the history of computers with the name "Linux."
    On a public forum (comp.os.minix) during the initial days of Linux, Linus referred
    to his work as "a better Minix than Minix." Quoting his own words:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"After that it was plain sailing: hairy coding still, but I had some devices,
    and debugging was easier. I started using C at this stage, and it certainly speeds
    up development. This is also when I start to get serious about my megalomaniac
    ideas to make "a better Minix than Minix." I was hoping I''d be able to recompile
    gcc under Linux some day...*'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Two months for basic setup, but then only slightly longer until I had a disk
    driver (seriously buggy, but it happened to work on my machine) and a small filesystem.
    That was about when I made 0.01 available [around late August of 1991]: it wasn''t
    pretty, it had no floppy drive, and it couldn''t do much of anything. I don''t
    think anybody ever compiled that version. But by then I was hooked, and didn''t
    want to stop until I could chuck out Minix."*'
  prefs: []
  type: TYPE_NORMAL
- en: If only he had guessed how widely adopted Linux would be 30 years on.
  prefs: []
  type: TYPE_NORMAL
- en: Linux version history
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For the first version of Linux (v0.01), there were no executables. To play with
    this version, you needed a Minix machine to compile, as the intention was to make
    the Minix system better. In 1991, v0.02 was launched and is now referred to as
    the first official version of Linux. The current Linux systems that we see have
    immense provisions for a variety of things, such as user support, documentation,
    and software repositories. However, this was not the case during the early stages
    of Linux. In v0.02, Bash (GNU Bourne Again Shell) and gcc (GNU compiler) were
    the only things that were running, and the main focus was kernel development.
  prefs: []
  type: TYPE_NORMAL
- en: After v0.02 came v0.03, and so on; revisions were made until Linux reached v0.95
    in 1992, with the goal of a bug-free v1.0\. After two years with a couple of revisions
    in between, v1.0 came out in March 1994\. After 25+ years of v1.0, we are currently
    in v5.x and, at the time of writing, the last version released is v5.9\. We are
    expecting v5.10 soon.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned earlier, Linux adopted GNU tools, and these tools played an inevitable
    role in the making of Linux. Without these, Linux might not have made the impact
    that we see today. Along with GNU, **Berkeley Software Distribution** (**BSD**)
    played a role in making Linux popular. Though BSD was not initially adopted in
    the early stages of Linux, later versions had tools that were ported from BSD.
    The networking daemon and several other utilities are perfect examples of BSD's
    contributions to Linux that have made it the subject of admiration.
  prefs: []
  type: TYPE_NORMAL
- en: Linux evolution and distributions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Linux evolved over these years and the fun project started by Linus Torvalds
    is now used by millions of computers, smartphones, servers, and even supercomputers
    across the globe. Today, Linux is capable of running web, mail, emacs, the X Windows
    System…the list goes on. Linux not only dominates on-premises but has a major
    share of the workload in Azure too. Currently, we have a lot of Linux flavors
    tailored for enterprise use as well as personal use.
  prefs: []
  type: TYPE_NORMAL
- en: As already stated, Linux isn't something that is developed by a single organization.
    It is a combination of different parts or modules, such as the kernel, GNU shell
    utilities, the X server, the desktop environments, system services, daemons, and
    Terminal commands—all of these come from different developers and they are developed
    independently. If you want, you can take source code for the kernel, shell, and
    other components and assemble it. There are projects such as **Linux from Scratch**
    (**LFS**) and **Beyond Linux from Scratch** (**BLFS**) where users can download
    these pieces of software that are licensed under open-source software, compile
    them, and make their own Linux flavor.
  prefs: []
  type: TYPE_NORMAL
- en: Although exciting, the amount of work needed for this is heavy and you have
    to invest a lot of time for these components to work together properly. Linux
    distributions (often referred to as **distros**) make this hectic task easier.
    Distros will take all the code from the repositories and compile them, finally
    creating a single operating system that you can boot up on your computer. Examples
    of distros include Ubuntu, Fedora, CentOS, RHEL, Mint, and SUSE Linux. Some distros,
    such as RHEL, SUSE, and Ubuntu, have an enterprise server–grade version as well,
    which is used by organizations to host their mission-critical workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Linux for Enterprise is a new realm altogether. It began with Red Hat, which
    used to have a monopoly. However, more competitors soon appeared, including Canonical
    and SUSE, as well as the non-commercial CentOS. Azure supports all of the preceding
    enterprise-grade Linux operating systems, so each and every organization can migrate
    their Linux workloads to Azure.
  prefs: []
  type: TYPE_NORMAL
- en: Before we talk about the benefits of moving workloads to Azure, let's understand
    the common use case scenarios for these Linux servers in IT infrastructure, along
    with some of the challenges associated with on-premises approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Typical Linux use cases in IT infrastructure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned in the previous section, *A brief history of Linux*, the customer
    base for the Linux operating system is very large for on-premises environments
    as well as the cloud. In this section, we will talk about some use cases of Linux
    in IT infrastructure. Some things have been relevant since the beginning of Linux
    adoption (files, the web, databases, and so on), while others have been adopted
    recently with the introduction of new technologies (containerization and container
    orchestration, for example). These use cases will be added to and evolve over
    time.
  prefs: []
  type: TYPE_NORMAL
- en: Workstations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There is a large subset of consumers who prefer to use Linux as a daily commuter
    on their personal computers. This area was mainly monopolized by Windows and macOS,
    but things changed a lot when Linux came to the stage. Traditionally, Linux was
    an all-time favorite for coders and programmers, providing more customization
    options for the general consumer than Windows or macOS. For this reason, Linux
    became the preferred option for millions of people across the globe:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Different workstation distros and GUIs](img/B17160_01_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.1: Different workstation distros and GUIs'
  prefs: []
  type: TYPE_NORMAL
- en: Currently, we have flavors such as Ubuntu, Fedora Workstation, Linux Mint, Elementary
    OS, CentOS, and Arch Linux. *Figure 1.1* shows how the **Graphical User Interface**
    (**GUI**) appears in different workstation distros.
  prefs: []
  type: TYPE_NORMAL
- en: Application servers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'An application server is computer software that is bundled together to facilitate
    business logic. If we take a three-tier application, the application server is
    the component that comprises the GUI, the business logic, and the database server.
    The majority of application servers support the Java platform, some examples being
    JBoss, Jetty, JOnAS, Apache Geronimo, and Glassfish:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Coupling of application servers with front-end and back-end services to provide
    end-to-end solutions](img/B17160_01_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.2: Coupling of application servers with other services to provide
    end-to-end solutions'
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 1.2*, you can see how the application servers are coupled with other
    services, including the front-end and back-end services. An application server
    handles connections between the user requests that originate from the front-end
    and back-end services, such as databases and other logic.
  prefs: []
  type: TYPE_NORMAL
- en: Database servers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Linux has been the home of databases for a very long time now. We can install
    relational and non-relational databases on Linux as per our data requirements.
    The term **database server** refers to the combination of a database application
    and memory allocated for data storage. These databases can be used to record transactions
    in a similar way to how SQL Server works on Microsoft Windows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Two-tier application model with databases behind a load balancer to provide
    high availability](img/B17160_01_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.3: Two-tier application model with databases behind a load balancer'
  prefs: []
  type: TYPE_NORMAL
- en: Some commonly used database services include MariaDB, PostgreSQL, MySQL, and
    MongoDB. In most scenarios, the databases hosted in Linux servers are kept behind
    a load balancing solution to provide high availability. *Figure 1.3* is an example
    of this.
  prefs: []
  type: TYPE_NORMAL
- en: Virtualization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The purpose of virtualization is to create virtual machines using specialized
    software called **hypervisors**. Most of you might be familiar with the term **virtual
    machines** (**VMs**), as this is quite common in on-premises environments as well
    as in the cloud. The purpose of making Linux a virtualization host is the same
    as installing a Windows Server instance with the Hyper-V role. VMs are often created
    for the isolation of workloads and for testing purposes. Popular Linux virtualization
    solutions include KVM, RHEV, Xen, QEMU, VirtualBox, and VMware:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Levels of virtualization: Isolated apps, different guest OS, physical hardware](img/B17160_01_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.4: Virtualization levels'
  prefs: []
  type: TYPE_NORMAL
- en: As shown in *Figure 1.4*, the hypervisor is installed on the hardware and different
    VMs are created using hypervisors. Each of these VMs is isolated from the operating
    system and can host different applications.
  prefs: []
  type: TYPE_NORMAL
- en: Containers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We just discussed VMs and their creation using hypervisors installed on our
    Linux servers. The footprint of these servers will be large and will often contain
    some stock libraries and binaries that we do not require. This leads to a waste
    of compute resources; with all VMs being deployed, your host capacity will soon
    be exhausted. With the introduction of containers, things have changed, and we
    don't need to deploy the entire VM to host a dedicated service.
  prefs: []
  type: TYPE_NORMAL
- en: A container is just a software package that contains the code, binaries, and
    libraries required for a specific task. For example, to run a web server, we could
    deploy a VM and install NGINX on it. The resource consumption for the VM would
    be high and encompass a lot of services that we do not need. We could instead
    use containers, so the image would only have code to run the NGINX server, and
    nothing else. This would mean a lightweight image and quick deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of VMs, we were using hypervisors to run them; in the case of containers,
    we use container runtime engines. A comparison of the two is shown in *Figure
    1.5*. Some common examples include Docker (which is the most used), Runc, Rkt
    (which is no longer in development), and Mesos:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A comparison between containers and VMs](img/B17160_01_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.5: Containers versus VMs'
  prefs: []
  type: TYPE_NORMAL
- en: Currently, we have container images available for each and every service, including
    NGINX, MySQL, and Apache. All major software packages have been ported.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud computing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Linux can be used to host cloud operating system solutions such as OpenStack.
    We can install OpenStack on our Linux server to host a cloud environment (both
    private and public) to manage large pools of underlying resources including compute,
    storage, and network. Think of this as the Azure Stack, where you can run Azure
    in your own datacenter. In a similar way, you can host a cloud environment in
    your datacenter for your users to deploy services using OpenStack, which is running
    on Linux:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The basic architecture of how OpenStack runs on top of Linux to serve as
    a platform for deployments](img/B17160_01_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.6: OpenStack running on top of Linux'
  prefs: []
  type: TYPE_NORMAL
- en: OpenStack exposes a lot of APIs using which users can track, manage, and monitor
    their deployment. *Figure 1.6* displays the basic architecture of how OpenStack
    runs on top of Linux to serve as a platform for deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Container orchestration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'With the introduction of containers, many organizations are moving from a monolithic
    architecture to a microservice architecture. As the number of containers increases,
    it''s not easy to manage them on a large scale. That is where container orchestration
    tools such as Kubernetes come into the picture. We can install the Kubernetes
    service on a Linux machine and add Linux and Windows worker nodes to it. The master
    will be running on a Linux server and this will act as a management plane for
    the cluster. *Figure 1.7* shows a high-level representation of how Linux nodes
    are added to the Kubernetes master. In a similar fashion, we can also create a
    pool of Windows nodes and add it to the Kubernetes cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A high-level representation of how Linux nodes are added to the Kubernetes
    cluster](img/B17160_01_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.7: Linux worker nodes in a Kubernetes cluster'
  prefs: []
  type: TYPE_NORMAL
- en: Another distribution of Kubernetes is OpenShift, developed by Red Hat. There
    are many Kubernetes distributions published by different vendors, all meant for
    container orchestration. In fact, there are dedicated Linux distributions that
    have been developed with Kubernetes in mind, such as k3OS from Rancher. Container
    orchestration is a booming and ever-growing sector, and we could even write a
    whole book on this topic alone.
  prefs: []
  type: TYPE_NORMAL
- en: Big data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We started with simple examples and have expanded our horizons all the way
    to complex scenarios, such as big data on Linux. You can install tools such as
    Apache Hadoop on Linux and then perform big data analysis. We don''t really see
    this scenario in every organization due to varying availability and support for
    managed cloud services such as Azure Synapse Analytics or Azure HDInsight. Nevertheless,
    if you would like to implement big data analytics on Linux, it''s possible. *Figure
    1.8* shows the extensive list of tools that are used by data scientists and big
    data analysts, and all of these can be installed on Linux:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The list of tools that are used by data scientists and big data analysts](img/B17160_01_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.8: Tools used for big data analytics'
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned earlier, using Linux for big data analytics is a seldom seen scenario,
    however, some customers to prefer to install certain analytics tools like Splunk
    on Linux.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we've talked about some common scenarios, but this doesn't
    mean that the use cases are confined to these only. With the introduction of new
    technologies almost daily, the potential use cases will keep on expanding. We
    explored these particular ones to demonstrate that Linux can handle wide-ranging
    scenarios, from basic functionality such as workstations all the way to container
    orchestration and big data.
  prefs: []
  type: TYPE_NORMAL
- en: Even though on-premises infrastructure can also support all these scenarios,
    there are some disadvantages to this approach. This is the driving force behind
    the cloud journey of each and every organization. Let's see what these challenges
    are and how the cloud mitigates them.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges in on-premises infrastructure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Hosting an infrastructure on-premises is quite challenging because of the requirement
    for qualified personnel and complex networking. The traditional approach has persisted
    for a long time. With the introduction of cloud computing, organizations started
    to recognize how the challenges they faced for decades could be resolved by cloud
    computing. Before we take a look at the benefits of cloud computing, let''s understand
    the root cause of these on-premises challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scaling**: This is one of the primary challenges. It is really hard to implement
    a solution that can scale in and out based on varying traffic. You can add more
    servers (physical or virtual) whenever there is a need for more resources and
    terminate them when they are no longer needed. However, resource utilization in
    this scenario is not optimized. With the introduction of the cloud, scaling is
    very easy; you just have to specify the scaling conditions (CPU %, memory %, and
    so on), and the cloud provider will take care of the scaling itself. You never
    know where your business is going to be next year and Microsoft Azure can help
    you scale your infrastructure alongside your business.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Agility**: Agility is the ability to react quickly. In Microsoft Azure, you
    can allocate and deallocate resources quickly, responding to changes in your business
    needs. All services are provided as on-demand self-service, which means that if
    you need a new server, it can be deployed in seconds. In on-premises, if we need
    a new physical server, the process for getting one is very involved. You might
    need to ask your hardware provider to ship the hardware, license it, patch it,
    and then install all the required software to make it suitable for running your
    workload. So, we are looking at a timeline of around 2-3 weeks at a minimum, which
    is in contrast to the agility offered by Microsoft Azure. Even if you are deploying
    a new VM on-premises, you need to make sure that your host machine has enough
    resources for the new VM, or else you may have to buy a new server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Skills**: The skills required to manage your own datacenter are very demanding
    and it''s very hard to find professionals to take care of it. Along with infrastructure
    management, you have to think about the security aspect of the datacenter as well.
    For that, you might need to hire more security professionals to make your datacenter
    more secure. An increase in the headcount of employees is another cost to the
    organization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security**: In the previous point, we noted that hiring more professionals
    increases the cost to the organization. Even after successful hiring, with ever-changing
    and ever-evolving threats, it''s hard to train employees on every possible set
    of security threats. Managing security and how to react to new threats is still
    a challenge in on-premises environments. Most organizations implement preventive
    measures only after they have been hit by a threat. After the incident, you will
    need to hire cyber forensic professionals to conduct an investigation, which again
    is an additional expense to the organization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are some of the main reasons why it can be challenging to work on-premises.
    With the introduction of the cloud, organizations can focus more on achieving
    business goals rather than wasting time on racking and stacking, software patching,
    and other time-consuming IT management chores.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we'll cover cloud economics, where we'll take a deep dive
    into the advantages of the cloud and how both the aforementioned and other unmentioned
    challenges can be resolved.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud economics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Owning a datacenter is not a core business of typical companies. While it might
    be tempting for the IT department to own physical servers that they can set up
    and physically interact with themselves, it probably is not something your **Chief
    Financial Officer** (**CFO**) wants to do. Owning servers not only shows up in
    the balance sheets as capital expenses, but the costs of the facilities, electricity,
    insurance, and so on also add up in terms of total operational costs. If you ask
    any IT manager how much it costs to buy, set up, operate, and dispose of the infrastructure
    needed to host one application for a year on their own datacenter, they most probably
    won't know or even dare to guess.
  prefs: []
  type: TYPE_NORMAL
- en: Outsourcing your infrastructure to a hosting provider sounds like a good idea
    after you realize how expensive it is to operate a datacenter yourself. A multi-customer
    datacenter is certainly more cost-effective compared to a single-customer datacenter.
    Adding scale makes it easier to save costs by sharing parts of the infrastructure
    between all or many customers. At the end of 2020, there were thousands or tens
    of thousands of professionally run, shared hosting datacenters around the world—how
    do we know which one to choose and which will be out of business next year?
  prefs: []
  type: TYPE_NORMAL
- en: The size and the complexity of business software have increased, together with
    the amount of data collected and processed by applications. This creates more
    and more demand for compute power and storage, which naturally increases the infrastructure
    costs. Constantly increasing the cost of the hosted environment is not something
    your CFO will tolerate over an extended period.
  prefs: []
  type: TYPE_NORMAL
- en: Scale comes with benefits
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Many hosted datacenter providers are migrating their own infrastructure to
    public clouds partly for the same reasons as their customers: public cloud infrastructures
    have become so massive in terms of the number of regions, datacenters, and servers
    that the scale and features for optimizing cost are really difficult to compete
    with. With traditional datacenters and hosting providers, it is usually not possible
    to pay only for times when you actually need the capacity, for example, during
    office hours.'
  prefs: []
  type: TYPE_NORMAL
- en: Public clouds can offer consumption-based pricing due to their massive scale.
    They can share regional and global resources with all of their customers. Additionally,
    they are able to make massive investments in their infrastructure and use custom-made
    components. In many cases, they can also optimize operating costs by choosing
    locations with favorable conditions, such as a cold climate, which helps in cooling
    a datacenter; what's more, the heat generated by the datacenter can be used to
    heat nearby homes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another benefit of public clouds worth mentioning is the security aspect. Let''s
    take a look at Azure: it uses Microsoft''s global network for all connectivity
    inside and outside of Azure. Microsoft operates various other cloud-based services,
    such as Microsoft 365 and Xbox, which receive lots of unwanted traffic from the
    internet. This has its benefits; for example, some badly behaved Xbox user trying
    to conduct a DDoS attack on another Xbox user will be noticed by Microsoft, and
    Microsoft can remediate the attack globally, making sure, for example, that Azure
    is not affected.'
  prefs: []
  type: TYPE_NORMAL
- en: By using public clouds, you save time and money by not having to employ your
    own datacenter team, or by not having to pay a hosting provider to do so. It also
    gives you almost unlimited scalability up and down, without having to commit to
    long-term contracts.
  prefs: []
  type: TYPE_NORMAL
- en: Migrating to public clouds does not mean you need to do it all at once. You
    may choose a hybrid approach where you leave some applications and data behind
    and just create a connection between the environments.
  prefs: []
  type: TYPE_NORMAL
- en: Many services available
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To better understand the migration strategies, it is useful to understand the
    various cloud services available.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud services such as Outlook and Gmail, or OneDrive and Google Drive, are
    good examples of **Software as a Service** (**SaaS**). Most cloud services targeted
    at consumers, such as Facebook, Instagram, and WhatsApp, also fall into this category.
  prefs: []
  type: TYPE_NORMAL
- en: From the user's point of view, these solutions are just "there" and can be used
    without much initial effort. The same applies to typical business solutions such
    as Salesforce CRM or Microsoft 365\. You cannot install these yourself even if
    you wanted; they always come as a turnkey service and you do not have any visibility
    into the underlying infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: '**Platform as a Service** (**PaaS**) solutions differ from SaaS in a couple
    of ways; they need some kind of installation work and an infrastructure where
    they can be installed. While the installation is automatic, you may need to manage
    some parts of the infrastructure yourself. Examples of such services include **Azure
    Kubernetes Service** (**AKS**) and **Azure Red Hat OpenShift** (**ARO**).'
  prefs: []
  type: TYPE_NORMAL
- en: In the context of migrating Linux servers to Azure, we are focusing on **Infrastructure
    as a Service** (**IaaS**), which means that you only get the lower-level infrastructure
    components as a service. Everything else is your own responsibility, including
    configuring the storage and network and operating the operating system yourself.
    This type of cloud service is similar to typical VM-hosting services offered by
    hosting companies.
  prefs: []
  type: TYPE_NORMAL
- en: Benefits of migrating to Azure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Typical Linux deployments in on-premises environments are based on VMs, and
    migrating them to Azure falls into the realm of IaaS, so they will still be VMs
    after the migration. For sysadmins, this means the same skills they already have
    and the same familiar management tools are still useful on Azure.
  prefs: []
  type: TYPE_NORMAL
- en: In the early days of Azure, some services were not designed for Linux use, and
    users sometimes got frustrated by the complexity of using Linux on Azure. Being
    originally named Microsoft Azure gives a hint as to what use cases it was designed
    for. Since then, Azure has evolved and it has been developed to be more and more
    Linux-friendly.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Linux has rapidly gained popularity in Azure. In 2015, Mark Russinovich, the
    CTO of Azure, said that one in four VM instances in Azure runs Linux. In 2018,
    Microsoft Cloud EVP Scott Guthrie revealed in an interview by ZDnet that about
    half of Azure VMs run Linux.
  prefs: []
  type: TYPE_NORMAL
- en: ([https://www.zdnet.com/article/mark-russinovich-the-microsoft-azure-cloud-and-open-source/](https://www.zdnet.com/article/mark-russinovich-the-microsoft-azure-cloud-and-open-source/)
    and [https://www.zdnet.com/article/linux-now-dominates-azure/](https://www.zdnet.com/article/linux-now-dominates-azure/))
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing in 2021, Microsoft has already become well known for
    its love of Linux and open source. Microsoft is supporting many open-source projects,
    initiatives, and foundations, such as the Linux Foundation. According to their
    website ([https://opensource.microsoft.com/program/](https://opensource.microsoft.com/program/)),
    Microsoft already uses over 150,000 open-source components while building their
    products and services.
  prefs: []
  type: TYPE_NORMAL
- en: Today, more and more customers are migrating their existing workloads to Azure.
    As mentioned earlier, many of these workloads are Linux-based. To facilitate these
    migrations, Microsoft has developed many tools and services with Linux users in
    mind. We will cover these in more detail later in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft has partnered with all the major Linux vendors to help their customers
    move workloads to Azure. These partnerships have the aim of developing new features
    and ensuring that existing features are better integrated, not to forget providing
    monetary benefits in the shape of the ability to continue to use existing commercial
    on-premises contracts in Azure.
  prefs: []
  type: TYPE_NORMAL
- en: Enterprise Linux companies such as Red Hat and SUSE are very popular in the
    world of on-premises IT infrastructure, and they have both worked with Microsoft
    to create unified global support services to ensure that their customers can migrate
    to Azure without hassle.
  prefs: []
  type: TYPE_NORMAL
- en: Community Linux distributions such as CentOS and Ubuntu are very popular in
    Azure, and there are many companies offering commercial Linux support, including
    Canonical, with its Ubuntu Pro offering.
  prefs: []
  type: TYPE_NORMAL
- en: The journey from Linux to Azure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we'll cover some aspects of typical Linux environments that
    we should know about when we are considering migration to Azure. We'll go through
    some key features and discuss the solutions available on Azure. We will also provide
    links to related Azure documentation throughout this section to make your learning
    curve a bit shallower—the documentation covers Linux on Azure extremely well.
  prefs: []
  type: TYPE_NORMAL
- en: Before going into the technical details, it's good to know that you don't necessarily
    need to implement everything yourself. Azure Marketplace has lots of Linux-based
    solutions that may solve your problem in a turnkey fashion.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Marketplace has over 2,000 Linux VM-based images at the time of writing
    compared to about 800 Windows-based images. Linux is clearly dominating the marketplace.
    Out of those images, only 14 are from Microsoft; the rest are created and published
    by third-party ISV companies. For example, if you want to install WordPress on
    a Linux VM, you need to install Apache, PHP, and MySQL as the database. On the
    other hand, if you're using a Marketplace image, you'll be able to find customized
    WordPress images. These images can easily be deployed right from the Marketplace
    to your Azure subscription without the need to manually install the Apache, PHP,
    and MySQL services.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find Azure Marketplace here: [https://azuremarketplace.microsoft.com/marketplace/](https://azuremarketplace.microsoft.com/marketplace/).
    The Marketplace images are also available via Azure command-line interfaces. The
    number of images is increasing as we speak, and it is also possible to publish
    your own images to Azure Marketplace and make them available to large numbers
    of customers.'
  prefs: []
  type: TYPE_NORMAL
- en: We will begin our discussion by talking about clustering, which is a scenario
    where there are a lot of gray areas.
  prefs: []
  type: TYPE_NORMAL
- en: Clustering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In plain English, the word "cluster" means group, flock, or assemble. When we
    say clustering in the IT world, we are expressing the idea of a group of computers
    (in this context, Linux computers), multiple storage components, and redundant
    network connections acting together to form a highly available system. Clustering
    avoids a single point of failure and also provides load balancing along with high
    availability. Clustering may look complex at first glance as we have to manage
    multiple computing resources, but this section is all about demystifying the complexity
    of clustering.
  prefs: []
  type: TYPE_NORMAL
- en: 'Typical Linux clustering scenarios can be categorized into four types:'
  prefs: []
  type: TYPE_NORMAL
- en: Storage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High availability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load balancing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of these is implemented with different software and requires its own architecture
    and configuration. In the next few sections, we will see how Azure addresses each
    of these four scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Azure shared disks for storage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Storage clusters in on-premises systems are usually considered to be consistent
    clustered file systems between multiple nodes. The technology used for file system
    clusters is very often GlusterFS, GFS2, or OCFS2 when using a software solution.
    For block-level storage sharing, it's very common to use DRBD. Using these solutions
    on Azure is not straightforward—setting them up properly even on an on-premises
    system requires a highly skilled sysadmin.
  prefs: []
  type: TYPE_NORMAL
- en: For shared block storage, you can use Azure shared disks. This is quite a recent
    feature that allows you to attach a managed disk to multiple VMs at the same time.
    This solves many issues associated with storage clustering. **SCSI Persistent
    Reservations** (**SCSI PR**) is an industry standard that was used by applications
    in on-premises environments running on a **Storage Area Network** (**SAN**). The
    same SCSI PR facilitates reservations that will be used by the VMs to read or
    write data to their attached disk. Shared managed disks need to use cluster manager
    tools such as Pacemaker, which will handle cluster node communication and write
    locking. Pacemaker is required in clustering as shared managed disks don't offer
    fully managed file systems that can be accessed via SMB/NFS.
  prefs: []
  type: TYPE_NORMAL
- en: One disadvantage here is that not all tiers of disk types can be used as shared
    disks. Currently, Ultra SSD and Premium SSD are supported. If you are using Standard
    HDD or Standard SSD for your VM, in order to fulfill the clustering prerequisites
    or to overcome the current limitation, you may have to upgrade the disk type to
    Ultra or Premium SSD.
  prefs: []
  type: TYPE_NORMAL
- en: 'The documentation on shared disks is available here: [https://docs.microsoft.com/azure/virtual-machines/disks-shared](https://docs.microsoft.com/azure/virtual-machines/disks-shared).
    We should note that Azure shared disks are not supported for all Linux distributions.'
  prefs: []
  type: TYPE_NORMAL
- en: Azure Files and Azure NetApp Files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A solution for shared file systems is a service called **Azure Files**. It is
    an easy-to-use cloud file system that allows the mounting of Azure file shares
    by using the **Server Message Block** (**SMB**) or **Network File System** (**NFS**)
    protocol. NFS is very popular for Linux servers and SMB is typically used with
    Windows servers. In the *Typical Linux use cases in IT infrastructure* section,
    we discussed how file servers play a vital role in IT infrastructure; Azure Files
    is an enterprise-grade cloud version of that. These file shares can be mounted
    on Linux, Windows, and macOS systems. Azure Files provides a common shared space
    that can be shared with your on-premises workstations as well as VMs. Being a
    part of Azure Storage, Azure Files has all the features that Azure Storage supports.
    When it comes to the NFS share, it has fewer features compared to the SMB share.
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure Files can be used as a complete replacement for the file server role
    that we had on our on-premises servers. Since we have the capability to attach
    to our on-premises server, we can also use Azure Files to move data from on-premises
    servers to cloud servers with the same file share mounted on both ends. The related
    documentation is available here: [https://docs.microsoft.com/azure/storage/files/storage-files-introduction](https://docs.microsoft.com/azure/storage/files/storage-files-introduction).'
  prefs: []
  type: TYPE_NORMAL
- en: 'An additional solution for a shared NFS filesystem is called **Azure NetApp
    Files** (**ANF**). This is an enterprise-class high-performance file system service.
    NetApp is a very popular storage solution typically used in on-premises systems,
    and it is also now available on Azure. You can read more about the solution here:
    [https://docs.microsoft.com/azure/azure-netapp-files](https://docs.microsoft.com/azure/azure-netapp-files).'
  prefs: []
  type: TYPE_NORMAL
- en: ANF supports various performance tiers for storage, depending on your application's
    IOPS requirement. As this is deeply integrated with the Azure platform, it can
    be used as a shared file solution for your clustered solutions. Additionally,
    ANF carries leading industry certifications, which makes it ideal for SAP HANA
    LOB applications, HPFS, VDI, and HPC. Note that the minimum storage capacity size
    for ANF is currently 4 TB.
  prefs: []
  type: TYPE_NORMAL
- en: Availability set for high availability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Azure offers very simple availability set functionality that can be used to
    create simple and easy-to-use HA environments. Availability sets are composed
    of **Fault Domains** (**FDs**) and **Update Domains** (**UDs**).
  prefs: []
  type: TYPE_NORMAL
- en: FDs are groups of hardware in an Azure datacenter that share common power, cooling,
    and network connectivity. When we deploy VMs to an availability set, Azure makes
    sure that they are distributed across three FDs, so that even if the power to
    FD 1 goes down, a VM in FD 2 or FD 3 can serve customers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, we have UDs where the VMs are grouped in a way where the underlying
    hardware can be rebooted at the same time. When a planned maintenance event happens
    in an Azure datacenter, only one UD gets rebooted at a time. By default, if you
    deploy to an availability set, the VMs will be distributed across five FDs. However,
    if you so wish, you can increase this to up to 20 UDs. *Figure 1.9* shows how
    UDs and FDs are mapped in a datacenter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Mapping of fault domains and update domains in a datacenter](img/B17160_01_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.9: FDs and UDs'
  prefs: []
  type: TYPE_NORMAL
- en: 'Availability sets enable you to deploy VMs on Azure in a distributed manner
    across isolated hardware clusters. A useful tutorial for this feature is available
    here: [https://docs.microsoft.com/azure/virtual-machines/linux/tutorial-availability-sets](https://docs.microsoft.com/azure/virtual-machines/linux/tutorial-availability-sets).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The proximity placement groups feature enables you to keep selected VMs near
    to one another in terms of distance within an availability set. This reduces network
    latency, which could impact your applications. See more information about this
    feature here: [https://docs.microsoft.com/azure/virtual-machines/co-location#proximity-placement-groups](https://docs.microsoft.com/azure/virtual-machines/co-location#proximity-placement-groups).'
  prefs: []
  type: TYPE_NORMAL
- en: Pacemaker, the software used for clustering on typical on-premises setups, is
    not often required on Azure. Some legacy solutions ported to Azure, however, are
    based on Pacemaker and DRBD, for example, the certified SAP on Azure architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Azure layer-4 load balancing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Azure comes with a very useful layer-4 load balancing functionality that can
    often be used to replace typical on-premises solutions. Load balancing is required
    to distribute requests and loads between multiple VMs. This tutorial will guide
    you through the creation and operation of Linux load balancing on Azure: [https://docs.microsoft.com/azure/virtual-machines/linux/tutorial-load-balancer](https://docs.microsoft.com/azure/virtual-machines/linux/tutorial-load-balancer).'
  prefs: []
  type: TYPE_NORMAL
- en: Many on-premises load balancing solutions are not suitable for moving to the
    cloud as-is, so it may be beneficial to investigate whether Azure load balancing
    solves the same need. In particular, if your application architecture is going
    to be modified during migration, then the current load balancing architecture
    might not have the features you need or might be unnecessarily expensive when
    used on Azure.
  prefs: []
  type: TYPE_NORMAL
- en: High-performance computing on Azure
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The last clustering type, high-performance computing, or HPC, is a scenario
    very well suited to Azure. Typical on-premises HPC solutions are extremely expensive,
    especially when you are not using them, due to the fact that you are paying for
    the hardware around the clock.
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure provides both a traditional CPU-based HPC solution and also a very powerful
    GPU-based highly scalable model. You can use various storage options to share
    data between the nodes running your workloads. You may also want to reap the benefits
    of the RDMA-based high-throughput back-end network. Related documentation is available
    here: [https://docs.microsoft.com/azure/architecture/topics/high-performance-computing](https://docs.microsoft.com/azure/architecture/topics/high-performance-computing).'
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, there are various third-party HPC solutions available on the Azure
    Marketplace.
  prefs: []
  type: TYPE_NORMAL
- en: Subscription portability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Very often, the biggest challenge with Azure migrations for Linux is surprisingly
    not technical. Let's stop here for a moment and think about your Linux licensing
    and subscriptions, especially if you are using a commercial Linux distribution
    such as Red Hat Enterprise Linux or SUSE Linux Enterprise Server.
  prefs: []
  type: TYPE_NORMAL
- en: 'Do you know whether you have simply lifted and shifted your existing VM to
    the public cloud? Do you need to discuss with your IT procurement or a lawyer
    the contract terms of Red Hat or SUSE? The correct answer to any question you
    may have in your mind right now is: *Yes, but check with your IT procurement first.*'
  prefs: []
  type: TYPE_NORMAL
- en: Both Red Hat and SUSE allow customers to move their existing enterprise subscriptions
    to the public cloud, but there are a couple of steps you'll need to take in order
    to be compliant and to continue to receive support directly from them. In Azure,
    the Linux VMs created using these migrated subscriptions are **Bring Your Own
    Subscription** (**BYOS**). Red Hat calls the related program **Red Hat Cloud Access**,
    and SUSE's program is called **SUSE Public Cloud Program**.
  prefs: []
  type: TYPE_NORMAL
- en: Please note that migrating your existing Linux subscriptions to Azure means
    that you will continue to have a billing relationship with Red Hat or SUSE for
    VMs utilizing these subscriptions. You can create new Linux VMs on Azure using
    Microsoft's **Pay as You Go** (**PAYG**) billing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, it''s useful to learn about Azure Hybrid Benefit, which allows you
    to change between BYOS and PAYG. This feature is under active development and,
    at the time of writing, supports only VMs migrated from on-premises to Azure.
    See more details in the documentation here: [https://docs.microsoft.com/azure/virtual-machines/linux/azure-hybrid-benefit-linux](https://docs.microsoft.com/azure/virtual-machines/linux/azure-hybrid-benefit-linux).'
  prefs: []
  type: TYPE_NORMAL
- en: If you are using community distributions such as CentOS and Ubuntu, none of
    the preceding should matter to you as those distributions are completely free
    to use, but at least you learned something new today.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This chapter started with the history of Linux. The leap that Linux took from
    being a fun project to being an enterprise-grade operating system was astonishing.
    Today, Linux is everywhere, from high-end servers to smartphones to smart bulbs.
    Due to the freedom of customization, there are a lot of variants of Linux, referred
    to as flavors or distros; there is a distro available for each and every use case.
    If none of the distros matches your exact requirements and you want to add more
    features, feel free to customize and build your own Linux. We explored some use
    case scenarios for Linux and looked at some of the challenges that traditional
    IT is facing with infrastructure management in on-premises environments.
  prefs: []
  type: TYPE_NORMAL
- en: Every organization runs by numbers. In the Cloud economics section, we examined
    how running workloads in the cloud can draw profit if we make a CapEx versus OpEx
    comparison. The upper hand of the cloud not only comes from cost reduction; it's
    a solution for all the challenges we encountered in on-premises environments.
    We discussed several advantages, including fault tolerance, high availability,
    agility, elasticity, and scaling.
  prefs: []
  type: TYPE_NORMAL
- en: It is safe to say that everything you used to do in on-premises environments
    can be migrated into Azure in one way or another. There's plenty of good-quality
    documentation available, and third-party ISV solutions can shorten your implementation
    cycle. There is additional help available from Microsoft partner companies, Microsoft's
    customer account teams, and also from the Microsoft Fast Track team, which is
    dedicated to helping customers move to Azure.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter is where we take a deep dive into these distros, starting with
    the licensing part, discussing some widely adopted distros and, ultimately, the
    Linux on Azure experience.
  prefs: []
  type: TYPE_NORMAL
