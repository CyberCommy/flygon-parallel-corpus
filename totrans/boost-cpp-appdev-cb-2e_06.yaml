- en: Manipulating Tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Registering a task for an arbitrary data type processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making timers and processing timer events as tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network communication as a task
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accepting incoming connections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Executing different tasks in parallel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipeline tasks processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making a nonblocking barrier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storing an exception and making a task from it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting and processing system signals as tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter is all about tasks. We'll be calling the functional object a *task*
    because it is shorter and better reflects what it will do. The main idea of this
    chapter is that we can split all the processing, computations, and interactions
    to functors (tasks), and process each of those tasks almost independently. Moreover,
    we may not block on some slow operations such as receiving data from the socket
    or waiting for the time out, but instead provide a callback task and continue
    working with other tasks. Once the OS finishes, the slow operation, our callback
    is executed.
  prefs: []
  type: TYPE_NORMAL
- en: The best way to understand the example is to play with it by modifying, running,
    and extending it. The site, [http://apolukhin.github.io/Boost-Cookbook/](http://apolukhin.github.io/Boost-Cookbook/),
    has all the examples from this chapter, and you can even play with some of them
    online.
  prefs: []
  type: TYPE_NORMAL
- en: Before you start
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter requires at least a basic knowledge of the first, second, and fifth
    chapters. Basic knowledge on C++11 rvalue references and lambdas is required.
  prefs: []
  type: TYPE_NORMAL
- en: Registering a task for an arbitrary data type processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First of all, let''s take care of the class that holds all the tasks and provides
    methods for their execution. We were already doing something like this in the
    [Chapter 5](part0262.html#7PRJC0-712b4ba1126a4c7c89e1d44de61b4bdd)*, Multithreading,
    Creating a work_queue class* recipe, but some of the following problems were not
    addressed:'
  prefs: []
  type: TYPE_NORMAL
- en: A `work_queue` class was only storing and returning tasks, but we also need
    to execute existing tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A task may throw an exception. We need to catch and process exceptions if they
    leave the task boundaries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A task may not notice a thread interruption. The next task on the same thread
    may get the interruption instead.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We need a way to stop the processing of the tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe requires linking with the `boost_system` and `boost_thread` libraries.
    A basic knowledge of `Boost.Thread` is also required.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we use `boost::asio::io_service` instead of `work_queue` from
    the previous chapter. There is a reason for doing this, and we'll see it in the
    following recipes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start from the structure that wraps around a user task:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'For ease of use, we''ll create a function that produces `task_wrapped` from
    the user''s functor:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we are ready to write the `tasks_processor` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s add the `push_task` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s finish this class by adding the member functions for starting and stopping
    a task''s execution loop:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Done! Now, it is time to test our class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The `main` function may look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `boost::asio::io_service` variable can store and execute tasks posted to
    it. But we may not post a user''s tasks to it directly, because they may receive
    an interruption addressed to other tasks or throw an exception. That is why we
    wrap a user''s task in the `detail::task_wrapped` structure. It resets all the
    previous interruptions by calling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '`detail::task_wrapped` executes the task in the `try{ } catch()` block making
    sure that no exception leaves the `operator()` bounds.'
  prefs: []
  type: TYPE_NORMAL
- en: Take a look at the `start()` function. The `boost::asio::io_service::run()`
    starts processing tasks posted to the `io_service` variable. If `boost::asio::io_service::run()`
    is not called, then posted tasks are not executed (this can be seen in the `main()`
    function). Task processing may be stopped via a call to `boost::asio::io_service::stop()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `boost::asio::io_service` class returns from the `run()` function if there
    are no more tasks left, so we force it to continue with the execution using an
    instance of `boost::asio::io_service::work`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The `iostream` classes and variables, such as `std::cerr` and `std::cout` are
    not thread safe on pre C++11 compilers and may produce interleaved characters
    on C++11 compatible compilers. In real projects, additional synchronization must
    be used to get readable output. For the simplicity of an example, we do not do
    that.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The C++17 standard library has no `io_service`. However, a big part of the `Boost.Asio`
    library is proposed as a Networking **Technical Specification** (**TS**) as an
    addition to C++.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following recipes in this chapter will show you why we choose `boost::asio::io_service`
    instead of using our handwritten code from [Chapter 5](part0262.html#7PRJC0-712b4ba1126a4c7c89e1d44de61b4bdd)**,
    Multithreading**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You may consider the documentation of `Boost.Asio` for getting some examples,
    tutorials, and class references at [http://boost.org/libs/asio](http://boost.org/libs/asio)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You may also read the *Boost.Asio C++ Network Programming* book, which gives
    a smoother introduction to `Boost.Asio` and covers some details that are not covered
    in this book
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making timers and processing timer events as tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is a common task to check something with specified intervals. For example,
    we need to check some sessions for an activity once in every 5 seconds. There
    are popular solutions for such a problem:'
  prefs: []
  type: TYPE_NORMAL
- en: The bad solution creates a thread that does the checking and then sleeps for
    5 seconds. This is a lame solution that eats a lot of system resources and scales
    badly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The right solution uses system specific APIs for manipulating timers asynchronously.
    This is a better solution, that requires some work and is not portable, unless
    you use `Boost.Asio`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You must know how to use C++11 rvalue-references and `unique_ptr`.
  prefs: []
  type: TYPE_NORMAL
- en: This recipe is based on the code from the previous recipe. See the first recipe
    of this chapter to get information about the `boost::asio::io_service` and `task_queue`
    classes.
  prefs: []
  type: TYPE_NORMAL
- en: Link this recipe with the `boost_system` and `boost_thread` libraries. Define
    `BOOST_ASIO_DISABLE_HANDLER_TYPE_REQUIREMENTS` to bypass restrictive library checks.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We just modify the `tasks_processor` class by adding new methods to run a task
    at some specified time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s add a method to our `tasks_processor` class for the delayed running
    of a task:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'As a final step, we create a `timer_task` structure:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'That''s how we could use the new functionality:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Where `test_functor` is structure with defined `operator()` and `test_func1`
    is a function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In short, when a specified amount of time is passed, `boost::asio::deadline_timer`
    pushes the task to the instance of `boost::asio::io_service` class for execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'All the nasty stuff is inside the `run_delayed` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The `tasks_processor::run_delayed` function accepts a timeout and a functor
    to call after the timeout. In it, a unique pointer to `boost::asio::deadline_timer`
    is created. `boost::asio::deadline_timer` holds platform-specific stuff for asynchronous
    execution of a task.
  prefs: []
  type: TYPE_NORMAL
- en: '`Boost.Asio` does not manage memory out of the box. The library user has to
    take care of managing resources usually by keeping them in the task. So if we
    need a timer and want some function to execute after the specified timeout, we
    have to move the timer''s unique pointer into the task, get a reference to the
    timer, and pass a task to the timer.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We are getting a reference to the `deadline_timer` in this line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we create a `detail::timer_task` object that stores a functor and gets
    the ownership of the `unique_ptr<boost::asio::deadline_timer>` :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The `boost::asio::deadline_timer` must not be destroyed until it is triggered,
    and moving it into the `timer_task` functor guarantees that.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we instruct the `boost::asio::deadline_timer` to post the `timer_task`
    functor to the `io_service` when the requested amount of time elapses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Reference to the `io_service` variable is kept inside the `boost::asio::deadline_timer`
    variable. That's why its constructor requires a reference to `io_service` to store
    it and post the task to it as soon as the timeout elapses.
  prefs: []
  type: TYPE_NORMAL
- en: The `detail::timer_task::operator()` method accepts `boost::system::error_code`,
    which contains error description if something bad happened while waiting. If no
    error occurred, we call the user's functor that is wrapped to catch exceptions
    (we re-use the `detail::task_wrapped` structure from the first recipe).
  prefs: []
  type: TYPE_NORMAL
- en: '`boost::asio::deadline_timer::async_wait` does not consume CPU resources or
    thread of execution while waiting for the timeout. You may simply push some further
    into the `io_service` and they will start executing while the timeout is being
    maintained by OS:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00010.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'As a rule of thumb: all the resources that are used during the `async_*` calls
    must be stored in the task.'
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Some exotic/antique platforms have no APIs to implement timers in a good way,
    so the `Boost.Asio` library emulates the behavior of the asynchronous timer using
    an additional thread of execution per `io_service`. There's just no other way
    to do it.
  prefs: []
  type: TYPE_NORMAL
- en: C++17 has no `Boost.Asio`-like classes in it; however, the Networking TS has
    `async_wait` and `timer` classes.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reading the first recipe from this chapter will teach you the basics of `boost::asio::io_service`.
    The following recipes will provide you with more examples of `io_service` usage
    and will show you how to deal with network communications, signals, and other
    features using `Boost.Asio`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You may consider the documentation of `Boost.Asio` for getting some examples,
    tutorials, and class references at [http://boost.org/libs/asio](http://boost.org/libs/asio)
    site.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network communication as a task
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Receiving or sending data by network is a slow operation. While packets are
    received by the machine, and while OS verifies them and copies the data to the
    user-specified buffer, multiple seconds may pass.
  prefs: []
  type: TYPE_NORMAL
- en: We may do a lot of work rather than waiting! Let's modify our `tasks_processor`
    class so that it would be capable of sending and receiving data in an asynchronous
    manner. In nontechnical terms, we ask it to receive at least *N* bytes from the
    remote host and after that is done, call our functor. By the way, do not block
    on this call. Those readers who know about **libev**, **libevent**, or Node.js
    may find a lot of familiar things in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe is based on the previous two recipes. See the first recipe of this
    chapter to get information about the `boost::asio::io_service` and `task_queue`
    classes. See the second recipe review the basics of async processing.
  prefs: []
  type: TYPE_NORMAL
- en: Link this recipe with the `boost_system` and `boost_thread` libraries. Define
    `BOOST_ASIO_DISABLE_HANDLER_TYPE_REQUIREMENTS` to bypass over restrictive library
    checks.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's extend the code from the previous recipe by adding methods to create connections.
  prefs: []
  type: TYPE_NORMAL
- en: 'A connection would be represented by a `connection_with_data` class. This class
    is keeping socket to the remote host and a `std::string` for receiving and sending
    data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Just like in the previous recipe, class would be mostly used by unique pointer
    to it. Let''s add a `typedef` for simplicity:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The `tasks_processor` class from previous recipe owns the `boost::asio::io_service`
    object. It seems reasonable to make it a factory for constructing connections:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the methods for async writing data to remote host:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the methods for async reading data from remote host:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The final part is the `task_wrapped_with_connection` class definition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Done! Now, the library user can use the preceding class like this to send the
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Users may also use it like this to receive data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'This is how a library user may handle the received data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `Boost.Asio` library does not manage resources and buffers out of the box.
    So, if we want some simple interface for reading and writing data, the simplest
    solution would be to tie together the socket and buffer for sending/receiving
    data. That's what the `connection_with_data` class does. It holds a `boost::asio::ip::tcp::socket`,
    which is a `Boost.Asio` wrapper around native sockets and a `std::string` variable
    that we use as a buffer.
  prefs: []
  type: TYPE_NORMAL
- en: 'A constructor of the `boost::asio::ip::tcp::socket` class accepts `boost::asio::io_service`
    as almost all the classes in `Boost.Asio`. After we create a socket, it must be
    connected to some remote endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Take a look at the writing function. It accepts a unique pointer to the `connection_with_data`
    class and functor `f`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'In it, we get references to socket and buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we ask for asynchronous write:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'All the interesting things happen in the `boost::asio::async_write` function.
    Just as in the case of timers, asynchronous call returns immediately without executing
    a function. It only tells to post the callback task to the `boost::asio::io_service`
    after some operation finishes (in our case, it''s writing data to the socket).
    `boost::asio::io_service` executes our function in one of the threads that called
    the `io_service::run()` method. The following diagram illustrates this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00011.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Now, take a look at `task_wrapped_with_connection::operator()`. It accepts `const
    boost::system::error_code& error` and `std::size_t bytes_count`, because both
    `boost::asio::async_write` and `boost::asio::async_read` functions pass those
    parameters on async operation completion. A call to `c_->data.resize(bytes_count);`
    resizes the buffer to contain only the received/written data. Finally, we call
    the callback that was initially passed to an `async` function and stored as `task_unwrapped_`.
  prefs: []
  type: TYPE_NORMAL
- en: 'What was that all about? That was all about having a simple way for sending
    data! Now, we have an `async_write_data` function that asynchronously writes data
    from the buffer to the socket and executes a callback on operation completion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '`async_read_data` is pretty close to `async_write_data`. It resizes the buffer,
    creates a `task_wrapped_with_connection` function, and pushes it into `is_service`
    on async operation completion.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note the `async_read_data_at_least` function. In its body, there''s a slightly
    different call to `boost::asio::async_read`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: It has a `boost::asio::transfer_at_least(al_least_bytes)` in it. `Boost.Asio`
    has a lot of functors for customizing reads and writes. This one functor says,
    *transfer at least* `at_least_bytes` *bytes before calling the callback. More
    bytes are OK until they fit in buffer*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let''s take a look at one of the callbacks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, callbacks must accept `connection_ptr` and a `boost::system::error_code`
    variable. A `boost::system::error_code` variable holds information about errors.
    It has an explicit conversion to `bool` operator, so the simple way to check for
    errors is just to write `if (err) { ... }`. If the remote ends transmission and
    closes the socket, `err` may contain `boost::asio::error::eof` error code. This
    is not always bad. In our example, we treat it as a non error behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Because we have tied together the socket and the buffer, you can get the received
    data from `soc->data`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The `soc->shutdown()` call is optional, because when `soc` goes out of scope,
    the destructor for it is called. Destructor of `unique_ptr<connection_with_data>`
    calls `~connection_with_data` that has a `shutdown()` in its body.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our `task_wrapped_with_connection::operator()` is not good enough! User provided
    `task_unwrapped_` callback my throw exceptions and may get interrupted by a `Boost.Thread`
    interruption that does not belong to that particular task. The fix would be to
    wrap the callback into the class from first recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: In `task_wrapped_with_connection::operator()`, we create a lambda function named
    `lambda`. On execution, `lambda` resizes the data inside the `connection_with_data`
    class to the `bytes_count` and calls an initially passed callback. Finally, we
    wrap the `lambda` into our safe for execution tasks from the first recipe and
    then execute it.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may see a lot of `Boost.Asio` examples on the Internet. Many of those use
    `shared_ptr` instead of a `unique_ptr` for keeping the data around. Approach with
    `shared_ptr` is simpler to implement; however, it has two big drawbacks:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Efficiency: `shared_ptr` has an atomic counter inside, and modifying it from
    different threads may significantly degrade performance. In one of the next recipes,
    you will see how to process tasks in multiple threads, and that''s the place where
    the differences may be noticeable in cases of high load.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Explicitness: With `unique_ptr`, you always see that the ownership of the connection
    was transferred to somewhere (you see `std::move` in code). With `shared_ptr`,
    you can not understand from the interface whether the function grabs the ownership
    or if it just uses a reference to an object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, you may be forced to use `shared_ptr`, if according to the application's
    logic, the ownership has to be shared across multiple tasks at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: '`Boost.Asio` is not a part of C++17, but it will be shipped as a Networking
    TS soon, and included into the one of the upcoming C++ standards.'
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: See the official documentation of `Boost.Asio` for more examples, tutorials,
    full reference at [http://boost.org/libs/asio](http://boost.org/libs/asio), and
    an example of how to use the UDP or ICMP protocols.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You may also read the *Boost.Asio C++ Network Programming* book, which describes
    `Boost.Asio` in more detail
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accepting incoming connections
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A server-side working with a network often looks like a sequence where we first
    get the new connection, read data, then process it, and then send the result.
    Imagine that we are creating some kind of authorization server that must process
    huge amount of requests per second. In that case, we need to accept, receive,
    send asynchronously, and process tasks in multiple threads.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we'll see how to extend our `tasks_processor` class to accept
    and process incoming connections, and, in the next recipe, we'll see how to make
    it multithreaded.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe requires a good knowledge of `boost::asio::io_service` basics as
    described in the first recipes of this chapter. Some knowledge about network communications
    will be of help to you. Knowledge of `boost::function` and information from at
    least two previous recipes is also required. Link this recipe with the `boost_system`
    and `boost_thread` libraries. Define `BOOST_ASIO_DISABLE_HANDLER_TYPE_REQUIREMENTS`
    to bypass over restrictive library checks.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just like in the previous recipes, we add new methods to our `tasks_processor`
    class.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start with adding some `typedefs` to the `tasks_processor`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s add a class that ties together the socket for new incoming connections,
    socket to listen to, and a user provided callback for processing new connections:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to add a function that starts listening on a specified port:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Function that starts accepting incoming connections:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'We also need a functor that handles the new connection:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Done! Now, we can accept connection in the following manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The function `add_listener` constructs new `tcp_listener`, that keeps all the
    stuff required for accepting connections. Just as with any asynchronous operation,
    we need to keep resources alive while the operations executes. A unique pointer
    to `tcp_listener` does the job.
  prefs: []
  type: TYPE_NORMAL
- en: When we construct `boost::asio::ip::tcp::acceptor` specifying the endpoint (see
    *step 3*), it opens a socket at the specified address and gets ready for accepting
    connections.
  prefs: []
  type: TYPE_NORMAL
- en: In *step 4*, we create a new socket and call `async_accept` for that new socket.
    When a new connection comes, `listener->acceptor_` binds this connection to a
    socket and pushes the `tasks_processor::handle_accept` callback into `boost::asio::io_service`.
    As we understood from the previous recipe, all the `async_*` calls return immediately
    and `async_accept` is not a special case.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a closer look at our `handle_accept::operator()`. In it, we create
    a `task_wrapped_with_connection` functor from the previous recipe and move a new
    connection into it. Now, our `listener_ptr` does not have a socket in `new_c_`,
    as it is owned by the functor. We call the function `start_accepting_connection(std::move(listener))`,
    and it creates a new socket in `listener->new_c_` and starts an asynchronous accept.
    An async accept operation does not block, so the program continues execution,
    returns from the `start_accepting_connection(std::move(listener))` function, and
    executes the functor with the connection `task(error, 0)`.
  prefs: []
  type: TYPE_NORMAL
- en: You've made everything as shown in the example, but the performance of the server
    is not good enough. That's because the example is simplified and many optimizations
    left behind at the scene. The most significant one is to keep a separate small
    buffer in `connection_with_data` and use it for all the internal `Boost.Asio`'s
    callback related allocations. See *Custom memory allocation example* in the official
    documentation of the `Boost.Asio` library for more information on this optimization
    topic.
  prefs: []
  type: TYPE_NORMAL
- en: When the destructor for the `boost::asio::io_service` is called, destructors
    for all the callbacks are called. This makes the destructor for `tcp_connection_ptr`
    to be called and frees the resources.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We did not use all the features of the `boost::asio::ip::tcp::acceptor` class.
    It can bind to a specific IPv6 or IPv4 address if we provide a specific `boost::asio::ip::tcp::endpoint`.
    You may also get a native socket via the `native_handle()` method and use some
    OS-specific calls for tuning the behavior. You may set up some options for `acceptor_`
    by calling `set_option`. For example, this is how you may force an `acceptor_`
    to reuse the address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Reusing the address provides an ability to restart the server quickly after
    it was terminated without correct shutdown. After the server was terminated, a
    socket may be opened for some time, and you won't be able to start the server
    on the same address without the `reuse_address` option.
  prefs: []
  type: TYPE_NORMAL
- en: C++17 has no classes from `Boost.Asio`, but Networking TS with most of the functionality
    is coming soon.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Starting this chapter from the beginning is a good idea to get much more information
    about `Boost.Asio`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See the official documentation of `Boost.Asio` for more examples, tutorials,
    and a complete reference at [http://boost.org/libs/asio](http://boost.org/libs/asio)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Executing different tasks in parallel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, it is time to make our `tasks_processor` process tasks in multiple threads.
    How hard can this be?
  prefs: []
  type: TYPE_NORMAL
- en: Getting started
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will need to read the first recipe from this chapter. Some knowledge of
    multithreading is also required, especially reading the *Manipulating a group
    of threads* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Link this recipe with the `boost_system` and `boost_thread` libraries. Define
    `BOOST_ASIO_DISABLE_HANDLER_TYPE_REQUIREMENTS` to bypass restrictive library checks.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'All we need to do is to add the `start_multiple` method to our `tasks_processor`
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'And now, we are able to do much more work as illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00012.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `boost::asio::io_service::run` method is thread safe. All we need to do
    is just run the `boost::asio::io_service::run` method from different threads.
  prefs: []
  type: TYPE_NORMAL
- en: If you are executing tasks that modify a common resource, you need to add mutexes
    around that resources, or organize your application in a way, that the common
    resource is not used simultaneously by different tasks. It is safe to use resource
    from different tasks without concurrent access to the resource because `boost::asio::io_service`
    takes care of additional synchronization between tasks and forces the modification
    results of one task to be seen by another task.
  prefs: []
  type: TYPE_NORMAL
- en: See the call to `boost::thread::hardware_concurrency()`. It returns the count
    of threads that can be run concurrently on current hardware. But, it is just a
    hint, and sometimes it may return a `0` value, which is why we are calling the
    `std::max` function for it. `std::max` ensures that `threads_count` stores at
    least the value `1`.
  prefs: []
  type: TYPE_NORMAL
- en: We wrapped `std::max` in parentheses because some popular compilers define the
    `min()` and `max()` macros, so we need additional tricks to work around this.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `boost::thread::hardware_concurrency()` function is a part of C++11; you
    may find it in the `<thread>` header of the `std::` namespace.
  prefs: []
  type: TYPE_NORMAL
- en: All the `boost::asio` classes are not part of C++17, but they will be available
    soon as a Networking TS.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: See the `Boost.Asio` documentation for more examples and information about different
    classes at [http://boost.org/libs/asio](http://boost.org/libs/asio)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recipes from [Chapter 5](part0262.html#7PRJC0-712b4ba1126a4c7c89e1d44de61b4bdd),
    *Multithreading*, (especially the last recipe called *Manipulating a group of
    threads*) will give you information about the `Boost.Thread` usage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See the `Boost.Thread` documentation for information about `boost::thread_group`
    and `boost::threads` at [http://boost.org/libs/thread](http://boost.org/libs/thread)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipeline tasks processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes, there is a requirement to process tasks in a specified time interval.
    Compared to previous recipes, where we were trying to process tasks in the order
    of their appearance in the queue, this is a big difference.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the example where we are writing a program that connects two subsystems,
    one of which produces data packets and the other writes modified data to the disk
    (something like this can be seen in video cameras, sound recorders, and other
    devices). We need to process data packets one by one in the specified order, smoothly
    with a small jitter, and in multiple threads.
  prefs: []
  type: TYPE_NORMAL
- en: 'Naive approach does not work here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'In a multithreaded environment, we can get *packet #1* in first thread and
    then *packet #2* in the second thread of execution. Because of different processing
    times, OS context switches and scheduling *packet #2* may be processed before
    *packet #1*. There''s no guarantee on packets, processing order. Let''s fix that!'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *Making a work_queue* recipe from [Chapter 5](part0262.html#7PRJC0-712b4ba1126a4c7c89e1d44de61b4bdd),
    *Multithreading*, is required for understanding this example. The code must be
    linked against the `boost_thread` and `boost_system` libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Basic knowledge of C++11, especially of lambda functions, is required.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe is based on the code of the `work_queue` class from the *Making
    a work_queue* recipe of [Chapter 5](part0262.html#7PRJC0-712b4ba1126a4c7c89e1d44de61b4bdd),
    *Multithreading*. We'll make some modifications and will be using a few instances
    of that class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by creating separate queues for data decoding, data compressing,
    and data sending:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, it is time to refactor the `process_data` and split it into multiple functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Our `work_queue` class from [Chapter 5](part0262.html#7PRJC0-712b4ba1126a4c7c89e1d44de61b4bdd),
    *Multithreading*, gets some interface changes for stopping and running tasks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The implementation of `work_queue`''s `stop()` and `run()` functions must look
    like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'That is all! Now, we only need to start the pipeline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The pipeline can be stopped like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The trick is to split the processing of a single data packet into some equally
    small subtasks and process them one by one in different `work_queues`. In this
    example, we can split the data process into data decoding, data compressing, and
    data sending.
  prefs: []
  type: TYPE_NORMAL
- en: 'Processing of six packets, ideally, would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Time** | **Receiving** | **Decoding** | **Compressing** | **Sending** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Tick 1: | packet #1 |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Tick 2: | packet #2 | packet #1 |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Tick 3: | packet #3 | packet #2 | packet #1 |  |'
  prefs: []
  type: TYPE_TB
- en: '| Tick 4: | packet #4 | packet #3 | packet #2 | packet #1 |'
  prefs: []
  type: TYPE_TB
- en: '| Tick 5: | packet #5 | packet #4 | packet #3 | packet #2 |'
  prefs: []
  type: TYPE_TB
- en: '| Tick 6: | packet #6 | packet #5 | packet #4 | packet #3 |'
  prefs: []
  type: TYPE_TB
- en: '| Tick 7: | - | packet #6 | packet #5 | packet #4 |'
  prefs: []
  type: TYPE_TB
- en: '| Tick 8: | - | - | packet #6 | packet #5 |'
  prefs: []
  type: TYPE_TB
- en: '| Tick 9: | - | - | - | packet #6 |'
  prefs: []
  type: TYPE_TB
- en: However, our world is not ideal, so some tasks may finish faster than others.
    For example, receiving may work faster than decoding and, in that case, the decoding
    queue will be holding a set of tasks to be done. To avoid queue overflows, try
    hard to make each subsequent task slightly faster than the previous one.
  prefs: []
  type: TYPE_NORMAL
- en: We did not use `boost::asio::io_service` in our example, because it does not
    guarantee that posted tasks are executed in order of their postage.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the tools used to create a pipeline in this example are available in C++11,
    so nothing would stop you from creating the same things without a Boost on a C++11
    compatible compiler. However, Boost makes your code more portable and usable on
    the pre-C++11 compilers.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This technique is well known and used by processor developers. See [http://en.wikipedia.org/wiki/Instruction_pipeline](http://en.wikipedia.org/wiki/Instruction_pipeline).
    Here, you may find a brief description of all the characteristics of the pipeline.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*The Making a work_queue* from [Chapter 5](part0262.html#7PRJC0-712b4ba1126a4c7c89e1d44de61b4bdd),
    *Multithreading* recipe will give you more information about methods used in this
    recipe.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making a nonblocking barrier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In multithreaded programming, there is an abstraction called **barrier**. It
    stops threads of execution that reach it until the requested number of threads
    are not blocked on it. After that, all the threads are released and they continue
    with their execution. Consider the following example of where it can be used.
  prefs: []
  type: TYPE_NORMAL
- en: 'We want to process different parts of data in different threads and then send
    the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'The `data_barrier.wait()` method blocks until all the threads fill the data.
    After that, all the threads are released. The thread with the index `0` computes
    data to be sent using `compute_send_data(data)`, while other threads are again
    waiting at the barrier as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00013.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Looks lame, doesn't it?
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe requires knowledge of the first recipe of this chapter. Knowledge
    of `Boost.Thread` is also required. Code from this recipe requires linking against
    the `boost_thread` and `boost_system` libraries.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We do not need to block at all! Let's take a closer look at the example. All
    we need to do is to post four `fill_data` tasks and make the last finished task
    call `compute_send_data(data)`.
  prefs: []
  type: TYPE_NORMAL
- en: We'll need the `tasks_processor` class from the first recipe; no changes to
    it need to be done.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Instead of a barrier, we''ll be using the atomic variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Our new runner function will look like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'The `main` function requires a minor change:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We do not block at all. Instead of blocking, we count the tasks that finished
    filling the data. This is done by the `counter` atomic variable. The last remaining
    task will have a `counter` variable equal to `data_t::static_size`. Only that
    task must compute and send the data.
  prefs: []
  type: TYPE_NORMAL
- en: After that, we check for the exit condition (1000 iterations are done) and post
    the new data by pushing tasks to the queue.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Is this a better solution? Well, first of all, it scales better:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00014.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: This method can also be more effective for situations where a program does a
    lot of different work. Because no threads are waiting in barriers, free threads
    may execute some other tasks while one of the threads computes and sends the data.
  prefs: []
  type: TYPE_NORMAL
- en: This recipe could be implemented in C++11 without Boost libraries. You'll only
    need to replace `io_service` inside `tasks_processor` with `work_queue` from [Chapter
    5](part0262.html#7PRJC0-712b4ba1126a4c7c89e1d44de61b4bdd), *Multithreading*. But
    as always, Boost provides better portability, and it is possible to make this
    example run on a pre-C++11, compilers using Boost libraries. You'll only need
    to replace lambda functions with `boost::bind` and `boost::ref`.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Official documentation of `Boost.Asio` may give you more information about `io_service`
    usage at [http://boost.org/libs/asio](http://boost.org/libs/asio)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See all the `Boost.Function` related recipes from [Chapter 2](part0108.html#36VSO0-712b4ba1126a4c7c89e1d44de61b4bdd),
    *Managing Resources*, and the official documentation at [http://boost.org/libs/function](http://boost.org/libs/function)
    for an overview of how tasks work
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See the recipes from [Chapter 1](part0029.html#RL0A0-712b4ba1126a4c7c89e1d44de61b4bdd),
    *Starting to Write Your Application*, related to `Boost.Bind` for getting more
    information about what the `boost::bind` function does, or see the official documentation
    at [http://boost.org/libs/bind](http://boost.org/libs/bind)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storing an exception and making a task from it
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Processing exceptions is not always trivial and may consume a lot of time. Consider
    the situation when an exception must be serialized and sent by the network. This
    may take milliseconds and a few thousands of lines of code. After the exception
    is caught, it is not always the best time and place to process it.
  prefs: []
  type: TYPE_NORMAL
- en: Can we store exceptions and delay their processing?
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe requires familiarity with `boost::asio::io_service`, which was described
    in the first recipe of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: This recipe requires linking with the `boost_system` and `boost_thread` libraries.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All we need is to have an ability to store exceptions and pass them between
    threads just like a usual variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with the function that stores and processes exceptions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The `operator()` of that functor just outputs the exception to the console:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s write some functions to demonstrate how exceptions work:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, if we run the example like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `Boost.Exception` library provides an ability to store and re-throw exceptions.
    The `boost::current_exception()` method must be called only from inside of the
    `catch()` block, and it returns an object of the type `boost::exception_ptr`.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding example in `func_test1()`, the `boost::bad_lexical_cast` exception
    is thrown. It is returned by `boost::current_exception()`; a `process_exception`
    task is created from that exception.
  prefs: []
  type: TYPE_NORMAL
- en: The only way to restore the exception type from `boost::exception_ptr` is to
    re-throw it using `boost::rethrow_exception(exc)` function. That's what the `process_exception`
    function does.
  prefs: []
  type: TYPE_NORMAL
- en: Throwing and catching exceptions is a heavy operation. Throwing may dynamically
    allocate memory, touch cold memory, lock mutex, compute a bunch of addresses,
    and do other stuff. Do not throw exception in performance critical paths without
    very good reasons to do so!
  prefs: []
  type: TYPE_NORMAL
- en: In `func_test2`, we are throwing a `std::logic_error` exception using the `BOOST_THROW_EXCEPTION`
    macro. This macro does a lot of useful work; it checks that our exception is derived
    from `std::exception`, adds information to our exception about the source filename,
    function name, and the code line number from where the exception was thrown. When
    our `std::logic_error` exception is re-thrown inside the `process_exception::operator()`
    it is caught by `catch(...)`. The `boost::current_exception_diagnostic_information()`
    outputs as much information about the thrown exception as possible.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Usually, `exception_ptr` is used to pass exceptions between threads. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: The `boost::exception_ptr` class may allocate memory through heap multiple times,
    uses atomics, and implements some of the operations by re-throwing and catching
    exceptions. Try not to use it without an actual need.
  prefs: []
  type: TYPE_NORMAL
- en: C++11 has adopted `boost::current_exception`, `boost::rethrow_exception`, and
    `boost::exception_ptr`. You may find them in the `<exception>` in the `std::`
    namespace. The `BOOST_THROW_EXCEPTION` and `boost::current_exception_diagnostic_information()`
    functions are not in C++17.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Official documentation of `Boost.Exception` at [http://boost.org/libs/exception](http://boost.org/libs/exception)
    contains a lot of useful information about implementation and restrictions. You
    may also find some information that is not covered in this recipe (for example,
    how to add additional information to an already thrown exception).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first recipe from this chapter gives you information about the `tasks_processor`
    class. The *Converting strings to numbers r*ecipe from [Chapter 3](part0169.html#515F20-712b4ba1126a4c7c89e1d44de61b4bdd),
    *Converting and Casting*, describes the `Boost.LexicalCast` library, that was
    used in this recipe.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting and processing system signals as tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When writing some server application (especially for Linux OS), catching and
    processing the signals is required. Usually, all the signal handlers are set up
    at server start and do not change during the application's execution.
  prefs: []
  type: TYPE_NORMAL
- en: The goal of this recipe is to make our `tasks_processor` class capable of processing
    signals.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will need code from the first recipe of this chapter. A sound knowledge of
    `Boost.Function` is also required.
  prefs: []
  type: TYPE_NORMAL
- en: This recipe requires linking with the `boost_system` and `boost_thread` libraries.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This recipe is similar to the recipes from *2* to *4* of this chapter: we have
    `async` signal waiting functions, some `async` signal handlers, and some support
    code.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by including the following headers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we add a member for signals processing to the `tasks_processor` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'The function that will be called upon signal capture is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'And now we need a function for registering the signals handler:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'That''s all. Now, we are ready to process signals. The following is a test
    program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Nothing is difficult here (compared to some previous recipes from this chapter).
    The `register_signals_handler` function adds the signal numbers that will be processed.
    It is done via a call to the `boost::asio::signal_set::add` function for each
    element of the `signals_to_wait`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, the `sigs.async_wait` starts the `async` waiting for a signal and calls
    the `tasks_processor::handle_signals` function on the signal capture. The `tasks_processor::handle_signals`
    function immediately starts async wait for the next signal, checks for errors
    and, if there are none, it calls a callback providing a signal number.
  prefs: []
  type: TYPE_NORMAL
- en: There is more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can do better! We can wrap the user provided callback into our class from
    the first recipe to correctly process exceptions and do other good stuff from
    the first recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: When a thread-safe dynamic adding and removing of signals is required, we may
    modify this example to look like `detail::timer_task` from the *Making timers
    and processing timer events as tasks* recipe of this chapter . When multiple `boost::asio::signal_set`
    objects are registered for waiting on the same signals, a handler from each of
    `signal_set` is called on a single signal.
  prefs: []
  type: TYPE_NORMAL
- en: C++ has been capable of processing signals for a long time using the `signal`
    function from the `<csignal>` header. Networking TS probably will not have the
    `signal_set` functionality.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *Storing any functional object in variable* recipe from [Chapter 2](part0108.html#36VSO0-712b4ba1126a4c7c89e1d44de61b4bdd)*,*
    *Managing Resources*, provides information about `boost::function`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: "See the official documentation of `Boost.Asio` for more information and examples\
    \ on `boost::asio::signal_set` and other features of this great library at [http://boost.org/libs/asio\uFEFF\
    ](http://boost.org/libs/asio)"
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
