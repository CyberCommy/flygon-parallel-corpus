- en: Amdahl's Law
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 阿姆达尔定律
- en: Often used in discussions revolving around concurrent programs, Amdahl's Law
    explains the theoretical speedup of the execution of a program that can be expected
    when using concurrency. In this chapter, we will discuss the concept of Amdahl's
    Law, and we will analyze its formula, which estimates the potential speedup of
    a program and replicates it in Python code. This chapter will also briefly cover
    the relationship between Amdahl's Law and the law of diminishing returns.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 阿姆达尔定律经常用于围绕并发程序的讨论，它解释了在使用并发时可以预期的程序执行的理论加速。在本章中，我们将讨论阿姆达尔定律的概念，并分析其估计程序潜在加速的公式，并在Python代码中复制它。本章还将简要介绍阿姆达尔定律与边际收益递减定律之间的关系。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Amdahl's Law
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阿姆达尔定律
- en: 'Amdahl''s Law: its formula and interpretation'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阿姆达尔定律：其公式和解释
- en: The relationship between Amdahl's Law and the law of diminishing returns
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阿姆达尔定律与边际收益递减定律之间的关系
- en: Simulation in Python, and the practical applications of Amdahl's Law
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python中的模拟和阿姆达尔定律的实际应用
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The following is a list of prerequisites for this chapter:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是本章的先决条件列表：
- en: Ensure that you have Python 3 installed on your computer
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保您的计算机上安装了Python 3
- en: Download the GitHub repository at [https://github.com/PacktPublishing/Mastering-Concurrency-in-Python](https://github.com/PacktPublishing/Mastering-Concurrency-in-Python)
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[https://github.com/PacktPublishing/Mastering-Concurrency-in-Python](https://github.com/PacktPublishing/Mastering-Concurrency-in-Python)下载GitHub存储库。
- en: During this chapter, we will be working with the subfolder named `Chapter02`
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用名为`Chapter02`的子文件夹
- en: Check out the following video to see the Code in Action: [http://bit.ly/2DWaOeQ](http://bit.ly/2DWaOeQ)
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看以下视频以查看代码实际运行情况：[http://bit.ly/2DWaOeQ](http://bit.ly/2DWaOeQ)
- en: Amdahl's Law
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 阿姆达尔定律
- en: 'How do you find a balance between parallelizing a sequential program (by increasing
    the number of processors) and optimizing the execution speed of the sequential
    program itself? For example, which is the better option: Having four processors
    running a given program for 40% of its execution, or using only two processors
    executing the same program, but for twice as long? This type of trade-off, which
    is commonly found in concurrent programming, can be strategically analyzed and
    answered by applying Amdahl''s Law.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如何在并行化顺序程序（通过增加处理器数量）和优化顺序程序本身的执行速度之间找到平衡？例如，哪个选项更好：有四个处理器运行给定程序的40%的执行时间，还是只使用两个处理器执行相同的程序，但时间加倍？这种权衡在并发编程中经常出现，可以通过应用阿姆达尔定律进行战略分析和回答。
- en: Additionally, while concurrency and parallelism can be a powerful tool that
    provides significant improvements in program execution time, they are not a silver
    bullet that can speed up any non-sequential architecture infinitely and unconditionally.
    It is therefore important for developers and programmers to know and understand
    the limits of the speed improvements that concurrency and parallelism offer to
    their programs, and Amdahl's Law addresses those concerns.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，虽然并发和并行可以是提供程序执行时间显著改进的强大工具，但它们并不是可以无限制地加速任何非顺序架构的银弹。因此，开发人员和程序员了解并理解并发和并行提供给他们的程序速度改进的限制是非常重要的，而阿姆达尔定律正是解决了这些问题。
- en: Terminology
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 术语
- en: 'Amdahl''s Law provides a mathematical formula that calculates the potential
    improvement in speed of a concurrent program by increasing its resources (specifically,
    the number of available processors). Before we can get into the theory behind
    Amdahl''s Law, first, we must clarify some terminology, as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 阿姆达尔定律提供了一个数学公式，计算通过增加资源（特别是可用处理器的数量）来提高并发程序速度的潜在改进。在我们深入阿姆达尔定律的理论之前，首先我们必须澄清一些术语，如下所示：
- en: Amdahl's Law solely discusses the potential speedup in latency resulting from
    executing a task in **parallel**. While concurrency is not directly discussed
    here, the results from Amdahl's Law concerning parallelism will nonetheless give
    us an estimation regarding concurrent programs.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阿姆达尔定律仅讨论由并行执行任务产生的潜在延迟加速。虽然这里并没有直接讨论并发性，但阿姆达尔定律关于并行性的结果将为我们提供有关并发程序的估计。
- en: The **speed** of a program denotes the time it takes for the program to execute
    in full. This can be measured in any increment of time.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 程序的**速度**表示程序执行所需的时间。这可以用任何时间单位来衡量。
- en: '**Speedup** is the time that measures the benefit of executing a computation
    in parallel. It is defined as the time it takes a program to execute in serial
    (with one processor), divided by the time it takes to execute in parallel (with
    multiple processors). The formula for speedup is as follows:'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加速**是衡量并行执行计算的好处的时间。它定义为程序在串行执行（使用一个处理器）所需的时间除以并行执行（使用多个处理器）所需的时间。加速的公式如下：'
- en: '![](assets/986d7d71-2d13-4c12-96ea-ee3dfe76c212.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/986d7d71-2d13-4c12-96ea-ee3dfe76c212.png)'
- en: In the preceding formula, *T(j)* is the time it takes to execute the program
    when using *j* processors.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述公式中，*T(j)*是使用*j*个处理器执行程序所需的时间。
- en: Formula and interpretation
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 公式和解释
- en: Before we get into the formula for Amdahl's Law and its implications, let's
    explore the concept of speedup, through some brief analysis. Let's assume that
    there are *N* workers working on a given job that is fully parallelizable—that
    is, the job can be perfectly divided into *N* equal sections. This means that
    *N* workers working together to complete the job will only take *1/N* of the time
    it takes one worker to complete the same job.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨阿姆达尔定律及其含义的公式之前，让我们通过一些简要分析来探讨加速的概念。假设有*N*个工人在完成一个完全可并行化的工作，也就是说，这项工作可以完全分成*N*个相等的部分。这意味着*N*个工人一起完成工作所需的时间只有一个工人完成相同工作所需时间的*1/N*。
- en: 'However, most computer programs are not 100% parallelizable: some parts of
    a program might be inherently sequential, while others are broken up into parallel
    tasks.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: The formula for Amdahl's Law
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let *B* denote the fraction of the program that is strictly serial, and
    consider the following:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '*B * T(1)* is the time it takes to execute the parts of the program that are
    inherently sequential.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*T(1) - B * T(1) = (1 - B) * T(1)* is the time it takes to execute the parts
    of the program that are parallelizable, with one processor:'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, *(1 - B) * T(1) / N* is the time it takes to execute these parts with
    *N* processors
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, *B * T(1) + (1 - B) * T(1) / N* is the total time it takes to execute the
    whole program with *N* processors.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Coming back to the formula for the speedup quantity, we have the following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/a34239f2-5c32-498d-b61d-411fbebcf3ee.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
- en: This formula is actually a form of Amdahl's Law, used to estimate the speedup
    in a parallel program.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: A quick example
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s assume that we have a computer program, and the following applies to
    it:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: 40% of it is subject to parallelism, so *B = 1 - 40% = 0.6*
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Its parallelizable parts will be processed by four processors, so *j = 4*
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Amdahl''s Law states that the overall speedup of applying the improvement will
    be as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/88f39be3-7a83-4262-a1f4-5a0c3ea01537.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
- en: Implications
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following is a quote from Gene Amdahl, in 1967:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '"For over a decade prophets have voiced the contention that the organization
    of a single computer has reached its limits and that truly significantly advances
    can be made only by interconnection of a multiplicity of computers in such a manner
    as to permit cooperative solution... The nature of this overhead (in parallelism)
    appears to be sequential so that it is unlikely to be amenable to parallel processing
    techniques. Overhead alone would then place an upper limit on throughput of five
    to seven times the sequential processing rate, even if the housekeeping were done
    in a separate processor... At any point in time it is difficult to foresee how
    the previous bottlenecks in a sequential computer will be effectively overcome."'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 'Through the quote, Amdahl indicated that whatever concurrent and parallel techniques
    are implemented in a program, the sequential nature of the overhead portion required
    in the program always sets an upper boundary on how much speedup the program will
    gain. This is one of the implications that Amdahl''s Law further suggests. Consider
    the following example:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/e4183f84-6169-4f5d-a160-a49a43684317.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: '![](assets/797bcd1b-a8ef-477e-9246-1fcc3a2f64f1.png) denotes the speedup gained
    from *n* processors'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: This shows that, as the number of resources (specifically, the number of available
    processors) increases, the speedup of the execution of the whole task also increases.
    However, this does not mean that we should always implement concurrency and parallelism
    with as many system processors as possible, to achieve the highest performance.
    In fact, from the formula, we can also gather that the speedup achieved from incrementing
    the number of processors decreases. In other words, as we add more processors
    for our concurrent program, we will obtain less and less improvement in execution
    time.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, as mentioned previously, another implication that Amdahl''s Law
    suggests concerns the upper limit of the execution time improvement:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/03badc5e-2ea1-479c-b6f7-6b4cc6b93b2f.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
- en: '![](assets/a05c110e-9b5b-4c0b-8e8e-9a22a9168615.png) is the cap of how much
    improvement concurrency and parallelism can offer your program. This is to say
    that, no matter how many available resources your system has, it is impossible
    to obtain a speedup larger than ![](assets/3f0fb7e7-5719-4e70-a7a7-d541c525f98f.png) through
    concurrency, and this limit is dictated by the sequential overhead portion of
    the program (*B* is the fraction of the program that is strictly serial).'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Amdahl's Law's relationship to the law of diminishing returns
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amdahl's Law is often conflated with the law of diminishing returns, which is
    a rather popular concept in economics. However, the law of diminishing returns
    is only a special case of applying Amdahl's Law, depending on the order of improvement.
    If the order of separate tasks in the program is chosen to be improved in an **optimal**
    way, a monotonically decreasing improvement in execution time will be observed,
    demonstrating diminishing returns. An optimal method indicates first applying
    those improvements that will result in the greatest speedups, and leaving those
    improvements yielding smaller speedups for later.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 阿姆达尔定律经常与边际收益递减定律混淆，后者是经济学中一个相当流行的概念。然而，边际收益递减定律只是应用阿姆达尔定律的特例，取决于改进的顺序。如果选择以**最佳**方式改进程序中的单独任务顺序，将观察到执行时间的单调递减改进，表明边际收益递减。最佳方法指的是首先应用那些将导致最大加速的改进，然后将那些产生较小加速的改进留到后面。
- en: Now, if we were to reverse this sequence for choosing resources, in which we
    improve less optimal components of our program before more optimal components,
    the speedup achieved through the improvement would increase throughout the process.
    Furthermore, it is actually more beneficial for us to implement system improvements
    in this **reverse-optimal** order in reality, as the more optimal components are
    usually more complex, and take more time to improve.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们选择资源的顺序进行反转，即在改进更不理想的程序组件之前改进更理想的组件，通过改进获得的加速将在整个过程中增加。此外，实际上，对我们来说更有利的是按照这种**反向最佳**顺序实施系统改进，因为更理想的组件通常更复杂，需要更多时间来改进。
- en: Another similarity between Amdahl's Law and the law of diminishing returns concerns
    the improvement in speedup obtained through adding more processors to a system.
    Specifically, as a new processor is added to the system to process a fixed-size
    task, it will offer less usable computation power than the previous processor.
    As we discussed in the last section, the improvement in this situation strictly
    decreases as the number of processors increases, and the total throughout approaches
    the upper boundary of *1/B*.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 阿姆达尔定律和边际收益递减定律之间的另一个相似之处涉及通过向系统添加更多处理器获得的加速改进。具体来说，当向系统添加新处理器以处理固定大小的任务时，它提供的可用计算能力将少于上一个处理器。正如我们在上一节中讨论的，这种情况下的改进严格减少，随着处理器数量的增加，总吞吐量接近*1/B*的上限。
- en: It is important to note that this analysis does not take into account other
    potential bottlenecks, such as memory bandwidth and I/O bandwidth. In fact, if
    these resources do not scale with the number of processors, then simply adding
    processors results in even lower returns.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，此分析未考虑其他潜在的瓶颈，如内存带宽和I/O带宽。实际上，如果这些资源不随处理器数量增加而增加，那么简单地添加处理器将导致更低的回报。
- en: How to simulate in Python
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何在Python中模拟
- en: In this section, we will look at the results of Amdahl's Law through a Python
    program. Still considering the task of determining whether an integer is a prime
    number, as discussed in [Chapter 1](0159c46a-c66b-4ba3-87b5-81dbeb3bcf02.xhtml),
    *Advanced Introduction to Concurrent and Parallel Programming**,* we will see
    what actual speedup is achieved through concurrency. If you already have the code
    for the book downloaded from the GitHub page, we are looking at the `Chapter02/example1.py`
    file.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过一个Python程序来查看阿姆达尔定律的结果。仍然考虑到确定整数是否为素数的任务，如[第1章](0159c46a-c66b-4ba3-87b5-81dbeb3bcf02.xhtml)中所讨论的，*并发和并行编程的高级介绍*，我们将看到通过并发实际实现了什么样的加速。如果您已经从GitHub页面下载了书籍的代码，我们将查看`Chapter02/example1.py`文件。
- en: 'As a refresher, the function that checks for prime numbers is as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 作为复习，检查素数的函数如下：
- en: '[PRE0]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The next part of the code is a function that takes in an integer that indicates
    the number of processors (workers) that we will be utilizing to concurrently solve
    the problem (in this case, it is used to determine which numbers in a list are
    prime numbers):'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的下一部分是一个函数，它接受一个整数，表示我们将利用多少个处理器（工作者）并发解决问题（在本例中，用于确定列表中的哪些数字是素数）：
- en: '[PRE1]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Notice that the variables `sub_start` and `sub_duration` measure the portion
    of the task that is being solved concurrently, which, in our earlier analysis,
    is denoted as *1 - B*. As for the input, we will be looking at numbers between
    *10^(13)* and *10^(13) + 1000*:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，变量`sub_start`和`sub_duration`测量正在同时解决的任务部分，在我们之前的分析中，它表示为*1 - B*。至于输入，我们将查看介于*10^(13)*和*10^(13)
    + 1000*之间的数字：
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Lastly, we will be looping from one to the maximum number of processors available
    in our system, and we will pass that number to the preceding `concurrent_solve()`
    function. As a quick tip, to obtain the number of available processors from your
    computer, call `multiprocessing.cpu_count()`, as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将循环从1到系统中可用的最大处理器数量，并将该数字传递给前面的`concurrent_solve()`函数。作为一个快速提示，要从计算机中获取可用处理器的数量，请调用`multiprocessing.cpu_count()`，如下所示：
- en: '[PRE3]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You can run the whole program by entering the command `python example1.py`.
    Since my laptop has four cores, the following is my output after running the program:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过输入命令`python example1.py`来运行整个程序。由于我的笔记本电脑有四个核心，运行程序后的输出如下：
- en: '[PRE4]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'A few things to note are as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是需要注意的几点：
- en: First, in each iteration, the subsection of the task was almost as long as the
    whole program. In other words, the concurrent computation formed the majority
    of the program during each iteration. This is quite understandable, since there
    is hardly any other heavy computation in the program, aside from prime checking.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，在每次迭代中，任务的子部分几乎和整个程序一样长。换句话说，在每次迭代期间，并发计算形成了程序的大部分。这是可以理解的，因为除了素数检查之外，程序中几乎没有其他繁重的计算。
- en: Secondly, and arguably more interestingly, we can see that, while considerable
    improvements were gained after increasing the number of processors from `1` to
    `2` (`7.6659 seconds` to `4.1153 seconds`), hardly any speedup was achieved during
    the third iteration. It took longer during the forth iteration than the third,
    but this was most likely overhead processing. This is consistent with our earlier
    discussions regarding the similarity between Amdahl's Law and the law of diminishing
    returns, when considering the number of processors.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can also refer to a speedup curve to visualize this phenomenon. A speedup
    curve is simply a graph with the *x* axis showing the number of processors, compared
    to the *y* axis showing the speedup achieved. In a perfect scenario, where *S
    = j* (that is, the speedup achieved is equal to the number of processors used),
    the speedup curve would be a straight, 45-degree line. Amdahl''s Law shows that
    the speedup curve produced by any program will remain below that line, and will
    begin to flatten out as efficiency reduced. In the preceding program, this was
    during the transition from two to three processors:'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](assets/7f945408-80b5-46f9-b34d-1c600d093e8f.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
- en: Speedup curves with different parallel portions
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Practical applications of Amdahl's Law
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have discussed, by analyzing the sequential and parallelizable portion
    of a given program or system with Amdahl's Law, we can determine, or at least
    estimate, the upper limit of any potential improvements in speed resulting from
    parallel computing. Upon obtaining this estimation, we can then make an informed
    decision on whether an improved execution time is worth an increase in processing
    power.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: From our examples, we can see that Amdahl's Law is applied when you have a concurrent
    program that is a mixture of both sequentially and executed-in-parallels instructions.
    By performing analysis using Amdahl's Law, we can determine the speedup through
    each incrementation of the number of cores available to perform the execution,
    as well as how close that incrementation is to helping the program achieve the
    best possible speedup from parallelization.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s come back to the initial problem that we raised at the beginning
    of the chapter: the trade-off between an increase in the number of processors
    versus an increase in how long parallelism can be applied. Let''s suppose that
    you are in charge of developing a concurrent program that currently has 40 percent
    of its instructions parallelizable. This means that multiple processors can be
    running simultaneously for 40 percent of the program execution. Now you have been
    tasked with increasing the speed of this program by implementing either of the
    following two choices:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Having four processors implemented to execute the program instructions
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having two processors implemented, in addition to increasing the parallelizable
    portion of the program to 80 percent
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'How can we analytically compare these two choices, in order to determine the
    one that will produce the best speed for our program? Luckily, Amdahl''s Law can
    assist us during this process:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'For the first option, the speedup that can be obtained is as follows:'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](assets/425163cc-efba-48da-8111-4987fcf0b20f.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
- en: 'For the second option, the speedup is as follows:'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](assets/ca967f21-ffa6-4f82-b6b4-a88bfb25fd4f.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
- en: As you can see, the second option (which has fewer processors than the first)
    is actually the better choice to speed up our specific program. This is another
    example of Amdahl's Law, illustrating that sometimes simply increasing the number
    of available processors is, in fact, undesirable in terms of improving the speed
    of a program. Similar trade-offs, with potentially different specifications, can
    also be analyzed this way.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: As a final note, it is important for us to know that, while Amdahl's Law offers
    an estimation of potential speedup in an unambiguous way, the law itself makes
    a number of underlying assumptions and does not take into account some potentially
    important factors, such as the overhead of parallelism or the speed of memory.
    For this reason, the formula of Amdahl's Law simplifies various considerations
    that might be common in practice.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: So, how should programmers of concurrent programs think about and use Amdahl's
    Law? We should keep in mind that the results of Amdahl's Law are simply estimates
    that can provide us with an idea about where, and by how much, we can further
    optimize a concurrent system, specifically by increasing the number of available
    processors. In the end, only actual measurements can precisely answer our questions
    about how much speedup our concurrent programs will achieve in practice. With
    that said, Amdahl's Law can still help us to effectively identify good theoretical
    strategies for improving computing speed using concurrency and parallelism.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amdahl's Law offers us a method to estimate the potential speedup in execution
    time of a task that we can expect from a system when its resources are improved.
    It illustrates that, as the resources of the system are improved, so is the execution
    time. However, the differential speedup when incrementing the resources strictly
    decreases, and the throughput speedup is limited by the sequential overhead of
    its program.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: You also saw that in specific situations (namely, when only the number of processors
    increases), Amdahl's Law resembles the law of diminishing returns. Specifically,
    as the number of processors increases, the efficiency gained through the improvement
    decreases, and the speedup curve flattens out.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, this chapter showed that improvement through concurrency and parallelism
    is not always desirable, and detailed specifications are needed for an effective
    and efficient concurrent program.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: With more knowledge of the extent to which concurrency can help to speed up
    our programs, we will now start to discuss the specific tools that Python provides
    to implement concurrency. Specifically, we will consider one of the main players
    in concurrent programming, threads, in the next chapter, including their application
    in Python programming.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is Amdahl's Law? What problem does Amdahl's Law try to solve?
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explain the formula of Amdahl's Law, along with its components.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: According to Amdahl's Law, will speedup increase indefinitely as the resources
    of the system improve?
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the relationship between Amdahl's Law and the law of diminishing returns?
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information you can refer to the following links:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '*Amdahl''s Law* ([https://home.wlu.edu/~whaleyt/classes/parallel/topics/amdahl.html](https://home.wlu.edu/~whaleyt/classes/parallel/topics/amdahl.html)),
    by Aaron Michalove'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Uses and abuses of Amdahl''s Law*, Journal of Computing Sciences in Colleges
    17.2 (2001): 288-293, S. Krishnaprasad'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Learning Concurrency in Python: Build highly efficient, robust, and concurrent
    applications* (2017), Elliot Forbes'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
