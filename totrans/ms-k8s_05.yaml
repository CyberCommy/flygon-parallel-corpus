- en: Configuring Kubernetes Security, Limits, and Accounts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 4](0b446f8f-3748-4bb4-8406-78f2af468e14.xhtml), *High Availability
    and Reliability*, we looked at reliable and highly available Kubernetes clusters,
    the basic concepts, the best practices, how to do live cluster upgrades, and the
    many design trade-offs regarding performance and cost.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will explore the important topic of security. Kubernetes
    clusters are complicated systems composed of multiple layers of interacting components.
    The isolation and compartmentalization of different layers is very important when
    running critical applications. To secure the system and ensure proper access to
    resources, capabilities, and data, we must first understand the unique challenges
    facing Kubernetes as a general-purpose orchestration platform that runs unknown
    workloads. Then, we can take advantage of various securities, isolation, and access
    control mechanisms to make sure the cluster and the applications running on it,
    and the data are all safe. We will discuss various best practices and when it
    is appropriate to use each mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of this chapter, you will have a good understanding of the Kubernetes
    security challenges. You will gain practical knowledge of how to harden Kubernetes
    against various potential attacks, establishing defense in depth, and will even
    be able to safely run a multitenant cluster while providing different users with
    full isolation as well as full control over their part of the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Kubernetes security challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes is a very flexible system that manages very low-level resources in
    a generic way. Kubernetes itself can be deployed on many operating systems and
    hardware or virtual-machine solutions on-premises or in the cloud. Kubernetes
    runs workloads implemented by runtimes it interacts with through a well-defined
    runtime interface, but without understanding how they are implemented. Kubernetes
    manipulates critical resources, such as networking, DNS, and resource allocation,
    on behalf or in service of applications it knows nothing about. This means that
    Kubernetes is faced with the difficult task of providing good security mechanisms
    and capabilities in a way that application administrators can use, while protecting
    itself and the application administrators from common mistakes.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will discuss security challenges in several layers or components
    of a Kubernetes cluster: nodes, networks, images, pods, and containers. In-dept
    defense is an important security concept that requires systems to protect themselves
    at each level, both to mitigate attacks that penetrated other layers and to limit
    the scope and damage of a breach. Recognizing the challenges in each layer is
    the first step toward defense in depth.'
  prefs: []
  type: TYPE_NORMAL
- en: Node challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The nodes are the hosts of the runtime engines. If an attacker gets access to
    a node, this is a serious threat. It can control at least the host itself and
    all the workloads running on it. But it gets worse. The node has a kubelet running
    that talks to the API server. A sophisticated attacker can replace the kubelet
    with a modified version and effectively evade detection by communicating normally
    with the Kubernetes API server, yet running its own workloads instead of the scheduled
    workloads, collecting information about the overall cluster, and disrupting the
    API server and the rest of the cluster by sending malicious messages. The node
    will have access to shared resources and secrets that may allow it to infiltrate
    even deeper. A node breach is very serious, both because of the possible damage
    and the difficulty of detecting it after the fact.
  prefs: []
  type: TYPE_NORMAL
- en: Nodes can be compromised at the physical level too. This is more relevant on
    bare-metal machines where you can tell which hardware is assigned to the Kubernetes
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Another attack vector is resource drain. Imagine that your nodes become part
    of a bot network which, unrelated to your Kubernetes cluster, just runs its own
    workloads and drains CPU and memory. The danger here is that Kubernetes and your
    infrastructure may scale automatically and allocate more resources.
  prefs: []
  type: TYPE_NORMAL
- en: Another problem is the installation of debugging and troubleshooting tools or
    modifying configuration outside of automated deployment. Those are typically untested
    and, if left behind and active, they can lead to at least degraded performance,
    but can also cause more sinister problems. At the least that increase the attack
    surface.
  prefs: []
  type: TYPE_NORMAL
- en: 'Where security is concerned, it''s a numbers game. You want to understand the
    attack surface of the system and where you''re vulnerable. Let''s list all the
    node challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: Attacker takes control of the host
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attacker replaces the kubelet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attacker takes control over a node that runs master components (API server,
    scheduler, and controller manager)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attacker gets physical access to a node
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attacker drains resources unrelated to the Kubernetes cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Self-inflicted damage through installation of debugging and troubleshooting
    tools or configuration change
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any important Kubernetes cluster spans at least one network. There are many
    challenges related to networking. You need to understand how your system components
    are connected at a very fine level. Which components are supposed to talk to each
    other? What network protocols do they use? What ports? What data do they exchange?
    How is your cluster connected to the outside world?
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a complex chain of exposing ports and capabilities or services:'
  prefs: []
  type: TYPE_NORMAL
- en: Container to host
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Host to host within the internal network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Host to the world
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using overlay networks (which will be discussed more in [Chapter 10](ce60bd21-54ec-4d19-93a5-18803927e9aa.xhtml),
    *Advanced Kubernetes Networking*) can help with defense in depth where, even if
    an attacker gains access to a Docker container, they are sandboxed and can't escape
    to the underlay network infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Discovering components is a big challenge too. There are several options here,
    such as DNS, dedicated discovery services, and load balancers. Each comes with
    a set of pros and cons that take careful planning and insight to get right for
    your situation.
  prefs: []
  type: TYPE_NORMAL
- en: Making sure that two containers can find each other and exchange information
    is important.
  prefs: []
  type: TYPE_NORMAL
- en: You need to decide which resources and endpoints should be publicly accessible.
    Then, you need to come up with a proper way to authenticate users and services
    and authorize them to operate on resources.
  prefs: []
  type: TYPE_NORMAL
- en: Sensitive data must be encrypted on the way in and out of the cluster and sometimes
    at rest, too. This means key management and safe key exchange, which is one of
    the most difficult problems to solve in security.
  prefs: []
  type: TYPE_NORMAL
- en: If your cluster shares networking infrastructure with other Kubernetes clusters
    or non-Kubernetes processes, then you have to be diligent about isolation and
    separation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The ingredients are network policies, firewall rules, and **software-defined
    networking** (**SDN**). The recipe is often customized. This is especially challenging
    with on-premise and bare-metal clusters. Let''s recap:'
  prefs: []
  type: TYPE_NORMAL
- en: Come up with a connectivity plan
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choose components, protocols, and ports
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figure out dynamic discovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Public versus private access
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Authentication and authorization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Design firewall rules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decide on a network policy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Key management and exchange
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is constant tension between making it easy for containers, users, and
    services to find and talk to each other at the network level versus locking down
    access and preventing attacks through the network or attacks on the network itself.
  prefs: []
  type: TYPE_NORMAL
- en: Many of these challenges are not Kubernetes specific. However, the fact that
    Kubernetes is a generic platform that manages key infrastructure and deals with
    low-level networking makes it necessary to think about dynamic and flexible solutions
    that can integrate system-specific requirements into Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Image challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes runs containers that comply with one of its runtime engines. It
    has no idea what these containers are doing (except collecting metrics). You can
    put certain limits on containers via quotas. You can also limit their access to
    other parts of the network via network policies. However, in the end, containers
    do need access to host resources, other hosts in the network, distributed storage,
    and external services. The image determines the behavior of a container. There
    are two categories of problems with images:'
  prefs: []
  type: TYPE_NORMAL
- en: Malicious images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vulnerable images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Malicious images are images that contain code or configuration that was designed
    by an attacker to do some harm or to collect information. Malicious code can be
    injected into your image preparation pipeline, including any image repositories
    you use. Alternatively, you may install third-party images that were attacked
    themselves and that may now contain malicious code.
  prefs: []
  type: TYPE_NORMAL
- en: Vulnerable images are images you designed (or third-party images you install)
    that just happen to contain some vulnerability that allows an attacker to take
    control of the running container or cause some other harm, including injecting
    their own code later.
  prefs: []
  type: TYPE_NORMAL
- en: It's hard to tell which category is worse. At the extreme, they are equivalent
    because they allow for seizing total control of the container. The other defenses
    are in place (remember defense in depth?), and the restrictions put on the container
    will determine how much damage it can do. Minimizing the danger of bad images
    is very challenging. Fast-moving companies using microservices may generate many
    images daily. Verifying an image is not an easy task either. Consider, for example,
    how Docker images are made up of layers. The base images that contain the operating
    system may become vulnerable any time a new vulnerability is discovered. Moreover,
    if you rely on base images prepared by someone else (very common), then malicious
    code may find its way into those base images, which you have no control over and
    you trust implicitly.
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize image challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes doesn't know what images are doing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes must provide access to sensitive resources for the designated function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's difficult to protect the image preparation and delivery pipeline (including
    image repositories)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The speed of development and deployment of new images may conflict with careful
    review of changes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Base images that contain the OS can easily get out of date and become vulnerable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Base images are often not under your control and might be more prone to injection
    of malicious code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrating a static image analyzer such as CoreOS Clair can help a lot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuration and deployment challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes clusters are administered remotely. Various manifests and policies
    determine the state of the cluster at each point in time. If an attacker gets
    access to a machine with administrative control over the cluster, they can wreak
    havoc, such as collecting information, injecting bad images, weakening security,
    and tampering with logs. As usual, bugs and mistakes can be just as harmful, affecting
    important security measures and leaving the cluster open for an attack. It is
    very common these days for employees with administrative access to the cluster
    to work remotely from home or a coffee shop and have their laptops with them,
    where they are one `kubectl` command away from opening the flood gates.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s reiterate the challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes is administered remotely
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An attacker with remote administrative access can gain complete control over
    the cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuration and deployment is typically more difficult to test than code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remote or out-of-office employees risk extended exposure, allowing an attacker
    to gain access to their laptops or phones with administrative access
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pod and container challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In Kubernetes, pods are the unit of work and contain one or more containers.
    The pod is just a grouping and deployment construct, but in practice, containers
    that are deployed together in the same pod usually interact through direct mechanisms.
    The containers all share the same localhost network and often share mounted volumes
    from the host. This easy integration between containers in the same pod can result
    in the exposure of parts of the host to all the containers. This might allow one
    bad container (either malicious or just vulnerable) to open the way for escalated
    attacks on other containers in the pod and later the taking over of the node itself.
    Master add-ons are often collocated with master components and present that kind
    of danger, especially because many of them are experimental. The same goes for
    daemon sets that run pods on every node.
  prefs: []
  type: TYPE_NORMAL
- en: 'Multi-container pod challenges include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The same pod containers share the localhost network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The same pod containers sometimes share a mounted volume on the host filesystem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bad containers might poison other containers in the pod
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bad containers have an easier time attacking the node if collocated with other
    containers that access crucial node resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Experimental add-ons that are collocated with master components might be experimental
    and less secure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Organizational, cultural, and process challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Security is often in contrast with productivity. This is a normal trade-off
    and nothing to worry about. Traditionally, when developers and operations were
    separate, this conflict was managed at an organizational level. Developers pushed
    for more productivity and treated security requirements as the cost of doing business.
    Operations controlled the production environment and were responsible for access
    and security procedures. The DevOps movement brought down the wall between developers
    and operations. Now, speed of development often takes a front row seat. Concepts
    such as continuous deployment-deploying multiple times a day without human intervention-were
    unheard of in most organizations. Kubernetes was designed for this new world of
    cloud-native applications. However, it was developed based on Google's experience.
    Google had a lot of time and skilled experts to develop the proper processes and
    tooling to balance rapid deployments with security. For smaller organizations,
    this balancing act might be very challenging and security could be compromised.
  prefs: []
  type: TYPE_NORMAL
- en: 'The challenges facing organizations that adopt Kubernetes are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Developers that control the operation of Kubernetes might be less security oriented
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The speed of development might be considered more important than security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous deployment might make it difficult to detect certain security problems
    before they reach production
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Smaller organizations might not have the knowledge and expertise to manage security
    properly in Kubernetes clusters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In this section, we reviewed the many challenges you face when you try to build
    a secure Kubernetes cluster. Most of these challenges are not specific to Kubernetes,
    but using Kubernetes means that there is a large part of your system that is generic
    and is unaware of what the system is doing. This can pose problems when trying
    to lock down a system. The challenges are spread across different levels:'
  prefs: []
  type: TYPE_NORMAL
- en: Node challenges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network challenges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image challenges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuration and deployment challenges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pod and container challenges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Organizational and process challenges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we will look at the facilities Kubernetes provides to address
    some of those challenges. Many of the challenges require solutions at the larger
    system level. It is important to realize that just using all of Kubernetes security
    features is not enough.
  prefs: []
  type: TYPE_NORMAL
- en: Hardening Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous section cataloged and listed the variety of security challenges
    facing developers and administrators deploying and maintaining Kubernetes clusters.
    In this section, we will hone in on the design aspects, mechanisms, and features
    offered by Kubernetes to address some of the challenges. You can get to a pretty
    good state of security via judicious use of capabilities, such as service accounts,
    network policies, authentication, authorization, admission control, AppArmor,
    and secrets.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that a Kubernetes cluster is one part of a bigger system that includes
    other software systems, people, and processes. Kubernetes can't solve all problems.
    You should always keep in mind general security principles, such as defense in
    depth, need-to-know basis, and the principle of least privilege. In addition,
    log everything you think may be useful in the event of an attack and set up alerts
    for early detection when the system deviates from its state. It may be just a
    bug or it may be an attack. Either way, you want to know about it and respond.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding service accounts in Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes has regular users managed outside the cluster for humans connecting
    to the cluster (for example, through the `kubectl` command), and it has service
    accounts.
  prefs: []
  type: TYPE_NORMAL
- en: Regular users are global and can access multiple namespaces in the cluster.
    Service accounts are constrained to one namespace. This is important. It ensures
    namespace isolation because whenever the API server receives a request from a
    pod, its credentials will apply only to its own namespace.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes manages service accounts on behalf of the pods. Whenever Kubernetes
    instantiates a pod, it assigns the pod a service account. The service account
    identifies all the pod processes when they interact with the API server. Each
    service account has a set of credentials mounted in a secret volume. Each namespace
    has a default service account named `default`. When you create a pod, it automatically
    assigns the default service account unless you specify a different service account.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can create additional service accounts. Create a file named `custom-service-account.yaml`
    with the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Note that a secret was created automatically for your new service account.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get more detail, type the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see the secret itself, which includes a `ca.crt` file and a token,
    by typing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: How does Kubernetes manage service accounts?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The API server has a dedicated component named the service account admission
    controller. It is responsible for checking, at pod creation time, whether it has
    a custom service account and, if it does, that the custom service account exists.
    If there is no service account specified, then it assigns the default service
    account.
  prefs: []
  type: TYPE_NORMAL
- en: It also ensures that the pod has `ImagePullSecrets`, which are necessary when
    images need to be pulled from a remote image registry. If the pod spec doesn't
    have any secrets, it uses the service account's `ImagePullSecrets`.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, it adds a volume with an API token for API access and a `volumeSource`
    mounted at `/var/run/secrets/kubernetes.io/serviceaccount`.
  prefs: []
  type: TYPE_NORMAL
- en: The API token is created and added to the secret by another component named
    the **Token Controller** whenever a service account is created. The Token Controller
    also monitors secrets and adds or removes tokens wherever secrets are added or
    removed to/from a service account.
  prefs: []
  type: TYPE_NORMAL
- en: The service account controller ensures that the default service account exists
    for every namespace.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing the API server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Accessing the API requires a chain of steps that include authentication, authorization,
    and admission control. At each stage, the request may be rejected. Each stage
    consists of multiple plugins that are chained together. The following diagram
    illustrates this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/d1531a41-3d47-4fc0-8bbe-f435cc592581.png)'
  prefs: []
  type: TYPE_IMG
- en: Authenticating users
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When you first create the cluster, a client certificate and key are created
    for you. `Kubectl` uses them to authenticate itself to the API server and vice
    versa over TLS on port `443` (an encrypted HTTPS connection). You can find your
    client key and certificate by checking your `.kube/config` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Note that if multiple users need to access the cluster, the creator should provide
    the client certificate and key to other users in a secure manner.
  prefs: []
  type: TYPE_NORMAL
- en: This is just establishing basic trust with the Kubernetes API server itself.
    You're not authenticated yet. Various authentication modules may look at the request
    and check for various additional client certificates, passwords, bearer tokens,
    and JWT tokens (for service accounts). Most requests require an authenticated
    user (either a regular user or a service account) although there are some anonymous
    requests too. If a request fails to authenticate with all the authenticators,
    it will be rejected with a 401 HTTP status code (unauthorized, which is a bit
    of a misnomer).
  prefs: []
  type: TYPE_NORMAL
- en: 'The cluster administrator determines what authentication strategies to use
    by providing various command-line arguments to the API server:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--client-ca-file=<filename>` (for x509 client certificates specified in a
    file)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--token-auth-file=<filename>` (for bearer tokens specified in a file)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--basic-auth-file=<filename>` (for user/password pairs specified in a file)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--experimental-bootstrap-token-auth` (for bootstrap tokens used by `kubeadm`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Service accounts use an automatically loaded authentication plugin. The administrator
    may provide two optional flags:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--service-account-key-file=<filename>` (PEM-encoded key for signing bearer
    tokens. If unspecified, the API server''s TLS private key will be used.)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--service-account-lookup` (If enabled, tokens that are deleted from the API
    will be revoked.)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are several other methods, such as open ID connect, web hooks, Keystone
    (the OpenStack identity service), and an authenticating proxy. The main theme
    is that the authentication stage is extensible and can support any authentication
    mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: 'The various authentication plugins will examine the request and, based on the
    provided credentials, will associate the following attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**username** (user-friendly name)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**uid** (unique identifier and more consistent than the username)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**groups** (a set of group names the user belongs to)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**extra fields** (maps string keys to string values)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The authenticator has no knowledge whatsoever of what a particular user is allowed
    to do. They just map a set of credentials to a set of identities. It is the job
    of the authorizers to figure out if the request is valid for the authenticated
    user. Authentication succeeds when any authenticator accepts the credentials.
    The order by which authenticators are run is undefined.
  prefs: []
  type: TYPE_NORMAL
- en: Impersonation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is possible for users to impersonate different users (with proper authorization).
    For example, an admin may want to troubleshoot some issue as a different user
    with less privileges. This requires passing impersonation headers to the API request.
    The headers are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Impersonate-User`: The username to act as.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Impersonate-Group`: This is a group name to act as and can be provided multiple
    times to set multiple groups. This is optional, and it requires `Impersonate-User`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Impersonate-Extra-(extra name)`: This is a dynamic header used to associate
    extra fields with the user. This is optional, and it requires `Impersonate-User`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With `kubectl`, you pass `--as` and `--as-group` parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Authorizing requests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once a user is authenticated, authorization commences. Kubernetes has generic
    authorization semantics. A set of authorization modules receives the request,
    which includes information such as the authenticated username and the request's
    verb (`list`, `get`, `watch`, `create`, and so on). Unlike authentication, all
    authorization plugins will get a shot at any request. If a single authorization
    plugin rejects the request or no plugin had an opinion, then it will be rejected
    with a `403` HTTP status code (forbidden). A request will be continue only if
    at least one plugin accepted and no other plugin rejected it.
  prefs: []
  type: TYPE_NORMAL
- en: The cluster administrator determines what authorization plugins to use by specifying
    the `--authorization-mode` command-line flag, which is a comma-separated list
    of plugin names.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following modes are supported:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--authorization-mode=AlwaysDeny` rejects all requests; it is useful during
    testing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-authorization-mode=AlwaysAllow` allows all requests; use if you don''t need
    authorization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--authorization-mode=ABAC` allows a simple, local file-based, and user-configured
    authorization policy. **ABAC** stands for **Attribute-Based Access Control**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--authorization-mode=RBAC` is a role-based mechanism where authorization policies
    are stored and driven by the Kubernetes API. **RBAC** stands for **Role-Based
    Access Control**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--authorization-mode=Node` is a special mode designed to authorize API requests
    made by kubelets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--authorization-mode=Webhook` allows authorization to be driven by a remote
    service using REST.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can add your own custom authorization plugin by implementing the following
    straightforward Go interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Attributes` input argument is also an interface that provides all the
    information you need to make an authorization decision:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Using admission control plugins
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OK. The request was authenticated and authorized, but there is one more step
    before it can be executed. The request must go through a gauntlet of admission-control
    plugins. Similar to the authorizers, if a single admission controller rejects
    a request, it is denied.
  prefs: []
  type: TYPE_NORMAL
- en: 'Admission controllers are a neat concept. The idea is that there may be global
    cluster concerns that could mean grounds for rejecting a request. Without admission
    controllers, all authorizers would have to be aware of these concerns and reject
    the request. However, with admission controllers, this logic can be performed
    once. In addition, an admission controller may modify the request. Admission controllers
    run in either validating mode or mutating mode. As usual, the cluster administrator
    decides which admission control plugins are run by providing a command-line argument
    named `admission-control`. The value is a comma-separated and ordered list of
    plugins. Here is the list of recommended plugins for Kubernetes >= 1.9 (the order
    matters):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s look at some of the available plugins (more are added all the time):'
  prefs: []
  type: TYPE_NORMAL
- en: '`AlwaysAdmit`: Passthrough (I''m not sure why it''s needed).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AlwaysDeny`: This rejects everything (useful for testing).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AlwaysPullImages`: This sets the new pod image pull policy to Always (useful
    in multi-tenant clusters to ensure that private images are not used by pods that
    don''t have credentials to pull them).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DefaultStorageClass`: This add a default storage class to requests for the
    creation of a `PersistentVolumeClaim` that don''t specify a storage class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DefaultTollerationSeconds`: This sets the default toleration of pods for taints
    (if not set already): `notready:NoExecute` and `notreachable:NoExecute`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DenyEscalatingExec`: This denies exec and attach commands to pods that run
    with escalated privileges and that allow host access. This includes pods that
    run as privileged, have access to the host IPC namespace, and have access to the
    host PID namespace.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`EventRateLimit`: This limits the flooding of the API server with events (new
    in Kubernetes 1.9).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ExtendedResourceToleration`: This combines taints on nodes with special resources
    such as GPU and FPGA with toleration on pods that request those resources. The
    end result is that the node with the extra resources will be dedicated to pods
    with the proper toleration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ImagePolicyWebhook`: This complicated plugin connects to an external backend
    to decide whether a request should be rejected based on the image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Initializers`: This sets the pending initializers by modifying the metadata
    of the resource to be created (based on `InitializerConfiguration`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`InitialResources` (experimental): This assigns compute resources and limits
    based on historical usage, if not specified.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LimitPodHardAntiAffinity`: This denies any pod that defines an anti-affinity
    topology key other than `kubernetes.io`/`hostname` in `requiredDuringSchedulingRequiredDuringExecution`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LimitRanger`: This rejects requests that violate resource limits.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MutatingAdmissionWebhook`: Calls in order, registered mutating web hooks that
    are able to modify their target object. Note that there is no guarantee that the
    change will be effective due to potential changes by other mutating web hooks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`NamespaceLifecycle`: This rejects object creation requests in namespaces that
    are in the process of being terminated or don''t exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ResourceQuota`: This rejects requests that violate the namespace''s resource
    quota.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ServiceAccount`: This is automation for service accounts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ValidatingAdmissionWebhook`: This admission controller calls any validating
    webhooks that match the request. Matching webhooks are called in parallel; if
    any of them rejects the request, the request fails.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, the admission control plugins have diverse functionalities.
    They support namespace-wide policies and enforce the validity of requests mostly
    from a resource management point of view. This frees the authorization plugins
    to focus on valid operations. `ImagePolicyWebHook` is the gateway to validating
    images, which is a big challenge. `Initializers` is the gateway to dynamic admission
    control where you can deploy your own admission controller without compiling it
    into Kubernetes. There are also external admission web hooks, which are suitable
    for tasks such as the semantic validation of resources (do all pods have the standard
    set of labels?).
  prefs: []
  type: TYPE_NORMAL
- en: The division of responsibility for validating an incoming request through the
    separate stages of authentication, authorization, and admission, each with their
    own plugins, makes a complicated process much easier to understand and use.
  prefs: []
  type: TYPE_NORMAL
- en: Securing pods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pod security is a major concern because Kubernetes schedules the pods and lets
    them run. There are several independent mechanisms in order to secure pods and
    containers. Together these mechanisms support defense in depth, where even if
    an attacker (or a mistake) bypasses one mechanism, it will get blocked by another.
  prefs: []
  type: TYPE_NORMAL
- en: Using a private image repository
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This approach gives you a lot of confidence that your cluster will only pull
    images that you have previously vetted, and you can manage upgrades better. You
    can configure `$HOME/.dockercfg` or `$HOME/.docker/config.json` on each node.
    However, on many cloud providers, you can't do it because nodes are provisioned
    automatically for you.
  prefs: []
  type: TYPE_NORMAL
- en: ImagePullSecrets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This approach is recommended for clusters on cloud providers. The idea is that
    the credentials for the registry will be provided by the pod, so it doesn't matter
    what node it is scheduled to run on. This circumvents the problem with `.dockercfg`
    at the node level.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you need to create a `secret` object for the credentials:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: You can create secrets for multiple registries (or multiple users for the same
    registry) if needed. The kubelet will combine all `ImagePullSecrets`.
  prefs: []
  type: TYPE_NORMAL
- en: However, because pods can access secrets only in their own namespace, you must
    create a secret within each namespace where you want the pod to run.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the secret is defined, you can add it to the pod spec and run some pods
    on your cluster. The pod will use the credentials from the secret to pull images
    from the target image registry:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Specifying a security context
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A security context is a set of operating-system-level security settings, such
    as UID, gid, capabilities, and SELinux roles. These settings are applied at the
    container level as container security content. You can specify pod security context
    that will apply to all the containers in the pod. The pod security context can
    also apply its security settings (in particular, `fsGroup` and `seLinuxOptions`)
    to volumes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a sample pod security context:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The container security context is applied to each container, and it overrides
    the pod security context. It is embedded in the containers section of the pod
    manifest. Container context settings can't be applied to volumes, which remain
    at the pod level.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a sample container security content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Protecting your cluster with AppArmor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`AppArmor` is a Linux kernel security module. With `AppArmor`, you can restrict
    a process running in a container to a limited set of resources, such as network
    access, Linux capabilities, and file permissions. You configure `AppArmor` though
    profiles.'
  prefs: []
  type: TYPE_NORMAL
- en: Requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'AppArmor support was added as beta in Kubernetes 1.4\. It is not available
    for every operating system, so you must choose a supported OS distribution in
    order to take advantage of it. Ubuntu and SUSE Linux support AppArmor and enable
    it by default. Other distributions have optional support. To check whether AppArmor
    is enabled, type the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: If the result is `Y`, then it's enabled.
  prefs: []
  type: TYPE_NORMAL
- en: 'The profile must be loaded into the kernel. Check the following file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Also, only the Docker runtime supports `AppArmor` at this time.
  prefs: []
  type: TYPE_NORMAL
- en: Securing a pod with AppArmor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As `AppArmor` is still in beta, you specify the metadata as annotations and
    not as `bonafide` fields; when it gets out of beta that will change.
  prefs: []
  type: TYPE_NORMAL
- en: 'To apply a profile to a container, add the following annotation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The pofile reference can be either the default profile, `runtime`/`default`,
    or a profile file on the host `localhost/<profile-name>`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a sample profile that prevents writing to files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: AppArmor is not a Kubernetes resource, so the format is not the YAML or JSON
    you're familiar with.
  prefs: []
  type: TYPE_NORMAL
- en: 'To verify that the profile was attached correctly, check the attributes of
    process `1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Pods can be scheduled on any node in the cluster by default. This means the
    profile should be loaded into every node. This is a classic use case for DaemonSet.
  prefs: []
  type: TYPE_NORMAL
- en: Writing AppArmor profiles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Writing profiles for `AppArmor` by hand is important. There are some tools
    that can help: `aa-genprof` and `aa-logprof` can generate a profile for you and
    help with fine tuning it by running your application with `AppArmor` in complain
    mode. The tools keep track of your application''s activity and `AppArmor` warnings
    and create a corresponding profile. This approach works, but it feels clunky.'
  prefs: []
  type: TYPE_NORMAL
- en: 'My favorite tool is bane ([https://github.com/jessfraz/bane](https://github.com/jessfraz/bane)),
    which generates `AppArmor` profiles from a simpler profile language based on TOML
    syntax. Bane profiles are very readable and easy to grasp. Here is a snippet from
    a bane profile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The generated `AppArmor` profile is pretty gnarly.
  prefs: []
  type: TYPE_NORMAL
- en: Pod security policies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Pod Security Policy** (**PSP**) is available as Beta since Kubernetes 1.4\.
    It must be enabled, and you must also enable the PSP admission control to use
    them. A PSP is defined at the cluster level and defines the security context for
    pods. There are a couple of differences between using PSP and directly specifying
    a security content in the pod manifest as we did earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: Applies the same policy to multiple pods or containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lets the administrator control pod creation, so users don't create pods with
    inappropriate security contexts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dynamically generates different security content for a pod via the admission
    controller
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PSPs really scale the concept of security contexts. Typically, you'll have a
    relatively small number of security policies compared with the number of pods
    (or rather, pod templates). This means that many pod templates and containers
    will have the same security policy. Without PSP, you have to manage it individually
    for each pod manifest.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a sample PSP that allows everything:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Authorizing pod security policies through RBAC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is the recommended way to enable the use of policies. Let''s create `clusterRole`
    (`Role` works too) to grant access to use the target policies. It should look
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we need to bind the cluster role to the authorized users:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'If using a role binding instead of cluster role, then it will apply only to
    pods in the same namespace as the binding. This can be paired with system groups
    to grant access to all pods run in the namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Managing network policies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Node, pod, and container security is imperative, but it's not enough. Network
    segmentation is critical to design secure Kubernetes clusters that allows multi-tenancy
    as well as to minimize the impact of security breaches. Defense in depth mandates
    that you compartmentalize parts of the system that don't need to talk to each
    other, and allows you to carefully manage the direction, protocols, and ports
    of traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Network policies give you fine-grained control and proper network segmentation
    in terms of your cluster. At its core, a network policy is a set of firewall rules
    applied to a set of namespaces and pods selected by labels. This is very flexible
    because labels can define virtual network segments and can be managed as Kubernetes
    resources.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a supported networking solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Some networking backends don't support network policies. For example, the popular
    Flannel can't be applied to policies.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a list of supported network backends:'
  prefs: []
  type: TYPE_NORMAL
- en: Calico
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: WeaveNet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Canal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cillium
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kube-Router
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Romana
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining a network policy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You define a network policy using a standard YAML manifest.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a sample policy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The `spec` part has two important parts—the `podSelector` and the `ingress`.
    The `podSelector` governs which pods this network policy applies to. The ingress
    governs which namespaces and pods can access these pods and which protocols and
    ports they can use.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the sample network policy, the `pod` selector specified the target for the
    network policy to be all the pods that are labeled `role: db`. The `ingress` section
    has a `from` subsection with a `namespace` selector and a `pod` selector. All
    the namespaces in the cluster that are labeled `project: cool-project`, and within
    these namespaces, all the pods that are labeled `role: frontend`, can access the
    target pods labeled `role: db`. The `ports` section defines a list of pairs (protocol
    and port) that further restrict what protocols and ports are allowed. In this
    case, the protocol is `tcp` and the port is `6379` (Redis standard port).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the network policy is cluster-wide, so pods from multiple namespaces
    in the cluster can access the target namespace. The current namespace is always
    included, so even if it doesn''t have the `project: cool label`, `pods` with `role:
    frontend` can still have access.'
  prefs: []
  type: TYPE_NORMAL
- en: It's important to realize that the network policy operates in a whitelist fashion.
    By default, all access is forbidden, and the network policy can open certain protocols
    and ports to certain pods that match the labels. This means that if your networking
    solution doesn't support network policies, all access will be denied.
  prefs: []
  type: TYPE_NORMAL
- en: Another implication of the whitelist nature is that if multiple network policies
    exist, the union of all the rules apply. If one policy gives access to port `1234`
    and another gives access to port `5678` for the same set of pods, then a pod may
    access either port `1234` or `5678`.
  prefs: []
  type: TYPE_NORMAL
- en: Limiting Egress to external networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes 1.8 added egress network policy support, so you can control outbound
    traffic too. Here is an example that prevents access to the external IP `1.2.3.4`.
    The `order: 999` ensures that the policy is applied before other policies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Cross-namespace policies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you divide your cluster into multiple namespaces, it can come in handy sometimes
    if pods communicate across namespaces. You can specify the `ingress.namespaceSelector`
    field in your network policy to enable access from multiple namespaces. For example,
    if you have production and staging namespaces and you periodically populate your
    staging environments with snapshots of your production data.
  prefs: []
  type: TYPE_NORMAL
- en: Using secrets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Secrets are paramount in secure systems. They can be credentials, such as a username
    and password, access tokens, API keys, or crypto keys. Secrets are typically small.
    If you have large amounts of data you want to protect, you should encrypt that
    and keep the encryption/decryption key as secrets.
  prefs: []
  type: TYPE_NORMAL
- en: Storing secrets in Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes used to store secrets in `etcd` as plaintext by default. This meant
    that direct access to `etcd` was limited and carefully guarded. As of Kubernetes
    1.7, you can now encrypt your secrets at rest (when they're stored by `etcd`).
  prefs: []
  type: TYPE_NORMAL
- en: Secrets are managed at the namespace level. Pods can mount secrets either as
    files via secret volumes or as environment variables. From a security standpoint,
    this means that any user or service that can create a pod in a namespace can have
    access to any secret managed for that namespace. If you want to limit access to
    a secret, put it in a namespace accessible to a limited set of users or services.
  prefs: []
  type: TYPE_NORMAL
- en: When a secret is mounted to a pod, it is never written to disk. It is stored
    in `tmpfs`. When the kubelet communicates with the API server it uses TLS normally,
    so the secret is protected in transit.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring encryption at Rest
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You need to pass this argument when you start the API server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a sample encryption config:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Creating secrets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Secrets must be created before you try to create a pod that requires them. The
    secret must exist; otherwise, the pod creation will fail.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can create secrets with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, I create a generic secret named `hush-hash`, which contains two keys—username
    and password:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting secret is `Opaque`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: You can create secrets from files using `--from-file` instead of `--from-literal`,
    and you can also create secrets manually if you encode the secret value as `base64`.
  prefs: []
  type: TYPE_NORMAL
- en: Key names inside a secret must follow the rules for DNS subdomains (without
    the leading dot).
  prefs: []
  type: TYPE_NORMAL
- en: Decoding secrets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To get the content of a secret, you can use `kubectl get secret`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The values are `base64`-encoded. You need to decode them yourself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Using secrets in a container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Containers can access secrets as files by mounting volumes from the pod. Another
    approach is to access the secrets as environment variables. Finally, a container
    (given its service account has the permission) can access the Kubernetes API directly
    or use the kubectl get secret.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use a secret mounted as a volume, the pod manifest should declare the volume,
    and it should be mounted in the container''s spec:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The volume name (`secret-volume`) binds the pod volume to the mount in the container.
    Multiple containers can mount the same volume.
  prefs: []
  type: TYPE_NORMAL
- en: 'When this pod is running, the username and password are available as files
    under `/etc/secret-volume`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Running a multiuser cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will look briefly at the option to use a single cluster
    to host systems for multiple users or multiple user communities. The idea is that
    those users are totally isolated and may not even be aware that they share the
    cluster with other users. Each user community will have its own resources, and
    there will be no communication between them (except maybe through public endpoints).
    The Kubernetes namespace concept is the ultimate expression of this idea.
  prefs: []
  type: TYPE_NORMAL
- en: The case for a multiuser cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Why should you run a single cluster for multiple isolated users or deployments?
    Isn''t it simpler to just have a dedicated cluster for each user? There are two
    main reasons: cost and operational complexity. If you have many relatively small
    deployments and you want to create a dedicated cluster for each one, then you''ll
    have a separate the master node and possibly a three-node `etcd` cluster for each
    one. That can add up. Operational complexity is very important too. Managing tens
    or hundreds or thousands of independent clusters is no picnic. Every upgrade and
    every patch needs to be applied to each cluster. Operations might fail, and you''ll
    have to manage a fleet of clusters where some of them are in slightly different
    states than the others. Meta-operations across all clusters may be more difficult.
    You''ll have to aggregate and write your tools to perform operations and collect
    data from all clusters.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at some use cases and requirements for multiple isolated communities
    or deployments:'
  prefs: []
  type: TYPE_NORMAL
- en: A platform or service provider for `<Blank>-` as a service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing separate testing, staging, and production environments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Delegating responsibility to community/deployment admins
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enforcing resource quotas and limits on each community
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Users see only resources in their community
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using namespaces for safe multitenancy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes namespaces are the perfect answer to safe multi-tenant clusters.
    This is not a surprise as this was one of the design goals of namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can easily create namespaces in addition to the built-in kube system and
    default. Here is a YAML file that will create a new namespace named `custom-namespace`.
    All it has is a metadata item named `name`. It doesn''t get any simpler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s create the namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The status field can be `active` or `terminating`. When you delete a namespace,
    it will get into the terminating state. When the namespace is in this state, you
    will not be able to create new resources in this namespace. This simplifies the
    cleanup of namespace resources and ensures that the namespace is really deleted.
    Without it, the replication controller might create new pods when existing pods
    are deleted.
  prefs: []
  type: TYPE_NORMAL
- en: 'To work with a namespace, you add the `--namespace` argument to the `kubectl`
    commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing pods in the custom namespace returns only the pod we just created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing pods without the namespace returns the pods in the default namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Avoiding namespace pitfalls
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Namespaces are great, but they can add some friction. When you use just the
    default namespace, you can simply omit the namespace. When using multiple namespaces,
    you must qualify everything with the namespace. This can be a burden, but doesn't
    present any danger. However, if some users (for example, cluster administrators)
    can access multiple namespaces, then you're open to accidentally modifying or
    querying the wrong namespace. The best way to avoid this situation is to hermetically
    seal the namespace and require different users and credentials for each namespace.
  prefs: []
  type: TYPE_NORMAL
- en: Also, tools can help make clear what namespace you're operating on (for example,
    the shell prompt if working from the command line or listing the namespace prominently
    in a web interface).
  prefs: []
  type: TYPE_NORMAL
- en: Make sure that users that can operate on a dedicated namespace don't have access
    to the default namespace. Otherwise, every time they forget to specify a namespace,
    they'll operate quietly on the default namespace.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered the many security challenges facing developers and
    administrators building systems and deploying applications on Kubernetes clusters.
    But we also explored the many security features and the flexible plugin-based
    security model that provide many ways to limit, control, and manage containers,
    pods, and nodes. Kubernetes already provides versatile solutions to most security
    challenges, and it will only get better as capabilities such as AppArmor and various
    plugins move from alpha/beta status to general availability. Finally, we considered
    how to use namespaces to support multiple user communities or deployments in the
    same Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look into many Kubernetes resources and concepts
    and how to use them and combine them effectively. The Kubernetes object model
    is built on top of a solid foundation of a small number of generic concepts such
    as resources, manifests, and metadata. This empowers an extensible, yet surprisingly
    consistent, object model to expose a very diverse set of capabilities for developers
    and administrators.
  prefs: []
  type: TYPE_NORMAL
