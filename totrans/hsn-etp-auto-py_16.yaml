- en: Automating AWS with Boto3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In previous chapters, we explored how to automate the OpenStack and VMware private
    clouds using Python. We will continue on our cloud automation journey by automating
    one of the most popular public clouds: **Amazon Web Services** (**AWS**). In this
    chapter, we will explore how to create Amazon **Elastic Compute Cloud** (**EC2**)
    and Amazon **Simple Storage Systems** (**S3**) using Python script.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: AWS Python modules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing AWS instances
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automating AWS S3 services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS Python modules
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon EC2 is a scalable computing system that is used to provide virtualization
    layers for hosting different virtual machines (such as the nova-compute project
    in the OpenStack ecosystem). It can communicate with other services, such as S3,
    Route 53, and AMI, in order to instantiate instances. Basically, you can think
    of EC2 as an abstraction layer above other hypervisors that are set over the virtual
    infrastructure manager (such as KVM and VMware). EC2 will receive the incoming
    API calls then will translate them into suitable calls for each hypervisor.
  prefs: []
  type: TYPE_NORMAL
- en: The **Amazon Machine Image **(**AMI**) is a packaged image system that contains
    the operating system and packages needed to start a virtual machine (like Glance
    in OpenStack). You can create your own AMI from existing virtual machines and
    use it when you need to replicate those machines on other infrastructures, or
    you can simply choose from publicly available AMIs on the internet or on the Amazon
    Marketplace. We will need to get the AMI ID from the Amazon web console and add
    it to our Python script.
  prefs: []
  type: TYPE_NORMAL
- en: AWS designed an SDK called **Boto3** ([https://github.com/boto/boto3](https://github.com/boto/boto3))
    that allows Python developers to have scripts and software that interact and consume
    the APIs of different services, like Amazon EC2 and Amazon S3\. The library was
    written to provide native support for Python 2.6.5, 2.7+, and 3.3.
  prefs: []
  type: TYPE_NORMAL
- en: 'The major Boto3 features are described in the official documentation at [https://boto3.readthedocs.io/en/latest/guide/new.html](https://boto3.readthedocs.io/en/latest/guide/new.html),
    and below are some important features:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Resources**: A high-level, object-oriented interface.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Collections**: A tool to iterate and manipulate groups of resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clients**: A low-level service connection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Paginators**: Automatic paging of responses.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Waiters**: A way to suspend execution until a certain state has been reached
    or a failure occurs. Each AWS resource has a waiter name that could be accessed
    using `<resource_name>.waiter_names`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boto3 installation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A few things are needed before connecting to AWS:'
  prefs: []
  type: TYPE_NORMAL
- en: First, you will need an Amazon admin account that has privileges to create,
    modify, and delete from the infrastructure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Secondly, install the `boto3` Python modules that are used to interact with
    AWS. You can create a user dedicated to sending API requests by going to the AWS
    **Identity and Access Management** (**IAM**) console and adding a new user. You
    should see the Programmatic access option, available under the Access Type section.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, you will need to assign a policy that allows full access across the Amazon
    services, such as EC2 and S3\. Do that by clicking on Attach existing policy to
    user and attaching AmazonEC2FullAccess and AmazonS3FullAccess policies to the
    username.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At the end, click on Create user to add the user with the configured options
    and policies.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can sign up for a free tier account on AWS, which will give you access to
    many services offered by Amazon for up to 12 months. Free access can be acquired
    at [https://aws.amazon.com/free/](https://aws.amazon.com/free/).
  prefs: []
  type: TYPE_NORMAL
- en: When using Python script to manage AWS, the access key ID is used to send API
    requests and get the responses back from the API server. We won't use the username
    or the password for sending requests, as they're easily captured by others. This
    information is obtained by downloading the text file that appears after creating
    the username. It's important to keep this file in a safe place and provide a proper
    Linux permission for it, for opening and reading file content.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another method is to create a `.aws` directory under your home user directory
    and place two files under it: `credentials` and `config`. The first file will
    have both the access key ID and the secret access ID.'
  prefs: []
  type: TYPE_NORMAL
- en: '`~/.aws/credentials` appears as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The second file will hold user-specific configurations, such as the preferred
    data center (zone) that will host the created virtual machines. (This is like
    the availability zone option in OpenStack.) In the following example, we are specifying
    that we want to host our machines in the `us-west-2` data center.
  prefs: []
  type: TYPE_NORMAL
- en: 'The config file, `~/.aws/config`, looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, installing `boto3` requires using the usual `pip` command to get the latest
    `boto3` version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../images/00203.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'To verify that the module has successfully installed, import `boto3` in the
    Python console, and you shouldn''t see any import errors reported:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00204.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Managing AWS instances
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, we''re ready to create our first virtual machine using `boto3`. As we
    have discussed, we need the AMI that we will instantiate an instance from. Think
    of an AMI as a Python class; creating an instance will create an object from it.
    We will use the Amazon Linux AMI, which is a special Linux operating system maintained
    by Amazon and used for deploying Linux machines without any extra charges. You
    can find a full AMI ID, per region, at [https://aws.amazon.com/amazon-linux-ami/](https://aws.amazon.com/amazon-linux-ami/):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00205.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, the following applies:'
  prefs: []
  type: TYPE_NORMAL
- en: We imported the `boto3` module that we installed previously.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, we specified a resource type that we wanted to interact with, which is
    EC2, and assigned that to the `ec2` object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, we are eligible to use the `create_instance()` method and provide it with
    instance parameters, such as `ImageID` and `InstanceType` (like flavor in OpenStack,
    which determines the instance specs in terms of computing and memory), and where
    we should create this instance in the `AvailabilityZone`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`MinCount` and `MaxCount` determine how far EC2 can go when scaling our instances.
    For example, when a high CPU has occurred on one of the instances, EC2 will deploy
    another instance automatically, to share the loads and keep the service in a healthy
    state.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we printed the instance ID to be used in the next script.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00206.jpeg)You can check all valid Amazon EC2 instance types
    at the following link; please read them carefully, in order to not be overcharged
    from choosing the wrong type: [https://aws.amazon.com/ec2/instance-types/](https://aws.amazon.com/ec2/instance-types/)'
  prefs: []
  type: TYPE_IMG
- en: Instance termination
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The printed ID is used in CRUD operations to manage or terminate the instance
    later. For example, we can terminate the instance by using the `terminate()` method
    also provided to the `ec2` resource created earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we hardcoded  `instance_id` in the preceding code (which is not
    always the case when you need to create a dynamic Python script that can be used
    in different environments). We can use other input methods that are available
    in Python, such as `raw_input()`, to take the input from the user or query the
    available instances in our accounts and make Python prompt us on which instances
    need to be terminated. Another use case is to create a Python script that checks
    the last login time or the resource consumption in our instance; if they exceed
    a specific value, we will terminate the instance. This is useful in a lab environment,
    where you don't want to be charged for consuming additional resources with a malicious
    or a poorly designed software.
  prefs: []
  type: TYPE_NORMAL
- en: Automating AWS S3 services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The AWS **Simple Storage Systems** (**S3**) provides a safe and highly scalable
    object storage service. You can use this service to store  any amount of data
    and restore it from anywhere. The system provides you with a versioning option,
    so you can roll back to any previous version of the files. Additionally, it provides
    the REST web services API, so you can access it from external applications.
  prefs: []
  type: TYPE_NORMAL
- en: When data comes to S3, S3 will create an `object` for it, and these objects
    will be stored inside `Buckets` (think of them like folders). You can provide
    a sophisticated user permission for each created bucket, and can also control
    its visibility (public, shared, or private). The bucket access can be either a
    policy or an **Access Control List** (**ACL**).
  prefs: []
  type: TYPE_NORMAL
- en: The bucket is also stored with metadata that describes the object in key-value
    pairs, which you can create and set by HTTP `POST` methods. Metadata can include
    the object's name, size, and date, or any other customized key-values that you
    want. The user account has a limit of 100 buckets, but there's no limit on the
    size of the object hosted inside each bucket.
  prefs: []
  type: TYPE_NORMAL
- en: Creating buckets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first logical thing to do, when interacting with an AWS S3 service, is
    create a bucket that can be used to store files. In that case, we will provide
    the `S3` to the `boto3.resource()` . That will tell the `boto3` to start the initialization
    process and will load required commands to interact with the S3 API system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, the following applies:'
  prefs: []
  type: TYPE_NORMAL
- en: We imported the `boto3` module that we installed previously.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, we specified a resource type that we wanted to interact with, which is
    `s3`, and assigned that to the `s3_resource` object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, we can use the `create_bucket()` method inside the resource and provide
    it with the required parameter to create buckets, such as `Bucket`, where we can
    specify its name. Remember, the bucket name must be unique and cannot have been
    used previously. The second parameter is the `CreateBucketConfiguration` dictionary,
    where we set the data center location for the created bucket.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Uploading a file to a bucket
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, we need to make use of the created bucket and upload a file to it. Remember,
    the file representation inside the bucket is an object. So, `boto3` provides some
    methods that contain the object as a part of it. We will start by using `put_object()`.
    This method will upload a file to the created bucket and store it as an object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, the following applies:'
  prefs: []
  type: TYPE_NORMAL
- en: We imported the `boto3` module that we installed previously.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, we specified a resource type that we wanted to interact with, which is
    `s3`, and assigned that to the `s3_resource` object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We accessed `my_first_bucket` through the `Bucket()` method and assigned the
    returned value to the bucket variable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, we opened a file using the `with` clause and named it `uploaded_data`.
    Notice that we opened the file as a binary data, using the `rb` flag.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we uploaded the binary data to our bucket using the `put_object()`
    method provided within the bucket space.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deleting a bucket
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To complete the CRUD operation for the bucket, the last thing we need to do
    is remove the bucket. This happens through calling the `delete()` method on our
    bucket variable, given that it already exists and we are referencing it by name,
    in the same manner that we created it and uploaded data to it. However,  `delete()`
    may fail when the bucket is not empty. So, we will use the `bucket_objects.all().delete()`
    method to get all of the objects inside the bucket, then apply the `delete()`
    operation on them, and finally, delete the bucket:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to install the Amazon **Elastic Compute Cloud**
    (**EC2**), and we learned about Boto3 and its installation. We also learned how
    to automate AWS S3 services.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about the SCAPY framework, which is a powerful
    Python tool used to build and craft packets and send them on the wire.
  prefs: []
  type: TYPE_NORMAL
