- en: Graph Analytics with GraphX
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our interconnected world, graphs are omnipresent. The **World Wide Web**
    (**WWW**) is just one example of a complex structure that we can consider a graph,
    in which web pages represent entities that are connected by incoming and outgoing
    links between them. In Facebook’s social graph, many millions of users form a
    network, connecting friends around the globe. Many other important structures
    that we see and can collect data for today come equipped with a natural graph
    structure; that is, they can, at a very basic level, be understood as a collection
    of *vertices* that are connected to each other in a certain way by what we call *edges*.
    Stated in this generality, this observation reflects how ubiquitous graphs are.
    What makes it valuable is that the graphs are well-studied structures and that
    there are many algorithms available that allow us to gain important insights about
    what these graphs represent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Spark’s GraphX library is a natural entry point to study graphs at scale. Leveraging
    RDDs from the Spark core to encode vertices and edges, we can do graph analytics
    on vast amounts of data with GraphX. To give an overview, you will learn about
    the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Basic graph properties and important graph operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How GraphX represents property graphs and how to work with them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading graph data in various ways and generating synthetic graph data to experiment
    with
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Essential graph properties by using GraphX’s core engine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing graphs with an open source tool called Gephi
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing efficient graph-parallel algorithms using two of GraphX’s key APIs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using GraphFrames, an extension of DataFrames to graphs, and studying graphs
    using an elegant query language
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running important graph algorithms available in GraphX on a social graph, consisting
    of retweets and a graph of actors appearing in movies together
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basic graph theory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before diving into Spark GraphX and its applications, we will first define graphs
    on a basic level and explain what properties they may come with and what structures
    are worth studying in our context. Along the way of introducing these properties,
    we will give more concrete examples of graphs that we consider in everyday life.
  prefs: []
  type: TYPE_NORMAL
- en: Graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To formalize the notion of a graph briefly sketched in the introduction, on
    a purely mathematical level, a graph *G = (V, E)* can be described as a pair of
    *vertices* V and *edges* E, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*V = {v[1], ..., v[n]}*'
  prefs: []
  type: TYPE_NORMAL
- en: '*E = {e[1], ..., e[m]}*'
  prefs: []
  type: TYPE_NORMAL
- en: 'We call the element *v[i]* in V a vertex and *e[i]* in E an edge, where each
    edge connecting two vertices *v[1] *and *v[2]* is, in fact, just a pair of vertices,
    that is, *e[i] = (v[1], v[2])*. Let''s construct a simple graph consisting of
    five vertices and six edges, as specified by the following graph data:'
  prefs: []
  type: TYPE_NORMAL
- en: '*V ={v[1], v[2], v[3], v[4], v[5]}*'
  prefs: []
  type: TYPE_NORMAL
- en: '*E = {e[1] = (v[1], v[2]), e[2] = (v[1], v[3]), e[3] = (v[2], v[3]),*'
  prefs: []
  type: TYPE_NORMAL
- en: '*       e[4] = (v[3], v[4]), e[5] = (v[4], v[1]), e[6] = (v[4], v[5])}*'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what the graph will look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00152.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: A simple undirected graph with five vertices and six edges'
  prefs: []
  type: TYPE_NORMAL
- en: Note that in the realization of the graph in *Figure 1*, the relative position
    of nodes to each other, the length of the edges, and other visual properties are
    inessential to the graph. In fact, we could have displayed the graph in any other
    way by means of deforming it. The graph definition entirely determines its *topology*.
  prefs: []
  type: TYPE_NORMAL
- en: Directed and undirected graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a pair of vertices that make up an edge *e*, by convention, we call the first
    vertex the *source* and the second one the *target*. The natural interpretation
    here is that the connection represented by edge *e* has a *direction;* it flows
    from the source to the target. Note that in *Figure 1*, the graph displayed is
    undirected; that is, we did not distinguish between the source and target.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the exact same definition, we can create a directed version of our graph,
    as shown in the following image. Note that the graph looks slightly different
    in the way it is presented, but the connections of vertices and edges remain unchanged:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00153.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: A directed graph with the same topology as the previous one. In fact,
    forgetting edge directions would yield the same graph as in Figure 1'
  prefs: []
  type: TYPE_NORMAL
- en: Each directed graph naturally has an associated undirected graph, realized by
    simply forgetting all the edge directions. From a practical perspective, most
    implementations of graphs inherently build on directed edges and suppress the
    additional information of direction whenever needed. To give an example, think
    of the preceding graph as a group of five people connected by the relationship,
    *friendship*. We may argue that friendship is a symmetric property in that if
    you are a friend of mine, I am also a friend of yours. With this interpretation,
    directionality is not a very useful concept in this example, so we are, in fact,
    better off to treat this as an undirected graph example. In contrast, if we were
    to run a social network that allows users to actively send friend requests to
    other users, a directed graph might be better to encode this information.
  prefs: []
  type: TYPE_NORMAL
- en: Order and degree
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For any graph, directed or not, we can read off some basic properties that are
    of interest later in the chapter. We call the number of vertices |V| the *order*
    of the graph and the number of edges |E| its *degree*, sometimes also referred
    to as its *valency*. The degree of a vertex is the number of edges that have this
    vertex as either source or target. In the case of directed graphs and a given
    vertex *v*, we can additionally distinguish between *in-degree**,* that is, the
    sum of all the edges pointing towards *v*, and *out-degree*, that is, the sum
    of all the edges starting at *v*. To give an example of this, the undirected graph
    in *Figure 1* has order 5 and degree 6, same as the directed graph shown in *Figure
    2*. In the latter, vertex v1 has out-degree 2 and in-degree 1, while v5 has out-degree
    0 and in-degree 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the last two examples, we annotated the vertices and edges with their respective
    identifiers, as specified by the definition *G = (V, E)*. For most graph visualizations
    that follow, we will assume that the identity of vertices and edges is implicitly
    known and will instead represent them by labeling our graphs with additional information.
    The reason we make this explicit distinction between identifiers and labels is
    that GraphX identifiers can’t be strings, as we will see in the next section.
    An example of a labeled graph with relationships of a group of people is shown
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00154.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: A directed labelled graph showing a group of people and their relationships'
  prefs: []
  type: TYPE_NORMAL
- en: Directed acyclic graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The next notion we want to discuss is that of acyclicity. A *cyclic graph* is
    one in which there is at least one vertex for which there is a path through the
    graph, connecting this vertex to itself. We call such a path a *cycle*. In an
    undirected graph, any chain creating a cycle will do, while in a directed graph,
    we only speak of cycles if we can reach the starting vertex by means of following
    the directed edges. For example, consider some of the graphs we have seen before.
    In *Figure 2*, there is precisely one cycle formed by *{e2, e4, e5}*, while in
    its undirected version, shown in *Figure 1*, there are precisely two cycles, namely
    *{e2, e4, e5}* and *{e1, e2, e3}*.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few special cases of cyclic graphs that are worth mentioning here.
    Firstly, if a vertex is connected to itself by a single edge, we will say the
    graph has a *loop*. Secondly, a directed graph that does not contain any two-loops,
    that is, without pairs of vertices joined by edges in both directions, is called
    an *oriented* *graph*. Thirdly, a graph with three-loops is said to contain *triangles*.
    The notion of triangles is an important one, as it is often used to assess the
    connectivity of a graph, which we will discuss later on. The following diagram
    shows an artificial example with different types of loops:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00155.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: A toy graph illustrating loops or self-edges, two-loops and triangles.'
  prefs: []
  type: TYPE_NORMAL
- en: In general, studying n-loops in a graph for any natural number *n* can tell
    you a lot about a graph, but triangles are the most common. As directed cycles
    are not only more expensive to compute but also rarer than their undirected versions,
    we will often look for undirected triangles only in a graph; that is, we'll forget
    its directed structure.
  prefs: []
  type: TYPE_NORMAL
- en: An important class of graphs found repeatedly in many applications is that of **Directed
    Acyclic Graphs** (**DAGs**). We already know what a DAG is from the last paragraph,
    namely a directed graph without cycles, but since DAGs are so ubiquitous, we should
    spend a little more time on them.
  prefs: []
  type: TYPE_NORMAL
- en: 'One instance of a DAG that we have implicitly used throughout all the chapters
    leading up to this one is Spark’s job execution graph. Remember that any Spark
    job consists of stages executed in a certain order. Stages consist of tasks executed
    on each partition, some of which may be independent, while others depend on each
    other. We can thus interpret the execution of a Spark job as a directed graph
    consisting of stages (or tasks) as vertices, in which an edge represents the output
    of one computation being required for the next. The prototypical example might
    be that of a reduce stage that needs the output of a preceding map stage. Naturally,
    this execution graph does not contain any cycles, as this would mean we are to
    feed the output of some operators into the graph ad infinitum, preventing our
    program to eventually halt. Thus, this execution graph can be represented, and
    is in fact implemented in the Spark scheduler, as DAG:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00156.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Visualizing a chain of operations carried out on RDDs with Spark.
    The execution graph is by definition a DAG.'
  prefs: []
  type: TYPE_NORMAL
- en: Connected components
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another important property of graphs is that of *connectivity*. A graph is said
    to be *connected* if there is a path of edges connecting any two vertices we choose,
    regardless of the edge directions. So, for directed graphs, we completely neglect
    the directions for this definition. What can be a stricter definition of connectivity
    used for directed graphs? A graph is said to be *strongly connected* if any two
    vertices are connected by a directed chain of edges. Note that strong connectivity
    is a very strong assumption to impose on a directed graph. In particular, any
    strongly connected graph is cyclic. These definitions allow us to define the closely
    related concept of (strongly) connected components. Every graph can be decomposed
    into connected components. If it is connected, there is precisely one such component.
    If it is not, there are at least two. Formally defined, a connected component
    is the largest subgraph of a given graph that is still connected. The same rationale
    holds for strongly connected components. Connectivity is an important measure,
    as it allows us to cluster the vertices of a graph into groups that naturally
    belong together.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, one might be interested in the number of connected components
    in a social graph indicating friendship. In a small graph, there may be many separate
    components. However, the larger the graph, one might suspect that it is more likely
    to have just a single connected component, following the commonly accepted rationale
    that everyone is connected to each other by around six connections.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will see how to compute connected components with GraphX in the next section;
    for now, let''s just inspect one simple example. In the following diagram*,* we
    see a directed graph with twelve vertices:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00157.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Connected and strongly connected components can easily be read off
    in small graphs, but this becomes increasingly difficult for larger graphs.'
  prefs: []
  type: TYPE_NORMAL
- en: We can immediately see that it has three connected components, namely the three
    sets of vertices *{1, 2, 3}, {4, 5}*, and *{6, 7, 8, 9, 10, 11, 12}*. As for strongly
    connected components, that requires a little more effort than a quick visual inspection.
    We can see that *{4, 5}* forms a strongly connected component, and so does *{8,
    9, 10, 11}*. All the other six vertices form their own strongly connected components,
    that is, they are isolated. This example goes on to show that for a massive graph
    with millions of vertices, with the right visualization tool, we may be lucky
    to find roughly connected components, but strongly connected components are a
    little more complicated to compute, and this is just one use case where Spark
    GraphX comes in handy.
  prefs: []
  type: TYPE_NORMAL
- en: Trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the definition of connected components in our hands, we can turn to another
    interesting class of graphs, namely trees. A *tree* is a connected graph in which
    there is precisely one path connecting any given vertex to another. A graph consisting
    of a disjointed group of trees is called a forest. In the following diagram, we
    see a schematic *decision tree* ran on the well known Iris dataset. Note that
    this is for illustration purposes only, that is, to show how the output of this
    algorithm can be seen as a graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00158.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7: A simple decision tree ran on Iris, classifying into the three categories
    Setosa, Virginica and Versicolor by means of two features, namely petal length
    (PL) and petal width (PW)
  prefs: []
  type: TYPE_NORMAL
- en: Multigraphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Generally, a graph without loops or multiple edges is called *simple*. Most
    graphs we will encounter in the applications of this chapter do not share this
    property. Very often, graphs constructed from real-world data will have multiple
    edges between vertices. In literature, graphs with multiple edges are referred
    to as multi-graphs or pseudo graphs. Throughout the chapter, we will stick with
    the multigraph notion and will follow the convention that such a multigraph can
    include loops as well. Since Spark supports multigraphs (including loops), this
    notion will be very useful in the applications. In the following diagram, we see
    a complex multigraph with multiple connected components:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00159.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: A slightly more involved social multigraph with loops and multiple
    edges.'
  prefs: []
  type: TYPE_NORMAL
- en: Property graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we move on to introduce GraphX as a graph processing engine, let's look
    at an extension of graphs as we have seen them before. We have already considered
    labeled graphs as a convenient way to name vertices and edges. In general, the
    graph data we will consider in the applications will have more information attached
    to both vertices and edges, and we need a way to model this additional information
    within our graph. To this end, we can utilize the notion of *property graphs*.
  prefs: []
  type: TYPE_NORMAL
- en: From the basic definition of a graph as a pair of vertices and edges, it is
    not directly possible to attach additional information to the two structures.
    Historically, one way to circumvent this is to blow up the graph and create more
    vertices corresponding to properties, connected to the original vertices by new
    edges that encode the relationship to the new vertices. For instance, in our previous
    examples of friend graphs, if we also want to encode the home addresses in our
    graph, each vertex representing a person must be connected to a vertex representing
    their address with the edge between them *lives at*. It does not take a lot of
    imagination to realize that this approach creates a lot of complexity, especially
    if the vertex properties interrelate. Representing properties in a graph by subject-predicate-object
    *triples* has been formalized in the so-called **Resource Description Framework** (**RDF**),
    and the result of this is called an RDF-model. RDFs are a subject on their own
    and allow for a little more flexibility than we presented. In any case, it is
    good to be familiar with the concept and understand its limitations.
  prefs: []
  type: TYPE_NORMAL
- en: In a *property graph*, in contrast, we can augment both vertices and edges with
    essentially arbitrary additional structure. As with anything, gaining flexibility
    in this generality usually comes as a trade-off. In our case, basic graphs as
    implemented in many graph databases allow for the powerful optimization of queries,
    while with property graphs, we should be careful when it comes to performance.
    We will touch this topic in more detail in the next section, when we show how
    Spark GraphX implements property graphs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Throughout the rest of the chapter, we''ll use the following convention for
    property graphs. The additional data attached to vertices is called *vertex data *and
    the one for edges is called *edge data*. To give an example of a little more involved
    vertex and edge data, see the following diagram for an extension of our idea of
    extending a friend graph. This example also displays what we mean by a *triplet*,
    that is, an edge with its adjacent vertices and all their properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00160.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: A property graph showing friends augmented by address data, connected
    by more than one relation. Property data is encoded in JSON format.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that in the preceding example, we kept it simple on purpose, but in a more
    realistic scenario, we would have the need for nested data structures--for example,
    to answer how much money is owed and when it is due.
  prefs: []
  type: TYPE_NORMAL
- en: An interesting special case of a property graph in our context is that of a *weighted
    graph*, in which edges, vertices, or both have weights, for example, integers
    or floating point numbers attached to them. A prototypical example for this is
    a graph consisting of a set of cities as vertices ,with the edges connecting them
    carrying the distance between locations. A few classical questions arise in this
    scenario. One example would be to find the shortest path between two given cities.
    A related issue is the *traveling salesman problem*, in which a hypothetical salesman
    is asked to visit every city using the shortest route possible.
  prefs: []
  type: TYPE_NORMAL
- en: As a closing remark for this section, it is important to know that in literature,
    there is a widely used synonymous notion for vertices, namely nodes. We will not
    use this term here, since in the context of Spark, it might easily be confused
    with compute nodes on which workers execute tasks. Instead, we will stick to vertices
    throughout the chapter. Also, whenever we speak of a graph, we generally assume
    that it is a *finite* *graph*, that is, the number of vertices and edges is finite,
    which, in practice, hardly counts as restriction.
  prefs: []
  type: TYPE_NORMAL
- en: GraphX distributed graph processing engine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Along with Spark MLlib for machine learning, which we have already encountered
    a few times in this book, and others like Spark Streaming, which we will cover
    in Chapter 8, *Lending Club Loan Prediction*, Spark GraphX is one of the core
    components of the Spark ecosphere. GraphX is tailored for processing large graphs
    in an efficient way by building on top of RDDs.
  prefs: []
  type: TYPE_NORMAL
- en: Using the nomenclature developed in the last section, a graph in GraphX is a
    finite multigraph with loops, where by *graph*, we actually mean the property
    graph extension discussed earlier. Next, we will see how graphs are built internally
    in GraphX.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the examples used, we recommend firing up `spark-shell` locally, which
    will automatically provide dependencies for GraphX. To test whether this works
    properly in your setup, try importing the full GraphX core module using Scala''s
    wildcard operator, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'On your screen, you should see the following prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00161.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'If you would rather follow the examples by building a package using sbt, you
    should include the following `libraryDependencies` in your `build.sbt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Doing so should allow you to import GraphX, as shown previously, to create an
    app of your choice that you can call with spark-submit instead.
  prefs: []
  type: TYPE_NORMAL
- en: Graph representation in GraphX
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Recall that a property graph is, for us, a directed multigraph with loops that
    have custom data objects for both vertices and edges. The central entry point
    of GraphX is the `Graph` API, which has the following signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: So, internally, a graph in GraphX is represented by one RDD encoding for vertices
    and one for edges. Here, `VD` is the vertex data type, and `ED` is the edge data
    type of our property graph. We will discuss both `VertexRDD` and `EdgeRDD` in
    more detail, as they are so essential for what follows.
  prefs: []
  type: TYPE_NORMAL
- en: In Spark GraphX, vertices have unique identifiers of the `Long` type, which
    are called `VertexId`. A `VertexRDD[VD]` is, in fact, just an extension of `RDD[(VertexId,
    VD)]`, but optimized and with an extensive list of utility functionality that
    we will talk about at length. Thus, vertices in GraphX, simply put, are RDDs with
    identifiers and vertex data, which goes hand in hand with the intuition developed
    earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'To explain the concept of `EdgeRDD`, let''s quickly explain what `Edge` is
    in GraphX. In a simplified form, `Edge` is defined by the following signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: So, an edge is completely determined by a source vertex ID, given by `srcId`,
    a target or destination vertex ID, provided as `dstId`, and an attribute object, `attr`,
    of the `ED` data type. Similar to the preceding vertex RDDs, we can understand
    `EdgeRDD[ED]` as an extension of `RDD[Edge[ED]]`. Thus, edges in GraphX are given
    by an RDD of edges of the `ED` type, which again lines up with what we discussed
    so far.
  prefs: []
  type: TYPE_NORMAL
- en: We now know that as of Spark 2.1, graphs in GraphX are essentially pairs of
    vertex and edge RDDs. This is important information, as it allows us, in principle,
    to apply the full functionality and power of RDDs from Spark core to these graphs.
    As a word of warning, though, graphs come with a lot of functionality that is
    optimized for the purpose of graph processing. Whenever you find yourself using
    basic RDD functionality, see if you can find a specific graph equivalent, which
    will likely be more performant.
  prefs: []
  type: TYPE_NORMAL
- en: 'To give a concrete example, let''s construct a graph from scratch, using what
    we just learned. We assume that you have a Spark context available as `sc`. We
    will create a graph with people connected to each other, namely the one from *Figure
    3* of the previous section, that is, a labelled graph. In the GraphX language
    we just acquired, to create such a graph, we need both vertex and edge data types
    to be of the `String` type. We do this by using `parallelize` to create vertices
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In the same way, we can create edges; note the use of `Edge` in the following
    definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Having these two RDDs ready is already sufficient to create `Graph`, which
    is as simple as the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that we explicitly write out the types for all variables, which is just
    for clarity. We could just leave them out and rely on the Scala compiler to infer
    them for us. Furthermore, as indicated by the preceding signature, we can access
    vertices with `friendGraph.vertices` and edges with `friendGraph.edges`. Just
    to give a first glimpse of what is possible, we can now collect all the vertices
    and print them as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00162.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Note that this does not use any GraphX-specific functionality, just what we
    already know from RDDs. As another example, let''s count all the edges for which
    the source ID is larger than the target ID. This could be done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives back the expected answer, that is, `1`, but has a drawback. Once
    we call `.edges` on the graph, we completely lose all the graph structure that
    we previously had. Assuming that we want to further process a graph with transformed
    edges, this is not the way to go. In such a case, it is better to use the built-in
    `Graph` functionality instead, like the following `mapEdges` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Note that the return value in this case is again a graph, but the edge data
    type is now `Boolean`, as expected. We will see many more examples of graph processing
    possibilities in just a bit. Having seen this example, let's take a step back
    and discuss why Spark GraphX implements graphs as it does. One reason is that
    we can effectively leverage both *data parallelism *and *graph parallelism.* In
    the previous chapters, we already encountered how RDDs and data frames in Spark
    exploit data parallelism by distributing data across partitions by keeping data
    in memory on each node. So, if we are only concerned about vertices or edges on
    their own and don't want to study their relationship, working with the vertex
    and edge RDDs will be very efficient.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, by graph parallelism we mean operations carried out in parallel
    *relative to notions of the graph*. For instance, a graph-parallel task will be
    to sum the weights of all the inbound edges for each vertex. To carry out this
    task, we need to work with both the vertex and edge data, which involves multiple
    RDDs. Doing this efficiently needs a suitable internal representation. GraphX
    tries to strike a balance between both the paradigms, which few other alternative
    programs offer.
  prefs: []
  type: TYPE_NORMAL
- en: Graph properties and operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having seen yet another artificial example, let's turn to a more interesting
    example next, which we will use to investigate some of the core properties that
    we have studied in the previous section. The data we will be considering in this
    chapter can be found at [http://networkrepository.com/](http://networkrepository.com/), an
    open network data repository with a vast amount of interesting data. First, we
    will load a relatively small data set retrieved from Twitter, which can be downloaded
    from [http://networkrepository.com/rt-occupywallstnyc.php](http://networkrepository.com/rt-occupywallstnyc.php).
    Download the zip file available on this page, that is, store rt_occupywallstnyc.zip
    and unpack it to access the file, rt_occupywallstnyc.edges. The file is in the
    CSV format with commas as separators. Each row represents a retweet of a tweet
    concerning the *occupy Wall Street* movement in New York City. The first two columns
    show Twitter user IDs and the third represents an ID for the retweet; that is,
    the user in the second column retweeted a tweet from the respective user in the
    first.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first ten items look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: For instance, we can see that the tweets from user 3,212 have been retweeted
    at least six times, but since we don't know if the file is ordered in any way
    and that contains roughly 3.6k vertices, we should utilize GraphX to answer such
    questions for us.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build a graph, we will proceed by first creating an RDD of edges from this
    file, that is, `RDD[Edge[Long]]`, by using basic Spark functionality:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Recall that IDs in GraphX are of the `Long` type, which is why we cast all
    the values to `Long` after loading the text file and splitting each line by comma;
    that is, our edge data type in this case is `Long`. Here, we assume that the file
    in question resides in the same folder that we started `spark-shell` in; adapt
    it to your needs, if necessary. Having such an edge RDD, we can now use the `fromEdges`
    method of the `Graph` companion object as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: It may not come as a surprise that we need to supply `edges` to this method,
    but the `defaultValue` keyword deserves some explanation. Note that so far, we
    only have knowledge of edges, and while the vertex IDs are implicitly available
    as sources and targets of edges, we still have not settled on a vertex data type
    `VD` needed for any GraphX graph. The `defaultValue` allows you to create a default
    vertex data value, which comes with a type. In our case, we chose an empty string,
    which explains the signature of `rtGraph`.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this first real-world data graph loaded, let''s check for some basic properties.
    Using the notation from earlier, the *order* and *degree* of the graph can be
    computed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will yield 3,609 and 3,936, respectively. As for the degree
    of individual vertices, GraphX provides the `degrees` method on Graphs that returns
    a graph of integer vertex data type, which is used to store degrees. Let''s compute
    the average degree of our retweet graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The result of this operation should be roughly  `2.18`, which means that each
    vertex has about two edges connected to it on average. The notation used in this
    concise operation may seem a bit dense,  mostly due to the many wildcards used,
    so let''s dissect it a little. To explain this, we first call degrees, as discussed.
    Afterwards, we extract the degrees only by mapping to the second item of the pair;
    that is, we forget the vertex IDs. This leaves us with an RDD of integer values,
    which we can sum up by reducing by addition. The last step is casting `order.toDouble`
    to make sure we get floating division and then dividing by this total. The next
    code listing shows the same four steps expanded in more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we compute in-degree and out-degree of this directed graph by simply
    calling `inDegrees` and `outDegrees`, respectively. To make things more interesting,
    let''s compute the maximum in-degree, as well as the minimum out-degree, over
    all the vertices present in the graph and return its ID as well. We tackle the
    maximum in-degree first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Carrying out this computation, you should see that the vertex with ID `1783`
    has in-degree 401, meaning that the user with this ID retweeted 401 different
    tweets. So, an interesting follow-up question to ask is, "From how many different
    users has this user retweeted?" Again, we can answer this in a very quick manner
    by counting the distinct sources of this target in all the edges:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Executing this command should prompt 34, so on average, user `1783` retweeted
    about 12 tweets from any given user that he retweeted from at all in this data
    set. This in turn means that we found a meaningful example of a multigraph--there
    are pairs of vertices in this graph with many different connections between each
    other. Answering the question of minimum out-degree is now straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The answer is `1` in this case, which means that in this data set, each tweet
    has been retweeted at least once.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall that a *triplet* of a property graph consists of an edge and its data,
    as well as both of the joining vertices and their respective data. In Spark GraphX,
    this concept is implemented in a class called `EdgeTriplet`, in which we can retrieve
    the edge data as `attr` and vertex data and IDs naturally through `srcAttr`, `dstAttr`,
    `srcId`, and `dstId`. To get triplets for our retweet graph, we can simply call
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Triplets often prove practical, as we can directly retrieve the corresponding
    edge and vertex data, which would otherwise live in separate RDDs in the graph.
    For instance, we can quickly transform the generated triplets to give us somewhat
    readable data for each retweet by executing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00163.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'When we discussed the `friendGraph` example earlier, we took note that `mapEdges`
    was, in certain regards, superior to first calling `edges` and then `map` them.
    The same holds true for vertices and triplets as well. Let''s say we want to change
    the vertex data of our graph to simply be the vertex IDs instead of the previously
    chosen default value. This can be most quickly and efficiently achieved by mapping
    the vertices as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, instead of retrieving triplets first, we can start equally well from
    our initial graph and directly transform triplets using `mapTriplets`, returning
    a Graph object with modified edge data. To achieve the same effect as with the
    preceding `tweetStrings` but keeping the graph structure intact, we can run the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'As a last example of basic graph processing functionality, we will now look
    at the subgraphs of a given graph and how to join graphs with each other. Consider
    the task of extracting information of all the Twitter users in our graph that
    have been retweeted at least 10 times. We have already seen how to obtain out-degree
    from `rtGraph.outDegrees`. To make this information accessible in our original
    graph, we need to join this information to it. For this purpose, GraphX has the
    functionality provided by `outerJoinVertices` in place. To do so, we need to provide
    a `VertexRDD` of vertex data type, `U`, to join with and a function that determines
    how to aggregate the vertex data. If we call the RDD to join `other`, this looks
    as follows on paper:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that since we carry out an outer join, not all IDs in the original graph
    may have a corresponding value in `other`, which is why we see the `Option` type
    in the respective map function. Doing this for our concrete example at hand works
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: We join with our original graph with the out-degree, `VertexRDD`, and as the
    map function, we simply discard the original vertex data and replace it with out-degree.
    If there is no out-degree available, we simply set it to `0` by using `getOrElse`
    to resolve the `Option`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we want to retrieve the subgraph of this graph, in which each vertex
    has at least 10 retweets. A subgraph of a graph consists of a subset of the original
    vertices and edges. Formally, we define a subgraph to be the result of a *predicate *on
    edges, vertices, or both. By this, we mean an expression evaluated on the vertices
    or edges that returns either true or false. The signature of the subgraph method
    on graphs is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that since the default functions are provided, we can choose to provide
    only one of either `vpred` or `epred`. In our concrete example, we want to restrict
    to vertices with a degree of at least `10`, which can be done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The resulting graph has a mere `10` vertices and `5` edges, but it's interesting
    to see that these influencers seem to connect to each other in about as much as
    the average.
  prefs: []
  type: TYPE_NORMAL
- en: 'To close this section, an interesting technique to know is that of *masking*.
    Assume that we now want to know the subgraph of vertices with less than 10 retweets,
    which is somewhat the opposite of the preceding `tenOrMoreRetweets`. Of course,
    this can be done by a subgraph definition, but we can also mask the original graph
    by `tenOrMoreRetweets`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: If we wanted, we could reconstruct `rtGraph` by joining `tenOrMoreRetweets`
    to `lessThanTenRetweets`.
  prefs: []
  type: TYPE_NORMAL
- en: Building and loading graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last section, we made a lot of leeway in graph analytics and discussed
    an interesting retweet graph. Before we dive into more complicated operations,
    let's take a step back and consider other options to construct graphs with GraphX.
    Having completed this interlude, we will have a quick look into visualization
    tools and then turn to the more involved applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, we have already seen two ways to create GraphX graphs, one was to
    construct the vertex and edge RDDs explicitly, ourselves, to construct a graph
    from it; the other one was to use `Graph.fromEdges`. Another very handy possibility
    is to load a so-called *edge list file*. An example of this format is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'So, an edge list file is a text file with pairs of IDs per row, separated by
    a space. Assuming that we store the preceding data as `edge_list.txt` in the current
    working directory, we can load a graph object in one line from it, using the `GraphLoader`
    interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This represents a very convenient entry point, given that we have data provided
    in the right format. Additional vertex and edge data has to be joined to the resulting
    graph after loading the edge list file, though. Another similar approach to constructing
    a graph from the preceding data is to use the `fromEdgeTuples` method provided
    by the `Graph` object, which can be utilised as shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The difference from the previous construction is that we create a raw-edge RDD,
    containing pairs of vertex IDs, which, together with a default value for vertex
    data, feeds into the construction of the graph.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this last example, we have essentially seen every single way currently
    supported in GraphX to load a graph from the given data. There is, however, also
    the possibility of *generating* random and deterministic graphs, which is very
    helpful for tests, quick sanity checks, and demonstrations. To this end, we import
    the following class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'This class has a lot of functionality to offer. The two deterministic graph
    construction methods help build *star* and *grid* graphs. A star graph consists
    of a single central vertex and several vertices connecting only to the central
    one by means of one single edge. Here is how to create a star graph with ten vertices
    connecting to the central vertex:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The following image is a graphical representation of a star graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00164.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: A star graph with ten vertices surrounding a central one.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The other deterministic method for graph creation builds a grid, meaning that
    the vertices are organised in a matrix, and each vertex connects to its direct
    neighbours both vertically and horizontally. In a grid graph with *n* rows and
    *m* columns, there are precisely *n(m-1) + m(n-1)* edges--the first term is for
    all the vertical connections and the second one is for all the horizontal grid
    connections. This is how to build a `5` times `5` grid with 40 edges in GraphX:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00165.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: A quadratic 3 by 3 grid graph with twelve vertices.'
  prefs: []
  type: TYPE_NORMAL
- en: As far as random graphs are concerned, we will cover one creation method that
    approximately reflects many real-world graphs structurally, namely *log normal
    graphs*. Many structures found in real life follow a *power law*, in which the
    measure of an entity is given by the power of another. A concrete example for
    this would be the Pareto-principle, often called 80/20 principle, which implies
    that 80% of the wealth is possessed by 20% of the people, that is, most wealth
    is attributed to a few. A variant of this, called *Zipf's law,* applies to our
    scenario, namely a few vertices have very high degree, while most have very little
    connections. In the context of a social graph, very few people tend to have a
    lot of followers, while the majority have very little. This leads to a distribution
    of vertex degrees that follows a *log-normal distribution.* The star graph in
    *Figure 10* is an extreme variant of this behavior, in which all the edges are
    centered around one vertex.
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating a log normal graph with 20 vertices in graphX is simply done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code snippet, we also impose a mean of one out-degree per
    vertex and a standard deviation of three. Let''s see if we can confirm the log-normal
    distribution on vertex out-degree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: This will produce a Scala array that should look as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00166.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Note that you might get different results, since the graph is randomly generated.
    Next, let's see how to visualize some of the graphs that we have constructed so
    far.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing graphs with Gephi
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'GraphX does not come with a built-in graph visualization tool, so for us to
    tackle visualizing massive graphs, we have to consider other options. There are
    many general-purpose visualization libraries out there, as well as a few specialized
    graph visualization tools. In this chapter, we choose *Gephi* for essentially
    two reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: It is a free open source tool that is available for all the major platforms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can utilise a simple exchange format, GEXF, to persist GraphX graphs, and
    can load them into the Gephi GUI to specify the visualization with it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While the first point should be universally considered a plus, not everyone
    is a fan of the GUIs and it's certainly more in the spirit of most developers
    to define visualizations programatically. Note that this is in fact also possible
    with Gephi, but more on this later. The reason we chose the mentioned approach
    is to keep the book self-contained and the coding parts about Spark only, by still
    using powerful visualizations provided by Gephi.
  prefs: []
  type: TYPE_NORMAL
- en: Gephi
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To get started, download Gephi from [https://gephi.org/](https://gephi.org/) and
    install it locally on your machine. At the time of writing this book, the stable
    version is 0.9.1, which we will use throughout. Upon opening the Gephi application,
    you will be prompted a welcome message and can choose from a few examples to explore.
    We will use `Les Miserables.gexf` to familiarize ourselves with the tool. We will
    discuss the GEXF file format in more detail later; for now, let's just focus on
    the application. The underlying graph data of this example consists of vertices representing
    characters of the piece, *Les Miserables*, and edges denoting the association
    of characters, *weighted* by an assessment of the importance of the connection.
  prefs: []
  type: TYPE_NORMAL
- en: 'Gephi is a very rich tool and we can only discuss a few basics here. Once you
    open the preceding file you should already see a preview of the example graph.
    Gephi has three main views:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Overview**: This is the view in which we can manipulate all the visual attributes
    of the graph and get a preview. For our purposes, this is the most important view,
    and we will discuss it in more detail.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data Laboratory**: This view shows raw graph data in a table format, split
    into *Nodes *and *Edges*, which can also be extended and modified as needed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Preview**: The preview view is used to see the result, that is, the graph
    visualization, as it can also be exported to various formats, such as SVG, PDF,
    and PNG.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If it is not already active, select Overview to proceed. In the main menu of
    the application, filed under *Window,* you can choose various tabs. Make sure
    to have Graph, Preview Settings, Appearance, Layout, and Statistics open, as indicated
    in the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00167.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12: Gephi's three main views and the essential tabs used in the Overview
    view
  prefs: []
  type: TYPE_NORMAL
- en: The Graphtab, in which you should already see a visual representation of the
    sample *les miserables *graph, can be used for final touch-ups and visual inspection.
    For instance, the *Rectangle selection* on the left of the respective window allows
    you to select subgraphs by selecting vertices, whereas with *Drag*, you can move
    around vertices to your aesthetic needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Preview settings, potentially the most interesting tab for us, we can configure
    most of the visual aspects of the graph. Presets allow you to change the general
    style of the graph, such as curved versus straight edges. We will keep the Defaultsetting
    as is. You may have noticed that the graph preview has no vertex or edge labels,
    so it''s impossible to see what each vertex stands for. We can change this by
    selecting *Show Labels *in the *Node Labels* category and then deselecting the *Proportional
    size *checkbox so that all the labels have the same size. If you now go to the Previewview,
    the graph you see should look as shown in the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00168.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: Les miserables example graph, slightly modified with Gephi. Vertices
    are characters of the piece and edges represent importance of connection by means
    of edge thickness. Vertex size is determined by degree and vertices are additionally
    grouped by colour to indicate family membership, the latter of which can''t be
    seen in print.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the preceding graph comes with visual attributes that we did not specifically
    set. The vertex size is proportional to the vertex degree, the edge thickness
    is determined by the weight, and the graph is color-coded to show which family
    the individual characters belong to. To understand how this is done, we discuss
    the *Appearance *tab next, which also distinguishes between *Nodes *and *Edges*.
    In the top-right corner of this tab, there are four options to choose from, and
    we select *Size*, which is depicted by an icon showing several circles. Having
    done so, we can first select Nodes in the top-left corner and then *Ranking* right
    below it. In the drop-down menu, we can choose an attribute to determine the node
    size by, which, in the preceding example, is *degree. *Similarly, the other two
    attributes discussed previously can be configured.
  prefs: []
  type: TYPE_NORMAL
- en: Moving on, the next tab we discuss is *Layout*, in which we can select methods
    to automatically arrange the graph. Interesting layouts to play with are the two
    available *Force Atlas* schemes, which simulate vertices gravitating toward each
    other with configurable vertex attraction and repulsion properties. In *Figure
    13*, no layout was chosen, but it can be interesting to explore them a little.
    Whatever layout you choose, activate them by hitting the Runbutton.
  prefs: []
  type: TYPE_NORMAL
- en: Using the *Statistics* tab, we can explore graph properties from within Gephi,
    such as connected components and PageRank. Since we will discuss how to do this
    with GraphX, which is also much more performant, we will just leave it at that,
    although you are encouraged to experiment with the functionality in this tab,
    as it can help build intuition quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Having configured the attributes to our needs, we can now switch to the Previewview
    to see if the resulting graph is what we expect it to be. Assuming that everything
    worked out, the SVG/PDF/PNGbutton of the Preview settingstab can be used to export
    our final infographic to be used in your product, be it reports, further analyses,
    or other use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Creating GEXF files from GraphX graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To connect the graph visualization capabilities of Gephi with Spark GraphX
    graphs, we need to address a way to communicate between the two. The canonical
    candidate for doing so is Gephi''s **Graph Exchange XML Format** (**GEXF**), a
    description of which can be found at [https://gephi.org/gexf/format/](https://gephi.org/gexf/format/).
    A very simple example of how graphs are described in this format is displayed
    in the following code listing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Apart from the header and the meta data of the XML, the graph encoding itself
    is self-explanatory. It is useful to know that the preceding XML is just the bare
    minimum required for graph descriptions, and in fact, GEXF can be used to encode
    other properties, such as edge weights or even visual attributes that are automatically
    picked up by Gephi.
  prefs: []
  type: TYPE_NORMAL
- en: 'To connect with GraphX, let''s write a little helper function that takes a
    `Graph` version and returns a `String` version of the preceding XML format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'While the code might seem a bit cryptic at first sight, very little is happening.
    We define the header and the footer for the XML. We need to map the edge and vertex
    properties to the `<nodes>` and `<edges>` XML tags. To this end, we use Scala''s
    convenient `${}` notation to ingest variables directly into strings. For a change,
    let''s use this `toGexf` function in a complete Scala app, which uses our simple
    friend graph from earlier. Note that for this to work, it is assumed that `toGexf`
    is available to `GephiApp`. So, either store it in the same object or in another
    file to import it from there. If you want to continue using spark-shell, just
    pasting the imports and the body of the main method, excluding the creation of
    `conf` and `sc`, should work without problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'This app stores our friend graph as `graph.gexf`, which we can use to import
    into Gephi. To do so, go to File, then click on *Open* to select this file and
    import the graph. The following diagram shows the result of this procedure by
    tweaking the visual attributes using the tabs and methods described earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00169.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14: Our example friend graph displayed using Gephi'
  prefs: []
  type: TYPE_NORMAL
- en: As noted earlier, it is indeed possible to define visual attributes programmatically,
    using *Gephi Toolkit*, a Java library you can import into your project. There
    are other language wrappers available, but this is the supported library, available
    as a single JAR. It's far beyond the scope of this book to discuss the toolkit,
    but if you are interested, you can refer to [https://gephi.org/toolkit/](https://gephi.org/toolkit/),
    which serves as a good entry point.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced graph processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After a quick interlude into graph generation and visualization, let's turn
    towards more challenging applications and more advanced techniques for graph analytics.
    To recap, what we have done so far in terms of graph processing is just using
    the basic properties of the underlying edge and vertex RDDs of a GraphX graph,
    as well as a few transformations, including `mapVertices`, `mapEdges`, and `mapTriplets`.
    As we have seen, these techniques are already quite useful, but by themselves
    not powerful enough to implement graph-parallel algorithms with. For this purpose,
    GraphX graph has two strong candidates, which we will discuss next. Most of the
    built-in GraphX algorithms, including triangle counting, PageRank and so on, are
    implemented using either one or the other.
  prefs: []
  type: TYPE_NORMAL
- en: Aggregating messages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we discuss the `aggregateMessages` method that GraphX graphs come with.
    The basic idea is to pass messages along edges in parallel across the whole graph,
    aggregate these messages suitably and store the result for further processing.
    Let''s have a closer look at how `aggregateMessages` is defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, to implement an `aggregateMessages` algorithm we need to specify
    a message type `Msg` and provide three functions, which we will explain next.
    You may notice that there are two additional types that we haven''t encountered
    before, namely `EdgeContext` and `TripletFields`. Simply put, an edge context
    is an extension of `EdgeTriplets` that we have already seen, that is, an edge
    plus all information about adjacent vertices, with the only difference being that
    we can additionally send information to the source and target vertex defined as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '`TripletFields` allows one to restrict the `EdgeContext` fields used in the
    computation, which defaults to all available fields. In fact, in what follows
    we will simply use this default for `tripletFields` and focus on `sendMsg` and
    `mergeMsg` only. As indicated in the introduction to this topic, `sendMsg` is
    used to pass messages along edges, `mergeMsg` aggregates them and we store the
    result of this operation in a vertex RDD of `Msg` type. To make this more concrete,
    consider the following example, an alternative way to compute in-degree for all
    vertices for our little friend graph from earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: In this example, sending a message is defined by taking an edge context and
    using its `sendToDst` method to send an integer message to each target vertex,
    namely the number one. What this means is that for each edge in parallel we send
    a one to each vertex this edge points to. This way vertices get send messages
    that we need to merge. The `mergeMsg` here should be understood the same way as
    `reduce` for RDDs in general, that is, we specify how two messages are merged
    and this recipe is used to collapse all messages into one. In the example at hand
    we just sum up all messages, which by definition yields the in-degree for each
    vertex. We confirm this by asserting equality of the arrays we get from collecting
    both `inDegVertexRdd` and `friendGraph.inDegrees` on master.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the return value of `aggregateMessages` is a vertex RDD, not a graph.
    So, using this mechanism iteratively, we need to generate a new graph object in
    each iteration, which is not ideal. Since Spark is especially strong with iterative
    algorithms due to keeping partition data in memory and the fact that a lot of
    interesting graph algorithms are in fact iterative, we next discuss the slightly
    more complicated, but extremely powerful, Pregel API.
  prefs: []
  type: TYPE_NORMAL
- en: Pregel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pregel is a system internally developed by Google, the companion paper of which
    is very accessible and available for download at [http://www.dcs.bbk.ac.uk/~dell/teaching/cc/paper/sigmod10/p135-malewicz.pdf](http://www.dcs.bbk.ac.uk/~dell/teaching/cc/paper/sigmod10/p135-malewicz.pdf).
    It represents an efficient, iterative graph-parallel compute model that allows
    one to implement a large class of graph algorithms. GraphX's implementation of
    Pregel differs slightly from the preceding paper, but we can't go into any details
    of this.
  prefs: []
  type: TYPE_NORMAL
- en: In flavor, GraphX's `Pregel` implementation is very close to `aggregateMessages`,
    but has a few key differences. Traits that are shared by both approaches are the
    send and merge message mechanics. On top of that, with Pregel we can define a
    so-called *vertex program* `vprog` that is executed before sending, to transform
    vertex data. Also, we start with a shared initial message on each vertex and can
    specify for how many iterations we want to execute the *vprog-send-merge* cycle,
    that is, iterations are part of the specification.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `apply` method of the Pregel implementation is sketched. Note that it takes
    two sets of inputs, namely a quadruple consisting of the graph itself, an initial
    message, the maximum iterations to be executed and a field called `activeDirection`.
    The last argument deserves some more attention. A detail of the Pregel specification
    we have not talked about yet is that *we only send new messages from vertices
    that have received messages in the previous iteration*. The active direction defaults
    to `Either`, but can also be both, `In` or `Out`. This behavior naturally lets
    algorithms converge in many cases and it also explains why the third argument
    is called `maxIterations` - we might stop earlier than specified:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: The second set of arguments to Pregel is the triple we already sketched, namely
    the vertex program, as well as sending and merging messages functions. The only
    noteworthy difference from before is the signature of `sendMsg`, which returns
    an *iterator over vertex ID and message pairs*. This does not change much for
    us, but interestingly, the signature of `sendMsg` in `aggregateMessage` has been
    such an iterator until Spark 1.6 and was changed to what we discussed previously
    in the update to Spark 2.0\. Very likely, the signature of Pregel will be changed
    accordingly as well, but as of 2.1.1 it remains as described.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate the possibilities of the Pregel API let''s sketch an implementation
    of an algorithm that computes connected components. This is a slight modification
    of the implementation currently available in GraphX. We define the `ConnectedComponents`
    object with a single following method, namely `run`, which takes any graph and
    a maximum number of iterations. The core idea of the algorithm is easy enough
    to explain. For each edge, whenever its source has a smaller ID than its target,
    send the source ID to the target and vice versa. To aggregate these messages,
    simply take the minimum of all broadcasted values and iterate this procedure long
    enough so that it runs out of updates. At this point, every vertex that is connected
    to another bears the same ID as vertex data, namely the smallest ID available
    in the original graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Going step by step, the algorithm does as follows. We first forget all previously
    available vertex data by defining `idGraph`. Next, we define the vertex program
    to emit the minimum of the current vertex data attribute and the current message.
    This way we can store the minimum vertex ID as vertex data. The `sendMsg` method
    propagates the smaller ID for each edge to either source or target, as described
    before and `mergeMsg` again just takes the minimum over IDs. Having these three
    key methods defined, we can simply run `Pregel` on the `idGraph` with `maxIterations`
    as specified. Note that we do not care about which direction the messages flow,
    so we use `EdgeDirection.Either`. Also, we start with the maximum available Long
    value as our initial message, which works since we take the minimum over vertex
    IDs everywhere.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having defined this allows us to find connected components on the retweet graph
    `rtGraph` from earlier as follows, choosing five iterations as maximum:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Counting distinct vertex data items of the resulting graph gives us the number
    of connected components (in this case it is just one component), that is, all
    tweets in the data set are connected if we forget directionality. It is interesting
    to note that we do in fact need five iterations for the algorithm to converge.
    Running it with fewer iterations, that is, 1, 2, 3 or 4, yields 1771, 172, 56
    and 4 connected components. Since there has to be at least one connected component,
    we know that further increasing iterations would not change the outcome. However,
    in general we would rather not specify the number of iterations, unless time or
    computing power are an issue. By wrapping the preceding run method as follows,
    we can run this algorithm on graphs only, without explicitly providing iterations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Simply add this as an additional method to the `ConnectedComponents` object.
    For the retweet graph, we can now simply write instead. Having seen both `aggregateMessages`
    and Pregel, the reader should now be adequately equipped to develop their own
    graph algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: GraphFrames
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Note that so far, to compute any interesting indicators on a given graph, we
    had to use the compute model of the graph, an extension of what we know from RDDs.
    With Spark's DataFrame or Dataset concept in mind, the reader may wonder if there
    is any possibility to use an SQL-like language to do run queries against a graph
    for analytics. Query languages often provide a convenient way to get results quickly.
  prefs: []
  type: TYPE_NORMAL
- en: This is indeed possible with GraphFrames. The library was developed by Databricks
    and serves as natural extension of GraphX graphs to Spark DataFrames. Unfortunately,
    GraphFrames are not part of Spark GraphX, but instead available as Spark package.
    To load GraphFrames upon starting spark-submit, simply run
  prefs: []
  type: TYPE_NORMAL
- en: '`spark-shell --packages graphframes:graphframes:0.5.0-spark2.1-s_2.11`'
  prefs: []
  type: TYPE_NORMAL
- en: 'and suitably adapt preceding version numbers for both your preferred Spark
    and Scala versions. Converting a GraphX Graph to a `GraphFrame` and vice versa
    is as easy as it gets; in the following we convert our friend graph from earlier
    to a `GraphFrame` and then back:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: As indicated before, one added benefit of GraphFrames is that you can use Spark
    SQL with them, as they are built on top of DataFrames. This also means that GraphFrames
    are much faster than Graphs, since the Spark core team has brought a lot of speed
    gains to DataFrames through their catalyst and tungsten frameworks. Hopefully
    we see GraphFrames added to Spark GraphX in one of the next releases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of looking at a Spark SQL example, which should be familiar enough
    from previous chapters, we consider another query language available for GraphFrames,
    that has a very intuitive compute model. GraphFrames has borrowed the *Cypher*
    SQL dialect from the graph database *neo4j*, which can be used for very expressive
    queries. Continuing with the `friendGraphFrame`, we can very easily find all length
    two paths for which either end in the vertex "Chris" or pass through the edge
    "trusts" first by using one concise command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Note how we can specify the graph structure in a manner that lets you think
    in terms of the actual graph, that is, we have two edges *e1* and *e2*, that are
    connected to each other by a common vertex *v2*. The result of this operation
    is listed in the following screenshot, which indeed gives back the three paths
    that suffice the preceding condition:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00170.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Unfortunately, we can not discuss GraphFrames here in more detail, but the interested
    reader is referred to the documentation available at [https://graphframes.github.io/](https://graphframes.github.io/) for
    more details. Instead, we will now turn to the algorithms available in GraphX
    and apply them to a massive graph of actor data.
  prefs: []
  type: TYPE_NORMAL
- en: Graph algorithms and applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this application section, in which we will discuss triangle counting, (strongly)
    connected components, PageRank and other algorithms available in GraphX, we will
    load another interesting graph dataset from [http://networkrepository.com/](http://networkrepository.com/).
    This time please download data from [http://networkrepository.com/ca-hollywood-2009.php](http://networkrepository.com/ca-hollywood-2009.php),
    which consists of an undirected graph whose vertices represent actors occurring
    in movies. Each line of the file contains two vertex IDs representing an edge,
    meaning that these actors appeared together in a movie.
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset consists of about 1.1 million vertices and has 56.3 million edges.
    Although the file size, even after unzipping, is not particularly large, a graph
    of this size is a real challenge for a graph processing engine. Since we assume
    you work with Spark''s standalone mode locally, this graph will likely not fit
    into your computer''s memory and will crash the Spark application. To prevent
    this, let''s restrict the data a little, which also gives us the chance to clean
    up the file header. We assume you have unpacked `ca-hollywood-2009.mtx` and stored
    it in your current working directory. We use unix tools *tail* and *head* to delete
    the first two lines and then restrict to the first million edges:'
  prefs: []
  type: TYPE_NORMAL
- en: '`tail -n+3 ca-hollywood-2009.mtx | head -1000000 > ca-hollywood-2009.txt`'
  prefs: []
  type: TYPE_NORMAL
- en: 'If these tools should not be available to you, any other will do, including
    manually modifying the file. From the structure described previously we can simply use
    `edgeListFile` functionality to load the graph into Spark and confirm that it indeed
    has a million edges:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Next, let's see what we can do with GraphX to analyze this graph.
  prefs: []
  type: TYPE_NORMAL
- en: Clustering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Given a graph, a natural question to ask is if there are any subgraphs to it
    that naturally belong together, that is, that cluster the graph in some way. This
    question can be addressed in many ways, one of which we have already implemented
    ourselves, namely by studying connected components. Instead of using our own implementation,
    let''s use GraphX''s built-in version this time. To do so, we can simply call
    `connectedComponents` directly on the graph itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'As in our own implementation, the vertex data of the graph contains cluster
    IDs, which correspond to the minimum available vertex ID within the cluster. This
    allows us to directly count connected components, by collecting distinct cluster
    IDs. The answer for our restricted cluster graph is 173\. Computing components,
    we cache the graph so we can further use it for other computations. For instance,
    we might ask how large the connected components are, for example by computing
    the maximum and the minimum cluster size in terms of vertices. We can do this
    by using the cluster ID as key and reducing each group by counting its items:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: It turns out the largest cluster spans a respectable group of 193,518 actors,
    while the smallest consists of a mere three actors. Next, let's ignore the fact
    that the graph in question does not actually have directionality, since appearing
    in a movie together is symmetric, and act as if the edge pairs were directed.
    We don't have to impose anything here, since an edge in Spark GraphX always has
    a source and a target. This allows us to study *strongly *connected components
    as well. We can call this algorithm similarly to that for connected components,
    but in this case we have to specify a number of iterations as well. The reason
    for this is that it's much more computationally demanding to "trace" directed
    edges in the same way we did for connected components and convergence is slower.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s settle for just one iteration to carry out the computation, since it
    is very expensive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: This computation might take a few minutes to complete. In case you have problems
    running even this example on your machine, consider further restricting `actorGraph`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s compute triangles for the actor graph, yet another way to cluster
    it. To do so, we need to slightly prepare the graph, namely we have to *canonicalize *the
    edges and specify a *graph partition strategy. *To canonicalize a graph means
    to get rid of loops and duplicate edges and make sure that the source ID is always
    smaller than the target ID for all the edges:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Graph partition strategies, like RDD partitions we have already encountered,
    are concerned with the question of how to distribute a graph across the cluster
    efficiently. Of course, what efficiently means depends in large part on what we
    do with our graph. Roughly speaking, there are two basic partition strategies,
    namely *vertex cut* and *edge cut*. Vertex cut strategy means enforce split edges
    in a disjointed manner by cutting vertices, that is, vertices are repeated across
    partitions, if necessary. Edge cut strategy does the opposite in that vertices
    are unique throughout the cluster, but we may duplicate edges. GraphX has four
    partition strategies that are all based on vertex cut.  We will not discuss them
    here in detail, but rather just use `RandomVertexCut`, which hashes vertex IDs
    so that all same-direction edges between vertices are located on the same partition.
  prefs: []
  type: TYPE_NORMAL
- en: Note that when creating a graph without specifying a partition strategy, the
    graph is distributed by simply adopting the structure of the underlying EdgeRDD
    that has been provided for construction. Depending on your use-case, this might
    not be ideal, for instance because edge partitions might be strongly imbalanced.
  prefs: []
  type: TYPE_NORMAL
- en: 'To partition `canonicalGraph` and continue with triangle counting, we now partition
    our graph using said strategy as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Computing triangles is conceptually simple. We first collect all neighboring
    vertices for each vertex and then compute the intersection of these sets for each
    edge. The logic is, if both source and target vertex sets contain the same third
    vertex, the three form a triangle. As a last step, we send the *count of the intersection
    set* to both source and target, thereby counting each triangle twice and we simply
    divide by two to get a triangle count per vertex. Doing the triangle count now
    boils down to running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'In fact, instead of canonicalising `actorGraph` explicitly, we could simply
    have gotten away with just imposing `triangleCount` directly on the initial graph,
    that is, by computing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Equivalently, we can also import `TriangleCount` and call it on our actor graph
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Note, however, that these last two equivalent operations will in fact canonicalize
    the graph in question the same way we did, and canonicalisation is a computationally
    very expensive operation. So, whenever you see the chance to already load your
    graph in canonical form, the first approach shown will be more efficient.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex importance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a graph of friends connected to each other, an interesting question to ask
    is who the most influential person in the group is. Is it the person with the
    most connections, that is, the vertex with the highest degree? For directed graphs,
    in-degree might be a good first guess. Or is it rather the person who knows a
    selected few people who themselves have a lot of connections? There are certainly
    many ways to describe how important or authoritative a vertex is and the concrete
    answer will depend on the problem domain a lot, as well as on what additional
    data we are given with the graph. Moreover, in the example we have given, for
    a specific person in the graph another person might be the most influential for
    their own, very subjective reasons.
  prefs: []
  type: TYPE_NORMAL
- en: Still, seeking for vertex importance in a given graph is a challenging problem,
    and one historically important example of such an algorithm is *PageRank*, which
    was described back in 1998 in the seminal paper "The Anatomy of a Large-Scale
    Hypertextual Web Search Engine" available at  [http://ilpubs.stanford.edu:8090/361/1/1998-8.pdf](http://ilpubs.stanford.edu:8090/361/1/1998-8.pdf).
     In it, Sergey Brin and Larry Page laid the foundations of what ran their search
    engine Google when the company had just started out. While PageRank had a significant
    impact on finding relevant search results in the vast graph of web pages connected
    by links, the algorithm has since been replaced by other approaches within Google
    over the years. However, PageRank remains a prime example of how to rank web pages,
    or graphs in general, to gain a deeper understanding of it. GraphX provides an
    implementation of PageRank, which we will have a look at after describing the
    algorithm itself.
  prefs: []
  type: TYPE_NORMAL
- en: PageRank is an iterative algorithm for directed graphs that is initialized by
    setting the same value to each vertex, namely *1/N* where *N* denotes the order
    of the graph, that is, the number of vertices. It then repeats the same procedure
    of updating vertex values, that is, their PageRank, until we choose to stop or
    certain convergence criteria is fulfilled. More specifically, in each iteration
    a vertex sends its *current PageRank divided by its out-degree* to all vertices
    it has an outbound connection to, that is, it distributes its current PageRank
    evenly over all outbound edges. Vertices then sum up all the values they receive
    to set their new PageRank. If overall PageRanks did not change much in the last
    iteration, stop the procedure. This is the very basic formulation of the algorithm
    and we will further specify the stopping criterion when discussing the GraphX
    implementation.
  prefs: []
  type: TYPE_NORMAL
- en: However, we also need to slightly extend the baseline algorithm by introducing
    a *damping factor d*. The damping factor was invented to prevent so called *rank
    sinks*. Imagine a strongly connected component that has only incoming edges from
    the rest of the graph, then by preceding prescription this component will accumulate
    more and more PageRank through incoming edges in each iteration, but never "release"
    any of it through outbound connections. This scenario is called a rank sink and
    to get rid of it we need to introduce more *rank sources* through damping*.* What
    PageRank does is simulate the idealistic idea of a completely random user following
    links probabilistically with likelihood given by the link target's PageRank. The
    idea of damping changes this by introducing a chance of probability d the user
    follows their current path, and with likelihood (*1-d*), gets bored and continues
    reading a completely different page.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our rank sink example above the user would leave the strongly connected
    component and end up somewhere else in the graph, thereby increasing relevance,
    that is, PageRank, of other parts of the graph. To wrap up this explanation, the
    PageRank update rule with damping can be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00171.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: that is, to update PageRank *PR* for vertex *v*, we sum over the PageRank of
    all inbound vertices *w* divided by their respective out-degree *out(w)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Spark GraphX has two implementations for PageRank, one called static, the other
    dynamic. In the static version, we simply carry out the preceding update rule
    for a fixed amount of iterations `numIter` specified upfront. In the dynamic version,
    we specify a *tolerance* `tol` for convergence, namely that a vertex drops out
    of the computation if its PageRank did not change at least by `tol` in the last
    iteration, which means it will neither emit new PageRanks nor update its own anymore.
    Let''s compute PageRank in both static and dynamic versions for the tiny `friendGraph`.
    The static version with 10 iterations is called as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'After running the algorithm, we simply collect all vertices on master and print
    them, which yields the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s interesting to see how PageRanks change with varying numbers of iterations;
    see the following table for details:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **numIter / vertex** | **Anne** | **Bernie** | **Chris** | **Don** | **Edgar**
    |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0.213 | 0.213 | 0.341 | 0.277 | 0.213 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 0.267 | 0.240 | 0.422 | 0.440 | 0.267 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 0.337 | 0.263 | 0.468 | 0.509 | 0.337 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 0.366 | 0.293 | 0.517 | 0.548 | 0.366 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 0.383 | 0.305 | 0.554 | 0.589 | 0.383 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 0.429 | 0.330 | 0.610 | 0.665 | 0.429 |'
  prefs: []
  type: TYPE_TB
- en: '| 20 | 0.438 | 0.336 | 0.622 | 0.678 | 0.438 |'
  prefs: []
  type: TYPE_TB
- en: '| 100 | 0.438 | 0.336 | 0.622 | 0.678 | 0.483 |'
  prefs: []
  type: TYPE_TB
- en: 'While the general tendency of which vertex is more important than the other,
    that is, the relative ranking of the vertices is already established after only
    two iterations, note that it takes about 20 iterations for the PageRanks to stabilize
    even for this tiny graph. So, if you are only interested in ranking vertices roughly
    or it is simply too expensive to run the dynamic version, the static algorithm
    can come in handy. To compute the dynamic version, we specify the tolerance `tol`
    to be `0.0001` and the so called `resetProb` to `0.15`. The latter is nothing
    but *1-d*, that is, the probability to leave the current path and pop up at a
    random vertex in the graph. In fact, `0.15` is the default value for `resetProb`
    and reflects the suggestion of the original paper:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this yields the following PageRank values, displayed in *Figure 15*.
    The numbers should look familiar, as they are the same as from the static version
    with 20 or more iterations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00172.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15: PageRanks computed for our toy friend graph, using the dynamic GraphX
    implementation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For a more interesting example, let''s turn to the actor graph once more. With
    the same tolerance as in the preceding example, we can quickly find the vertex
    ID with the highest PageRank:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'This returns ID 33024 with a PageRank of 7.82\. To highlight how PageRank differs
    from the naive idea of simply taking in-degree as shot at vertex importance, consider
    the following analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Restricting to the vertex ID in question and checking its in-degree results
    in 62 incoming edges. Let''s see what the top ten highest in-degrees in the graph
    are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in `Array(704, 733, 746, 756, 762, 793, 819, 842, 982, 1007)`,which
    means the vertex with the highest PageRank does not even come close to having
    among the highest in-degrees. In fact, there is a total of 2167 vertices that
    have at least `62` inbound edges, as can be seen by running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: So, while this still means the vertex is in the top 2% of all vertices in terms
    of in-degree, we see that PageRank yields a completely different answer from other
    approaches.
  prefs: []
  type: TYPE_NORMAL
- en: GraphX in context
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having seen a lot of applications of graph analytics throughout the chapter,
    a natural question to follow up with is how GraphX fits into other parts of the
    Spark ecosphere and how we can use it for machine learning applications in conjunction
    with systems like MLlib, which we have seen earlier.
  prefs: []
  type: TYPE_NORMAL
- en: The quick answer is that while the concept of graphs is limited to Spark GraphX
    only, due to the underlying vertex and edge RDDs of a graph, we can seamlessly talk
    to any other module of Spark. In fact, we have used many core RDD operations throughout
    the chapter, but it does not stop there. MLlib does make use of GraphX functionality
    in a few selected places, like *Latent Dirichlet Analysis* or *Power Iteration
    Clustering*, which are unfortunately beyond the scope of this chapter to explain.
    Instead, we focused on explaining the basics of GraphX from first principles.
    However, the reader is encouraged to apply what we have learnt in this chapter,
    together with the ones before, and experiment with the preceding algorithms. For
    sake of completeness, there is one machine learning algorithm completely implemented
    in GraphX, namely *SVD++*, which you can read more about at [http://public.research.att.com/~volinsky/netflix/kdd08koren.pdf](http://public.research.att.com/~volinsky/netflix/kdd08koren.pdf),
    and which is a graph-based recommender algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have seen how to put large-scale graph analytics in practice
    using Spark GraphX. Modeling entity relationships as graphs with vertices and
    edges is a powerful paradigm to assess many interesting problems.
  prefs: []
  type: TYPE_NORMAL
- en: In GraphX, graphs are finite, directed property graphs, potentially with multiple
    edges and loops. GraphX does graph analytics on highly optimized versions of vertex
    and edge RDDs, which allows you to leverage both data and graph-parallel applications.
    We have seen how such graphs can be read by either loading them from `edgeListFile`
    or constructing them individually from other RDDs. On top of that, we have seen
    how easy it is to create both random and deterministic graph data for quick experiments.
    Using just the rich built-in functionality of the `Graph` model, we have shown
    how to investigate a graph for core properties. To visualize more complex graphs,
    we introduced *Gephi* and an interface to it, which allows one to gain intuition
    about the graph structure at hand.
  prefs: []
  type: TYPE_NORMAL
- en: Among the many other possibilities that Spark GraphX has to offer, we introduced
    two powerful graph analytics tools, namely `aggregateMessages` and the `Pregel`
    API. Most of GraphX’s built-in algorithms are written using one of these options.
    We have seen how to write our own algorithms using each of these APIs. We also
    gave a brief overview of the GraphFrames package, which builds on top of DataFrames,
    comes equipped with an elegant query language that is not available in plain GraphX,
    and can come in handy for analytics purposes.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of practical applications, we have seen an interesting retweet graph,
    as well as a Hollywood movie actor graph in action. We carefully explained and
    applied Google’s PageRank algorithm, studied (strongly) connected components of
    graphs, and counted triangles thereof as a means of doing clustering. We finished
    by discussing the relationship between Spark MLlib and GraphX for advanced machine
    learning applications.
  prefs: []
  type: TYPE_NORMAL
