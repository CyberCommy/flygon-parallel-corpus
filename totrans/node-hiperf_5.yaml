- en: Chapter 5. Data and Cache
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data is one of your most important assets in your application. Actually, it
    should be the fundamental asset. You might run your application anywhere, but
    without your data, it is pointless. By data, I mean the information that your
    application manipulates, generated or not by your end users. If your application
    can't work without a database, that database has an important piece of data that
    you must preserve.
  prefs: []
  type: TYPE_NORMAL
- en: Application data is very important. In web applications, users access it using
    the Internet and their data is stored on the server side, this importance increases.
    As your user base grows and the total size of your data increases, it becomes
    even more important to plan how your data is stored and how it's used.
  prefs: []
  type: TYPE_NORMAL
- en: And don't forget to have a backup plan. You wouldn't want to lose your data
    and have no way to roll back, even if the rollback means going one week back in
    time. Your users might accept losing some data (1 week), but will definitely not
    accept losing everything.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at data storage by looking at some important topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Excessive I/O
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Database management systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Caching data and asynchronous caching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clustering data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accessing data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data storage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many ways of storing data. It depends on what type of data you have
    and how big it can become. If you just need to store a simple key/value pair,
    you can use a file with the format of your choice (for example, an INI or a JSON
    file). If that key/value pair grows to thousands or millions, you probably won't
    want to keep it there. You need to think about your data and choose the best possible
    storage for it, at least from your viewpoint.
  prefs: []
  type: TYPE_NORMAL
- en: If you have other applications, you might try to choose the same data storage
    to all or some of those applications. This is actually not a bad decision. Choosing
    the second best tool and trying to use just one or two tools for a couple of applications
    greatly improves your chances of gaining knowledge about that subset, instead
    of using the best tool for every application and ending up with many tools and
    little knowledge about each one.
  prefs: []
  type: TYPE_NORMAL
- en: Excessive I/O
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When using a custom solution, we need to carefully plan how we store and access
    our data, especially when and how many times we do it. Your host has a disk throughput
    limit and you wouldn't want to reach it. Also, you'll certainly not want to read
    your data from the disk every time you need it. It can work during your local
    tests, but if your application is targeted to thousands of users, it will break
    and you might start receiving `EBUSY` or `EMFILE` errors.
  prefs: []
  type: TYPE_NORMAL
- en: One of the strategies is to avoid excessive I/O to just read it at start, manipulate
    it in the memory, and flush the data to disk from time to time. Data can be stored
    in a variety of formats, **JSON** being the most famous and used as of now. This
    has the disadvantage of forcing your application to implement a single channel
    to read and write to the file or else you'll get corrupted data sooner or later.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of creating your custom data storage, use databases or other data model
    servers. Leave data storage to professionals and focus on your applications. Some
    advantages of this are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Data storage does not need to be maintained
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Database servers are optimized for high-performance scenarios
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Database servers normally support having more than one machine holding the data,
    allowing your application to scale in size as you need it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It all depends on the system you choose. It's better to take your time and pick
    a good one before you start. I would focus on scalability and consistency. Speed
    is something you can't measure, and it varies from application to application
    and from use case to use case.
  prefs: []
  type: TYPE_NORMAL
- en: Database management systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you choose a **database management system** (**DBMS**), it''s very important
    that you be comfortable with it. Don''t put a server that you''re uncomfortable
    with in production, as you''ll definitely regret it. When using a DBMS in production,
    you need to be comfortable with:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Management**: It''s very important that you be able to replicate your application
    scenario to a new host without thinking too much about it. You should know how
    to initialize your storage and manage access. Look for visual interfaces (such
    as desktop and web) and avoid managing only through a console; you''ll make more
    mistakes in a console as it''s harder for complex tasks. Visual interfaces usually
    have automation tools and can help you avoid syntax errors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security**: Be careful about default permissions, especially localhost permissions,
    as they''re usually set as permissive and give full control over the data. You
    don''t want to lose data, right?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Backups**: It''s critical that you have a scheduled and automated plan and
    that you know how to roll back to a backup. You should run trials on another host.
    You wouldn''t want to roll back just to find that your backups are corrupted.
    Install a cron job (either locally or remotely), export it from time to time,
    and try it out. I personally prefer to have one or two backups that work rather
    than have 10 that don''t.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Structure**: Knowing how you can organize and correlate your data for better
    storage and faster access is mandatory. You definitely don''t want to make changes
    later.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The data structure you choose is directly related to your DBMS and your application's
    performance. Make a sketch of your data and see how your data entities relate
    with each other. It's quite common to have several tables in your database. After
    all, that's one of the reasons you use a database in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: What you usually don't think about is that you probably have a single table,
    maybe a history table or similar, that over time will represent more than 90 percent
    of your database space usage. It is critical that you optimize that table and
    decide whether there are columns you don't need or you can move to another table.
    You can thank me later!
  prefs: []
  type: TYPE_NORMAL
- en: Even after optimizing that table, you won't be able to stop its growth. Do you
    really need to have a lifetime history or can you export data monthly or yearly
    to another format and wipe it from the database? Having a database that can grow
    and even expand to multiple servers is good, but that isn't a synonym for performance.
  prefs: []
  type: TYPE_NORMAL
- en: With respect to this matter, analyze what you might value the most. Is it integrity?
    Do you need extra security? Do you plan on splitting the database across different
    servers, as MongoDB is able to? Do you prefer a mature server that has been proven
    to be stable or will you opt for a new technology? As I said before, try the second
    best choice. You'll probably be able to use it more often and avoid getting a
    lot of different technologies that will be harder to maintain.
  prefs: []
  type: TYPE_NORMAL
- en: Your data should be structured by now. For example, if you're creating a calendar
    application, you probably have entities such as users, calendars, and events.
    After creating the basic structure, you'll probably realize that you need more
    structures to relate calendars with users (maybe access permissions) and users
    with events (maybe participants). After a couple of development iterations, you'll
    probably have more.
  prefs: []
  type: TYPE_NORMAL
- en: Your structures will grow and your tables will start getting more columns. You'll
    realize that in this case, your bottleneck table is the one that holds events.
    Hopefully, it will not be too late to optimize it and remove some columns that
    are rarely used and can be moved to another table. When there's no space left
    to reduce, you have to think about other options.
  prefs: []
  type: TYPE_NORMAL
- en: Caching data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Caching becomes relevant when a piece of information is requested too often
    and its value will not change, for example, historic values. It's a good method
    of improving performance if these values require some complexity and manipulation
    in the database. Even if they're not historic values and can change, sometimes
    caching is not that bad, at least for a couple of minutes.
  prefs: []
  type: TYPE_NORMAL
- en: In complex systems, you may find cache as the second level of abstraction between
    the application and the database. In such cases, bidirectional updates happen;
    that is, data is fetched to the cache and when changed by some user action, the
    cache data is updated and then the database is also updated. This is faster than
    clearing the cache and forcing a new request to the database to fetch the data
    that we already know. You may find this in basic applications, for example, in
    session data.
  prefs: []
  type: TYPE_NORMAL
- en: Some databases can perform this caching, but others don't, and you cannot rely
    on them to do it. Also, in other cases, they can't cache because you need to manipulate
    the data. In some cases you need to address caching to another application or
    another key/value service that you can use to save values and use them for a while.
    Redis can be used as a caching service. It supports some nice features, such as
    complex structures, transactions, and time-to-live keys.
  prefs: []
  type: TYPE_NORMAL
- en: 'Your cache logic should be something similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Caching data](img/4183_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This logic can be used in a variety of ways. You can use a cache in memory,
    getting the fastest cache possible for small sets. If you know that your cached
    data may exceed your available memory, you can use files. This happens if, for
    example, you generate image or document thumbnails. You can cache them, and probably,
    the best location to store them is the disk.
  prefs: []
  type: TYPE_NORMAL
- en: You can use services that handle data storage and allow you to focus on your
    application logic. Some of the most popular and simple services to work with are
    memcached and Redis. There are pros and cons for each of them. In both cases,
    they need zero setup to start using them.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous caching
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Writing Node.js applications forces you to think asynchronously. This means
    that you'll face some challenges, a few of which you probably don't even know
    yet. One particularly painful challenge is asynchronous caching. It doesn't matter
    whether you're using an external service or a simple internal function; the asynchronous
    part is on your side and is the one responsible for giving you unpleasantness.
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem won''t show up easily; you might figure it out just when the load
    gets high and you see a lot of cache function hits. This is not simple to describe,
    so let''s look at a fake example of a cache that we probably do somewhere in every
    application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: It's very incomplete but you get the idea. Every time you want a user, you call
    `getUser`. This function will get it from somewhere (`users.findOne` might be
    from an ORM) and return it. Then it will store it in a hash table, and if you
    request it again, it will return that user directly. There's no time to live or
    proper error handling, but that won't solve the next problem.
  prefs: []
  type: TYPE_NORMAL
- en: We're assuming that fetching the user is very quick, right? Imagine it takes
    some time, a few seconds maybe. Next, imagine that this function is used very
    often. What happens if fetching the user takes, for instance, 10 seconds because
    of some hiccup in the network and, in that time, you call this function 100 times?
  prefs: []
  type: TYPE_NORMAL
- en: There's no cached value and each one of the 100 calls will try to access the
    database because they ignore that the first call will actually cache the value
    and the rest of the 99 calls could use it. If the problem is in the user fetching,
    it will accumulate calls and drop your application to the ground. This happens
    because fetching the user is not instant, and so the following calls to the same
    user should be queued until the user is fetched.
  prefs: []
  type: TYPE_NORMAL
- en: 'It could be something like the following code. Again, this is a simplified
    version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Take your time to understand it. As you can see, it's not the paradigm that
    has pitfalls; it's the way. Usually, developers are trained but not prepared for
    the asynchronous platform that Node.js (and others for the matter) enforces on
    you.
  prefs: []
  type: TYPE_NORMAL
- en: For many years, it was good practice (and it still is) to get an abstraction
    to the database called **Object-relational mapping** (**ORM**). Abstractions create
    a new layer that allows you to change the database type (more or less) and still
    keep your application working. This is actually not that simple for a more mature
    application, as it can be quite difficult to avoid certain specificities of a
    server in order to improve performance. Besides this small advantage, it can reduce
    access speed and so make your application a little slower. It has other advantages,
    however, especially in the professional market, as you can apply your business
    model and entities directly to your code.
  prefs: []
  type: TYPE_NORMAL
- en: For historic data or a big dataset in general, ORMs are not exactly the best
    option. Many ORMs give you extra power over every item but that comes with a cost
    (speed and memory). For a big dataset, you get extra power (and big speed and
    memory cost). You'll figure out that it's not just the layer that's turning your
    application slow; it's also the database, which is usually not ready for huge
    datasets in a table (huge means gigabytes).
  prefs: []
  type: TYPE_NORMAL
- en: You may look for other services that can give you intermediate levels of caching
    and, if used correctly, a sense of performance by helping you reach specific data
    that you use the most. Services such as **ØMQ** and **RabbitMQ** (both message
    queue services) may be of your interest in achieving this. They can act as proxies
    for your data storage servers, creating the idea that you have a big and unified
    storage server. These services are targeted to be performant and this is one of
    the use cases they're designed for.
  prefs: []
  type: TYPE_NORMAL
- en: Adding services to act like proxies adds another layer to your application environment.
    In small scenarios with a small dataset, they might be overkill. But in bigger
    datasets, even on a single storage server, they can help maintain a constant throughput
    while your dataset grows.
  prefs: []
  type: TYPE_NORMAL
- en: Clustering data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Spreading services across different hosts will be necessary. Somewhere, while
    your application dataset is growing, you'll see your host screaming for resources
    and your average load gradually eating up every one of your processors. From that
    moment onward, you need to add a host to keep the speed stable and allow your
    dataset to grow a little more.
  prefs: []
  type: TYPE_NORMAL
- en: Moving from using one host to using two hosts can be complex, forcing you to
    dominate a database server or another type of data clustering. Many database services
    support clustering or some kind of replication. The following image is an example
    of a database replicated in the servers, allowing the application to access any
    of the database instances
  prefs: []
  type: TYPE_NORMAL
- en: '![Clustering data](img/4183_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In multimaster replication mode, the dataset is usually stored (and duplicated)
    in two or more hosts, allowing the data to be updated from any of those hosts.
    This replicates data across all hosts, called **members**. Since there's no partitioning,
    every member is responsible for handling client requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'These are some of the advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: No single point of failure. Every member is a master, so everyone can fail.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hosts can be geographically distributed, allowing your application also to be
    distributed near your clients.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Some of the disadvantages are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: It's not usually consistent if in asynchronous mode, as the network may disappoint
    you before your data is replicated to another host
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It introduces latency if in some kind of synchronous mode, since your server
    won't reply to you until data is replicated, and once again your network may fail
    on you
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There's no silver bullet, and for a really performant application, you definitely
    need to take a deep look into your data. You might need to split it between different
    types of servers, taking advantage of their unique features. As stated before,
    a message queue server might be the best choice for part of your data.
  prefs: []
  type: TYPE_NORMAL
- en: Replication does not allow you to scale properly. Your data is complete on every
    server. For huge datasets, this is a waste of space, given that the probability
    of all but one server going down is really small. And you have backups, right?
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are better alternatives, such as clustering, where your data is partitioned
    and every block is replicated on at least two hosts. It's normally up to you to
    decide. This is similar to RAID5 on disks but without the *write hole* phenomenon
    ([http://www.raid-recovery-guide.com/raid5-write-hole.aspx](http://www.raid-recovery-guide.com/raid5-write-hole.aspx)).
  prefs: []
  type: TYPE_NORMAL
- en: Accessing data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Your application needs to be prepared for these scenarios. One of the possibilities
    is shown in the previous diagram. Your application knows about replication members
    and tries to use them randomly or by a specific rule. It's up to your application
    or database module to identify failures and handle them correctly. The following
    image describes how you can also replicate the application instances and introduce
    a proxy to intermediate access to the application.
  prefs: []
  type: TYPE_NORMAL
- en: '![Accessing data](img/4183_05_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Another possible scenario is to have an instance of your application tied to
    each of your replication hosts, possibly even localhost. In this way, your application
    works locally. This, however, brings forth two issues to solve:'
  prefs: []
  type: TYPE_NORMAL
- en: Having a reverse proxy enables this to assign an application instance to each
    user depending on the user geographic location or application instance load.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Your application needs to be able to work in this scenario (stateless), unless
    your proxy ensures that every client will always access the same instance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your application only needs data stored in a database, these are the possible
    scenarios. If it depends on a filesystem, some scenarios won't fit unless you
    have some kind of synchronization between hosts. GlusterFS comes to my mind. If
    you don't need a filesystem and you're comfortable with some kind of object/blob
    storage, Ceph or even MongoDB can be a good choice. If you want a highly scalable
    data storage server, you might just start looking at Cassandra and forget about
    the alternatives. Prepare your application from the ground up to work with it
    and you won't regret it.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data is a critical part of your application and planning how to structure it
    is important. Even more important is how you plan your application growth and
    data escalation. Don't forget about caching for the most used parts of your data,
    and most importantly, don't forget backups. Replication and clustering are not
    kinds of backup. You need a correct backup plan that avoids downtime in the future.
    Don't forget to value your data.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll continue with topics on application performance by
    seeing how and why tests are important and how you should benchmark and carefully
    read the results (with a grain of salt). Your application is almost ready for
    high performance. But before you go for production, make sure you test it thoroughly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Prepared for Bentham Chang, Safari ID bentham@gmail.com User number: 2843974
    © 2015 Safari Books Online, LLC. This download file is made available for personal
    use only and is subject to the Terms of Service. Any other use requires prior
    written consent from the copyright owner. Unauthorized use, reproduction and/or
    distribution are strictly prohibited and violate applicable laws. All rights reserved.'
  prefs: []
  type: TYPE_NORMAL
