- en: Adopting Container-First Solution Design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Adopting Docker as your application platform brings clear operational benefits.
    Containers are a much lighter unit of compute than virtual machines, but they
    still provide isolation, so you can run more workloads on less hardware. All these
    workloads have the same shape in Docker, so operations teams can manage .NET,
    Java, Go, and Node.js applications in the same way. The Docker platform also has
    benefits in application architecture. In this chapter, I'll look at how container-first
    solution design helps you add features to your application, with high quality
    and low risk.
  prefs: []
  type: TYPE_NORMAL
- en: I'll be returning to NerdDinner in this chapter, picking up from where I left
    off in [Chapter 3](ee527f27-ee07-40e1-a39d-86aa2d11da72.xhtml), *Developing Dockerized
    .NET Framework and .NET Core Applications*. NerdDinner is a traditional .NET application,
    a monolithic design with tight coupling between components in which all communication
    is synchronous. There is no unit testing, integration testing, or end-to-end testing.
    NerdDinner is like millions of other .NET apps—it may have the features the users
    need, but it's difficult and dangerous to modify. Moving apps like this to Docker
    lets you take a different approach to modifying or adding features.
  prefs: []
  type: TYPE_NORMAL
- en: Two aspects of the Docker platform will change the way you think about solution
    design. First, networking, service discovery, and load balancing means you can
    distribute applications across multiple components, each running in containers
    that can be moved, scaled, and upgraded independently. Second, the expanding range
    of production-grade software available on Docker Hub and other registries means
    you can use off-the-shelf software for many generic services and manage them in
    the same way as your own components. This gives you the freedom to design better
    solutions, without infrastructure or technology restrictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, I''ll show you how to modernize a traditional .NET application,
    by adopting container-first design:'
  prefs: []
  type: TYPE_NORMAL
- en: Design goals for NerdDinner
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running a message queue in Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Starting a multi-container solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modernizing legacy applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding new features in containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From monolith to distributed solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will need Docker running on Windows 10 with update 18.09, or Windows Server
    2019 to follow along with the examples. The code for this chapter is available at [https://github.com/sixeyed/docker-on-windows/tree/second-edition/ch05](https://github.com/sixeyed/docker-on-windows/tree/second-edition/ch05).
  prefs: []
  type: TYPE_NORMAL
- en: Design goals for NerdDinner
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 3](ee527f27-ee07-40e1-a39d-86aa2d11da72.xhtml), *Developing Dockerized
    .NET Framework and .NET Core Applications*, I extracted the NerdDinner home page
    into a separate component, which enabled the rapid delivery of UI changes. Now
    I'm going to make some more fundamental changes, breaking down the legacy application
    and modernizing the architecture.
  prefs: []
  type: TYPE_NORMAL
- en: I'll start by looking at a performance issue in the web application. The data
    layer in NerdDinner uses **Entity Framework** (**EF**), and all database access
    is synchronous. A lot of traffic to the site will create a lot of open connections
    to SQL Server and run a lot of queries. Performance will deteriorate as the load
    increases, to the point where queries time out or the connection pool is starved
    and the site will show errors to the users.
  prefs: []
  type: TYPE_NORMAL
- en: One way to improve this would be to make all the data-access methods `async`,
    but that's an invasive change—all the controller actions would need to be made
    `async` too, and there is no automated test suite to verify such a wholesale set
    of changes. Alternatively, I could add a cache for data retrieval so that `GET`
    requests would hit the cache and not the database. That's also a complex change,
    and I would need to cache data for long enough to make a cache hit likely while
    keeping the cache in sync when the data changed. Again, the lack of tests means
    complex changes such as this are hard to verify, so this is also a risky approach.
  prefs: []
  type: TYPE_NORMAL
- en: It would be hard to estimate the benefit if I did implement these complex changes.
    If all the data access moves to asynchronous methods, will that make the website
    run faster and enable it to handle more traffic? If I can integrate a cache that
    is efficient enough to take reads away from the database, will that improve the
    overall performance? These benefits are difficult to quantify until you've actually
    made the change, when you might find that the improvement doesn't justify the
    investment.
  prefs: []
  type: TYPE_NORMAL
- en: 'With a container-first approach, you can look at the design differently. If
    you identify one feature that makes expensive database calls but doesn''t need
    to run synchronously, you can move the database code to a separate component.
    Then you use asynchronous messaging between the components, publishing an event
    from the main web app to a message queue and acting on the event message in the
    new component. With Docker, each of these components will run in one or more containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/ddfe4194-1d38-4f65-b62d-874a61c97120.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If I focus on just one feature, then I can implement the change quickly. This
    design has none of the drawbacks of the other approaches, and it has a number
    of benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: It's a targeted change, and only one controller action changes in the main application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The new message handler component is small and highly cohesive, so it will be
    easy to test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The web layer and the data layer are decoupled, so they can be scaled independently
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I'm moving work away from the web application, so we can be sure of a performance
    improvement
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are other advantages too. The new component is completely independent
    of the original application; it just needs to listen for an event message and
    act on it. You can use .NET, .NET Core, or any other technology stack for the
    message handler; you don't need to be constrained to a single stack. You also
    have events that are being published from the app, so you have the option to add
    other features later by adding new handlers that listen for these events.
  prefs: []
  type: TYPE_NORMAL
- en: Dockerizing NerdDinner's configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: NerdDinner uses `Web.config` for configuration—both for application configuration
    values that are constant between releases and for environmental configuration
    values that change between different environments. The configuration file is baked
    into the release package, which makes it awkward to change. In [Chapter 3](ee527f27-ee07-40e1-a39d-86aa2d11da72.xhtml),
    *Developing Dockerized .NET Framework and .NET Core Applications*, I split the
    `appSettings` and the `connectionStrings` sections from `Web.config` into separate
    files; doing this lets me run a container with a different set of configurations,
    by attaching a volume containing different config files.
  prefs: []
  type: TYPE_NORMAL
- en: There are different types of configuration, though, and having to mount a volume
    is quite a heavy option for developers. It's good for feature settings that you
    want to toggle without changing code—settings like `UnobtrusiveJavaScriptEnabled`
    do belong in configuration files. But settings that change for every environment
    and every developer—like `BingMapsKey`—should have an easier way to set them.
  prefs: []
  type: TYPE_NORMAL
- en: Ideally you want multiple layers of configuration, reading from files but with
    the option to override values using environment variables. That's how the configuration
    system works in .NET Core, and because the configuration packages in .NET Core
    are actually .NET Standard libraries, they can be used in classic .NET Framework
    projects too.
  prefs: []
  type: TYPE_NORMAL
- en: 'In preparation for the bigger changes to come, I''ve updated the code for this
    chapter to use the .NET Core configuration model for all environment configuration
    settings, as shown in the following code. The previous files `appSettings.config`
    and `connectionStrings.config`, have been migrated to the new JSON configuration
    style in `appsettings.json`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The JSON format is easier to read, and because it contains nested objects, you
    can group similar settings together, which I've done with the `Apis` object. I
    can get the Bing Maps API key in my code by accessing the current config object
    with the key `Apis:BingMaps:Key`. I'm still storing the config file in a separate
    directory, so I can use a volume to override the whole file, but I've also set
    the configuration to use environment variables. This means that if an environment
    variable called `Apis:BingMaps:Key` is set, the value of that variable overrides
    the value in the JSON file. In my code, I just reference the configuration key,
    and at runtime, .NET Core fetches it from environment variables or the config
    file.
  prefs: []
  type: TYPE_NORMAL
- en: This approach lets me use default values for the database connection strings
    in the JSON file so that the app is usable when developers start the database
    and web containers without having to specify any environment variables. The app
    isn't 100% functional, though, because the API keys are needed for Bing Maps and
    the IP geolocation services. These are rate-limited services, so you are likely
    to have different keys for each developer and each environment, which can be set
    with environment variables in the web container.
  prefs: []
  type: TYPE_NORMAL
- en: 'To keep environment values safer, Docker lets you load them from a file rather
    than specifying them in plain text in the `docker container run` command. Isolating
    values in a file means that the file itself can be secured so that only administrators
    and the Docker service account can access it. The environment file is a simple-text
    format, with one line for each environment variable, written as a key-value pair.
    For the web container, my environment file contains the secret API keys:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: To run the container and load the file contents as environment variables, you
    can use the `--env-file` option.
  prefs: []
  type: TYPE_NORMAL
- en: Environment values still aren't secure. If someone gains access to your app,
    they could print out all the environment variables and get your API keys. The
    approach I'm using with a JSON file as well as environment variables means I can
    use the same application image in production with Docker secrets for configuration—and
    that is secure.
  prefs: []
  type: TYPE_NORMAL
- en: I've packaged those changes in a new version of the NerdDinner Docker image,
    which you can find at `dockeronwindows/ch05-nerd-dinner-web:2e`. Like the other
    examples from [Chapter 3](ee527f27-ee07-40e1-a39d-86aa2d11da72.xhtml), *Developing
    Dockerized .NET Framework and .NET Core Applications*, the Dockerfile uses a bootstrap
    script as the entry point, which promotes environment variables to the machine
    level so the ASP.NET application can read them.
  prefs: []
  type: TYPE_NORMAL
- en: 'The new version of the NerdDinner website runs in Docker with this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The application needs other components to be running for it to start correctly.
    I have a PowerShell script which starts containers in the right order with the
    right options, but by the end of the chapter this script will be unwieldy. I'll
    address that in the next chapter when I look at Docker Compose.
  prefs: []
  type: TYPE_NORMAL
- en: Splitting out the create dinner feature
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the `DinnerController` class the `Create` action is a relatively expensive
    database operation, which doesn't need to be synchronous. This feature is a good
    candidate for splitting into a separate component. I can publish a message from
    the web app instead of saving it to the database while the user waits—if the site
    is experiencing a high load, the message may wait in the queue for seconds or
    even minutes before being processed, but the response back to the user will be
    almost instant.
  prefs: []
  type: TYPE_NORMAL
- en: There are two pieces of work that need to be done to split the feature into
    a new component. The web application needs to publish a message to a queue when
    a dinner is created, and a message handler needs to listen on the queue and save
    the dinner when it receives a message. In NerdDinner, there's a bit more work
    to do because the existing code base is a physical monolith as well as a logical
    monolith—there's just one Visual Studio project that contains everything, all
    the model definitions as well as the UI code.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter's source code, I've added a new .NET assembly project called
    `NerdDinner.Model` to the solution and moved the EF classes to that project so
    that they can be shared between the web app and the message handler. The model
    project targets the full .NET Framework rather than the .NET Core, so I can use
    the existing code as it is and I don't need to bring an upgrade of EF into scope
    for this feature change. This choice restricts the message handler to being a
    full .NET Framework application too.
  prefs: []
  type: TYPE_NORMAL
- en: There's also a shared assembly project to isolate the message queue code in
    `NerdDinner.Messaging`. I'll be using the NATS message system, which is a high-performance
    open source message queue. There is a NATS client package on NuGet that targets
    .NET Standard, so it can be used in both .NET Framework and .NET Core, and my
    messaging project has the same client package. This means that I can be flexible
    so that other message handlers that don't use the EF model could be written in
    .NET Core.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the model project, the original definition of the `Dinner` class is polluted
    with a lot of EF and MVC code to capture validation and storage behavior, like
    the following definition for the `Description` property:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The class should be a simple POCO definition, but these attributes mean that
    the model definition is not portable because any consumers also need to reference
    EF and MVC. To avoid this in the messaging project, I have defined a simple `Dinner`
    entity without any of these attributes, and that class is the one I use to send
    dinner information in the messages. I can use the `AutoMapper` NuGet package to
    convert between `Dinner` class definitions, as the properties are fundamentally
    the same.
  prefs: []
  type: TYPE_NORMAL
- en: This is the sort of challenge you will find in lots of older projects—there's
    no clear separation of concerns, so breaking out features is not straightforward.
    You can take this approach to isolate shared components into new library projects.
    This is restructuring the code base without fundamentally changing its logic,
    which will help with modernizing the app.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main code in the `Create` method of the `DinnersController` class now maps
    the dinner model to the clean `Dinner` entity and publishes an event instead of
    writing to the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This is the fire-and-forget messaging pattern. The web application is the producer,
    publishing an event message. The producer doesn't wait for a response and doesn't
    know which components—if any—will consume the message and act on it. It's loosely
    coupled and fast, and it puts the responsibility to deliver the message on to
    the message queue, which is where it should be.
  prefs: []
  type: TYPE_NORMAL
- en: 'Listening for this event message is a new .NET Framework console project in
    `NerdDinner.MessageHandlers.CreateDinner`. The `Main` method of the console app
    uses the shared messaging project to open a connection to the message queue and
    subscribe to these dinner-created event messages. When a message is received,
    the handler maps the `Dinner` entity in the message back to a dinner model and
    saves the model to the database using code taken from the original implementation
    in the `DinnersController` class (and tidied up a little):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Now the message handler can be packaged into its own Docker image and run in
    a container alongside the website container.
  prefs: []
  type: TYPE_NORMAL
- en: Packaging .NET console apps in Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Console apps are easy to build as good citizens for Docker. The compiled executable
    for the app will be the main process that Docker starts and monitors, so you just
    need to make use of the console for logging and you can use files and environment
    variables for configuration.
  prefs: []
  type: TYPE_NORMAL
- en: For my message handler, I'm using a Dockerfile with a slightly different pattern.
    I have a separate image for the builder stage that I use to compile the whole
    solution—both the web project and the new projects I've added. I'll walk through
    the builder image later in the chapter once you've seen all the new components.
  prefs: []
  type: TYPE_NORMAL
- en: 'The builder compiles the solution and the Dockerfile for the console application
    references the `dockeronwindows/ch05-nerd-dinner-builder:2e` image to copy out
    the compiled binaries. The whole Dockerfile is very simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The `from` argument in the `COPY` instruction specifies the source of the files.
    It can be another stage in a multistage build, or—as in this example—an existing
    image on the local machine or a registry.
  prefs: []
  type: TYPE_NORMAL
- en: The new message handler needs to access the message queue and the database,
    and the connection strings for each are captured in the project's `appsettings.json`
    file. The console app uses the same `Config` class as the NerdDinner web app,
    which loads default values from the JSON file and can override them from environment
    variables.
  prefs: []
  type: TYPE_NORMAL
- en: In the Dockerfile, the entry point in the `CMD` instruction is the console executable,
    so the container will keep running as long as the console app is running. The
    listener for the message queue runs asynchronously on a separate thread to the
    main application. The handler code will fire when a message is received, so there's
    no polling of the queue, and the app runs very efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: 'Keeping the console app running indefinitely is straightforward using a `ManualResetEvent`
    object. In the `Main` method, I wait for a reset event that never happens, so
    the program keeps running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This is a simple and efficient way of keeping a .NET Framework or a .NET Core
    console app alive. When I start a message handler container, it will keep running
    in the background and listen for messages until the container is stopped.
  prefs: []
  type: TYPE_NORMAL
- en: Running a message queue in Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The web application now publishes messages, and a handler listens for them,
    so the final component I need is a message queue to connect the two. Queues need
    the same level of availability as the rest of the solution, so they're good candidates
    for running in Docker containers. In a distributed solution that is deployed on
    many servers, the queue can be clustered across multiple containers for performance
    and redundancy.
  prefs: []
  type: TYPE_NORMAL
- en: Your choice of messaging technology depends on the features you need, but there
    are plenty of options with .NET client libraries. **Microsoft Message Queue**
    (**MSMQ**) is the native Windows queue, **RabbitMQ** is a popular open source
    queue that supports durable messaging, and **NATS** is an open source in-memory
    queue that is hugely performant.
  prefs: []
  type: TYPE_NORMAL
- en: The high throughput and low latency of NATS messaging makes it a good choice
    to communicate between containers, and there is an official image for NATS on
    Docker Hub. NATS is a Go application that runs cross platform, and there are Linux,
    Windows Server Core, and Nano Server variants of the Docker image.
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing, the NATS team only had images for Windows Server 2016
    published on Docker Hub. There will be a Windows Server 2019 image soon, but I've
    built my own for this chapter. Look at the Dockerfile for `dockeronwindows/ch05-nats:2e`
    and you'll see how easy it is to use the content from an official image in one
    of your own images.
  prefs: []
  type: TYPE_NORMAL
- en: 'You run the NATS message queue like any other container. The Docker images
    exposes port `4222`, which is the port that clients use to connect to the queue,
    but you don''t need to publish that port unless you want to send messages to NATS
    outside a Docker container. Containers in the same network can always access one
    another''s ports, and they only need to be published to make them available outside
    Docker. The NerdDinner web app and message handler are using the server name `message-queue`
    to connect to NATS, so that needs to be the container name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The NATS server application logs messages to the console so that the log entries
    are collected by Docker. When the container is running, you can verify that the
    queue is listening using `docker container logs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The message queue is an infrastructure-level component with no dependencies
    on other components. It can be started before other containers and left running
    when application containers are stopped or upgraded.
  prefs: []
  type: TYPE_NORMAL
- en: Starting a multi-container solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you make more use of Docker, your solution will become distributed across
    more containers—either running custom code that you split out from a monolith
    or tried and trusted third-party software from Docker Hub or a third-party registry.
  prefs: []
  type: TYPE_NORMAL
- en: NerdDinner now runs across five containers—SQL Server, the original web app,
    the new homepage, the NATS message queue, and the message handler. There are dependencies
    between the containers, and they need to be started in the correct order and created
    with the correct names so that components can be found using Docker's service
    discovery.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, I''ll use Docker Compose to declaratively map out these
    dependencies. For now, I have a PowerShell script called `ch05-run-nerd-dinner_part-1.ps1` that
    explicitly starts the containers with the correct configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In this script I'm using the SQL database and home page images from [Chapter
    3](ee527f27-ee07-40e1-a39d-86aa2d11da72.xhtml), *Developing Dockerized .NET Framework
    and .NET Core Applications*—these components haven't changed, so they can be run
    alongside the new components. If you want to run this yourself with full functionality,
    you will need to populate your own API keys in the file `api-keys.env`. You'll
    need to sign up to the Bing Maps API and the IP information database. You can
    run the app without those keys, but not all features will work correctly.
  prefs: []
  type: TYPE_NORMAL
- en: 'When I run the script with my own API keys set and inspect the web container
    to get the port, I can browse to the application. It''s a fully featured version
    of NerdDinner now. I can log in and complete the create dinner form, complete
    with map integration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/68a1f0a6-8a3f-42ff-b0e0-aeb43fe1b36e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'When I submit the form, the web app publishes an event message to the queue.
    That is a very cheap operation, so the web app returns to the user almost immediately.
    Listening for messages is the console application, running in a different container—potentially
    on a different host. It picks up the message and processes it. The handler logs
    the activity to the console so that admin users can monitor it using `docker container
    logs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The functionality of the create dinner feature is the same—data entered by the
    user is saved to SQL Server—and the user experience is the same, but the scalability
    of this feature is massively improved. Designing for containers lets me extract
    the persistence code into a new component, knowing the component can be deployed
    on the same infrastructure as the existing solution and that it will inherit the
    existing levels of scalability and failover, if the application is deployed on
    a cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'I can rely on the Docker platform and take a dependency on a new core component:
    the message queue. The queue technology itself is enterprise-grade software, capable
    of processing hundreds of thousands of messages per second. NATS is free open
    source software that is available on Docker Hub to drop straight into your solution,
    running as a container and connected to other containers in the Docker network.'
  prefs: []
  type: TYPE_NORMAL
- en: So far I've used the container-first design and the power of Docker to modernize
    one part of NerdDinner. Targeting a single feature means I can release this new
    version confidently, after testing only the feature that's changed. If I wanted
    to add auditing to the create dinner feature, I would just make an update to the
    message handler, and I wouldn't need to do a full regression test of the web application,
    because that component is not going to be updated.
  prefs: []
  type: TYPE_NORMAL
- en: Designing with containers in mind also gives me a foundation to modernize the
    architecture of my legacy app and to add new features.
  prefs: []
  type: TYPE_NORMAL
- en: Modernizing legacy applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Breaking out backend features is a great way to start decomposing legacy monoliths.
    Adding a message queue to your deployment makes this a pattern you can repeat
    with any feature that would benefit from being asynchronous. There are other patterns
    for breaking down monolithic apps. We can really start to modernize NerdDinner
    if we expose a REST API and move to a modular UI for the frontend, with a reverse
    proxy to route between different components. We can do all of this with Docker.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a REST API to expose data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Legacy apps often end up as stores of data that can't be accessed outside the
    app. The data would be valuable to other applications or to business partners
    if it was accessible. NerdDinner is a good example—it was designed and built before
    the age of Single Page Apps, where the UI is logic is separated from the business
    logic, which is exposed through a REST API. NerdDinner keeps its data to itself;
    you can't see a list of dinners unless you go through the NerdDinner UI.
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s easy to unlock legacy data with a simple REST API running in a Docker
    container. It doesn''t need to be a complex delivery: you can start by identifying
    a single dataset in the legacy app, which is useful for other business units or
    external consumers. Then, simply extract the loading logic for that dataset into
    a separate feature and deploy it as a read-only API in a container. You can iteratively
    add more features to the API when you have the demand, you don''t need to implement
    the whole service catalogue for your first release.'
  prefs: []
  type: TYPE_NORMAL
- en: The main dataset in NerdDinner is the list of dinners, and I've built an ASP.NET
    Core REST API to expose all the dinners in a read-only `GET` request. The code
    is in the `NerdDinner.DinnerApi` project for this chapter, and it's a very simple
    implementation. Because I've already split the core entity definitions out from
    the main `NerdDinner` project, I can expose the existing contract from the API
    and use whatever data access technology I like inside the project.
  prefs: []
  type: TYPE_NORMAL
- en: 'I''ve chosen to use Dapper, which is a fast and intuitive object-relational
    mapper built for .NET Standard, so it works with .NET Framework and .NET Core
    apps. Dapper uses convention-based mapping; you provide a SQL statement and a
    target class type and it executes the database query and maps the results to objects.
    The code to load the dinner data from the existing table and map it to the shared
    `Dinner` object is quite straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The `GetAll` method is called in the API controller class, and the rest of the
    code is the usual ASP.NET Core setup.
  prefs: []
  type: TYPE_NORMAL
- en: Dapper is usually much easier to work with than this example, but it lets you
    do some manual mapping when you need to, which is what I've done here. NerdDinner
    uses an SQL Server location data type to store where dinners are taking place.
    This maps to a .NET `DbGeography` type, but that type doesn't exist in .NET Standard.
    If you look through the code in `Chapter 5`, you'll see a few places where I map
    between `DbGeography` and my custom `Coordinates` types, which is what you'll
    need to do if you have a similar issue.
  prefs: []
  type: TYPE_NORMAL
- en: 'I''ve changed the original NerdDinner web app to use this new API when it fetches
    the list of dinners in the `DinnersController` class. I''m using a feature flag
    through the configuration setting `DinnerApi:Enabled` so that the app can either
    use the API as the data source, or query from the database directly. This lets
    me do a staged roll-out of the feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The new API gets packaged into the Docker image named `dockeronwindows/ch05-nerd-dinner-api`.
    The Dockerfile for this is very simple; it just starts from the official ASP.NET
    Core base image called `microsoft/dotnet:2.1-aspnetcore-runtime-nanoserver-1809`
    and copies in the compiled API code.
  prefs: []
  type: TYPE_NORMAL
- en: I could run the API in a Docker container as an internal component, used by
    the NerdDinner web container but not publicly accessible, or I could publish a
    port on the API container and make it available outside the Docker network. It
    would be unusual to have a custom port for a public REST API, where consumers
    expect to access it on port `80` for HTTP and port `443` for HTTPS. I can add
    one more component to my solution that lets me use the standard set of ports for
    all my services and route incoming requests to different containers—that is called
    a **reverse proxy**.
  prefs: []
  type: TYPE_NORMAL
- en: Routing HTTP requests between containers with a reverse proxy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A reverse proxy is a very useful piece of technology to add to your project,
    whether you're looking at building a new microservices architecture or modernizing
    a legacy monolith. The reverse proxy is just an HTTP server that receives all
    the incoming web traffic from the outside world, fetches content from another
    HTTP server, and returns it to the client. In Docker the reverse proxy runs in
    a container with published ports, and it proxies traffic from other containers,
    which do not have any published ports.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the architecture of the UI and API containers with the reverse proxy
    in place:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/c25f793f-b5b8-4a2c-99da-5fe28361943e.png)'
  prefs: []
  type: TYPE_IMG
- en: All the routing rules for incoming traffic are in the proxy container. It will
    be configured to load requests for the home page location `/` from the `nerd-dinner-homepage`
    container; requests that start with the path `/api` will be loaded from the `nerd-dinner-api`
    container, and any other requests will be loaded from the original app in the
    `nerd-dinner-web` container.
  prefs: []
  type: TYPE_NORMAL
- en: It's important to realize that the proxy does not redirect the client to these
    other services. The proxy is the only endpoint that the client connects to. The
    proxy makes HTTP requests to the actual service on the client's behalf, using
    the containers' host names.
  prefs: []
  type: TYPE_NORMAL
- en: Reverse proxies can do a lot more than routing requests. All traffic passes
    through the reverse proxy, so it can be the layer where you apply SSL termination
    and HTTP caching. You can even build security into your reverse proxy, using it
    for authentication and as a web application firewall, protecting you from common
    attacks like SQL injection. This is especially attractive for legacy applications.
    You can make performance and security improvements in the proxy layer, leaving
    the original app as an internal component in a container that can't be reached
    except through the proxy.
  prefs: []
  type: TYPE_NORMAL
- en: There are many technology options for the reverse proxy. Nginx and HAProxy are
    popular options in the Linux world, and they can also be used in Windows containers.
    You can even implement IIS as a reverse proxy, running it in a separate container
    with all the routing rules set up using the URL rewrite module. These options
    are powerful, but need quite a lot of configuration to get up and running. I'm
    going to use a reverse proxy called **Traefik**, which was built to run in a container
    in cloud-native applications, and it gets the configuration it needs from Docker.
  prefs: []
  type: TYPE_NORMAL
- en: Proxying traffic from Docker containers with Traefik
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Traefik is a fast, powerful, and easy-to-use reverse proxy. You run it in a
    container and publish the HTTP (or HTTPS) port, and configure the container to
    listen for events from the Docker Engine API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Traefik is an official image on Docker Hub, but just like NATS the only Windows
    images available are based on Windows Server 2016\. I'm using my own image here,
    based on Windows Server 2019\. The Dockerfile is in my `sixeyed/dockerfiles-windows`
    repository on GitHub, but you should check Docker Hub to see whether there's a
    2019 variant of the official Traefik image before you use mine.
  prefs: []
  type: TYPE_NORMAL
- en: You've seen the `volume` option before - it's used to mount a filesystem directory
    on the host into the container. Her, I'm using it to mount a Windows **named pipe**,
    called `docker_engine`. Pipes are a networking approach for client-server communication.
    The Docker CLI and Docker API support connections over both TCP/IP and named pipes.
    Mounting a pipe like this lets a container query the Docker API without needing
    to know the IP address of the host where the container is running.
  prefs: []
  type: TYPE_NORMAL
- en: Traefik subscribes to the event stream from the Docker API with the named pipe
    connection, using the connection details in the `docker.endpoint` option. It will
    get notifications from Docker when containers are created or removed, and Traefik
    uses the data in those events to build its own routing map.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you have Traefik running, you create your application containers with
    labels to tell Traefik which requests should be routed to which containers. Labels
    are just key-value pairs that can be applied to containers when you create them.
    They are surfaced in the event stream from Docker. Traefik uses labels with the
    prefix `traefik.frontend` to build its routing rules. This is how I run the API
    container with routing by Traefik:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Docker creates the container called `nerd-dinner-api` and then publishes an
    event with the new container's details. Traefik gets that event, and adds a rule
    to its routing map. Any requests that come into Traefik with the HTTP `Host` header
    `api.nerddinner.local` will be proxied from the API container. The API container
    does not publish any ports - the reverse proxy is the only publicly accessible
    component.
  prefs: []
  type: TYPE_NORMAL
- en: Traefik has a very rich set of routing rules, using different parts of the HTTP
    request—the host, path, headers, and query string. You can map anything from wildcard
    strings to very specific URLs using Traefik's rules. There's much more that Traefik
    can do too, like load balancing and SSL termination. The documentation can be
    found at [https://traefik.io](https://traefik.io).
  prefs: []
  type: TYPE_NORMAL
- en: 'Using similar rules I can deploy the new version of NerdDinner and have all
    the frontend containers proxied by Traefik. The script `ch05-run-nerd-dinner_part-2.ps1`
    is an upgrade that removes the existing web containers first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Labels and environment variables are applied when a container is created, and
    they last for the life of the container. You can''t change those values on an
    existing container; you need to remove it and create a new one. I want to run
    the NerdDinner web and home page containers with labels for Traefik, so I need
    to replace the existing containers. The rest of the script starts Traefik, replaces
    the web containers with a new configuration, and starts the API container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now when I load the NerdDinner website, I''ll browse to the Traefik container
    on port `80`. I''m using `Host` header routing rules, so I''ll be putting `http://nerddinner.local`
    into my browser. This is a local development environment, so I''ve added these
    values to my `hosts` file (in test and production environments, there would be
    a real DNS system resolving the host names):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The home page request for the path `/` gets proxied from the home page container,
    and I also have a routing path specified for the CSS file so that I see the new
    home page complete with styling:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/a2acc8e6-3888-4052-b7ee-991a945b7e29.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This response is generated by the home page container, but proxied by Traefik.
    I can browse to `api.nerddinner.local` and see the all the dinners in JSON format
    from the new REST API container:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/7c905e8a-1c7a-402a-87be-8afb6fa9c156.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The original NerdDinner app still works in the same way, but when I browse
    to `/Dinners`, the list of dinners to display is fetched from the API instead
    of the database directly:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/4c9a8b38-967c-4e76-921a-b5f648d91eb8.png)'
  prefs: []
  type: TYPE_IMG
- en: Working out the routing rules for the proxy is one of the harder parts of breaking
    up a monolith into multiple frontend containers. Microservice apps tend to be
    easier here, because they're designed to be different concerns running at different
    domain paths. You'll need a good understanding of Traefik's rules and of regular
    expressions when you start routing UI features to their own containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Container-first design has let me modernize the architecture of NerdDinner
    without a complete rewrite. I''m using enterprise-grade open source software and
    Docker to power the following three patterns for breaking up the monolith:'
  prefs: []
  type: TYPE_NORMAL
- en: Making features asynchronous by publishing and subscribing to events on a message
    queue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exposing data with REST APIs, using a simple modern technology stack
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Splitting frontend features across multiple containers and routing between them
    with a reverse proxy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now I can be far more agile about delivering improvements to features because
    I won't always need to regression test the full application. I also have events
    that are published from key user activities, which is a step towards event-driven
    architecture. This lets me add completely new features without changing any existing
    code.
  prefs: []
  type: TYPE_NORMAL
- en: Adding new features in containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Breaking down a monolith into small components and modernizing the architecture
    has a beneficial side effect. The approach I've taken has introduced event publishing
    for one feature. I can build on that to add new features, again taking a container-first
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: In NerdDinner there is a single data store, a transactional database stored
    in SQL Server. That's fine for servicing the website, but it's limited when it
    comes to user-facing features, such as reporting. There's no user-friendly way
    to search the data, build dashboards, or enable self-service reporting.
  prefs: []
  type: TYPE_NORMAL
- en: An ideal solution to this would be to add a secondary data store, a reporting
    database, using a technology that does provide self-service analytics. Without
    Docker, that would be a major project, needing a redesign or additional infrastructure
    or both. With Docker, I can leave the existing application alone and add new features
    running in containers on the existing servers.
  prefs: []
  type: TYPE_NORMAL
- en: Elasticsearch is another enterprise-grade open source project which is available
    as an official image on Docker Hub. Elasticsearch is a full search document data
    store that works well as a reporting database, along with the companion product
    Kibana, which provides a user-friendly web frontend.
  prefs: []
  type: TYPE_NORMAL
- en: I can add self-service analytics for the dinners created in NerdDinner by running
    Elasticsearch and Kibana in containers in the same network as the other containers.
    The current solution already publishes events with dinner details, so to add dinners
    to the reporting database, I need to build a new message handler that subscribes
    to the existing events and saves the details in Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: When the new reporting feature is ready, it can be deployed to production without
    any changes to the running application. Zero-downtime deployment is another benefit
    of container-first design. Features are built to run in decoupled units, so individual
    containers can be started or upgraded without affecting other containers.
  prefs: []
  type: TYPE_NORMAL
- en: For the next feature, I'll add a new message handler that is independent of
    the rest of the solution. If I needed to replace the implementation of the save-dinner
    handler, I could also do that with zero-downtime, using the message queue to buffer
    events while replacing the handler.
  prefs: []
  type: TYPE_NORMAL
- en: Using Elasticsearch with Docker and .NET
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Elasticsearch is such a widely useful technology that it's worth looking at
    in a little detail. It's a Java application, but running in Docker, you can treat
    it as a black box and manage it in the same way as all other Docker workloads—you
    don't need to install Java or configure the JDK. Elasticsearch exposes a REST
    API for writing, reading, and searching data, and there are client wrappers for
    the API available in all major languages.
  prefs: []
  type: TYPE_NORMAL
- en: Data in Elasticsearch is stored as JSON documents, and every document can be
    fully indexed so that you can search for any value in any field. It's a clustered
    technology that can run across many nodes for scale and resilience. In Docker,
    you can run each node in a separate container and distribute them across your
    server estate to gain scale and resilience, but with the ease of deployment and
    management you get with Docker.
  prefs: []
  type: TYPE_NORMAL
- en: The same storage considerations apply to Elasticsearch as they do to any stateful
    workload—in development, you can save data inside the container so that when the
    container is replaced, you start with a fresh database. In test environments,
    you can use a Docker volume mounted to a drive folder on the host to keep persistent
    storage outside the container. In production, you can use a volume with a driver
    for an on-premises storage array or a cloud-storage service.
  prefs: []
  type: TYPE_NORMAL
- en: 'There''s an official Elasticsearch image on Docker Hub, but it currently has
    only Linux variants. I have my own image on Docker Hub which packages Elasticsearch
    into a Windows Server 2019 Docker image. Running Elasticsearch in Docker is the
    same as starting any container. This command exposes port `9200`, which is the
    default port for the REST API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Elasticsearch is a memory-hungry application, and by default it allocates 2
    GB of system memory when it starts. In a development environment, I don't need
    that much memory for the database. I can configure this by setting the `ES_JAVA_OPTS`
    environment variable. In this command, I limit Elasticsearch to 512 MB of memory.
  prefs: []
  type: TYPE_NORMAL
- en: Elasticsearch is a cross-platform application, like NATS. There is no official
    Elasticsearch image for Windows, but you can check my Dockerfile on GitHub in
    the repository `sixeyed/dockerfiles-windows`. You'll see that I use the official
    OpenJDK Java image based on Windows Server Core 2019 for my Elasticsearch image.
  prefs: []
  type: TYPE_NORMAL
- en: There is a NuGet package for Elasticsearch called **NEST**, which is an API
    client for reading and writing data, and is targeted for the .NET Framework and
    .NET Core. I use this package in a new .NET Core console project, `NerdDinner.MessageHandlers.IndexDinner`.
    The new console app listens for the dinner-created event message from NATS and
    writes the dinner details as a document in Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code to connect to the message queue and subscribe to messages is the same
    as the existing message handler. I have a new `Dinner` class, which represents
    the Elasticsearch document, so that the message handler code maps from the `Dinner`
    entity to the dinner document and saves it in Elasticsearch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Elasticsearch will run in a container, and the new document message handler
    will run in a container, all in the same Docker network as the rest of the NerdDinner
    solution. I can start the new containers while the existing solution is running,
    as there are no changes to the web application or the SQL Server message handler.
    Adding this new feature with Docker is a zero-downtime deployment.
  prefs: []
  type: TYPE_NORMAL
- en: The Elasticsearch message handler has no dependency on EF or any of the legacy
    code, just like the new REST API. I've taken advantage of this to write those
    apps in .NET Core, which gives me the freedom to run them in a Docker container
    on Linux or Windows hosts. My Visual Studio solution now has .NET Framework, .NET
    Standard, and .NET Core projects. Parts of the codebase are shared between the
    .NET Framework and .NET Core application projects. I can use multistage builds
    for each application Dockerfile, but that could cause problems in larger projects.
  prefs: []
  type: TYPE_NORMAL
- en: Large .NET codebases tend to have a multi-solution approach, with a master solution
    containing all the projects used in the CI server, and different `.sln` files
    for each area of the application, which each have a subset of projects. This lets
    different teams work on their part of the codebase without every developer having
    to load millions of lines of code into Visual Studio. It saves a lot of developer
    time, but it does introduce the risk that changes to a shared component can break
    another team's build.
  prefs: []
  type: TYPE_NORMAL
- en: If you move to multi-stage builds for all your components, you could still have
    this problem when you move to Docker. In that case, you can use an alternative
    approach where you build all the code in a single Dockerfile, much like the old
    master solution for Visual Studio.
  prefs: []
  type: TYPE_NORMAL
- en: Building hybrid .NET Framework and .NET Core solutions in Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The multistage builds you've seen up until now have all used the `microsoft/dotnet-framework:4.7.2-sdk`
    image or the `microsoft/dotnet:2.2-sdk` image on Docker Hub. These images provide
    the relevant .NET runtime, together with the SDK components to restore packages,
    compile source code, and publish applications.
  prefs: []
  type: TYPE_NORMAL
- en: The .NET Framework 4.7.2 image also contains the .NET Core 2.1 SDK, so if you're
    using those versions (or earlier), then you can build both .NET Framework and
    .NET Core apps in the same Dockerfile.
  prefs: []
  type: TYPE_NORMAL
- en: In the first edition of this book, there was no official image that had both
    the .NET Framework and .NET Core SDKs, so I showed you how to build your own using
    quite a complex Dockerfile with lots of Chocolatey installs. I also wrote, "*I
    expect later releases of MSBuild and .NET Core will have integrated tooling, so
    the complexity of managing multiple toolchains will go away," *and I'm glad to
    say that's where we are right now, with Microsoft managing those toolchains in
    Docker for us.
  prefs: []
  type: TYPE_NORMAL
- en: Compiling the hybrid NerdDinner solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I'm taking a different approach to building NerdDinner in this chapter, one
    that fits nicely with a CI process if you're mixing .NET Core and .NET Framework
    projects (I cover CI and CD with Docker in [Chapter 10](e0946741-5df7-4a13-b220-ffc963f1e3d3.xhtml),
    *Powering a Continuous Deployment Pipeline with Docker*). I'll compile the whole
    solution in one image and use that image as the source for the binaries in my
    application Dockerfiles.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows how the SDK and builder images are used to package
    the application images for this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/747a90e4-03ad-417c-ab18-06b37344e7ef.png)'
  prefs: []
  type: TYPE_IMG
- en: 'All the tools I need to build the solution are in Microsoft''s SDK, so the
    Dockerfile for `dockeronwindows/ch05-nerd-dinner-builder:2e` is straightforward.
    It starts from the SDK, copies in the source tree for the solution, and restores
    dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This runs `nuget restore` for the NerdDinner solution file. This restores all
    the .NET Framework, .NET Standard, and .NET Core references for all the projects.
    The last instruction builds each of the application projects, specifying the project
    file and a separate output path for each of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: You can just run `msbuild` for the whole solution file, but this produces the
    compiled binaries and not the fully publish directories. This approach means that
    each app is published ready to be packaged, and the output is in a known location
    in the builder image. It also means that the whole application is compiled from
    the same set of source code, so you will find any breaking issues with dependencies
    between applications.
  prefs: []
  type: TYPE_NORMAL
- en: The disadvantage of this approach is that it doesn't make smart use of the Docker
    cache. The whole source tree is copied into the image as the first step. Whenever
    there is a code change, the build will update the packages, even if the package
    references haven't changed. You could write this builder differently, copying
    in the `.sln`, `.csproj` and `package.config` files first for the restore phase,
    and then copying in the rest of the source for the build phase.
  prefs: []
  type: TYPE_NORMAL
- en: That would give you package caching and a faster build, at the cost of a more
    brittle Dockerfile—you'd need to edit the initial file list every time you added
    or removed a project.
  prefs: []
  type: TYPE_NORMAL
- en: You can choose the approach that works best with your processes. In the case
    of a more complex solution than this, developers may build and run the app from
    Visual Studio and only build the Docker images to run tests before checking in
    the code. In this case, the slower Docker image build is not an issue (I discuss
    the options for running your application in Docker while you're developing it
    in [Chapter 11](d8929de7-3bbe-48ed-b755-5e918f048bd9.xhtml), *Debugging and Instrumenting
    Application Containers*).
  prefs: []
  type: TYPE_NORMAL
- en: 'One thing is different regarding how this image is built. The Dockerfile copies
    in the `src` folder, which is one level higher than the folder where the Dockerfile
    lives. To make sure the `src` folder is included in the Docker context, I need
    to run the `build image` command from the `ch05` folder and specify the path to
    the Dockerfile with the `--file` option:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Building the image compiles and packages all the projects, so I can use that
    image as the source for the published output in the application Dockerfiles. I
    need to build the builder only once, and then I can use it to build all the other
    images.
  prefs: []
  type: TYPE_NORMAL
- en: Packaging .NET Core console apps in Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 3](ee527f27-ee07-40e1-a39d-86aa2d11da72.xhtml), *Developing Dockerized
    .NET Framework and .NET Core Applications*, I built the replacement NerdDinner
    home page as an ASP.NET Core web application, and in this chapter, I have the
    REST API and the Elasticsearch message handler as .NET Core applications. These
    can be packaged as Docker images, using variants of the `microsoft/dotnet` image
    on Docker Hub.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Dockerfile for the REST API `dockeronwindows/ch05-nerd-dinner-api:2e` is
    very simple: it just sets up the container environment and then copies in the
    published application from the builder image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The Dockerfile for the message handler `dockeronwindows/ch05-nerd-dinner-index-handler:2e`
    is even simpler—this is a .NET Core console app, so there are no ports to expose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The content is very similar to the .NET Framework console app used for the SQL
    Server message handler. The differences are the `FROM` image; here, I'm using
    the .NET Core runtime image and the `CMD` instruction, and here it's the `dotnet`
    command that is running the console application DLL. Both the message handlers
    use the builder image as the source for copying the compiled application, and
    then set up the environment variables and startup commands they need.
  prefs: []
  type: TYPE_NORMAL
- en: Both the .NET Core applications are bundled with default configuration values
    in `appsettings.json`, which can be overridden at container runtime using environment
    variables. These capture the URLs for the message queue and the Elasticsearch
    API, and the connection string for the SQL Server database. The startup command
    runs the .NET Core application. ASP.NET Core apps continue running in the foreground
    until the application is stopped. The .NET Core console app for the message handler
    stays alive in the foreground with a `ManualResetEvent` object. Both write log
    entries to the console, so they integrate well with Docker.
  prefs: []
  type: TYPE_NORMAL
- en: When the index handler application runs, it will listen for messages from NATS,
    with the dinner-created message subject. When events are published from the web
    application, NATS will send copies to every subscriber, so the SQL Server save
    handler and the Elasticsearch index handler will both get copies of the event.
    The event message contains enough detail for both handlers to operate. If a future
    feature requires more detail, then the web app can publish a new version of the
    event with additional information, but the existing message handlers will not
    need to change.
  prefs: []
  type: TYPE_NORMAL
- en: Running another container with Kibana will complete this feature and add self-service
    analytics to NerdDinner.
  prefs: []
  type: TYPE_NORMAL
- en: Providing analytics with Kibana
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kibana is an open source web frontend for Elasticsearch that gives you visualizations
    for analytics and the ability to search for specific data. It's produced by the
    company behind Elasticsearch and is very widely used because it provides a user-friendly
    way to navigate huge quantities of data. You can explore the data interactively,
    and power users can build comprehensive dashboards to share with others.
  prefs: []
  type: TYPE_NORMAL
- en: 'The latest version of Kibana is a Node.js application, so like Elasticsearch
    and NATS, it''s a cross-platform application. There''s an official image on Docker
    Hub with Linux and variants, and I''ve packaged my own image based on Windows
    Server 2019\. The Kibana image is built using the same convention-based approach
    that I''ve used in the message handlers: it expects to connect to a container
    called `elasticsearch` on the default API port `9200`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the source code directory for this chapter, there is a second PowerShell
    script that deploys the containers for this feature. The fine named `ch05-run-nerd-dinner_part-3.ps1`
    starts the additional Elasticsearch, Kibana, and index handler containers, and
    it assumes that the other components are already running from the part-1 and part-2
    scripts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The Kibana container is labelled with Traefik's frontend rules. By default,
    Kibana listens on port `5601`, but in my setup, I'll be able to reach it on port
    `80` using the `kibana.nerddinner.local` domain, which I've added to my `hosts`
    file, and Traefik will proxy the UI.
  prefs: []
  type: TYPE_NORMAL
- en: 'The full stack is running now. When I add a new dinner, I will see the logs
    from the message handler containers showing that the data is now being saved to
    Elasticsearch, as well as to the SQL Server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Kibana is being proxied by Traefik, so I just need to browse to `kibana.nerddinner.local`.
    The only configuration the launch-screen needs is the name of the document collection,
    which Elasticsearch calls an index. In this case, the index is called **dinners**.
    I''ve already added a document with the message handler so that Kibana can access
    the Elasticsearch metadata to determine the fields in the documents:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/e12648b2-f748-4981-a941-a9ca1de192e9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Every dinner created will now be saved in the original transactional database
    SQL Server, and also in the new reporting database, Elasticsearch. Users can create
    visualizations over aggregated data, looking for patterns in popular times or
    locations, and they can search for particular dinner details and retrieve specific
    documents:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/7f7fed5f-7a23-4f37-bbea-8747c53e1135.png)Elasticsearch and Kibana
    are hugely capable software systems. Docker has made them accessible to a whole
    new set of users. I won''t cover them in any further detail in this book, but
    they are popular components with a lot of online resources, that you can search
    for, if you want to learn more.'
  prefs: []
  type: TYPE_NORMAL
- en: From monolith to distributed solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: NerdDinner has evolved from a legacy monolith to an easily scalable, easily
    extensible solution running on a modern application platform using modern design
    patterns. It's been a fast and low-risk evolution, powered by the Docker platform
    and container-first design.
  prefs: []
  type: TYPE_NORMAL
- en: 'The project started by migrating NerdDinner to Docker as-is, running one container
    for the web application and one for the SQL Server database. Now I have ten components
    running in containers. Five are running my custom code:'
  prefs: []
  type: TYPE_NORMAL
- en: The original ASP.NET NerdDinner web application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The new ASP.NET Core web homepage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The new .NET Framework save-dinner message handler
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The new .NET Core index-dinner message handler
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The new ASP.NET Core dinners API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Four are enterprise-grade open source technologies:'
  prefs: []
  type: TYPE_NORMAL
- en: Traefik reverse proxy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NATS message queue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elasticsearch document database
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kibana analytics UI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The last is SQL Server Express, which is free to use in production. Each component
    runs in a lightweight Docker container, and each is capable of being independently
    deployed so that they can follow their own release cadence:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/810be7f9-9933-4e95-8b15-0a730684c67a.png)'
  prefs: []
  type: TYPE_IMG
- en: One of the great benefits of Docker is the huge library of packaged software
    available to add to your solution. The official images on Docker Hub have been
    tried and trusted by the community for years. Certified images on Docker Hub provide
    commercial software that is guaranteed to work correctly on Docker Enterprise.
  prefs: []
  type: TYPE_NORMAL
- en: More and more software packages are becoming available for Windows in easily-consumed
    Docker images, giving you the scope to add features to your application without
    significant development.
  prefs: []
  type: TYPE_NORMAL
- en: The new custom components in the NerdDinner stack are the message handlers and
    the REST API, all simple applications containing around 100 lines of code. The
    save-dinner handler uses the original code from the web application and uses the
    EF model, which I refactored into its own project to enable its reuse. The index
    dinner handler and the REST API use all new code written in .NET Core, which makes
    it efficient and portable at runtime, but at build time, all the projects are
    in a single Visual Studio solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The container-first approach is about breaking features into discrete components
    and designing these components to run in containers, either as small custom applications
    that you write yourself or as off-the-shelf images from Docker Hub. This feature-driven
    approach means that you focus on an area that is valuable to the project''s stakeholders:'
  prefs: []
  type: TYPE_NORMAL
- en: To the business, because it gives them new functionality or more frequent releases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To operations, because it makes the application more resilient and easier to
    maintain
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To the development team, because it addresses technical debt and allows greater
    architectural freedom
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing build and deployment dependencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the current evolution, NerdDinner has a well-structured and logical architecture,
    but practically, it has a lot of dependencies. The container-first design approach
    gives me technology stack freedom, but that can lead to a lot of new technologies.
    If you were to join the project at this stage and wanted to run the application
    locally outside Docker, you''d need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Visual Studio 2017
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: .NET Core 2.1 runtime and SDK
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IIS and ASP.NET 4.7.2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SQL Server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traefik, NATS, Elasticsearch, and Kibana
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you join the project and you have Docker Desktop on Windows 10, you don't
    need any of these dependencies. When you've cloned the source code, you can build
    and run the whole application stack with Docker. You can even develop and debug
    the solution with Docker and a lightweight editor, such as VS Code, removing even
    the dependency for Visual Studio.
  prefs: []
  type: TYPE_NORMAL
- en: 'This also makes continuous integration very easy: your build servers only need
    Docker installed to build and package the solution. You can use disposable build
    servers, spinning up a VM when you have builds queued and then destroying the
    VM when the queue is empty. You don''t need complex initialization scripts for
    the VM, just a scripted Docker install. You could also use a managed CI service
    in the cloud, as they all now support Docker.'
  prefs: []
  type: TYPE_NORMAL
- en: There are still runtime dependencies for the solution, which I'm currently managing
    with a script that starts all the containers with the right options and in the
    right order. This is a brittle and limited approach—the script has no logic to
    handle any failures or to allow for a partial start where some containers are
    already running. You wouldn't do this in a real project; I'm only using the script
    so we can focus on building and running the containers. In the next chapter, I'll
    show you the right way to do it, using Docker Compose to define and run the whole
    solution.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter I looked at container-first solution design, making use of the
    Docker platform at design time to easily and safely add features to your application.
    I described a feature-driven approach to modernizing an existing software project
    that maximizes return on your investment and gives you clear visibility on its
    progress.
  prefs: []
  type: TYPE_NORMAL
- en: The container-first approach to features lets you use production-grade software
    from Docker Hub to add capabilities to your solution, with official and certified
    images that are high-quality curated applications. You can add these off-the-shelf
    components and focus on building small custom components to complete the features.
    Your application will evolve to be loosely coupled so that individual elements
    can each have the most appropriate release cycle.
  prefs: []
  type: TYPE_NORMAL
- en: The speed of development in this chapter has outpaced operations, so we currently
    have a well-architected solution that is fragile to deploy. In the next chapter
    I'll introduce **Docker Compose**, which provides a clear and uniform way to describe
    and manage multi-container solutions.
  prefs: []
  type: TYPE_NORMAL
