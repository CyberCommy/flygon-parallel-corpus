- en: Testing, Profiling, and Dealing with Exceptions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '"Just as the wise accepts gold after testing it by heating, cutting and rubbing
    it, so are my words to be accepted after examining them, but not out of respect
    for me." – Buddha'
  prefs: []
  type: TYPE_NORMAL
- en: I love this quote by the Buddha. Within the software world, it translates perfectly
    into the healthy habit of never trusting code just because someone smart wrote
    it or because it's been working fine for a long a time. If it has not been tested,
    code is not to be trusted.
  prefs: []
  type: TYPE_NORMAL
- en: Why are tests so important? Well, for one, they give you predictability. Or,
    at least, they help you achieve high predictability. Unfortunately, there is always
    some bug that sneaks into the code. But we definitely want our code to be as predictable
    as possible. What we don't want is to have a surprise, in other words, our code
    behaving in an unpredictable way. Would you be happy to know that the software
    that checks on the sensors of the plane that is taking you on your holidays sometimes
    goes crazy? No, probably not.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we need to test our code; we need to check that its behavior is correct,
    that it works as expected when it deals with edge cases, that it doesn't hang
    when the components it's talking to are broken or unreachable, that the performances
    are well within the acceptable range, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is all about that—making sure that your code is prepared to face
    the scary outside world, that it's fast enough, and that it can deal with unexpected
    or exceptional conditions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''re going to explore the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Testing (several aspects of it, including a brief introduction to test-driven
    development)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exception handling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Profiling and performances
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's start by understanding what testing is.
  prefs: []
  type: TYPE_NORMAL
- en: Testing your application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many different kinds of tests, so many, in fact, that companies often
    have a dedicated department, called **quality assurance** (**QA**), made up of
    individuals who spend their day testing the software the company developers produce.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start making an initial classification, we can divide tests into two broad
    categories: white-box and black-box tests.'
  prefs: []
  type: TYPE_NORMAL
- en: '**White-box tests** are those that exercise the internals of the code; they
    inspect it down to a very fine level of detail. On the other hand, **black-box
    tests** are those that consider the software under test as if within a box, the
    internals of which are ignored. Even the technology, or the language used inside
    the box, is not important for black-box tests. What they do is plug input into
    one end of the box and verify the output at the other end—that''s it.'
  prefs: []
  type: TYPE_NORMAL
- en: There is also an in-between category, called **gray-box** testing, which involves
    testing a system in the same way we do with the black-box approach, but having
    some knowledge about the algorithms and data structures used to write the software
    and only partial access to its source code.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many different kinds of tests in these categories, each of which
    serves a different purpose. To give you an idea, here are a few:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Frontend tests**: Make sure that the client side of your application is exposing
    the information that it should, all the links, the buttons, the advertising, everything
    that needs to be shown to the client. It may also verify that it is possible to
    walk a certain path through the user interface.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scenario tests**: Make use of stories (or scenarios) that help the tester
    work through a complex problem or test a part of the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integration tests**: Verify the behavior of the various components of your
    application when they are working together sending messages through interfaces.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Smoke tests**: Particularly useful when you deploy a new update on your application.
    They check whether the most essential, vital parts of your application are still
    working as they should and that they are not *on fire*. This term comes from when
    engineers tested circuits by making sure nothing was smoking.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Acceptance tests**, or **user acceptance testing** (**UAT**): What a developer
    does with a product owner (for example, in a SCRUM environment) to determine whether
    the work that was commissioned was carried out correctly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Functional tests**: Verify the features or functionalities of your software.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Destructive tests**: Take down parts of your system, simulating a failure,
    to establish how well the remaining parts of the system perform. These kinds of
    tests are performed extensively by companies that need to provide an extremely
    reliable service, such as Amazon and Netflix, for example.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance tests**: Aim to verify how well the system performs under a specific
    load of data or traffic so that, for example, engineers can get a better understanding
    of the bottlenecks in the system that could bring it to its knees in a heavy-load
    situation, or those that prevent scalability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Usability tests**, and the closely related **user experience** (**UX**) tests:
    Aim to check whether the user interface is simple and easy to understand and use.
    They aim to provide input to the designers so that the user experience is improved.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security and penetration tests**: Aim to verify how well the system is protected
    against attacks and intrusions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unit tests**: Help the developer to write the code in a robust and consistent
    way, providing the first line of feedback and defense against coding mistakes,
    refactoring mistakes, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regression tests**: Provide the developer with useful information about a
    feature being compromised in the system after an update. Some of the causes for
    a system being said to have a regression are an old bug coming back to life, an
    existing feature being compromised, or a new issue being introduced.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many books and articles have been written about testing, and I have to point
    you to those resources if you're interested in finding out more about all the
    different kinds of tests. In this chapter, we will concentrate on unit tests,
    since they are the backbone of software-crafting and form the vast majority of
    tests that are written by a developer.
  prefs: []
  type: TYPE_NORMAL
- en: Testing is an *art*, an art that you don't learn from books, I'm afraid. You
    can learn all the definitions (and you should), and try to collect as much knowledge
    about testing as you can, but you will likely be able to test your software properly
    only when you have done it for long enough in the field.
  prefs: []
  type: TYPE_NORMAL
- en: When you are having trouble refactoring a bit of code, because every little
    thing you touch makes a test blow up, you learn how to write less rigid and limiting
    tests, which still verify the correctness of your code but, at the same time,
    allow you the freedom and joy to play with it, to shape it as you want.
  prefs: []
  type: TYPE_NORMAL
- en: When you are being called too often to fix unexpected bugs in your code, you
    learn how to write tests more thoroughly, how to come up with a more comprehensive
    list of edge cases, and strategies to cope with them before they turn into bugs.
  prefs: []
  type: TYPE_NORMAL
- en: When you are spending too much time reading tests and trying to refactor them
    to change a small feature in the code, you learn to write simpler, shorter, and
    better-focused tests.
  prefs: []
  type: TYPE_NORMAL
- en: I could go on with this *when you... you learn...*, but I guess you get the
    picture. You need to get your hands dirty and build experience. My suggestion?
    Study the theory as much as you can, and then experiment using different approaches.
    Also, try to learn from experienced coders; it's very effective.
  prefs: []
  type: TYPE_NORMAL
- en: The anatomy of a test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we concentrate on unit tests, let's see what a test is, and what its
    purpose is.
  prefs: []
  type: TYPE_NORMAL
- en: A **test** is a piece of code whose purpose is to verify something in our system.
    It may be that we're calling a function passing two integers, that an object has
    a property called `donald_duck`, or that when you place an order on some API,
    after a minute you can see it dissected into its basic elements, in the database.
  prefs: []
  type: TYPE_NORMAL
- en: 'A test is typically composed of three sections:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Preparation**: This is where you set up the scene. You prepare all the data,
    the objects, and the services you need in the places you need them so that they
    are ready to be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Execution**: This is where you execute the bit of logic that you''re checking
    against. You perform an action using the data and the interfaces you have set
    up in the preparation phase.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Verification**: This is where you verify the results and make sure they are
    according to your expectations. You check the returned value of a function, or
    that some data is in the database, some is not, some has changed, a request has
    been made, something has happened, a method has been called, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While tests usually follow this structure, in a test suite, you will typically
    find some other constructs that take part in the testing game:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Setup**: This is something quite commonly found in several different tests.
    It''s logic that can be customized to run for every test, class, module, or even
    for a whole session. In this phase usually developers set up connections to databases,
    maybe populate them with data that will be needed there for the test to make sense,
    and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Teardown**: This is the opposite of the setup; the teardown phase takes place
    when the tests have been run. Like the setup, it can be customized to run for
    every test, class or module, or session. Typically in this phase, we destroy any
    artefacts that were created for the test suite, and clean up after ourselves.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fixtures**: They are pieces of data used in the tests. By using a specific
    set of fixture, outcomes are predictable and therefore tests can perform verifications
    against them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will use the `pytest` Python library. It is an incredibly
    powerful tool that makes testing much easier and provides plenty of helpers so
    that the test logic can focus more on the actual testing than the wiring around
    it. You will see, when we get to the code, that one of the characteristics of
    `pytest` is that fixtures, setup, and teardown often blend into one.
  prefs: []
  type: TYPE_NORMAL
- en: Testing guidelines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Like software, tests can be good or bad, with a whole range of shades in the
    middle. To write good tests, here are some guidelines:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Keep them as simple as possible**. It''s okay to violate some good coding
    rules, such as hardcoding values or duplicating code. Tests need, first and foremost,
    to be as **readable** as possible and easy to understand. When tests are hard
    to read or understand, you can never be confident they are actually making sure
    your code is performing correctly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tests should verify one thing and one thing only**. It''s very important
    that you keep them short and contained. It''s perfectly fine to write multiple
    tests to exercise a single object or function. Just make sure that each test has
    one and only one purpose.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tests should not make any unnecessary assumption when verifying data**. This
    is tricky to understand at first, but it is important. Verifying that the result
    of a function call is `[1, 2, 3]` is not the same as saying the output is a list
    that contains the numbers `1`, `2`, and `3`. In the former, we''re also assuming
    the ordering; in the latter, we''re only assuming which items are in the list.
    The differences sometimes are quite subtle, but they are still very important.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tests should exercise the what, rather than the how**. Tests should focus
    on checking *what* a function is supposed to do, rather than *how* it is doing
    it. For example, focus on the fact that it''s calculating the square root of a
    number (the *what*), instead of on the fact that it is calling `math.sqrt` to
    do it (the *how*). Unless you''re writing performance tests or you have a particular
    need to verify how a certain action is performed, try to avoid this type of testing
    and focus on the *what*. Testing the *how* leads to restrictive tests and makes
    refactoring hard. Moreover, the type of test you have to write when you concentrate
    on the *how* is more likely to degrade the quality of your testing code base when
    you amend your software frequently.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tests should use the minimal set of fixtures needed to do the job**. This
    is another crucial point. Fixtures have a tendency to grow over time. They also
    tend to change every now and then. If you use big amounts of fixtures and ignore
    redundancies in your tests, refactoring will take longer. Spotting bugs will be
    harder. Try to use a set of fixtures that is big enough for the test to perform
    correctly, but not any bigger.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tests should run as fast as possible**. A good test codebase could end up
    being much longer than the code being tested itself. It varies according to the
    situation and the developer, but, whatever the length, you''ll end up having hundreds,
    if not thousands, of tests to run, which means the faster they run, the faster
    you can get back to writing code. When using TDD, for example, you run tests very
    often, so speed is essential.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tests should use up the least possible amount of resources**. The reason
    for this is that every developer who checks out your code should be able to run
    your tests, no matter how powerful their box is. It could be a skinny virtual
    machine or a neglected Jenkins box, your tests should run without chewing up too
    many resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **Jenkins** box is a machine that runs Jenkins, software that is capable of,
    among many other things, running your tests automatically. Jenkins is frequently
    used in companies where developers use practices such as continuous integration
    and extreme programming.
  prefs: []
  type: TYPE_NORMAL
- en: Unit testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that you have an idea about what testing is and why we need it, let''s
    introduce the developer''s best friend: the **unit test**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we proceed with the examples, allow me to share some words of caution:
    I''ll try to give you the fundamentals about unit testing, but I don''t follow
    any particular school of thought or methodology to the letter. Over the years,
    I have tried many different testing approaches, eventually coming up with my own
    way of doing things, which is constantly evolving. To put it as Bruce Lee would
    have:'
  prefs: []
  type: TYPE_NORMAL
- en: '"Absorb what is useful, discard what is useless and add what is specifically
    your own."'
  prefs: []
  type: TYPE_NORMAL
- en: Writing a unit test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Unit tests take their name after the fact that they are used to test small
    units of code. To explain how to write a unit test, let''s take a look at a simple
    snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `get_clean_data` function is responsible for getting data from `source`,
    cleaning it, and returning it to the caller. How do we test this function?
  prefs: []
  type: TYPE_NORMAL
- en: One way of doing this is to call it and then make sure that `load_data` was
    called once with `source` as its only argument. Then we have to verify that `clean_data`
    was called once, with the return value of `load_data`. And, finally, we would
    need to make sure that the return value of `clean_data` is what is returned by
    the `get_clean_data` function as well.
  prefs: []
  type: TYPE_NORMAL
- en: To do this, we need to set up the source and run this code, and this may be
    a problem. One of the golden rules of unit testing is that *anything that crosses
    the boundaries of your application needs to be simulated*. We don't want to talk
    to a real data source, and we don't want to actually run real functions if they
    are communicating with anything that is not contained in our application. A few
    examples would be a database, a search service, an external API, and a file in
    the filesystem.
  prefs: []
  type: TYPE_NORMAL
- en: We need these restrictions to act as a shield, so that we can always run our
    tests safely without the fear of destroying something in a real data source.
  prefs: []
  type: TYPE_NORMAL
- en: Another reason is that it may be quite difficult for a single developer to reproduce
    the whole architecture on their box. It may require the setting up of databases,
    APIs, services, files and folders, and so on and so forth, and this can be difficult,
    time-consuming, or sometimes not even possible.
  prefs: []
  type: TYPE_NORMAL
- en: Very simply put, an **application programming interface** (**API**) is a set
    of tools for building software applications. An API expresses a software component
    in terms of its operations, input and output, and underlying types. For example,
    if you create a software that needs to interface with a data provider service,
    it's very likely that you will have to go through their API in order to gain access
    to the data.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, in our unit tests, we need to simulate all those things in some way.
    Unit tests need to be run by any developer without the need for the whole system
    to be set up on their box.
  prefs: []
  type: TYPE_NORMAL
- en: A different approach, which I always favor when it's possible to do so, is to
    simulate entities without using fake objects, but using special-purpose test objects
    instead. For example, if your code talks to a database, instead of faking all
    the functions and methods that talk to the database and programming the fake objects
    so that they return what the real ones would, I'd much rather spawn a test database,
    set up the tables and data I need, and then patch the connection settings so that
    my tests are running real code, against the test database, thereby doing no harm
    at all. In-memory databases are excellent options for these cases.
  prefs: []
  type: TYPE_NORMAL
- en: One of the applications that allow you to spawn a database for testing is Django.
    Within the `django.test` package, you can find several tools that help you write
    your tests so that you won't have to simulate the dialog with a database. By writing
    tests this way, you will also be able to check on transactions, encodings, and
    all other database-related aspects of programming. Another advantage of this approach
    consists in the ability of checking against things that can change from one database
    to another.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, though, it's still not possible, and we need to use fakes, so let's
    talk about them.
  prefs: []
  type: TYPE_NORMAL
- en: Mock objects and patching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First of all, in Python, these fake objects are called **mocks**. Up to Version
    3.3, the `mock` library was a third-party library that basically every project
    would install via `pip` but, from Version 3.3, it has been included in the standard
    library under the `unittest` module, and rightfully so, given its importance and
    how widespread it is.
  prefs: []
  type: TYPE_NORMAL
- en: The act of replacing a real object or function (or in general, any piece of
    data structure) with a mock, is called **patching**. The `mock` library provides
    the `patch` tool, which can act as a function or class decorator, and even as
    a context manager that you can use to mock things out. Once you have replaced
    everything you don't need to run with suitable mocks, you can pass to the second
    phase of the test and run the code you are exercising. After the execution, you
    will be able to check those mocks to verify that your code has worked correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Assertions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The verification phase is done through the use of assertions. An **assertion**
    is a function (or method) that you can use to verify equality between objects,
    as well as other conditions. When a condition is not met, the assertion will raise
    an exception that will make your test fail. You can find a list of assertions
    in the `unittest` module documentation; however, when using `pytest`, you will
    typically use the generic `assert` statement, which makes things even simpler.
  prefs: []
  type: TYPE_NORMAL
- en: Testing a CSV generator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's now adopt a practical approach. I will show you how to test a piece of
    code, and we will touch on the rest of the important concepts around unit testing,
    within the context of this example.
  prefs: []
  type: TYPE_NORMAL
- en: 'We want to write an `export` function that does the following: it takes a list
    of dictionaries, each of which represents a user. It creates a CSV file, puts
    a header in it, and then proceeds to add all the users who are deemed valid according
    to some rules. The `export` function takes also a filename, which will be the
    name for the CSV in output. And, finally, it takes an indication on whether to
    allow an existing file with the same name to be overwritten.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As for the users, they must abide by the following: each user has at least
    an email, a name, and an age. There can be a fourth field representing the role,
    but it''s optional. The user''s email address needs to be valid, the name needs
    to be non-empty, and the age must be an integer between 18 and 65.'
  prefs: []
  type: TYPE_NORMAL
- en: This is our task, so now I'm going to show you the code, and then we're going
    to analyze the tests I wrote for it. But, first things first, in the following
    code snippets, I'll be using two third-party libraries: `marshmallow` and `pytest`.
    They both are in the requirements of the book's source code, so make sure you
    have installed them with `pip`.
  prefs: []
  type: TYPE_NORMAL
- en: '`marshmallow` is a wonderful library that provides us with the ability to serialize
    and deserialize objects and, most importantly, gives us the ability to define
    a schema that we can use to validate a user dictionary. `pytest` is one of the
    best pieces of software I have ever seen. It is used everywhere now, and has replaced
    other tools such as `nose`, for example. It provides us with great tools to write
    beautiful short tests.'
  prefs: []
  type: TYPE_NORMAL
- en: 'But let''s get to the code. I called it `api.py` just because it exposes a
    function that we can use to do things. I''ll show it to you in chunks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This first part is where we import all the modules we need (`os` and `csv`),
    and some tools from `marshmallow`, and then we define the schema for the users.
    As you can see, we inherit from `marshmallow.Schema`, and then we set four fields.
    Notice we are using two `String` fields, `Email` and `Integer`. These will already
    provide us with some validation from `marshmallow`. Notice there is no `required=True` in
    the `role` field.
  prefs: []
  type: TYPE_NORMAL
- en: We need to add a couple of custom bits of code, though. We need to add `validate_age`
    to make sure the value is within the range we want. We raise `ValidationError`
    in case it's not. And `marshmallow` will kindly take care of raising an error
    should we pass anything but an integer.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we add `validate_name`, because the fact that a `name` key in the dictionary
    is there doesn't guarantee that the name is actually non-empty. So we take its
    value, we strip all leading and trailing whitespace characters, and if the result
    is empty, we raise `ValidationError` again. Notice we don't need to add a custom
    validator for the `email` field. This is because `marshmallow` will validate it,
    and a valid email cannot be empty.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then instantiate `schema`, so that we can use it to validate data. So let''s
    write the `export` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'As you see, its internals are quite straightforward. If `overwrite` is `False`
    and the file already exists, we raise `IOError` with a message saying the file
    already exists. Otherwise, if we can proceed, we simply get the list of valid
    users and feed it to `write_csv`, which is responsible for actually doing the
    job. Let''s see how all these functions are defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Turns out I coded `get_valid_users` as a generator, as there is no need to make
    a potentially big list in order to put it in a file. We can validate and save
    them one by one. The heart of validation is simply a delegation to `schema.validate`,
    which uses validation engine by `marshmallow`. The way this works is by returning
    a dictionary, which is empty if validation succeeded, or else it will contain
    error information. We don't really care about collecting the error information
    for this task, so we simply ignore it, and within `is_valid` we basically return
    `True` if the return value from `schema.validate` is empty, and `False` otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: 'One last piece is missing; here it is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Again, the logic is straightforward. We define the header in `fieldnames`, then
    we open `filename` for writing, and we specify `newline=''`, which is recommended
    in the documentation when dealing with CSV files. When the file has been created,
    we get a `writer` object by using the `csv.DictWriter` class. The beauty of this
    tool is that it is capable of mapping the user dictionaries to the field names,
    so we don't need to take care of the ordering.
  prefs: []
  type: TYPE_NORMAL
- en: We write the header first, and then we loop over the users and add them one
    by one. Notice, this function assumes it is fed a list of valid users, and it
    may break if that assumption is false (with the default values, it would break
    if any user dictionary had extra fields).
  prefs: []
  type: TYPE_NORMAL
- en: That's the whole code you have to keep in mind. I suggest you spend a moment
    to go through it again. There is no need to memorize it, and the fact that I have
    used small helper functions with meaningful names will enable you to follow the
    testing along more easily.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now get to the interesting part: testing our `export` function. Once
    again, I''ll show you the code in chunks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s start from the imports: we need `os`, temporary directories (which we
    already saw in [Chapter 7](part0187.html#5IAP60-2ddb708647cc4530a187c2c6c0e9acfe), *Files
    and Data Persistence*), then `pytest`, and, finally, we use a relative import
    to fetch the three functions that we want to actually test: `is_valid`, `export`,
    and `write_csv`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we can write tests, though, we need to make a few fixtures. As you will
    see, a `fixture` is a function that is decorated with the `pytest.fixture` decorator.
    In most cases, we expect `fixture` to return something, so that we can use it
    in a test. We have some requirements for a user dictionary, so let''s write a
    couple of users: one with minimal requirements, and one with full requirements.
    Both need to be valid. Here is the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the only difference is the presence of the `role` key, but
    it's enough to show you the point I hope. Notice that instead of simply declaring
    dictionaries at a module level, we actually have written two functions that return
    a dictionary, and we have decorated them with the `pytest.fixture` decorator.
    This is because when you declare a dictionary at module-level, which is supposed
    to be used in your tests, you need to make sure you copy it at the beginning of
    every test. If you don't, you may have a test that modifies it, and this will
    affect all tests that follow it, compromising their integrity.
  prefs: []
  type: TYPE_NORMAL
- en: 'By using these fixtures, `pytest` will give us a new dictionary every test
    run, so we don''t need to go through that pain ourselves. Notice that if a fixture
    returns another type, instead of dict, then that is what you will get in the test.
    Fixtures also are *composable*, which means they can be used in one another, which
    is a very powerful feature of `pytest`. To show you this, let''s write a fixture
    for a list of users, in which we put the two we already have, plus one that would
    fail validation because it has no age. Let''s take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Nice. So, now we have two users that we can use individually, but also we have
    a list of three users. The first round of tests will be testing how we are validating
    a user. We will group all the tests for this task within a class. This not only
    helps giving related tests a namespace, a place to be, but, as we''ll see later
    on, it allows us to declare class-level fixtures, which are defined just for the
    tests belonging to the class. Take a look at this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We start very simply by making sure our fixtures are actually passing validation.
    This is very important, as those fixtures will be used everywhere, so we want
    them to be perfect. Next, we test the age. Two things to notice here: I will not
    repeat the class signature, so the code that follows is indented by four spaces
    and it''s because these are all methods within the same class, okay? And, second,
    we''re going to use parametrization quite heavily.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Parametrization is a technique that enables us to run the same test multiple
    times, but feeding different data to it. It is very useful, as it allows us to
    write the test only once with no repetition, and the result will be very intelligently
    handled by `pytest`, which will run all those tests as if they were actually separate,
    thus providing us with clear error messages when they fail. If you parametrize
    manually, you lose this feature, and believe me you won''t be happy. Let''s see
    how we test the age:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Right, so we start by writing a test to check that validation fails when the
    user is too young. According to our rule, a user is too young when they are younger
    than 18\. We check for every age between 0 and 17, by using `range`.
  prefs: []
  type: TYPE_NORMAL
- en: If you take a look at how the parametrization works, you'll see we declare the
    name of an object, which we then pass to the signature of the method, and then
    we specify which values this object will take. For each value, the test will be
    run once. In the case of this first test, the object's name is `age`, and the
    values are all those returned by `range(18)`, which means all integer numbers
    from `0` to `17` are included. Notice how we feed `age` to the test method, right
    after `self`, and then we do something else, which is also very interesting. We
    pass this method a fixture: `min_user`. This has the effect of activating that
    fixture for the test run, so that we can use it, and can refer to it from within
    the test. In this case, we simply change the age within the `min_user` dictionary,
    and then we verify that the result of `is_valid(min_user)` is `False`.
  prefs: []
  type: TYPE_NORMAL
- en: We do this last bit by asserting on the fact that `not False` is `True`. In `pytest`, this
    is how you check for something. You simply assert that something is truthy. If
    that is the case, the test has succeeded. Should it instead be the opposite, the
    test would fail.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s proceed and add all the tests needed to make validation fail on the
    age:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: So, another two tests. One takes care of the other end of the spectrum, from
    66 years of age to 99\. And the second one instead makes sure that age is invalid
    when it's not an integer number, so we pass some values, such as a string, a float,
    and `None`, just to make sure. Notice how the structure of the test is basically
    always the same, but, thanks to the parametrization, we feed very different input
    arguments to it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have the age-failing all sorted out, let''s add a test that actually
    checks the age is within the valid range:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: It's as easy as that. We pass the correct range, from `18` to `65`, and remove
    the `not` in the assertion. Notice how all tests start with the `test_` prefix,
    and have a different name.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can consider the age as being taken care of. Let''s move on to write tests
    on mandatory fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The previous three tests still belong to the same class. The first one tests
    whether a user is invalid when one of the mandatory fields is missing. Notice
    that at every test run, the `min_user` fixture is restored, so we only have one
    missing field per test run, which is the appropriate way to check for mandatory
    fields. We simply pop the key out of the dictionary. This time the parametrization
    object takes the name `field`, and, by looking at the first test, you see all
    the mandatory fields in the parametrization decorator: `email`, `name`, and `age`.
  prefs: []
  type: TYPE_NORMAL
- en: In the second one, things are a little different. Instead of popping keys out,
    we simply set them (one at a time) to the empty string. Finally, in the third
    one, we check for the name to be made of whitespace only.
  prefs: []
  type: TYPE_NORMAL
- en: 'The previous tests take care of mandatory fields being there and being non-empty,
    and of the formatting around the `name` key of a user. Good. Let''s now write
    the last two tests for this class. We want to check email validity, and type for
    email, name, and the role:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This time, the parametrization is slightly more complex. We define two objects
    (`email` and `outcome`), and then we pass a list of tuples, instead of a simple
    list, to the decorator. What happens is that each time the test is run, one of
    those tuples will be unpacked so to fill the values of `email` and `outcome`,
    respectively. This allows us to write one test for both valid and invalid email
    addresses, instead of two separate ones. We define an email address, and we specify
    the outcome we expect from validation. The first four are invalid email addresses,
    but the last three are actually valid. I have used a couple of examples with Unicode,
    just to make sure we're not forgetting to include our friends from all over the
    world in the validation.
  prefs: []
  type: TYPE_NORMAL
- en: Notice how the validation is done, asserting the result of the call needs to
    match the outcome we have set.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now write a simple test to make sure validation fails when we feed the
    wrong type to the fields (again, the age has been taken care of separately before):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: As we did before, just for fun, we pass three different values, none of which
    is actually a string. This test could be expanded to include more values, but,
    honestly, we shouldn't need to write tests such as this one. I have included it
    here just to show you what's possible.
  prefs: []
  type: TYPE_NORMAL
- en: Before we move to the next test class, let me talk about something we have seen
    when we were checking the age.
  prefs: []
  type: TYPE_NORMAL
- en: Boundaries and granularity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While checking for the age, we have written three tests to cover the three
    ranges: 0-17 (fail), 18-65 (success), 66-99 (fail). Why did we do this? The answer
    lies in the fact that we are dealing with two boundaries: 18 and 65\. So our testing
    needs to focus on the three regions those two boundaries define: before `18`,
    within `18` and `65`, and after `65`. How you do it is not crucial, as long as
    you make sure you test the boundaries correctly. This means if someone changes
    the validation in the schema from `18 <= value <= 65` to `18 <= value < 65` (notice
    the missing `=`), there must be a test that fails on the `65`.'
  prefs: []
  type: TYPE_NORMAL
- en: This concept is known as **boundary**, and it's very important that you recognize
    them in your code so that you can test against them.
  prefs: []
  type: TYPE_NORMAL
- en: Another important thing is to understand is which zoom level we want to get
    close to the boundaries. In other words, which unit should I use to move around
    it? In the case of age, we're dealing with integers, so a unit of `1` will be
    the perfect choice (which is why we used `16`, `17`, `18`, `19`, `20`, ...). But
    what if you were testing for a timestamp? Well, in that case, the correct granularity
    will likely be different. If the code has to act differently according to your
    timestamp and that timestamp represent seconds, then the granularity of your tests
    should zoom down to seconds. If the timestamp represents years, then years should
    be the unit you use. I hope you get the picture. This concept is known as **granularity**,
    and needs to be combined with that of boundaries, so that by going around the
    boundaries with the correct granularity, you can make sure your tests are not
    leaving anything to chance.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now continue with our example, and test the `export` function.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the export function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the same test module, I have defined another class that represents a test
    suite for the `export` function. Here it is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Let's start understanding the fixtures. We have defined them at class-level
    this time, which means they will be alive only for as long as the tests in the
    class are running. We don't need these fixtures outside of this class, so it doesn't
    make sense to declare them at a module level like we've done with the user ones.
  prefs: []
  type: TYPE_NORMAL
- en: So, we need two files. If you recall what I wrote at the beginning of this chapter,
    when it comes to interaction with databases, disks, networks, and so on, we should
    mock everything out. However, when possible, I prefer to use a different technique.
    In this case, I will employ temporary folders, which will be born within the fixture,
    and die within it, leaving no trace of their existence. I am much happier if I
    can avoid mocking. Mocking is amazing, but it can be tricky, and a source of bugs,
    unless it's done correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Now, the first fixture, `csv_file`, defines a managed context in which we obtain
    a reference to a temporary folder. We can consider the logic up to and including
    the `yield`, as the setup phase. The fixture itself, in terms of data, is represented
    by the temporary filename. The file itself is not present yet. When a test runs,
    the fixture is created, and at the end of the test, the rest of the fixture code
    (the one after `yield`, if any) is executed. That part can be considered the teardown
    phase. In this case, it consists of exiting the context manager, which means the
    temporary folder is deleted (along with all its content). You can put much more
    in each phase of any fixture, and with experience, I'm sure you'll master the
    art of doing setup and teardown this way. It actually comes very naturally quite
    quickly.
  prefs: []
  type: TYPE_NORMAL
- en: The second fixture is very similar to the first one, but we'll use it to test
    that we can prevent overwriting when we call `export` with `overwrite=False`.
    So we create a file in the temporary folder, and we put some content into it,
    just to have the means to verify it hasn't been touched.
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice how both fixtures are returning the filename with the full path information,
    to make sure we actually use the temporary folder in our code. Let''s now see
    the tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This test employs the `users` and `csv_file` fixtures, and immediately calls `export`
    with them. We expect that a file has been created, and populated with the two
    valid users we have (remember the list contains three users, but one is invalid).
  prefs: []
  type: TYPE_NORMAL
- en: To verify that, we open the temporary file, and collect all its lines into a
    list. We then compare the content of the file with a list of the lines that we
    expect to be in it. Notice we only put the header, and the two valid users, in
    the correct order.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we need another test, to make sure that if there is a comma in one of the
    values, our CSV is still generated correctly. Being a **comma-separated values**
    (**CSV**) file, we need to make sure that a comma in the data doesn''t break things
    up:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This time, we don't need the whole users list, we just need one as we're testing
    a specific thing, and we have the previous test to make sure we're generating
    the file correctly with all the users. Remember, always try to minimize the work
    you do within a test.
  prefs: []
  type: TYPE_NORMAL
- en: So, we use `min_user`, and put a nice comma in its name. We then repeat the
    procedure, which is very similar to that of the previous test, and finally we
    make sure that the name is put in the CSV file surrounded by double quotes. This
    is enough for any good CSV parser to understand that they don't have to break
    on the comma inside the double quotes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now I want one more test, which needs to check that whether the file exists
    and we don''t want to override it, our code won''t touch it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This is a beautiful test, because it allows me to show you how you can tell `pytest`
    that you expect a function call to raise an exception. We do it in the context
    manager given to us by `pytest.raises`, to which we feed the exception we expect
    from the call we make inside the body of that context manager. If the exception
    is not raised, the test will fail.
  prefs: []
  type: TYPE_NORMAL
- en: I like to be thorough in my test, so I don't want to stop there. I also assert
    on the message, by using the convenient `err.match` helper (watch out, it takes
    a regular expression, not a simple string–we'll see regular expressions in [Chapter
    14](part0341.html#A56FQ0-2ddb708647cc4530a187c2c6c0e9acfe), *Web Development*).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, let's make sure that the file still contains its original content (which
    is why I created the `existing_file` fixture) by opening it, and comparing all
    of its content to the string it should be.
  prefs: []
  type: TYPE_NORMAL
- en: Final considerations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we move on to the next topic, let me just wrap up with some considerations.
  prefs: []
  type: TYPE_NORMAL
- en: First, I hope you have noticed that I haven't tested all the functions I wrote.
    Specifically, I didn't test `get_valid_users`, `validate`, and `write_csv`. The
    reason is because these functions are implicitly tested by our test suite. We
    have tested `is_valid` and `export`, which is more than enough to make sure our
    schema is validating users correctly, and the `export` function is dealing with
    filtering out invalid users correctly, respecting existing files when needed,
    and writing a proper CSV. The functions we haven't tested are the internals, they
    provide logic that participates to doing something that we have thoroughly tested
    anyway. Would adding extra tests for those functions be good or bad? Think about
    it for a moment.
  prefs: []
  type: TYPE_NORMAL
- en: The answer is actually difficult. The more you test, the less you can refactor
    that code. As it is now, I could easily decide to call `is_valid` with another
    name, and I wouldn't have to change any of my tests. If you think about it, it
    makes sense, because as long as `is_valid` provides correct validation to the `get_valid_users`
    function, I don't really need to know about it. Does this make sense to you?
  prefs: []
  type: TYPE_NORMAL
- en: If instead I had tests for the `validate` function, then I would have to change
    them, if I decided to call it differently (or to somehow change its signature).
  prefs: []
  type: TYPE_NORMAL
- en: So, what is the right thing to do? Tests or no tests? It will be up to you.
    You have to find the right balance. My personal take on this matter is that everything
    needs to be thoroughly tested, either directly or indirectly. And I want the smallest
    possible test suite that guarantees me that. This way, I will have a great test
    suite in terms of coverage, but not any bigger than necessary. You need to maintain
    those tests!
  prefs: []
  type: TYPE_NORMAL
- en: I hope this example made sense to you, I think it has allowed me to touch on
    the important topics.
  prefs: []
  type: TYPE_NORMAL
- en: If you check out the source code for the book, in the `test_api.py` module,
    I have added a couple of extra test classes, which will show you how different
    testing would have been had I decided to go all the way with the mocks. Make sure
    you read that code and understand it well. It is quite straightforward and will
    offer you a good comparison with my personal approach, which I have shown you
    here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, how about we run those tests? (The output is re-arranged to fit this book''s
    format):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Make sure you run `$ pytest test` from within the `ch8` folder (add the `-vv`
    flag for a verbose output that will show you how parametrization modifies the
    names of your tests). As you can see, `132` tests were run in less than half a
    second, and they all succeeded. I strongly suggest you check out this code and
    play with it. Change something in the code and see whether any test is breaking.
    Understand why it is breaking. Is it something important that means the test isn't
    good enough? Or is it something silly that shouldn't cause the test to break?
    All these apparently innocuous questions will help you gain deep insight into
    the art of testing.
  prefs: []
  type: TYPE_NORMAL
- en: I also suggest you study the `unittest` module, and `pytest` too. These are
    tools you will use all the time, so you need to be very familiar with them.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now check out test-driven development!
  prefs: []
  type: TYPE_NORMAL
- en: Test-driven development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's talk briefly about **test-driven development** (**TDD**). It is a methodology
    that was rediscovered by Kent Beck, who wrote *Test-Driven Development by Example*,
    *Addison Wesley, 2002*, which I encourage you to check out if you want to learn
    about the fundamentals of this subject.
  prefs: []
  type: TYPE_NORMAL
- en: TDD is a software development methodology that is based on the continuous repetition
    of a very short development cycle.
  prefs: []
  type: TYPE_NORMAL
- en: First, the developer writes a test, and makes it run. The test is supposed to
    check a feature that is not yet part of the code. Maybe it is a new feature to
    be added, or something to be removed or amended. Running the test will make it
    fail and, because of this, this phase is called **Red**.
  prefs: []
  type: TYPE_NORMAL
- en: When the test has failed, the developer writes the minimal amount of code to
    make it pass. When running the test succeeds, we have the so-called **Green**
    phase. In this phase, it is okay to write code that cheats, just to make the test
    pass. This technique is called *fake it 'till you make it*. In a second moment,
    tests are enriched with different edge cases, and the cheating code then has to
    be rewritten with proper logic. Adding other test cases is called **triangulation**.
  prefs: []
  type: TYPE_NORMAL
- en: The last piece of the cycle is where the developer takes care of both the code
    and the tests (in separate times) and refactors them until they are in the desired
    state. This last phase is called **Refactor**.
  prefs: []
  type: TYPE_NORMAL
- en: The **TDD** mantra therefore is **Red-Green-Refactor**.
  prefs: []
  type: TYPE_NORMAL
- en: At first, it feels really weird to write tests before the code, and I must confess
    it took me a while to get used to it. If you stick to it, though, and force yourself
    to learn this slightly counter-intuitive way of working, at some point something
    almost magical happens, and you will see the quality of your code increase in
    a way that wouldn't be possible otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: When you write your code before the tests, you have to take care of *what* the
    code has to do and *how* it has to do it, both at the same time. On the other
    hand, when you write tests before the code, you can concentrate on the *what*
    part alone, while you write them. When you write the code afterward, you will
    mostly have to take care of *how* the code has to implement *what* is required
    by the tests. This shift in focus allows your mind to concentrate on the *what*
    and *how* parts in separate moments, yielding a brain power boost that will surprise
    you.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several other benefits that come from the adoption of this technique:'
  prefs: []
  type: TYPE_NORMAL
- en: '**You will refactor with much more confidence**: Tests will break if you introduce
    bugs. Moreover, the architectural refactor will also benefit from having tests
    that act as guardians.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The code will be more readable**: This is crucial in our time, when coding
    is a social activity and every professional developer spends much more time reading
    code than writing it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The code will be more loosely coupled and easier to test and maintain**: Writing
    the tests first forces you to think more deeply about code structure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Writing tests first requires you to have a better understanding of the business
    requirements**: If your understanding of the requirements is lacking information,
    you''ll find writing a test extremely challenging and this situation acts as a
    sentinel for you.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Having everything unit tested means the code will be easier to debug**: Moreover,
    small tests are perfect for providing alternative documentation. English can be
    misleading, but five lines of Python in a simple test are very hard to misunderstand.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Higher speed**: It''s faster to write tests and code than it is to write
    the code first and then lose time debugging it. If you don''t write tests, you
    will probably deliver the code sooner, but then you will have to track the bugs
    down and solve them (and, rest assured, there will be bugs). The combined time
    taken to write the code and then debug it is usually longer than the time taken
    to develop the code with TDD, where having tests running before the code is written,
    ensuring that the amount of bugs in it will be much lower than in the other case.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'On the other hand, the main shortcomings of this technique are the following
    ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The whole company needs to believe in it**: Otherwise, you will have to constantly
    argue with your boss, who will not understand why it takes you so long to deliver.
    The truth is, it may take you a bit longer to deliver in the short-term, but in
    the long-term, you gain a lot with TDD. However, it is quite hard to see the long-term
    because it''s not under our noses like the short-term is. I have fought battles
    with stubborn bosses in my career, to be able to code using TDD. Sometimes it
    has been painful, but always well worth it, and I have never regretted it because,
    in the end, the quality of the result has always been appreciated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**If you fail to understand the business requirements, this will reflect in
    the tests you write, and therefore it will reflect in the code too**: This kind
    of problem is quite hard to spot until you do UAT, but one thing that you can
    do to reduce the likelihood of it happening is to pair with another developer.
    Pairing will inevitably require discussions about the business requirements, and
    discussion will bring clarification, which will help writing correct tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Badly written tests are hard to maintain:** This is a fact. Tests with too
    many mocks or with extra assumptions or badly-structured data will soon become
    a burden. Don''t let this discourage you; just keep experimenting and change the
    way you write them until you find a way that doesn''t require you a huge amount
    of work every time you touch your code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I'm quite passionate about TDD. When I interview for a job, I always ask whether
    the company adopts it. I encourage you to check it out and use it. Use it until
    you feel something clicking in your mind. You won't regret it, I promise.
  prefs: []
  type: TYPE_NORMAL
- en: Exceptions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even though I haven't formally introduced them to you, by now I expect you to
    at least have a vague idea of what an exception is. In the previous chapters,
    we've seen that when an iterator is exhausted, calling `next` on it raises a `StopIteration`
    exception. We met `IndexError` when we tried accessing a list at a position that
    was outside the valid range. We also met `AttributeError` when we tried accessing
    an attribute on an object that didn't have it, and `KeyError` when we did the
    same with a key and a dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: Now the time has come for us to talk about exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, even though an operation or a piece of code is correct, there are
    conditions in which something may go wrong. For example, if we're converting user
    input from `string` to `int`, the user could accidentally type a letter in place
    of a digit, making it impossible for us to convert that value into a number. When
    dividing numbers, we may not know in advance whether we're attempting a division
    by zero. When opening a file, it could be missing or corrupted.
  prefs: []
  type: TYPE_NORMAL
- en: 'When an error is detected during execution, it is called an **exception**.
    Exceptions are not necessarily lethal; in fact, we''ve seen that `StopIteration`
    is deeply integrated in the Python generator and iterator mechanisms. Normally,
    though, if you don''t take the necessary precautions, an exception will cause
    your application to break. Sometimes, this is the desired behavior, but in other
    cases, we want to prevent and control problems such as these. For example, we
    may alert the user that the file they''re trying to open is corrupted or that
    it is missing so that they can either fix it or provide another file, without
    the need for the application to die because of this issue. Let''s see an example
    of a few exceptions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the Python shell is quite forgiving. We can see `Traceback`,
    so that we have information about the error, but the program doesn't die. This
    is a special behavior, a regular program or a script would normally die if nothing
    were done to handle exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: To handle an exception, Python gives you the `try` statement. When you enter
    the `try` clause, Python will watch out for one or more different types of exceptions
    (according to how you instruct it), and if they are raised, it will allow you
    to react. The `try` statement is composed of the `try` clause, which opens the
    statement, one or more `except` clauses (all optional) that define what to do
    when an exception is caught, an `else` clause (optional), which is executed when
    the `try` clause is exited without any exception raised, and a `finally` clause
    (optional), whose code is executed regardless of whatever happened in the other
    clauses. The `finally` clause is typically used to clean up resources (we saw
    this in [Chapter 7](part0187.html#5IAP60-2ddb708647cc4530a187c2c6c0e9acfe), *Files
    and Data Persistence*, when we were opening files without using a context manager).
  prefs: []
  type: TYPE_NORMAL
- en: 'Mind the order—it''s important. Also, `try` must be followed by at least one
    `except` clause or a `finally` clause. Let''s see an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The preceding example defines a simple `try_syntax` function. We perform the
    division of two numbers. We are prepared to catch a `ZeroDivisionError` exception
    if we call the function with `denominator = 0`. Initially, the code enters the
    `try` block. If `denominator` is not `0`, `result` is calculated and the execution,
    after leaving the `try` block, resumes in the `else` block. We print `result`
    and return it. Take a look at the output and you'll notice that just before returning
    `result`, which is the exit point of the function, Python executes the `finally`
    clause.
  prefs: []
  type: TYPE_NORMAL
- en: 'When `denominator` is `0`, things change. We enter the `except` block and print
    `zde`. The `else` block isn''t executed because an exception was raised in the
    `try` block. Before (implicitly) returning `None`, we still execute the `finally`
    block. Take a look at the output and see whether it makes sense to you:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'When you execute a `try` block, you may want to catch more than one exception.
    For example, when trying to decode a JSON object, you may incur into `ValueError`
    for malformed JSON, or `TypeError` if the type of the data you''re feeding to
    `json.loads()` is not a string. In this case, you may structure your code like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This code will catch both `ValueError` and `TypeError`. Try changing `json_data
    = '{}'` to `json_data = 2` or `json_data = '{{'`, and you'll see the different
    output.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to handle multiple exceptions differently, you can just add more
    `except` clauses, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Keep in mind that an exception is handled in the first block that defines that
    exception class or any of its bases. Therefore, when you stack multiple `except`
    clauses like we've just done, make sure that you put specific exceptions at the
    top and generic ones at the bottom. In OOP terms, children on top, grandparents
    at the bottom. Moreover, remember that only one `except` handler is executed when
    an exception is raised.
  prefs: []
  type: TYPE_NORMAL
- en: You can also write **custom exceptions**. To do that, you just have to inherit
    from any other exception class. Python's built-in exceptions are too many to be
    listed here, so I have to point you to the official documentation. One important
    thing to know is that every Python exception derives from `BaseException`, but
    your custom exceptions should never inherit directly from it. The reason is because
    handling such an exception will also trap **system-exiting exceptions**, such
    as `SystemExit` and `KeyboardInterrupt`, which derive from `BaseException`, and
    this could lead to severe issues. In the case of disaster, you want to be able
    to *Ctrl* + *C* your way out of an application.
  prefs: []
  type: TYPE_NORMAL
- en: You can easily solve the problem by inheriting from `Exception`, which inherits
    from `BaseException` but doesn't include any system-exiting exception in its children
    because they are siblings in the built-in exceptions hierarchy (see [https://docs.python.org/3/library/exceptions.html#exception-hierarchy](https://docs.python.org/3/library/exceptions.html#exception-hierarchy)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Programming with exceptions can be very tricky. You could inadvertently silence
    out errors, or trap exceptions that aren''t meant to be handled. Play it safe
    by keeping in mind a few guidelines: always put in the `try` clause only the code
    that may cause the exception(s) that you want to handle. When you write `except`
    clauses, be as specific as you can, don''t just resort to `except Exception` because
    it''s easy. Use tests to make sure your code handles edge cases in a way that
    requires the least possible amount of exception handling. Writing an `except`
    statement without specifying any exception would catch any exception, therefore
    exposing your code to the same risks you incur when you derive your custom exceptions
    from `BaseException`.'
  prefs: []
  type: TYPE_NORMAL
- en: You will find information about exceptions almost everywhere on the web. Some
    coders use them abundantly, others sparingly. Find your own way of dealing with
    them by taking examples from other people's source code. There are plenty of interesting
    open source projects on websites such as GitHub ([https://github.com](https://github.com))
    and Bitbucket ([https://bitbucket.org/](https://bitbucket.org/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we talk about profiling, let me show you an unconventional use of exceptions,
    just to give you something to help you expand your views on them. They are not
    just simply errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code is quite a common idiom if you deal with numbers. You have
    to iterate over a few nested ranges and look for a particular combination of `a`,
    `b`, and `c` that satisfies a condition. In the example, condition is a trivial
    linear equation, but imagine something much cooler than that. What bugs me is
    having to check whether the solution has been found at the beginning of each loop,
    in order to break out of them as fast as we can when it is. The breakout logic
    interferes with the rest of the code and I don''t like it, so I came up with a
    different solution for this. Take a look at it, and see whether you can adapt
    it to other cases too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Can you see how much more elegant it is? Now the breakout logic is entirely
    handled with a simple exception whose name even hints at its purpose. As soon
    as the result is found, we raise it, and immediately the control is given to the
    `except` clause that handles it. This is food for thought. This example indirectly
    shows you how to raise your own exceptions. Read up on the official documentation
    to dive into the beautiful details of this subject.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, if you are up for a challenge, you might want to try to make this
    last example into a context manager for nested `for` loops. Good luck!
  prefs: []
  type: TYPE_NORMAL
- en: Profiling Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a few different ways to profile a Python application. Profiling means
    having the application run while keeping track of several different parameters,
    such as the number of times a function is called and the amount of time spent
    inside it. Profiling can help us find the bottlenecks in our application, so that
    we can improve only what is really slowing us down.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you take a look at the profiling section in the standard library official
    documentation, you will see that there are a couple of different implementations
    of the same profiling interface—`profile` and `cProfile`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`cProfile` is recommended for most users, it''s a C extension with reasonable
    overhead that makes it suitable for profiling long-running programs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`profile` is a pure Python module whose interface is imitated by `cProfile`,
    but which adds significant overhead to profiled programs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This interface does **determinist profiling**, which means that all function
    calls, function returns, and exception events are monitored, and precise timings
    are made for the intervals between these events. Another approach, called **statistical
    profiling**, randomly samples the effective instruction pointer, and deduces where
    time is being spent.
  prefs: []
  type: TYPE_NORMAL
- en: The latter usually involves less overhead, but provides only approximate results.
    Moreover, because of the way the Python interpreter runs the code, deterministic
    profiling doesn't add as much overhead as one would think, so I'll show you a
    simple example using `cProfile` from the command line.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''re going to calculate Pythagorean triples (I know, you''ve missed them...)
    using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The script is extremely simple; we iterate over the interval [`1`, `mx`] with
    `a` and `b` (avoiding repetition of pairs by setting `b >= a`) and we check whether
    they belong to a right triangle. We use `calc_hypotenuse` to get `hypotenuse`
    for `a` and `b`, and then, with `is_int`, we check whether it is an integer, which
    means (*a*, *b*, *c*) is a Pythagorean triple. When we profile this script, we
    get information in a tabular form. The columns are `ncalls`, `tottime`, `percall`,
    `cumtime`, `percall`, and `filename:lineno(function)`. They represent the amount
    of calls we made to a function, how much time we spent in it, and so on. I''ll
    trim a couple of columns to save space, so if you run the profiling yourself—don''t
    worry if you get a different result. Here is the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Even with this limited amount of data, we can still infer some useful information
    about this code. First, we can see that the time complexity of the algorithm we
    have chosen grows with the square of the input size. The amount of times we get
    inside the inner loop body is exactly *mx (mx + 1) / 2*. We run the script with
    `mx = 1000`, which means we get `500500` times inside the inner `for` loop. Three
    main things happen inside that loop: we call `calc_hypotenuse`, we call `is_int`,
    and, if the condition is met, we append it to the `triples` list.'
  prefs: []
  type: TYPE_NORMAL
- en: Taking a look at the profiling report, we notice that the algorithm has spent
    `0.393` seconds inside `calc_hypotenuse`, which is way more than the `0.096` seconds
    spent inside `is_int`, given that they were called the same number of times, so
    let's see whether we can boost `calc_hypotenuse` a little.
  prefs: []
  type: TYPE_NORMAL
- en: 'As it turns out, we can. As I mentioned earlier in this book, the `**` power
    operator is quite expensive, and in `calc_hypotenuse`, we''re using it three times.
    Fortunately, we can easily transform two of those into simple multiplications,
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: This simple change should improve things. If we run the profiling again, we
    see that `0.393` is now down to `0.137`. Not bad! This means now we're spending
    only about 37% of the time inside `calc_hypotenuse` that we were before.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see whether we can improve `is_int` as well, by changing it, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: This implementation is different, and the advantage is that it also works when
    `n` is an integer. Alas, when we run the profiling against it, we see that the
    time taken inside the `is_int` function has gone up to `0.135` seconds, so, in
    this case, we need to revert to the previous implementation. You will find the
    three versions in the source code for the book.
  prefs: []
  type: TYPE_NORMAL
- en: This example was trivial, of course, but enough to show you how one could profile
    an application. Having the amount of calls that are performed against a function
    helps us better understand the time complexity of our algorithms. For example,
    you wouldn't believe how many coders fail to see that those two `for` loops run
    proportionally to the square of the input size.
  prefs: []
  type: TYPE_NORMAL
- en: 'One thing to mention: depending on what system you''re using, results may be
    different. Therefore, it''s quite important to be able to profile software on
    a system that is as close as possible to the one the software is deployed on,
    if not actually on that one.'
  prefs: []
  type: TYPE_NORMAL
- en: When to profile?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Profiling is super cool, but we need to know when it is appropriate to do it,
    and in what measure we need to address the results we get from it.
  prefs: []
  type: TYPE_NORMAL
- en: Donald Knuth once said, <q class="calibre30">*"premature optimization is the
    root of all evil"*,</q> and, although I wouldn't have put it down so drastically,
    I do agree with him. After all, who am I to disagree with the man who gave us
    *The Art of Computer Programming, TeX*, and some of the coolest algorithms I have
    ever studied when I was a university student?
  prefs: []
  type: TYPE_NORMAL
- en: 'So, first and foremost: *correctness*. You want your code to deliver the correct
    results, therefore write tests, find edge cases, and stress your code in every
    way you think makes sense. Don''t be protective, don''t put things in the back
    of your brain for later because you think they''re not likely to happen. Be thorough.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Second, take care of coding *best practices*. Remember the following—readability,
    extensibility, loose coupling, modularity, and design. Apply OOP principles: encapsulation,
    abstraction, single responsibility, open/closed, and so on. Read up on these concepts.
    They will open horizons for you, and they will expand the way you think about
    code.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Third, *refactor like a beast!* The Boy Scouts rule says:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Always leave the campground cleaner than you found it*."'
  prefs: []
  type: TYPE_NORMAL
- en: Apply this rule to your code.
  prefs: []
  type: TYPE_NORMAL
- en: And, finally, when all of this has been taken care of, then and only then, take
    care of optimizing and profiling.
  prefs: []
  type: TYPE_NORMAL
- en: Run your profiler and identify bottlenecks. When you have an idea of the bottlenecks
    you need to address, start with the worst one first. Sometimes, fixing a bottleneck
    causes a ripple effect that will expand and change the way the rest of the code
    works. Sometimes this is only a little, sometimes a bit more, according to how
    your code was designed and implemented. Therefore, start with the biggest issue
    first.
  prefs: []
  type: TYPE_NORMAL
- en: One of the reasons Python is so popular is that it is possible to implement
    it in many different ways. So, if you find yourself having trouble boosting up
    some part of your code using sheer Python, nothing prevents you from rolling up
    your sleeves, buying 200 liters of coffee, and rewriting the slow piece of code
    in C—guaranteed to be fun!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored the world of testing, exceptions, and profiling.
  prefs: []
  type: TYPE_NORMAL
- en: I tried to give you a fairly comprehensive overview of testing, especially unit
    testing, which is the kind of testing that a developer mostly does. I hope I have
    succeeded in channeling the message that testing is not something that is perfectly
    defined that you can learn from a book. You need to experiment with it a lot before
    you get comfortable. Of all the efforts a coder must make in terms of study and
    experimentation, I'd say testing is the one that is the most important.
  prefs: []
  type: TYPE_NORMAL
- en: We briefly saw how we can prevent our program from dying because of errors,
    called exceptions, that happen at runtime. And, to steer away from the usual ground,
    I have given you an example of a somewhat unconventional use of exceptions to
    break out of nested `for` loops. That's not the only case, and I'm sure you'll
    discover others as you grow as a coder.
  prefs: []
  type: TYPE_NORMAL
- en: At the end, we very briefly touched on profiling, with a simple example and
    a few guidelines. I wanted to talk about profiling for the sake of completeness,
    so at least you can play around with it.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we're going to explore the wonderful world of secrets,
    hashing, and creating tokens.
  prefs: []
  type: TYPE_NORMAL
- en: I am aware that I gave you a lot of pointers in this chapter, with no links
    or directions. I'm afraid this was by choice. As a coder, there won't be a single
    day at work when you won't have to look something up in a documentation page,
    in a manual, on a website, and so on. I think it's vital for a coder to be able
    to search effectively for the information they need, so I hope you'll forgive
    me for this extra training. After all, it's all for your benefit.
  prefs: []
  type: TYPE_NORMAL
