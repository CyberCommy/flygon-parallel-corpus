- en: Kubernetes Concepts and Windows Support
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we focused on containerization and Docker support
    on the Windows platform. These concepts were mainly limited to single-machine
    scenarios, where the application requires only one container host. For production-grade
    distributed container systems, you have to consider different aspects, such as
    scalability, high availability, and load balancing, and this always requires orchestrating
    containers running on multiple hosts.
  prefs: []
  type: TYPE_NORMAL
- en: '**Container** **orchestration** is a way of managing the container life cycle
    in large, dynamic environments – it ranges from provisioning and deploying containers
    to managing networks, providing redundancy and high-availability of containers,
    automatically scaling up and down container instances, automated health checks,
    and telemetry gathering. Solving the problem of container orchestration is non-trivial
    – this is why **Kubernetes** (k8s for short, where 8 denotes the number of omitted
    characters) was born.'
  prefs: []
  type: TYPE_NORMAL
- en: The story of Kubernetes dates back to the early 2000s and the Borg system, which
    was developed internally by Google for managing and scheduling jobs at a large
    scale. Subsequently, in the early 2010s, the Omega cluster management system was
    developed at Google as a clean-slate rewrite of Borg. While Omega was still used
    internally by Google only, in 2014, Kubernetes was announced as an open source
    container orchestration solution that takes its roots from both Borg and Omega.
    In July 2015, when the 1.0 version of Kubernetes was released, Google partnered
    with the Linux Foundation to form the **Cloud Native Computing Foundation** (**CNCF**).
    This foundation aims at empowering organizations so that they can build and run
    scalable applications in modern, dynamic environments such as public, private,
    and hybrid clouds. Four years later, in April 2019, Kubernetes 1.14 was released,
    which delivered production-level support for Windows nodes and Windows containers.
    This chapter is all about the current state of Kubernetes with regard to Windows!
  prefs: []
  type: TYPE_NORMAL
- en: '**Cloud-native application** is a commonly used term in container orchestration
    for applications that leverage containerization, cloud computing frameworks, and
    the loose coupling of components (microservices). But it doesn''t necessarily
    mean that cloud-native applications must run in a cloud – they adhere to a set
    of principles that make them easy to be hosted on-premises or in the public/private
    cloud. If you are interested in learning more about CNCF, please refer to the
    official web page: [https://www.cncf.io/](https://www.cncf.io/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes high-level architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Windows and Kubernetes ecosystem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes limitations on Windows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating your own development cluster from scratch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Production cluster deployment strategies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managed Kubernetes providers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you will need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Windows 10 Pro, Enterprise, or Education (version 1903 or later, 64-bit) installed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Desktop for Windows 2.0.0.3 or later installed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Chocolatey package manager for Windows installed ([https://chocolatey.org/](https://chocolatey.org/))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure CLI installed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to install Docker Desktop for Windows and its system requirements was covered
    in [Chapter 1](deffbcf5-3a21-4690-ad42-ae5e4cd97dea.xhtml)*, Creating Containers*.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Chocolatey package manager is not mandatory, but it makes installation
    and application version management much easier. The installation process is documented
    here: [https://chocolatey.org/install](https://chocolatey.org/install).
  prefs: []
  type: TYPE_NORMAL
- en: For Azure CLI, you can find detailed installation instructions in [Chapter 2](43d5e48b-311c-462c-a68e-6a0b5c4224e8.xhtml)*, Managing
    State in Containers**.*
  prefs: []
  type: TYPE_NORMAL
- en: To learn about managed Kubernetes providers, you will need your own Azure account
    in order to create an AKS instance with Windows nodes. If you haven't already
    created an account for the previous chapters in this book, you can read more about
    how to obtain a limited free account for personal use here: [https://azure.microsoft.com/en-us/free/](https://azure.microsoft.com/en-us/free/).
  prefs: []
  type: TYPE_NORMAL
- en: You can download the latest code samples for this chapter from this book's official
    GitHub repository: [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter04](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter04).
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes high-level architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this and the next section, we will focus on the Kubernetes high-level architecture
    and its core components. If you are already familiar with Kubernetes in general
    but you would like to know more regarding Kubernetes support for Windows, you
    can skip to the *Windows and Kubernetes ecosystem* section.
  prefs: []
  type: TYPE_NORMAL
- en: What is Kubernetes?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In general, Kubernetes can be seen as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A container (microservices) orchestration system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A cluster management system for running distributed applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As a container orchestrator, Kubernetes solves common challenges that arise
    when deploying containerized, cloud-native applications at scale. This includes
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning and deploying containers on multiple container hosts (nodes)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service discovery and load balancing network traffic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatically scaling container instances up and down
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automated rollouts and rollbacks of new container image versions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatic, optimal bin-packing of containers with regard to resources such as
    CPU or memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application monitoring, telemetry gathering, and health checks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orchestrating and abstracting storage (local, on-premises, or the cloud)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the same time, Kubernetes can also be described as a cluster management system –
    the master (or multiple masters, in highly available deployments) is responsible
    for effectively coordinating multiple worker nodes that handle the actual container
    workloads. These workloads are not limited to Docker containers only – Kubernetes
    uses the **Container Runtime Interface** (**CRI**) on worker nodes to abstract
    container runtimes. Eventually, cluster clients (for example, DevOps engineers)
    can manage the cluster using the RESTful API that's been exposed by the master.
    Cluster management is performed using a declarative model, which makes Kubernetes
    very powerful – you describe the desired state and Kubernetes does all the heavy
    lifting in order to transform thecurrent state of the cluster into the desired
    state.
  prefs: []
  type: TYPE_NORMAL
- en: Imperative cluster management by using ad hoc commands is also possible but
    it is generally discouraged for production environments. The operations are performed
    directly on a live cluster and there is no history of previous configurations.
    In this book, we will use the declarative object configuration technique whenever
    possible. For a more detailed discussion regarding Kubernetes cluster management
    techniques, please refer to the official documentation: [https://kubernetes.io/docs/concepts/overview/working-with-objects/object-management/](https://kubernetes.io/docs/concepts/overview/working-with-objects/object-management/).
  prefs: []
  type: TYPE_NORMAL
- en: 'The high-level architecture for Kubernetes can be seen in the following diagram.
    We''ll go through each component in the next few paragraphs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/b69c82e9-b93c-440a-97ba-5e639a928a3e.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's begin by focusing on the role of Kubernetes master, also known as the control
    plane.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes master – control plane
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the Kubernetes cluster, the master (control plane) consists of a set of components
    that are responsible for global decisions regarding the cluster, such as scheduling
    and deploying application instances to worker nodes, as well as managing cluster
    events. Additionally, the master exposes an API for communication for both worker
    nodes and managing clients.
  prefs: []
  type: TYPE_NORMAL
- en: Master components are not restricted to running on a dedicated host; it is also possible
    to have them running on worker nodes. The master node can act as a worker node,
    just like any node in a Kubernetes cluster. However, in general, these are not
    recommended due to reliability reasons – what's more, for production environments,
    you should consider running a highly available Kubernetes setup, which requires
    multiple master nodes running components redundantly.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most significant limitations of running Kubernetes master services
    is that they have to be hosted on a Linux machine. It is not possible to have
    a Windows machine with master components, which means that even if you are planning
    to run Windows containers only, you still need Linux machine(s) as a master. Currently,
    there are no plans for the implementation of Windows-only Kubernetes clusters,
    although this may change as the development of the Windows Subsystem for Linux
    2 progresses.
  prefs: []
  type: TYPE_NORMAL
- en: We will briefly go through the components that compose the master. Let's begin
    by taking a look at the Kubernetes API Server (or `kube-apiserver`, which is the
    binary name of this component).
  prefs: []
  type: TYPE_NORMAL
- en: kube-apiserver
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **Kubernetes API Server** (**kube-apiserver**) is the central component
    in the Kubernetes control plane and acts as a gateway for all interactions between
    clients and cluster components. Its main responsibilities are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Exposing cluster APIs that have been implemented as a set of RESTful endpoints
    over HTTPS. The API is used by clients managing the cluster as well as by internal
    Kubernetes components. All the resources in the Kubernetes cluster are abstracted
    as Kubernetes API objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Persisting cluster state in the `etcd` cluster – each action performed by a
    client or state update reported by a cluster component has to go through the API
    Server and be persisted in the cluster store.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Authentication and authorization of users and service accounts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Validation of requests.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Providing the *watch* API to inform subscribers (for example, other cluster
    components) about changes in the cluster state using incremental notification
    feeds. The watch API is the key concept that makes Kubernetes highly extensible
    and distributed in nature.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In highly available Kubernetes deployments, `kube-apiserver` is hosted on multiple
    master nodes, behind a dedicated load balancer.
  prefs: []
  type: TYPE_NORMAL
- en: etcd cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To persist the cluster state, Kubernetes uses `etcd` – a distributed, reliable
    key-value store that utilizes the Raft distributed consensus algorithm in order
    to provide sequential consistency. The `etcd` cluster is the most important part
    of the control plane – this is the source of truth for the whole cluster, both
    for the current state and the desired state of the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Generally, single-node `etcd` clusters are only recommended for testing purposes.
    For production scenarios, you should always consider running at least a five-member
    cluster (with an odd number of members) in order to provide sufficient fault tolerance.
  prefs: []
  type: TYPE_NORMAL
- en: 'When choosing an `etcd` cluster deployment topology, you can consider either
    a stacked etcd topology or an external etcd topology. A stacked etcd topology
    consists of one etcd member per Kubernetes master instance, whereas an external
    etcd topology utilizes an etcd cluster deployed separately from Kubernetes and
    is available via a load balancer. You can find out more about these topologies
    in the official documentation: [https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/).'
  prefs: []
  type: TYPE_NORMAL
- en: The *watch* protocol that's exposed by `etcd` is also a core functionality for
    the watch API in Kubernetes, which is provided by `kube-apiserver` for other components.
  prefs: []
  type: TYPE_NORMAL
- en: kube-scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The main responsibility of the **Kubernetes Scheduler** (**kube-scheduler**)
    component is scheduling container workloads (Kubernetes Pods) and assigning them
    to healthy worker nodes that fulfill the criteria required for running a particular
    workload.
  prefs: []
  type: TYPE_NORMAL
- en: A **Pod** is a group of one or more containers with a shared network and storage
    and is the smallest Deployment unit in the Kubernetes system. We will cover this
    Kubernetes object in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scheduling is performed in two phases:'
  prefs: []
  type: TYPE_NORMAL
- en: Filtering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the filtering phase, `kube-scheduler` determines the set of nodes that are
    capable of running a given Pod. This includes checking the actual state of nodes
    and verifying any resource requirements specified by the Pod definition. At this
    point, if there are no nodes that can run a given Pod, the Pod cannot be scheduled
    and remains pending. Next, in the scoring step, the scheduler assigns scores for
    each node based on a set of policies. Then, the Pod is assigned by the scheduler
    to the node with the highest score.
  prefs: []
  type: TYPE_NORMAL
- en: You can read more about available policies in the official documentation: [https://kubernetes.io/docs/concepts/scheduling/kube-scheduler/#kube-scheduler-implementation](https://kubernetes.io/docs/concepts/scheduling/kube-scheduler/#kube-scheduler-implementation).
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes design offers a great deal of extensibility and possibility to replace
    components. Kube-scheduler is one of the components that's used to demonstrate
    this principle. Even if its internal business logic is complex (all efficient
    scheduling heuristics are rather complex...), the scheduler only needs to watch
    for *unassigned* Pods, determine the best node for them, and inform the API Server
    about the assignment. You can check out an example implementation of a custom
    scheduler here: [https://banzaicloud.com/blog/k8s-custom-scheduler/](https://banzaicloud.com/blog/k8s-custom-scheduler/).
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's take a look at `kube-controller-manager`.
  prefs: []
  type: TYPE_NORMAL
- en: kube-controller-manager
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Kubernetes Controller Manager** (**kube-controller-manager**) is a component
    that is responsible for running core reconciliation and control loops in the cluster.
    The Controller Manager consists of a set of separate, specialized controllers
    that act independently. The main aim of controllers is to observe the *current*
    and the *desired* cluster state that's exposed by API Server and command changes
    that attempt to transform the *current* state to the *desired* one.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most important controllers that are shipped in `kube-controller-manager`
    binary are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Node** **Controller (formally named nodelifecycle)**: This observes the status
    of the node and reacts when it is unavailable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ReplicaSet Controller (replicaset)**: This is responsible for ensuring that
    the correct number of Pods for each ReplicaSet API object is running.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment Controller (deployment)**: This is responsible for managing associated
    ReplicaSet API objects and performing rollouts and rollbacks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Endpoints Controller (endpoint)**: This manages Endpoint API objects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service Account Controller (serviceaccount) and Token Controller (serviceaccount-token)**:
    This is responsible for creating default accounts and access tokens for new namespaces.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can think of kube-controller-manager as a Kubernetes brain that ensures
    that the *current* state of the cluster moves toward the *desired* cluster state.
  prefs: []
  type: TYPE_NORMAL
- en: cloud-controller-manager
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Originally a part of `kube-controller-manager`, the **Kubernetes Cloud Controller
    Manager** (**cloud-controller-manager**) provides cloud-specific control loops.
    The reason for the separation of Cloud Controller Manager is to allow for the
    easier evolution of cloud-specific connectors (providers) code, which in most
    cases, is released at different cadences than the core Kubernetes code.
  prefs: []
  type: TYPE_NORMAL
- en: As of Kubernetes 1.17, cloud-controller-manager is still in its beta stage.
    You can check the current status of the feature in the official documentation: [https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller](https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller).
  prefs: []
  type: TYPE_NORMAL
- en: 'When enabling cloud-controller-manager, the cloud-specific control loops in
    kube-controller-manager must be disabled. Then, the following controllers will
    depend on the cloud provider''s implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Node Controller**: The provider is used for determining a node''s status
    and detecting if the node was deleted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Route Controller**: Requires the provider for setting up network routing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service Controller**: Manages load balancers via the provider.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'V**olume Controller**: Manages storage volumes using the provider.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The list of external cloud providers offered as a part of Kubernetes constantly
    evolves and can be checked in the official documentation ([https://kubernetes.io/docs/concepts/cluster-administration/cloud-providers/](https://kubernetes.io/docs/concepts/cluster-administration/cloud-providers/))
    and on Kubernetes' organization GitHub page ([https://github.com/kubernetes?q=cloud-provider-&type=&language=](https://github.com/kubernetes?q=cloud-provider-&type=&language=)).
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes nodes – data plane
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the Kubernetes cluster, the data plane consists of nodes (formerly known
    as *minions*) that are responsible for running container workloads scheduled by
    the master. Nodes can be physical bare-metal machines or virtual machines, which
    gives flexibility when designing a cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram summarizes the architecture and components that compose
    Kubernetes nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/d035407d-e290-4389-a794-5f072d975582.png)'
  prefs: []
  type: TYPE_IMG
- en: In terms of Windows support, all node components can run both on Windows and
    Linux machines. This means that Windows Kubernetes nodes are visible to the master
    in the same way as Linux nodes and from this perspective, they only differ by
    the type of containers that they can support.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main components of Kubernetes nodes are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**kubelet**: The main Kubernetes agent, which ensures that container workloads
    (Pods) are executed on the node.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Container runtime**: The software that''s responsible for managing containers.
    It''s abstracted by the **Container Runtime Interface** (**CRI**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kube-proxy**: The network proxy that''s responsible for managing the local
    node network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's take a look at `kubelet` first.
  prefs: []
  type: TYPE_NORMAL
- en: kubelet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Running on every node in the cluster, `kubelet` is a service that''s responsible
    for ensuring that container workloads (Pods) that have been assigned by the control
    plane are executed. Additionally, it is also responsible for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Reporting node and Pods statuses to the API Server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reporting resource utilization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing the node registration process (when joining a new node to the cluster)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Executing liveness and readiness Probes (health checks) and reporting their
    status to the API Server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To perform actual container-related operations, kubelet uses a container runtime.
  prefs: []
  type: TYPE_NORMAL
- en: Container runtime
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubelet is not directly coupled with Docker – in fact, as we mentioned in the
    introduction to this section, Docker is not the only **container runtime** that
    Kubernetes supports. To perform container-related tasks, for example, pulling
    an image or creating a new container, kubelet utilizes the **Container Runtime
    Interface** (**CRI**), which is a plugin interface that abstracts all common container
    operations for different runtimes.
  prefs: []
  type: TYPE_NORMAL
- en: The actual definition of the Container Runtime Interface is a protobuf API specification,
    which can be found in the official repository: [https://github.com/kubernetes/cri-api/](https://github.com/kubernetes/cri-api/).
    Any container runtime that implements this specification can be used to execute
    container workloads in Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Currently, there are numerous container runtimes that can be used with Kubernetes
    on Linux. The most popular are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Docker**: The *traditional* Docker runtime, abstracted by `dockershim`, which
    is the CRI implementation for `kubelet`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CRI-containerd**: In short, `containerd` is a component of Docker that is
    responsible for the management of containers. Currently, CRI-containerd is the
    recommended runtime for Kubernetes on Linux. For more information, please visit [https://containerd.io/](https://containerd.io/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CRI-O**: The container runtime implementation dedicated to CRI that follows
    the **Open Containers Initiative** (**OCI**) specification. For more information,
    please visit [https://cri-o.io/](https://cri-o.io/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gVisor**: The OCI-compatible sandbox runtime for containers that''s integrated
    with Docker and containerd. For more information, please visit [https://gvisor.dev/](https://gvisor.dev/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The difference between dockershim and CRI-containerd can be seen in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/319c91e3-e62c-451e-90f5-5d6929202701.png)'
  prefs: []
  type: TYPE_IMG
- en: The CRI-containerd runtime offers a much simpler architecture with less communication
    between daemons and processes, thereby eliminating the traditional Docker Engine.
    This solution aims at providing a *stripped down* Docker runtime that exposes
    the crucial components for Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: If you are interested in getting a more historical context regarding Docker
    and containerd separation, you can read the following article: [http://alexander.holbreich.org/docker-components-explained/](http://alexander.holbreich.org/docker-components-explained/).
  prefs: []
  type: TYPE_NORMAL
- en: For Windows, the list is much shorter, and currently includes Docker (Enterprise
    Edition 18.09+, also abstracted by dockershim) and incoming support for CRI-containerd.
    This is expected to be available when a stable version of containerd, 1.3, is
    released and *runhcs shim* is fully supported. This will also come with new support
    for Hyper-V isolation for containers, which is currently (as of Kubernetes 1.17)
    implemented without CRI-containerd as a limited experimental feature.
  prefs: []
  type: TYPE_NORMAL
- en: kube-proxy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the Kubernetes cluster, networking rules and routes on nodes are managed
    by kube-proxy,which runs on every node. These rules allow communication between
    Pods and external clients to Pods and are a vital part of the Service API Object.
    On the Linux platform, kube-proxy configures rules using iptables (most commonly),
    whereas on the Windows platform, the **Host Networking Service** (**HNS**) is
    used.
  prefs: []
  type: TYPE_NORMAL
- en: We will cover Kubernetes networking in more detail in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: DNS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An internal DNS server is optional and can be installed as an add-on, but it
    is highly recommended in standard deployments as it simplifies service discovery
    and networking. Currently, the default DNS server used by Kubernetes is CoreDNS
    ([https://coredns.io/](https://coredns.io/)).
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes automatically adds an internal static IP address of the DNS server
    to the domain name resolution configuration for each container. This means that
    processes running in Pods can communicate with Services and Pods running in the
    cluster just by knowing their domain name, which will be resolved to the actual
    internal IP address. The concept of Kubernetes Service objects will be covered
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's take a look at the most commonly used Kubernetes objects.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Setting up a Kubernetes cluster with Windows nodes is complex and will be covered
    later in this book, and the principles will be demonstrated on Linux examples.
    From a Kubernetes API Server perspective, Windows and Linux nodes operate in almost
    the same way.
  prefs: []
  type: TYPE_NORMAL
- en: In the Kubernetes cluster, the cluster state is managed by the kube-apiserver
    component and is persisted in the `etcd` cluster. The state is abstracted and
    modeled as a set of Kubernetes objects – these entities describe what containerized
    applications should be run, how they should be scheduled, and are the policies
    concerning restarting or scaling them. If there is anything you would like to
    achieve in your Kubernetes cluster, then you have to create or update Kubernetes
    objects. This type of model is called a **declarative model** – you declare your intent
    and Kubernetes is responsible for changing the current state of the cluster to
    the desired (intended) one. The declarative model and the idea of maintaining
    the desired state is what makes Kubernetes so powerful and easy to use.
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we will follow the convention from the official documentation,
    where objects are capitalized; for example, Pod or Service.
  prefs: []
  type: TYPE_NORMAL
- en: 'The anatomy of each Kubernetes Object is exactly the same; it has two fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Spec**: This defines the *desired state* of the Object. This is where you
    define your requirements when creating or updating an Object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Status**: This is provided by Kubernetes and describes the *current state*
    of the Object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with Kubernetes objects always requires using the Kubernetes API. Most
    commonly, you will manage Kubernetes objects using the **command-line interface**
    (**CLI**) for Kubernetes, which comes as a `kubectl` binary. It is also possible
    to interact with the Kubernetes API directly using client libraries.
  prefs: []
  type: TYPE_NORMAL
- en: The installation of `kubectl` and examples of its usage will be covered in [Chapter
    6](791e78c0-f625-4232-9907-36e25ec2767d.xhtml), *Interacting with Kubernetes Clusters*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s take a quick look at how an example Kubernetes Object is structured.
    When interacting directly with the Kubernetes API, objects must be specified in
    JSON format. However, `kubectl` allows us to use YAML manifest files, which are
    translated into JSON when you perform operations. Using YAML manifest files is
    generally recommended and you can expect most of the examples that you find in
    the documentation to follow this convention. As an example, we will use a definition
    of a Pod that consists of a single nginx web server Linux container, stored in
    a file called `nginx.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The required parts in the manifest file are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`apiVersion`: The version of the Kubernetes API being used for this Object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kind`: The type of Kubernetes Object. In this case, this is `Pod`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`metadata`: Additional metadata for the Object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`spec`: The Object Spec. In the example specification, the nginx container
    uses the `nginx:1.17` Docker image and exposes port `80`. The Spec is different
    for every Kubernetes Object and has to follow the API documentation. For example,
    for Pod, you can find the API reference here: [https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#podspec-v1-core](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#podspec-v1-core).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Creating the Pod is now as simple as running the following `kubectl apply`
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'If you would like to try out this command without a local Kubernetes cluster,
    we recommend using one for Kubernetes playground; for example, [https://www.katacoda.com/courses/kubernetes/playground](https://www.katacoda.com/courses/kubernetes/playground):'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the master window, run the following `kubectl` command, which will apply
    a manifest file hosted on GitHub:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'After a few seconds, the Pod will be created and its `STATUS` should be `Running`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `curl` command in the master window to get the Pod''s IP (in this case, `10.40.0.1`)
    to verify that the container is indeed running. You should see the raw contents
    of the default nginx web page:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '`kubectl` currently offers two declarative approaches for managing Kubernetes
    objects: manifest files and kustomization files. Using the kustomize approach
    is much more powerful as it organizes manifest files and configuration generation
    in a predictable structure. You can learn more about kustomize here: [https://github.com/kubernetes-sigs/kustomize/tree/master/docs](https://github.com/kubernetes-sigs/kustomize/tree/master/docs).'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's take a closer look at the Pod API Object.
  prefs: []
  type: TYPE_NORMAL
- en: Pods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes uses Pods as its basic, atomic unit for Deployment and scaling,
    and represents processes running in the cluster – an analogy from Microsoft Hyper-V
    would be a single virtual machine that you deploy as an atomic unit in your Hyper-V
    cluster. A Kubernetes Pod consists of one or more containers that share kernel
    namespaces, IPC, network stack (you address them by the same cluster IP and they
    can communicate via localhost), and storage. To understand Pods, it is good to
    know the origin of the name: in the English language, a pod is a group of whales,
    and Docker uses a whale for its logo – think of a whale as a Docker container!'
  prefs: []
  type: TYPE_NORMAL
- en: 'In their simplest form, you can create single-container Pods – this is what
    we did in the introduction to this section when demonstrating nginx Pod creation.
    For some scenarios, you may need multiple-container Pods, where the main container
    is accompanied by additional containers that serve multiple purposes. Let''s take
    a look at a few of these:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sidecar** **containers**, which can perform various *helper* operations,
    such as log collection, data synchronization for the main container, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adapter** **containers**, which can normalize output or monitor the data
    of the main container so that it can be used by other services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ambassador** **containers**, which proxy the communication of the main container
    with the outside world.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Init** **containers**, which are specialized containers that run before application
    containers in the Pod. For example, they may set up the environment, which isn''t
    performed in the main container image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Technically, even single-container Pods contain an extra infra container, which
    is often a pause image. It acts as a *parent* container for all containers in
    the pod and enables kernel namespaces sharing. If you are interested in more details
    regarding infra containers, please refer to this article: [https://www.ianlewis.org/en/almighty-pause-container](https://www.ianlewis.org/en/almighty-pause-container).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The concept of a Pod can be seen in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bb6c0115-edb1-429f-ac9c-f3614a78d1c9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There are a couple of considerations that you should keep in mind when using
    Pods:'
  prefs: []
  type: TYPE_NORMAL
- en: Pod's containers always run on one node and once a Pod is created, it is always
    bound to one node.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You scale your application by adding more Pods, not by adding more containers
    inside the same Pod.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Pod is considered *ready* and able to serve requests when *all* its containers
    are ready. The status of a container is determined by Probes, for example, liveness
    and readiness Probes, which can be defined in the Spec.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pods are ephemeral. They are created, they die, and new ones are recreated in
    their place (if needed).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When a Pod is recreated, it receives a new cluster IP. This means that your
    application design should never rely on static IP assignments and assume that
    the Pod may even be recreated on a different node.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will rarely create bare Pods independently, as we did in the introduction
    to the section. In most cases, they are managed through Deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Pods have a finite life cycle and if the containers inside crash or exit, they
    may not be automatically recreated, depending on the restart policy. To maintain
    a desired number of Pods with a certain Spec and metadata in the cluster, you
    need `ReplicaSet` objects.
  prefs: []
  type: TYPE_NORMAL
- en: ReplicaSets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes builds many powerful concepts on top of Pods, which makes container
    management easy and predictable. The simplest one is the `ReplicaSet`API Object (the
    successor of ReplicationController), which aims at maintaining a fixed number
    of healthy Pods (replicas) to fulfill certain conditions. In other words, if you
    say *I want three nginx Pods running in my cluster*, ReplicaSet does that for
    you. If a Pod is destroyed, `ReplicaSet` will automatically create a new Pod replica
    to restore the desired state.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at an example ReplicaSet manifest `nginx-replicaset.yaml` file
    that creates three replicas of the nginx Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'There are three main components of the `ReplicaSet` Spec:'
  prefs: []
  type: TYPE_NORMAL
- en: '`replicas`: Defines the number of Pod replicas that should run using the given
    `template` and matching `selector`. Pods may be created or deleted in order to
    maintain the required number.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`selector`: A label selector, which defines how to identify Pods that the ReplicaSet
    will acquire. Note that this may have a consequence of acquiring existing bare
    Pods by `ReplicaSet`!'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`template`: Defines the template for Pod creation. Labels used in metadata
    must positively match the `selector`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can apply the `ReplicaSet` manifest in a similar manner to how we applied
    a Pod in the Katacoda playground:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You can observe how three Pod replicas are created using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'ReplicaSets mark the newly created or acquired Pods by assigning themselves
    to the `.metadata.ownerReferences` property of the Pod (if you are curious, you
    can check by using the `kubectl get pod <podId> -o yaml` command). This means
    that if you create exactly the same ReplicaSet, with exactly the same selectors
    but with a different name, for example, `nginx-replicaset-example2`, they will
    not *steal* Pods from each other. However, if you have already created bare Pods
    with matching labels, such as `environment: test`, the ReplicaSet will acquire
    them and may even delete the Pods if the number of replicas is too high!'
  prefs: []
  type: TYPE_NORMAL
- en: If you really need to create a single Pod in Kubernetes cluster, it is a much
    better idea to use a `ReplicaSet` with the `replicas` field set to 1, which will
    act as a container *supervisor*. In this manner, you will prevent the creation
    of bare Pods without owners that are tied to the original node only.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be seen in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/4a6bf410-9102-4124-9fc9-1ac27d4ef670.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Usually, you don''t create ReplicaSets on your own as they are not capable
    of performing rolling updates or rolling back to earlier versions easily. To facilitate
    such scenarios, Kubernetes provides objects built on top of ReplicaSets: Deployment
    and StatefulSet. Let''s take a look at Deployment first.'
  prefs: []
  type: TYPE_NORMAL
- en: Deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At this point, you already know the purpose of Pods and ReplicaSets. Deployments
    are Kubernetes objects that provide declarative updates for Pods and ReplicaSets.
    You can declaratively perform operations such as the following by using them:'
  prefs: []
  type: TYPE_NORMAL
- en: Perform a *rollout* of a new ReplicaSet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change the Pod template and perform a controlled rollout. The old ReplicaSet
    will be gradually scaled down, whereas the new ReplicaSet will scale up at the
    same rate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform a *rollback* to an earlier version of the Deployment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scale the ReplicaSet up or down.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The relationship of Deployment to ReplicaSets and Pods can be seen in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/553efa0f-59d7-44b6-94eb-5a837aaf5785.png)'
  prefs: []
  type: TYPE_IMG
- en: You should **avoid** managing ReplicaSets created by a Deployment on your own.
    If you need to make any changes to the ReplicaSet, perform the changes on the
    owning Deployment Object.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the issue of the *accidental* acquisition of Pods by ReplicaSets managed
    by Deployments does not exist. The reason for this is that Pods and ReplicaSets
    use a special, automatically generated label called `pod-template-hash` that guarantees
    the uniqueness of the selection.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at an example Deployment manifest in the `nginx-deployment.yaml`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the basic structure is almost identical to `ReplicaSet`, but
    there are significant differences in how Deployment behaves when you perform a
    declarative update. Let''s quickly demonstrate this in the playground:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create manually the Deployment manifest file or download it using the `wget`
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the Deployment manifest file using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The `--record` flag adds a metadata annotation of `kubernetes.io/change-cause` to
    API objects that were created or modified by the preceding command. This feature
    allows you to easily track changes in your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Wait for the Deployment to fully roll out (you can observe the number of ready
    Pods in your deployment using `kubectl get deployment -w`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, change the Pod Spec in the template in the YAML manifest; for example,
    change `.spec.template.spec.containers[0].image` to `nginx:1.**16**` and apply
    the Deployment manifest again.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Immediately after that, observe how the rollout progresses using the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The Spec of Deployment is much richer than ReplicaSet. You can check the official
    documentation for more details: [https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#writing-a-deployment-spec](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#writing-a-deployment-spec).
    The official documentation contains multiple use cases of Deployments, all of
    which are described in detail: [https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#use-case](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#use-case).
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the declarative update to the Deployment template definition
    caused a smooth rollout of new Pod replicas. The old ReplicaSet was scaled down
    and, simultaneously, a new ReplicaSet, with a new Pod template, was created and
    gradually scaled up. You can now try performing the same operation with an `image`
    update for an existing bare ReplicaSet and you will see that... actually, nothing
    happens. This is because ReplicaSet only uses a Pod template to create new Pods.
    Existing Pods will not be updated or removed by such a change.
  prefs: []
  type: TYPE_NORMAL
- en: A rollout is only triggered when the `.spec.template` for Deployment is changed.
    Other changes to the Deployment manifest will not trigger a rollout.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s take a look at a concept similar to Deployments: StatefulSets.'
  prefs: []
  type: TYPE_NORMAL
- en: StatefulSets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Deployments are usually used to deploy stateless components of your application.
    For stateful components, Kubernetes provides another API Object named `StatefulSet`.
    The principle of this operation is very similar to Deployment – it manages ReplicaSets
    and Pods in a declarative way and provides smooth rollouts and rollbacks. However,
    there are some key differences:'
  prefs: []
  type: TYPE_NORMAL
- en: StatefulSets ensure a deterministic (sticky) ID of Pods, which consists of `<statefulSetName>-<ordinal>`.
    For Deployments, you would have a random ID consisting of `<deploymentName>-<randomHash>`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For StatefulSets, the Pods are started and terminated in a specific, predictable
    order while scaling the ReplicaSet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In terms of storage, Kubernetes creates PersistentVolumeClaims based on `volumeClaimTemplates`
    of the StatefulSet Object for each Pod in the StatefulSet and always attaches
    this to the Pod with the same ID. For Deployments, if you choose to use `volumeClaimTemplates`,
    Kubernetes will create a single PersistentVolumeClaim and attach the same to all
    the Pods in the Deployment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You need to create a headless Service Object that is responsible for managing
    the deterministic network identity (DNS names) for Pods. The Headless Service
    allows us to return all Pod IPs behind the Service as DNS A records instead of
    a single DNS A record with a Service Cluster IP.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: StatefulSets use a similar Spec to Deployments – you can find out more regarding
    StatefulSets by looking at the official documentation: [https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/).
  prefs: []
  type: TYPE_NORMAL
- en: DaemonSets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A DaemonSet is another controller-backed Object that is similar to a ReplicaSet
    but aims at running *exactly one* templated Pod replica per node in the cluster
    (optionally matching selectors). The most common use cases for running a DaemonSet
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Managing monitoring telemetry for a given cluster node, for example, running
    Prometheus Node Exporter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running a log collection daemon on each node, for example, `fluentd` or `logstash`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running troubleshooting Pods, for example, node-problem-detector ([https://github.com/kubernetes/node-problem-detector](https://github.com/kubernetes/node-problem-detector))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One of the DaemonSets that may run on your cluster out of the box is `kube-proxy`.
    In a standard cluster deployment performed by kubeadm, `kube-proxy` is distributed
    to nodes as a DaemonSet. You can also verify this on your Katacoda playground:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: If you would like to find out more about DaemonSets, please refer to the official
    documentation: [https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/).
  prefs: []
  type: TYPE_NORMAL
- en: Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pods that are created by ReplicaSets or Deployments have a finite life cycle.
    At some point, you can expect them to be terminated and new Pod replicas with new
    IP addresses will be created in their place. So, what if you have a Deployment
    running web server Pods that need to communicate with Pods that have been created
    as a part of another Deployment, for example, backend Pods?  Web server Pods cannot
    assume anything about IP addresses or the DNS names of backend Pods, as they may
    change over time. This issue is resolved with Service API objects, which provide
    reliable networking for a set of Pods.
  prefs: []
  type: TYPE_NORMAL
- en: In general, Services target a set of Pods, and this is determined by label selectors.
    The most common scenario is exposing a Service for an existing Deployment by using
    exactly the same label selector. The Service is responsible for providing a reliable
    DNS name and IP address, as well as for monitoring selector results and updating
    the associated Endpoint Object with the current IP addresses of matching Pods.
  prefs: []
  type: TYPE_NORMAL
- en: For internal clients (Pods in the cluster), the communication to Pods behind
    a service is transparent – they use the Cluster IP or DNS name of the Service
    and the traffic is routed to one of the destination Pods. Routing capabilities
    are provided by kube-proxy, but it is important to know that the traffic is not
    routed through any master components – kube-proxy implements routing at the operating
    system kernel level and directly routes this to an appropriate Pod's IP address.
    In its simplest form, the destination Pod will be chosen randomly, but with **IP
    Virtual Server** (**IPVS**) proxy mode, you can have more complex strategies,
    such as least connection or shortest expected delay.
  prefs: []
  type: TYPE_NORMAL
- en: Services can also expose Pods to external traffic.
  prefs: []
  type: TYPE_NORMAL
- en: 'The principle of how Service works can be seen in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/3dcc1fc0-c4d7-4a3c-a0b0-898653ac3af3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s expose an example service for our nginx Deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you don''t have a running Deployment on the Katacoda playground, you can
    create one using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Expose the Service for a deployment using the following `kubectl expose` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This command is *imperative* and should be avoided in favor of the *declarative*
    manifest. This command is equivalent to applying the following Service manifest:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, after the Service has been exposed, create an interactive `busybox` Pod
    and start the Bourne shell process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'When the container shell prompt appears, download the default web page served
    by nginx Pods while using the `nginx-deployment-example` Service name as the DNS
    name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: You can also use a **Fully Qualified Domain Name** (**FQDN**), which is in the
    following form: `<serviceName>.<namespaceName>.svc.<clusterDomain>`. In this case,
    it is `nginx-deployment-example.default.svc.cluster.local`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's take a quick look at objects that provide storage in Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Storage-related objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this book, we will cover Kubernetes storage only when needed as it is a broad
    and complex topic – in fact, storage and managing the stateful components of any
    cluster is often the hardest challenge to solve. If you are interested in details
    regarding storage in Kubernetes, please refer to the official documentation: [https://kubernetes.io/docs/concepts/storage/](https://kubernetes.io/docs/concepts/storage/).
  prefs: []
  type: TYPE_NORMAL
- en: In Docker, we use volumes to provide persistence either on local disk or remote/cloud
    storage using volume plugins. Docker volumes have a life cycle that's independent
    of the containers that consume them. In Kubernetes, there is a similar concept
    of a Volume, which is tightly coupled with a Pod and has the same life cycle as
    the Pod. The most important aspect of Volumes in Kubernetes is that they support
    multiple backing storage providers (types) –– this is abstracted by Volume Plugins
    and, more recently, the **Container Storage Interface** (**CSI**), which is an
    interface for out-of-tree Volume Plugins that are developed independently from
    Kubernetes core. You can, for example, mount an Amazon Web Services EBS volume
    or Microsoft Azure Files SMB Share as a Volume for your Pod – the full list of
    Volume types is available here: [https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes](https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes).
  prefs: []
  type: TYPE_NORMAL
- en: One of the Volume types is **PersistentVolumeClaim **(**PVC**)**,** which aims
    at decoupling Pods from the actual storage. PersistentVolumeClaim is an API Object
    that models a request for the storage of a specific type, class, or size – think
    of saying *I would like 10 GB of read/write-once SSD storage*. To fulfill such
    a request, a **PersistentVolume **(**PV**) API Object is required, which is a
    piece of storage that has been provisioned by the cluster's automation process.
    PersistentVolume types are also implemented as plugins, in a similar manner to
    Volumes.
  prefs: []
  type: TYPE_NORMAL
- en: Now, the whole process of provisioning PersistentVolumes can be dynamic – it
    requires creating a **StorageClass** (**SC**) API Object and using it when defining
    PVCs. When creating a new StorageClass, you provide a **provisioner** (or plugin)
    with specific parameters, and each PVC using the given SC will automatically create
    a PV using the selected provisioner.
  prefs: []
  type: TYPE_NORMAL
- en: 'These dependencies can be seen in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/5c8b7508-c114-417d-a7ef-9954cccadf71.png)'
  prefs: []
  type: TYPE_IMG
- en: 'When you would like to deploy a Pod with a PersistentVolume mounted, the sequence
    of events would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a StorageClass with a desired provisioner.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a PersistentVolumeClaim that uses the SC.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: PersistentVolume is dynamically provisioned.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When creating a Pod, mount the PVC as a Volume.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The idea of dynamically provisioned PersistentVolumes is complemented by the
    concept of StatefulSets. StatefulSets define volumeClaimTemplates, which can be
    used for the dynamic creation of the PersistentVolumeClaims of a given StorageClass.
    By doing this, the whole process of storage provisioning is fully dynamic – you
    just create a StatefulSet and the underlying storage objects are managed by the
    StatefulSet controller. You can find more details and examples here: [https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#stable-storage](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#stable-storage).
  prefs: []
  type: TYPE_NORMAL
- en: Such storage architecture in Kubernetes ensures the portability of workloads,
    which means that you can easily move your Deployments and PersistentVolumeClaims
    to a different cluster. All you need to do is provide a StorageClass that fulfills
    the requirements of PVC. No modifications need to be made to the StatefulSet or
    PVC.
  prefs: []
  type: TYPE_NORMAL
- en: The Windows and Kubernetes ecosystem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Initially, Kubernetes was a Linux-centric solution – this was a result of the
    fact that mainstream containerization also originates from the Linux platform.
    In 2014, Microsoft and Windows were soon to join the containerization world –
    Microsoft announced support for Docker Engine in the upcoming release of Windows
    Server 2016\. Kubernetes **Special Interest Group** (**SIG**) Windows was started
    in March 2016 and in January 2018, Kubernetes 1.9 provided beta support for Windows
    Server Containers. This support eventually matured to production level in April
    2019 when Kubernetes 1.14 was released.
  prefs: []
  type: TYPE_NORMAL
- en: Why is Windows support for Kubernetes so important? Windows dominates in enterprise
    workloads and with Kubernetes being the de facto standard in container orchestration,
    support for Windows brings the possibility of migrating the vast majority of enterprise
    software to containers. Developers and system operators can now leverage the same
    tools and pipelines to deploy both Windows and Linux workloads, scale them in
    a similar way, and monitor them efficiently. From a business perspective, container
    adoption for Windows means better operational costs and better hardware utilization
    than plain VMs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Windows containers support in Kubernetes is constantly evolving and more and
    more limitations are being replaced by new features. There are two key points
    that you need to remember in general:'
  prefs: []
  type: TYPE_NORMAL
- en: Currently, Windows machines can only join the cluster as nodes. There is no
    possibility and no plans for running master components on Windows. Clusters that
    run both Linux and Windows nodes are known as being hybrid or heterogeneous.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will need the latest stable version of Kubernetes and the latest (or almost
    latest) version of the Windows Server operating system to enjoy the full support
    that's on offer. For example, for Kubernetes 1.17, you need Windows Server 1809
    (Semi-Annual Channel release) or Windows Server 2019 (the same release but coming
    from the Long-Term Servicing Channel), although the latest Windows Server, 1903,
    is also supported.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Currently, the amount of documentation regarding Windows support for Kubernetes
    is limited but growing. The best resources out there are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Official Kubernetes documentation: [https://kubernetes.io/docs/setup/production-environment/windows/intro-windows-in-kubernetes/](https://kubernetes.io/docs/setup/production-environment/windows/intro-windows-in-kubernetes/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Official Windows containerization and Kubernetes support documentation: [https://docs.microsoft.com/en-us/virtualization/windowscontainers/kubernetes/getting-started-kubernetes-windows](https://docs.microsoft.com/en-us/virtualization/windowscontainers/kubernetes/getting-started-kubernetes-windows).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Kubernetes Engine How-Tos for Windows: [https://docs.microsoft.com/en-us/azure/aks/windows-container-cli](https://docs.microsoft.com/en-us/azure/aks/windows-container-cli).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SIG-Windows meeting notes and recordings: [https://github.com/kubernetes/community/tree/master/sig-windows](https://github.com/kubernetes/community/tree/master/sig-windows).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes release notes and changelogs (look for SIG-Windows or Windows-related
    points): [https://github.com/kubernetes/kubernetes/releases](https://github.com/kubernetes/kubernetes/releases).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes Community Forums for Windows discussion: [https://discuss.kubernetes.io/c/general-discussions/windows](https://discuss.kubernetes.io/c/general-discussions/windows).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Slack channel for SIG-Windows (you can really find a lot of help here if you
    run into problems!): [https://kubernetes.slack.com/messages/sig-windows](https://kubernetes.slack.com/messages/sig-windows).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's take a look at the current state of Windows support for Kubernetes and
    the limitations as of version 1.17.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes limitations on Windows
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Windows Server containers support comes with a set of limitations that constantly
    change as each new version of Kubernetes is released and new releases of Windows
    Server arrive. Generally, from a Kubernetes API Server and kubelet perspective,
    in heterogeneous (hybrid) Linux/Windows Kubernetes clusters, the containers on
    Windows behave almost the same as Linux containers. However, there are some key
    differences in the details. First, let''s take a look at some high-level, major
    limitations:'
  prefs: []
  type: TYPE_NORMAL
- en: Windows machines can only join the cluster as worker nodes. There is no possibility
    and no plans for running master components on Windows.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Windows Server 1809 or 2019 is the minimal requirement for the OS on worker
    nodes. You cannot use Windows 10 machines as nodes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Enterprise Edition (Basic) 18.09 or later is required as the container
    runtime. Enterprise Edition is available at no extra cost for the Windows Server
    operating system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Windows Server operating system is subject to licensing ([https://www.microsoft.com/en-us/cloud-platform/windows-server-pricing](https://www.microsoft.com/en-us/cloud-platform/windows-server-pricing)).
    Windows Container images are subject to the Microsoft Software Supplemental License
    ([https://docs.microsoft.com/en-us/virtualization/windowscontainers/images-eula](https://docs.microsoft.com/en-us/virtualization/windowscontainers/images-eula)).
    For development and evaluation purposes, you can also use the Evaluations Center: [https://www.microsoft.com/en-us/evalcenter/evaluate-windows-server-2019](https://www.microsoft.com/en-us/evalcenter/evaluate-windows-server-2019).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyper-V isolation for Windows Server containers running on Kubernetes is in
    its experimental phase (alpha) and the current design will be deprecated in favor
    of the containerd implementation of the runtime. Until that time comes, the compatibility
    rules for process-isolated containers apply – you have to run containers with
    a base OS image that matches the host OS version. You can find more details in
    [Chapter 1](deffbcf5-3a21-4690-ad42-ae5e4cd97dea.xhtml), *Creating Containers*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Linux Containers on Windows** (**LCOW**) is not supported.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Probably the most relevant to you is as follows: setting up a local Kubernetes
    development environment for hybrid Linux/Windows clusters is complex and currently,
    no standard solutions, such as Minikube or Docker Desktop for Windows, support
    such a configuration. This means you either need an on-premises, multi-node cluster
    or managed cloud offering to develop and evaluate your scenarios.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Windows nodes join process is not automated as much as it is for Linux nodes. Kubeadm
    will soon support the process of joining Windows nodes, but until then, you have
    to do this manually (with some help from Powershell scripting).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For container workload/compute, some of the limitations are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Privileged containers are not supported on Windows nodes. This may pose some
    other limitations, such as running CSI plugins that must run in privileged mode.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Windows does not have an out of memory process killer and currently, the Pods
    cannot be limited in terms of memory that's used. This is true for process-isolated
    containers but once containerd Hyper-V isolation is available on Kubernetes, a
    limit can be enforced.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You need to specify proper node selectors to prevent, for example, Linux DaemonSets
    from trying to run on Windows nodes. This is technically not a limitation, but
    you should be aware that you need to control these selectors for your deployments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For networking, some of the limitations are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Network management for Windows nodes is more complex and Windows container networking
    is similar to VM networking.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fewer network plugins (CNI) are supported on Windows. You need to choose a solution
    that works for both Linux and Windows nodes in your cluster, for example, Flannel
    with a host-gw backend.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: L2bridge, l2tunnel, or overlay networks do not support IPv6 stack.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kube-proxy for Windows does not support IPVS and advanced load balancing policies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accessing the NodePort Service from the node running the Pod fails.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ingress Controllers can run on Windows, but only if they support Windows containers;
    for example, *ingress-nginx*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pinging external network hosts from inside the cluster with ICMP packets is
    not supported. In other words, don't be surprised when you are testing connectivity
    from Pods to the outside world with ping. You can use `curl` or Powershell `Invoke-WebRequest`
    instead.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For storage, some of the limitations are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Expanding mounted volumes is not possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Secrets that are mounted to Pods are written in clear-text using node storage.
    This may pose security risks and you will need to take additional actions to secure
    the cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Windows nodes only support the following volume types:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FlexVolume (SMB, iSCSI)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: azureDisk
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: azureFile
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: gcePersistentDisk
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: awsElasticBlockStore (since 1.16)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: vsphereVolume (since 1.16)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The following limitations concern Kubernetes 1.17\. Since the list of supported
    functionalities and current limitations changes, we advise that you check the
    official documentation for more up to date details: [https://kubernetes.io/docs/setup/production-environment/windows/intro-windows-in-kubernetes/#supported-functionality-and-limitations](https://kubernetes.io/docs/setup/production-environment/windows/intro-windows-in-kubernetes/#supported-functionality-and-limitations).
  prefs: []
  type: TYPE_NORMAL
- en: Even if there is no support for local development clusters with Windows nodes,
    we'll still take a look at them; it is very likely that support for Windows workloads
    will be available in the near future.
  prefs: []
  type: TYPE_NORMAL
- en: Creating your own development cluster from scratch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, you will learn how to set up a local Kubernetes cluster for
    development and learning on the Windows operating system. We will be using minikube,
    which is the official, recommended toolset, and Docker Desktop for Windows Kubernetes
    clusters. Please note that the current tooling for local clusters *does not* support
    Windows containers as it requires a multi-node setup with Linux master and Windows
    Server nodes. So, in other words, these tools allow you to develop Kubernetes
    applications running in Linux containers on your Windows machine. Basically, they
    provide an optimized Linux VM that hosts a one-node Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: If you wish to experiment, you can use Katacoda Kubernetes playground ([https://www.katacoda.com/courses/kubernetes/playground](https://www.katacoda.com/courses/kubernetes/playground)),
    which was used to demonstrate Kubernetes objects in this chapter, or Play with
    Kubernetes ([https://labs.play-with-k8s.com/](https://labs.play-with-k8s.com/)),
    which is provided by Docker, Inc.
  prefs: []
  type: TYPE_NORMAL
- en: minikube
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Minikube** is available on Windows, Linux, and macOS and aims at providing
    a stable environment for local development with Kubernetes. The key requirement
    on Windows is that a VM hypervisor needs to be installed. For Docker Desktop for
    Windows and Windows containers, we already use Hyper-V, so this will be our choice
    here. If you haven''t enabled Hyper-V yet, please either follow the instructions
    for installing Docker Desktop for Windows in [Chapter 1](deffbcf5-3a21-4690-ad42-ae5e4cd97dea.xhtml),
    *Creating Containers*, or follow the official documentation: [https://docs.microsoft.com/en-us/virtualization/hyper-v-on-windows/quick-start/enable-hyper-v](https://docs.microsoft.com/en-us/virtualization/hyper-v-on-windows/quick-start/enable-hyper-v).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To install minikube, you need to perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: If you don't have a Hyper-V virtual external network switch, create one by opening
    Hyper-V Manager from the Start menu and clicking Virtual Switch Manager... from
    the Actions tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select External and click Create Virtual Switch.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use External Switch as the name of the virtual switch and choose the network
    adapter that you will use to connect to the internet; for example, your Wi-Fi
    adapter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/862cdc2b-1458-4961-980c-26cb2ed45ea9.png)'
  prefs: []
  type: TYPE_IMG
- en: Click OK to accept the changes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Install kubectl (Kubernetes CLI) using the *Chocolatey*package manager. Execute
    the following command as an Administrator in a Powershell window:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Install minikube using Chocolatey, also as an Administrator:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Set Hyper-V as the default virtualization driver for minikube:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Set your virtual external switch to minikube by default:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Start minikube. This may take a few minutes as the VM has to be set up and
    the Kubernetes node needs to be initialized:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: If you need to debug issues on the actual minikube VM (for example, connection
    problems), you can use the `minikube ssh` command or connect to the terminal directly
    from Hyper-V manager. The login username is `docker` and the password is `tcuser`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Verify that the installation was successful by running the `kubectl` command,
    which will be configured to connect to the minikube cluster. You should see a
    variety of Pods running in the `kube-system` namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'You can use any of the example Kubernetes objects that we used in this chapter
    or just create your own:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Eventually, you can try using the Kubernetes Dashboard in your web browser.
    To initialize and open the dashboard, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Now, we will take a look at another approach to local development that uses
    Docker Desktop for Windows.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Desktop for Windows
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For Windows users, using Docker Desktop for Windows and its built-in local Kubernetes
    cluster is the easiest approach. It is also recommended if you are working in
    environments that require a proxy to connect to the internet as the setup is seamless
    and easier compared to minikube.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you haven''t installed Docker Desktop for Windows yet, you should follow
    the instructions in [Chapter 1](deffbcf5-3a21-4690-ad42-ae5e4cd97dea.xhtml), *Creating
    Containers*. To enable the local Kubernetes cluster, you need to follow these
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that you are running in Linux containers mode. DockerDesktopVM will be
    responsible for hosting the Kubernetes cluster. To do that, open the tray icon
    for Docker Desktop for Windows and click Switch to Linux containers....
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When the operation is finished, open Settings from the tray icon.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the Kubernetes section.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check the Enable Kubernetes checkbox and click Apply.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The setup process will take a few minutes to complete .
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you have set up minikube, you need to **switch context** to kubectl. From
    the command line, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, you can also switch the context from Docker Desktop from the
    Windows tray:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/68b696e6-7b41-48ac-84a1-1a88a2695862.png)'
  prefs: []
  type: TYPE_IMG
- en: You will learn more about the kubectl configuration and its contexts in [Chapter
    6](791e78c0-f625-4232-9907-36e25ec2767d.xhtml), *Interacting with Kubernetes Clusters*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, you can start hacking with your local Kubernetes cluster. Let''s deploy
    the Kubernetes Dashboard:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Wait until all the Pods are Running:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Get the default service account token. Copy the `token:` value from the command''s
    output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Enable the kubectl proxy for the cluster. This process should be running while
    you are accessing the dashboard:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Navigate to [http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#!/overview?namespace=kube-system](http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#!/overview?namespace=kube-system).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select Token, paste your default token, and Sign In.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Alternative strategies for setting up a local development Kubernetes cluster with
    Windows containers support involve the automated setup of VMs on your local machine
    using, for example, vagrant. You can explore some of the small projects on GitHub
    that use this approach, but you should expect them to be outdated and no longer
    supported.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will provide a short overview of the production cluster
    deployment strategies that we can perform for Kubernetes clusters, especially
    with Windows nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Production cluster deployment strategies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The deployment of production-level clusters and even the development of clusters
    with Windows nodes requires a very different approach. There are three important
    questions that determine your options for the deployment of Kubernetes clusters:'
  prefs: []
  type: TYPE_NORMAL
- en: Are you deploying the cluster in the cloud or using on-premises bare metal or
    virtual machines?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do you need **high availability** (**HA**) set up?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do you need Windows containers support?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's summarize the most popular deployment tools currently available.
  prefs: []
  type: TYPE_NORMAL
- en: kubeadm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first one is **kubeadm** ([https://github.com/kubernetes/kubeadm](https://github.com/kubernetes/kubeadm)),
    which is a command-line tool focused on getting a minimum viable, secure cluster
    up and running in a user-friendly way. One of the aspects of kubeadm is that it
    is a tool that is scoped only to a given machine and Kubernetes API communication,
    so, in general, it is intended to be a building block for other automation tools
    that manage the cluster as a whole. Its principle is simple: use the `kubeadm
    init` command on master node(s) and `kubeadm join` on worker nodes. The features
    of kubeadm can be summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: You can deploy clusters in on-premises environments and cloud environments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Highly available clusters are supported but as of version 1.17, this feature
    is still in its beta stage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Official Windows support is currently planned for version 1.18\. The current
    version of kubeadm is a good base for starting a hybrid Kubernetes cluster. First,
    you bootstrap master node(s) and (optionally) Linux worker nodes and continue
    with the scripts currently provided by Microsoft for joining Windows nodes ([https://github.com/microsoft/SDN](https://github.com/microsoft/SDN))
    or previewing versions of scripts in the sig-windows-tools GitHub repository ([https://github.com/kubernetes-sigs/sig-windows-tools](https://github.com/kubernetes-sigs/sig-windows-tools)).
    We will be using this approach in [Chapter 7](165c2fcc-4ce8-4dbc-a19c-c7fd427b3379.xhtml),
    *Deploying Hybrid On-Premises Kubernetes Cluster*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are planning to automate how your Kubernetes cluster is provisioned,
    for example, using Ansible, kubeadm is a good starting point as it provides a
    good degree of flexibility and easy configuration.
  prefs: []
  type: TYPE_NORMAL
- en: kops
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next option is using **Kubernetes Operations** (**kops**, [https://github.com/kubernetes/kops](https://github.com/kubernetes/kops)),
    which uses kubeadm internally. Kops aims to manage whole Kubernetes clusters in
    cloud environments – you can think of it as *kubectl for clusters*. Its main features
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Deployment of clusters on Amazon Web Services (officially supported), Google
    Compute Engine, and OpenStack (both in their beta stages). On-premises deployments
    are not supported unless you are running your own deployment of OpenStack. VMware
    vSphere support is in its alpha stage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Production-level support for HA clusters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Windows nodes are not supported.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this book, we will not focus on kops due to its lack of support for Windows.
  prefs: []
  type: TYPE_NORMAL
- en: kubespray
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Kubespray** ([https://github.com/kubernetes-sigs/kubespray](https://github.com/kubernetes-sigs/kubespray))
    is a composition of configurable Ansible playbooks that run kubeadm in order to
    bootstrap fully-functional, production-ready Kubernetes clusters. The main difference
    between kubespray and kops is that kops is more tightly integrated with cloud
    providers, whereas kubespray is aimed at multiple platforms, including bare-metal
    deployments. Its features can be summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Support for installing Kubernetes clusters for multiple cloud providers and
    bare-metal machines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Production-level support for HA clusters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Windows nodes are currently not supported, but with incoming kubeadm support
    for Windows nodes, kubespray is the best candidate to extend its support.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As kubespray does not support Windows nodes at this point, we will not focus
    on it in this book.
  prefs: []
  type: TYPE_NORMAL
- en: AKS Engine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**AKS Engine** ([https://github.com/Azure/aks-engine](https://github.com/Azure/aks-engine))
    is an official, open source tool for provisioning self-managed Kubernetes clusters
    on Azure. It aims at generating **Azure Resource Manager** (**ARM**) templates
    that bootstrap Azure VMs and set up the cluster.'
  prefs: []
  type: TYPE_NORMAL
- en: AKS Engine should not be confused with **Azure Kubernetes Service** (**AKS**),
    which is a fully-managed Kubernetes cluster offering by Azure. AKS Engine is used
    by AKS internally, though.
  prefs: []
  type: TYPE_NORMAL
- en: 'Its features can be summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Available only for Azure; other platforms are not supported.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High availability is implemented through Azure VMSS ([https://kubernetes.io/blog/2018/10/08/support-for-azure-vmss-cluster-autoscaler-and-user-assigned-identity/](https://kubernetes.io/blog/2018/10/08/support-for-azure-vmss-cluster-autoscaler-and-user-assigned-identity/)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Good Windows support – the official test suites are validated on AKS Engine
    configuration. We'll use this approach in [Chapter 8](ab695a0d-05dc-48f8-8c41-bbd167cfbfa6.xhtml),  *Deploying
    a Hybrid Azure Kubernetes Engine Service Cluster*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, please note that AKS Engine offers experimental features that are not
    available as managed AKS offerings yet. This means that this approach may not
    always be suitable for running production workloads, depending on which AKS Engine
    features you use.
  prefs: []
  type: TYPE_NORMAL
- en: Managed Kubernetes providers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As the popularity of Kubernetes constantly grows, there are multiple, **fully-managed**
    Kubernetes offerings being provided by different cloud providers and companies
    specializing in Kubernetes. You can find a long, but not complete, list of Kubernetes
    providers (not only managed) at [https://kubernetes.io/docs/setup/#production-environment](https://kubernetes.io/docs/setup/#production-environment).
    In this section, we will summarize the managed offerings of the tier-1 cloud service
    providers and what they offer in terms of Windows support, namely the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Microsoft Azure: **Azure Kubernetes Service **(**AKS**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Google Cloud Platform: **Google Kubernetes Engine** (**GKE**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Web Services: **Elastic Kubernetes Service** (**EKS**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For** managed** Kubernetes providers, the key principle is that you are not
    responsible for managing the control plane, the data plane, and the underlying
    cluster infrastructure. From your perspective, you get a ready cluster of a given
    size (that may scale on demand) with high availability and the appropriate SLAs
    in place. You just need to deploy your workload! An alternative, less managed
    approach is the **turnkey cloud solution**, where you manage the control plane,
    data plane, and upgrades yourself, but the infrastructure is managed by the cloud
    provider. A good example of such a solution is the **AKS Engine** running on top
    of Azure VMs.
  prefs: []
  type: TYPE_NORMAL
- en: All of these cloud providers have Windows containers support in their managed
    Kubernetes offerings and for all them, this feature is currently in preview. You
    can expect limited support for the feature and limited backward compatibility.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Kubernetes Service introduced Windows nodes support in May 2019 and is
    the most mature offering for Windows Containers, with good support in its documentation
    ([https://docs.microsoft.com/en-us/azure/aks/windows-container-cli](https://docs.microsoft.com/en-us/azure/aks/windows-container-cli)).
    This offering is built on top of the AKS Engine internally, so you can expect
    similar features to be available there. You can monitor the official roadmap for
    incoming Windows support features by going to [https://github.com/Azure/AKS/projects/1](https://github.com/Azure/AKS/projects/1).
  prefs: []
  type: TYPE_NORMAL
- en: Google Kubernetes Engine announced support for Windows Containers in their Rapid
    release channel in May 2019\. Currently, there is limited information available
    about this alpha feature – for Google Cloud Platform, the most common and well-validated
    use case is deploying Kubernetes for Windows directly to Google Compute Engine
    VMs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon Elastic Kubernetes Service announced preview support for Windows Containers
    in March 2019\. You can find more details about Windows Containers support in
    EKS in the official documentation: [https://docs.aws.amazon.com/eks/latest/userguide/windows-support.html](https://docs.aws.amazon.com/eks/latest/userguide/windows-support.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Creating AKS cluster with Windows nodes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To complete this walkthrough, you need an Azure account and Azure CLI installed
    on your machine. You can find more details in [Chapter 2](43d5e48b-311c-462c-a68e-6a0b5c4224e8.xhtml)*, Managing
    State in Containers*.
  prefs: []
  type: TYPE_NORMAL
- en: The following steps are also available as a Powershell script in the official
    GitHub repository for this book: [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter04/05_CreateAKSWithWindowsNodes.ps1](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter04/05_CreateAKSWithWindowsNodes.ps1).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s begin by enabling the preview features for AKS:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install the `aks-preview` extension using the Azure CLI from Powershell:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Update the `aks-preview` extension to its latest available version:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Register the `WindowsPreview` feature flag for your subscription to enable
    multiple node pools. A separate node pool is required for Windows nodes. Note
    that this operation should be performed on test or development subscriptions as
    any cluster that is created after enabling this flag will use this feature:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This operation will take a few minutes. You have to wait until the `Status`
    of the feature is `Registered` to be able to continue. To check the current `Status`,
    run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'When the feature is registered, execute the following command to propagate
    the change:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, wait until the provider finishes the registration and switches status
    to `Registered`. You can monitor the status using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: The actual cost of AKS is determined by the number and size of the Azure VMs
    that host the cluster. You can find the predicted costs of running an AKS cluster
    here: [https://azure.microsoft.com/en-in/pricing/details/kubernetes-service/](https://azure.microsoft.com/en-in/pricing/details/kubernetes-service/).
    It is advised that you delete the cluster if you are not planning to use it after
    this walkthrough to avoid extra costs.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the preview feature enabled, you can continue creating the actual AKS
    cluster with Windows nodes. The available versions of Kubernetes depend on the
    location where you create the cluster. In this walkthrough, we suggest using the `westeurope`
    Azure location. Follow these steps to create the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a dedicated resource group for your AKS cluster, for example, `aks-windows-resource-group`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Get the list of available Kubernetes versions in a given location:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Choose the desired one. It is advised that you use the latest one; for example, `1.15.3`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create an `aks-windows-cluster` AKS instance using the selected version and
    provide the desired Windows username and password (choose a secure one!). The
    following command will create a two-node pool of Linux nodes running in VMSS high-availability
    mode:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'After a few minutes, when the AKS cluster is ready, add a Windows **node pool**
    named `w1pool` to the cluster – this operation will take a few minutes. There
    is a limit of six characters for the Windows node pool name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'If you do not have `kubectl` installed already, install it using the Azure
    CLI:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Get the cluster credentials for `kubectl`. The following command will add a
    new context for `kubectl` and switch to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Verify that the cluster has been deployed successfully! Run any `kubectl` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, you can start hacking with your first Kubernetes cluster with Windows
    nodes! For example, create a sample Deployment that runs three replicas of the
    official ASP.NET sample in Windows containers, exposed behind a Service of the
    LoadBalancer type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The container creation process may take up to 10 minutes as the Windows base
    image needs to be pulled first. Wait for the external load balancer IP to be available:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Navigate to the address in a web browser to check if your application is running
    properly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/f891c6ea-8446-4bd7-b801-4f7362947187.png)'
  prefs: []
  type: TYPE_IMG
- en: To delete the AKS cluster, use the `az group delete --name aks-windows-resource-group --yes
    --no-wait` command.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You have successfully created your first, fully-managed Kubernetes
    cluster with Windows nodes. In the next few chapters, we will look at different
    approaches for creating Kubernetes clusters with Windows containers support.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about the key theory behind Kubernetes – its high-level
    architecture and the most commonly used Kubernetes API objects. On top of that,
    we summarized how Kubernetes currently fits into the Windows ecosystem and the
    current limitations in Windows support. Next, you learned how to set up your own
    Kubernetes development environment for Linux containers using the recommended
    tools, such as minikube and Docker Desktop for Windows, as well as the possible
    production cluster deployment strategies available. Finally, we reviewed the managed
    Kubernetes offerings that support Windows containers and performed a successful
    deployment of Azure Kubernetes Service cluster with the Windows node pool!
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will bring you more knowledge regarding Kubernetes architecture
    – Kubernetes networking in general and in the Windows ecosystem. This will be
    the last chapter that focuses on the theory of Kubernetes and its working principles.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is the difference between the control plane and the data plane in Kubernetes?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does the declarative model and the concept of desired state work and what
    are its benefits?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between a container and a Pod?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the purpose of the Deployment API Object?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the key limitations of Kubernetes support on Windows?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is minikube and when should you use it?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between AKS and AKS Engine?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can find answers to these questions in the *Assessments*section of this
    book.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information regarding Kubernetes concepts, please refer to the following
    PacktPub books:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*The Complete Kubernetes Guide* ([https://www.packtpub.com/virtualization-and-cloud/complete-kubernetes-guide](https://www.packtpub.com/virtualization-and-cloud/complete-kubernetes-guide))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Getting Started with Kubernetes – Third Edition* ([https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition](https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Kubernetes for Developers* ([https://www.packtpub.com/virtualization-and-cloud/kubernetes-developers](https://www.packtpub.com/virtualization-and-cloud/kubernetes-developers))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can also refer to the excellent official Kubernetes documentation ([https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/)),
    which is always the most up to date source of knowledge about Kubernetes in general.
    For Windows-specific scenarios, the official Microsoft Virtualization documentation
    is recommended: [https://docs.microsoft.com/en-us/virtualization/windowscontainers/kubernetes/getting-started-kubernetes-windows](https://docs.microsoft.com/en-us/virtualization/windowscontainers/kubernetes/getting-started-kubernetes-windows).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
