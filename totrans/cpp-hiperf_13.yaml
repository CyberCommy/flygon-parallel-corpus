- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Asynchronous Programming with Coroutines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The generator class implemented in the previous chapter helped us to use coroutines
    for building lazily evaluated sequences. C++ coroutines can also be used for asynchronous
    programming by having a coroutine represent an asynchronous computation or an
    **asynchronous task**. Although asynchronous programming is the most important
    driver for having coroutines in C++, there is no support for asynchronous tasks
    based on coroutines in the standard library. If you want to use coroutines for
    asynchronous programming, I recommend you find and use a library that complements
    C++20 coroutines. I've already recommended CppCoro ([https://github.com/lewissbaker/cppcoro](https://github.com/lewissbaker/cppcoro)),
    which at the time of writing seems like the most promising alternative. It's also
    possible to use asynchronous coroutines with the well-established library Boost.Asio,
    as you will see later on in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will show that asynchronous programming is possible using coroutines
    and that there are libraries available to complement C++20 coroutines. More specifically,
    we will focus on:'
  prefs: []
  type: TYPE_NORMAL
- en: The `co_await` keyword and awaitable types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The implementation of a rudimentary task type—a type that can be returned from
    coroutines that perform some asynchronous work
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boost.Asio to exemplify asynchronous programming using coroutines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before moving on, it should also be said that there are no performance-related
    topics in this chapter and very few guidelines and best practices are presented.
    Instead, this chapter serves more as an introduction to the novel feature of asynchronous
    coroutines in C++. We'll begin this introduction by exploring awaitable types
    and `co_await` statements.
  prefs: []
  type: TYPE_NORMAL
- en: Awaitable types revisited
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We already talked a bit about awaitable types in the previous chapter. But now
    we need to get a little bit more specific about what `co_await` does and what
    an awaitable type is. The keyword `co_await` is a unary operator, meaning that
    it takes a single argument. The argument we pass to `co_await` needs to fulfill
    some requirements that we will explore in this section.
  prefs: []
  type: TYPE_NORMAL
- en: When we say `co_await` in our code, we express that we are *waiting* for something
    that may or may not be ready for us. If it's not ready, `co_await` suspends the
    currently executing coroutine and returns control back to its caller. When the
    asynchronous task has completed, it should transfer the control back to the coroutine originally
    waiting for the task to finish. From here on, I will typically refer to the awaiting
    function as the **continuation**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now consider the following expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'For this code to compile, `X` needs to be an awaitable type. So far we have
    only used the trivial awaitable types: `std::suspend_always` and `std::suspend_never`.
    Any type that directly implements the three member functions listed next, or alternatively
    defines `operator co_wait()` to produce an object with these member functions,
    is an awaitable type:'
  prefs: []
  type: TYPE_NORMAL
- en: '`await_ready()` returns a `bool` that indicates whether the result is ready
    (`true`) or whether it is necessary to suspend the current coroutine and wait
    for the result to become ready.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`await_suspend(coroutine_handle)` – If `await_ready()` returned `false`, this
    function will be called with a handle to the coroutine that executed `co_await`.
    This function gives us an opportunity to start asynchronous work and subscribe
    for a notification that will trigger when the task has finished and thereafter
    resume the coroutine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`await_resume()` is the function responsible for unpacking the result (or error)
    back to the coroutine. If an error has occurred during the work initiated by `await_suspend()`,
    this function could rethrow the caught error or return an error code. The result
    of the entire `co_await` expression is whatever `await_resume()` returns.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'With this overload in place, we can now pass a time interval to the `co_await`
    operator, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The example is not complete but gives you a hint about how to use the unary
    operator `co_await`. As you may have noticed, the three `await_*()` functions
    are not called directly by us; instead, they are invoked by code inserted by the
    compiler. Another example will clarify the transformations made by the compiler.
    Assume that the compiler stumbles upon the following statement in our code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Then the compiler will (very) roughly transform the code into something like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The `await_ready()` function is first called to check whether a suspension is
    needed. If so, `await_suspend()` is called with a handle to the coroutine that
    will be suspended (the coroutine with the `co_await` statement). Finally, the
    result of the awaitable is requested and assigned to the `result` variable.
  prefs: []
  type: TYPE_NORMAL
- en: The implicit suspend points
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As you have seen in numerous examples, a coroutine defines *explicit* suspend
    points by using `co_await` and `co_yield`. Each coroutine also has two *implicit*
    suspend points:'
  prefs: []
  type: TYPE_NORMAL
- en: The **initial suspend point**, which occurs at the initial invocation of a coroutine
    before the coroutine body is executed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **final suspend point**, which occurs after the coroutine body has been
    executed and before the coroutine is destroyed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The promise type defines the behavior of these two points by implementing `initial_suspend()`
    and `final_suspend()`. Both functions return awaitable objects. Typically, we
    pass `std::suspend_always` from the `initial_suspend()` function so that the coroutine
    is started lazily rather than eagerly.
  prefs: []
  type: TYPE_NORMAL
- en: The final suspend point plays an important role for asynchronous tasks, because
    it makes it possible for us to tweak the behavior of `co_await`. Normally, a coroutine
    that has been `co_await:`ed should resume the awaiting coroutine at the final
    suspend point.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's get a better understanding of how the three awaitable functions
    are meant to be used and how they cooperate with the `co_await` operator.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a rudimentary task type
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The task type we are about to implement is a type that can be returned from
    coroutines that represent asynchronous tasks. The task is something that a caller
    can wait for using `co_await`. The goal is to be able to write asynchronous application
    code that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The standard library already provides a type that allows a function to return
    an object that a caller can use for waiting on a result to be computed, namely
    `std::future`. We could potentially wrap `std::future` into something that would
    conform to the awaitable interface. However, `std::future` does not support continuations,
    which means that whenever we try to get the value from a `std::future`, we block
    the current thread. In other words, there is no way to compose asynchronous operations
    without blocking when using `std::future`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another alternative would be to use `std::experimental::future` or a future
    type from the Boost library, which supports continuations. But these future types
    allocate heap memory and include synchronization primitives that are not needed
    in the use cases set out for our tasks. Instead, we will create a new type with
    minimum overhead with the responsibilities to:'
  prefs: []
  type: TYPE_NORMAL
- en: Forward return values and exceptions to the caller
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resume the caller waiting for the result
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A coroutine task type has been proposed (see P1056R0 at [http://www7.open-std.org/JTC1/SC22/WG21/docs/papers/2018/p1056r0.html](http://www7.open-std.org/JTC1/SC22/WG21/docs/papers/2018/p1056r0.html)),
    and the proposal gives us a good hint about what components we need. The implementation
    that follows is based on work presented by Gor Nishanov and source code shared
    by Lewis Baker, which is available in the CppCoro library.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the implementation of the class template for representing an asynchronous
    task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'An explanation of each part will follow in the subsequent sections, but first
    we need the implementation of the promise type that uses a `std::variant` to hold
    a value or an error. The promise also keeps a reference to the coroutine waiting
    for the task to complete using the `continuation_` data member:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s important to distinguish between the two coroutine handles we are using:
    the handle identifying the *current coroutine* and the handle identifying the
    *continuation*.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that this implementation doesn't support `Task<void>` due to limitations
    of `std::variant`, and also the limitation that we can't have both `return_value()`
    and `return_void()` on the same promise type. Not supporting `Task<void>` is unfortunate
    since not all asynchronous tasks necessarily return values. We will overcome this
    limitation in a while by providing a template specialization for `Task<void>`.
  prefs: []
  type: TYPE_NORMAL
- en: Since we implemented a few coroutine return types in the previous chapter (`Resumable`
    and `Generator`), you will already be familiar with the requirements of a type
    that can be returned from a coroutine. Here, we will focus on the things that
    are new to you, such as exception handling and the ability to resume the caller
    currently waiting for us. Let's start looking at how `Task` and `Promise` handle return
    values and exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: Handling return values and exceptions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An asynchronous task can complete by returning (a value or `void`) or by throwing
    an exception. The value and the error need to be handed over to the caller, which
    has been waiting for the task to complete. As usual, this is the responsibility
    of the promise object.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Promise` class uses a `std::variant` to store the result of three possible
    outcomes:'
  prefs: []
  type: TYPE_NORMAL
- en: No value at all (the `std::monostate`). We use this in our variant to make it
    default-constructible, but without requiring the other two types to be default-constructible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A return value of type `T`, where `T` is the template argument of `Task`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A `std::exception_ptr`, which is a handle to an exception that was thrown earlier.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The exception is captured by using the `std::current_exception()` function inside
    the function `Promise::unhandled_exception()`. By storing a `std::exception_ptr`,
    we can later rethrow this exception in another context. This is also the mechanism
    used when exceptions are passed between threads.
  prefs: []
  type: TYPE_NORMAL
- en: A coroutine that uses `co_return value;` must have a promise type that implements
    `return_value()`. However, coroutines that use `co_return;`, or run off the body
    without returning a value, must have a promise type that implements `return_void()`.
    Implementing a promise type that contains both `return_void()` and `return_value()`
    generates a compilation error.
  prefs: []
  type: TYPE_NORMAL
- en: Resuming an awaiting coroutine
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When the asynchronous task has completed, it should transfer the control back
    to the coroutine waiting for the task to finish. To be able to resume this continuation,
    the `Task` object needs the `coroutine_handle` to the continuation coroutine.
    This handle was passed to the `Task` object''s `await_suspend()` function, and
    conveniently we made sure to save that handle into the promise object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The `final_suspend()` function is responsible for suspending at the final suspend
    point of this coroutine and transferring execution to the awaiting coroutine.
    This is the relevant part of the `Promise` reproduced for your convenience:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: To begin with, returning `false` from `await_ready()` will leave the coroutine
    suspended at the final suspend point. The reason we do this is so that the promise
    is still alive and available for the continuation to have a chance to pull the
    result out from this promise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s have a look at the `await_suspend()` function. This is the place
    where we want to resume the continuation. We could potentially call `resume()`
    directly on the `continuation_` handle and wait for it to finish, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'However, that would run the risk of creating a long chain of nested call frames
    on the stack, which eventually could result in a stack overflow. Let''s see how
    this could happen with a short example using two coroutines, `a()` and `b()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'If the `Promise` object associated with coroutine `a()` directly called `resume()`
    on the handle to coroutine `b()`, a new call frame to resume `b()` would be created
    on the stack on top of the call frame for `a()`. This process would be repeated
    over and over again in the loop, creating new nested call frames on the stack
    for each iteration. This call sequence when two functions call each other is a
    form of recursion, sometimes called mutual recursion:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15619_13_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.1: Coroutine b() calls coroutine a(), which resumes b(), which calls
    a(), which resumes b(), and so on'
  prefs: []
  type: TYPE_NORMAL
- en: 'Even though there is only one coroutine frame created for `b()`, each call
    to `resume()` that resumes coroutine `b()` creates a new frame on the stack. The
    solution to avoid this problem is called **symmetric transfer**. Instead of resuming
    the continuation directly from the coroutine that is about to finish, the task
    object instead returns the `coroutine_handle` identifying the continuation from
    `await_suspend()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: An optimization called *tail call optimization* is then guaranteed to happen
    by the compiler. In our case, this means that the compiler will be able to transfer
    control directly to the continuation without creating a new nested call frame.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will not spend more time on the details of symmetric transfer and tail calls,
    but an excellent and more in-depth explanation of these topics can be found in
    the article *C++ Coroutines: Understanding Symmetric Transfer* by Lewis Baker,
    available at [https://lewissbaker.github.io/2020/05/11/understanding_symmetric_transfer](https://lewissbaker.github.io/2020/05/11/understanding_symmetric_transfer).'
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned earlier, our `Task` template has the limitation of not handling
    a template parameter of type `void`. Now it's time to fix that.
  prefs: []
  type: TYPE_NORMAL
- en: Supporting void tasks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To overcome the limitations addressed earlier regarding the inability to handle
    tasks that do not produce any values, we need a template specialization for `Task<void>`.
    It is spelled out here for completeness, but it does not add many new insights
    beyond the general `Task` template defined earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The promise type in this template specialization only keeps a reference to a
    potentially unhandled exception. And instead of having `return_value()` defined,
    the promise contains the member function `return_void()`.
  prefs: []
  type: TYPE_NORMAL
- en: We can now represent tasks that return values or `void`. But there is still
    some work to be done before we can actually build a standalone program to test
    our `Task` type.
  prefs: []
  type: TYPE_NORMAL
- en: Synchronously waiting for a task to complete
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An important aspect of the `Task` type is that whatever invokes a coroutine
    that returns a `Task` must `co_await` on it, and is therefore also a coroutine.
    This creates a chain of coroutines (continuations). For example, assume we have
    a coroutine like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, it''s not possible to use it in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we call an asynchronous function that returns a `Task`, we need to `co_await`
    on it, or nothing will happen. This is also the reason why we declare `Task` to
    be `nodiscard`: so that it generates a compilation warning if the return value
    is ignored, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The forced chaining of coroutines has the interesting effect that we finally
    get to the `main()` function of the program, which the C++ standard says is not
    allowed to be a coroutine. This needs to be addressed somehow, and the proposed
    solution is to provide at least one function that synchronously waits on the asynchronous
    chains to complete. For example, the CppCoro library includes the function `sync_wait()`,
    which has this effect of breaking the chain of coroutines, which makes it possible
    for an ordinary function to use coroutines.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, implementing `sync_wait()` is rather complicated, but in order
    to at least make it possible to compile and test our `Task` type, I will here
    provide a simplified version based on the Standard C++ Proposal P1171R0, [https://wg21.link/P1171R0](https://wg21.link/P1171R0).
    Our goal here is to be able to write a test program like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: With the aim of testing and running asynchronous tasks, let's continue with
    the implementation of `sync_wait()`.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing sync_wait()
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`sync_wait()` internally uses a custom task class specifically designed for
    our purpose, called `SyncWaitTask`. Its definition will be revealed in a while,
    but first let''s have a look at the definition of the function template `sync_wait()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: First, in order to specify the type that the task is returning, we use a combination
    of `decltype` and `declval`. The rather cumbersome `using-e`xpression gives us
    the type returned by `T::await_resume()`, where `T` is the type of the task passed
    to `sync_wait()`.
  prefs: []
  type: TYPE_NORMAL
- en: Inside `sync_wait()` we distinguish between tasks that return values and tasks
    that return `void`. We make a distinction here to avoid the need for implementing
    a template specialization of `SyncWaitTask` to handle both `void` and non-void
    types. Both cases are handled similarly by introducing an empty `struct`, which
    can be provided as the template argument to `SyncWaitTask` for handling `void`
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: In the case where an actual value is returned, a lambda expression is used to
    define a coroutine that will `co_await` on the result and then finally yield its
    value. It's important to note that the coroutine might resume from `co_await`
    on another thread, which requires us to use a synchronization primitive in the
    implementation of `SyncWaitTask`.
  prefs: []
  type: TYPE_NORMAL
- en: Calling `get()` on the coroutine lambda resumes the coroutine until it yields
    a value. The implementation of `SyncWaitTask` guarantees that the coroutine lambda
    will never have a chance to resume again after the `co_yield` statement.
  prefs: []
  type: TYPE_NORMAL
- en: 'We used `co_yield` extensively in the previous chapter, but without mentioning
    its relationship to `co_await`; namely that the following `co_yield` expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'is transformed by the compiler into:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: where `promise` is the promise object associated with the currently executing
    coroutine. Knowing this is helpful when trying to understand the control flow
    between `sync_wait()` and the `SyncWaitTask` class.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing SyncWaitTask
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now we are ready to inspect the `SyncWaitTask`, which is a type intended only
    to be used as a helper for `sync_wait()`. For that reason, we add it under a namespace
    called `detail` to make it clear that this class is an implementation detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The most interesting part to pay attention to is the function `get()` and its
    blocking call to `acquire()` on a semaphore owned by the promise object. This
    is what makes this task type synchronously wait for a result to be ready for us.
    The promise type that owns the binary semaphore looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'There''s a lot of boilerplate code here that we have already talked about.
    But pay special attention to `yield_value()` and `final_suspend()`, which is the
    interesting part of this class. Recall that the coroutine lambda inside `sync_wait()`
    yielded the return value like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: So, once the value is yielded, we end up in `yield_value()` of the promise object.
    And the fact that `yield_value()` can return an awaitable type gives us the opportunity
    to customize the behavior of the `co_yield` keyword. In this case, `yield_value()`
    returns an awaitable that will signal through the binary semaphore that a value
    from the original `Task` object has been produced.
  prefs: []
  type: TYPE_NORMAL
- en: The semaphore is signaled inside `await_suspend()`. We cannot signal earlier
    than that because the other end of the code waiting for the signal will eventually
    destroy the coroutine. Destroying a coroutine must only happen if the coroutine
    is in a suspended state.
  prefs: []
  type: TYPE_NORMAL
- en: The blocking call to `semaphore_`.`acquire()` from within `SyncWaitTask::get()`
    will return on the signal, and finally the computed value will be handed over
    to the client that called `sync_wait()`.
  prefs: []
  type: TYPE_NORMAL
- en: Testing asynchronous tasks with sync_wait()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, a small asynchronous test program using `Task` and `sync_wait()` can
    be constructed like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: We have implemented the absolute minimum infrastructure for using asynchronous
    tasks with C++ coroutines. More infrastructure is needed, though, in order to
    use coroutines for asynchronous programming effectively. This is a big difference
    from the generator (presented in the previous chapter), which required a fairly
    small amount of groundwork before we could really benefit from it. To get a little
    bit closer to the real world, we will, in the following sections, explore some
    examples using Boost.Asio. The first thing we will do is to try to wrap a callback-based
    API inside an API compatible with C++ coroutines.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping a callback-based API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many asynchronous APIs based on callbacks. Typically, an asynchronous
    function takes a callback function provided by the caller. The asynchronous function
    returns immediately and then eventually invokes the callback (completion handler)
    when the asynchronous function has a computed value or is done waiting for something.
  prefs: []
  type: TYPE_NORMAL
- en: To show you what an asynchronous callback-based API can look like, we will take
    a peek at a Boost library for asynchronous I/O named **Boost.Asio**. There is
    a lot to learn about Boost.Asio that won't be covered here; I will only describe
    the absolute minimum of the Boost code and instead focus on the parts directly
    related to C++ coroutines.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make the code fit the pages of the book, the examples assume that the following
    namespace alias has been defined whenever we use code from Boost.Asio:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a complete example of using Boost.Asio for delaying a function call
    but without blocking the current thread. This asynchronous example runs in a single
    thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Compiling and running this program will generate the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: When using Boost.Asio, we always need to create an `io_context` object that
    runs an event processing loop. The call to `async_wait()` is asynchronous; it
    returns immediately back to `main()` and invokes the callback (the lambda) when
    the timer expires.
  prefs: []
  type: TYPE_NORMAL
- en: 'The timer example does not use coroutines but instead a callback API to provide
    asynchronicity. Boost.Asio is also compatible with C++20 coroutines, which I will
    demonstrate later on. But on our path to explore awaitable types, we will take
    a detour and instead assume that we need to provide a coroutine-based API that
    returns awaitable types on top of the callback-based API of Boost.Asio. In that
    way, we can use a `co_await` expression to call and wait (but without blocking
    the current thread) for the asynchronous task to complete. Instead of using a
    callback, we would like to be able to write something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see how we can implement the function `async_sleep()` so that it can
    be used with `co_await`. The pattern we will follow is to have `async_sleep()`
    return an awaitable object that will implement the three required functions: `await_ready()`,
    `await_suspend()`, and `await_resume()`. An explanation of the code will follow
    after it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Once again, we are creating a custom awaitable type that does all the necessary
    work:'
  prefs: []
  type: TYPE_NORMAL
- en: '`await_ready()` will return `false` unless the timer has already reached zero.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`await_suspend()` starts the asynchronous operation and passes a callback that will
    be called when the timer has expired or produced an error. The callback saves
    the error code (if any) and resumes the suspended coroutine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`await_resume()` has no result to unpack because the asynchronous function
    we are wrapping, `boost::asio::timer::async_wait()`, does not return any value
    except an optional error code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Before we can actually test `async_sleep()` in a standalone program, we need
    some way to start the `io_context` run loop and break the chain of coroutines,
    as we did when testing the `Task` type previously. We will do that in a rather
    hacky way here by implementing two functions, `run_task()` and `run_task_impl()`,
    and a naive coroutine return type called `Detached` that ignores error handling
    and can be discarded by the caller:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The `Detached` type makes the coroutine start immediately and runs the coroutine
    detached from the caller. The `executor_work_guard` prevents the `run()` call
    from returning until the coroutine `run_task_impl()` has completed.
  prefs: []
  type: TYPE_NORMAL
- en: Starting operations and detaching them should typically be avoided. It's similar
    to detached threads or allocated memory without any references. However, the purpose
    of this example is to demonstrate what we can use awaitable types for and how
    we can write asynchronous programs and run them single-threaded.
  prefs: []
  type: TYPE_NORMAL
- en: 'Everything is in place; the wrapper called `async_sleep()` returns a `Task`
    and a function `run_task()`, which can be used to execute a task. It''s time to
    write a small coroutine to test the new code we implemented:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Executing this program will generate the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: You have seen how a callback-based API can be wrapped in a function that can
    be used by `co_await` and therefore allows us to use coroutines instead of callbacks
    for asynchronous programming. This program also provided a typical example of
    how the functions in the awaitable type can be used. However, as mentioned earlier,
    it turns out that recent versions of Boost, starting with 1.70, already provide
    an interface that is compatible with C++20 coroutines. In the next section, we
    will use this new coroutine API when building a tiny TCP server.
  prefs: []
  type: TYPE_NORMAL
- en: A concurrent server using Boost.Asio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will demonstrate how to write concurrent programs that have multiple
    threads of execution but only use a single OS thread. We are about to implement
    a rudimentary concurrent single-threaded TCP server that can handle multiple clients.
    There are no networking capabilities in the C++ standard library, but fortunately
    Boost.Asio provides us with a platform-agnostic interface for handling socket
    communication.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of wrapping the callback-based Boost.Asio API, I will demonstrate how
    to use the `boost::asio::awaitable` class for the purpose of showing a more realistic
    example of how asynchronous application programming using coroutines can look.
    The class template `boost::asio::awaitable` corresponds to the `Task` template
    we created earlier; it's used as a return type for coroutines that represent asynchronous
    computations.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the server
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The server is very simple; once a client connects, it starts updating a numeric
    counter and writes back the value whenever it is updated. This time we will follow
    the code from top to bottom, starting with the `main()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The mandatory `io_context` runs the event processing loop. It's possible to
    invoke `run()` from multiple threads as well, if we want our server to execute
    multiple OS threads. In our case we only use one thread but with multiple concurrent
    flows. The function `boost::asio::co_spawn()` starts a detached concurrent flow.
    The server is implemented using a lambda; it defines a TCP endpoint (with port
    37259) and starts listening for incoming client connections on the endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: 'The coroutine `listen()` is fairly simple and looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The executor is the object responsible for actually executing our asynchronous
    functions. An executor may represent a thread pool or a single system thread,
    for example. We will most likely see some form of executors in upcoming versions
    of C++ to give us programmers more control and flexibility over when and where
    our code executes (including GPUs).
  prefs: []
  type: TYPE_NORMAL
- en: Next, the coroutine runs an infinite loop and waits for TCP clients to connect.
    The first `co_await` expression returns a socket when a new client successfully
    connects to our server. The socket object is then moved to the coroutine `serve_client()`,
    which will serve the newly connected client until the client disconnects.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main application logic of the server happens in the coroutine that handles
    each client. Here is how it looks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Each coroutine invocation serves one unique client during the entire client
    session; it runs until the client disconnects from the server. The coroutine updates
    a counter at regular intervals (every 100 ms) and writes the value asynchronously
    back to the client using `async_write()`. Note how we can write the function `serve_client()`
    in a linear fashion although it invokes two asynchronous operations: `async_write()`
    and `async_wait()`.'
  prefs: []
  type: TYPE_NORMAL
- en: Running and connecting to the server
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once we have started this server, we can connect clients on port 37259\. To
    try this out, I''m using a tool called `nc` (netcat), which can be used for communicating
    over TCP and UDP. Here is an example of a short session where a client connects
    to the server running on localhost:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We can start multiple clients and they will all be served by a dedicated `serve_client()`
    coroutine invocation and have their own copy of the incrementing counter variable,
    as shown in the screenshot below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15619_13_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.2: A running server with two connected clients'
  prefs: []
  type: TYPE_NORMAL
- en: Another way to create an application serving multiple sessions concurrently
    would be to create one thread for each new client that connects. However, the
    memory overhead of threads would set the limit of the number of sessions substantially
    lower compared to this model using coroutines.
  prefs: []
  type: TYPE_NORMAL
- en: The coroutines in this example are all executed on the same thread, which makes
    the locking of shared resources unnecessary. Imagine we had a global counter that
    each session updated. If we used multiple threads, the access to the global counter
    would need some kind of synchronization (using a mutex or an atomic data type).
    This is not necessary for coroutines that execute on the same thread. In other
    words, coroutines that execute on the same thread can share state without using
    any locking primitives.
  prefs: []
  type: TYPE_NORMAL
- en: What we have achieved with the server (and what we haven't)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The example application using Boost.Asio demonstrates that coroutines can be
    used for asynchronous programming. Instead of implementing continuations with
    nested callbacks, we can write code in a linear fashion using `co_await` statements.
    However, this example is minimal and avoids some really important aspects of asynchronous
    programming, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous read and write operations. The server only writes data to its clients
    and ignores the challenge of synchronizing read and write operations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Canceling asynchronous tasks and graceful shutdown. The server runs in an infinite
    loop, completely ignoring the challenge of a clean shutdown.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Error handling and exception safety when using multiple `co_await` statements.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These topics are immensely important but are out of scope for this book. I already
    mentioned that detached operations are best avoided. Creating detached tasks using
    `boost::asio::co_spawn()`, as shown in the example, should be done with utmost
    caution. A fairly new programming paradigm for avoiding detached work is called
    **structured concurrency**. It aims to solve exception safety and the cancellation
    of multiple asynchronous tasks by encapsulating concurrency into general and reusable
    algorithms such as `when_all()` and `stop_when()`. The key idea is to never allow
    some child task to exceed the lifetime of its parent. This makes it possible to
    pass local variables by reference to asynchronous child operations safely and
    with better performance. Strictly nested lifetimes of concurrent tasks also make
    the code easier to reason about.
  prefs: []
  type: TYPE_NORMAL
- en: Another important aspect is that asynchronous tasks should always be lazy (immediately
    suspended), so that continuations can be attached before any exceptions can be
    thrown. This is also a requirement if you want to be able to cancel a task in
    a safe manner.
  prefs: []
  type: TYPE_NORMAL
- en: 'There will most likely be a lot of talks, libraries, and articles related to
    this important subject in the years to come. Two talks from CppCon 2019 addressed
    this topic:'
  prefs: []
  type: TYPE_NORMAL
- en: '*A Unifying Abstraction for Async in C++*, Eric Neibler and D. S. Hollman,
    [https://sched.co/SfrC](https://sched.co/SfrC)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Structured Concurrency: Writing Safer Concurrent Code with Coroutines and
    Algorithms*, Lewis Baker, [https://sched.co/SfsU](https://sched.co/SfsU)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you've seen how to use C++ coroutines for writing asynchronous
    tasks. To be able to implement the infrastructure in the form of a `Task` type
    and a `sync_wait()` function, you needed to fully understand the concept of awaitable
    types and how they can be used to customize the behavior of coroutines in C++.
  prefs: []
  type: TYPE_NORMAL
- en: By using Boost.Asio, we could build a truly minimal but fully functional concurrent
    server application executing on a single thread while handling multiple client
    sessions.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, I briefly introduced a methodology called structured concurrency and
    gave some directions for where you can find more information about this topic.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will move on to explore parallel algorithms, which are
    a way to speed up concurrent programs by utilizing multiple cores.
  prefs: []
  type: TYPE_NORMAL
