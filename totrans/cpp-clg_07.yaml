- en: Concurrency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 61\. Parallel transform algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Write a general-purpose algorithm that applies a given unary function to transform
    the elements of a range in parallel. The unary operation used to transform the
    range must not invalidate range iterators or modify the elements of the range.
    The level of parallelism, that is, the number of execution threads and the way
    it is achieved, is an implementation detail.
  prefs: []
  type: TYPE_NORMAL
- en: 62\. Parallel min and max element algorithms using threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Implement general-purpose parallel algorithms that find the minimum value and, respectively,
    the maximum value in a given range. The parallelism should be implemented using
    threads, although the number of concurrent threads is an implementation detail.
  prefs: []
  type: TYPE_NORMAL
- en: 63\. Parallel min and max element algorithms using asynchronous functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Implement general-purpose parallel algorithms that find the minimum value and,
    respectively, the maximum value in a given range. The parallelism should be implemented
    using asynchronous functions, although the number of concurrent functions is an
    implementation detail.
  prefs: []
  type: TYPE_NORMAL
- en: 64\. Parallel sort algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Write a parallel version of the sort algorithm as defined for problem *53\.
    Sort Algorithm*, in [Chapter 6](980cb06d-ef7f-4c20-b4ff-7bb8bc4d401a.xhtml), *Algorithms
    and Data Structures*, which, given a pair of random access iterators to define
    its lower and upper bounds, sorts the elements of the range using the quicksort
    algorithm. The function should use the comparison operators for comparing the
    elements of the range. The level of parallelism and the way to achieve it is an
    implementation detail.
  prefs: []
  type: TYPE_NORMAL
- en: 65\. Thread-safe logging to the console
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Write a class that enables components running in different threads to safely
    print log messages to the console by synchronizing access to the standard output
    stream to guarantee the integrity of the output. This logging component should
    have a method called `log()` with a string argument representing the message to
    be printed to the console.
  prefs: []
  type: TYPE_NORMAL
- en: 66\. Customer service system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Write a program that simulates the way customers are served in an office. The
    office has three desks where customers can be served at the same time. Customers
    can enter the office at any time. They take a ticket with a service number from
    a ticketing machine and wait until their number is next for service at one of
    the desks. Customers are served in the order they entered the office, or more
    precisely, in the order given by their ticket. Every time a service desk finishes
    serving a customer, the next customer in order is served. The simulation should
    stop after a particular number of customers have been issued tickets and served.
  prefs: []
  type: TYPE_NORMAL
- en: Solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 61\. Parallel transform algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The general-purpose function `std::transform()` applies a given function to
    a range and stores the result in another (or the same) range. The requirement
    for this problem is implementing a parallel version of such a function. A general-purpose
    one would take iterators as arguments to define the first and one-past-last element
    of the range. Because the unary function is applied in the same manner to all
    the elements of the range, it is fairly simple to parallelize the operation. For
    this task, we will be using threads. Since it is not specified how many threads
    should be running at the same time, we could use `std::thread::hardware_concurrency()`.
    This function returns a hint for the number of concurrent threads supported by
    the implementation.
  prefs: []
  type: TYPE_NORMAL
- en: A parallel version of the algorithm performs better than a sequential implementation
    only if the size of the range exceeds a particular threshold, which may vary with
    compilation options, platform, or hardware. In the following implementation that
    threshold is set to 10,000 elements. As a further exercise, you could experiment
    with various thresholds and range sizes to see how the execution time changes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following function, `ptransform()`, implements the parallel transform algorithm
    as requested. It simply calls `std::transform()` if the range size does not exceed
    the defined threshold. Otherwise, it splits the range into several equal parts,
    one for each thread, and calls `std::transform()` on each thread for a particular
    subrange. In this case, the function blocks the calling thread until all the worker
    threads finish execution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The function `palter()`, shown as follows, is a helper function that applies
    `ptransform()` to an `std::vector` and returns another `std::vector` with the
    result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The function can be used as follows (a complete example can be found in the
    source code accompanying this book):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In C++17, a series of standard general-purpose algorithms, including `std::transform()`,
    have overloads that implement a parallel version of the algorithm that can be
    executed according to a specified execution policy.
  prefs: []
  type: TYPE_NORMAL
- en: 62\. Parallel min and max element algorithms using threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This problem, and its solution, is similar in most ways to the previous one.
    What is slightly different is that the function concurrently executing on each
    thread must return a value that represents the minimum or the maximum element
    in the subrange. The `pprocess()` function template, shown as follows, is a higher-level
    function that implements the requested functionality generically, in the following
    way:'
  prefs: []
  type: TYPE_NORMAL
- en: Its arguments are the first and one-past-last iterators to the range and a function
    object that processes the range that we will call `f`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the size of the range is smaller than a particular threshold, set to 10,000
    elements here, it simply executes the function object `f` received as argument.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Otherwise, it splits the input range into a number of subranges of equal size,
    one for each concurrent thread that could be executed. Each thread runs `f` for
    the selected subrange.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The results of the parallel execution of `f` are collected in an `std::vector`,
    and after the execution of all threads is completed, `f` is used again to determine
    the overall result from the intermediate results:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Two functions, called `pmin()` and `pmax()`, are provided to implement the
    required general-purpose min and max parallel algorithms. These two are in turn
    calling `pprocess()`, passing for the third argument a lambda that uses either
    the `std::min_element()` or the `std::max_element()` standard algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'These functions can be used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: You can take it as a further exercise to implement yet another general-purpose
    algorithm that computes the sum of all the elements of a range in parallel using
    threads.
  prefs: []
  type: TYPE_NORMAL
- en: 63\. Parallel min and max element algorithms using asynchronous functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The only difference between this problem and the previous one is how the parallelism
    is achieved. For the previous problem, the use of threads was required. For this
    one, you must use asynchronous functions. A function can be executed asynchronously
    with `std::async()`. This function creates a *promise*, which is an asynchronous
    provider of the result of a function executed asynchronously. A promise has a
    shared state (which can store either the return value of a function or an exception
    that resulted from the execution of the function) and an associated *future* object
    that provides access to the shared state from a different thread. The promise-future
    pair defines a channel that enables communicating values across threads. `std::async()`
    returns the future associated with the promise it creates.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following implementation of `pprocess()`, the use of threads from the
    previous version has been replaced with calls to `std::async()`. Note that you
    must specify `std::launch::async` as the first parameter to `std::async()` to
    guarantee an asynchronous execution and not a lazy evaluation. The amount of changes
    from the previous implementation is very small and it should be easy to follow
    the code based on the description of the algorithm from the previous implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code shows how this function can be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: You can again take it as a further exercise to implement a general-purpose algorithm
    that computes the sum of all the elements of a range in parallel using asynchronous
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: 64\. Parallel sort algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We saw a sequential implementation of the quicksort algorithm earlier. Quicksort
    is a divide and conquer algorithm that relies on partitioning the range to be
    sorted into two parts, one that contains only elements smaller than a selected
    element, called the pivot, and one that contains only elements greater than the
    pivot. It then proceeds to recursively apply the same algorithm on the two partitions,
    until the partitions have only one element or none. Because of the nature of the
    algorithm, quicksort can be easily parallelized to recursively apply the algorithm
    on the two partitions concurrently.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `pquicksort()` function uses asynchronous functions for this purpose. However,
    parallelization is only efficient for larger ranges. There is a threshold under
    which the overhead with context switches for parallel execution is too large and
    the parallel execution time is greater than the sequential execution time. In
    the following implementation, this threshold is set to 100,000 elements, but as
    a further exercise, you could experiment with setting different values and see
    how the parallel version performs compared to the sequential one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code shows how a large vector of random integers (with values
    between 1 and 1000) can be sorted using the `pquicksort()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 65\. Thread-safe logging to the console
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although C++ does not have the concept of a console and uses streams to perform
    input and output operations on sequential media such as files, the `std::cout`
    and `std::wcout` global objects control the output to a stream buffer associated
    with the C output stream `stdout`. These global stream objects cannot be safely
    accessed from different threads. Should you need that, you must synchronize the
    access to them. That is exactly the purpose of the requested component for this
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `logger` class, shown as follows, uses an `std::mutex` to synchronize access
    to the `std::cout` object in the `log()` method. The class is implemented as a
    thread-safe singleton. The static method `instance()` returns a reference to a
    local static object (that has storage duration). In C++11, initialization of a
    static object happens only once, even if several threads attempt to initialize
    the same static object at the same time. In such a case, concurrent threads are
    blocked until the initialization executed on the first calling thread completes.
    Therefore, there is no need for additional user-defined synchronization mechanisms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding `logger` class can be used to write console message from multiple
    threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 66\. Customer service system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to implement the simulation of the customer service office as required,
    we could use several helper classes. `ticketing_machine` is a class that models
    a very simple machine that issues incremental ticketing numbers, starting with
    an initial, user-specified seed. `customer` is a class that represents a customer
    that enters the store and receives a ticket from the ticketing machine. `operator<`
    is overloaded for this class in order to store customers in a priority queue from
    which they should be taken in the order given by their ticket number. In addition,
    the `logger` class from the previous problem is used to print messages to the
    console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Each desk from the office is modeled using a different thread. Customers entering
    the store and queuing after getting a ticket are modeled using a separate thread.
    In the following simulation, a new customer enters the store every 200-500 milliseconds,
    gets a ticket and is placed in a priority queue. The execution of the store thread
    finishes after 25 customers enter the store and are placed in the queue. An `std::condition_variable`
    is used to communicate between threads to notify that a new customer has been
    placed in the queue or that an existing customer has been removed from the queue
    (which happens when a customer moves to an open desk). The threads that represent
    the office desk are running until a flag indicating the office is opened is reset
    but not before all customers that are in the queue are served. In this simulation,
    each customer spends 2,000 to 3,000 milliseconds at a desk:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a snippet of the output of an execution of this problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: As a further exercise, you can try to change the intervals at which the customers
    enter the store, how many customers are allowed to get a ticket before the office
    closes, how long it takes to serve them, or how many desks are opened in the office.
  prefs: []
  type: TYPE_NORMAL
