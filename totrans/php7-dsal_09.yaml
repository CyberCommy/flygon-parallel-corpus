- en: Putting Graphs into Action
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The graph is one of the most interesting data structures that is used to solve
    various real-life problems. Whether we are talking about showing directions on
    maps, finding the shortest route, planning for complex network flow, finding a
    connection between profiles in social media, or recommendations, we are dealing
    with graph data structures and their associated algorithms. Graphs give us so
    many ways to solve problems that they have been used frequently to solve complex
    problems. As a result, it is very important for us to understand graphs and how
    we can use them in our solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding graph properties
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A graph is a collection of vertices or nodes that are connected to each other
    through edges. These edges can be ordered or unordered, which means that the edge
    can have a direction associated with it or it can be non-directed, which is also
    known as bidirectional edge. We represent a graph using a set *G* in relationship
    with vertices *V* and edges *E* as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*G = (V, E)*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00069.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the preceding diagram, we have five vertices and six edges:'
  prefs: []
  type: TYPE_NORMAL
- en: '*V = {A, B, C, D, E}*'
  prefs: []
  type: TYPE_NORMAL
- en: '*E = {AB, AC, AD, BD, BE, CD, DE}*'
  prefs: []
  type: TYPE_NORMAL
- en: If we consider the previous diagram, the connectivity between **A** and **B**
    can be represented as **AB** or **BA** as we have not defined the direction for
    the connectivity. One of the significant differences between the graph and the
    tree data structures is that the graph can form a cycle or loop, but a tree data
    structure cannot. Unlike a tree data structure, we can start from any vertices
    in a graph data structure. Also, we can have a direct edge between any two vertices,
    whereas in a tree, two nodes can only be connected if the child node is the immediate
    descendant of the parent node.
  prefs: []
  type: TYPE_NORMAL
- en: There are different properties and keywords related to graphs. We will now explore
    those terms before moving on to further discussions on graphs and their applications.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Each node in a graph is called a vertex. Usually, a vertex is represented as
    a circle. In our diagram, the nodes **A** , **B** , **C** , **D,** and **E** are
    vertices.
  prefs: []
  type: TYPE_NORMAL
- en: Edge
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An edge is a connection between two vertices. Usually, it is represented by
    a line drawn between two vertices. In the previous diagram, we had edges between
    **A** and **B** , **A** and **C** , **A** and **D** , **B** and **D** , **C**
    and **D** , **B** and **E** , and **D** and **E** . We can represent the edge
    as **AB** or (**A** , **B** ). Edges can be of three types:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Directed edge** : If an edge is marked with an arrow, then it indicates a
    directed edge. A directed edge is unidirectional. The head of the arrow is the
    end vertex and the tail of the arrow is the start vertex:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](Image00070.gif)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding diagram, we can see that **A** has a directed edge to **B**
    , which means **A** , **B** is an edge, but not vice versa (**B** , **A** ). So,
    this is an example of a unidirectional edge, or directed edge.
  prefs: []
  type: TYPE_NORMAL
- en: '**Undirected edge** : An undirected edge is a connection between two vertices
    without any direction. This means that the edge satisfies a bidirectional relationship.
    The following diagram is an example of an undirected graph, where **A** is connected
    to **B** in such a way that both edges (**A** , **B** ) and (**B** , **A** ) are
    the same:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](Image00071.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**Weighted edge** : When an edge carries additional information, such as cost,
    distance, or other information, we call that edge a weighted edge. This is used
    for many graph algorithms. In the following diagram, the weight for edge (**A**
    , **B** ) is **5** . This can be distance, or cost, or anything, as per the definition
    of the graph:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](Image00072.gif)'
  prefs: []
  type: TYPE_IMG
- en: Adjacent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Two vertices are adjacent if they have an edge in between them. Two vertices
    A and B are said to be adjacent if they have a direct edge between them. In the
    following diagram, we can see that vertex **1** and vertex **2** are connected
    with the edge **e1** , and as a result, they are called adjacent. Since vertex
    **2** has no edge between vertex 3 and 4, vertex **2** is not adjacent to vertex
    **3** and vertex **4** .
  prefs: []
  type: TYPE_NORMAL
- en: Incident
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An edge is incident on a vertex if the vertex is one of the end points of the
    edge. Also, two edges are incident if both of them share a vertex. If we consider
    the following diagram, we can see the incident edges (**e1** , **e2** ), (**e2**
    , **e3** ), and (**e1** , **e3** ) sharing vertex **1** among themselves. W e
    also have incident edges (**e3** , **e4** ) that share vertex **4** among themselves
    and edges (**e2** , **e4** ) that share vertex **3** among themselves. Similarly,
    we can say that vertex **1** is incident on edges **e1** , **e2** , and **e3**
    , vertex **2** is incident on edge **e1** , vertex **3** is incident on edges
    **e2** , and **e4** , and vertex **4** is incident on edges **e3** , and **e4**
    :'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00073.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Indegree and outdegree
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The total count of incoming edges to a particular vertex is known as the indegree
    of that vertex, and the total number of outgoing edges from a particular vertex
    is known as the outdegree of that vertex. If we consider the directed edges of
    the following diagram, we can say that vertex **A** has an indegree of 0 and an
    outdegree of 1, vertex **B** has an indegree of 2 and an outdegree 1, vertex **C**
    has an indegree 1 and an outdegree of 1, vertex **D** has an indegree of 1 and
    an outdegree of 1, vertex **E** has an indegree of 1 and an outdegree of 2, and
    lastly, vertex **F** has an indegree of 1 and an outdegree of 0.
  prefs: []
  type: TYPE_NORMAL
- en: Path
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A path is a sequence of vertices and edges that starts from a starting vertex
    and ends in another vertex that we are trying to reach. In the following diagram,
    the path from **A** to **F** is represented by (**A** , **B** ), (**B** , **C**
    ), (**C** , **E** ), and (**E** , **F** ):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00074.gif)'
  prefs: []
  type: TYPE_IMG
- en: Types of graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are different types of graphs available based on how they are drawn or
    represented. Each type of graph has a different behavior and usage. We will focus
    on four main types of graph.
  prefs: []
  type: TYPE_NORMAL
- en: Directed graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If a graph contains only directed edges, then the graph is known as a directed
    graph. A directed graph is also known as a digraph or a directed network. The
    following diagram represents a directed graph. Here, the (**A** , **B** ), (**B**
    , **C** ), (**C** , **E** ), (**E** , **D** ), (**E** , **F** ), and (**D** ,
    **B** ) edges are directed edges. Since the edges are directed, edge **AB** is
    not the same as edge **BA** :'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00075.gif)'
  prefs: []
  type: TYPE_IMG
- en: Undirected graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If a graph contains only undirected edges, then the graph is an undirected
    graph. In other words, the edges in an undirected graph are bidirectional. Sometimes,
    the undirected graph is also known as an undirected network. In an undirected
    graph, if vertex A is connected to vertex B, then it is assumed that both (A,
    B) and (B, A) represent the same edge. The following diagram shows an example
    of an undirected graph where all the edges do not have arrows to indicate direction:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00076.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Weighted graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If all the edges of a graph are weighted edges, then the graph is known as
    a weighted graph. We will talk a lot about weighted graphs in the upcoming sections.
    Weighted graphs can be directed or undirected graphs. Each edge must have a value
    associated with it. The weight of an edge is always referred to as the cost of
    the edge. The following diagram represents an undirected weighted graph with five
    vertices and seven edges. Here, the weight of the edge between vertex **1** and
    **2** is **2** , the edge between vertex **1** and **4** is **5** , and the edge
    between vertex **4** and **5** is **58** :'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00077.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Directed acyclic graphs (DAG)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An acyclic graph is a graph without a cycle or loop. If we want to visit other
    nodes from a particular node, we will not visit any of the nodes twice. A directed
    acyclic graph, popularly known as a DAG, is a directed graph that is acyclic.
    A directed acyclic graph has many usages in graph algorithms. A directed acyclic
    graph has a topological ordering, where the ordering of the vertices is such that
    the starting endpoint of every edge occurs earlier in the ordering than the ending
    endpoints of the edges. The following diagram represents a DAG:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00078.jpg)'
  prefs: []
  type: TYPE_IMG
- en: From the first look, it seems that **B** , **C** , **E** , and **D** form a
    cycle, but close observation shows that they do not form a cycle, whereas, the
    example we have used in the directed graph section is a perfect example of a cyclic
    graph.
  prefs: []
  type: TYPE_NORMAL
- en: Representing graphs in PHP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since graphs are represented with vertices and edges, we have to consider both
    in representing the graph. There are several ways to represent a graph, but the
    most popular ones are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Adjacency list
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adjacency matrix
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adjacency lists
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can represent a graph using a linked list where one array will be used for
    vertices and each vertex will have a linked list, which will represent the edges
    between adjacent vertices. An example graph looks like this when represented in
    an adjacency list:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00079.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Adjacency matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In an adjacency matrix, we represent the graph in a two-dimensional array,
    where each node represents the array index horizontally and vertically. If the
    edge from A to B is directional, then we mark that array index [A][B] to 1 to
    mark the connection; otherwise, it''s 0\. If the edge is not directional, then
    both [A][B] and [B][A] are set to 1\. If the graph is a weighted graph, then [A][B]
    or [B][A] will store the weight instead of 1\. The following diagram shows the
    undirected graph representation using a matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00080.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'This one shows the directed graph representation of the matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00081.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Though our graph representation shows an alphabetic representation of array
    indexes in both an adjacency list and matrix, we can use a numeric index to represent
    vertices as well.
  prefs: []
  type: TYPE_NORMAL
- en: Revisiting BFS and DFS for graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have already seen how we can implement a **breadth first search** (**BFS**
    ) and a **depth** **first** **search** (**DFS** ) in a tree structure. We will
    revisit our BFS and DFS for graphs. The difference between a tree implementation
    and a graph implementation is that in a graph implementation, we can start from
    any vertex, whereas we start from the root of the tree in a tree data structure.
    Another important thing to consider is that our graphs can have cycles, which
    were absent in the tree, so, we cannot revisit a node or vertex as it will end
    up in an infinite loop. We will use a concept called graph coloring where we keep
    the status of different node visits with a color or a value to keep it simple.
    Let's now write some code to implement the BFS and DFS in the graph.
  prefs: []
  type: TYPE_NORMAL
- en: Breadth first search
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are now going to implement a BFS for a graph. Considering the following
    undirected graph, first, we need to represent the graph in a matrix or list. For
    the sake of simplicity, we will use the adjacency matrix for the graph representation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00082.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding adjacency graph has six vertices, and the vertices are labeled
    from **1** to **6** (no 0). Since our vertices are numbered, we can use those
    as array indexes for faster access. We will can construct the graph like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we have two arrays, one for representing the actual graph and the other
    one for keeping track of the visited nodes. We want to make sure that we do not
    visit a node multiple times as it might end up in an infinite loop. Since our
    graph has six vertices, we kept `$vertexCount` as `6` . We then initialize the
    graph array as a two-dimensional array with an initial value of `0` . We will
    start the index from `1` for the array. We also set each vertex as not visited
    by assigning each vertex to `0` in the `$visited` array. Now, we will add the
    edges in our graph representation. Since the graph is undirected, we need to set
    two properties for each edge. In other words, we need to set bidirectional edge
    values for edges between the vertex labeled 1 and 2 since both share an edge between
    them. Here is the code for the full representation of the earlier graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'So, we have represented the graph using an adjacency matrix. Now, let''s define
    the BFS algorithm for the matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Our implemented BFS function takes three arguments: the actual graph, the starting
    vertex, and the empty visited array. We could have avoided the third argument
    and written the initialization inside the BFS function. At the end of the day,
    we can choose either of the ways to accomplish this. Inside our function implementation,
    we have two queues: one to keep the nodes that we need to visit and another one
    for the order of the visited nodes, or the path of the search. At the end of the
    function, we return the path queue.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside the function, we first add the starting node to the queue. Then, we
    start from that node to visit its adjacent nodes. If the node is not visited and
    has a connection to the current node, we add it to our queue for visiting. We
    also mark the current node as visited and add it to our path. Now, we will call
    our BFS function with our constructed graph matrix and a visiting node. Here is
    the program to execute the BFS functionality:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see from the preceding code snippet, we start the search from node
    1\. The output will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'If we had 5 as the starting node by changing the second argument of the `BFS`
    function call from 1 to 5, then the output would have been the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Depth first search
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we have seen for the BFS, we can define any starting vertex for the DFS
    as well. The difference is that for a list of visited nodes, we will use a stack
    instead of a queue. Other parts of the code will be similar to our BFS code. We
    will also use the same graph we used for the BFS implementation. The DFS implementation
    we will implement is an iterative one. Here is the code for it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'As mentioned earlier, for a DFS, we have to use a stack instead of a queue
    as we need the last vertex from the stack instead of the first one (if we have
    used a queue). For the path part, we use a queue so that we can show the path
    sequentially during the display. Here is the code to call for our graph `$graph`
    :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The code will produce the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: For the preceding example, we start from vertex 1, and we will visit vertex
    5 first out of the two adjacent vertices with the labels 5 and 2 of vertex 1\.
    Now, vertex 5 has two vertices with labels 4 and 2\. Vertex 4 will be visited
    first as it appears as the first edge from vertex 5 (bearing in mind our left
    to right direction of visiting nodes). Next, we will visit vertex 6 from vertex
    4\. Since, we cannot go any further from vertex 6, it will return to vertex 4
    and visit the unvisited adjacent vertex with the label 3\. When we are at vertex
    3, there are two adjacent vertices available from 3\. They are labeled as vertex
    4 and vertex 2\. We already visited vertex 4 earlier, so we cannot revisit it,
    and we have to visit vertex 2 from vertex 3\. Since vertex 2 has three vertices,
    vertex 3, 5, and 1, and all of them are already visited, we are actually done
    with our DFS implementation here.
  prefs: []
  type: TYPE_NORMAL
- en: We can pass an extra parameter if we are looking for a specific end vertex from
    a starting vertex. In the earlier example, we were just getting the adjacent vertex
    and visiting all of them. For a specific end vertex, we had to match the target
    vertex with each of our visiting vertex during the iteration of the DFS algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Topological sorting using Kahn's algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s assume that we have some tasks to do, and each of the tasks has some
    dependencies that mean that the dependent tasks should be done first before doing
    the actual task. The problem arises when we have an interrelationship between
    tasks and dependencies. Now, we need to come up with a proper order for completing
    the tasks. We need a special type of sorting so that we can sort these connected
    tasks without violating our rules for finishing the tasks. Topological sorting
    will be the right choice for solving such problems. In topological sorting, a
    directed edge AB from vertex A to B is sorted in such a way that A will always
    come before B in the ordering. This will be applicable for all the vertices and
    edges. Another important factor for applying a topological sort is that the graph
    must be a DAG. Any DAG has at least one topological sorting. Most of the time,
    there are multiple topological sortings that are possible for a given graph. There
    are two popular algorithms available for topological sorting: Kahn''s algorithm
    and the DFS approach. We will talk about Kahn''s algorithm here as we have already
    discussed DFS a few times in this book.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Kahn''s algorithm has the following steps to find the topological ordering
    from a DAG:'
  prefs: []
  type: TYPE_NORMAL
- en: Calculate the indegree (incoming edges) for each of the vertex and put all vertices
    in a queue where the indegree is 0\. Also, initialize the count for the visited
    node to 0.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Remove a vertex from the queue and perform the following operations on it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 1\. Increment the visited node count by 1.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Reduce the indegree for all adjacent vertices by 1.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. If the indegree of the adjacent vertex becomes 0, add it to the queue.
  prefs: []
  type: TYPE_NORMAL
- en: Repeat *step 2* until the queue is empty.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the count of the visited node is not the same as the count of the nodes,
    then topological sorting is not possible for the given DAG.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s consider the following graph. It is a perfect example of DAG. Now, we
    want to sort it using topological sorting and Kahn''s algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00083.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now let us represent this graph using an adjacency matrix as we did previously
    for the other graphs. The matrix will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will implement Kahn''s algorithm as per our defined steps. Here is
    the implementation for it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see from the preceding implementation, we have actually considered
    every step we mentioned for Kahn''s algorithm. We started by finding the indegree
    for vertices and also putting the 0 indegree vertices in a queue. Then, we checked
    each node of the queue and reduced the indegree of the neighbor vertices and again
    added any neighbor with 0 indegrees to the queue. At the end, we returned the
    sorted queue, or an empty queue if the count of ordered vertices and actual vertices
    count does not match. We can now call the function to return the sorted list of
    vertices as a queue. Here is the code to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, this will go through each of the queue elements and print them. The output
    will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The output corresponds to our expectations. As we can see from the earlier diagram,
    vertex **2** has a direct edge to vertex **1** and vertex **3** , and vertex **1**
    has a direct edge to vertex **0** and vertex **3** . Since vertex **2** has no
    incoming edges, we will start from vertex **2** for the topological sorting. Vertex
    **1** has one incoming edge and vertex **3** has two, so, after vertex **2** ,
    we will visit vertex **1** as per the algorithm. The same principle will take
    us to vertex **0** followed by vertex **3** and at the end to vertex **4** . We
    have to also remember that there can be multiple topological orderings possible
    for a given graph. The complexity of Kahn's algorithm is **O** (*V+E* ), where
    **V** is the number of vertices and **E** is the number of edges.
  prefs: []
  type: TYPE_NORMAL
- en: Shortest path using the Floyd-Warshall algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A common scenario for a pizza-delivery company is to deliver the pizza as quickly
    as possible. Graph algorithms can help us in such situations. The Floyd-Warshall
    algorithm is a very common algorithm that is used to find the shortest path from
    u to v using all pairs of vertices (u, v). The shortest path indicates the shortest
    possible distance between two nodes that are interconnected. The graph for calculating
    the shortest path has to be a weighted graph. In some cases, the weight can be
    negative as well. The algorithm is very simple and one of the easiest to implement.
    It is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we copied each of our weights to a cost or distance matrix. Then, we
    ran through each vertex and figured out the cost or distance of visiting from
    vertex `i` to vertex `j` through vertex `k` . If the distance or cost is less
    than a direct path between vertex `i` and vertex `j` , we choose the path `i`
    to `k` to `j` instead of the direct path of `i` to `j` . Let''s consider the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00084.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, we can see an undirected graph with weights on each edge. Now, if we
    look for the shortest path from **A** to **E** , then we have the following options:'
  prefs: []
  type: TYPE_NORMAL
- en: '**A** to **E** via **B** has a distance of **20**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A** to **E** via **D** has a distance of **25**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A** to **E** via **D** and **B** has a distance of **20**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A** to **E** via **B** and **D** has a distance of **35**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, we can see that the lowest distance is **20** . Now, let''s implement this
    programmatically with numeric representations of the vertices. We will use 0,
    1, 2, 3, and 4 instead of A, B, C, D, and E, respectively. Now, let''s represent
    the earlier graph in an adjacency matrix format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we took a difference approach and initialized all the edges to the maximum
    value of the PHP integer. The reason for doing this is to ensure that a value
    of 0 for non-edges does not impact the algorithm logic, as we are searching for
    the minimum value. Now, we need to add the weights to the graph as shown in the
    earlier diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Since this is an undirected graph, we assign both edges the same value. If
    it were a directed graph, we could have made only one entry for each weight. Now,
    it is time to implement the Floyd-Warshall algorithm to find the shortest paths
    for any given pair of nodes. Here is our implementation of this function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'As we mentioned earlier, the implementation is really simple. We have three
    inner loops to calculate the minimum distance, and we also return the distance
    array at the end of the function. Now, let''s call this function and check whether
    our expected results match:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output of the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: If we check our previous graph, we can see that the shortest distance between
    **D** and **C** is actually **10** , and the path is D → B → C (5+5), which is
    the shortest distance out of all the possible routes (D → A → B → C (20), or D
    → E → B → C (35)).
  prefs: []
  type: TYPE_NORMAL
- en: The complexity for the Floyd-Warshall algorithm is **O** (*V3* ), where **V**
    is the number of vertices in the graph. Now we will explore another algorithm
    that is famous for finding the single source shortest path.
  prefs: []
  type: TYPE_NORMAL
- en: Single source shortest path using Dijkstra's algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can easily find the shortest path using the Floyd-Warshall algorithm, but
    we do not get the actual path to go from node X to Y. This is because the Floyd-Warshall
    algorithm does the calculation for the distance or cost and does not store the
    actual path for the minimum cost. For example, using Google Maps, we can always
    find a route to our destination from any given location. Google Maps can show
    us the best route as regards the distance, time of travel, or other factors. This
    is a perfect example of single source shortest path algorithm usage. There are
    many algorithms to find the solution for a single source shortest path problem;
    however, Dijkstra''s shortest path algorithm is the most popular one. There are
    many ways to implement Dijkstra''s algorithm, such as using Fibonacci heaps, min-heaps,
    priority queues, and so on. Each implementation has its own advantage regarding
    the performance and improvement of Dijkstra''s solution. Let''s go through the
    pseudocode for the algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will implement the algorithm using a priority queue. First, let''s
    choose a graph to implement the algorithm. We can select the following undirected
    weighted graph. It has six nodes with many connections between the nodes and vertices.
    First, we need to represent the following graph in an adjacency matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00085.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'As we can see from the preceding diagram, our vertices are labeled with the
    letters **A** to **F** , so we will use the vertex name as the key in a PHP associative
    array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will implement Dijkstra''s algorithm using a priority queue. We will
    find a path from the source vertex to the target vertex using the adjacency matrix
    we created for the last diagram. Our Dijkstra''s algorithm will return an array
    with the minimum distance between two nodes and the followed path. We will return
    the path as a stack so that we can get the actual path in the reverse order. Here
    is the implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: As we can see from the preceding implementation, first, we created two arrays
    to store the distance and predecessors, along with the priority queue. Then, we
    set each vertex as the maximum integer (`PHP_INT_MAX` ) value of PHP (INFINITY
    in the pseudocode) and the predecessor as `NULL` . We also took the minimum value
    of all adjacent nodes and stored them in the queue. After the loop, we set the
    source node distance as `0` . Then we checked each node in the queue and checked
    the nearest neighbors to find a minimum path. If a path is found using `if ($dist[$u]
    + $cost < $dist[$v])` , we assign it to the vertex.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then created a stack named `$s` to store the path. We started from our target
    vertex and visited adjacent vertices to reach our source vertex. As we moved through
    the adjacent vertices, we also calculated the distance we covered by visiting
    those vertices. Since our function is returning both the distance and the path,
    we constructed an array to return both the distance and path for the given graph,
    source, and target. If no path exists, we return 0 as the distance and an empty
    stack for the output. Now, we will write a few lines of code to use the graph
    `$graph` and the function `Dijkstra` to check our implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run this code, it will have the following output in our command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The output looks exactly right, as we can see from the graph that the shortest
    path from **A** to **F** is through **C** and the shortest distance is *5 + 3
    = 8* .
  prefs: []
  type: TYPE_NORMAL
- en: Dijkstra's algorithm has a running complexity of **O** (*V2* ). Since we are
    using the minimum priority queue, the runtime complexity is **O** (*E + V log
    V* ).
  prefs: []
  type: TYPE_NORMAL
- en: Finding the shortest path using the Bellman-Ford algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Though Dijkstra''s algorithm is the most popular and efficient one that is
    used to find the single source shortest path, there is one problem that it does
    not address. If the graph has a negative cycle, Dijkstra''s algorithm cannot detect
    the negative cycle, and, thus, it does not work. A negative cycle is a cycle where
    the sum of all the edges in the cycle is negative. If a graph contains a negative
    cycle, then finding the shortest path will not be possible, so it is important
    that we address the issue while finding the shortest path. That is why we use
    the Bellman-Ford algorithm, even though it is slower compared to Dijkstra''s algorithm.
    Here is the algorithm pseudocode for the Bellman-Ford algorithm for the shortest
    path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that the Bellman-Ford algorithm also considers the edge sand vertices
    in finding the shortest path between nodes. This is known as the relaxation process,
    which is also used in Dijkstra''s algorithm. The relaxation process in graph algorithms
    refers to the updating of the cost of all vertices connected to a vertex *V* if
    those costs would be improved by including the path via *V* . In simple words,
    the relaxation process is trying to lower the cost of getting to a vertex using
    another vertex. Now, we will implement this algorithm for the same graph we used
    in Dijkstra''s algorithm. The only difference is that here we will use numeric
    labels for our nodes and vertex here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00086.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now it is time to represent the graph in an adjacency matrix format. Here is
    the matrix in PHP:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Previously, we used a value of 0 to indicate that there was no edge between
    two vertices. If we do the same here, then taking a minimum between two edges
    where one represents 0 will always yield a 0 during the relaxation process, which
    actually means that there is no connection between two vertices. As a result,
    we have to choose a larger number to represent the non-existent edges. We can
    use the `MAX_INT_VALUE` constant of PHP to represent those edges so that those
    non-existent edges are not considered. This can be our new graph representation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s write the implementation for the Bellman-Ford algorithm. We will
    use the same approach we defined in the pseudocode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Unlike Dijkstra''s algorithm, we are not tracking the predecessors. We are
    considering the distance during the relaxation process. Since we are using the
    maximum value for an integer in PHP, it automatically cancels outs the possibility
    of choosing a nonexistent edge with a value of 0 as the minimum path. The last
    part of the implementation detects any negative cycle in the given graph and returns
    an empty array in that case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'This will have the following output, which shows the shortest path distance
    from our source node to other nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The Bellman-Ford algorithm has the run-time complexity of **O** (*V* , *E* ).
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the minimum spanning tree (MST)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Suppose we are designing our new office campus with multiple buildings interconnected
    to each other. If we approach the problem by considering the interconnectivity
    between each building, it will take a huge number of cables. However, if we could
    somehow connect all the buildings through a common connectivity where each building
    is connected to every other building with only one connection, then this solution
    will reduce the redundancy and cost. If we think of our buildings as vertices
    and the connectivity between buildings as the edges, we can construct a graph
    using this approach. The problem we are trying to solve is also known as the **minimum
    spanning tree,** or **MST** . Consider the following graph. We have 10 vertices
    and 21 edges. However, we can connect all 10 vertices with only nine edges (the
    dark line). This will keep our cost or distance to a minimal level:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00087.jpg)'
  prefs: []
  type: TYPE_IMG
- en: There are several algorithms that we can use to find an MST from a given graph.
    The two most popular are Prim's algorithm and Kruskal's algorithm. We will explore
    these two algorithms in the upcoming sections.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Prim's spanning tree algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Prim''s algorithm for finding the minimum spanning tree relies on a greedy
    approach. A greedy approach is defined as an algorithm paradigm where we try to
    find the global optimal solution by considering the local optimal solution at
    each stage. We will explore greedy algorithms in [Chapter 11](text00238.html)
    , *Solve Problems with Advanced Techniques* . In a greedy approach, the algorithm
    creates subsets of edges and finds out the least costly one from the subset of
    edges. This subset of edges will include all vertices. It starts from an arbitrary
    position and grows the tree one vertex at a time by choosing the cheapest possible
    connection between the vertices. Let''s consider the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00088.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, we will apply a very basic version of Prim''s algorithm to get the minimum
    spanning tree as well as the minimum cost or weight of the edges. The graph will
    look like this as an adjacency matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will implement the algorithm for Prim''s minimum spanning tree. We
    are assuming that we are going to start from vertex 0 to find out the whole spanning
    tree, so we will just pass the graph adjacency matrix in the function, and it
    will display the connecting edges for the spanning tree along with the minimum
    cost:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, if we call the function `primMST` with our graph `$G` , the following
    will be the output and the MST constructed by the algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '![](Image00089.jpg)'
  prefs: []
  type: TYPE_IMG
- en: There are other ways to implement Prim's algorithm with the help of a Fibonacci
    heap, a priority queue, and so on. It is quite similar to Dijkstra's algorithm
    to find the shortest path. Our implementation has a time complexity of **O** (*V²*
    ). Using the binary heap and the Fibonacci heap, we can reduce the complexity
    significantly.
  prefs: []
  type: TYPE_NORMAL
- en: Kruskal's algorithm for spanning tree
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another popular algorithm for finding a minimum spanning tree is Kruskal''s
    algorithm. It is similar to Prim''s algorithm and uses a greedy approach to find
    the solution. Here are the steps we need to implement Kruskal''s algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a forest **T** (a set of trees), where each vertex in the graph is a
    separate tree.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a set **S** containing all the edges in the graph.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'While **S** is non-empty and **T** is not yet spanning:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 1\. Remove an edge with the minimum weight from **S** .
  prefs: []
  type: TYPE_NORMAL
- en: 2\. If that edge connects two different trees, then add it to the forest, combining
    two trees into a single tree; otherwise, discard that edge.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the same graph that we used for Prim''s algorithm. Here is the
    implementation of Kruskal''s algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, we have two separate functions—`unionSet` and `findSet` —to
    perform the union operations of two disjointed sets, as well as find out whether
    a number exists in a set or not. Now, let''s run the program with our constructed
    graph like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'This will produce the following output, which is similar to our output from
    Prim''s algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The complexity of Kruskal's algorithm is **O** (*E log V* ), which is better
    than the generic implementation of Prim's algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed different graph algorithms and their operations.
    Graphs are very handy in solving a wide range of problems. We have seen that for
    the same graph, we can apply different algorithms and get different performances.
    We have to choose carefully which algorithms we want to apply based on the nature
    of the problem. There are many other graph topics that we left out of this book
    due to some constraints. There are topics such as graph coloring, bipartite matching,
    and flow problems, which should be studied and applied where applicable. In the
    next chapter, we will shift our focus to our last data structure topic for this
    book, called heap, and learn the different usages of the heap data structure.
  prefs: []
  type: TYPE_NORMAL
