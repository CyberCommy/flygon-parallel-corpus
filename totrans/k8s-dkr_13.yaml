- en: '*Chapter 10*: Creating PodSecurityPolicies'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most of the security discussed so far has focused on protecting Kubernetes APIs.
    Authentication has meant the authentication of API calls. Authorization has meant
    authorizing access to certain APIs. Even the discussion on the dashboard centered
    mostly around how to securely authenticate to the API server by way of the dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will be different as we will now shift our focus to securing our
    nodes. We will learn how **PodSecurityPolicies** (**PSPs**) protect the nodes
    of a Kubernetes cluster. Our focus will be on how containers run on the nodes
    of your cluster and how to keep those containers from having more access than
    they should. We'll get into the details of impacts in this chapter by looking
    at how exploits can be used to gain access to a cluster when the nodes aren't
    protected. We'll also explore how these scenarios can be exploited even in code
    that doesn't need node access.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is a PSP?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aren't they going away?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enabling pod security policies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alternatives to PSPs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To follow the examples in this chapter, make sure you have a KinD cluster running
    with the configuration from [*Chapter 8*](B15514_08_Final_ASB_ePub.xhtml#_idTextAnchor228),
    *RBAC Policies and Auditing*.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can access the code for this chapter at the following GitHub repository:
    [https://github.com/PacktPublishing/Kubernetes-and-Docker-The-Complete-Guide/tree/master/chapter10](https://github.com/PacktPublishing/Kubernetes-and-Docker-The-Complete-Guide/tree/master/chapter10).'
  prefs: []
  type: TYPE_NORMAL
- en: What is a PodSecurityPolicy?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A PSP is a Kubernetes resource that allows you to set security controls for
    your workloads, allowing you to set limitations on what a pod can do. PSPs are
    evaluated before a pod is allowed to start up and if the pod attempts to do something
    that a PSP forbids, it will not be allowed to start.
  prefs: []
  type: TYPE_NORMAL
- en: Many people have experience with physical and virtual servers, and most know
    how to secure workloads running on them. Containers need to be considered differently
    when you talk about securing each workload. To understand why PSPs and other Kubernetes
    security tools such as the **Open Policy Agent** (**OPA**) exist, you need to
    understand how a container is different from a **virtual machine** (**VM**).
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the difference between containers and VMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '"*A container is a lightweight VM*" is often how containers are described to
    those new to containers and Kubernetes. While this makes for a simple analogy,
    from a security standpoint, it''s a dangerous comparison. A container at runtime
    is a process that runs on a node. On a Linux system, these processes are isolated
    by a series of Linux technologies that limit their visibility to the underlying
    system.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to any node in a Kubernetes cluster and run the **top** command and all
    of the processes from containers are listed. As an example, even though Kubernetes
    is running in KinD, running **ps -A -elf | grep java** will show the OpenUnison
    and operator container processes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Pod processes from the system console'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Fig_10.1_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.1 – Pod processes from the system console
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, a VM is, as the name implies, a complete virtual system. It emulates
    its own hardware, has an isolated kernel, and so on. The hypervisor provides isolation
    for VMs down to the silicone layer, whereas by comparison, there is very little
    isolation between every container on a node.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: There are container technologies that will run a container on their own VM.
    The container is still just a process.
  prefs: []
  type: TYPE_NORMAL
- en: When containers aren't running, they're simply a "tarball of tarballs," where
    each layer of the filesystem is stored in a file. The image is still stored on
    the host system, or multiple host systems, wherever the container has been run
    or pulled previously.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: A "tarball" is a file created by the **tar** Unix command. It can also be compressed.
  prefs: []
  type: TYPE_NORMAL
- en: A VM, on the other hand, has its own virtual disk that stores the entire OS.
    While there are some very lightweight VM technologies, there's often an order
    of magnitude's difference in the size between a VM and a container.
  prefs: []
  type: TYPE_NORMAL
- en: While some people refer to containers as lightweight VMs, that couldn't be further
    from the truth. They aren't isolated in the same way and require more attention
    to be paid to the details of how they are run on a node.
  prefs: []
  type: TYPE_NORMAL
- en: From this section, you may think that we are trying to say that containers are
    not secure. Nothing could be further from the truth. Securing a Kubernetes cluster,
    and the containers running on it, requires attention to detail and an understanding
    of how containers differ from VMs. Since so many people do understand VMs, it's
    easy to attempt to compare them to containers, but doing so puts you at a disadvantage
    since they are very different technologies.
  prefs: []
  type: TYPE_NORMAL
- en: Once you understand the limitations of a default configuration and the potential
    dangers that come from it, you can remediate the "issues."
  prefs: []
  type: TYPE_NORMAL
- en: Container breakouts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A container breakout is when the process of your container gets access to the
    underlying node. Once on the node, an attacker now has access to all the other
    pods and any capability the node has in your environment. A breakout can also
    be a matter of mounting the local filesystem into your container. An example from
    [https://securekubernetes.com](https://securekubernetes.com), originally pointed
    out by Duffie Cooley from VMware, uses a container to mount the local filesystem.
    Running this on a KinD cluster opens both reads and writes to the node''s filesystem:'
  prefs: []
  type: TYPE_NORMAL
- en: 'kubectl run r00t --restart=Never -ti --rm --image lol --overrides ''{"spec":{"hostPID":
    true, "containers":[{"name":"1","image":"alpine","command":["nsenter","--mount=/proc/1/ns/mnt","--","/bin/bash"],"stdin":
    true,"tty":true,"imagePullPolicy":"IfNotPresent","securityContext":{"privileged":true}}]}}'''
  prefs: []
  type: TYPE_NORMAL
- en: If you don't see a command prompt, try pressing Enter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **run** command in the preceding code started a container that added an
    option that is key to the example, **hostPID: true**, which allows the container
    to share the host''s process namespace. You may see a few other options, such
    as **–mount** and a security context setting that sets **privileged** to **true**.
    All of the options combined will allow us to write to the host''s filesystem.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you are in the container, execute the **ls** command to look at the
    filesystem. Notice how the prompt is **root@r00t:/#**, confirming you are in the
    container and not on the host:'
  prefs: []
  type: TYPE_NORMAL
- en: root@r00t:/# ls
  prefs: []
  type: TYPE_NORMAL
- en: '**bin  boot  build  dev  etc  home  kind  lib  lib32  lib64  libx32  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var**'
  prefs: []
  type: TYPE_NORMAL
- en: 'To prove that we have mapped the host''s filesystem to our container, create
    a file called **this is from a container** and exit the container:'
  prefs: []
  type: TYPE_NORMAL
- en: root@r00t:/# touch this_is_from_a_container
  prefs: []
  type: TYPE_NORMAL
- en: root@r00t:/# exit
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let''s look at the host''s filesystem to see whether the container
    created the file. Since we are running KinD with a single worker node, we need
    to use Docker to **exec** into the worker node. If you are using the KinD cluster
    from the book, the worker node is called **cluster01-worker**:'
  prefs: []
  type: TYPE_NORMAL
- en: docker exec -ti cluster01-worker ls /
  prefs: []
  type: TYPE_NORMAL
- en: '**bin  boot  build  dev  etc  home  kind  lib  lib32  lib64  libx32  media  mnt  opt  proc  root  run  sbin  srv  sys  this_is_from_a_container  tmp  usr  var**'
  prefs: []
  type: TYPE_NORMAL
- en: There it is! In this example, a container was run that mounted the local filesystem.
    From inside of the pod, the **this_is_from_a_container** file was created. After
    exiting the pod and entering the node container, the file was there. Once an attacker
    has access to the node's filesystem, they also have access to the kubelet's credentials,
    which can open the entire cluster up.
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s not hard to envision a string of events that can lead to a Bitcoin miner
    (or worse) running on a cluster. A phishing attack gets the credentials a developer
    is using for their cluster. Even though those credentials only have access to
    one namespace, a container is created to get the kubelet''s credentials, and from
    there, containers are launched to stealthily deploy miners across the environment.
    There are certainly multiple mitigations that could be used to prevent this attack,
    including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Multi-factor authentication, which would have kept the phished credentials from
    being used
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pre-authorizing only certain containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A PSP, which would have prevented this attack by stopping a container from running
    as **privileged**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A properly secured base image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the core of security is a properly designed image. In the case of physical
    machines and VMs, this is accomplished by securing the base OS. When you install
    an OS, you don't select every possible option during installation. It is considered
    poor practice to have anything running on a server that is not required for its
    role or function. This same practice needs to be carried over to the images that
    will run on your clusters, which should only contain the necessary binaries that
    are required for your application.
  prefs: []
  type: TYPE_NORMAL
- en: Given how important it is to properly secure images on your cluster, the next
    section explores container design from a security standpoint. Building a locked-down
    container makes managing the security of the nodes much easier.
  prefs: []
  type: TYPE_NORMAL
- en: Properly designing containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before exploring how to build a **PodSecurityPolicy**, it's important to address
    how containers are designed. Often, the hardest part of using a **PodSecurityPolicy**
    to mitigate attacks on the node is the fact that so many containers are built
    and run as root. Once a restricted policy is applied, the container stops running.
    This is problematic at multiple levels. System administrators have learned over
    the decades of networked computing not to run processes as root, especially services
    such as web servers that are accessed anonymously over untrusted networks.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: All networks should be considered "untrusted." Assuming all networks are hostile
    leads to a more secure approach to implementation. It also means that services
    that need security need to be authenticated. This concept is called zero trust.
    It has been used and advocated by identity experts for years but was popularized
    in the DevOps and cloud native worlds by Google's BeyondCorp whitepaper ([https://cloud.google.com/beyondcorp](https://cloud.google.com/beyondcorp)).
    The concept of zero trust should apply inside your clusters too!
  prefs: []
  type: TYPE_NORMAL
- en: Bugs in code can lead to access to underlying compute resources, which can then
    lead to breakouts from a container. Running as root in a privileged container
    when not needed can lead to a breakout if exploited via a code bug.
  prefs: []
  type: TYPE_NORMAL
- en: The Equifax breach in 2017 used a bug in the Apache Struts web application framework
    to run code on the server that was then used to infiltrate and extract data. Had
    this vulnerable web application been running on Kubernetes with a privileged container,
    the bug could have led to the attackers gaining access to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'When building containers, at a minimum, the following should be observed:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Run as a user other than root**: The vast majority of applications, especially
    micro services, don''t need root. Don''t run as root.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Only write to volumes**: If you don''t write to a container, you don''t need
    write access. Volumes can be controlled by Kubernetes. If you need to write temporary
    data, use an **emptyVolume** object instead of writing to the container''s filesystem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Minimize binaries in your container**: This can be tricky. There are those
    that advocate for "distro-less" containers that only contain the binary for the
    application, statically compiled. No shells, no tools. This can be problematic
    when trying to debug why an application isn''t running as expected. It''s a delicate
    balance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scan containers for known Common Vulnerability Exposures (CVEs); rebuild
    often**: One of the benefits of a container is that it can be easily scanned for
    known CVEs. There are several tools and registries that will do this for you.
    Once CVEs have been patched, rebuild. A container that hasn''t been rebuilt in
    months, or years even, is every bit as dangerous as a server that hasn''t been
    patched.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: Scanning for CVEs is a standard way to report security issues. Application and
    OS vendors will update CVEs with patches to their code that fix the issues. This
    information is then used by security scanning tools to act on when a container
    has a known issue that has been patched.
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing, the most restrictive defaults for any Kubernetes distribution
    on the market belong to Red Hat's OpenShift. In addition to sane default policies,
    OpenShift runs pods with a random user ID, unless the pod definition specifies
    an ID.
  prefs: []
  type: TYPE_NORMAL
- en: It's a good idea to test your containers on OpenShift, even if it's not your
    distribution for production use. If a container will run on OpenShift, it's likely
    to work with almost any security policy a cluster can throw at it. The easiest
    way to do this is with Red Hat's CodeReady Containers ([https://developers.redhat.com/products/codeready-containers](https://developers.redhat.com/products/codeready-containers)).
    This tool can run on your local laptop and launches a minimal OpenShift environment
    that can be used for testing containers.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: While OpenShift has very tight security controls out of the box, it doesn't
    use PSPs. It has its own policy system that pre-dates PSPs, called **Security
    Context Constraints** (**SCCs**). SCCs are similar to PSPs but don't use RBAC
    for associating with pods.
  prefs: []
  type: TYPE_NORMAL
- en: PSP details
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: PSPs are tightly bound to how Linux processes run. The policy itself is a list
    of potential options any Linux process can have.
  prefs: []
  type: TYPE_NORMAL
- en: 'A PSP has several categories of privileges:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Privilege**: Does the pod need to run as a privileged pod? Does the pod need
    to do something that will change the underlying OS or environment?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Host interaction**: Does the pod need to interact with the host directly?
    For instance, does it need host filesystem access?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Volume types**: What kind of volumes can this pod mount? Do you want to limit
    it to specific volumes such as secrets but not disks?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User context**: What user will the process be allowed to run as? In addition
    to determining the allowed user ID and group ID ranges, SELinux and AppArmor contexts
    can be set as well.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A simple, unprivileged policy might look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'apiVersion: policy/v1beta1'
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: PodSecurityPolicy'
  prefs: []
  type: TYPE_NORMAL
- en: 'metadata:'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: pod-security-policy-default'
  prefs: []
  type: TYPE_NORMAL
- en: 'spec:'
  prefs: []
  type: TYPE_NORMAL
- en: 'fsGroup:'
  prefs: []
  type: TYPE_NORMAL
- en: 'rule: ''MustRunAs'''
  prefs: []
  type: TYPE_NORMAL
- en: 'ranges:'
  prefs: []
  type: TYPE_NORMAL
- en: Forbid adding the root group.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '- min: 1'
  prefs: []
  type: TYPE_NORMAL
- en: 'max: 65535'
  prefs: []
  type: TYPE_NORMAL
- en: 'runAsUser:'
  prefs: []
  type: TYPE_NORMAL
- en: 'rule: ''MustRunAs'''
  prefs: []
  type: TYPE_NORMAL
- en: 'ranges:'
  prefs: []
  type: TYPE_NORMAL
- en: Forbid adding the root group.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '- min: 1'
  prefs: []
  type: TYPE_NORMAL
- en: 'max: 65535'
  prefs: []
  type: TYPE_NORMAL
- en: 'seLinux:'
  prefs: []
  type: TYPE_NORMAL
- en: 'rule: RunAsAny'
  prefs: []
  type: TYPE_NORMAL
- en: 'supplementalGroups:'
  prefs: []
  type: TYPE_NORMAL
- en: 'rule: ''MustRunAs'''
  prefs: []
  type: TYPE_NORMAL
- en: 'ranges:'
  prefs: []
  type: TYPE_NORMAL
- en: Forbid adding the root group.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '- min: 1'
  prefs: []
  type: TYPE_NORMAL
- en: 'max: 65535'
  prefs: []
  type: TYPE_NORMAL
- en: 'volumes:'
  prefs: []
  type: TYPE_NORMAL
- en: '- emptyDir'
  prefs: []
  type: TYPE_NORMAL
- en: '- secret'
  prefs: []
  type: TYPE_NORMAL
- en: '- configMap'
  prefs: []
  type: TYPE_NORMAL
- en: '- persistentVolumeClaim'
  prefs: []
  type: TYPE_NORMAL
- en: The spec doesn't mention whether the containers can be privileged, nor does
    it mention any resources from the host that can be accessed. This means that if
    the pod definition attempts to mount the host's filesystem directly or to start
    as root, the pod will fail. Any permissions must be explicitly enabled in order
    for a pod to use them.
  prefs: []
  type: TYPE_NORMAL
- en: This policy limits which users a pod can run to anything except root by specifying
    the **MustRunAs** option, which is set to between **1** and **65535**; it does
    not include user 0 (root).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the policy allows the mounting of standard volume types that most pods
    might need. Few, if any, pods need to be able to mount the node's filesystem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having this policy in place would have stopped the breakout we used earlier
    to get access to the node''s filesystem. Here''s a YAML of the pod we tried running
    earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '---'
  prefs: []
  type: TYPE_NORMAL
- en: 'spec:'
  prefs: []
  type: TYPE_NORMAL
- en: '**hostPID: true**'
  prefs: []
  type: TYPE_NORMAL
- en: 'containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '- name: ''1'''
  prefs: []
  type: TYPE_NORMAL
- en: 'image: alpine'
  prefs: []
  type: TYPE_NORMAL
- en: 'command:'
  prefs: []
  type: TYPE_NORMAL
- en: '- nsenter'
  prefs: []
  type: TYPE_NORMAL
- en: '- "--mount=/proc/1/ns/mnt"'
  prefs: []
  type: TYPE_NORMAL
- en: '- "--"'
  prefs: []
  type: TYPE_NORMAL
- en: '- "/bin/bash"'
  prefs: []
  type: TYPE_NORMAL
- en: 'stdin: true'
  prefs: []
  type: TYPE_NORMAL
- en: 'tty: true'
  prefs: []
  type: TYPE_NORMAL
- en: 'imagePullPolicy: IfNotPresent'
  prefs: []
  type: TYPE_NORMAL
- en: '**securityContext:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**      privileged: true**'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two highlighted settings. The first is **hostPID**, which lets the
    pod share the process ID space with the node. One of the technologies used by
    the Linux kernel to enable containers is cgroups, which isolate processes in containers.
    In Linux, cgroups will give processes in containers a different process ID than
    what it would be if simply run on the node. As shown, the processes for all containers
    can be viewed from the node. Running **ps -A -elf | grep java** from inside the
    pod will have a different ID than what''s coming from the node. Since the **hostPID**
    option wasn''t set to **true** on our policy, the **PodSecurityPolicy** enforcement
    webhook would reject this pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2 – Process ID from the host and from inside a container'
  prefs: []
  type: TYPE_NORMAL
- en: '](image/Fig_10.2_B15514.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.2 – Process ID from the host and from inside a container
  prefs: []
  type: TYPE_NORMAL
- en: The next highlighted portion is the security context setting privileged to **true**.
    These two settings will allow the container to run as if it's a root user logged
    into a node. Again, the default PSP would have stopped this because privilege
    wasn't enabled. The PSP controller would stop it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, examine the NGINX Ingress controller''s recommended PSP from [https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/docs/examples/psp/psp.yaml](https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/docs/examples/psp/psp.yaml):'
  prefs: []
  type: TYPE_NORMAL
- en: 'apiVersion: policy/v1beta1'
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: PodSecurityPolicy'
  prefs: []
  type: TYPE_NORMAL
- en: 'metadata:'
  prefs: []
  type: TYPE_NORMAL
- en: .
  prefs: []
  type: TYPE_NORMAL
- en: .
  prefs: []
  type: TYPE_NORMAL
- en: '.spec:'
  prefs: []
  type: TYPE_NORMAL
- en: '**allowedCapabilities:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**  - NET_BIND_SERVICE**'
  prefs: []
  type: TYPE_NORMAL
- en: '**  allowPrivilegeEscalation: true**'
  prefs: []
  type: TYPE_NORMAL
- en: .
  prefs: []
  type: TYPE_NORMAL
- en: .
  prefs: []
  type: TYPE_NORMAL
- en: .
  prefs: []
  type: TYPE_NORMAL
- en: 'hostPID: false'
  prefs: []
  type: TYPE_NORMAL
- en: '**hostPorts:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**  - min: 80**'
  prefs: []
  type: TYPE_NORMAL
- en: '**    max: 65535**'
  prefs: []
  type: TYPE_NORMAL
- en: In a typical web server running on a host, the process will start as root (or
    at least a privileged user), then downgrades itself to an unprivileged user so
    that it can open ports **80** and **443** for HTTP and HTTPS. These ports are
    under **1024** and so are reserved in Linux for root processes.
  prefs: []
  type: TYPE_NORMAL
- en: If you're wondering whether a web server needs to be able to run on ports **80**
    or **443** in Kubernetes, it doesn't. As discussed earlier in this book, the vast
    majority of deployments have a load balancer in front of them that can map **80**
    and **443** to any port. This should really be an exception, not the rule. The
    NGINX Ingress controller was released at a time when security wasn't as front
    and center in Kubernetes as it is today. Also, deployment models weren't quite
    as mature.
  prefs: []
  type: TYPE_NORMAL
- en: To allow similar behavior as an NGINX web server would have running directly
    on a host, NGINX wants to be able to open ports from **80** up and escalate to
    privileged, specifically using the **NET_BIND_SERVICE** privilege so that the
    web server can open ports **80** and **443** without running the entire process
    as root.
  prefs: []
  type: TYPE_NORMAL
- en: As discussed earlier, the vast majority of containers do not need special privileges.
    Instances of getting access to these special privileges should be few and far
    between and need to be reserved only for specific use cases. When evaluating systems
    that may run on a cluster, it's important to see whether the vendor or project
    provides a PSP that's been tested to work. If not, assume it is unprivileged and
    use the tools discussed later in this chapter to debug a specific policy.
  prefs: []
  type: TYPE_NORMAL
- en: Assigning a PSP
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Once a policy is designed, it needs to be assigned. This is often the hardest
    part of deploying PSPs. The mechanism for determining whether a PSP is applied
    to a pod is the union of two sets of permissions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The user that submitted the pod**: This can get tricky as users rarely submit
    pods directly. The best practice is to create a **Deployment** or a **StatefulSet**.
    Controllers then create Pods (though not directly). The user that "creates" the
    pod is the correct controller''s service account, not the user that submitted
    the **Deployment** or **StatefulSet**. This can mean that usually only one or
    two service accounts ever actually create pods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The service account the pod runs as**: Each pod can define a service account
    that the pod can run as. This service account is scoped at the pod level, not
    on individual containers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By "union," Kubernetes will combine these permissions to determine which capabilities
    are to be allowed. For instance, if the controller's service account that submitted
    the pod has no privileges, but the service account for the pod can run as root,
    then the *best* policy will be chosen to apply to the pod that allows the pod
    to run as root. This process can be confusing and difficult to debug, and can
    often create unexpected results. A policy cannot be directly requested by a pod;
    it has to be assigned. It is important to keep policies constrained to make it
    more likely that the correct policy is applied.
  prefs: []
  type: TYPE_NORMAL
- en: Policies are evaluated and applied using special RBAC objects. Just as with
    the policy objects created to authorize access to APIs, both a **Role**/**ClusterRole**
    and a **RoleBinding**/**ClusterRoleBinding** need to be created. Instead of applying
    to specific APIs, RBAC objects that apply to **PodSecurityPolicy** objects use
    the **apiGroups** of **policy**, the resources of PSPs, and the **use** verb.
    The **use** verb doesn't have any corresponding HTTP action. The binding objects
    are generally the same as when authorizing API usage, but the subjects are generally
    service accounts, not users.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first policy created previously is a good generic minimum access policy.
    To apply it across the cluster, first create a **ClusterRole**:'
  prefs: []
  type: TYPE_NORMAL
- en: 'apiVersion: rbac.authorization.k8s.io/v1'
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: ClusterRole'
  prefs: []
  type: TYPE_NORMAL
- en: 'metadata:'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: default-psp'
  prefs: []
  type: TYPE_NORMAL
- en: 'rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '- apiGroups:'
  prefs: []
  type: TYPE_NORMAL
- en: '- policy'
  prefs: []
  type: TYPE_NORMAL
- en: 'resourceNames:'
  prefs: []
  type: TYPE_NORMAL
- en: '- **pod-security-policy-default**'
  prefs: []
  type: TYPE_NORMAL
- en: 'resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '- podsecuritypolicies'
  prefs: []
  type: TYPE_NORMAL
- en: 'verbs:'
  prefs: []
  type: TYPE_NORMAL
- en: '- use'
  prefs: []
  type: TYPE_NORMAL
- en: 'The **resourceNames** section is the only part of the policy that is specific
    to the PSP being referenced. Everything else in the policy is boilerplate. The
    **ClusterRoleBinding** will apply this across the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: 'apiVersion: rbac.authorization.k8s.io/v1'
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: ClusterRoleBinding'
  prefs: []
  type: TYPE_NORMAL
- en: 'metadata:'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: default-psp'
  prefs: []
  type: TYPE_NORMAL
- en: 'roleRef:'
  prefs: []
  type: TYPE_NORMAL
- en: 'apiGroup: rbac.authorization.k8s.io'
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: ClusterRole'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: default-psp'
  prefs: []
  type: TYPE_NORMAL
- en: 'subjects:'
  prefs: []
  type: TYPE_NORMAL
- en: '- apiGroup: rbac.authorization.k8s.io'
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: Group'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: system:authenticated'
  prefs: []
  type: TYPE_NORMAL
- en: When new pods are created, if no other policy applies, then the restricted policy
    will be used.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: If you're coming from the OpenShift ecosystem and are used to using SCCs, the
    authorization process is different. SCCs contain information on who is authorized
    directly on the object, whereas **PodSecurityPolicy** objects rely on RBAC.
  prefs: []
  type: TYPE_NORMAL
- en: Aren't they going away?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When Kubernetes 1.11 was released in 2018, it was revealed that PSPs will likely
    never go **General Availability** (**GA**). This revelation was based on feedback
    that PSPs were difficult to use and the issues were systemic from their design.
    The discussion that came out of this revelation focused on three potential solutions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Fix PSPs/reimplement a new standard**: These two options are bundled together
    because it''s believed "fixing" PSPs will result in a standard that breaks backward-compatibility,
    resulting in a new policy system. Another option that''s been floated is to port
    OpenShift''s SCC implementation upstream.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Remove PSPs**: An argument has been made that this should be implementation-specific
    and so up to the implementer. Since PSPs are implemented using an admission controller,
    the argument is that this can be left to third parties.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Provide a "basic" implementation**: This is a hybrid approach where the upstream
    Kubernetes build supports a subset of PSPs and relies on custom admission controllers
    to support more advanced implementations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There have not been any clear favorites as to which direction to go. What has
    been made clear is that PSPs will not be deprecated and removed until well after
    a replacement has become generally available. With Kubernetes 1.19, a new policy
    of not allowing APIs to remain in alpha or beta mode for more than three releases
    has forced the **PodSecurityPolicy** API to be deprecated. The API won't be removed
    until version 1.22, which isn't scheduled for release until January 2023 at the
    earliest (assuming at least 6 months between releases).
  prefs: []
  type: TYPE_NORMAL
- en: 'There are multiple approaches for protecting against an eventual deprecation
    of PSPs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Don''t use them at all**: This isn''t a great approach. It leaves the nodes
    of a cluster open.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Avoid ad hoc policies**: Automating the policy application process will make
    it easier to move to whatever replaces PSPs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use another technology**: There are other options for PSP implementations
    that will be covered in the *Alternatives to PSPs* section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Make a decision on PSPs based on your implementation needs. To stay updated
    on the progress of PSPs, watch the issue on GitHub: [https://github.com/kubernetes/enhancements/issues/5](https://github.com/kubernetes/enhancements/issues/5).'
  prefs: []
  type: TYPE_NORMAL
- en: Enabling PSPs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Enabling PSPs is very simple. Adding **PodSecurityPolicy** to the API server''s
    list of admission controllers will send all newly created Pod objects through
    the **PodSecurityPolicy** admission controller. This controller does two things:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Identifies the best policy**: The best policy to use is identified by the
    capabilities requested by a pod''s definition. A pod cannot explicitly state which
    policy it wants to enforce, only what capabilities it wants.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Determines whether the Pod''s policy is authorized**: Once a policy is identified,
    the admission controller needs to determine whether the creator of the pod or
    the **serviceAccount** of the pod is authorized to use that policy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The combination of these two criteria can lead to unexpected results. The creator
    of the pod isn't the user that submits the **Deployment** or **StatefulSet** definition.
    There's a controller that watches for **Deployment** updates and creates a **ReplicaSet**.
    There is a controller that watches for **ReplicaSet** objects and creates (**Pod)**
    objects. So, instead of the user who created the **Deployment** being the one
    that needs to be authorized, the **serviceAccount** for the **ReplicaSet** controller
    is. It's typical for blog posts and many default configurations to assign a privileged
    policy to all of the **ServiceAccount** objects in the **kube-system** namespace.
    This includes the **ServiceAccount** that the **ReplicaSet** controller runs as,
    which means it could create a pod with a privileged PSP without the creator of
    the **Deployment** or the **serviceAccount** of the pod being authorized to do
    so. It's important to press on your vendors to provide certified PSP definitions
    that have been tested.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before enabling the admission controller, it''s important to first create initial
    policies. The policy set from [https://raw.githubusercontent.com/PacktPublishing/Kubernetes-and-Docker-The-Complete-Guide/master/chapter10/podsecuritypolicies.yaml](https://raw.githubusercontent.com/PacktPublishing/Kubernetes-and-Docker-The-Complete-Guide/master/chapter10/podsecuritypolicies.yaml)
    has two policies and associated RBAC bindings. The first policy is the unprivileged
    policy that was described earlier in this chapter. The second policy is a privileged
    policy that is assigned to most of the **ServiceAccount** objects in the **kube-system**
    namespace. The **ReplicaSet** controller''s **ServiceAccount** is not assigned
    access to the privileged policy. If a **Deployment** needs to create a privileged
    pod, the pod''s **serviceAccount** will need to be authorized via RBAC to use
    the privileged policy. The first step is to apply these policies; the policy file
    is in the **chapter10** folder of your cloned repo:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Go into the **chapter10** folder and create the PSP object using **kubectl**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: kubectl create -f podsecuritypolicies.yaml
  prefs: []
  type: TYPE_NORMAL
- en: '**podsecuritypolicy.policy/pod-security-policy-default created**'
  prefs: []
  type: TYPE_NORMAL
- en: '**clusterrole.rbac.authorization.k8s.io/default-psp created**'
  prefs: []
  type: TYPE_NORMAL
- en: '**clusterrolebinding.rbac.authorization.k8s.io/default-psp created**'
  prefs: []
  type: TYPE_NORMAL
- en: '**podsecuritypolicy.policy/privileged created**'
  prefs: []
  type: TYPE_NORMAL
- en: '**clusterrole.rbac.authorization.k8s.io/privileged-psp created**'
  prefs: []
  type: TYPE_NORMAL
- en: '**rolebinding.rbac.authorization.k8s.io/kube-system-psp created**'
  prefs: []
  type: TYPE_NORMAL
- en: Once the policies are created, **docker exec** into the control plain container
    and edit **/etc/kubernetes/manifests/kube-apiserver.yaml**. Look for **- --enable-admission-plugins=NodeRestriction**
    and change it to **- --enable-admission plugins=PodSecurityPolicy,NodeRestriction**.
    Once the API server pod is restarted, all new and updated pod objects will go
    through the **PodSecurityPolicy** admission controller.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Managed Kubernetes offerings often pre-configure the **PodSecurityPolicy** admission
    controller. All pods are granted privileged access, so everything just "works."
    Enabling PSPs is a matter of creating the policies and the RBAC rules but not
    explicitly enabling them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since policies are enforced through an admission controller, any pods started
    that don''t have access to a privileged policy will continue to run. For instance,
    the NGINX Ingress controller is still running. Checking the annotations of any
    pod using **kubectl describe** will show that there are no annotations for which
    policy is being used. In order to apply policies to all of the running pods, they
    must all be deleted:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: kubectl delete pods --all-namespaces --all
  prefs: []
  type: TYPE_NORMAL
- en: '**pod "nginx-ingress-controller-7d6bf88c86-q9f2j" deleted**'
  prefs: []
  type: TYPE_NORMAL
- en: '**pod "calico-kube-controllers-5b644bc49c-8lkvs" deleted**'
  prefs: []
  type: TYPE_NORMAL
- en: '**pod "calico-node-r6vwk" deleted**'
  prefs: []
  type: TYPE_NORMAL
- en: '**pod "calico-node-r9ck9" deleted**'
  prefs: []
  type: TYPE_NORMAL
- en: '**pod "coredns-6955765f44-9vw6t" deleted**'
  prefs: []
  type: TYPE_NORMAL
- en: '**pod "coredns-6955765f44-qrcss" deleted**'
  prefs: []
  type: TYPE_NORMAL
- en: '**pod "etcd-cluster01-control-plane" deleted**'
  prefs: []
  type: TYPE_NORMAL
- en: '**pod "kube-apiserver-cluster01-control-plane" deleted**'
  prefs: []
  type: TYPE_NORMAL
- en: '**pod "kube-controller-manager-cluster01-control-plane" deleted**'
  prefs: []
  type: TYPE_NORMAL
- en: '**pod "kube-proxy-n2xf6" deleted**'
  prefs: []
  type: TYPE_NORMAL
- en: '**pod "kube-proxy-tkxh6" deleted**'
  prefs: []
  type: TYPE_NORMAL
- en: '**pod "kube-scheduler-cluster01-control-plane" deleted**'
  prefs: []
  type: TYPE_NORMAL
- en: '**pod "dashboard-metrics-scraper-c79c65bb7-vd2k8" deleted**'
  prefs: []
  type: TYPE_NORMAL
- en: '**pod "kubernetes-dashboard-6f89967466-p7rv5" deleted**'
  prefs: []
  type: TYPE_NORMAL
- en: '**pod "local-path-provisioner-7745554f7f-lklmf" deleted**'
  prefs: []
  type: TYPE_NORMAL
- en: '**pod "openunison-operator-858d496-zxnmj" deleted**'
  prefs: []
  type: TYPE_NORMAL
- en: '**pod "openunison-orchestra-57489869d4-btkvf" deleted**'
  prefs: []
  type: TYPE_NORMAL
- en: It will take a few minutes to run because the cluster needs to rebuild itself.
    Everything from etcd to the network is rebuilding its pods. After the command
    completes, watch all the pods to make sure they come back.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once all the **Pod** objects are back, take a look at the OpenUnison pod''s
    annotations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: kubectl describe pod -l application=openunison-orchestra -n openunison
  prefs: []
  type: TYPE_NORMAL
- en: Name:         openunison-orchestra-57489869d4-jmbk2
  prefs: []
  type: TYPE_NORMAL
- en: Namespace:    openunison
  prefs: []
  type: TYPE_NORMAL
- en: Priority:     0
  prefs: []
  type: TYPE_NORMAL
- en: Node:         cluster01-worker/172.17.0.3
  prefs: []
  type: TYPE_NORMAL
- en: Start Time:   Thu, 11 Jun 2020 22:57:24 -0400
  prefs: []
  type: TYPE_NORMAL
- en: Labels:       application=openunison-orchestra
  prefs: []
  type: TYPE_NORMAL
- en: operated-by=openunison-operator
  prefs: []
  type: TYPE_NORMAL
- en: pod-template-hash=57489869d4
  prefs: []
  type: TYPE_NORMAL
- en: 'Annotations:  cni.projectcalico.org/podIP: 10.240.189.169/32'
  prefs: []
  type: TYPE_NORMAL
- en: 'cni.projectcalico.org/podIPs: 10.240.189.169/32'
  prefs: []
  type: TYPE_NORMAL
- en: '**kubernetes.io/psp: pod-security-policy-default**'
  prefs: []
  type: TYPE_NORMAL
- en: The highlighted annotation shows that OpenUnison is running under the default
    restricted policy.
  prefs: []
  type: TYPE_NORMAL
- en: 'While OpenUnison is running, attempts to log in will fail. The NGINX Ingress
    pods aren''t running. As we discussed earlier in the chapter, NGINX needs to be
    able to open ports **443** and **80**, but using the default policy won''t allow
    this to happen. Confirm why NGINX isn''t running by inspecting the events in the
    **ingress-nginx** namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**$ kubectl get events -n ingress-nginx**'
  prefs: []
  type: TYPE_NORMAL
- en: '**2m4s        Warning   FailedCreate       replicaset/nginx-ingress-controller-7d6bf88c86   Error
    creating: pods "nginx-ingress-controller-7d6bf88c86-" is forbidden: unable to
    validate against any pod security policy: [spec.containers[0].securityContext.capabilities.add:
    Invalid value: "NET_BIND_SERVICE": capability may not be added spec.containers[0].hostPort:
    Invalid value: 80: Host port 80 is not allowed to be used. Allowed ports: [] spec.containers[0].hostPort:
    Invalid value: 443: Host port 443 is not allowed to be used. Allowed ports: []]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Even though the NGINX Ingress project provides polices and RBAC bindings, let''s
    debug this as if it doesn''t. Inspecting the **Deployment** object, the key block
    in the spec is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'ports:'
  prefs: []
  type: TYPE_NORMAL
- en: '- containerPort: 80'
  prefs: []
  type: TYPE_NORMAL
- en: 'hostPort: 80'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: http'
  prefs: []
  type: TYPE_NORMAL
- en: 'protocol: TCP'
  prefs: []
  type: TYPE_NORMAL
- en: '- containerPort: 443'
  prefs: []
  type: TYPE_NORMAL
- en: 'hostPort: 443'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: https'
  prefs: []
  type: TYPE_NORMAL
- en: 'protocol: TCP'
  prefs: []
  type: TYPE_NORMAL
- en: .
  prefs: []
  type: TYPE_NORMAL
- en: .
  prefs: []
  type: TYPE_NORMAL
- en: .
  prefs: []
  type: TYPE_NORMAL
- en: 'securityContext:'
  prefs: []
  type: TYPE_NORMAL
- en: 'allowPrivilegeEscalation: true'
  prefs: []
  type: TYPE_NORMAL
- en: 'capabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: 'add:'
  prefs: []
  type: TYPE_NORMAL
- en: '- NET_BIND_SERVICE'
  prefs: []
  type: TYPE_NORMAL
- en: 'drop:'
  prefs: []
  type: TYPE_NORMAL
- en: '- ALL'
  prefs: []
  type: TYPE_NORMAL
- en: 'runAsUser: 101'
  prefs: []
  type: TYPE_NORMAL
- en: First, the pod is declaring that it wants to open ports **80** and **443**.
    Next, its **securityContext** declares that it wants a privilege escalation and
    it wants the **NET_BIND_SERVICE** capability to open those ports without being
    root.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to the **audit2rbac** tool used when debugging RBAC policies, Sysdig
    has published a tool that will inspect the pods in a namespace and generate a
    recommended policy and RBAC set. Download the latest version from [https://github.com/sysdiglabs/kube-psp-advisor/releases](https://github.com/sysdiglabs/kube-psp-advisor/releases):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ./kubectl-advise-psp inspect  --namespace=ingress-nginx
  prefs: []
  type: TYPE_NORMAL
- en: '**apiVersion: policy/v1beta1**'
  prefs: []
  type: TYPE_NORMAL
- en: '**kind: PodSecurityPolicy**'
  prefs: []
  type: TYPE_NORMAL
- en: '**metadata:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**  creationTimestamp: null**'
  prefs: []
  type: TYPE_NORMAL
- en: '**  name: pod-security-policy-ingress-nginx-20200611232031**'
  prefs: []
  type: TYPE_NORMAL
- en: '**spec:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**  defaultAddCapabilities:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**  - NET_BIND_SERVICE**'
  prefs: []
  type: TYPE_NORMAL
- en: '**  fsGroup:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**    rule: RunAsAny**'
  prefs: []
  type: TYPE_NORMAL
- en: '**  hostPorts:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**  - max: 80**'
  prefs: []
  type: TYPE_NORMAL
- en: '**    min: 80**'
  prefs: []
  type: TYPE_NORMAL
- en: '**  - max: 443**'
  prefs: []
  type: TYPE_NORMAL
- en: '**    min: 443**'
  prefs: []
  type: TYPE_NORMAL
- en: '**  requiredDropCapabilities:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**  - ALL**'
  prefs: []
  type: TYPE_NORMAL
- en: '**  runAsUser:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**    ranges:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**    - max: 101**'
  prefs: []
  type: TYPE_NORMAL
- en: '**      min: 101**'
  prefs: []
  type: TYPE_NORMAL
- en: '**    rule: MustRunAs**'
  prefs: []
  type: TYPE_NORMAL
- en: '**  seLinux:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**    rule: RunAsAny**'
  prefs: []
  type: TYPE_NORMAL
- en: '**  supplementalGroups:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**    rule: RunAsAny**'
  prefs: []
  type: TYPE_NORMAL
- en: '**  volumes:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**  - secret**'
  prefs: []
  type: TYPE_NORMAL
- en: Compare this policy to the one provided by the NGINX Ingress project that was
    examined earlier in the chapter; you'll see that it's more restrictive on the
    ports and user, but less restrictive on the group. The **Deployment** declared
    the user but not the group, so **kube-psp-advisor** didn't know to restrict it.
    Unlike **audit2rbac**, **kube-psp-advisor** isn't scanning a log to see what is
    denied; it is proactively inspecting pod definitions to create policies. If a
    pod doesn't declare that it needs to run as root but just starts a container that
    runs as root, then **kube-psp-advisor** won't generate a proper policy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a policy file from **kube-psp-advisor** called **psp-ingress.yaml**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**$ ./kubectl-advise-psp inspect  --namespace=ingress-nginx > psp-ingress.yaml**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Deploy the PSP using **kubectl**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**$ kubectl create -f ./psp-ingress.yaml -n ingress-nginx**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, create RBAC bindings for the **nginx-ingress-serviceaccount ServiceAccount**
    (as referenced in the Deployment) to have access to this policy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'apiVersion: rbac.authorization.k8s.io/v1'
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: Role'
  prefs: []
  type: TYPE_NORMAL
- en: 'metadata:'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: nginx-ingress-psp'
  prefs: []
  type: TYPE_NORMAL
- en: 'namespace: ingress-nginx'
  prefs: []
  type: TYPE_NORMAL
- en: 'rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '- apiGroups:'
  prefs: []
  type: TYPE_NORMAL
- en: '- policy'
  prefs: []
  type: TYPE_NORMAL
- en: 'resourceNames:'
  prefs: []
  type: TYPE_NORMAL
- en: '- pod-security-policy-ingress-nginx-20200611232826'
  prefs: []
  type: TYPE_NORMAL
- en: 'resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '- podsecuritypolicies'
  prefs: []
  type: TYPE_NORMAL
- en: 'verbs:'
  prefs: []
  type: TYPE_NORMAL
- en: '- use'
  prefs: []
  type: TYPE_NORMAL
- en: '---'
  prefs: []
  type: TYPE_NORMAL
- en: 'apiVersion: rbac.authorization.k8s.io/v1'
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: RoleBinding'
  prefs: []
  type: TYPE_NORMAL
- en: 'metadata:'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: nginx-ingress-psp'
  prefs: []
  type: TYPE_NORMAL
- en: 'namespace: ingress-nginx'
  prefs: []
  type: TYPE_NORMAL
- en: 'roleRef:'
  prefs: []
  type: TYPE_NORMAL
- en: 'apiGroup: rbac.authorization.k8s.io'
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: Role'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: nginx-ingress-psp'
  prefs: []
  type: TYPE_NORMAL
- en: 'subjects:'
  prefs: []
  type: TYPE_NORMAL
- en: '- kind: ServiceAccount'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: nginx-ingress-serviceaccount'
  prefs: []
  type: TYPE_NORMAL
- en: 'namespace: ingress-nginx'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the RBAC objects are created, the Deployment needs to be updated to force
    Kubernetes to attempt to recreate the pods since the API server will stop trying
    after a certain point:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**$ kubectl scale deployment.v1.apps/nginx-ingress-controller --replicas=0
    -n ingress-nginx**'
  prefs: []
  type: TYPE_NORMAL
- en: '**deployment.apps/nginx-ingress-controller scaled**'
  prefs: []
  type: TYPE_NORMAL
- en: '**$ kubectl scale deployment.v1.apps/nginx-ingress-controller --replicas=1
    -n ingress-nginx**'
  prefs: []
  type: TYPE_NORMAL
- en: '**deployment.apps/nginx-ingress-controller scaled**'
  prefs: []
  type: TYPE_NORMAL
- en: '**$ kubectl get pods -n ingress-nginx**'
  prefs: []
  type: TYPE_NORMAL
- en: '**NAME                                        READY   STATUS    RESTARTS   AGE**'
  prefs: []
  type: TYPE_NORMAL
- en: '**nginx-ingress-controller-7d6bf88c86-h4449   0/1     Running   0          21s**'
  prefs: []
  type: TYPE_NORMAL
- en: If you check the annotations on the pod, the **PodSecurityPolicy** annotation
    will be there and OpenUnison is accessible again.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: A side effect of using RBAC to control PSP authorization is that an admin in
    a namespace is able to create **ServiceAccount** objects that can run privileged
    containers. Stopping this capability while still allowing a namespace admin to
    create RBAC policies in their namespace will be discussed in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations, you have successfully implemented PSPs on your cluster! Try
    running the breakout code we ran earlier in this chapter and you'll see that it
    won't work. The **Pod** won't even start! Seeing that the NGINX Ingress controller
    wouldn't start and debugging it gave you the tools to understand how to work through
    issues after enabling policy enforcement.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatives to PSPs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If not PSPs, then what? That really depends on a cluster's use case. There have
    been attempts to implement the full **PodSecurityPolicy** enforcement specification
    in OPA, which will be discussed in more detail in the next chapter. Several other
    projects have attempted to implement PSPs, if not the exact spec as the **PodSecurityPolicy**
    object. Given how fluid the space is, this chapter isn't going to enumerate all
    of the projects that are attempting to do this.
  prefs: []
  type: TYPE_NORMAL
- en: In May 2020, the authentication special interest group (**sig-auth**) published
    the *pod security standards* document to make it easier for different implementations
    of security policies to standardize on vocabulary and nomenclature. The standards
    were published on the Kubernetes website ([https://kubernetes.io/docs/concepts/security/pod-security-standards/](https://kubernetes.io/docs/concepts/security/pod-security-standards/)).
  prefs: []
  type: TYPE_NORMAL
- en: Be wary of implementing this logic on your own in your own admission controller
    as a validating webhook. Just as with any security implementation, great care
    needs to be taken to not only validate the expected outcome but also to make sure
    that unexpected scenarios are handled in an expected way. For instance, what happens
    if a **Deployment** is used to create a **Pod** versus creating a **Pod** directly?
    What happens when someone tries to inject invalid data into the definition? Or
    if someone tries to create a side car or an **init** container? When choosing
    an approach, it's important to ensure that any implementation has a thorough testing
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we began by exploring the importance of protecting nodes, the
    differences between containers and VMs from a security standpoint, and how easy
    it is to exploit a cluster when nodes aren't protected. We also looked at secure
    container design, and finally, we implemented and debugged a PSP implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Locking down the nodes of your cluster provides one less vector for attackers.
    Encapsulating the policy makes it easier to explain to your developers how to
    design their containers and makes it easier to build secure solutions.
  prefs: []
  type: TYPE_NORMAL
- en: So far, all of our security has been built on Kubernetes' standard technologies
    and is nearly universal across Kubernetes distributions. In the next chapter,
    we'll work on applying policies that are beyond the scope of Kubernetes using
    dynamic admission controllers and the OPA.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: True or false – containers are "lightweight VMs."
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. True
  prefs: []
  type: TYPE_NORMAL
- en: B. False
  prefs: []
  type: TYPE_NORMAL
- en: Can a container access resources from its host?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. No, it's isolated.
  prefs: []
  type: TYPE_NORMAL
- en: B. If marked as privileged, yes.
  prefs: []
  type: TYPE_NORMAL
- en: C. Only if explicitly granted by a policy.
  prefs: []
  type: TYPE_NORMAL
- en: D. Sometimes.
  prefs: []
  type: TYPE_NORMAL
- en: How could an attacker gain access to a cluster through a container?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. A bug in the container's application can lead to a remote code execution,
    which can be used to break out of a vulnerable container and then used to get
    the kubelet's credentials.
  prefs: []
  type: TYPE_NORMAL
- en: B. Compromised credentials with the ability to create a container in one namespace
    can be used to create a container that mounts the node's filesystem to get the
    kubelet's credentials.
  prefs: []
  type: TYPE_NORMAL
- en: C. Both of the above.
  prefs: []
  type: TYPE_NORMAL
- en: How does the **PodSecurityPolicy** admission controller determine which policy
    to apply to a pod?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. By reading an annotation on the pod's definition
  prefs: []
  type: TYPE_NORMAL
- en: B. By comparing the pod's requested capabilities and the policies authorized
    via the union of the pod's creator and its own **ServiceAccount**
  prefs: []
  type: TYPE_NORMAL
- en: C. By comparing the Pod's requested capabilities and the policies authorized
    for its own **ServiceAccount**
  prefs: []
  type: TYPE_NORMAL
- en: D. By comparing the pod's requested capabilities and the policies authorized
    for the pod's creator
  prefs: []
  type: TYPE_NORMAL
- en: What mechanism enforces PSPs?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. An admission controller that inspects all pods on creation and update
  prefs: []
  type: TYPE_NORMAL
- en: B. The **PodSecurityPolicy** API
  prefs: []
  type: TYPE_NORMAL
- en: C. The OPA
  prefs: []
  type: TYPE_NORMAL
- en: D. Gatekeeper
  prefs: []
  type: TYPE_NORMAL
- en: True or false – the **PodSecurityPolicy** API will be removed quickly.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. True
  prefs: []
  type: TYPE_NORMAL
- en: B. False
  prefs: []
  type: TYPE_NORMAL
- en: True or false – containers should generally run as root.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. True
  prefs: []
  type: TYPE_NORMAL
- en: B. False
  prefs: []
  type: TYPE_NORMAL
