- en: Graphs and Other Algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will discuss concepts related to the graphs. The concept
    of graphs comes from a branch of mathematics called **graph theory**. Graphs are
    used to solve a number of computing problems. Graphs are a non-linear data structure.
    This structure represents data by connecting a set of nodes or vertices along
    their edges. It is quite a different data structure compared to what we have looked
    at so far, and operations on graphs (for example, traversal) may be unconventional.
    We will be discussing many concepts related to graphs in this chapter. In addition,
    we will also be discussing priority queues and heaps later in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you should be able to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Understand what graphs are
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Know the types of graphs and their constituents
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Know how to represent a graph and traverse it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Get a fundamental idea of what priority queues are
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be able to implement a priority queue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be able to determine the i^(th) smallest element in a list
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All source code discussed in this chapter is provided in the GitHub repository
    at the following link: [https://github.com/PacktPublishing/Hands-On-Data-Structures-and-Algorithms-with-Python-Second-Edition/tree/master/Chapter08](https://github.com/PacktPublishing/Hands-On-Data-Structures-and-Algorithms-with-Python-Second-Edition/tree/master/Chapter08).
  prefs: []
  type: TYPE_NORMAL
- en: Graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A graph is a set of vertices and edges that form connections between the vertices.
    In a more formal approach, a graph **G** is an ordered pair of a set *V* of vertices
    and a set **E** of edges, given as `G = (V, E)` in formal mathematical notation.
  prefs: []
  type: TYPE_NORMAL
- en: 'An example of a graph is given here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/05db308a-34cf-4ecf-90df-2798d1d0153d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s discuss some of the important definitions of a graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Node or vertex**: A point or node in a graph is called a vertex, which is
    usually represented in a graph by a dot. In the preceding diagram, the vertices or
    nodes are **A**, **B**, **C**, **D**, and **E**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Edge**: This is a connection between two vertices. The line connecting **A**
    and **B** is an example of an edge in the preceding graph.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Loop**: When an edge from a node is incident on itself, that edge forms a
    loop.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Degree of a vertex**: The total number of edges that are incident on a given
    vertex is called the degree of that vertex. For example, the degree of the **B** vertex in
    the previous diagram is `4`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adjacency**: This refers to the connection(s) between any two nodes; thus,
    if there is a connection between any two vertices or nodes, then they are said
    to be adjacent to each other. For example, the **C** node is adjacent to the **A **node
    because there is an edge between them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Path**: A sequence of vertices and edges between any two nodes represents
    a path from the **A** vertex to the **B **vertex. For example, **CABE** represents
    a path from the **C** node to the **E** node.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Leaf vertex** (also called *pendant vertex*): A vertex or node is called
    a leaf vertex or pendant vertex if it has exactly one degree.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Directed and undirected graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Graphs are represented by the edges between the nodes. The connecting edges
    can be considered directed or undirected. If the connecting edges in a graph are
    undirected, then the graph is called an undirected graph, and if the connecting
    edges in a graph are directed, then it is called a directed graph. An undirected
    graph simply represents edges as lines between the nodes. There is no additional
    information about the relationship between the nodes, other than the fact that
    they are connected. For example, in the following diagram, we demonstrate an undirected
    graph of four nodes, **A**, **B**, **C**, and **D**, which are connected using
    edges:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/3b95d068-1a3e-4396-a06e-ccb8d3212bc8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In a directed graph, the edges provide the information on the direction of
    connection between any two nodes in a graph. If an edge from node **A** to **B**
    is said to be directed, then the edge (**A**, **B**) would not be equal to the
    edge (**B**, **A**). The directed edges are drawn as lines with arrows, which
    will point in whichever direction the edge connects the two nodes. For example,
    in the following diagram, we show a directed graph where many nodes are connected
    using directed edges:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/2a0b4a49-1e7d-4191-9261-ec2f3631e0c8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The arrow of an edge determines the flow of direction. One can only move from
    **A** to **B**, as shown in the preceding diagram—not **B** to **A**. In a directed
    graph, each node (or vertex) has an indegree and an outdegree. Let''s have a look
    at what these are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Indegree**: The total number of edges that come into a vertex in the graph
    is called the indegree of that vertex. For example, in the previous diagram, the
    **E** node has `1` indegree, due to edge **CE** coming into the **E** node.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Outdegree**: The total number of edges that goes out from a vertex in the
    graph is called the outdegree of that vertex. For example, the **E** node in the
    previous diagram has an outdegree of `2`, as it has two edges, **EF** and **ED**, going
    out of that node.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Isolated vertex**:A node or vertex is called an isolated vertex when it has
    a degree of zero.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Source vertex**: A vertex is called a source vertex if it has an indegree
    of zero. For example, in the previous diagram, the **A** node is the source vertex.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sink** **vertex**: A vertex is a sink vertex if that has an outdegree of
    zero. For example, in the previous diagram, the **F** node is the sink vertex.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weighted graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A weighted graph is a graph that has a numeric weight associated with the edges
    in the graph. It can be either a directed or an undirected graph. This numerical
    value can possibly be used to indicate distance or cost, depending upon the purpose
    of the graph. Let''s consider an example. The following graph indicates different
    ways to get from the **A** node to the **D **node. You can either go straight
    from **A** to **D**, or choose to pass through **B** and **C,** considering that
    the associated weight with each edge is the amount of time, in minutes, for the
    journey to the next node:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/16b1ee37-e5b6-4d4e-951c-7dfd2bcf24ba.png)'
  prefs: []
  type: TYPE_IMG
- en: In this example, **AD** and **ABCD** represent two different paths. A path is
    simply a sequence of edges that you pass through between two nodes. Following
    these paths, you see that the **AD** journey takes **40** minutes, whereas the
    **ABCD** journey takes **25** minutes. If the only concern is time, then it would
    be better to travel along the **ABCD **path, even though it may be a longer route. The
    point to take away here is that edges can be directed and may hold other information
    (for example, time taken, distance to be traveled, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: We can implement our graphs in a similar manner to what we have done with other
    data structures, such as linked lists. With graphs, it makes sense to see edges
    as objects, just as nodes. Just like nodes, edges can also contain extra information
    that makes it necessary to follow a particular path. The edges in the graphs can
    be represented using the links between different nodes; if there is a directed
    edge in the graph, we can implement it with an arrow pointing from one node to
    another, which is easy to represent in the node class by using `next` or `previous`,
    `parent`, or `child`.
  prefs: []
  type: TYPE_NORMAL
- en: Graph representations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Graphs can be represented with two main forms while implementing them in Python.
    One way is to use an adjacency list, and the other is to use an adjacency matrix.
    Let''s consider an example, shown in the following diagram, to develop both types
    of representation for graphs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/56cf0157-d3c0-4cbc-96f5-106bf1595186.png)'
  prefs: []
  type: TYPE_IMG
- en: Adjacency lists
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An adjacency list stores all the nodes, along with other nodes that are directly
    connected to them in the graph. Two nodes, `A` and `B`, in a graph `G`, are said
    to be adjacent if there is a direct connection between them. A `list` data structure
    in Python is used to represent a graph. The `indices` of the list can be used
    to represent the nodes or vertices in the graph.
  prefs: []
  type: TYPE_NORMAL
- en: 'At each index, the adjacent nodes to that vertex are stored. For example, consider
    the following adjacency list corresponding to the sample graph shown previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/ef3c9ee0-ee1c-4d1b-bac9-7ac85ad81b87.png)'
  prefs: []
  type: TYPE_IMG
- en: The numbers in the box represent the vertices. The `0` index represents the `A` vertex
    of the graph, with its adjacent nodes being `B` and `C`. The `1` index represents
    the `B` vertex of the graph, with its adjacent nodes of `E`, `C`, and `A`. Similarly,
    the other vertices, `C`, `E`, and `F`, of the graph are represented at the indices
    of `2`, `3`, and `4` with their adjacent nodes, as shown in the previous diagram.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using a `list` for the representation is quite restrictive, because we lack
    the ability to directly use the vertex labels. Therefore, a `dictionary` data
    structure is more suitable to represent the graph. To implement the same preceding
    graph using a dictionary data structure, we can use the following statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now we can easily establish that the **A** vertex has the adjacent vertices of **B**
    and **C**. The **F** vertex has the **C** vertex as its only neighbor. Similarly,
    the **B** vertex has adjacent vertices of **E**, **B**, and **A**.
  prefs: []
  type: TYPE_NORMAL
- en: Adjacency matrices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another approach by which a graph can be represented is by using an adjacency
    matrix. A matrix is a two-dimensional array. The idea here is to represent the
    cells with a `1` or `0`, depending on whether two vertices are connected by an
    edge or not. We demonstrate an example graph, along with its corresponding adjacency
    matrix, in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/239d325d-3579-44fc-9574-51a29681914d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'An adjacency matrix can be implemented using the given an adjacency list. To
    implement the adjacency matrix, let''s take the previous dictionary-based implementation
    of the graph. Firstly, we have to obtain the key elements of the adjacency matrix.
    It is important to note that these matrix elements are the vertices of the graph.
    We can get the key elements by sorting the keys of the graph. The code snippet
    for this is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, the length of the keys of the graph is used to provide the dimensions
    of the adjacency matrix, which are stored in `cols` and `rows`, and the values
    in the `cols` and `rows` are equal. We then create an empty adjacency matrix of
    the right size for the number of `cols` by `rows`, filling it with zeros. The `edges_list` variable
    will store the tuples that form the edges in the graph. For example, an edge between
    the A and B nodes will be stored as `(A, B)`. The code snippet to initialize an
    empty adjacency matrix is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The multidimensional array is filled using a nested `for` loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The neighbors of a vertex are obtained by `graph[key]`. The key, in combination
    with the `neighbor`, is then used to create the tuple stored in `edges_list`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of the preceding Python code for storing the edges of the graph
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The next step in implementing the adjacency matrix is to fill it, using `1`
    to denote the presence of an edge in the graph. This can be done with the `adjacency_matrix[index_of_first_vertex][index_of_second_vertex]
    = 1` statement. The full code snippet that marks the presence of edges of the
    graph is as follows
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The `matrix_elements` array has its `rows` and `cols`, starting from `A` to
    all other vertices with indices of `0` to `5`. The `for` loop iterates through
    our list of tuples and uses the `index` method to get the corresponding index
    where an edge is to be stored.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of the preceding code is the adjacency matrix for the sample graph
    shown previously. The adjacency matrix produced looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: At row `1` and column `1`, the `0` represents the absence of an edge between
    A and A. Similarly, at column `2` and row `3`, there is a value of `1` that denotes
    the edge between the C and B vertices in the graph.
  prefs: []
  type: TYPE_NORMAL
- en: Graph traversals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A graph traversal means to visit all the vertices of the graph, while keeping
    track of which nodes or vertices have already been visited and which ones have
    not. A graph traversal algorithm is efficient if it traverses all the nodes of
    the graph in the minimum possible time. A common strategy of graph traversal is
    to follow a path until a dead end is reached, then traverse back up until there
    is a point where we meet an alternative path. We can also iteratively move from
    one node to another in order to traverse the full graph, or part of it. Graph
    traversal algorithms are very important in answering many fundamental problems—they
    can be useful to determine how to reach from one vertex to another in a graph,
    and which path from the A to B vertices in the graph is better than other paths.
    In the next section, we will discuss two important graph traversal algorithms:
    **breadth-first search** (**BFS**) and **depth-first search** (**DFS**).'
  prefs: []
  type: TYPE_NORMAL
- en: Breadth-first traversal
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Breadth-first traversal algorithms work breadth-wise in the graph. A queue data
    structure is used to store the information of vertices that are to be visited
    in the graph. We begin with the starting node, the **A** node. Firstly, we visit
    that node, and then we look up all of its neighboring, or adjacent, vertices.
    We first visit these adjacent vertices one by one, while adding their neighbors
    to the list of vertices that are to be visited. We follow this process until we
    have visited all the vertices of the graph, ensuring that no vertex is visited
    twice.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider an example to better understand breadth-first traversal for
    graphs, using the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/f707225d-efca-4c9e-be16-cd6a3bac6ff5.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding diagram, we have a graph of five nodes on the left, and on
    the right, a queue data structure to store the vertices to be visited. We start
    visiting the first node, **A**, and then add all its adjacent vertices, **B**,
    **C**, and **E**, to the queue. Here, it is important to note that there are multiple
    ways of adding the adjacent nodes to the queue, since there are three nodes, **B**,
    **C**, and **E**, that can be added in the queue as either **BCE**, **CEB**, **CBE**, **BEC**,
    or **ECB**, each of which would give us different tree traversal results.
  prefs: []
  type: TYPE_NORMAL
- en: 'All of these possible solutions to the graph traversal are correct, but in
    this example, we will add the nodes in alphabetical order. The **A** node is visited
    as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/27150f8e-3c54-4124-95e2-52a1a5b48413.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once we have visited the **A** vertex, next, we visit its first adjacent vertex,
    **B**, and add those adjacent vertices that are not already added in the queue
    or not visited. In this case, we have to add the **D** vertex to the queue:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/3b782d49-aea9-4aa0-bccd-32be854c1741.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, after visiting the **B** vertex , we visit the next vertex from the queue—the
    **C** vertex. And again, add those of its adjacent vertices that have not already
    been added in the queue. In this case, there are no unrecorded vertices left,
    so there is no need to do anything:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/cb98173e-c3f9-4254-ac75-cb3eefaa916e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After visiting the **C** vertex, we visit the next vertex from the queue, the
    **E** vertex:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/a444bc08-d7ec-42e2-a6e7-32b1c06491c4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, after visiting the **E** vertex, we visit the **D** vertex in the
    last step:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/3e1093a8-d4a6-4d88-9140-2f5d5cb36f85.png)'
  prefs: []
  type: TYPE_IMG
- en: Therefore, the BFS algorithm for traversing the preceding graph visits the vertices
    in the order of **A-B-C-E-D**. This is one of the possible solutions to the BFS
    traversal for the preceding graph, but we can get many possible solutions, depending
    on how we add the adjacent nodes to the queue.
  prefs: []
  type: TYPE_NORMAL
- en: 'To learn the implementation of this algorithm in Python, let''s consider another
    example of an undirected graph. Consider the following diagram as a graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dbc67290-a5cd-4ffe-835a-3e11ea10b056.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The adjacency list for the graph is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: To traverse this graph using the breadth-first algorithm, we will employ the
    use of a queue. The algorithm creates a list to store the vertices that have been
    visited as the traversal process proceeds. We shall start our traversal from the `A` node.
  prefs: []
  type: TYPE_NORMAL
- en: The `A` node is queued and added to the list of visited nodes. Afterward, we
    use a `while` loop to effect traversal of the graph. In the `while` loop, the
    A node is dequeued. Its unvisited adjacent nodes, B, G, and D, are sorted in alphabetical
    order and queued up. The queue will now contain the B, D, and G nodes. These nodes
    are also added to the list of visited nodes. At this point, we start another iteration
    of the `while` loop, because the queue is not empty, which also means that we
    are not really done with the traversal.
  prefs: []
  type: TYPE_NORMAL
- en: The B node is dequeued. Out of its adjacent nodes, A, F, and E, node A has already
    been visited. Therefore, we only queue the E and F nodes in alphabetical order.
    The E and F nodes are then added to the list of visited nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Our queue now holds the following nodes at this point—D, G, E, and F. The list
    of visited nodes contains A, B, D, G, E, and F.
  prefs: []
  type: TYPE_NORMAL
- en: The D node is dequeued, but all of its adjacent nodes have been visited, so
    we simply dequeue it. The next node at the front of the queue is G. We dequeue
    the G node, but we also find out that all its adjacent nodes have been visited,
    because they are in the list of visited nodes. So, the G node is also dequeued.
    We dequeue the E node too, because all of its nodes have also been visited. The
    only node in the queue now is the F node.
  prefs: []
  type: TYPE_NORMAL
- en: The F node is dequeued, and we realize that out of its adjacent nodes, B, D,
    and C, only C has not been visited. We then enqueue the C node and add it to the
    list of visited nodes. Then, the C node is dequeued. C has the adjacent nodes
    of F and H, but F has already been visited, leaving the H node. The H node is
    enqueued and added to the list of visited nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the last iteration of the `while` loop will lead to the H node being
    dequeued. Its only adjacent node, C, has already been visited. Once the queue
    is completely empty, the loop breaks.
  prefs: []
  type: TYPE_NORMAL
- en: The output of the traversal the graph in the diagram is A, B, D, G, E, F, C,
    and H.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for a BFS is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: When we want to find out whether a set of nodes are in the list of visited nodes,
    we use the `remaining_elements = set(adj_nodes).difference(set(visited_vertices))` statement. This
    uses the `set` object's `difference` method to find the nodes that are in `adj_nodes`, but
    not in `visited_vertices`.
  prefs: []
  type: TYPE_NORMAL
- en: In the worst-case scenario, each vertex or node and the edge will be traversed,
    thus the time complexity of the BFS algorithm is `O(|V| + |E|)`, where `|V|` is
    the number of vertices or nodes, while `|E|` is the number of edges in the graph.
  prefs: []
  type: TYPE_NORMAL
- en: Depth-first search
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As the name suggests, the DFS algorithm traverses the depth of any particular
    path in the graph before traversing its breadth. As such, child nodes are visited
    first before sibling nodes. The `stack` data structure is used to implement the
    DFS algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by visiting the A node, and then we look at the neighbors of the A
    vertex, then a neighbor of that neighbor, and so on. Let''s consider the following
    graph in the context of DFS:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/ed6faf7a-b221-4000-bd58-91e6cf00c945.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After visiting the **A** vertex, we visit one of its neighbors, **B**, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/ec27341d-6a80-4b5d-a952-8fac290a5ae0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After visiting the **B** vertex, we look at another neighbor of **A**, that
    is, **S**, as there is no vertex connected to **B** which can be visited. Next,
    we look for the neighbors of the **S** vertex, which are the **C** and **G** vertices.
    We visit **C** as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/fe9f9af7-5783-4f10-bf19-af222854d129.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After visiting the **C** node, we visit its neighboring vertices, **D** and
    **E**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/6c2139c7-20f9-4d2f-9027-4e972e122b5c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, after visiting the **E** vertex, we visit the **H** and **F** vertices,
    as shown in the following graphs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/b063f8a5-beec-41da-bd2b-73bf9bec1cc9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, we visit the **F** node:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/bded1b28-229f-4a15-a99b-50dc72925357.png)'
  prefs: []
  type: TYPE_IMG
- en: The output of the DFS traversal is **A-B-S-C-D-E-H-G-F**.
  prefs: []
  type: TYPE_NORMAL
- en: 'To implement the DFS, we start with the adjacency list of the given graph.
    Here is the adjacency list of the preceding graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The implementation of the DFS algorithm begins by creating a list to store
    the visited nodes. The `graph_stack` stack variable is used to aid the traversal
    process. We are using a regular Python list as a stack. The starting node, called `root`,
    is passed with the graph''s adjacency matrix, graph. `root` is pushed onto the
    stack. `node = root` holds the first node in the stack:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The body of the `while` loop will be executed, provided the stack is not empty.
    If `node` is not in the list of visited nodes, we add it. All adjacent nodes to `node` are
    collected by `adj_nodes = graph[node]`. If all the adjacent nodes have been visited,
    we pop that node from the stack and set `node` to `graph_stack[-1]`. `graph_stack[-1]` is
    the top node on the stack. The `continue` statement jumps back to the beginning
    of the `while` loop's test condition.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: If, on the other hand, not all the adjacent nodes have been visited, then the
    nodes that are yet to be visited are obtained by finding the difference between
    the `adj_nodes` and `visited_vertices` with the `remaining_elements = set(adj_nodes).difference(set(visited_vertices))` statement.
  prefs: []
  type: TYPE_NORMAL
- en: The first item within `sorted(remaining_elements)` is assigned to `first_adj_node`,
    and pushed onto the stack. We then point the top of the stack to this node.
  prefs: []
  type: TYPE_NORMAL
- en: When the `while` loop exists, we will return `visited_vertices`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now explain the working of the source code by relating it to the previous
    example. The **A** node is chosen as our starting node. **A** is pushed onto the
    stack and added to the `visisted_vertices` list. In doing so, we mark it as having
    been visited. The `graph_stack` stack is implemented with a simple Python list.
    Our stack now has A as its only element. We examine the **A** node''s adjacent
    nodes, **B** and **S**. To test whether all the adjacent nodes of **A** have been
    visited, we use the `if` statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: If all the nodes have been visited, we pop the top of the stack. If the `graph_stack`
    stack is not empty, we assign the node on top of the stack to `node`, and start
    the beginning of another execution of the body of the `while` loop. The `set(adj_nodes).issubset(set(visited_vertices))`
    statement will evaluate to `True` if all the nodes in `adj_nodes` are a subset
    of `visited_vertices`. If the `if` statement fails, it means that some nodes remain
    to be visited. We obtain that list of nodes with `remaining_elements = set(adj_nodes).difference(set(visited_vertices))`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Referring to the diagram, the **B** and **S** nodes will be stored in `remaining_elements`.
    We will access the list in alphabetical order as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: We sort `remaining_elements` and return the first node to `first_adj_node`.
    This will return **B**. We push the **B** node onto the stack by appending it
    to the `graph_stack`. We prepare the **B** node for access by assigning it to
    `node`.
  prefs: []
  type: TYPE_NORMAL
- en: On the next iteration of the `while` loop, we add the **B** node to the list
    of `visited nodes`. We discover that the only adjacent node to **B**, which is
    **A**, has already been visited. Because all the adjacent nodes of **B** have
    been visited, we pop it off the stack, leaving **A** as the only element on the
    stack. We return to **A** and examine whether all of its adjacent nodes have been
    visited. The **A** node now has **S** as the only unvisited node. We push **S**
    to the stack and begin the whole process again.
  prefs: []
  type: TYPE_NORMAL
- en: The output of the traversal is `A-B-S-C-D-E-H-G-F`.
  prefs: []
  type: TYPE_NORMAL
- en: DFS find applications in solving maze problems, finding connected components,
    and finding the bridges of a graph, among others.
  prefs: []
  type: TYPE_NORMAL
- en: Other useful graph methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is very often that we need to use graphs for finding a path between two nodes.
    Sometimes, it is necessary to find all the paths between nodes, and in some situations,
    we might need to find the shortest path between nodes. For example, in routing
    applications, we generally use various algorithms to determine the shortest path
    from the source node to the destination node. For an unweighted graph, we would
    simply determine the path with the lowest number of edges between them. If a weighted
    graph is given, we have to calculate the total weight of passing through a set
    of edges.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, in a different situation, we may have to find the longest or shortest
    path using different algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Priority queues and heaps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A priority queue is a data structure which is similar to the queue and stack
    data structures that stores data along with the priority associated with it. In
    the priority queue, the item with the highest priority is served first. Priority
    queues are often implemented using a heap, since it is very efficient for this
    purpose; however, it can be implemented using other data structures. It is a modified
    queue that returns the items in the order of highest priority, whereas the queue
    returns the items in the order that the items were added. The priority queue is
    used in many applications, such as CPU scheduling.
  prefs: []
  type: TYPE_NORMAL
- en: Let's consider an example to demonstrate the importance of priority queues over
    regular queues. Assume that, in a store, customers queue in a line where service
    is rendered only at the front of the queue. Each customer will spend some time
    in the queue before getting served. If the units of time spent by four customers
    in the queue are 4, 30, 2, and 1 respectively, then the average time spent in
    the queue becomes `(4 + 34 + 36 + 37)/4`, which is `27.75`. However, if we associate
    the priority condition with the data stored in the queue, then we can give more
    priority to the customer that spends the least time. In this situation, the customers
    will be served in the order of time spent by the customers, that is, in the order
    of 1, 2, 4, then 30\. Thus, the average waiting time would be `(1 + 3 + 7 + 37)/4`,
    which now equals `12`—a better average waiting time. Clearly, there is merit to
    serving the customers by the least time spent. This method of selecting the next
    item by priority, or some other criterion, is the basis for creating priority
    queues. Priority queues are mostly implemented using heaps.
  prefs: []
  type: TYPE_NORMAL
- en: A heap is a data structure that satisfies a heap property. A heap property states
    that there must be a certain relationship between a parent node and its child
    nodes. This property must apply throughout the entire heap.
  prefs: []
  type: TYPE_NORMAL
- en: In a min heap, the relationship between parent and children is that the value
    at the parent must always be less than or equal to its children. As a consequence
    of this, the lowest element in the heap must be the root node.
  prefs: []
  type: TYPE_NORMAL
- en: In a max heap, on the other hand, the parent is greater than or equal to its
    child or its children. It follows from this that the largest value makes up the
    root node.
  prefs: []
  type: TYPE_NORMAL
- en: 'The heaps are binary trees, and although we are going to use a binary tree,
    we will actually use a list to represent it. The heap stores a complete binary
    tree. A complete binary tree is one in which each row must be fully filled before
    starting to fill the next row, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/1cc995f2-9454-47c1-9f92-c16a8b884182.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To make the math with indexes easier, we are going to leave the first item
    in the list (index 0) empty. After that, we place the tree nodes into the list,
    from top to bottom and left to right, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/8ddea893-9e46-4226-9160-4fcdd911daef.png)'
  prefs: []
  type: TYPE_IMG
- en: If you observe carefully, you will notice that you can retrieve the children
    of any node at the `n` index very easily. The left child is located at `2n`, and
    the right child is located at `2n + 1`. This will always hold true. For example,
    the C node would be at the `3` index, as **C** is a right child of the **A** node,
    whose index is `1`, so it becomes `2n+1 = 2*1 + 1 = 3`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s discuss the implementation of the min heap using Python, as implementing
    the max heap will be more straightforward once we understand the min heap. We
    start with the heap class, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We initialize our heap list with a zero to represent the dummy first element
    (remember that we are only doing this to make the math simpler). We also create
    a variable to hold the size of the heap. This would not be necessary as such,
    since we could check the size of the list, but we would always have to remember
    to reduce it by one. So, we choose to keep a separate variable instead.
  prefs: []
  type: TYPE_NORMAL
- en: Insert operation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Inserting an item to the min heap works in two steps. First, we add the new
    element to the end of the list (which we understand to be the bottom of the tree),
    and we increment the size of the heap by one. Secondly, after each insertion operation,
    we need to arrange the new element up in the heap tree, to organize all the nodes
    in such a way that it satisfies the heap property. This is to remind us that the
    lowest element in the min-heap needs to be the root element.
  prefs: []
  type: TYPE_NORMAL
- en: 'We first create a helper method, called `arrange`, that takes care of arranging
    all the nodes after insertion. Let''s consider an example of adding an element
    in the min heap. We provide an example heap in the following diagram, and want
    to insert the value of `2` in it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/8bb8b3e5-192f-4127-92f1-d97d8a56fcf2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The new element has occupied the last slot in the third row or level. Its index
    value is **7**. Now we compare that value with its parent. The parent is at index
    `7/2 = 3` (integer division). That element holds **6**, so we swap the **2**, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/1086030c-280d-4d34-bfa6-90f390182773.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Our new element has been swapped and moved up to the **3 **index. We have not
    reached the top of the heap yet (*3/2 > 0*), so we continue. The new parent of
    our element is at index *3/2=1*. So we compare and, if necessary, swap again:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/00545df1-f14c-4d8b-8d93-5120d5ab74d9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After the final swap, we are left with a heap that looks as follows. Notice
    that it adheres to the definition of a heap:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/53fadd7f-0c58-43a7-bdc3-f8ef93057166.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here is the implementation of `arrange()` method after we insert an element
    into the min-heap:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We are going to loop until we have reached the root node, so that we can keep
    arranging the element up as high as it needs to go. Since we are using integer
    division, as soon as we get below `2`, the loop will break out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Compare between the parent and child. If the parent is greater than the child,
    swap the two values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let''s not forget to move up the tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This method ensures that the elements are ordered properly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we just need to call this from our `insert` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the last line in `insert` calls the `arrange()` method to reorganize
    the heap as necessary.
  prefs: []
  type: TYPE_NORMAL
- en: Pop operation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `pop` operation removes an element from the heap. The reason for removing
    an element from the min-heap is, first, to find out the index of the item to be
    deleted, and then organize the heap so that it satisfies the heap property. However,
    it is more common to pop off the minimum value from the min-heap, and as per the
    property of the min-heap, we can get the minimum value by its root value. Therefore,
    to obtain and remove the minimum value from the min-heap, we remove the root node
    and re-organize all the nodes of the heap. We also decrement the size of the heap
    by one.
  prefs: []
  type: TYPE_NORMAL
- en: However, once the root has been popped off, we need a new root node. For this,
    we just take the last item from the list and make it the new root. That is, we
    move it to the beginning of the list. However, the selected last node might not
    be the lowest element of the heap, so we have to reorganize the nodes of the heap.
    To structure all the nodes according to the min-heap property, we follow a strategy
    that is opposite to the `arrange()` method that we used while inserting an element
    into the heap. We make the last node a new root, and then we let it move down
    (or sink down) as required.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider an example to help understand this concept in the following
    heap. First, we pop off the `root` element:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/ea6a7355-42dc-44ce-b906-c8a74c6c2856.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If we choose to move up one of the children of the root, we will have to figure
    out how to rebalance the entire tree structure, which would have been more complex.
    So, instead, we do something really interesting. We move up the very last element
    in the list to fill the position of the `root` element; for example, the last
    element, **6**, is placed at the root position in the following heap example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/7e7ff95f-1917-4ab7-9a1f-4f2a2d53dbe6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, this element is clearly not the lowest in the heap. So, we have to sink
    it down in the heap. Firstly, we need to determine whether to sink it down toward either the
    left or right child. We compare the two children, so that the lowest element will
    be the one to move up as the root sinks down. In the example, we compare the two
    children of the root, that is, **5** and **3**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/1d633f27-44e6-47c9-acfb-7ccb19717cb0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The right child is clearly smaller: its index is **3**, which represents *root
    index * 2 + 1*. We go ahead and compare our new root node with the value at this
    index, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/bc3c7d19-1995-4618-9569-e595be98aacc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now our node has moved down to index **3**. We need to compare it to the lesser
    of its children. However, now we only have one child, so we don''t need to worry
    about which child to compare it against (for a min heap, it is always the lesser
    child):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/2dc6e0f7-7801-4991-b6f6-dd66f46dc674.png)'
  prefs: []
  type: TYPE_IMG
- en: There is no need to swap here. Since there are no more rows, we don't need to
    do anything else. Notice here that, after the `sink()` operation is completed,
    the heap adheres to our definition of a heap.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can begin implementing this. But before we implement the `sink()` method,
    we need to note how we determine which of the children to compare against the
    parent node. Let''s put that selection in its own little method, just to make
    the code look a little simpler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We may get beyond the end of the list—if we do, then we return the index of
    the left child:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Otherwise, we simply return the index of the lesser of the two children:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can create the `sink` function. As we did before, we are going to loop
    so that we can sink our element down as far as is needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to know which of the left or the right children to compare against.
    This is where we make use of the `minindex()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'As we did in the `arrange()` method during the insertion operation, we compare
    parent and child to see whether we need to make the swap:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'And we need to make sure that we move down the tree, so that we don''t get
    stuck in a loop, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The only thing remaining now is to implement the main `pop()` method itself.
    This is very straightforward, as the grunt work is performed by the `sink()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Testing the heap
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s test the implementation of the heap, and discuss this with an example.
    We start with the construction of a heap by inserting 10 elements, one by one.
    Let the elements be `{4, 8, 7, 2, 9, 10, 5, 1, 3, 6}`. First, we manually create
    a heap with these elements, and then we will implement it and verify if we are
    doing it correctly or not:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/43b714fe-a272-4abf-8977-2404128f041b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We show, in the preceding diagram, a step-by-step process to insert elements
    in the heap. Here, we continue adding elements as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/f378b0d1-6ba0-4ad1-8c70-2fcd91194238.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, we insert an element, **6**, to the heap:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/73e8a792-fa08-4fc2-97e3-26ae969442a8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, let''s begin by creating the heap and inserting that data, as shown in
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We can print the heap list, just to inspect how the elements are ordered. If
    you redraw this as a tree structure, you would notice that it meets the required
    properties of a heap, similar to what we created manually:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we will pop off the items, one at a time. Notice how the items come out
    in a sorted order, from lowest to highest. Also, notice how the heap list changes
    after each `pop`. The `sink()` method will reorganize all the items in the heap:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: We have discussed, in the preceding section, the concepts around using the min-heap,
    so it should be a simple task to implement a max-heap by simply reversing the
    logic.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the min-heap that we discussed here again in [Chapter 10](3b546628-5e98-41b9-a0a8-066c907061c3.xhtml),
    *Sorting*, on sorting algorithms, and will rewrite the code for sorting the elements
    in the list. These algorithms are called heap sort algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Selection algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Selection algorithms fall under a class of algorithms that seek to answer the
    problem of finding the `i^(th)`-smallest element in a list. When a list is sorted
    in ascending order, the first element in the list will be the smallest item in
    the list. The second element in the list will be the second-smallest element in
    the list. The last element in the list will be the least-smallest (or, largest)
    element in the list.
  prefs: []
  type: TYPE_NORMAL
- en: In creating the heap data structure, we have come to understand that a call
    to the `pop` method will return the smallest element in the min-heap. The first
    element to pop off a min heap is the smallest element in the list. Similarly,
    the seventh element to be popped off the min heap will be the seventh-smallest
    element in the list. Therefore, finding the `i^(th)`-smallest element in a list
    will require us to pop the heap i number of times. This is a very simple and efficient
    way of finding the `i^(th)`-smallest element in a list.
  prefs: []
  type: TYPE_NORMAL
- en: However, in Chapter 11, *Selection Algorithms*, we will study more approaches
    to find the `i^(th)`-smallest element in a list.
  prefs: []
  type: TYPE_NORMAL
- en: Selection algorithms have applications in filtering out noisy data, finding
    the median, smallest, and largest elements in a list, and can even be applied
    in computer chess programs.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Graphs and heaps have been discussed in this chapter. The subject of graphs
    is very important and useful for many real-world applications. We have looked
    at different ways to represent a graph in Python, using lists and dictionaries.
    In order to traverse the graph, we used two methods: BFS and DFS.'
  prefs: []
  type: TYPE_NORMAL
- en: We then switched our attention to heaps and priority queues, in order to understand
    their implementation. The chapter ended with a discussion on using the concept
    of a heap to find the `i^(th)`-smallest element in a list.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will usher us into the arena of searching, and the various
    methods by which we can efficiently search for items in lists.
  prefs: []
  type: TYPE_NORMAL
