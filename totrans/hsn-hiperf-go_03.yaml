- en: Data Structures and Algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data structures and algorithms are the basic units of building software, notably
    complex, performance software. Understanding them helps us think about how to
    impactfully organize and manipulate data in order to write effective, performant
    software. This chapter will include explanations of different data structures
    and algorithms, as well as how their Big O notation is impacted.
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned in [Chapter 1](27d9fd37-672c-499b-88b9-89b9990117ed.xhtml),
    *Introduction to Performance in Go*, design-level decisions very often have the
    most measurable impact on performance. The least expensive calculation is the
    one you don't have to make – if you work toward optimizing your design early on
    while architecting your software, you can save yourself from a lot of performance
    penalties down the line.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will be discussing the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Benchmarking by utilizing Big O notation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Search and sort algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Queues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating simple data structures that don't contain superfluous information will
    help you write practical, performant code. Algorithms will also help improve the
    performance of the data structures that you have.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding benchmarking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Metrics and measurement are at the root of optimization. The adage *You can't
    improve what you can't measure* rings true with performance. To be able to make
    intelligent decisions about performance optimizations, we must continuously measure
    the performance of the functions we are trying to optimize.
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned in [Chapter 1](27d9fd37-672c-499b-88b9-89b9990117ed.xhtml),
    *Introduction to Performance in Go*, the Go creators made performance a forethought
    in their language design. The Go testing package ([https://golang.org/pkg/testing/](https://golang.org/pkg/testing/))
    is used to test Go code in a systematic way. The testing package is a fundamental
    part of the Go language. This package also includes a helpful built-in benchmarking
    functionality. This functionality, which is invoked by `go test -bench`, runs
    the benchmarks that you've defined for your functions. The results from your tests
    can also be saved and viewed at a later date. Having previous results of benchmarks
    from your functions available allows you to track the long-term changes that you
    are making in your functions and their outcomes. Benchmarking dovetails nicely
    with profiling and tracing to retrieve an accurate report of the state of our
    system. We will learn more about profiling and tracing in [Chapter 12](3ad3f76b-80c3-4992-8201-c025ece696b7.xhtml),
    *Profiling Go Code*, and [Chapter 13](ec12b9e7-c528-45c2-b0b8-dea297659b3e.xhtml),
    *Tracing Go Code*. As we are benchmarking, it's important to note that CPU frequency
    scaling should be disabled (see [https://blog.golang.org/profiling-go-programs](https://blog.golang.org/profiling-go-programs)).
    This will allow for more consistent benchmarking across benchmarking runs. An
    included bash script for disabling frequency scaling can be found at [https://github.com/bobstrecansky/HighPerformanceWithGo/blob/master/frequency_scaling_governor_diable.bash](https://github.com/bobstrecansky/HighPerformanceWithGo/blob/master/frequency_scaling_governor_diable.bash).
  prefs: []
  type: TYPE_NORMAL
- en: Benchmark execution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Benchmarks in Go use the axiom of starting with the word `Benchmark` (with
    a capital B) in the function call to denote that they are a benchmark and that
    they should use the benchmark functionality. To execute the benchmarks that you''ve
    defined for your code in your test package, you can use the `-bench=.` flag in
    your `go test` execution. This testing flag ensures all your benchmarking tests
    are run. An example of a benchmark is shown in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In this (admittedly simple) benchmark, we are iterating over our `fmt.Sprintf`
    statement b.N times. The benchmarking package executes and runs our `Sprintf`
    statement. During our test run, `b.N` is adjusted in the benchmark test until
    this function can be timed reliably. By default, a go benchmark test is run for
    1 second in order to get a statistically significant result set.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a number of flags that are available during the invocation of the
    benchmarking utility. A few helpful flags for benchmarking can be found in the
    following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Flag** | **Use Case** |'
  prefs: []
  type: TYPE_TB
- en: '| `-benchtime t` | Run enough iterations of the test to take the defined t
    duration. Increasing this value will run more iterations of `b.N`. |'
  prefs: []
  type: TYPE_TB
- en: '| `-count n` | Run each test n times. |'
  prefs: []
  type: TYPE_TB
- en: '| `-benchmem` | Turn on memory profiling for your test. |'
  prefs: []
  type: TYPE_TB
- en: '| `-cpu x,y,z` | Specify a list of `GOMAXPROCS` values for which the benchmarks
    should be executed. |'
  prefs: []
  type: TYPE_TB
- en: 'The following is an example of benchmark execution. In our example execution,
    we are profiling our existing Hello benchmark twice. We''re also using four `GOMAXPROCS`,
    viewing the memory profiling for our test, and performing these requests for 2
    seconds instead of the default 1-second test invocation. We can invoke our `go
    test -bench` functionality like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'A benchmark will run until the function returns, fails, or skips. The results
    of the benchmark are returned as a standard error once the test has completed.
    After the tests have completed and the results have been collated, we can make
    smart comparisons about the results of our benchmarks. Our following result shows
    an example test execution and the  resulting output from the preceding `BenchmarkHello`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/96668579-0851-402f-af1e-051278ef6c8d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In our output result, we can see a couple of different bits of data being returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '`GOOS` and `GOARCH` (which were discussed in the *Go toolset* section of [Chapter
    1](27d9fd37-672c-499b-88b9-89b9990117ed.xhtml), *Introduction to Performance in
    Go*)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The name of the benchmark that was run, followed by the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '-8: The number of `GOMAXPROCS` that were used to execute the tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '10000000: The number of times our loop ran to gather the necessary data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '112 ns/op: The speed per loop during our test.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'PASS: Indicates the end state of our benchmark run.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The final line of the test, with a compilation of the end state of our test
    run (ok), the path that we ran the test on, and the total time of our test run.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Real-world benchmarking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While you are running the benchmarks in this book, be sure to remember that
    benchmarks aren''t the be-all and end-all for performance results. Benchmarking
    has both positives and drawbacks:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The positives of benchmarking are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Surfaces potential problems before they become unwieldy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Helps developers have a deeper understanding of their code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can identify potential bottlenecks in the design and data structures and algorithms
    stages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The drawbacks of benchmarking are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Needs to be completed on a given cadence for meaningful results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data collation can be difficult
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does not always yield a meaningful result for the problem at hand
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Benchmarking is good for comparison. Benchmarking two things against one another
    on the same system can yield relatively consistent results. If you have the ability
    to run longer running benchmarks, it'll probably give you a much more indicative
    result of how a function is performing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Go `benchstat` ([https://godoc.org/golang.org/x/perf/cmd/benchstat](https://godoc.org/golang.org/x/perf/cmd/benchstat))
    package is a useful utility that helps you compare two benchmarks. Comparisons
    are very important in order to deduce whether or not the change you made to your
    function had a positive or negative impact on the system. You can install `benchstat`
    by using the `go get` utility:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Consider the following comparison test. We are going to test the marshaling
    of a single JSON structure with three elements, compared to the marshaling of
    two JSON arrays with five elements. You can find the source for these at [https://github.com/bobstrecansky/HighPerformanceWithGo/tree/master/2-data-structures-and-algorithms/Benchstat-comparison](https://github.com/bobstrecansky/HighPerformanceWithGo/tree/master/2-data-structures-and-algorithms/Benchstat-comparison).
  prefs: []
  type: TYPE_NORMAL
- en: 'To get an example comparison operator, we execute our benchmarks against our
    tests, as shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces an HTML table that can be used to validate the largest delta
    at execution time. As shown in the following screenshot, adding even a small amount
    of complexity to our data structure and the number of elements we process makes
    a fairly substantial change to the execution time of the function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7c08f7d1-7c30-4e40-b081-c9c6165f057d.png)'
  prefs: []
  type: TYPE_IMG
- en: Quickly identifying the performance pain points for your end users can help
    you determine the path to writing performant software.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will see what Big O notation is.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Big O notation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Big O notation is a good way to approximate the speed in which the algorithm
    you've chosen will change with the size of the data that's passed to your algorithm.
    Big O notation is often described as the growth behavior of a function, specifically
    its upper limit. Big O notation is broken down into classes. The most common classes
    that are described are O(1), O(log n), O(n), O(n log n), O(n²), and O(2^n). Let's
    take a quick look at each of these algorithms, their definitions, and a practical
    example of them in Go.
  prefs: []
  type: TYPE_NORMAL
- en: 'A graph of these common classes is as follows. The source code for generating
    this plot can be found at [https://github.com/bobstrecansky/HighPerformanceWithGo/blob/master/2-data-structures-and-algorithms/plot/plot.go](https://github.com/bobstrecansky/HighPerformanceWithGo/blob/master/2-data-structures-and-algorithms/plot/plot.go):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/034638be-b29a-488f-8aa3-c3493058aa2a.png)'
  prefs: []
  type: TYPE_IMG
- en: This Big O notation graph gives us a visual representation of the different
    algorithms that are commonly used in computer software.
  prefs: []
  type: TYPE_NORMAL
- en: Practical Big O notation example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If we take a sample dataset of 32 input values, we can quickly calculate the
    amount of time it''s going to take for each of our algorithms to complete. You''ll
    notice that the unit time to complete in the following table starts to grow very
    quickly. The practical Big O notation values are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Algorithm** | **Unit time to complete** |'
  prefs: []
  type: TYPE_TB
- en: '| O(1) | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| O(log n) | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| O(n) | 32 |'
  prefs: []
  type: TYPE_TB
- en: '| O(n log n) | 160 |'
  prefs: []
  type: TYPE_TB
- en: '| O(n²) | 1,024 |'
  prefs: []
  type: TYPE_TB
- en: '| O(2^n) | 4,294,967,296 |'
  prefs: []
  type: TYPE_TB
- en: As the unit time to complete gets larger, our code becomes less performant.
    We should strive to use the simplest algorithm possible to solve the dataset that
    we have at hand.
  prefs: []
  type: TYPE_NORMAL
- en: Data structure operations and time complexity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following diagram contains some of the common data structure operations
    and their time complexities. As we mentioned previously, data structures are a
    core piece of computer science performance. Understanding the difference between
    different data structures is important when writing performant code. Having this
    table readily accessible can help the developer choose the right data structure
    operation for the task at hand, while considering the impact that this operation
    is going to have on performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7fcfc5a9-a9fb-4bf2-8891-b508ce6d290c.png)'
  prefs: []
  type: TYPE_IMG
- en: Common data structure operations (from bigocheatsheet.com) – thanks to Eric
    Rowell
  prefs: []
  type: TYPE_NORMAL
- en: This table shows us time and space complexity given specific data structures.
    It is a valuable performance reference tool.
  prefs: []
  type: TYPE_NORMAL
- en: O(1) – constant time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Algorithms written in constant time have an upper bound that does not depend
    on the input size of the algorithm. Constant time is an upper bound by a constant
    value, and thus won't take longer than the upper bound of the dataset. This type
    of algorithm is usually okay to add to a function in practice – it doesn't add
    a lot of processing time to your function. Make sure to note the constant that
    occurs here. A single array lookup adds a negligible amount of time to a function.
    Looking up thousands of individual values in an array may add some overhead. Performance
    is always relative, and it is important to maintain cognizant of the additional
    load you're adding to your functions, even if they only perform a trivial amount
    of processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples of constant time are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Accessing a single element in a map or an array
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determining the modulus of a number
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stack push or stack pop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deducing whether or not an integer is even or odd
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An example of a constant time algorithm in Go would be accessing a single element
    within an array.
  prefs: []
  type: TYPE_NORMAL
- en: 'This would be written as follows in Go:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This function has a Big O notation of O(1) because we only have to look at
    the individual defined value of `words[1]` in order to find the value we are looking
    for, that is, `bar`. As our array size in this example grows, the time to refer
    to an object within the array will remain constant. The normalized timings for
    this algorithm should all be the same, as shown in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Number of items in the dataset** | **Resulting computation time** |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 1 second |'
  prefs: []
  type: TYPE_TB
- en: '| 100 | 1 second |'
  prefs: []
  type: TYPE_TB
- en: '| 1,000 | 1 second |'
  prefs: []
  type: TYPE_TB
- en: 'Some sample code for O(1) notation is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'No matter how many items are in an array, the lookup for one element takes
    the same amount of time. In the following example output, we have arrays with
    three elements and 10 elements, respectively. Both take the same amount of time
    to execute and complete the same number of test iterations within their allotted
    time frame. This can be seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/11a995b2-cec2-497c-971e-264288fee4ae.png)'
  prefs: []
  type: TYPE_IMG
- en: This benchmark performs as we would expect it to. Both the `BenchmarkThree`
    and `BenchmarkTen` benchmarks took 0.26 ns/op, which should be consistent across
    array lookups.
  prefs: []
  type: TYPE_NORMAL
- en: O(log n) - logarithmic time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Logarithmic growth is often represented as a partial sum of the harmonic series.
    This can be represented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5a4ae3d3-8114-4368-9af5-cf2254c4bfd8.png)'
  prefs: []
  type: TYPE_IMG
- en: An algorithm written in logarithmic time has a number of operations that tend
    toward zero as the size of the input decreases. An O(log n) algorithm cannot be
    used in an algorithm when all of the elements in the array must be accessed. O(log
    n) is usually considered an efficient algorithm when it is used by itself. One
    important concept to think about with respect to performance in logarithmic time
    is that search algorithms are commonly used with sort algorithms, which adds to
    the complexity of finding the solution. Depending on the size and complexity of
    the dataset, it can often make sense to sort the data before the search algorithm
    is executed. Note the input and output ranges for this test – additional tests
    were added to show the logarithmic growth of the resulting computation time of
    the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some examples of logarithmic time algorithms are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Binary search
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dictionary search
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following table shows the normalized timings for logarithmic time:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Number of items in the dataset** | **Resulting computation time** |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 1 second |'
  prefs: []
  type: TYPE_TB
- en: '| 100 | 2 seconds |'
  prefs: []
  type: TYPE_TB
- en: '| 1,000 | 3 seconds |'
  prefs: []
  type: TYPE_TB
- en: 'Go''s standard library has a function called `sort.Search()`. It has been included
    in the following snippet for reference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This code sample can be found in the standard library at [https://golang.org/src/sort/search.go](https://golang.org/src/sort/search.go).
    The code and benchmark for an O(log n) function can be found at [https://github.com/bobstrecansky/HighPerformanceWithGo/tree/master/2-data-structures-and-algorithms/BigO-notation-o-logn](https://github.com/bobstrecansky/HighPerformanceWithGo/tree/master/2-data-structures-and-algorithms/BigO-notation-o-logn).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows a logarithmic time benchmark:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cf9bd878-23e5-42f0-b56c-efa3ba48457e.png)'
  prefs: []
  type: TYPE_IMG
- en: This test shows a logarithmic increase in timing based on the input we set.
    Algorithms with a logarithmic time response are very helpful in writing performant
    code.
  prefs: []
  type: TYPE_NORMAL
- en: O(n) – linear time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Algorithms written in linear time scale linearly with the size of their dataset.
    Linear time is the best possible time complexity when an entire dataset needs
    to be read sequentially. The amount of time an algorithm takes in linear time,
    scales on a 1:1 relationship with the number of items that are contained within
    the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some examples of linear time are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Simple loop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linear search
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Normalized timings for linear time can be found in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Number of items in the dataset** | **Resulting computation time** |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 10 seconds |'
  prefs: []
  type: TYPE_TB
- en: '| 100 | 100 seconds |'
  prefs: []
  type: TYPE_TB
- en: '| 1,000 | 1,000 seconds |'
  prefs: []
  type: TYPE_TB
- en: 'Note that the result computation time increases linearly and correlates to
    the number of items that were found in our dataset (refer to the following screenshot).
    The code and benchmark of an O(n) function can be found at [https://github.com/bobstrecansky/HighPerformanceWithGo/tree/master/2-data-structures-and-algorithms/BigO-notation-o-n](https://github.com/bobstrecansky/HighPerformanceWithGo/tree/master/2-data-structures-and-algorithms/BigO-notation-o-n):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0353b6e7-8ef9-4446-b4f5-100d01bdd6d5.png)'
  prefs: []
  type: TYPE_IMG
- en: An important point to remember is that Big O notation isn't necessarily a perfect
    indicator of response time growth; it just denotes an upper ceiling. While reviewing
    this benchmark, focus on the fact that the resulting computation time grows linearly
    with the number of items in the dataset. O(n) algorithms are typically not the
    big showstopper in computer science from a performance perspective. Computer scientists
    perform loops on iterators frequently, and it's a common pattern that's used to
    get computational work completed. Make sure that you're always cognizant of the
    size of your dataset!
  prefs: []
  type: TYPE_NORMAL
- en: O(n log n) – quasilinear time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Algorithms written in quasilinear (or log-linear) time are often used to order
    values within an array in Go.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some examples of quasilinear time are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The average case time complexity for Quicksort
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The average case time complexity for Mergesort
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The average case time complexity for Heapsort
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The average case time complexity for Timsort
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The normalized timings for quasilinear time can be found in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Number of items in the dataset** | **Resulting computation time** |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 10 seconds |'
  prefs: []
  type: TYPE_TB
- en: '| 100 | 200 seconds |'
  prefs: []
  type: TYPE_TB
- en: '| 1,000 | 3,000 seconds |'
  prefs: []
  type: TYPE_TB
- en: 'You''ll see a familiar pattern here. This algorithm follows a pattern that''s
    similar to the O(log n) algorithm. The only thing that changes here is the n multiplier,
    so we can see similar results with a scaling factor (refer to the following screenshot).
    The code and benchmark of an O(n log n) function can be found at [https://github.com/bobstrecansky/HighPerformanceWithGo/tree/master/2-data-structures-and-algorithms/BigO-notation-o-nlogn](https://github.com/bobstrecansky/HighPerformanceWithGo/tree/master/2-data-structures-and-algorithms/BigO-notation-o-nlogn):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dba95ab6-8b0c-41c9-8531-dc894233bcb7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Sorting algorithms are still fairly fast and aren''t the crux of ill-performing
    code. Frequently, sorting algorithms used in languages use a hybrid of multiple
    sorting algorithms based on size. Go''s `quickSort` algorithm, the sort that''s
    used in `sort.Sort()`, uses `ShellSort` and `insertionSort` if the slice contains
    less than 12 elements. This standard library algorithm for `quickSort` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code can be found in the standard library at [https://golang.org/src/sort/sort.go#L183](https://golang.org/src/sort/sort.go#L183).
    This `quickSort` algorithm is performant and is used constantly in the Go ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: O(n2) – quadratic time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Algorithms written in quadratic time have an execution time that corresponds
    directly to the square of the input size. Nested loops are common quadratic time
    algorithms, which brings along sorting algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some examples of quadratic time are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Bubble Sort
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Insertion Sort
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selection Sort
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Normalized timings for quadratic time can be found in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Number of items in the dataset** | **Resulting computation time** |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 100 seconds |'
  prefs: []
  type: TYPE_TB
- en: '| 100 | 10,000 seconds |'
  prefs: []
  type: TYPE_TB
- en: '| 1,000 | 1,000,000 seconds |'
  prefs: []
  type: TYPE_TB
- en: You'll note from this table that as the input grows by a factor of 10, the resulting
    computation time grows quadratically.
  prefs: []
  type: TYPE_NORMAL
- en: Quadratic time algorithms should be avoided if possible. If you need to have
    a nested loop or a quadratic calculation, be sure to validate your inputs and
    attempt to constrain your input sizes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code and benchmark of an O(n²) function can be found at [https://github.com/bobstrecansky/HighPerformanceWithGo/tree/master/2-data-structures-and-algorithms/BigO-notation-o-n2](https://github.com/bobstrecansky/HighPerformanceWithGo/tree/master/2-data-structures-and-algorithms/BigO-notation-o-n2).
    The following is the output of running this benchmark:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f412695c-2fa3-46c7-9204-eaf40c91c468.png)'
  prefs: []
  type: TYPE_IMG
- en: Quadratic timing algorithms get very expensive very quickly. We can see this
    with our own benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: O(2n) – exponential time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An exponential algorithm grows exponentially when data is added to the input
    set. These are usually used when there isn't an inclination of the input dataset
    and you must try every possible composite of the input set.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some examples of exponential time are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Poor recursion implementation of the Fibonacci sequence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Towers of Hanoi
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traveling salesman problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Normalized timings for exponential time can be found in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Number of items in the dataset** | **Resulting computation time** |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 1,024 seconds |'
  prefs: []
  type: TYPE_TB
- en: '| 100 | 1.267 * 10^(30) seconds |'
  prefs: []
  type: TYPE_TB
- en: '| 1,000 | 1.07 * 10^(301) seconds |'
  prefs: []
  type: TYPE_TB
- en: As the number of items in the dataset grows, the resulting computation time
    grows exponentially.
  prefs: []
  type: TYPE_NORMAL
- en: Exponential time algorithms should only be used in dire situations with very
    narrowly scoped datasets. Usually, clarifying your underlying problem or dataset
    further can help you avoid using an exponential time algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for an O(n²) algorithm can be found at [https://github.com/bobstrecansky/HighPerformanceWithGo/tree/master/2-data-structures-and-algorithms/BigO-notation-o-n2](https://github.com/bobstrecansky/HighPerformanceWithGo/tree/master/2-data-structures-and-algorithms/BigO-notation-o-n2).
    Some example output for this benchmark can be seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5fc4a22c-73c8-485f-91af-d06ed8509d48.png)'
  prefs: []
  type: TYPE_IMG
- en: Exponential time algorithm problems can often be broken down into smaller, more
    digestible pieces. This also allows for optimization.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at sort algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding sort algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Sorting algorithms are used to take individual elements in a dataset and put
    them in a specific order. Usually, sorting algorithms take a dataset and put them
    in either lexicographical or numerical order. Being able to sort efficiently is
    important in writing performant code, as many search algorithms require a sorted
    dataset. The common data structure operations can be seen in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e82896f2-626c-45f7-9ce7-54b0be484b54.png)'
  prefs: []
  type: TYPE_IMG
- en: Common Data Structure Operations (from bigocheatsheet.com) - thanks to Eric
    Rowell
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, array sorting algorithms can have vastly different Big O notation.
    Choosing the correct sort algorithm for your unordered list is important when
    it comes to providing an optimized solution.
  prefs: []
  type: TYPE_NORMAL
- en: Insertion sort
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Insertion sort is a sorting algorithm that constructs an array one item at a
    time until it results in a sorted array. It's not very efficient, but it does
    have a simple implementation and is quick for very small datasets. The array is
    sorted in place, which can also help reduce the memory footprint of the function
    call.
  prefs: []
  type: TYPE_NORMAL
- en: 'This standard library algorithm for `insertionSort` can be found in the following
    code snippet. We can use the following code snippet to deduce that insertion sort
    is an average case of an O(n²) algorithm. This is due to the fact that we iterate
    through a 2D array and manipulate data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This code can be found in the standard library at [https://golang.org/src/sort/sort.go#L183](https://golang.org/src/sort/sort.go#L24).
    A simple insertion sort is often valuable for small datasets because it is very
    easy to read and comprehend. Simplicity often outweighs everything else when it
    comes to writing performant code.
  prefs: []
  type: TYPE_NORMAL
- en: Heap sort
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Go has a built-in `heapSort` in the standard library, as shown in the following
    code snippet. This code snippet helps us understand that `heapSort` is an O(n
    log n) sorting algorithm. This is better than our preceding insertion sort example,
    so for larger datasets, we are going to have more performant code when using our
    heap sort algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This code can be found in the standard library at [https://golang.org/src/sort/sort.go#L53](https://golang.org/src/sort/sort.go#L53).
    When our datasets become larger, it is important to start using efficient sort
    algorithms such as `heapSort`.
  prefs: []
  type: TYPE_NORMAL
- en: Merge sort
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Merge sort is a sorting algorithm with an O(n log n) average time complexity.
    `MergeSort` is often used if the goal of the algorithm is to produce a stable
    sort. A stable sort ensures that two objects that share the same key in an input
    array appear in the resulting array in the same order. Stability is important
    if we want to make sure that a key-value order pair is organized within an array.
    An implementation of a stable sort can be found in the Go standard library. This
    can be seen in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This code can be found in the standard library at [https://golang.org/src/sort/sort.go#L356](https://golang.org/src/sort/sort.go#L356).
    Stable sorting algorithms are important when order needs to be maintained.
  prefs: []
  type: TYPE_NORMAL
- en: Quick sort
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Go standard library has a quick sort algorithm, as we saw in the *O( n log
    n) – quasilinear time* section. QuickSort was initially implemented in Unix as
    the default sort routine in the standard library. From there, it was built upon
    and used as qsort in the C programming language. Because of its familiarity and
    vast history, it is commonly used as a sorting algorithm in many computer science
    problems today. Using our algorithms table, we can deduce that a standard implementation
    of the `quickSort` algorithm has an average time complexity of O(n log n). It
    also has the added benefit of using, at worst, an O(log n) space complexity, making
    it ideal for in-place moves.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we are done with sort algorithms, we will move on to search algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding search algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Search algorithms are typically used in order to retrieve an element from a
    dataset or to check for the presence of that element. Search algorithms are generally
    classified into two separate categories: linear search and interval search.'
  prefs: []
  type: TYPE_NORMAL
- en: Linear search
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a linear search algorithm, every element in the slice or array is checked
    when the slice or array is traversed sequentially. This algorithm isn't the most
    efficient algorithm since it ranks in at an O(n) complexity because it can traverse
    every element on the list.
  prefs: []
  type: TYPE_NORMAL
- en: 'A linear search algorithm can be written simply as an iteration through a slice,
    as shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This function shows us that it'll get expensive quickly with larger datasets.
    With a dataset of 10 elements, this algorithm won't take very long as it will
    only iterate through 10 values at a maximum. If our dataset contained 1 million
    elements, this function would take much longer to return a value.
  prefs: []
  type: TYPE_NORMAL
- en: Binary search
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A much more commonly used pattern (and the pattern that you''d most likely
    want to use for a performant search algorithm) is called binary search. An implementation
    of a binary search algorithm can be found in the Go standard library at [https://golang.org/src/sort/search.go](https://golang.org/src/sort/search.go)
    and was displayed in the sort search function earlier in this chapter. A binary
    search tree has an O(log n) search complexity compared to the O(n) complexity
    of the linear search function that we wrote previously. Binary search tends to
    get used frequently, especially when the dataset that needs to be searched gets
    to any sort of reasonable size. Binary search is also smart to implement early
    – if the dataset that you have grows without you being privy to the growth, at
    least the utilized algorithm will not increase in complexity. In the following
    code, we''re using the `SearchInts` convenience wrapper for the Go search function.
    This allows us to iterate through an integer array with a binary search:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The output from this function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/66928f1b-7aa7-44b9-a8a6-79fd381a9650.png)'
  prefs: []
  type: TYPE_IMG
- en: This shows us that the binary search library was able to find the number we
    were searching for (`34`) in the array that we were searching (`intArray`). It
    found the integer 34 in the 6th position in the array (which is correct; the array
    is 0 indexed).
  prefs: []
  type: TYPE_NORMAL
- en: 'The upcoming section deals with another data structure: trees.'
  prefs: []
  type: TYPE_NORMAL
- en: Exploring trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A tree is a non-linear data structure that is used in computer science to store
    information. It's commonly used to store data that maintains relationships, particularly
    if the relationships form a hierarchy. Trees are also simple to search (diagram
    for array sorting algorithms in the *Understanding sort algorithms* section) shows
    us that many trees have an O(log n) time complexity with operations in trees).
    For many problems, trees are the best solution because of how they reference hierarchical
    data. Trees are combinations of nodes that don't make a cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Each tree is made up of elements called nodes. We start at the root node (the
    yellow box labeled root in the binary trees figure below). There is a left and
    a right reference pointer (numbers 2 and 7, in our case ) and a data element (the
    number 1, in this case) within each node. As a tree grows, the depth of the node
    (the number of edges from the root to a given node) increases. Nodes 4, 5, 6,
    and 7 all have a depth of 3 in this diagram. The height of the node is the number
    of edges that occur from the node to the deepest leaf in the tree (as seen in
    the height 4 box in the following binary tree diagram). The height of the entire
    tree is equivalent to the height of the root node.
  prefs: []
  type: TYPE_NORMAL
- en: Binary trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Binary trees are an important data structure in computer science. They are
    often used for search, priority queues, and databases. They are efficient because
    they are easy to traverse in a concurrent fashion. Go has great concurrency primitives
    (which we''ll discuss in [Chapter 3](61b73482-0431-4b8f-a069-d647ac1c1b87.xhtml),
    *Understanding Concurrency*) that allow us to do this in a simple manner. Being
    able to use goroutines and channels to walk a binary tree can help speed up how
    we traverse a grouping of hierarchical data. A balanced binary tree can be seen
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b4cfd02e-78ce-43a6-a49c-7b5b7a863f90.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A couple of special binary trees are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Full binary tree**: Every node sans the leaf nodes has 2 child nodes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Complete binary tree**: A tree that is completely filled, sans the bottom
    layer. The bottom layer must be filled from left to right.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Perfect binary tree**: A complete binary tree in which all the nodes have
    two children and all the leaves of the tree are at the same level.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doubly linked list
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Doubly linked lists are also part of the Go standard library. This is a relatively
    large package, so for convenience, the function signatures for this package can
    be found in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: These function signatures (and their corresponding methods) can be found in
    the Go standard library at [https://golang.org/src/container/list/list.go](https://golang.org/src/container/list/list.go).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we will look at queues.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring queues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A queue is a pattern that is frequently used in computer science to implement
    a **first in first out** (**FIFO**) data buffer. The first thing to come into
    the queue is also the first thing to leave. This happens in an ordered fashion
    in order to process sorted data. Adding things to the queue is known as enqueueing
    the data into the queue, and removing it from the end of the queue is known as
    dequeuing. Queues are commonly used as a fixture in which data is stored and processed
    at another time.
  prefs: []
  type: TYPE_NORMAL
- en: Queues are beneficial because they don't have a fixed capacity. A new element
    can be added to the queue at any time, which makes a queue an ideal solution for
    asynchronous implementations such as a keyboard buffer or a printer queue. Queues
    are used in situations where tasks must be completed in the order that they were
    received, but when real-time occurs, it may not be possible based on extraneous
    factors.
  prefs: []
  type: TYPE_NORMAL
- en: Common queuing functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Very frequently, other small queue operations are added in order to make a
    queue a little more useful:'
  prefs: []
  type: TYPE_NORMAL
- en: '`isfull()` is commonly implemented to check whether or not a queue is full.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`isempty()` is commonly implemented to check whether or not a queue is empty.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`peek()` retrieves the element that is ready to be dequeued, but does not dequeue
    it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These functions are useful because a normal enqueueing operation goes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Check to see if the queue is full and return an error if the queue is full
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increment the rear pointer; return the next empty space
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the data element to the location in which the rear is being pointed at
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After these steps are completed, we can enqueue the next item in our queue.
  prefs: []
  type: TYPE_NORMAL
- en: 'Dequeuing is also just as simple as doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Check to see if the queue is empty and return an error if the queue is empty
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Access the data at the front of the queue
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increment the front pointer to the next available element
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After these steps are completed, we have dequeued this item from our queue.
  prefs: []
  type: TYPE_NORMAL
- en: Common queuing patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having an optimized queuing mechanism can be very helpful for writing performant
    Go code. Being able to push non-critical tasks to a queue allows you to complete
    the critical tasks faster. Another point to consider is that the queueing mechanism
    that you're using doesn't necessarily have to be a Go queue. You can push data
    to external mechanisms such as Kafka ([https://kafka.apache.org/](https://kafka.apache.org/))
    or RabbitMQ ([https://www.rabbitmq.com/](https://www.rabbitmq.com/)) in a distributed
    system. Managing your own messaging queue can become very operationally expensive,
    so having a separate message queuing system is commonplace today. We will cover
    this in more detail in [Chapter 14](74c0cef8-9628-4e31-abc3-9bd9aa52fafa.xhtml),
    *Clusters and Job Queues*, when we look at clustering and job queuing.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about benchmarking Go programs. We learned about
    how Big O notation considerations can help you design impactful data structures
    and algorithms around your problem set. We also learned about search and sorting
    algorithms, trees, and queues in order to make our data structures and algorithms
    most impactful to the problem at hand.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 3](61b73482-0431-4b8f-a069-d647ac1c1b87.xhtml), *Understanding Concurrency*,
    we'll learn about some of the most important Go constructs and how they can impact
    performance. Closures, channels, and goroutines can help us make some powerful
    design decisions with respect to both parallelism and concurrency.
  prefs: []
  type: TYPE_NORMAL
