- en: Designing Cost-Effective Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will discuss the pricing model of AWS Lambda and learn
    how to estimate this pricing based on the expected load. We will also cover some
    tips to optimize and reduce your serverless application cost while maintaining
    resiliency and availability. We will cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Lambda pricing model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimal memory size
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lambda cost and memory tracking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lambda pricing model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AWS Lambda shifted in the way Ops teams provision and manage their organization's infrastructure.
    Customers can now run their code without worrying about the underlying infrastructure
    while paying a low price. The first 1 million requests per month are free, and
    it's $0.20 per 1 million requests thereafter, so you might use Lambda's free tier
    indefinitely. However, intensive use cases and huge workload applications can
    unnecessarily cost you thousands of dollars if you don't pay extra attention to
    your function's resource usage and code optimization.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to keep your Lambda costs under control, you must understand how the
    Lambda pricing model works. There are three factors that determine the cost of
    your function:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Number of executions**: Number of invocations; you pay $0.0000002 per request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Allocated memory**: The amount of RAM provisioned for your function (ranges
    between 128 MB and 3,008 MB).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Execution time**: The duration is calculated from the time your code begins
    executing until it returns a response or otherwise terminates. The time is rounded
    up to the nearest 100 ms (Lambda is billed in 100 ms increments), and the maximum
    timeout you can set is 5 minutes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data transfer**: If your Lambda function initiates external data transfers,
    they will be charged at the EC2 data transfer rate ([https://aws.amazon.com/ec2/pricing](https://aws.amazon.com/ec2/pricing)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lambda cost calculator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you're familiar with the pricing model, let's see how you can calculate
    the cost of your Lambda function in advance.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the previous chapters, we allocated 128 MB of memory to the `FindAllMovies`
    function, and we set the execution timeout to be 3 seconds. Let''s suppose the
    function will be executed 10 times per second (25 million times in one month).
    Your charges would be calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Monthly compute charges**: The monthly compute price is $0.00001667 per GB/s
    and the free tier provides 400,000 GB/s. Total compute (seconds) = 25 M * (1s)
    = 25,000,000 seconds. Total compute (GB/s) = 25,000,000 * 128 MB/1,024 =3,125,000
    GB/s.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Total compute – Free tier compute = Monthly billable compute GB/s
  prefs: []
  type: TYPE_NORMAL
- en: 3,125,000 GB/s – 400,000 free tier GB/s = 2,725,000 GB/s
  prefs: []
  type: TYPE_NORMAL
- en: Monthly compute charges = 2,725,000 GB/s * $0.00001667 = $45.42
  prefs: []
  type: TYPE_NORMAL
- en: '**Monthly request charges**: The monthly request price is $0.20 per 1 million
    requests and the free tier provides 1 million requests per month.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Total requests – Free tier requests = Monthly billable requests
  prefs: []
  type: TYPE_NORMAL
- en: 25 M requests – 1 M free tier requests = 24 M monthly billable requests
  prefs: []
  type: TYPE_NORMAL
- en: Monthly request charges = 24 M * $0.2/M = $4.8
  prefs: []
  type: TYPE_NORMAL
- en: 'Hence, the total monthly charges is the sum of the compute and request charges,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Total charges = Compute charges + Request charges = $45.24 + $4.8 = $50.04
  prefs: []
  type: TYPE_NORMAL
- en: Optimal memory size
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we saw in the previous section, the amount of allocated RAM impacts billing.
    Furthermore, it impacts the amount of CPU and network bandwidth your function
    receives. Hence, you need to choose the optimal memory size. In order to find
    the right balance and optimal level of price and performance for your function,
    you must test your Lambda function with different memory settings and analyze
    the actual memory used by your function. Fortunately, AWS Lambda writes a log
    entry in the associated log group. The logs contains, for each request, the amount
    of memory allocated and used by the function. The following is an example of a
    log output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1b845000-05a4-4f9e-a8c3-3ecd17d8b512.png)'
  prefs: []
  type: TYPE_IMG
- en: 'By comparing the Memory Size and Max Memory Used fields, you can determine
    whether your function needs more memory or if you over-provisioned your function''s
    memory size. In case your function needs more memory, you can always give it more
    memory from the Basic settings section, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bdbb004a-7775-4eea-ad7a-21666e517aa3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on Save and then invoke the function once again. In the log''s output,
    you will notice that the memory size impacts the execution time:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d5662e8d-fb13-47ff-b4c9-0ebdbfdf92d7.png)'
  prefs: []
  type: TYPE_IMG
- en: While increasing the function memory settings will provide substantial performance
    gains. The cost will increase linearly as the memory settings increase in Lambda.
    Similarly, decreasing the function memory setting might help reduce costs, but
    this will also increase your execution time, and, in the worst case scenario,
    lead to timeouts or memory exceeded errors.
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning the smallest memory settings to your Lambda function won't always
    provide the lowest total cost. The function will fail and timeout due to insufficient
    memory. Also, it might take longer time to complete. By consequence, you will
    pay more.
  prefs: []
  type: TYPE_NORMAL
- en: Code optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we saw how testing your function at scale with different
    memory settings results in more CPU capacity allocated, which could impact your
    Lambda function's performance and cost. However, before optimizing the resource
    usage, you need to optimize your function's code first to help reduce the amount
    of memory and CPU it needs in order to be executed. Contrary to traditional applications,
    AWS Lambda manages and patches the infrastructure for you, which allows developers
    to focus on writing good quality, efficient, and world-class code that executes
    fast.
  prefs: []
  type: TYPE_NORMAL
- en: Allocating more resources to your function can result in faster executions until
    a certain threshold, where adding more memory will no longer provide better performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some points you should keep in mind when designing your function
    with AWS Lambda in a cost-effective manner:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Warm containers can be used for certain requests. Having this knowledge in
    mind, we can improve the Lambda function''s performance by implementing the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid the reinitialization of variables on every invocation by using global
    variables and the singleton pattern.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep alive and reuse databases and HTTP connections that were established during
    a previous invocation. In Go, you can use the `init` function to set up the required
    state and run one-time computations when your function handler is loaded.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Design your architecture to be asynchronous; a decoupled component might take
    less compute time to finish its work than a tightly coupled component. Also, avoid
    spending CPU cycles awaiting responses to synchronous requests.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use monitoring and debugging tools like AWS X-Ray to analyze and troubleshoot performance
    bottlenecks, latency spikes, and other issues that impact the performance of your
    Lambda application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set limits using concurrency reservation to prevent unlimited autoscaling, cold
    starts, and to protect your downstream services. You can also throttle and limit
    the number of executions by placing a **Simple Queue Service** (**SQS**) between
    the Lambda trigger and the function to adjust how frequently your Lambda function
    should be triggered.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lambda cost and memory tracking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The key behind designing cost-effective serverless applications in AWS Lambda
    is by monitoring your cost and resource usage. Unfortunately, CloudWatch doesn''t
    provide out of the box metrics about the resource usage or the Lambda function
    cost. Luckily, for each execution, the Lambda function writes an execution log
    to CloudWatch that looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The preceding log shows the memory that's allocated and used for a given request.
    Those values can be extracted with a simple CloudWatch log metric filter. This
    feature enables you to search for specific keywords in your logs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the AWS CloudWatch console and select Log Groups from the navigation pane.
    Next, search for the log group associated with your Lambda function. It should
    be named as follows: `/aws/lambda/FUNCTION_NAME`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8b313ac1-baaa-4996-94f5-ea1ac1f5704e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, click on the Create Metric Filter button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/72633fb3-bd3c-49aa-873c-703c1beeabb4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Define a metric filter pattern that parses space-delimited terms. The metric
    filter pattern has to specify the fields with a name, separated by commas, with
    the entire pattern enclosed in square brackets, for example, `[a,b,c]`. Then,
    click on Test Pattern to test the results of your filter pattern against the existing
    data in the logs. The following records will be printed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6688061e-2169-4bd6-bea3-63ae62585a04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If you don''t know the number of fields that you have, you can use an ellipsis
    enclosed in square brackets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e7294961-4c0c-4ea7-bffa-a8b4f0677295.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Column `$13` will be storing the memory allocated to the function and `$18`
    represents the actual memory used. Next, click on Assign Metric to create a metric
    for the memory that''s been allocated:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5e0d8104-b632-4f28-bc4f-5e7f8dc59dd7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on the Create Filter button to save it. You should now see the newly
    created filter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d0585e8c-c28b-4ae7-97e6-aa7019760560.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Apply the same steps to create another filter for the memory usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2611714f-cc6d-4e29-906a-2dfe92ab57ed.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once the two filters are defined, make sure your Lambda function is running
    and wait a few seconds while the function is populating the new CloudWatch metrics
    with some values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f83d8de0-1321-49f5-9792-2b5a75a4041c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Back in CloudWatch, create a new chart based on the two metrics that we created
    previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ab2a597f-8820-46e2-a0f7-830434ab4c0c.png)'
  prefs: []
  type: TYPE_IMG
- en: You can take this further and create a near real-time CloudWatch alarm if the
    memory used exceeds a certain threshold (for instance, 80% relative to the memory
    that you allocated). Moreover, it's important to keep an eye on the function's
    duration. You can follow the same procedure that was described in this section
    to extract the billed duration from Lambda execution logs and set up an alarm
    based on the extracted value so that you're notified if your function is taking
    a suspiciously long time to complete.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Getting started with AWS Lambda is easy – you don't have to provision and manage
    any underlying infrastructure and it's very cheap to get something useful up and
    running in a few seconds. Plus, a great advantage of AWS Lambda over EC2 is that
    you don't have to pay for idle resources. This is extremely powerful, but it's
    also one of Lambda's biggest risks. It's very common to forget about cost during
    development, but once you start running heavy workloads and multiple functions
    in production, cost can be significant. Hence, it's very important to keep track
    of Lambda cost and usage before this becomes an issue.
  prefs: []
  type: TYPE_NORMAL
- en: The final chapter will introduce the concept of **Infrastructure as Code** (**IaC**)
    to help you design and deploy your N-tier serverless application in an automated
    way, in order to avoid human errors and repeatable tasks.
  prefs: []
  type: TYPE_NORMAL
