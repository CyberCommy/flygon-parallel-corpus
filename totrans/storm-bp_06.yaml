- en: Chapter 6. Artificial Intelligence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In earlier chapters, we saw a pattern that combined real-time analytics using
    Storm with batch processing using Hadoop. In this chapter, we will go in the other
    direction. We will incorporate Storm into an operational system that must respond
    in real time to end user queries.
  prefs: []
  type: TYPE_NORMAL
- en: Typical applications of Storm focus on a never-ending stream of data. The data
    is often queued and processed as fast as possible by persistent topologies. The
    system includes a queue to accommodate varying amounts of load. At times of light
    load, the queue is empty. During heavy load, the queue will persist the data for
    eventual processing.
  prefs: []
  type: TYPE_NORMAL
- en: Even the untrained eye will recognize that such a system does not provide true
    real-time data processing. Storm monitors tuple timeouts, but it is focused on
    the processing time of tuple(s) after the spout emits the data.
  prefs: []
  type: TYPE_NORMAL
- en: To support real-time scenarios more completely, timeouts and **Service Level
    Agreements** (**SLA**) must be monitored from the reception of the data to the
    delivery of the response. These days, requests are often received via an HTTP-based
    API and response time SLAs must be subsecond.
  prefs: []
  type: TYPE_NORMAL
- en: HTTP is a synchronous protocol. It often introduces an asynchronous mechanism
    like a queue, complicates the system, and introduces added latency. For this reason,
    when exposing features and functions via HTTP, we typically prefer synchronous
    integrations with components involved.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will explore Storm's place in an architecture that exposes
    a web services API. Specifically, we will construct the world's best tic-tac-toe
    **Artificial Intelligence** (**AI**) system. Our system will include both synchronous
    and asynchronous subsystems. The asynchronous portion of the system will work
    continually, exploring the best options for game states. The synchronous component
    exposes a web services interface that, given a game state, returns the best move
    possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Recursion in Storm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Distributed Remote Procedure Call (DRPC)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Distributed Read-before-write paradigm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing for our use case
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The "hello world" of the artificial intelligence world is tic-tac-toe. Sticking
    to the tradition, we will also use this as our subject game, although the architecture
    and approach extend well beyond this simple example (for example, Global Thermonuclear
    War; for other use cases, refer to John Badham's *War Games*).
  prefs: []
  type: TYPE_NORMAL
- en: Tic-tac-toe is a two-player game of Xes and Os. The board is a 3 x 3 grid. One
    player has the symbol O and the other has the symbol X, and the play alternates.
    On a turn, a player places their symbol in any open cell in the grid. If by placing
    their symbol, it completes a horizontal, vertical, or diagonal line of three contiguous
    symbols, that player wins. If all cells are filled without forming a line of three,
    then the game is a tie.
  prefs: []
  type: TYPE_NORMAL
- en: A common approach to developing Artificial Intelligence programs for games with
    alternating turns is to explore the game tree recursively searching for the game
    state that evaluates best for the current player (or worse for the opposition).
    A game tree is a tree structure whose nodes are game states. A node's immediate
    children are game states that can be achieved by making a legal move from that
    node's game state.
  prefs: []
  type: TYPE_NORMAL
- en: 'A sample game tree for tic-tac-toe is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Designing for our use case](img/8294OS_06_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The simplest of algorithms that traverses a game tree searching for the best
    move is the **Minimax** algorithm. The algorithm scores each board recursively
    and returns the best score found. For this algorithm, we assume that a good score
    for the opposition is a bad score for the current player. Thus, the algorithm
    actually alternates between maximizing and minimizing the score of the current
    board. The Minimax algorithm can be summarized with the following pseudocode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: A client invokes the algorithm with a game state, a depth, and a Boolean variable
    that indicates whether or not the algorithm should seek to maximize or minimize
    the score. In our use case, the game state is fully encapsulated by the board,
    which is a 3 x 3 grid partially filled with Xes and Os.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm is recursive. The first few lines of the code are the base case.
    This ensures that the algorithm does not recurse endlessly. This conditions on
    the depth variable. In a game of alternating turns, the depth indicates how many
    turns the algorithm should explore.
  prefs: []
  type: TYPE_NORMAL
- en: In our use case, the Storm topology need not track the depth. We will let the
    Storm topology explore endlessly (or until there are no new boards returned from
    the `move` method).
  prefs: []
  type: TYPE_NORMAL
- en: Typically, each player is given a set amount of time and must make his or her
    move within the allotted time. Since we will more likely have antsy human players
    competing against the AI, let's assume the system needs to respond in fewer than
    200 milliseconds.
  prefs: []
  type: TYPE_NORMAL
- en: After the algorithm checks for the base case, it calls the `move()` method,
    which returns boards for all possible moves. The algorithm then cycles through
    all possible child boards. If maximizing, the algorithm finds the child board
    that leads to the highest score. If minimizing, the algorithm finds the board
    that leads to the least score.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **Negamax** algorithm accomplishes the same more succinctly by alternating
    the sign of the score. Additionally, in a real-world scenario, we might apply
    Alpha-Beta pruning, which attempts to trim the branches of the tree that are explored.
    The algorithm only considers branches that fall within a threshold. In our use
    case, this is not necessary because the search space is small enough to explore
    in its entirety.
  prefs: []
  type: TYPE_NORMAL
- en: In our simple use case, it is possible to enumerate the entire game tree. In
    more complicated games such as Chess, the game tree is impossible to enumerate.
    In an extreme case such as Go, experts have calculated the number of legal boards
    to be in excess of 2 x 10170.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal of the Minimax algorithm is to traverse the game tree and assign a
    score to each node. In our Storm topology, which is not beholden to any SLA, the
    score of any non-leaf node is simply the maximum (or minimum) of its descendants.
    For a leaf node, we must interpret the game state into a corresponding score.
    In our simple use case, there are three possible outcomes: we win, our opponent
    wins, or the game is a tie.'
  prefs: []
  type: TYPE_NORMAL
- en: In our synchronous system, however, we might very well run out of time before
    we reach a leaf node. In this case, we need to calculate the score from the current
    state of the board. Scoring heuristics are often the most difficult aspect of
    developing an AI application.
  prefs: []
  type: TYPE_NORMAL
- en: 'For our simple use case, we will compute the score for any board by considering
    the lines in the grid. There are eight lines to consider: three horizontal, three
    vertical, and two diagonals. Each line contributes to the score according to the
    following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Status | Score |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Three in a row for the current player | +1000 |'
  prefs: []
  type: TYPE_TB
- en: '| Two in a row for the current player | +10 |'
  prefs: []
  type: TYPE_TB
- en: '| One in a row for current player | +1 |'
  prefs: []
  type: TYPE_TB
- en: '| Three in a row for an opponent | -1000 |'
  prefs: []
  type: TYPE_TB
- en: '| Two in a row for an opponent | -10 |'
  prefs: []
  type: TYPE_TB
- en: '| One in a row for an opponent | -1 |'
  prefs: []
  type: TYPE_TB
- en: The preceding table applies only if the remaining cells in the line are empty.
    Although there are improvements to the preceding heuristic, it suffices for this
    example. And, since we expect Storm to work continually on our game tree, we hope
    not to rely on the heuristic all that much. Instead, we would rely directly on
    the minimum (or maximum) of the leaf scores, which will always be a win (+1000),
    loss (-1000), or draw (0).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, armed with an approach, our algorithm and a scoring function, we are
    able to move on to the architecture and design.
  prefs: []
  type: TYPE_NORMAL
- en: Establishing the architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Examining the preceding algorithm, there are a number of interesting design
    and architectural considerations, especially given the current state of Storm.
    The algorithm requires recursion. We also need a means of synchronously processing
    requests. Recursion within Storm is an evolving topic, and while Storm provides
    a means of interacting with topologies synchronously, when combined with a demand
    for recursion, this presents some unique and interesting challenges.
  prefs: []
  type: TYPE_NORMAL
- en: Examining the design challenges
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Originally, native Storm provided a mechanism to service asynchronous procedure
    calls. The feature is **Distributed Remote Procedure Call** (**DRPC**). DRPC allowed
    a client to make requests of a topology by submitting data directly to the topology.
    With DRPC, a simple RPC client acts as a spout.
  prefs: []
  type: TYPE_NORMAL
- en: With the advent of Trident, DRPC was deprecated in native Storm and is now officially
    supported only in Trident.
  prefs: []
  type: TYPE_NORMAL
- en: Although there has been some exploratory work into recursive/nonlinear DRPC,
    which is what we would require here, it is not a mainstream functionality ([https://groups.google.com/forum/#!topic/storm-user/hk3opTiv3Kc](https://groups.google.com/forum/#!topic/storm-user/hk3opTiv3Kc)).
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, that work would rely on the deprecated classes within the native
    Storm. Thus, we need to find alternative means to create a recursive structure
    without relying on Storm.
  prefs: []
  type: TYPE_NORMAL
- en: Once we find a construct to implement the recursion, we need to be able to invoke
    the same functionality synchronously. Seeking to leverage what Storm provides
    means incorporating DRPC calls into our architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the recursion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If we map our algorithm directly to Storm constructs, we would expect a means
    of allowing a stream to feed back data into itself. We can imagine a topology
    similar to the following logical data flow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Implementing the recursion](img/8294OS_06_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The `BoardSpout` function emits a board (for example, the 3 x 3 array) in the
    `currentBoard` field with a second field named `parents` that will be used to
    store all parent nodes. The `parents` field will be empty initially.
  prefs: []
  type: TYPE_NORMAL
- en: The `isLeaf` filter decides whether this is an end state (for example, win,
    loss, or draw). If the `currentBoard` field is not an end state, the `GenerateBoards`
    function emits all the new boards, replacing the value of the `currentBoard` field
    with the child board and adding the `currentBoard` field to the list of nodes
    in the `parents` field. The `GenerateBoards` function could emit the tuple back
    through the spout or directly into the `isLeaf` filter, bypassing the spout.
  prefs: []
  type: TYPE_NORMAL
- en: If the `isLeaf` filter determines that this is an end state, we need to score
    the `currentBoard` field and then update all the parents to reflect that new score.
    The `ScoreFunction` computes the score of the board and persists that to the `GameTree
    State`.
  prefs: []
  type: TYPE_NORMAL
- en: To update the parents, we iterate over each of the parents and query the current
    maximum (or minimum) for that node. If the child's score is a new maximum (or
    minimum), then we would persist the new values.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is only a logical data flow. Constructing such a topology is not only impossible,
    but also not recommended for reasons described in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: You can already see that this data flow is not as straightforward as our pseudocode.
    There are a few constraints within Trident and Storm that force us to introduce
    additional complexities, and furthermore, not all the operations articulated in
    the data flow are available in Storm/Trident. Let's examine this data flow more
    closely.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing the function's return values
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Firstly, notice that we are forced to maintain our own call stack in the form
    of a list of parents because Storm and Trident do not have any mechanisms to access
    the results of functions downstream in the topology. In classic recursion, the
    results of the recursive method call are immediately available within the function
    and can be incorporated into the results of that method. Thus, the preceding data
    flow resembles a more iterative approach to the problem.
  prefs: []
  type: TYPE_NORMAL
- en: Immutable tuple field values
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Secondly, in the preceding data flow, we invoke a magical ability to replace
    the value of a field. We do that in the recursive emit from the `GenerateBoards`
    function. Replacing the `currentBoard` field with the new board is not possible.
    Additionally, adding the `currentBoard` field to the parents list would require
    updating the value of the `parents` field. In Trident, tuples are immutable.
  prefs: []
  type: TYPE_NORMAL
- en: Upfront field declaration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To get around tuple immutability, we could always add additional fields to the
    tuple—one for each layer of the recursion—but Trident requires that all fields
    be declared prior to deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Tuple acknowledgement in recursion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have additional problems when we consider tuple acknowledgement in this data
    flow. At what point do we acknowledge the initial tuple that triggered the processing?
    From a logical data flow perspective, that initial tuple shouldn't be acknowledged
    until all the children for that node have been considered and the game tree state
    reflects those scores. Surely, however, the processing time to compute large subsections
    of the game tree for any non-trivial game would most likely exceed any tuple timeouts.
  prefs: []
  type: TYPE_NORMAL
- en: Output to multiple streams
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another issue with topology is the multiple paths that emit from the `isLeaf`
    filter. Presently, there is no way to output to multiple streams within Trident.
    The enhancement can be found at [https://issues.apache.org/jira/browse/STORM-68](https://issues.apache.org/jira/browse/STORM-68).
  prefs: []
  type: TYPE_NORMAL
- en: As we will see, you can work around this by forking the stream and affecting
    the decision as filters on both streams.
  prefs: []
  type: TYPE_NORMAL
- en: Read-before-write
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Lastly, because we do not have access to the return values, updating the parent
    scores requires a read-before-write paradigm. This is an anti-pattern in any distributed
    system. The following sequence diagram demonstrates the issues that arise in read-before-write
    constructs in the absence of locking mechanisms:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Read-before-write](img/8294OS_06_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding diagram, there are two threads operating independently. In
    our use case, this occurs when multiple children complete simultaneously and attempt
    to resolve the maximum score of a parent node at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: The first thread is resolving a child score of **7**. The second thread is resolving
    a child score of **15**. They are both resolving the same node. At the end of
    the process, the new maximum should be **15**, but because there was no coordination
    between the threads, the maximum score becomes **7**.
  prefs: []
  type: TYPE_NORMAL
- en: The first thread reads the current maximum score for the node, which returns
    **5**. Then, the second thread reads from the state and also receives **5**. Both
    threads compare the current maximum to their respective child scores and update
    the maximum with new values. Since the second thread's update takes place after
    the first, the result is an incorrect maximum value for the parent node.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will see how to properly address the preceding constraints
    to produce a functional system.
  prefs: []
  type: TYPE_NORMAL
- en: Solving the challenges
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To accommodate the constraints outlined in the preceding section, we will break
    the topology into two parts. The first topology will perform the actual recursion.
    The second topology will resolve the scores. This is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Solving the challenges](img/8294OS_06_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The system is broken down into two topologies: the **Recursion Topology** and
    the **Scoring Topology** . The **Recursion Topology** attempts to enumerate all
    the boards in the system. The Scoring Topology attempts to score all of the boards
    enumerated by the Recursion Topology.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To affect the recursion, we introduce two queues in the system. The first queue,
    **Work Queue**, contains a list of nodes that we need to visit. The Recursion
    Topology consumes from that queue via the **Work Spout**. If the node is not a
    leaf, the topology queues the child boards. The format of the messages on the
    Work Queue is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Each `board` is a 3 x 3 array. The `parents` array contains all of the parent
    boards.
  prefs: []
  type: TYPE_NORMAL
- en: If the node is a leaf node, the board is queued on the **Scoring Queue** using
    the same message format. The Scoring Topology reads from the Scoring Queue via
    the **Scoring Spout**. The **Scoring Function** scores the node. The board is
    necessarily a leaf node because that is the only type of node queued for scoring.
    Then, the Scoring Function emits a tuple for the current node and each parent.
  prefs: []
  type: TYPE_NORMAL
- en: We then need to update the state. The query-and-write paradigms are encapsulated
    in a single function because of the race condition we outlined previously. In
    the following design, we will demonstrate how we accommodate the race condition
    introduced by read-before-write.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, before we move on to the design, notice that because we introduced
    queues, we clearly delineated lines along which we can acknowledge tuples. In
    the first topology, a tuple is acknowledged when either of the cases is true:'
  prefs: []
  type: TYPE_NORMAL
- en: The topology has enumerated and queued the descendants of a node
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The topology has queued the node for scoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the second topology, a tuple is acknowledged when the current board and all
    of its parents have been updated to reflect the value in the leaf node.
  prefs: []
  type: TYPE_NORMAL
- en: Also notice that we do not need to introduce new fields or mutate existing fields
    during processing. The only fields used in the first topology are `board` and
    `parents`. The second topology is the same but adds a single additional field
    to capture the score.
  prefs: []
  type: TYPE_NORMAL
- en: Notice also that we forked the stream coming out of the Work Spout. This was
    done to accommodate the fact that we cannot emit to multiple streams from a single
    function. Instead, both `GenerateBoards` and `IsEndGame` must determine whether
    the game has ended and react accordingly. In `GenerateBoards`, the tuple is filtered
    to avoid an infinite recursion. In `IsEndGame`, the tuple is passed along for
    scoring. When functions are able to emit to different streams, we will be able
    to collapse this function into a single "decision" filter that choses which stream
    a tuple should proceed with.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's now delve into the details of the implementation. For example purposes,
    the following code assumes the topology is running locally. We use an in-memory
    queue instead of a persistent queue, and a hash map as our storage mechanism.
    In a real production implementation, we would most likely use a durable queuing
    system such as Kafka and a distributed storage mechanism such as Cassandra.
  prefs: []
  type: TYPE_NORMAL
- en: The data model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will look at each of the topologies in depth, but first, let''s have a look
    at the data model. To simplify things, we''ve encapsulated the game logic and
    the data model into two classes: `Board` and `GameState`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a listing of the `Board` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The `Board` class provides three main functions. The `Board` class encapsulates
    the board itself in a multidimensional string array as a member variable. It then
    provides functions that will generate the child boards (for example, `nextBoards()`),
    determines whether the game has ended (for example, `isEndState()`), and finally,
    provides a method to compute the score of the board when a player is provided
    (for example, `nextBoards(player)`, and its supporting methods).
  prefs: []
  type: TYPE_NORMAL
- en: Notice also that the `Board` class provides a `toKey()` method. This key uniquely
    represents the board and is what we will use as a unique identifier when accessing
    our persistence mechanism. In this case, the unique identifier is just a concatenation
    of the values from the board grid.
  prefs: []
  type: TYPE_NORMAL
- en: 'To completely represent the game state, we also need to know which player is
    currently taking their turn. Thus, we have one higher-level object that encapsulates
    the board and the current player. This is the `GameState` object whose listing
    is shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: There is nothing terribly surprising in this class except for the `history`
    variable. This member variable tracks all the previous board states for this path
    through the game tree. This is the breadcrumb trail required to update the game
    tree with the score from the leaf node.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we represent the player in the game with the `Player` class, which
    is shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Examining the recursive topology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the data model outlined previously, we can create a topology that recurses
    down the game tree. In our implementation, this is the `RecursiveTopology` class.
    The code for the topology is shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The first section configures the in-memory queues for work and scoring. The
    input stream is configured from a single spout working off of the Work Queue.
    This queue is seeded with the initial game state.
  prefs: []
  type: TYPE_NORMAL
- en: The stream is then forked. The first prong of the fork is filtered for only
    endgame boards, which are then passed along to the Scoring Queue. The second prong
    of the fork generates new boards and queues the descendants.
  prefs: []
  type: TYPE_NORMAL
- en: The queue interaction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this example implementation, we used an in-memory queue. In a real production
    system, we would rely on the Kafka spout. The listing for the `LocalQueueEmitter`
    class is shown in the following code snippet. Note that queues are instances of
    a `BlockingQueue` instance within a map, which links a queue name to the `BlockingQueue`
    instance. This is a handy class when testing topologies that use a single queue
    as the input and output (that is, recursive topologies):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The main method in this class is the `emitBatch` implementation for the `Emitter`
    interface. This simply reads from the queue while it has data and while the maximum
    batch size has not been reached.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, note that the class provides an `enqueue()` method. The `enqueue()` method
    is used by our `LocalQueueFunction` class to complete the recursion. The listing
    for the `LocalQueueFunction` class is shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Note that the function is actually instantiated with the `emitter` function
    used by the spout. This allows the function to enqueue data directly into the
    spout. Again, this construct is useful when developing recursive topologies, but
    real production topologies would most likely use durable storage. Without durable
    storage, there is a chance for data loss since tuples are acknowledged before
    the processing (recursion) is complete.
  prefs: []
  type: TYPE_NORMAL
- en: Functions and filters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, we turn our attention to the functions and filters specific to this topology.
    The first is a simple filter used to filter out the endgame boards. The code for
    the `IsEndGame` filter is shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that this class is not necessary if Trident had support for emitting tuples
    to different streams from a single function. In the following listing for the
    `IsEndGame` function, it performs the same check/filter function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The function adds the current board to the history list, and then queues a new
    `GameState` object, with the child board position.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Alternatively, we could have implemented `IsEndGame` as a function, adding another
    field to capture the results; however, it was more constructive to use this as
    an example to motivate having multiple stream capabilities within functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a sample output from the Recursive Topology:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Examining the Scoring Topology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Scoring Topology is more straightforward in that it is linear. The complicated
    aspect is the state's update to avoid the read-before-write race condition.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for the topology is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'There are only two functions: `ScoreFunction` and `ScoreUpdater`. The `ScoreFunction`
    scores the current board and emits that score for each board in the history.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The listing for `ScoreFunction` is shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The function simply scores the current board and emits a tuple for the current
    board. Then, the function loops through the player emitting tuples for each board,
    swapping the player with each turn.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, we have the `ScoreUpdater` function. Again, we kept it simple for the
    example. The following is the code for this class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Addressing read-before-write
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Notice in the preceding code that we used a mutex to sequence the updates to
    scores, thereby eliminating the race condition mentioned earlier. This only works
    because we are operating in a single/local JVM. When this topology is deployed
    to a real cluster, this will not work; however, we do have a few options to address
    the issue.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed locking
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As we see in other chapters, it is possible to leverage a distributed locking
    mechanism such as ZooKeeper. In this approach, ZooKeeper provides a mechanism
    for maintaining a mutex across multiple hosts. This is certainly a viable approach,
    but distributed locks come at a cost to performance. Every operation incurs overhead
    to accommodate what in reality might be an infrequent occurrence.
  prefs: []
  type: TYPE_NORMAL
- en: Retry when stale
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Another pattern that might be useful is the *retry when stale* approach. In
    this scenario, along with the data, we also pull back a version number, timestamp,
    or checksum. Then, we perform a conditional update, including the version/timestamp/checksum
    information in a clause that will fail the update if that metadata has changed
    (for example, adding the `WHERE` clause to the `UPDATE` statement in the SQL/CQL
    paradigm). If the metadata has changed, it indicates that the value on which we
    based our decision is now stale and we should reselect the data.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, there are trade-offs between these approaches. With retries, in the
    extreme case where there is a tremendous amount of contention, a thread may have
    to be retried a number of times in order to commit an update. However, with distributed
    locking, you may run into timeout issues if a single thread gets stuck, loses
    communication with the server, or fails entirely.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Recently, there have been advances in this area. I suggest that you should
    look at Paxos and Cassandra''s use of that algorithm to affect conditional updates
    at the following URLs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf](http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[http://www.datastax.com/dev/blog/lightweight-transactions-in-cassandra-2-0](http://www.datastax.com/dev/blog/lightweight-transactions-in-cassandra-2-0)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In our simple case, we are extremely lucky, and we can actually incorporate
    the logic into the update directly. Consider the following SQL statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: As we have resolved our read-before-write issues, the topology is suitable to
    score all of the boards queued by the Recursive Topology. The topology assigns
    a value to the endgame state and propagates that value up the game tree, persisting
    the proper score with the respective game state. In a real production system,
    we would access that state from our DRPC topology to be able to look ahead multiple
    turns.
  prefs: []
  type: TYPE_NORMAL
- en: Executing the topology
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The following is sample output for the Scoring Topology:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: It is resolving a tie-game leaf node, shown at the beginning of the listing.
    You can see that the value propagates through the parents after that, updating
    the current score for those nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Enumerating the game tree
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The final result of combining the Recursive Topology with the Scoring Topology
    is a set of topologies working together continually to enumerate as much of the
    problem space as possible. Most likely, this process would be combined with heuristics
    that would only store key nodes. Also, we would prune the search space using heuristics
    to reduce the number of boards we need to evaluate. Regardless, however, we will
    need to interact with the system through an interface in order to determine the
    best move, given a current game state. This is what we will tackle in the next
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed Remote Procedure Call (DRPC)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have a functioning Recursive Topology that will continually seek
    to compute the entire game tree, let's take a look at a synchronous invocation.
    The DRPC capabilities that Storm provided were ported to Trident and deprecated
    in Storm. This was the major motivation for using Trident in this example.
  prefs: []
  type: TYPE_NORMAL
- en: 'With DRPC, you construct a topology much like you would in the asynchronous
    case. The following diagram show our DRPC topology:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Distributed Remote Procedure Call (DRPC)](img/8294OS_06_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The DRPC client acts as a spout. The output of the client passes through the
    `ArgsFunction`, which normalizes the input so we can reuse the existing functions:
    `GenerateBoards` and `ScoreFunction`. Then, we use `.groupBy(state)` and aggregate
    the results using an `Aggregator` class''s `FindBestMove`. We then perform a simple
    projection to return only the best move to the client.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You might also want to take a look at Spring Breeze, which allows you to wire
    POJOs together into a Storm topology. This is another approach to gain reuse,
    because those same POJOs could be exposed via web services without introducing
    DRPC.
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/internet-research-network/breeze](https://github.com/internet-research-network/breeze)'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will have a look at the code for the topology:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: For this example, we use a `LocalDRPC` client. This is passed in as an argument
    to the `newDRPCStream` call, which is the crux of a DRPC topology. From there
    on, the topology functions as a normal topology.
  prefs: []
  type: TYPE_NORMAL
- en: You can see the actual remote procedure call takes place via the `client.execute()`
    method. Presently, the signature for that method takes and returns only strings.
    There is an outstanding enhancement request to change this signature. You can
    find that enhancement at [https://issues.apache.org/jira/browse/STORM-42](https://issues.apache.org/jira/browse/STORM-42).
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the current signature only accepts strings, we need to marshal the input.
    This takes place in the `ArgsFunction` as shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The second parameter to the call we made to `client.execute()` was a string
    that contained our input. In this case, you can see it in the topology code that
    we passed in the key for the board. This was the 3 x 3 grid, with the cells concatenated
    as a string. In order to marshal that string into a board, we added a constructor
    to the `Board` class that parses the string into a board as shown in the following
    code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The next two functions applied in the DRPC topology demonstrate the reuse that
    you can achieve by leveraging DRPC as a synchronous interface. In this case, we
    are leveraging the functions in isolation, but you can imagine that you could
    reuse more complicated data flows as well.
  prefs: []
  type: TYPE_NORMAL
- en: Using the `GenerateBoard` function, we emit all the children for the current
    board. Then, the `ScoreFunction` scores each of those boards.
  prefs: []
  type: TYPE_NORMAL
- en: 'As it was in the Scoring Topology, the output of the `ScoreFunction` is a triple
    of `board`, `score`, and `player`. These are the scores for each of the children
    boards. To determine our next best move, we simply need to maximize (or minimize)
    the value. This can be done using a simple `Aggregator`. We created an aggregating
    function named `FindBestMove` as shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This aggregation extends `BaseAggregator`, which is a Java generic. In this
    case, we want to emit the best possible move, combined with its score. Thus, we
    parameterize the `BaseAggregator` class with a `BestMove` class, which is simply
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: If you recall, for aggregation, Trident initially calls the `init()` method,
    which returns the initial aggregate value. In our case, we simply seed the `BestMove`
    class with the worst move. Note that the score variable of the `BestMove` class
    is seeded with the absolute minimum value. Then, Trident makes subsequent calls
    to the `aggregate()` method, which allows the function to incorporate the tuple
    into the aggregate value. An aggregation can also emit values here, but since
    we are only concerned with the final best move, we do not emit anything form the
    `aggregate()` method. Finally, Trident calls the `complete()` method when all
    values of tuples have been aggregated. It is in this method that we emit the final
    best move.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the output from the topology:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: In this example, it is O's turn, and he or she has a scoring opportunity. You
    can see that the topology correctly identifies the scoring opportunity and returns
    it as the best possible move (with the appropriate score value).
  prefs: []
  type: TYPE_NORMAL
- en: Remote deployment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'What we showed is local invocation of a DRPC topology. To invoke a remote topology,
    you need to launch the DRPC server. You do this, just like any other Storm service,
    by executing the Storm script with `drpc` as the parameter as shown in the following
    code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The Storm cluster will connect to the DRPC server to receive invocations. In
    order for it to do that, it needs to know the location(s) of the DRPC servers.
    These are specified in the `storm.yaml` file as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'With the servers configured and the DRPC server started, the topology is submitted
    like any other topology, and the DRPC client can be used from any Java application
    that requires large-scale synchronous distributed processing. To switch from a
    local DRPC client to a remote, the only line that needs to change is the instantiation
    of the DRPC client. Instead of instantiating a local DRPC client, you need to
    use the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The parameters specify the host and port of the DRPC server and should match
    the configuration in the YAML file.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we took on an AI use case. There are many problems within that
    domain that leverage tree and graph data structures, and the algorithms most appropriate
    for those data structures are often recursive. To demonstrate how those algorithms
    translate to Storm, we took the Minimax algorithm and implemented it using Storm's
    constructs.
  prefs: []
  type: TYPE_NORMAL
- en: Along the way, we noted a few constraints within Storm that make it more complicated
    than expected, and we saw patterns and approaches that work around those constraints
    to produce a working/scalable system.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we introduced DRPC. DRPC can be used to expose a synchronous interface
    to clients. DRPC also allows the design to reuse code and data flows between synchronous
    and asynchronous interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: Combining synchronous and asynchronous topologies, with shared state, is a powerful
    pattern not only for AI applications, but also for analytics. Often, new data
    arrives in the background continuously, but users interrogate that data through
    synchronous interfaces. When you combine DRPC with the Trident state capabilities
    covered in other chapters, you should be able to build a system that can accommodate
    the real-time analytics' use cases.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we integrate Storm with a non-transactional real-time analytics
    system, Druid. We will also look deeper into distributed state management with
    Trident and ZooKeeper.
  prefs: []
  type: TYPE_NORMAL
