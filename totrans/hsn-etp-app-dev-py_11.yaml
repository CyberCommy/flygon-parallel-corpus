- en: Taking the Microservices Approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this book, we have learned about how to develop an enterprise-grade
    application and how to mature our processes so that the application we deliver
    meets our standards of quality and provides a robust and resilient experience
    to its users. In this chapter, we will take a look at a new paradigm for developing
    applications, where the application is not a single product but rather a combination
    of multiple products interacting with each other to provide a unified experience.
  prefs: []
  type: TYPE_NORMAL
- en: Over recent years, development scenarios have changed rapidly. Application development
    has moved from developing large monoliths to developing smaller services, all
    of which interact with each other to provide the desired result to the user. This
    change has come to meet the demand for faster shipping of projects in order to
    increase the ability to add new features and improve the scalability of the application.
  prefs: []
  type: TYPE_NORMAL
- en: Over the course of this chapter, we will take a look at this new paradigm of
    application development where teams have become smaller and the ability to ship
    new features inside an application at an ever-reducing cost has become the new
    standard. This paradigm, known as the microservices development approach, has
    radically changed the way in which application development cycles work, and has
    also led to the current trend toward techniques related to DevOps, continuous
    integration, and deployments.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you progress through this chapter, you will learn about the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Moving toward the microservices development approach
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: API-driven communication between services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building robust microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling user-server interaction in microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asynchronous communication between microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The code listings in this book can be found under `chapter11` directory at [https://github.com/PacktPublishing/Hands-On-Enterprise-Application-Development-with-Python.](https://github.com/PacktPublishing/Hands-On-Enterprise-Application-Development-with-Python)
  prefs: []
  type: TYPE_NORMAL
- en: 'The code samples can be cloned by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The steps to set up and run the code have been included inside the `README.md`
    file inside the directory to give a deeper context about the code samples.
  prefs: []
  type: TYPE_NORMAL
- en: The shift toward microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the last few years, developers have been trying to experiment with new
    ways in which they can develop applications. The aim of this is to reduce the
    time of development life cycles, increasing the ability to ship projects faster
    into production, increasing the decoupling between the components so that they
    can be developed independently, and improving the parallelism of the teams working
    on the development of the application.
  prefs: []
  type: TYPE_NORMAL
- en: With this came the development technique of using microservices, which helped
    in solving the aforementioned use cases. In this approach, the application is
    not a single large repository of code where all the components are placed together,
    and where a single change to any of the components requires the deployment of
    the whole application again. First, let's look at how the microservices model
    differs from the monolithic model and then see what advantages there are in following
    the microservices approach.
  prefs: []
  type: TYPE_NORMAL
- en: Monolithic development model versus microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are all accustomed to building an application where a single code base consists
    of all the functional components of an application, closely tied together to achieve
    a certain desired result. These applications follow a rigorous development approach
    where the functioning and architecture of the application is first thought of
    during the initial requirement-gathering and design phases, and then the rigorous
    development of the application starts.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is only after all the components have been developed and thoroughly tested
    that an application enters the production stage, where it is deployed on the infrastructure
    for regular use. This model is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: This process ...
  prefs: []
  type: TYPE_NORMAL
- en: Advantages of the microservices architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The microservices architecture solves a lot of problems for us, mostly because
    of the changes in the way in which we develop and deploy the microservices. Let''s
    go through some of the advantages that the microservices architecture brings to
    our development process, as shown in the following list:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Small teams:** Since a particular microservice usually focuses on doing one
    thing and doing it well, the teams responsible for building that microservice
    can usually be small. A team can own multiple microservices end to end, where
    they are not only responsible for their development but also their deployment
    and management, giving rise to a good DevOps culture.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Increased independence:** In a microservices architecture, the team responsible
    for the development of one microservice does not need to have complete knowledge
    of how another microservice works internally. The teams only need to take care
    of the API endpoints that have been exposed by the microservice in order to interact
    with it. This avoids the dependence of teams on each other to carry out their
    development activities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Increased resilience to failures:** In a microservices architecture, the
    failure resilience is quite high because of the fact that a malfunction in one
    microservice won''t affect the whole application, and will rather provide a gradual
    degradation of the service. During this time, a new instance of the failing service
    might be launched, or the failing service can be easily isolated for debugging
    so as to reduce the impact.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Increased scalability:** The microservices architecture provides a lot of
    freedom in the scalability of the application. Now, as the load increases, the
    individual microservices can be scaled up independently instead of scaling the
    whole application up. This scaling can happen as horizontal scaling, where more
    instances of a select set of microservices can be launched depending upon the
    load being experienced by the application, or these services can be individually
    scaled up using vertical scaling, where more resources are dedicated to a particular
    service to allow for better handling of the increasing load.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Easy integration:** With microservices, the integration between the different
    services is easy, as no knowledge of the internals of the other microservices
    is required. All the integration happens while assuming the other microservices
    to be black boxes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Increased reusability:** Once developed, a microservice can be utilized in
    different applications. For example, a microservice that''s responsible for the
    handling of user authentication can be reused in multiple applications, which
    may require user authentication without the replication of the code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Freedom to roll** **out new features with ease:** With the microservices
    architecture, new features can be rolled out easily. In most cases, a particular
    feature is converted into its own microservice, and the service is then deployed
    in production after proper testing. Once the service is live in production, its
    features are available for use. This differs from the monolithic approach, where
    the whole application needs to be redeployed when a new feature or improvement
    needs to be deployed to production environments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From this list, we can see a number of benefits that the move toward a microservices
    architecture provides us with. From the choice of the tools to the ease in rolling
    out new features, the microservices architecture makes it lucrative for developers
    to hop into the wagon and quickly start rolling out new microservices.
  prefs: []
  type: TYPE_NORMAL
- en: But all of these advantages do not come for free. As much as there are advantages,
    there is also the possibility of creating a mess of the infrastructure while working
    on the microservices architecture, which may not only create increased costs.
    However, this may also impact the overall productivity of the team, which may
    end up more focused on firefighting the issues that may arise because of the flawed
    implementation of the architecture rather than focusing on the improvement and
    development of the features that may be essential to the users of the application.
  prefs: []
  type: TYPE_NORMAL
- en: This is nothing to worry about. We can follow a few simple pieces of advice
    that can help a lot during our journey with the microservices architecture. So,
    let's spend some time understanding these simple tips, which can go a long way
    in helping us make our microservices journey smooth.
  prefs: []
  type: TYPE_NORMAL
- en: Guidelines for microservice development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The development of microservices is challenging, and getting them right is
    quite hard. Is there something we can do to make this process easier? It turns
    out that there are a couple of guidelines that, if followed, can help a lot in
    getting microservices right. So, let''s take a look at these guidelines, as shown
    in the following list:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Design before developing**: When microservices development takes place, they
    are usually supposed to model a particular domain of responsibility. But this
    is also the point where the biggest mistakes occur. Usually, the boundaries of
    a service are not defined. During the later stages, as the domain evolves, the
    microservice also becomes complex so as to handle the increased ...'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service discovery in microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In traditional models of application development, the services pertaining to
    a particular application are usually deployed in a static manner where their network
    locations do not change automatically. If this is the case, then maintaining a
    configuration file that is updated occasionally to reflect the changed network
    location of the services is absolutely fine.
  prefs: []
  type: TYPE_NORMAL
- en: But in modern microservice-based applications—where the number of services may
    go up and down based on a number of factors, such as load balancing, upscaling,
    the launch of new features, and so on—maintaining a configuration file turns out
    to be a bit hard. In addition, most cloud environments these days do not offer
    static network deployments for these services, meaning that the network location
    for the services may keep on changing, adding more trouble to the maintenance
    of the configuration file.
  prefs: []
  type: TYPE_NORMAL
- en: To tackle these kinds of scenarios, we need to have something that is more dynamic
    and can adapt to the changing environment. Enter the concept of service discovery.
    Service discovery allows for the dynamic resolution of the network endpoints of
    a required service and removes the need for a manually updated configuration file.
  prefs: []
  type: TYPE_NORMAL
- en: 'The service discovery usually comes in the following two flavors:'
  prefs: []
  type: TYPE_NORMAL
- en: Client-side service discovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Server-side service discovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: But before we cover these two approaches, we need to understand one more important
    component of the service discovery system. Let's take a look at what this important
    component is and how it facilitates the service discovery process.
  prefs: []
  type: TYPE_NORMAL
- en: Client-side service discovery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the client-side service discovery method, the individual services need
    to be aware of the service registry. For example, in this model, if **Service
    Instance A** wants to make a request to **Service Instance C**, then the process
    of making this request will be as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/87d24590-eb4f-4df1-822c-da856ddefd76.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The flow of the request is explained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Service Instance A** queries the service registry for the network address
    of **Service Instance C**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Service Registry** checks its database for the network address of **Service Instance
    C** and returns it to **Service Instance A**. In case **Service Instance C** is
    a load balanced service ...
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Server-side service discovery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the server-side service discovery pattern, the ability to resolve the
    network address of the services is not present inside the individual clients—rather,
    this logic is moved into the load balancer. Inside a server-side service discovery
    pattern, a request flow looks like the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/2af7c994-b611-4963-8c6d-50a842bfaac0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This diagram shows the following process:'
  prefs: []
  type: TYPE_NORMAL
- en: The **Client** makes a request for an API endpoint
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The **Load Balancer** intercepts the request and queries the **Service Registry**
    to resolve the network address for the appropriate service
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The **Load Balancer** then sends the request to the appropriate network service
    to handle the request
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The advantage of this pattern comes in the form of a reduction of code duplication
    by the removal of service discovery logic from the clients and better load balancing
    because the service registry is not taking up the load of the load-balancing algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know how service discovery happens inside a microservices architecture,
    let's focus our efforts on understanding another interesting concept inside microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine that you are building an application that is supposed to handle multiple
    devices and the functionality provided to every device differs based on certain
    aspects such as mobile devices will not have feature for allowing to send a direct
    message to other users. In this case, every device will require a different API
    endpoint that it can call to access its specific set of services. However, making
    the clients aware of every single API endpoint can become an issue during the
    maintenance phases of the application, or when some of the APIs change. To handle
    these kinds of scenarios, we need to have something that can act as an intermediate
    layer for our communication.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, inside the microservices architecture, we have something to help
    us with this problem. Let's take a look at what we have at our disposal.
  prefs: []
  type: TYPE_NORMAL
- en: Service-level agreements in microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: During the development of any production-grade application based upon microservices
    architecture, the services might depend a lot upon the availability of the other
    services deployed in production. For example, a service providing functionality
    to the administration panel for the application might require the availability
    of the user authentication service to allow for administrator logins and privilege
    management. In case the user management service goes down, there can be severe
    consequences in the stability of the operations provided by the application.
  prefs: []
  type: TYPE_NORMAL
- en: To guarantee these kinds of requirements, we need to have SLAs that act as contracts
    between the teams delivering particular microservices. These ...
  prefs: []
  type: TYPE_NORMAL
- en: Building your first microservices application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are now ready to build our first application using the microservices architecture.
    During the development of this application, we will get to see how we can utilize
    the knowledge that we have gained so far to roll out a working application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, regarding our example, to keep this application simple and provide an
    easy understanding of how the microservices architecture works, we will build
    a simple to-do-list-creation application: Let''s take a look at how this application
    will look, as stipulated in the following list:'
  prefs: []
  type: TYPE_NORMAL
- en: The application will consist of two microservices—namely the to-do manager service
    and the user authentication service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The services will be developed in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the purpose of this exercise, the services will utilize their own SQLite
    databases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The to-do service will depend upon the user service to gather any kind of information
    related to the user operations, including user authentication, profile fetching,
    and so on
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The services will communicate through the use of RESTful APIs, each providing
    a JSON-encoded response
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the basic requirements specified, it's now time for us to start writing
    our microservices.
  prefs: []
  type: TYPE_NORMAL
- en: The user microservice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The user microservice is responsible for handling anything related to user
    profile management. The service facilitates the following functionalities:'
  prefs: []
  type: TYPE_NORMAL
- en: Registration of new users
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Management of user profiles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Authentication of existing users
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating unique authentication tokens for the user to log in with
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Providing user authentication functionality to other services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For this service to operate, we need to have the following two database models:'
  prefs: []
  type: TYPE_NORMAL
- en: '**User database model:** The user database model is responsible for the management
    of the user records, such as their username, hashed passwords, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Token database model:** The token database model is responsible for storing
    information about the tokens that has been generated ...'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The to-do manager service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The to-do manager service is the service that will help our users manage their
    `todo` items. This service provides the functionality for the user to create a
    new list and add items to the list. For this, the only requirement is that the
    user should be authenticated.
  prefs: []
  type: TYPE_NORMAL
- en: To work correctly, the service will require the presence of a list database
    model, which will be used to store the information about the user-created `todo`
    list and an items model, which will contain the list of items for a particular
    `todo` list.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following snippet of code implements these models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Once these models have been developed, the next thing we have to do is implement
    the APIs.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the to-do manager service, the following APIs will be in place, providing
    the interaction endpoints for the service:'
  prefs: []
  type: TYPE_NORMAL
- en: '`/list/new`: This API endpoint takes in the name of the list to be created
    and creates a new list.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/list/add_item`: This API endpoint takes in the list of the items that need
    to be added to the list and the name of the list in which the items are supposed
    to be added. Once validated, the items are added to the list.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/list/view`: This API endpoint takes the name of the list for which the contents
    need to be displayed and displays the content of the list.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following snippet of code shows the endpoint implementations for the service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: With the preceding code in place, we are now ready with our to-do manager service,
    which will help us create and manage our to-do lists through the use of RESTful
    APIs.
  prefs: []
  type: TYPE_NORMAL
- en: 'But before we get the to-do manager service to execute, we need to remember
    one important thing. The service is dependent upon the user service to perform
    any kind of user authentication and to fetch information about the user profile.
    For this to happen, our to-do manager needs to know where the user service is
    running so that it can interact with the user service. For this example, we achieve
    this by setting up a configuration key for the user service endpoint inside the
    to-do manager service configuration file. The following snippet shows the contents
    of the to-do manager service configuration file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'To get the to-do manager service running, the following command needs to be
    executed from inside the `todo_service` directory, inside the repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Once the command executes successfully, the to-do manager service will be available
    at `http://localhost:5001/`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the service is up and running, we can utilize its API to manage our inventory.
    For example, if we wanted to create a new to-do list, all we need to do is send
    an HTTP POST request to the `http://localhost:5001/list/new` API endpoint, passing
    the following keys as JSON formatted inputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '`auth_token`**:** This is the authentication token the user receives after
    successfully logging in with the user service using the `http://localhost:5000/auth/login`
    API endpoint'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`list_name`**:** This is the name of the new list that is to be created'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once the API endpoint call is made, the to-do manager service first makes an
    attempt to validate the `auth` token provided in the API call by interacting with
    the user service. If the `auth` token is validated, the to-do manager service
    then receives a user ID that is used to identify the user. With this complete,
    the to-do manager service creates an entry for the new to-do list inside its database
    against the user ID that has been retrieved.
  prefs: []
  type: TYPE_NORMAL
- en: This was a simple workflow of the to-do manager service.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand how we can build a simple microservice, we can now focus
    on some interesting topics regarding the microservices architecture. Did you notice
    how we informed our to-do manager service of the presence of the user service?
    We utilized a configuration key to achieve this. Using the configuration key is
    by no means a bad option when all you have is two or three services that, no matter
    what happens, will always run on the same endpoints. However, this approach breaks
    down badly when the microservices number even moderately more than two or three
    services, which may run anywhere on the infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: To add on to these troubles, the problem intensifies even further if new services
    are being brought into production frequently to add new features to the application.
    At this point, we will need something better that should not only provide an easy
    way to identify the new services, but also automatically resolve their endpoints.
  prefs: []
  type: TYPE_NORMAL
- en: Service registry inside microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Say there is a magic show that is going to take place inside an auditorium.
    This show is open to everyone, and anyone can come to the auditorium to attend
    it. At the gate of the auditorium, there is a registration desk where you need
    to register before you can enter the auditorium. As soon as the audience members
    start coming, they first go to the registration desk, provide their information—such
    as their names, addresses, and so on—and are then given a ticket to enter the
    auditorium.
  prefs: []
  type: TYPE_NORMAL
- en: The service registry is something like this. It is a special kind of database
    that keeps a record of which services are running on an infrastructure and where
    they are located. Whenever a new service comes up, it registers ...
  prefs: []
  type: TYPE_NORMAL
- en: API gateways in microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When building a microservices architecture, we have a lot of choices, and we
    are mostly free to choose a technology stack that is best suited for implementing
    a microservice. Along with this, we always have an option to render different
    features for different devices by rolling out a different microservice that is
    specific to them. But when we do this, we also add complexity to the client, which
    now has to handle all these different scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let''s first take a look at the challenges we may face on the client side,
    as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/5a3e46ee-c709-497a-9ada-9dc57c1ad77c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding diagram shows the challenges that we face, as shown in the following
    list:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Handling different APIs:** When every device has a specific microservice
    that provides the set of features that it requires, the client for that device
    needs to know about the API endpoints related to that specific service. This adds
    complexity because now the team that is responsible for handling the development
    of the clients needs to be aware of the microservice-specific endpoints that may
    slow down the process of client development.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Changing API endpoints:** Over a period of time, we may modify how a specific
    API endpoint inside a microservice works. This will require us to update all the
    clients that utilize the service provided by the microservice in order to reflect
    these changes. This is a cumbersome process, and could also introduce bugs or
    break existing functionality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Poor protocol support:** With the microservices architecture, we have the
    power to control the technology stack we use to build a microservice. Sometimes,
    a microservice may be powered by a protocol that is usually not supported on other
    platforms or has poor implementation on them. For example, most of the platforms
    on which the client runs may not support something like AMQP, which will make
    the development of the client a hard job, because now the developers have to build
    the logic to handle AMQP protocol inside every client. This kind of requirement
    may not only be challenging, but may also be impossible to complete if the platform
    has no support for handling the excess load of the processing required.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security:** If we need to embed the details of the individual network locations
    of the microservices powering every client, we may also open up security vulnerabilities
    in our infrastructure if even one of these microservices is not configured properly
    for security.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are only a few of the challenges that we may face during the development
    of microservice applications. But can we do something to overcome them?
  prefs: []
  type: TYPE_NORMAL
- en: The answer to this question lies with the use of API gateways.
  prefs: []
  type: TYPE_NORMAL
- en: An **API gateway** can be seen as an intermediary between the client and application
    communication, handling the routing of the client requests and the translation
    of those requests from the protocol that is supported by the client to the protocol
    that is supported by the backend microservice. It does all of this without making
    the client worry about where the microservice may be running.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a microservices-architecture-based application utilizing API gateways, the
    flow of a request from the client to the application may be described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The client has a common set of endpoints that it knows about to access a certain
    set of functionalities.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The client sends a request to the API endpoint, along with any data that needs
    to be passed for the request to be completed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The API gateway intercepts the request made to the API endpoint by the client.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The API gateway determines the client type and the capabilities that are supported
    by the client.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The API gateway then determines the individual microservices that need to be
    called for the request to complete.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The API gateway then forwards the requests to the specific microservices running
    in the backend. In case the protocol accepted by the microservice is different
    from the one in which the client made the request, the API gateway translates
    the request from the client protocol to the one supported by the microservice
    and then forwards the request.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the microservices have finished generating the response, the API gateway
    collects the response and sends a collective response back to the requesting client.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This kind of process has several advantages; let''s take a look at a few of
    them:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Simple clients:** With the API gateways in place, the clients need not be
    aware of the individual microservices that they might need to call. The clients
    here make a call to a common endpoint for a particular functionality, and the
    API gateway is then responsible for figuring out which service needs to be called
    to complete the request. This greatly reduces the complexity of the clients being
    developed and makes their maintenance easy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ease of changing API endpoints:** When there is a change in an implementation
    of a particular API in the backend microservice, the API gateway can handle the
    compatibility for the older clients that have not been updated. This can be done
    by making the API gateway either return a degraded response or automatically update
    the request it has received to the newer API compatibility layer, if this is possible.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Simpler protocol support:** With the API gateway in place to handle any kind
    of conversion of the protocol that might be required by a microservice, the client
    does not need to worry about how to handle the protocols that it cannot support,
    greatly reducing the complexity and the issues that may arise by introducing the
    support for protocol that are not supported by the platform.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Improved security:** With the API gateway, the clients need not be aware
    of the individual network locations of where a particular microservice is running.
    All they need to know is where the API gateway is listening to the requests to
    make a successful API call. Once the call has been made, the API gateway is then
    responsible for determining where the individual microservices serving that API
    are running and then forwarding the request to them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Improved failure handling:** An API gateway can also prove to be of help
    if a particular backend service is experiencing a failure. In this case, if the
    backend microservice was a non-essential microservice, the API gateway can return
    a degraded response back to the client, whereas if there was a failure in an essential
    backend service, the API gateway can immediately return an error response without
    letting the requests queue up, increasing the load on the servers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we can see, the benefits of using an API gateway are enormous and greatly
    simplify the development of the clients in the microservices application. Also,
    by utilizing an API gateway, interservice communication can be easily established.
  prefs: []
  type: TYPE_NORMAL
- en: To have the services communicate with each other, all they have to do is make
    the call to the appropriate endpoint that the API gateway is aware of, and from
    there the API gateway is responsible for determining the appropriate microservice
    and its network address to complete the request that has been made to it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding approach is really good, but there is a drawback: everything
    here is serialized and synchronous in nature. A call is made and then the calling
    client/service waits until a response is generated back. If the load on the services
    is high, these responses may take a long time to arrive, which may either cause
    a large number of requests to queue up on the infrastructure, increasing the load
    even further on the infrastructure, or it may cause a lot of requests to time
    out. This can greatly reduce the throughput of the application, and may even take
    the whole infrastructure down if the number of queued requests becomes really
    large.'
  prefs: []
  type: TYPE_NORMAL
- en: Is there an asynchronous method of communication between these services through
    which they can interact with each other, without making API calls again and again?
    Let's take a look at one such method.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous communication in microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Inside a microservices architecture, every service does one job and does it
    well. To achieve any meaningful response for a business application, these services
    need to communicate with each other. All of this communication happens over the
    network.
  prefs: []
  type: TYPE_NORMAL
- en: Here, a service makes a request to another service and then waits for the response
    to come back. But there is a catch. What if the other service takes a long time
    to process the request, or the service is down? What happens then?
  prefs: []
  type: TYPE_NORMAL
- en: Most of the time, the request will time out. But if this service was a critical
    service, then the number of requests that might be arriving at it may be huge
    and can keep on getting queued up. If the service is slow, this will ...
  prefs: []
  type: TYPE_NORMAL
- en: Message queues for microservices communication
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Message queues are a fairly old mechanism for establishing communication between
    a lot of different components inside an application. This old method is even good
    for our current use cases of the microservices architecture. But before we take
    a dive into how we can use message queues for making microservice communication
    asynchronous, let''s first take a look at some of the jargon that is used when
    dealing with this method of communication:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Message:** A message is a kind of package that a particular service generates
    to communicate about what it wants to achieve to another service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Queue:** A queue is a kind of topic under which a particular message may
    come. For any practical application there could be a number of queues, each representing
    a specific topic of communication.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Producer:** A producer is a service that generates a message and sends it
    to a specific topic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consumer:** A consumer is a service that listens to a specific topic and
    processes any messages that may come to it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Router:** A router is a component inside the message queues that is responsible
    for routing the messages for a particular topic to the appropriate queue.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we know the jargon, we can move on to look at how message queues can
    help us in establishing communication between the microservices.
  prefs: []
  type: TYPE_NORMAL
- en: When the microservices utilize something like a message queue, they interact
    over asynchronous protocols. For example, AMQP is one of the more famous protocols
    for asynchronous communication.
  prefs: []
  type: TYPE_NORMAL
- en: 'With asynchronous communication, the communication between microservices will
    take place as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A message broker is set up, which will provide the functionality for the management
    of the message queues and the routing of the messages to the appropriate queue.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A new service comes up and registers the topic it wants to listen to or send
    the messages to. The message broker creates an appropriate queue for the topic
    and adds the requesting service as either a consumer or a producer for that queue.
    This process also continues for other services.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, a service that wants to achieve a particular goal sends a message to the
    topic, let's say *Topic Authenticate*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A consumer listening to *Topic Authenticate* is notified about a new message
    and consumes it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The consumer processes the message it has consumed and puts a response back
    on another topic, *Topic Auth_Response*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The producer of the original message is the consumer for *Topic Auth_Response*,
    and is notified about a new message.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The original requesting client then reads this message and completes the request–response
    cycle.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, we know what communication inside a microservices architecture that is
    powered by asynchronous message queues looks like. But is there any other benefit
    to this method other than asynchronous communication?
  prefs: []
  type: TYPE_NORMAL
- en: 'It turns out that there are a number of benefits that we may see from such
    a communication pattern. The following list shows some of the benefits that we
    may experience:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Better distribution of requests:** Since there could be a number of consumers
    that may be listening to a particular topic, the messages can be processed in
    parallel, and load balancing can be automatically taken care of by the equal distribution
    of messages among the consumers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Better error resilience:** In the case where a particular microservice goes
    down, the messages that need to be processed by that microservice can be queued
    up inside the message queue for a certain time, and can then be processed by the
    service once it comes up, reducing possible data loss.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reduction in duplicate responses:** Since a message is delivered only once
    to a single consumer and is dequeued as soon as it is consumed, there is a very
    small chance that there could be duplicate responses for a single request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Increased tolerance:** During a time when the different microservices inside
    an infrastructure are experiencing high loads, the message queue system provides
    an asynchronous request–response cycle, thereby reducing the chance of request
    queue-ups.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this, we now have an idea of how we can establish asynchronous communication
    between the microservices and make our infrastructure evolve over time without
    having to worry about how to handle the addition of new API endpoints for interservice
    communication.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we took a look at how we can work with the microservices architecture
    and how it differs from the traditional monolithic way of developing enterprise
    applications. We then took a look at the advantages that come as we move toward
    the microservice development approach and learned about the guidelines that we
    can follow to make our journey toward microservices smoother.
  prefs: []
  type: TYPE_NORMAL
- en: Once we had an idea about the basics of microservices, we went on to take a
    look at how SLAs guarantee us a certain desired set of functionalities between
    the services and how they act as a contract so as to support a smooth service
    by the application. We then moved on to a hands-on exercise by writing a simple
    to-do list management application utilizing ...
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How does a service-oriented architecture differ from a microservice architecture?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can we ensure high uptime for microservice-based applications?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What kind of guarantees are provided by a SLA?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Can we make API gateways communicate directly with the service registry?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the tools that we can use to implement asynchronous communication between
    microservices?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Want to learn more about microservices? Take a look at *Practical Microservices* by
    *Umesh Ram Sharma* from *Packt Publishing*.
  prefs: []
  type: TYPE_NORMAL
